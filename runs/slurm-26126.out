Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 1000 simulations.:   0%|          | 0/1000 [00:00<?, ?it/s]Running 1000 simulations.:   3%|▎         | 30/1000 [00:00<00:03, 291.61it/s]Running 1000 simulations.:   6%|▌         | 60/1000 [00:00<00:03, 292.01it/s]Running 1000 simulations.:   9%|▉         | 90/1000 [00:00<00:03, 292.72it/s]Running 1000 simulations.:  12%|█▏        | 120/1000 [00:00<00:03, 292.37it/s]Running 1000 simulations.:  15%|█▌        | 150/1000 [00:00<00:02, 293.19it/s]Running 1000 simulations.:  18%|█▊        | 180/1000 [00:00<00:02, 294.24it/s]Running 1000 simulations.:  21%|██        | 210/1000 [00:00<00:02, 294.43it/s]Running 1000 simulations.:  24%|██▍       | 240/1000 [00:00<00:02, 294.49it/s]Running 1000 simulations.:  27%|██▋       | 270/1000 [00:00<00:02, 294.06it/s]Running 1000 simulations.:  30%|███       | 300/1000 [00:01<00:02, 293.62it/s]Running 1000 simulations.:  33%|███▎      | 330/1000 [00:01<00:02, 292.95it/s]Running 1000 simulations.:  36%|███▌      | 360/1000 [00:01<00:02, 292.96it/s]Running 1000 simulations.:  39%|███▉      | 390/1000 [00:01<00:02, 293.20it/s]Running 1000 simulations.:  42%|████▏     | 420/1000 [00:01<00:01, 293.59it/s]Running 1000 simulations.:  45%|████▌     | 450/1000 [00:01<00:01, 293.56it/s]Running 1000 simulations.:  48%|████▊     | 480/1000 [00:01<00:01, 292.87it/s]Running 1000 simulations.:  51%|█████     | 510/1000 [00:01<00:01, 293.28it/s]Running 1000 simulations.:  54%|█████▍    | 540/1000 [00:01<00:01, 292.07it/s]Running 1000 simulations.:  57%|█████▋    | 570/1000 [00:01<00:01, 292.28it/s]Running 1000 simulations.:  60%|██████    | 600/1000 [00:02<00:01, 290.83it/s]Running 1000 simulations.:  63%|██████▎   | 630/1000 [00:02<00:01, 290.27it/s]Running 1000 simulations.:  66%|██████▌   | 660/1000 [00:02<00:01, 290.17it/s]Running 1000 simulations.:  69%|██████▉   | 690/1000 [00:02<00:01, 290.35it/s]Running 1000 simulations.:  72%|███████▏  | 720/1000 [00:02<00:00, 290.50it/s]Running 1000 simulations.:  75%|███████▌  | 750/1000 [00:02<00:00, 290.96it/s]Running 1000 simulations.:  78%|███████▊  | 780/1000 [00:02<00:00, 291.34it/s]Running 1000 simulations.:  81%|████████  | 810/1000 [00:02<00:00, 292.03it/s]Running 1000 simulations.:  84%|████████▍ | 840/1000 [00:02<00:00, 291.72it/s]Running 1000 simulations.:  87%|████████▋ | 870/1000 [00:02<00:00, 291.62it/s]Running 1000 simulations.:  90%|█████████ | 900/1000 [00:03<00:00, 292.44it/s]Running 1000 simulations.:  93%|█████████▎| 930/1000 [00:03<00:00, 292.27it/s]Running 1000 simulations.:  96%|█████████▌| 960/1000 [00:03<00:00, 292.12it/s]Running 1000 simulations.:  99%|█████████▉| 990/1000 [00:03<00:00, 292.81it/s]Running 1000 simulations.: 100%|██████████| 1000/1000 [00:03<00:00, 292.45it/s]
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5823it [00:00, 66682.59it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples:  99%|█████████▉| 4972/5000 [00:00<00:00, 49238.73it/s]Drawing 5000 posterior samples: 5691it [00:00, 48684.04it/s]                          
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5249it [00:00, 61648.99it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5142it [00:00, 60756.02it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 7735it [00:00, 312462.12it/s]           
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 6265it [00:00, 88577.21it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 6183it [00:00, 87891.59it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5898it [00:00, 68770.36it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5157it [00:00, 212402.67it/s]           
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5688it [00:00, 56599.91it/s]            Drawing 5000 posterior samples: 5688it [00:00, 56431.35it/s]
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5627it [00:00, 79074.44it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 6452it [00:00, 260930.74it/s]           
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5500it [00:00, 53989.34it/s]            Drawing 5000 posterior samples: 5500it [00:00, 53826.20it/s]
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples:  85%|████████▌ | 4259/5000 [00:00<00:00, 42502.18it/s]Drawing 5000 posterior samples: 5520it [00:00, 42070.17it/s]                          
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5506it [00:00, 64972.53it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5502it [00:00, 63913.69it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5219it [00:00, 60191.80it/s]            
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 8035it [00:00, 328459.25it/s]           
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5117it [00:00, 49718.32it/s]            Drawing 5000 posterior samples: 5117it [00:00, 49559.31it/s]
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples: 5626it [00:00, 231394.56it/s]           
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00<?, ?it/s]Drawing 5000 posterior samples:  79%|███████▉  | 3969/5000 [00:00<00:00, 39430.38it/s]Drawing 5000 posterior samples: 5149it [00:00, 39131.27it/s]                          
lstm_sbi.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Neural network successfully converged after 364 epochs.
torch.Size([350, 10, 5])
tensor([0.0068, 0.0062, 0.0073, 0.0037, 0.0072, 0.0067, 0.0077, 0.0073, 0.0073,
        0.0073, 0.0077, 0.0086, 0.0095, 0.0116, 0.0122, 0.0126, 0.0112, 0.0097,
        0.0098, 0.0103, 0.0104, 0.0127, 0.0119, 0.0111, 0.0106, 0.0123, 0.0113,
        0.0114, 0.0131, 0.0136, 0.0118, 0.0133, 0.0128, 0.0129, 0.0124, 0.0144,
        0.0165, 0.0173, 0.0174, 0.0170, 0.0155, 0.0160, 0.0166, 0.0172, 0.0191,
        0.0195, 0.0186, 0.0190, 0.0179, 0.0179, 0.0188, 0.0189, 0.0215, 0.0224,
        0.0206, 0.0210, 0.0195, 0.0185, 0.0173, 0.0185, 0.0181, 0.0176, 0.0171,
        0.0164, 0.0173, 0.0168, 0.0175, 0.0198, 0.0207, 0.0191, 0.0200, 0.0205,
        0.0216, 0.0217, 0.0205, 0.0194, 0.0189, 0.0195, 0.0189, 0.0189, 0.0186,
        0.0176, 0.0185, 0.0199, 0.0215, 0.0222, 0.0205, 0.0201, 0.0201, 0.0202,
        0.0216, 0.0218, 0.0215, 0.0199, 0.0203, 0.0209, 0.0193, 0.0192, 0.0184,
        0.0180, 0.0172, 0.0165, 0.0194, 0.0210, 0.0204, 0.0212, 0.0226, 0.0223,
        0.0213, 0.0212, 0.0226, 0.0217, 0.0221, 0.0215, 0.0213, 0.0211, 0.0216,
        0.0214, 0.0215, 0.0219, 0.0219, 0.0215, 0.0211, 0.0209, 0.0193, 0.0183,
        0.0166, 0.0171, 0.0185, 0.0199, 0.0195, 0.0204, 0.0200, 0.0193, 0.0192,
        0.0189, 0.0186, 0.0199, 0.0228, 0.0247, 0.0234, 0.0215, 0.0183, 0.0237,
        0.0191, 0.0187, 0.0176, 0.0181, 0.0192, 0.0204, 0.0204, 0.0225, 0.0205,
        0.0202, 0.0200, 0.0205, 0.0202, 0.0177, 0.0162, 0.0164, 0.0172, 0.0175,
        0.0179, 0.0202, 0.0172, 0.0176, 0.0147, 0.0163, 0.0171, 0.0167, 0.0167,
        0.0179, 0.0181, 0.0189, 0.0184, 0.0214, 0.0195, 0.0192, 0.0226, 0.0231,
        0.0201, 0.0174, 0.0179, 0.0173, 0.0157, 0.0159, 0.0170, 0.0171, 0.0182,
        0.0193, 0.0207, 0.0233, 0.0230, 0.0201, 0.0211, 0.0200, 0.0231, 0.0267,
        0.0280, 0.0275, 0.0267, 0.0245, 0.0236, 0.0268, 0.0332, 0.0273, 0.0330,
        0.0366, 0.0329, 0.0328, 0.0309, 0.0329, 0.0313, 0.0410, 0.0442, 0.0520,
        0.0555, 0.0472, 0.0524, 0.0528, 0.0542, 0.0583, 0.0572, 0.0589, 0.0632,
        0.0665, 0.0613, 0.0634, 0.0643, 0.0643, 0.0640, 0.0686, 0.0770, 0.0827,
        0.0769, 0.0862, 0.0933, 0.1064, 0.1152, 0.1126, 0.1088, 0.1147, 0.1148,
        0.1148, 0.1081, 0.1183, 0.1202, 0.1349, 0.1379, 0.1519, 0.1777, 0.1965,
        0.1920, 0.1830, 0.1697, 0.1693, 0.1624, 0.1599, 0.1324, 0.1303, 0.1273,
        0.1177, 0.1014, 0.1068, 0.1032, 0.1154, 0.1117, 0.1077, 0.0991, 0.0966,
        0.0916, 0.0880, 0.0872, 0.0838, 0.0803, 0.0736, 0.0733, 0.0708, 0.0697,
        0.0662, 0.0661, 0.0668, 0.0625, 0.0592, 0.0530, 0.0450, 0.0416, 0.0388,
        0.0336, 0.0337, 0.0345, 0.0302, 0.0276, 0.0261, 0.0227, 0.0202, 0.0175,
        0.0160, 0.0159, 0.0149, 0.0154, 0.0168, 0.0164, 0.0145, 0.0107, 0.0111,
        0.0119, 0.0148, 0.0167, 0.0118, 0.0116, 0.0117, 0.0152, 0.0163, 0.0181,
        0.0217, 0.0200, 0.0201, 0.0180, 0.0140, 0.0137, 0.0119, 0.0109, 0.0120,
        0.0134, 0.0118, 0.0120, 0.0150, 0.0112, 0.0159, 0.0186, 0.0170, 0.0180,
        0.0163, 0.0177, 0.0173, 0.0161, 0.0169, 0.0155, 0.0139, 0.0135, 0.0092,
        0.0098, 0.0096, 0.0101, 0.0108, 0.0127, 0.0147, 0.0153, 0.0177],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0079, 0.0071, 0.0082, 0.0043, 0.0072, 0.0059, 0.0069, 0.0062, 0.0063,
        0.0064, 0.0068, 0.0074, 0.0082, 0.0099, 0.0105, 0.0109, 0.0098, 0.0087,
        0.0087, 0.0092, 0.0086, 0.0111, 0.0104, 0.0099, 0.0094, 0.0098, 0.0095,
        0.0096, 0.0112, 0.0115, 0.0099, 0.0112, 0.0107, 0.0108, 0.0102, 0.0123,
        0.0141, 0.0149, 0.0149, 0.0145, 0.0132, 0.0136, 0.0142, 0.0147, 0.0164,
        0.0166, 0.0157, 0.0162, 0.0153, 0.0153, 0.0162, 0.0163, 0.0191, 0.0205,
        0.0181, 0.0184, 0.0168, 0.0158, 0.0147, 0.0158, 0.0153, 0.0148, 0.0144,
        0.0137, 0.0147, 0.0143, 0.0150, 0.0172, 0.0182, 0.0166, 0.0177, 0.0184,
        0.0194, 0.0195, 0.0182, 0.0170, 0.0166, 0.0170, 0.0164, 0.0163, 0.0159,
        0.0149, 0.0158, 0.0172, 0.0188, 0.0193, 0.0176, 0.0173, 0.0174, 0.0175,
        0.0188, 0.0191, 0.0188, 0.0173, 0.0176, 0.0182, 0.0165, 0.0164, 0.0157,
        0.0153, 0.0145, 0.0139, 0.0168, 0.0186, 0.0181, 0.0189, 0.0201, 0.0197,
        0.0188, 0.0188, 0.0203, 0.0193, 0.0196, 0.0190, 0.0188, 0.0187, 0.0192,
        0.0193, 0.0192, 0.0195, 0.0196, 0.0198, 0.0187, 0.0186, 0.0170, 0.0159,
        0.0143, 0.0147, 0.0161, 0.0175, 0.0172, 0.0181, 0.0177, 0.0170, 0.0169,
        0.0166, 0.0161, 0.0175, 0.0210, 0.0226, 0.0211, 0.0190, 0.0157, 0.0217,
        0.0164, 0.0162, 0.0150, 0.0156, 0.0169, 0.0182, 0.0179, 0.0202, 0.0182,
        0.0180, 0.0178, 0.0183, 0.0180, 0.0154, 0.0139, 0.0141, 0.0146, 0.0152,
        0.0157, 0.0182, 0.0153, 0.0155, 0.0124, 0.0143, 0.0151, 0.0146, 0.0146,
        0.0157, 0.0159, 0.0168, 0.0163, 0.0196, 0.0178, 0.0175, 0.0207, 0.0212,
        0.0182, 0.0155, 0.0158, 0.0151, 0.0134, 0.0137, 0.0150, 0.0151, 0.0161,
        0.0173, 0.0187, 0.0211, 0.0209, 0.0180, 0.0192, 0.0177, 0.0209, 0.0253,
        0.0268, 0.0262, 0.0255, 0.0230, 0.0220, 0.0251, 0.0314, 0.0252, 0.0313,
        0.0344, 0.0309, 0.0313, 0.0297, 0.0316, 0.0298, 0.0402, 0.0442, 0.0523,
        0.0548, 0.0467, 0.0524, 0.0527, 0.0546, 0.0595, 0.0589, 0.0609, 0.0650,
        0.0678, 0.0630, 0.0645, 0.0652, 0.0647, 0.0645, 0.0697, 0.0787, 0.0850,
        0.0806, 0.0905, 0.0989, 0.1121, 0.1198, 0.1165, 0.1120, 0.1171, 0.1168,
        0.1165, 0.1103, 0.1215, 0.1241, 0.1391, 0.1454, 0.1719, 0.1932, 0.2063,
        0.1940, 0.1801, 0.1656, 0.1676, 0.1602, 0.1534, 0.1257, 0.1178, 0.1150,
        0.1133, 0.1001, 0.1095, 0.1065, 0.1176, 0.1119, 0.1064, 0.0966, 0.0928,
        0.0871, 0.0832, 0.0818, 0.0781, 0.0751, 0.0697, 0.0697, 0.0671, 0.0651,
        0.0611, 0.0606, 0.0611, 0.0567, 0.0535, 0.0475, 0.0402, 0.0371, 0.0348,
        0.0303, 0.0301, 0.0311, 0.0274, 0.0251, 0.0240, 0.0207, 0.0183, 0.0157,
        0.0142, 0.0140, 0.0130, 0.0135, 0.0149, 0.0146, 0.0129, 0.0093, 0.0098,
        0.0104, 0.0132, 0.0148, 0.0099, 0.0103, 0.0102, 0.0131, 0.0139, 0.0156,
        0.0191, 0.0176, 0.0174, 0.0158, 0.0120, 0.0120, 0.0102, 0.0095, 0.0103,
        0.0117, 0.0103, 0.0105, 0.0130, 0.0087, 0.0134, 0.0162, 0.0146, 0.0155,
        0.0138, 0.0150, 0.0147, 0.0139, 0.0146, 0.0134, 0.0119, 0.0117, 0.0075,
        0.0087, 0.0087, 0.0089, 0.0094, 0.0111, 0.0128, 0.0139, 0.0155],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0071, 0.0065, 0.0076, 0.0040, 0.0075, 0.0068, 0.0078, 0.0073, 0.0072,
        0.0072, 0.0077, 0.0085, 0.0096, 0.0116, 0.0122, 0.0126, 0.0113, 0.0098,
        0.0099, 0.0102, 0.0105, 0.0127, 0.0119, 0.0112, 0.0107, 0.0123, 0.0113,
        0.0114, 0.0131, 0.0136, 0.0118, 0.0133, 0.0127, 0.0129, 0.0124, 0.0144,
        0.0165, 0.0173, 0.0174, 0.0170, 0.0155, 0.0160, 0.0166, 0.0172, 0.0191,
        0.0194, 0.0185, 0.0189, 0.0179, 0.0179, 0.0187, 0.0189, 0.0215, 0.0224,
        0.0206, 0.0210, 0.0195, 0.0184, 0.0173, 0.0185, 0.0181, 0.0175, 0.0171,
        0.0164, 0.0173, 0.0168, 0.0175, 0.0198, 0.0207, 0.0191, 0.0201, 0.0205,
        0.0216, 0.0217, 0.0204, 0.0193, 0.0189, 0.0195, 0.0189, 0.0188, 0.0185,
        0.0176, 0.0185, 0.0199, 0.0215, 0.0221, 0.0205, 0.0201, 0.0201, 0.0202,
        0.0215, 0.0217, 0.0215, 0.0199, 0.0202, 0.0208, 0.0192, 0.0192, 0.0184,
        0.0179, 0.0171, 0.0165, 0.0194, 0.0210, 0.0204, 0.0212, 0.0225, 0.0222,
        0.0213, 0.0212, 0.0226, 0.0217, 0.0221, 0.0214, 0.0212, 0.0211, 0.0215,
        0.0214, 0.0214, 0.0218, 0.0218, 0.0214, 0.0211, 0.0209, 0.0193, 0.0182,
        0.0166, 0.0170, 0.0185, 0.0198, 0.0194, 0.0203, 0.0200, 0.0193, 0.0192,
        0.0189, 0.0185, 0.0198, 0.0228, 0.0247, 0.0234, 0.0214, 0.0182, 0.0236,
        0.0190, 0.0186, 0.0175, 0.0180, 0.0192, 0.0204, 0.0204, 0.0225, 0.0204,
        0.0202, 0.0200, 0.0205, 0.0202, 0.0176, 0.0161, 0.0164, 0.0171, 0.0175,
        0.0179, 0.0202, 0.0172, 0.0176, 0.0147, 0.0163, 0.0171, 0.0167, 0.0167,
        0.0178, 0.0181, 0.0189, 0.0184, 0.0214, 0.0195, 0.0192, 0.0225, 0.0231,
        0.0200, 0.0174, 0.0177, 0.0172, 0.0156, 0.0158, 0.0170, 0.0171, 0.0181,
        0.0193, 0.0207, 0.0232, 0.0229, 0.0200, 0.0211, 0.0199, 0.0230, 0.0267,
        0.0280, 0.0275, 0.0268, 0.0245, 0.0236, 0.0267, 0.0332, 0.0272, 0.0328,
        0.0364, 0.0328, 0.0327, 0.0309, 0.0329, 0.0312, 0.0412, 0.0445, 0.0523,
        0.0556, 0.0474, 0.0527, 0.0531, 0.0545, 0.0589, 0.0579, 0.0596, 0.0639,
        0.0670, 0.0619, 0.0638, 0.0647, 0.0646, 0.0643, 0.0691, 0.0776, 0.0834,
        0.0779, 0.0873, 0.0946, 0.1077, 0.1163, 0.1136, 0.1096, 0.1153, 0.1153,
        0.1153, 0.1086, 0.1191, 0.1211, 0.1358, 0.1394, 0.1558, 0.1819, 0.1993,
        0.1926, 0.1826, 0.1691, 0.1695, 0.1631, 0.1601, 0.1312, 0.1275, 0.1232,
        0.1170, 0.1011, 0.1074, 0.1041, 0.1159, 0.1117, 0.1074, 0.0986, 0.0957,
        0.0905, 0.0869, 0.0859, 0.0825, 0.0792, 0.0729, 0.0726, 0.0701, 0.0689,
        0.0653, 0.0651, 0.0658, 0.0615, 0.0583, 0.0521, 0.0442, 0.0408, 0.0380,
        0.0330, 0.0330, 0.0338, 0.0296, 0.0271, 0.0256, 0.0222, 0.0197, 0.0171,
        0.0156, 0.0155, 0.0146, 0.0151, 0.0165, 0.0161, 0.0142, 0.0104, 0.0108,
        0.0116, 0.0145, 0.0164, 0.0117, 0.0115, 0.0117, 0.0152, 0.0163, 0.0181,
        0.0217, 0.0200, 0.0200, 0.0180, 0.0140, 0.0137, 0.0118, 0.0108, 0.0118,
        0.0133, 0.0117, 0.0119, 0.0150, 0.0111, 0.0158, 0.0186, 0.0169, 0.0179,
        0.0162, 0.0176, 0.0172, 0.0160, 0.0168, 0.0155, 0.0139, 0.0134, 0.0091,
        0.0098, 0.0096, 0.0101, 0.0109, 0.0127, 0.0147, 0.0154, 0.0179],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0076, 0.0069, 0.0081, 0.0046, 0.0080, 0.0070, 0.0081, 0.0074, 0.0073,
        0.0073, 0.0077, 0.0087, 0.0097, 0.0118, 0.0124, 0.0128, 0.0117, 0.0100,
        0.0101, 0.0103, 0.0108, 0.0129, 0.0121, 0.0114, 0.0109, 0.0126, 0.0115,
        0.0116, 0.0134, 0.0139, 0.0120, 0.0135, 0.0129, 0.0131, 0.0125, 0.0146,
        0.0168, 0.0175, 0.0176, 0.0172, 0.0158, 0.0163, 0.0169, 0.0174, 0.0192,
        0.0195, 0.0187, 0.0191, 0.0181, 0.0181, 0.0190, 0.0191, 0.0217, 0.0226,
        0.0208, 0.0212, 0.0197, 0.0186, 0.0175, 0.0187, 0.0183, 0.0177, 0.0173,
        0.0166, 0.0176, 0.0171, 0.0178, 0.0200, 0.0209, 0.0194, 0.0203, 0.0208,
        0.0218, 0.0219, 0.0206, 0.0195, 0.0191, 0.0197, 0.0191, 0.0190, 0.0187,
        0.0178, 0.0187, 0.0201, 0.0216, 0.0223, 0.0207, 0.0203, 0.0203, 0.0204,
        0.0217, 0.0219, 0.0216, 0.0200, 0.0203, 0.0209, 0.0194, 0.0193, 0.0186,
        0.0181, 0.0173, 0.0166, 0.0196, 0.0212, 0.0206, 0.0213, 0.0226, 0.0224,
        0.0214, 0.0213, 0.0227, 0.0218, 0.0222, 0.0215, 0.0213, 0.0212, 0.0217,
        0.0215, 0.0215, 0.0220, 0.0219, 0.0215, 0.0213, 0.0210, 0.0195, 0.0184,
        0.0168, 0.0172, 0.0186, 0.0200, 0.0196, 0.0204, 0.0201, 0.0194, 0.0193,
        0.0190, 0.0187, 0.0200, 0.0229, 0.0247, 0.0235, 0.0215, 0.0183, 0.0236,
        0.0191, 0.0187, 0.0175, 0.0181, 0.0194, 0.0206, 0.0205, 0.0227, 0.0206,
        0.0204, 0.0202, 0.0207, 0.0204, 0.0177, 0.0162, 0.0165, 0.0171, 0.0176,
        0.0181, 0.0204, 0.0175, 0.0178, 0.0149, 0.0166, 0.0174, 0.0170, 0.0169,
        0.0180, 0.0183, 0.0191, 0.0186, 0.0217, 0.0198, 0.0195, 0.0226, 0.0232,
        0.0202, 0.0174, 0.0177, 0.0171, 0.0157, 0.0159, 0.0172, 0.0174, 0.0183,
        0.0194, 0.0208, 0.0231, 0.0230, 0.0201, 0.0212, 0.0200, 0.0230, 0.0269,
        0.0282, 0.0277, 0.0270, 0.0246, 0.0237, 0.0269, 0.0333, 0.0272, 0.0328,
        0.0361, 0.0327, 0.0328, 0.0310, 0.0330, 0.0313, 0.0416, 0.0451, 0.0528,
        0.0559, 0.0478, 0.0532, 0.0536, 0.0552, 0.0598, 0.0589, 0.0607, 0.0649,
        0.0679, 0.0629, 0.0646, 0.0654, 0.0650, 0.0648, 0.0698, 0.0786, 0.0846,
        0.0794, 0.0890, 0.0967, 0.1098, 0.1180, 0.1150, 0.1108, 0.1162, 0.1162,
        0.1160, 0.1095, 0.1204, 0.1226, 0.1373, 0.1418, 0.1627, 0.1873, 0.2027,
        0.1932, 0.1815, 0.1676, 0.1692, 0.1631, 0.1580, 0.1292, 0.1231, 0.1182,
        0.1156, 0.1007, 0.1085, 0.1053, 0.1167, 0.1119, 0.1070, 0.0977, 0.0944,
        0.0891, 0.0854, 0.0842, 0.0808, 0.0776, 0.0718, 0.0716, 0.0690, 0.0676,
        0.0640, 0.0637, 0.0644, 0.0601, 0.0570, 0.0509, 0.0431, 0.0398, 0.0369,
        0.0320, 0.0321, 0.0330, 0.0288, 0.0263, 0.0249, 0.0216, 0.0191, 0.0165,
        0.0151, 0.0150, 0.0142, 0.0146, 0.0160, 0.0158, 0.0138, 0.0101, 0.0105,
        0.0112, 0.0141, 0.0160, 0.0115, 0.0116, 0.0117, 0.0153, 0.0164, 0.0183,
        0.0219, 0.0202, 0.0202, 0.0182, 0.0141, 0.0138, 0.0119, 0.0107, 0.0117,
        0.0132, 0.0116, 0.0118, 0.0150, 0.0111, 0.0159, 0.0187, 0.0170, 0.0180,
        0.0162, 0.0175, 0.0172, 0.0160, 0.0168, 0.0155, 0.0139, 0.0135, 0.0092,
        0.0098, 0.0097, 0.0102, 0.0111, 0.0129, 0.0149, 0.0156, 0.0183],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([-8.8915e-05,  7.4144e-04,  1.9256e-03,  1.2777e-02,  1.9560e-02,
         2.7613e-02,  2.9135e-02,  3.1683e-02,  3.2470e-02,  3.2980e-02,
         3.3275e-02,  3.1590e-02,  3.1253e-02,  3.3964e-02,  3.5835e-02,
         3.3942e-02,  3.3584e-02,  3.2011e-02,  2.9967e-02,  2.7386e-02,
         2.6590e-02,  2.7348e-02,  3.2601e-02,  3.2090e-02,  3.1498e-02,
         3.3881e-02,  3.1288e-02,  2.8493e-02,  2.8042e-02,  2.7126e-02,
         2.9077e-02,  2.9080e-02,  2.8010e-02,  2.8026e-02,  3.2542e-02,
         3.0660e-02,  2.9936e-02,  3.5850e-02,  3.8078e-02,  3.6120e-02,
         3.2783e-02,  3.3145e-02,  3.3597e-02,  3.6294e-02,  4.0902e-02,
         4.4574e-02,  4.2804e-02,  4.0859e-02,  3.9289e-02,  3.9635e-02,
         3.8302e-02,  3.8845e-02,  3.9117e-02,  3.9723e-02,  4.1544e-02,
         4.2684e-02,  4.3148e-02,  4.1121e-02,  4.1224e-02,  3.9559e-02,
         3.8415e-02,  3.8940e-02,  4.0530e-02,  3.9852e-02,  3.8047e-02,
         3.6291e-02,  3.7128e-02,  3.9172e-02,  3.9005e-02,  3.2966e-02,
         2.8758e-02,  2.9087e-02,  3.2795e-02,  3.7415e-02,  3.8408e-02,
         3.6218e-02,  3.7630e-02,  3.6653e-02,  3.7499e-02,  3.8915e-02,
         4.0109e-02,  3.9488e-02,  3.8616e-02,  4.1182e-02,  4.7671e-02,
         4.7836e-02,  4.6175e-02,  4.5448e-02,  4.4579e-02,  4.4471e-02,
         4.5186e-02,  4.5737e-02,  4.5768e-02,  4.4184e-02,  4.4391e-02,
         4.4267e-02,  4.5385e-02,  4.3775e-02,  4.2235e-02,  4.1849e-02,
         4.2196e-02,  4.1097e-02,  4.0824e-02,  3.8103e-02,  3.8398e-02,
         4.2182e-02,  4.3067e-02,  4.0581e-02,  3.9794e-02,  4.1092e-02,
         4.0767e-02,  4.1623e-02,  4.3066e-02,  4.3611e-02,  4.3136e-02,
         4.3619e-02,  4.3219e-02,  4.2837e-02,  4.3872e-02,  4.5076e-02,
         4.6427e-02,  4.6029e-02,  4.5283e-02,  4.1160e-02,  4.1084e-02,
         3.9408e-02,  3.8146e-02,  3.6759e-02,  3.6031e-02,  3.4956e-02,
         3.5300e-02,  3.7822e-02,  3.8794e-02,  3.9512e-02,  3.9720e-02,
         4.1054e-02,  4.2416e-02,  4.3899e-02,  4.3485e-02,  4.8125e-02,
         4.4948e-02,  4.1695e-02,  4.3915e-02,  4.5277e-02,  4.6071e-02,
         4.2731e-02,  4.2200e-02,  4.2852e-02,  4.0783e-02,  4.2878e-02,
         4.1254e-02,  4.2157e-02,  4.1064e-02,  4.0342e-02,  4.0729e-02,
         4.1595e-02,  4.3617e-02,  4.3902e-02,  4.1847e-02,  4.2667e-02,
         3.9186e-02,  3.9813e-02,  3.4925e-02,  3.7705e-02,  3.3224e-02,
         3.1765e-02,  3.1523e-02,  3.1989e-02,  3.1616e-02,  3.0647e-02,
         3.0787e-02,  3.1171e-02,  3.2783e-02,  3.5174e-02,  3.7422e-02,
         3.6887e-02,  3.4219e-02,  3.3829e-02,  4.4032e-02,  4.3728e-02,
         3.9399e-02,  3.6361e-02,  3.2966e-02,  3.3038e-02,  2.7221e-02,
         2.9650e-02,  3.0558e-02,  2.3605e-02,  3.2753e-02,  2.8007e-02,
         3.2096e-02,  3.2832e-02,  3.2283e-02,  3.1998e-02,  3.3423e-02,
         3.6791e-02,  3.8587e-02,  3.7556e-02,  3.9939e-02,  3.8726e-02,
         4.0104e-02,  4.1351e-02,  3.9129e-02,  3.2963e-02,  3.5768e-02,
         2.9235e-02,  4.3916e-02,  3.9649e-02,  3.8255e-02,  4.0401e-02,
         3.7017e-02,  3.9499e-02,  4.1252e-02,  3.9091e-02,  3.4757e-02,
         3.7577e-02,  5.5793e-02,  5.1464e-02,  5.2618e-02,  5.0746e-02,
         4.8193e-02,  4.6731e-02,  4.4150e-02,  4.2499e-02,  4.8361e-02,
         5.4354e-02,  4.7486e-02,  4.7379e-02,  5.0257e-02,  5.4159e-02,
         5.3039e-02,  5.2439e-02,  5.7366e-02,  5.7895e-02,  5.2994e-02,
         5.4608e-02,  4.9199e-02,  5.5287e-02,  6.3253e-02,  6.3872e-02,
         6.5301e-02,  7.3925e-02,  7.7233e-02,  7.8576e-02,  6.9395e-02,
         7.0971e-02,  7.3820e-02,  7.4176e-02,  6.8615e-02,  7.2757e-02,
         7.4123e-02,  8.2813e-02,  8.5543e-02,  8.9058e-02,  8.9867e-02,
         9.0188e-02,  9.2827e-02,  9.1396e-02,  8.5564e-02,  8.5248e-02,
         8.5304e-02,  7.4520e-02,  7.7148e-02,  8.1454e-02,  8.3511e-02,
         9.4533e-02,  1.0352e-01,  1.1226e-01,  1.0947e-01,  1.1086e-01,
         1.0704e-01,  1.0227e-01,  1.0427e-01,  1.0506e-01,  1.0620e-01,
         1.0605e-01,  1.0972e-01,  1.0974e-01,  1.1674e-01,  1.1392e-01,
         1.1550e-01,  1.1141e-01,  1.0480e-01,  1.0538e-01,  1.0086e-01,
         1.0136e-01,  1.0512e-01,  1.0253e-01,  1.0648e-01,  1.0493e-01,
         1.0478e-01,  9.8666e-02,  1.0272e-01,  1.0069e-01,  1.0291e-01,
         1.0002e-01,  9.8603e-02,  9.2324e-02,  9.1283e-02,  8.3218e-02,
         8.1384e-02,  8.6282e-02,  9.1143e-02,  9.5367e-02,  8.7215e-02,
         7.5803e-02,  6.4778e-02,  6.7995e-02,  6.9347e-02,  5.9747e-02,
         5.6006e-02,  4.9892e-02,  5.3653e-02,  6.3330e-02,  6.1929e-02,
         5.9692e-02,  5.7386e-02,  5.8005e-02,  5.5047e-02,  4.8153e-02,
         4.5379e-02,  4.3685e-02,  4.3103e-02,  4.8539e-02,  4.9442e-02,
         4.6657e-02,  4.9126e-02,  4.8239e-02,  4.0888e-02,  3.9601e-02,
         3.9308e-02,  4.2162e-02,  4.1917e-02,  5.0430e-02,  5.3117e-02,
         4.5657e-02,  4.5907e-02,  4.6680e-02,  4.5653e-02,  4.3734e-02,
         4.3495e-02,  4.7738e-02,  4.2040e-02,  3.8337e-02,  3.7407e-02,
         3.4322e-02,  2.8065e-02,  2.6276e-02,  2.5321e-02,  2.8745e-02],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0049, 0.0048, 0.0060, 0.0035, 0.0081, 0.0093, 0.0103, 0.0100, 0.0098,
        0.0096, 0.0103, 0.0114, 0.0127, 0.0151, 0.0158, 0.0159, 0.0142, 0.0119,
        0.0123, 0.0127, 0.0140, 0.0159, 0.0151, 0.0140, 0.0135, 0.0170, 0.0151,
        0.0152, 0.0169, 0.0174, 0.0156, 0.0176, 0.0170, 0.0169, 0.0168, 0.0187,
        0.0209, 0.0213, 0.0217, 0.0213, 0.0198, 0.0202, 0.0209, 0.0215, 0.0236,
        0.0243, 0.0235, 0.0235, 0.0222, 0.0222, 0.0231, 0.0231, 0.0253, 0.0251,
        0.0245, 0.0252, 0.0240, 0.0231, 0.0219, 0.0231, 0.0228, 0.0222, 0.0220,
        0.0212, 0.0220, 0.0214, 0.0220, 0.0241, 0.0246, 0.0230, 0.0236, 0.0237,
        0.0247, 0.0249, 0.0238, 0.0228, 0.0225, 0.0231, 0.0229, 0.0232, 0.0230,
        0.0222, 0.0231, 0.0242, 0.0258, 0.0266, 0.0252, 0.0247, 0.0246, 0.0245,
        0.0258, 0.0260, 0.0256, 0.0240, 0.0242, 0.0251, 0.0240, 0.0238, 0.0230,
        0.0225, 0.0218, 0.0211, 0.0236, 0.0247, 0.0239, 0.0247, 0.0262, 0.0260,
        0.0251, 0.0247, 0.0259, 0.0252, 0.0258, 0.0251, 0.0249, 0.0246, 0.0251,
        0.0246, 0.0248, 0.0254, 0.0251, 0.0239, 0.0247, 0.0243, 0.0230, 0.0221,
        0.0206, 0.0210, 0.0223, 0.0235, 0.0229, 0.0237, 0.0235, 0.0229, 0.0228,
        0.0226, 0.0225, 0.0236, 0.0255, 0.0277, 0.0268, 0.0251, 0.0226, 0.0266,
        0.0232, 0.0227, 0.0216, 0.0220, 0.0227, 0.0239, 0.0242, 0.0260, 0.0241,
        0.0238, 0.0236, 0.0241, 0.0237, 0.0216, 0.0202, 0.0205, 0.0216, 0.0216,
        0.0215, 0.0233, 0.0204, 0.0211, 0.0185, 0.0198, 0.0205, 0.0201, 0.0201,
        0.0213, 0.0215, 0.0221, 0.0217, 0.0242, 0.0221, 0.0218, 0.0253, 0.0260,
        0.0231, 0.0207, 0.0215, 0.0215, 0.0196, 0.0195, 0.0201, 0.0199, 0.0214,
        0.0222, 0.0237, 0.0265, 0.0262, 0.0232, 0.0239, 0.0234, 0.0264, 0.0290,
        0.0297, 0.0294, 0.0285, 0.0268, 0.0260, 0.0295, 0.0361, 0.0303, 0.0357,
        0.0398, 0.0358, 0.0352, 0.0328, 0.0351, 0.0337, 0.0423, 0.0443, 0.0519,
        0.0567, 0.0484, 0.0527, 0.0532, 0.0540, 0.0573, 0.0557, 0.0567, 0.0613,
        0.0651, 0.0596, 0.0620, 0.0633, 0.0640, 0.0635, 0.0674, 0.0750, 0.0798,
        0.0727, 0.0810, 0.0865, 0.0990, 0.1088, 0.1073, 0.1047, 0.1117, 0.1122,
        0.1125, 0.1052, 0.1143, 0.1158, 0.1293, 0.1304, 0.1361, 0.1491, 0.1721,
        0.1875, 0.1810, 0.1696, 0.1650, 0.1555, 0.1459, 0.1319, 0.1355, 0.1366,
        0.1165, 0.1023, 0.1045, 0.0987, 0.1125, 0.1113, 0.1096, 0.1023, 0.1018,
        0.0983, 0.0959, 0.0965, 0.0933, 0.0895, 0.0794, 0.0784, 0.0757, 0.0755,
        0.0727, 0.0731, 0.0740, 0.0702, 0.0669, 0.0608, 0.0524, 0.0489, 0.0453,
        0.0392, 0.0398, 0.0405, 0.0352, 0.0319, 0.0296, 0.0259, 0.0232, 0.0205,
        0.0190, 0.0190, 0.0184, 0.0188, 0.0201, 0.0197, 0.0174, 0.0132, 0.0134,
        0.0147, 0.0179, 0.0201, 0.0154, 0.0144, 0.0150, 0.0194, 0.0209, 0.0227,
        0.0263, 0.0248, 0.0249, 0.0226, 0.0183, 0.0176, 0.0157, 0.0142, 0.0156,
        0.0170, 0.0150, 0.0151, 0.0190, 0.0158, 0.0204, 0.0231, 0.0214, 0.0222,
        0.0209, 0.0224, 0.0218, 0.0201, 0.0208, 0.0197, 0.0181, 0.0172, 0.0126,
        0.0123, 0.0117, 0.0125, 0.0137, 0.0159, 0.0180, 0.0183, 0.0220],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0061, 0.0059, 0.0072, 0.0045, 0.0089, 0.0094, 0.0105, 0.0099, 0.0097,
        0.0095, 0.0102, 0.0115, 0.0128, 0.0153, 0.0159, 0.0162, 0.0148, 0.0123,
        0.0127, 0.0127, 0.0143, 0.0162, 0.0154, 0.0144, 0.0138, 0.0172, 0.0153,
        0.0154, 0.0171, 0.0176, 0.0157, 0.0177, 0.0171, 0.0171, 0.0168, 0.0188,
        0.0212, 0.0214, 0.0219, 0.0214, 0.0200, 0.0204, 0.0211, 0.0216, 0.0236,
        0.0242, 0.0234, 0.0236, 0.0223, 0.0223, 0.0232, 0.0233, 0.0254, 0.0252,
        0.0246, 0.0252, 0.0240, 0.0231, 0.0219, 0.0232, 0.0229, 0.0222, 0.0220,
        0.0213, 0.0221, 0.0215, 0.0221, 0.0242, 0.0247, 0.0232, 0.0239, 0.0239,
        0.0248, 0.0250, 0.0238, 0.0229, 0.0225, 0.0232, 0.0230, 0.0232, 0.0231,
        0.0222, 0.0232, 0.0242, 0.0257, 0.0265, 0.0252, 0.0247, 0.0246, 0.0245,
        0.0258, 0.0260, 0.0256, 0.0240, 0.0242, 0.0250, 0.0240, 0.0238, 0.0230,
        0.0225, 0.0218, 0.0211, 0.0238, 0.0249, 0.0240, 0.0247, 0.0261, 0.0260,
        0.0251, 0.0247, 0.0260, 0.0252, 0.0257, 0.0251, 0.0248, 0.0246, 0.0250,
        0.0246, 0.0248, 0.0254, 0.0251, 0.0238, 0.0247, 0.0243, 0.0230, 0.0222,
        0.0207, 0.0210, 0.0223, 0.0235, 0.0230, 0.0237, 0.0234, 0.0229, 0.0228,
        0.0226, 0.0225, 0.0236, 0.0255, 0.0276, 0.0267, 0.0250, 0.0225, 0.0265,
        0.0231, 0.0226, 0.0215, 0.0219, 0.0228, 0.0240, 0.0242, 0.0260, 0.0241,
        0.0239, 0.0237, 0.0242, 0.0238, 0.0216, 0.0202, 0.0205, 0.0214, 0.0214,
        0.0216, 0.0234, 0.0207, 0.0212, 0.0186, 0.0200, 0.0207, 0.0203, 0.0203,
        0.0214, 0.0217, 0.0222, 0.0218, 0.0245, 0.0224, 0.0220, 0.0252, 0.0261,
        0.0232, 0.0206, 0.0212, 0.0210, 0.0194, 0.0194, 0.0202, 0.0202, 0.0214,
        0.0222, 0.0236, 0.0262, 0.0260, 0.0232, 0.0239, 0.0233, 0.0262, 0.0290,
        0.0299, 0.0295, 0.0287, 0.0268, 0.0260, 0.0294, 0.0359, 0.0300, 0.0351,
        0.0392, 0.0355, 0.0350, 0.0327, 0.0349, 0.0335, 0.0428, 0.0454, 0.0528,
        0.0570, 0.0489, 0.0536, 0.0540, 0.0551, 0.0588, 0.0574, 0.0587, 0.0632,
        0.0667, 0.0614, 0.0635, 0.0646, 0.0649, 0.0644, 0.0688, 0.0768, 0.0821,
        0.0755, 0.0842, 0.0904, 0.1031, 0.1124, 0.1103, 0.1071, 0.1136, 0.1139,
        0.1141, 0.1070, 0.1167, 0.1184, 0.1322, 0.1340, 0.1429, 0.1641, 0.1860,
        0.1895, 0.1824, 0.1700, 0.1678, 0.1598, 0.1552, 0.1363, 0.1362, 0.1366,
        0.1183, 0.1023, 0.1057, 0.1014, 0.1140, 0.1115, 0.1086, 0.1006, 0.0990,
        0.0946, 0.0916, 0.0915, 0.0883, 0.0848, 0.0768, 0.0762, 0.0736, 0.0731,
        0.0701, 0.0704, 0.0712, 0.0673, 0.0643, 0.0582, 0.0500, 0.0465, 0.0428,
        0.0370, 0.0376, 0.0384, 0.0333, 0.0302, 0.0281, 0.0244, 0.0218, 0.0192,
        0.0178, 0.0180, 0.0175, 0.0178, 0.0191, 0.0188, 0.0166, 0.0124, 0.0126,
        0.0138, 0.0170, 0.0193, 0.0151, 0.0144, 0.0149, 0.0195, 0.0210, 0.0228,
        0.0265, 0.0249, 0.0251, 0.0228, 0.0184, 0.0177, 0.0156, 0.0139, 0.0152,
        0.0167, 0.0147, 0.0148, 0.0189, 0.0156, 0.0203, 0.0231, 0.0214, 0.0222,
        0.0206, 0.0220, 0.0216, 0.0200, 0.0207, 0.0197, 0.0181, 0.0172, 0.0126,
        0.0125, 0.0119, 0.0127, 0.0141, 0.0162, 0.0182, 0.0187, 0.0227],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0062, 0.0058, 0.0069, 0.0035, 0.0074, 0.0074, 0.0084, 0.0080, 0.0079,
        0.0079, 0.0084, 0.0093, 0.0104, 0.0126, 0.0133, 0.0135, 0.0121, 0.0103,
        0.0105, 0.0109, 0.0115, 0.0136, 0.0128, 0.0119, 0.0114, 0.0138, 0.0124,
        0.0125, 0.0143, 0.0148, 0.0129, 0.0146, 0.0140, 0.0141, 0.0137, 0.0157,
        0.0179, 0.0186, 0.0187, 0.0183, 0.0169, 0.0173, 0.0180, 0.0186, 0.0206,
        0.0210, 0.0201, 0.0204, 0.0193, 0.0193, 0.0202, 0.0203, 0.0228, 0.0233,
        0.0219, 0.0224, 0.0210, 0.0199, 0.0188, 0.0200, 0.0196, 0.0190, 0.0186,
        0.0179, 0.0188, 0.0183, 0.0189, 0.0212, 0.0220, 0.0204, 0.0212, 0.0216,
        0.0226, 0.0228, 0.0216, 0.0205, 0.0201, 0.0207, 0.0202, 0.0202, 0.0200,
        0.0191, 0.0200, 0.0213, 0.0229, 0.0237, 0.0221, 0.0216, 0.0216, 0.0216,
        0.0230, 0.0232, 0.0229, 0.0213, 0.0216, 0.0222, 0.0208, 0.0207, 0.0199,
        0.0194, 0.0186, 0.0180, 0.0207, 0.0222, 0.0216, 0.0224, 0.0238, 0.0235,
        0.0226, 0.0224, 0.0238, 0.0229, 0.0233, 0.0227, 0.0225, 0.0223, 0.0228,
        0.0225, 0.0226, 0.0231, 0.0230, 0.0223, 0.0223, 0.0220, 0.0205, 0.0195,
        0.0179, 0.0184, 0.0198, 0.0211, 0.0206, 0.0215, 0.0212, 0.0205, 0.0204,
        0.0201, 0.0198, 0.0211, 0.0237, 0.0257, 0.0246, 0.0227, 0.0197, 0.0247,
        0.0204, 0.0200, 0.0189, 0.0194, 0.0204, 0.0216, 0.0217, 0.0237, 0.0216,
        0.0214, 0.0212, 0.0217, 0.0214, 0.0190, 0.0175, 0.0177, 0.0186, 0.0188,
        0.0190, 0.0212, 0.0182, 0.0187, 0.0159, 0.0174, 0.0182, 0.0178, 0.0178,
        0.0190, 0.0193, 0.0200, 0.0195, 0.0223, 0.0203, 0.0201, 0.0235, 0.0241,
        0.0211, 0.0184, 0.0190, 0.0186, 0.0169, 0.0170, 0.0180, 0.0180, 0.0192,
        0.0203, 0.0217, 0.0244, 0.0241, 0.0211, 0.0221, 0.0211, 0.0242, 0.0275,
        0.0286, 0.0281, 0.0273, 0.0253, 0.0244, 0.0276, 0.0342, 0.0283, 0.0338,
        0.0377, 0.0339, 0.0336, 0.0315, 0.0336, 0.0321, 0.0415, 0.0442, 0.0520,
        0.0559, 0.0476, 0.0525, 0.0529, 0.0541, 0.0580, 0.0567, 0.0581, 0.0626,
        0.0660, 0.0607, 0.0629, 0.0639, 0.0642, 0.0638, 0.0682, 0.0763, 0.0817,
        0.0755, 0.0844, 0.0910, 0.1039, 0.1131, 0.1109, 0.1074, 0.1137, 0.1139,
        0.1140, 0.1071, 0.1169, 0.1187, 0.1331, 0.1353, 0.1455, 0.1686, 0.1898,
        0.1906, 0.1830, 0.1702, 0.1683, 0.1604, 0.1566, 0.1349, 0.1346, 0.1343,
        0.1182, 0.1019, 0.1059, 0.1018, 0.1144, 0.1115, 0.1083, 0.1002, 0.0983,
        0.0936, 0.0903, 0.0899, 0.0866, 0.0830, 0.0754, 0.0750, 0.0724, 0.0717,
        0.0684, 0.0685, 0.0692, 0.0651, 0.0618, 0.0556, 0.0474, 0.0439, 0.0408,
        0.0353, 0.0355, 0.0363, 0.0317, 0.0289, 0.0272, 0.0236, 0.0211, 0.0184,
        0.0169, 0.0168, 0.0159, 0.0164, 0.0178, 0.0174, 0.0153, 0.0114, 0.0118,
        0.0127, 0.0157, 0.0177, 0.0129, 0.0124, 0.0127, 0.0165, 0.0177, 0.0195,
        0.0231, 0.0215, 0.0216, 0.0194, 0.0152, 0.0148, 0.0130, 0.0118, 0.0130,
        0.0144, 0.0127, 0.0129, 0.0162, 0.0126, 0.0172, 0.0200, 0.0183, 0.0193,
        0.0177, 0.0192, 0.0187, 0.0174, 0.0181, 0.0168, 0.0152, 0.0146, 0.0101,
        0.0105, 0.0102, 0.0108, 0.0117, 0.0137, 0.0157, 0.0162, 0.0191],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([-0.0093, -0.0085, -0.0075,  0.0025,  0.0068,  0.0151,  0.0169,  0.0192,
         0.0196,  0.0201,  0.0209,  0.0203,  0.0210,  0.0255,  0.0279,  0.0254,
         0.0241,  0.0220,  0.0201,  0.0173,  0.0168,  0.0176,  0.0222,  0.0210,
         0.0207,  0.0232,  0.0209,  0.0189,  0.0191,  0.0181,  0.0189,  0.0192,
         0.0180,  0.0180,  0.0214,  0.0191,  0.0182,  0.0247,  0.0264,  0.0245,
         0.0213,  0.0227,  0.0234,  0.0262,  0.0304,  0.0334,  0.0321,  0.0313,
         0.0299,  0.0298,  0.0289,  0.0297,  0.0300,  0.0305,  0.0309,  0.0320,
         0.0326,  0.0308,  0.0306,  0.0289,  0.0274,  0.0282,  0.0290,  0.0288,
         0.0280,  0.0258,  0.0268,  0.0298,  0.0304,  0.0241,  0.0202,  0.0205,
         0.0239,  0.0282,  0.0292,  0.0271,  0.0290,  0.0274,  0.0279,  0.0294,
         0.0308,  0.0300,  0.0292,  0.0315,  0.0369,  0.0368,  0.0357,  0.0354,
         0.0346,  0.0346,  0.0356,  0.0364,  0.0365,  0.0349,  0.0350,  0.0349,
         0.0353,  0.0342,  0.0330,  0.0327,  0.0330,  0.0318,  0.0325,  0.0300,
         0.0305,  0.0351,  0.0371,  0.0351,  0.0334,  0.0351,  0.0357,  0.0363,
         0.0379,  0.0381,  0.0379,  0.0387,  0.0381,  0.0369,  0.0372,  0.0379,
         0.0391,  0.0397,  0.0395,  0.0372,  0.0357,  0.0340,  0.0322,  0.0331,
         0.0337,  0.0330,  0.0321,  0.0341,  0.0343,  0.0340,  0.0333,  0.0353,
         0.0357,  0.0374,  0.0372,  0.0420,  0.0404,  0.0389,  0.0382,  0.0415,
         0.0404,  0.0373,  0.0371,  0.0380,  0.0348,  0.0367,  0.0349,  0.0355,
         0.0338,  0.0334,  0.0336,  0.0349,  0.0367,  0.0375,  0.0353,  0.0362,
         0.0333,  0.0340,  0.0294,  0.0315,  0.0278,  0.0261,  0.0257,  0.0267,
         0.0271,  0.0266,  0.0273,  0.0282,  0.0291,  0.0306,  0.0319,  0.0317,
         0.0289,  0.0296,  0.0388,  0.0388,  0.0344,  0.0317,  0.0278,  0.0283,
         0.0224,  0.0250,  0.0260,  0.0193,  0.0284,  0.0240,  0.0270,  0.0278,
         0.0274,  0.0269,  0.0283,  0.0319,  0.0335,  0.0315,  0.0333,  0.0327,
         0.0340,  0.0353,  0.0329,  0.0265,  0.0296,  0.0224,  0.0364,  0.0312,
         0.0314,  0.0343,  0.0297,  0.0336,  0.0348,  0.0322,  0.0272,  0.0286,
         0.0474,  0.0435,  0.0437,  0.0408,  0.0374,  0.0362,  0.0333,  0.0328,
         0.0372,  0.0438,  0.0361,  0.0370,  0.0400,  0.0418,  0.0401,  0.0386,
         0.0447,  0.0443,  0.0401,  0.0410,  0.0339,  0.0405,  0.0480,  0.0487,
         0.0485,  0.0540,  0.0556,  0.0585,  0.0514,  0.0537,  0.0571,  0.0567,
         0.0501,  0.0538,  0.0553,  0.0620,  0.0642,  0.0672,  0.0697,  0.0708,
         0.0744,  0.0731,  0.0706,  0.0704,  0.0711,  0.0593,  0.0631,  0.0656,
         0.0660,  0.0758,  0.0849,  0.0940,  0.0951,  0.0994,  0.0972,  0.0928,
         0.0946,  0.0951,  0.0954,  0.0953,  0.1004,  0.1009,  0.1091,  0.1058,
         0.1067,  0.1041,  0.0989,  0.1007,  0.0966,  0.0981,  0.1024,  0.0992,
         0.1043,  0.1033,  0.1036,  0.0963,  0.1001,  0.0961,  0.0966,  0.0911,
         0.0892,  0.0823,  0.0834,  0.0780,  0.0775,  0.0811,  0.0845,  0.0872,
         0.0780,  0.0720,  0.0638,  0.0694,  0.0718,  0.0631,  0.0595,  0.0550,
         0.0575,  0.0625,  0.0591,  0.0556,  0.0531,  0.0536,  0.0518,  0.0486,
         0.0454,  0.0447,  0.0421,  0.0462,  0.0486,  0.0453,  0.0513,  0.0527,
         0.0431,  0.0403,  0.0374,  0.0370,  0.0340,  0.0388,  0.0392,  0.0350,
         0.0360,  0.0360,  0.0369,  0.0371,  0.0367,  0.0388,  0.0316,  0.0279,
         0.0281,  0.0250,  0.0201,  0.0190,  0.0188,  0.0205],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0076, 0.0069, 0.0081, 0.0044, 0.0077, 0.0066, 0.0077, 0.0070, 0.0070,
        0.0070, 0.0075, 0.0083, 0.0093, 0.0112, 0.0118, 0.0123, 0.0111, 0.0096,
        0.0097, 0.0100, 0.0102, 0.0124, 0.0116, 0.0110, 0.0105, 0.0118, 0.0109,
        0.0110, 0.0127, 0.0132, 0.0114, 0.0128, 0.0123, 0.0124, 0.0119, 0.0140,
        0.0160, 0.0168, 0.0169, 0.0165, 0.0151, 0.0155, 0.0161, 0.0166, 0.0185,
        0.0188, 0.0179, 0.0184, 0.0173, 0.0173, 0.0182, 0.0184, 0.0210, 0.0220,
        0.0201, 0.0204, 0.0189, 0.0179, 0.0167, 0.0179, 0.0175, 0.0170, 0.0165,
        0.0158, 0.0168, 0.0163, 0.0170, 0.0192, 0.0202, 0.0186, 0.0196, 0.0201,
        0.0212, 0.0213, 0.0200, 0.0189, 0.0185, 0.0190, 0.0184, 0.0183, 0.0180,
        0.0170, 0.0179, 0.0193, 0.0209, 0.0215, 0.0199, 0.0195, 0.0195, 0.0196,
        0.0209, 0.0212, 0.0209, 0.0193, 0.0196, 0.0202, 0.0186, 0.0186, 0.0178,
        0.0173, 0.0165, 0.0159, 0.0188, 0.0205, 0.0199, 0.0207, 0.0220, 0.0217,
        0.0208, 0.0206, 0.0221, 0.0212, 0.0215, 0.0209, 0.0207, 0.0205, 0.0210,
        0.0210, 0.0210, 0.0213, 0.0213, 0.0210, 0.0206, 0.0204, 0.0188, 0.0177,
        0.0161, 0.0165, 0.0180, 0.0193, 0.0190, 0.0198, 0.0195, 0.0188, 0.0187,
        0.0184, 0.0180, 0.0193, 0.0224, 0.0242, 0.0229, 0.0209, 0.0176, 0.0232,
        0.0184, 0.0181, 0.0169, 0.0175, 0.0187, 0.0199, 0.0199, 0.0220, 0.0200,
        0.0198, 0.0196, 0.0201, 0.0198, 0.0171, 0.0156, 0.0159, 0.0165, 0.0170,
        0.0174, 0.0198, 0.0169, 0.0172, 0.0142, 0.0159, 0.0168, 0.0163, 0.0162,
        0.0174, 0.0177, 0.0185, 0.0180, 0.0211, 0.0193, 0.0190, 0.0221, 0.0227,
        0.0196, 0.0169, 0.0172, 0.0166, 0.0151, 0.0153, 0.0166, 0.0168, 0.0177,
        0.0188, 0.0202, 0.0226, 0.0225, 0.0196, 0.0207, 0.0194, 0.0225, 0.0265,
        0.0279, 0.0273, 0.0266, 0.0242, 0.0233, 0.0264, 0.0328, 0.0267, 0.0324,
        0.0357, 0.0323, 0.0324, 0.0307, 0.0326, 0.0309, 0.0412, 0.0449, 0.0526,
        0.0556, 0.0475, 0.0530, 0.0533, 0.0550, 0.0596, 0.0588, 0.0606, 0.0648,
        0.0678, 0.0628, 0.0645, 0.0653, 0.0649, 0.0647, 0.0697, 0.0785, 0.0846,
        0.0795, 0.0892, 0.0970, 0.1101, 0.1183, 0.1152, 0.1109, 0.1163, 0.1162,
        0.1161, 0.1096, 0.1205, 0.1228, 0.1376, 0.1423, 0.1641, 0.1884, 0.2034,
        0.1935, 0.1814, 0.1674, 0.1691, 0.1627, 0.1573, 0.1286, 0.1223, 0.1175,
        0.1152, 0.1006, 0.1086, 0.1055, 0.1169, 0.1119, 0.1069, 0.0975, 0.0942,
        0.0887, 0.0850, 0.0838, 0.0803, 0.0771, 0.0714, 0.0712, 0.0687, 0.0671,
        0.0634, 0.0631, 0.0637, 0.0594, 0.0563, 0.0502, 0.0425, 0.0392, 0.0365,
        0.0317, 0.0317, 0.0325, 0.0285, 0.0260, 0.0247, 0.0214, 0.0190, 0.0164,
        0.0149, 0.0148, 0.0139, 0.0144, 0.0158, 0.0155, 0.0136, 0.0099, 0.0103,
        0.0110, 0.0139, 0.0157, 0.0111, 0.0112, 0.0113, 0.0147, 0.0157, 0.0175,
        0.0211, 0.0195, 0.0194, 0.0175, 0.0135, 0.0133, 0.0114, 0.0104, 0.0113,
        0.0128, 0.0112, 0.0115, 0.0144, 0.0104, 0.0152, 0.0180, 0.0163, 0.0173,
        0.0155, 0.0168, 0.0165, 0.0155, 0.0162, 0.0149, 0.0133, 0.0130, 0.0087,
        0.0095, 0.0094, 0.0098, 0.0106, 0.0124, 0.0143, 0.0151, 0.0175],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0061, 0.0058, 0.0069, 0.0036, 0.0076, 0.0077, 0.0087, 0.0083, 0.0082,
        0.0081, 0.0086, 0.0096, 0.0108, 0.0130, 0.0137, 0.0139, 0.0125, 0.0106,
        0.0108, 0.0112, 0.0119, 0.0140, 0.0132, 0.0122, 0.0117, 0.0143, 0.0128,
        0.0130, 0.0147, 0.0153, 0.0134, 0.0151, 0.0145, 0.0145, 0.0142, 0.0162,
        0.0184, 0.0190, 0.0192, 0.0188, 0.0173, 0.0178, 0.0185, 0.0191, 0.0211,
        0.0215, 0.0207, 0.0210, 0.0198, 0.0198, 0.0206, 0.0208, 0.0232, 0.0236,
        0.0224, 0.0228, 0.0215, 0.0205, 0.0193, 0.0205, 0.0201, 0.0196, 0.0192,
        0.0185, 0.0193, 0.0188, 0.0195, 0.0217, 0.0225, 0.0209, 0.0217, 0.0220,
        0.0230, 0.0232, 0.0220, 0.0209, 0.0205, 0.0211, 0.0207, 0.0207, 0.0205,
        0.0196, 0.0205, 0.0218, 0.0234, 0.0241, 0.0226, 0.0221, 0.0221, 0.0221,
        0.0234, 0.0236, 0.0233, 0.0217, 0.0220, 0.0227, 0.0214, 0.0212, 0.0204,
        0.0199, 0.0192, 0.0185, 0.0212, 0.0226, 0.0220, 0.0228, 0.0242, 0.0239,
        0.0230, 0.0228, 0.0241, 0.0233, 0.0238, 0.0231, 0.0229, 0.0227, 0.0232,
        0.0229, 0.0229, 0.0235, 0.0233, 0.0226, 0.0227, 0.0224, 0.0209, 0.0199,
        0.0183, 0.0188, 0.0202, 0.0215, 0.0210, 0.0219, 0.0216, 0.0209, 0.0208,
        0.0205, 0.0203, 0.0215, 0.0240, 0.0260, 0.0249, 0.0231, 0.0201, 0.0250,
        0.0209, 0.0205, 0.0193, 0.0198, 0.0208, 0.0220, 0.0221, 0.0241, 0.0221,
        0.0218, 0.0216, 0.0221, 0.0218, 0.0194, 0.0179, 0.0182, 0.0191, 0.0193,
        0.0194, 0.0215, 0.0186, 0.0191, 0.0163, 0.0179, 0.0186, 0.0182, 0.0182,
        0.0194, 0.0197, 0.0203, 0.0199, 0.0226, 0.0207, 0.0204, 0.0238, 0.0244,
        0.0214, 0.0188, 0.0193, 0.0190, 0.0173, 0.0174, 0.0184, 0.0184, 0.0196,
        0.0206, 0.0220, 0.0247, 0.0244, 0.0214, 0.0224, 0.0215, 0.0246, 0.0277,
        0.0288, 0.0283, 0.0275, 0.0256, 0.0247, 0.0279, 0.0345, 0.0286, 0.0341,
        0.0380, 0.0342, 0.0338, 0.0317, 0.0338, 0.0323, 0.0417, 0.0444, 0.0521,
        0.0561, 0.0478, 0.0526, 0.0531, 0.0542, 0.0580, 0.0567, 0.0581, 0.0626,
        0.0660, 0.0607, 0.0629, 0.0640, 0.0643, 0.0639, 0.0683, 0.0763, 0.0817,
        0.0753, 0.0843, 0.0907, 0.1036, 0.1128, 0.1106, 0.1073, 0.1136, 0.1138,
        0.1140, 0.1070, 0.1168, 0.1186, 0.1328, 0.1349, 0.1447, 0.1672, 0.1886,
        0.1904, 0.1829, 0.1702, 0.1681, 0.1602, 0.1560, 0.1352, 0.1351, 0.1351,
        0.1182, 0.1020, 0.1058, 0.1016, 0.1143, 0.1115, 0.1084, 0.1003, 0.0985,
        0.0939, 0.0907, 0.0904, 0.0871, 0.0835, 0.0758, 0.0753, 0.0727, 0.0720,
        0.0688, 0.0689, 0.0697, 0.0656, 0.0624, 0.0562, 0.0479, 0.0444, 0.0412,
        0.0357, 0.0359, 0.0367, 0.0320, 0.0291, 0.0273, 0.0238, 0.0213, 0.0186,
        0.0171, 0.0170, 0.0162, 0.0166, 0.0180, 0.0176, 0.0156, 0.0116, 0.0119,
        0.0129, 0.0159, 0.0180, 0.0132, 0.0127, 0.0130, 0.0169, 0.0182, 0.0200,
        0.0237, 0.0220, 0.0221, 0.0199, 0.0157, 0.0153, 0.0134, 0.0121, 0.0133,
        0.0148, 0.0130, 0.0132, 0.0166, 0.0131, 0.0177, 0.0205, 0.0188, 0.0198,
        0.0182, 0.0197, 0.0191, 0.0178, 0.0185, 0.0172, 0.0156, 0.0149, 0.0105,
        0.0108, 0.0105, 0.0111, 0.0120, 0.0140, 0.0160, 0.0166, 0.0196],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0006, 0.0034, 0.0046, 0.0158, 0.0232, 0.0298, 0.0311, 0.0329, 0.0336,
        0.0340, 0.0343, 0.0327, 0.0324, 0.0347, 0.0366, 0.0345, 0.0345, 0.0326,
        0.0309, 0.0284, 0.0282, 0.0289, 0.0339, 0.0335, 0.0331, 0.0351, 0.0323,
        0.0301, 0.0299, 0.0287, 0.0310, 0.0297, 0.0280, 0.0289, 0.0338, 0.0320,
        0.0316, 0.0355, 0.0358, 0.0326, 0.0304, 0.0303, 0.0328, 0.0371, 0.0398,
        0.0421, 0.0384, 0.0352, 0.0337, 0.0366, 0.0381, 0.0382, 0.0379, 0.0342,
        0.0376, 0.0386, 0.0387, 0.0367, 0.0386, 0.0371, 0.0367, 0.0345, 0.0360,
        0.0349, 0.0333, 0.0321, 0.0328, 0.0336, 0.0323, 0.0296, 0.0271, 0.0259,
        0.0276, 0.0309, 0.0334, 0.0355, 0.0368, 0.0352, 0.0365, 0.0366, 0.0373,
        0.0363, 0.0357, 0.0384, 0.0407, 0.0390, 0.0387, 0.0374, 0.0368, 0.0361,
        0.0378, 0.0389, 0.0394, 0.0426, 0.0432, 0.0419, 0.0407, 0.0397, 0.0384,
        0.0381, 0.0377, 0.0371, 0.0347, 0.0319, 0.0313, 0.0335, 0.0350, 0.0341,
        0.0334, 0.0337, 0.0338, 0.0342, 0.0358, 0.0358, 0.0355, 0.0360, 0.0355,
        0.0342, 0.0363, 0.0404, 0.0392, 0.0368, 0.0360, 0.0347, 0.0342, 0.0336,
        0.0325, 0.0319, 0.0321, 0.0314, 0.0308, 0.0321, 0.0326, 0.0329, 0.0331,
        0.0339, 0.0348, 0.0370, 0.0363, 0.0387, 0.0376, 0.0368, 0.0373, 0.0398,
        0.0387, 0.0369, 0.0357, 0.0356, 0.0348, 0.0370, 0.0350, 0.0355, 0.0342,
        0.0334, 0.0347, 0.0375, 0.0413, 0.0423, 0.0404, 0.0412, 0.0375, 0.0383,
        0.0346, 0.0369, 0.0319, 0.0315, 0.0308, 0.0300, 0.0279, 0.0260, 0.0259,
        0.0263, 0.0278, 0.0302, 0.0333, 0.0347, 0.0324, 0.0320, 0.0412, 0.0415,
        0.0369, 0.0340, 0.0315, 0.0314, 0.0255, 0.0277, 0.0286, 0.0222, 0.0309,
        0.0268, 0.0308, 0.0317, 0.0310, 0.0311, 0.0321, 0.0347, 0.0373, 0.0370,
        0.0391, 0.0377, 0.0380, 0.0400, 0.0381, 0.0325, 0.0349, 0.0285, 0.0438,
        0.0400, 0.0379, 0.0397, 0.0368, 0.0383, 0.0393, 0.0376, 0.0342, 0.0390,
        0.0548, 0.0495, 0.0506, 0.0489, 0.0468, 0.0460, 0.0432, 0.0414, 0.0471,
        0.0529, 0.0462, 0.0464, 0.0496, 0.0536, 0.0528, 0.0525, 0.0568, 0.0577,
        0.0516, 0.0535, 0.0491, 0.0560, 0.0634, 0.0638, 0.0656, 0.0756, 0.0790,
        0.0798, 0.0701, 0.0723, 0.0749, 0.0757, 0.0703, 0.0747, 0.0758, 0.0859,
        0.0889, 0.0924, 0.0925, 0.0926, 0.0946, 0.0932, 0.0856, 0.0847, 0.0840,
        0.0736, 0.0756, 0.0804, 0.0822, 0.0954, 0.1050, 0.1144, 0.1095, 0.1096,
        0.1052, 0.0999, 0.1016, 0.1026, 0.1039, 0.1045, 0.1091, 0.1112, 0.1173,
        0.1128, 0.1132, 0.1121, 0.1041, 0.1020, 0.0965, 0.0964, 0.1004, 0.0988,
        0.1027, 0.1013, 0.1011, 0.0956, 0.0996, 0.0979, 0.0997, 0.0973, 0.0944,
        0.0869, 0.0825, 0.0707, 0.0676, 0.0756, 0.0821, 0.0867, 0.0786, 0.0662,
        0.0575, 0.0617, 0.0650, 0.0554, 0.0520, 0.0452, 0.0486, 0.0586, 0.0593,
        0.0598, 0.0579, 0.0587, 0.0539, 0.0448, 0.0420, 0.0404, 0.0401, 0.0440,
        0.0452, 0.0430, 0.0433, 0.0423, 0.0372, 0.0372, 0.0372, 0.0377, 0.0362,
        0.0433, 0.0465, 0.0415, 0.0411, 0.0419, 0.0410, 0.0382, 0.0387, 0.0442,
        0.0377, 0.0348, 0.0347, 0.0336, 0.0286, 0.0280, 0.0268, 0.0326],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0076, 0.0069, 0.0080, 0.0043, 0.0075, 0.0064, 0.0075, 0.0068, 0.0068,
        0.0069, 0.0073, 0.0081, 0.0090, 0.0109, 0.0115, 0.0119, 0.0108, 0.0094,
        0.0094, 0.0098, 0.0098, 0.0121, 0.0113, 0.0107, 0.0102, 0.0113, 0.0106,
        0.0107, 0.0123, 0.0128, 0.0110, 0.0124, 0.0119, 0.0120, 0.0114, 0.0135,
        0.0155, 0.0163, 0.0164, 0.0160, 0.0146, 0.0151, 0.0157, 0.0162, 0.0180,
        0.0182, 0.0173, 0.0178, 0.0168, 0.0168, 0.0177, 0.0178, 0.0205, 0.0216,
        0.0196, 0.0199, 0.0184, 0.0174, 0.0162, 0.0174, 0.0170, 0.0164, 0.0160,
        0.0153, 0.0162, 0.0158, 0.0165, 0.0187, 0.0197, 0.0181, 0.0191, 0.0197,
        0.0208, 0.0209, 0.0195, 0.0184, 0.0180, 0.0185, 0.0179, 0.0178, 0.0175,
        0.0165, 0.0174, 0.0188, 0.0204, 0.0210, 0.0193, 0.0189, 0.0190, 0.0191,
        0.0204, 0.0207, 0.0204, 0.0189, 0.0192, 0.0197, 0.0181, 0.0180, 0.0173,
        0.0168, 0.0160, 0.0154, 0.0183, 0.0200, 0.0195, 0.0202, 0.0216, 0.0212,
        0.0203, 0.0202, 0.0217, 0.0207, 0.0211, 0.0204, 0.0203, 0.0201, 0.0206,
        0.0206, 0.0205, 0.0209, 0.0209, 0.0208, 0.0202, 0.0200, 0.0184, 0.0173,
        0.0157, 0.0161, 0.0175, 0.0189, 0.0185, 0.0194, 0.0191, 0.0183, 0.0182,
        0.0179, 0.0176, 0.0189, 0.0221, 0.0238, 0.0225, 0.0205, 0.0171, 0.0228,
        0.0179, 0.0176, 0.0164, 0.0170, 0.0183, 0.0195, 0.0194, 0.0216, 0.0195,
        0.0193, 0.0192, 0.0196, 0.0193, 0.0167, 0.0152, 0.0154, 0.0160, 0.0165,
        0.0170, 0.0194, 0.0165, 0.0167, 0.0138, 0.0155, 0.0163, 0.0159, 0.0158,
        0.0170, 0.0173, 0.0180, 0.0176, 0.0208, 0.0189, 0.0186, 0.0218, 0.0223,
        0.0193, 0.0166, 0.0169, 0.0162, 0.0147, 0.0149, 0.0162, 0.0164, 0.0173,
        0.0185, 0.0199, 0.0223, 0.0221, 0.0192, 0.0204, 0.0190, 0.0221, 0.0262,
        0.0276, 0.0270, 0.0263, 0.0239, 0.0230, 0.0261, 0.0325, 0.0264, 0.0322,
        0.0355, 0.0320, 0.0322, 0.0304, 0.0324, 0.0306, 0.0409, 0.0446, 0.0525,
        0.0554, 0.0472, 0.0527, 0.0531, 0.0548, 0.0594, 0.0586, 0.0605, 0.0647,
        0.0676, 0.0627, 0.0644, 0.0652, 0.0648, 0.0646, 0.0696, 0.0784, 0.0845,
        0.0795, 0.0892, 0.0971, 0.1102, 0.1184, 0.1153, 0.1110, 0.1163, 0.1162,
        0.1160, 0.1096, 0.1205, 0.1228, 0.1377, 0.1425, 0.1646, 0.1888, 0.2037,
        0.1936, 0.1814, 0.1674, 0.1690, 0.1626, 0.1571, 0.1284, 0.1220, 0.1173,
        0.1150, 0.1005, 0.1086, 0.1055, 0.1169, 0.1119, 0.1068, 0.0975, 0.0941,
        0.0886, 0.0848, 0.0836, 0.0801, 0.0769, 0.0712, 0.0711, 0.0685, 0.0669,
        0.0631, 0.0628, 0.0634, 0.0590, 0.0559, 0.0498, 0.0421, 0.0388, 0.0363,
        0.0315, 0.0314, 0.0323, 0.0284, 0.0259, 0.0247, 0.0214, 0.0189, 0.0163,
        0.0148, 0.0147, 0.0138, 0.0142, 0.0156, 0.0153, 0.0135, 0.0098, 0.0102,
        0.0110, 0.0138, 0.0156, 0.0108, 0.0110, 0.0110, 0.0143, 0.0153, 0.0171,
        0.0206, 0.0190, 0.0189, 0.0171, 0.0131, 0.0129, 0.0111, 0.0102, 0.0111,
        0.0125, 0.0110, 0.0112, 0.0141, 0.0100, 0.0148, 0.0176, 0.0159, 0.0169,
        0.0151, 0.0164, 0.0161, 0.0151, 0.0158, 0.0146, 0.0130, 0.0127, 0.0084,
        0.0093, 0.0092, 0.0096, 0.0103, 0.0121, 0.0139, 0.0148, 0.0169],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0079, 0.0071, 0.0081, 0.0042, 0.0071, 0.0058, 0.0067, 0.0061, 0.0062,
        0.0063, 0.0067, 0.0073, 0.0080, 0.0097, 0.0103, 0.0107, 0.0095, 0.0086,
        0.0085, 0.0091, 0.0084, 0.0109, 0.0102, 0.0097, 0.0092, 0.0094, 0.0093,
        0.0093, 0.0109, 0.0112, 0.0097, 0.0109, 0.0104, 0.0105, 0.0099, 0.0121,
        0.0137, 0.0146, 0.0145, 0.0141, 0.0129, 0.0133, 0.0139, 0.0143, 0.0160,
        0.0162, 0.0153, 0.0158, 0.0149, 0.0150, 0.0158, 0.0159, 0.0187, 0.0202,
        0.0178, 0.0180, 0.0164, 0.0154, 0.0144, 0.0154, 0.0150, 0.0144, 0.0141,
        0.0134, 0.0143, 0.0139, 0.0146, 0.0168, 0.0178, 0.0162, 0.0173, 0.0180,
        0.0191, 0.0192, 0.0179, 0.0167, 0.0163, 0.0167, 0.0161, 0.0159, 0.0156,
        0.0146, 0.0155, 0.0169, 0.0184, 0.0189, 0.0173, 0.0169, 0.0170, 0.0171,
        0.0185, 0.0187, 0.0185, 0.0170, 0.0173, 0.0178, 0.0161, 0.0161, 0.0153,
        0.0149, 0.0142, 0.0136, 0.0165, 0.0182, 0.0178, 0.0185, 0.0198, 0.0194,
        0.0185, 0.0185, 0.0200, 0.0190, 0.0193, 0.0187, 0.0185, 0.0184, 0.0189,
        0.0190, 0.0189, 0.0192, 0.0193, 0.0196, 0.0184, 0.0183, 0.0167, 0.0156,
        0.0140, 0.0144, 0.0157, 0.0172, 0.0169, 0.0178, 0.0174, 0.0167, 0.0165,
        0.0163, 0.0158, 0.0172, 0.0207, 0.0223, 0.0208, 0.0187, 0.0153, 0.0214,
        0.0161, 0.0159, 0.0147, 0.0153, 0.0166, 0.0178, 0.0176, 0.0199, 0.0178,
        0.0176, 0.0175, 0.0179, 0.0177, 0.0151, 0.0136, 0.0138, 0.0144, 0.0149,
        0.0153, 0.0179, 0.0150, 0.0152, 0.0121, 0.0140, 0.0148, 0.0143, 0.0143,
        0.0153, 0.0156, 0.0165, 0.0160, 0.0193, 0.0175, 0.0172, 0.0204, 0.0209,
        0.0179, 0.0153, 0.0156, 0.0148, 0.0132, 0.0134, 0.0147, 0.0148, 0.0158,
        0.0171, 0.0184, 0.0208, 0.0206, 0.0178, 0.0190, 0.0174, 0.0206, 0.0250,
        0.0266, 0.0260, 0.0253, 0.0228, 0.0218, 0.0248, 0.0311, 0.0250, 0.0311,
        0.0342, 0.0307, 0.0311, 0.0296, 0.0314, 0.0296, 0.0400, 0.0440, 0.0521,
        0.0546, 0.0465, 0.0522, 0.0525, 0.0544, 0.0594, 0.0587, 0.0608, 0.0649,
        0.0677, 0.0628, 0.0644, 0.0651, 0.0646, 0.0644, 0.0696, 0.0786, 0.0849,
        0.0805, 0.0904, 0.0989, 0.1121, 0.1199, 0.1166, 0.1120, 0.1170, 0.1168,
        0.1164, 0.1103, 0.1215, 0.1241, 0.1391, 0.1454, 0.1720, 0.1934, 0.2064,
        0.1941, 0.1802, 0.1656, 0.1676, 0.1601, 0.1533, 0.1256, 0.1177, 0.1149,
        0.1132, 0.1000, 0.1094, 0.1064, 0.1176, 0.1119, 0.1063, 0.0966, 0.0927,
        0.0870, 0.0831, 0.0817, 0.0780, 0.0750, 0.0696, 0.0696, 0.0670, 0.0650,
        0.0609, 0.0603, 0.0609, 0.0565, 0.0533, 0.0473, 0.0399, 0.0369, 0.0347,
        0.0303, 0.0300, 0.0310, 0.0273, 0.0251, 0.0240, 0.0207, 0.0183, 0.0157,
        0.0142, 0.0140, 0.0129, 0.0134, 0.0149, 0.0146, 0.0128, 0.0092, 0.0098,
        0.0104, 0.0131, 0.0147, 0.0097, 0.0102, 0.0100, 0.0128, 0.0136, 0.0153,
        0.0187, 0.0173, 0.0171, 0.0155, 0.0117, 0.0117, 0.0100, 0.0094, 0.0102,
        0.0115, 0.0102, 0.0104, 0.0127, 0.0084, 0.0132, 0.0159, 0.0143, 0.0152,
        0.0135, 0.0147, 0.0144, 0.0136, 0.0143, 0.0131, 0.0116, 0.0116, 0.0074,
        0.0085, 0.0086, 0.0088, 0.0092, 0.0109, 0.0126, 0.0137, 0.0151],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0082, 0.0074, 0.0087, 0.0052, 0.0084, 0.0071, 0.0082, 0.0072, 0.0071,
        0.0071, 0.0076, 0.0085, 0.0096, 0.0116, 0.0121, 0.0126, 0.0117, 0.0100,
        0.0101, 0.0102, 0.0107, 0.0128, 0.0120, 0.0114, 0.0109, 0.0123, 0.0113,
        0.0114, 0.0132, 0.0137, 0.0118, 0.0132, 0.0126, 0.0128, 0.0122, 0.0144,
        0.0165, 0.0172, 0.0173, 0.0169, 0.0155, 0.0160, 0.0166, 0.0171, 0.0188,
        0.0191, 0.0183, 0.0188, 0.0178, 0.0177, 0.0186, 0.0188, 0.0215, 0.0224,
        0.0206, 0.0209, 0.0193, 0.0183, 0.0171, 0.0183, 0.0179, 0.0174, 0.0170,
        0.0163, 0.0173, 0.0168, 0.0175, 0.0197, 0.0206, 0.0191, 0.0201, 0.0206,
        0.0216, 0.0216, 0.0202, 0.0192, 0.0188, 0.0194, 0.0188, 0.0187, 0.0184,
        0.0174, 0.0184, 0.0197, 0.0212, 0.0219, 0.0203, 0.0199, 0.0199, 0.0200,
        0.0213, 0.0215, 0.0213, 0.0197, 0.0200, 0.0205, 0.0190, 0.0189, 0.0182,
        0.0177, 0.0169, 0.0163, 0.0193, 0.0210, 0.0203, 0.0210, 0.0223, 0.0220,
        0.0211, 0.0210, 0.0224, 0.0215, 0.0218, 0.0212, 0.0210, 0.0208, 0.0213,
        0.0212, 0.0212, 0.0216, 0.0216, 0.0212, 0.0210, 0.0208, 0.0192, 0.0181,
        0.0164, 0.0169, 0.0183, 0.0197, 0.0193, 0.0201, 0.0197, 0.0190, 0.0190,
        0.0187, 0.0183, 0.0197, 0.0226, 0.0244, 0.0231, 0.0211, 0.0179, 0.0233,
        0.0186, 0.0183, 0.0171, 0.0177, 0.0191, 0.0203, 0.0202, 0.0224, 0.0203,
        0.0201, 0.0200, 0.0205, 0.0202, 0.0174, 0.0159, 0.0162, 0.0167, 0.0173,
        0.0178, 0.0203, 0.0175, 0.0176, 0.0146, 0.0163, 0.0172, 0.0168, 0.0166,
        0.0178, 0.0180, 0.0188, 0.0184, 0.0216, 0.0198, 0.0194, 0.0223, 0.0230,
        0.0199, 0.0171, 0.0173, 0.0166, 0.0153, 0.0156, 0.0170, 0.0172, 0.0180,
        0.0191, 0.0205, 0.0227, 0.0226, 0.0199, 0.0210, 0.0196, 0.0226, 0.0268,
        0.0282, 0.0276, 0.0269, 0.0245, 0.0236, 0.0267, 0.0331, 0.0268, 0.0324,
        0.0354, 0.0324, 0.0327, 0.0308, 0.0328, 0.0311, 0.0418, 0.0458, 0.0534,
        0.0560, 0.0482, 0.0538, 0.0541, 0.0560, 0.0610, 0.0603, 0.0622, 0.0663,
        0.0690, 0.0643, 0.0656, 0.0663, 0.0655, 0.0655, 0.0707, 0.0798, 0.0862,
        0.0817, 0.0915, 0.0998, 0.1128, 0.1205, 0.1171, 0.1125, 0.1176, 0.1174,
        0.1171, 0.1109, 0.1224, 0.1250, 0.1395, 0.1464, 0.1747, 0.1935, 0.2061,
        0.1930, 0.1789, 0.1643, 0.1668, 0.1591, 0.1520, 0.1249, 0.1162, 0.1146,
        0.1129, 0.1001, 0.1101, 0.1071, 0.1179, 0.1120, 0.1062, 0.0963, 0.0924,
        0.0868, 0.0831, 0.0818, 0.0783, 0.0753, 0.0700, 0.0699, 0.0673, 0.0655,
        0.0617, 0.0613, 0.0619, 0.0576, 0.0547, 0.0487, 0.0412, 0.0378, 0.0351,
        0.0305, 0.0306, 0.0315, 0.0275, 0.0251, 0.0238, 0.0206, 0.0182, 0.0156,
        0.0143, 0.0143, 0.0135, 0.0139, 0.0152, 0.0151, 0.0132, 0.0095, 0.0099,
        0.0106, 0.0134, 0.0153, 0.0110, 0.0113, 0.0114, 0.0150, 0.0161, 0.0179,
        0.0216, 0.0198, 0.0198, 0.0179, 0.0138, 0.0136, 0.0115, 0.0104, 0.0113,
        0.0127, 0.0112, 0.0114, 0.0146, 0.0106, 0.0155, 0.0183, 0.0166, 0.0175,
        0.0156, 0.0169, 0.0167, 0.0156, 0.0163, 0.0151, 0.0136, 0.0131, 0.0089,
        0.0097, 0.0095, 0.0100, 0.0109, 0.0127, 0.0147, 0.0155, 0.0182],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0076, 0.0069, 0.0081, 0.0046, 0.0080, 0.0070, 0.0082, 0.0074, 0.0073,
        0.0073, 0.0078, 0.0087, 0.0098, 0.0119, 0.0125, 0.0129, 0.0118, 0.0101,
        0.0102, 0.0104, 0.0109, 0.0130, 0.0122, 0.0115, 0.0110, 0.0128, 0.0116,
        0.0118, 0.0135, 0.0140, 0.0121, 0.0136, 0.0130, 0.0132, 0.0126, 0.0147,
        0.0169, 0.0176, 0.0177, 0.0174, 0.0159, 0.0164, 0.0170, 0.0175, 0.0194,
        0.0197, 0.0188, 0.0193, 0.0182, 0.0182, 0.0191, 0.0192, 0.0219, 0.0227,
        0.0210, 0.0213, 0.0198, 0.0188, 0.0176, 0.0188, 0.0184, 0.0179, 0.0175,
        0.0168, 0.0177, 0.0173, 0.0179, 0.0202, 0.0211, 0.0195, 0.0205, 0.0209,
        0.0219, 0.0220, 0.0207, 0.0196, 0.0192, 0.0198, 0.0192, 0.0192, 0.0189,
        0.0179, 0.0189, 0.0202, 0.0217, 0.0224, 0.0208, 0.0204, 0.0204, 0.0205,
        0.0218, 0.0221, 0.0218, 0.0202, 0.0205, 0.0211, 0.0195, 0.0195, 0.0187,
        0.0182, 0.0174, 0.0168, 0.0197, 0.0214, 0.0207, 0.0214, 0.0228, 0.0225,
        0.0216, 0.0214, 0.0228, 0.0219, 0.0223, 0.0217, 0.0215, 0.0213, 0.0218,
        0.0216, 0.0217, 0.0221, 0.0220, 0.0215, 0.0214, 0.0212, 0.0196, 0.0185,
        0.0169, 0.0173, 0.0188, 0.0201, 0.0197, 0.0205, 0.0202, 0.0195, 0.0194,
        0.0191, 0.0188, 0.0201, 0.0230, 0.0248, 0.0236, 0.0217, 0.0184, 0.0237,
        0.0192, 0.0189, 0.0177, 0.0183, 0.0195, 0.0207, 0.0207, 0.0228, 0.0207,
        0.0205, 0.0204, 0.0209, 0.0206, 0.0179, 0.0164, 0.0166, 0.0173, 0.0177,
        0.0182, 0.0205, 0.0177, 0.0179, 0.0150, 0.0167, 0.0175, 0.0171, 0.0170,
        0.0182, 0.0184, 0.0192, 0.0187, 0.0218, 0.0199, 0.0196, 0.0227, 0.0233,
        0.0203, 0.0175, 0.0178, 0.0173, 0.0158, 0.0161, 0.0173, 0.0175, 0.0184,
        0.0195, 0.0209, 0.0232, 0.0231, 0.0202, 0.0213, 0.0201, 0.0231, 0.0270,
        0.0283, 0.0277, 0.0270, 0.0247, 0.0238, 0.0270, 0.0334, 0.0273, 0.0328,
        0.0362, 0.0328, 0.0329, 0.0310, 0.0330, 0.0314, 0.0416, 0.0452, 0.0528,
        0.0559, 0.0479, 0.0533, 0.0536, 0.0553, 0.0598, 0.0589, 0.0607, 0.0649,
        0.0679, 0.0630, 0.0646, 0.0654, 0.0651, 0.0649, 0.0698, 0.0786, 0.0846,
        0.0794, 0.0889, 0.0966, 0.1097, 0.1179, 0.1149, 0.1107, 0.1162, 0.1162,
        0.1160, 0.1095, 0.1203, 0.1226, 0.1372, 0.1417, 0.1624, 0.1870, 0.2025,
        0.1932, 0.1815, 0.1677, 0.1693, 0.1631, 0.1582, 0.1294, 0.1233, 0.1184,
        0.1156, 0.1007, 0.1085, 0.1053, 0.1167, 0.1119, 0.1070, 0.0978, 0.0945,
        0.0891, 0.0855, 0.0844, 0.0809, 0.0777, 0.0719, 0.0717, 0.0691, 0.0677,
        0.0641, 0.0639, 0.0645, 0.0603, 0.0572, 0.0511, 0.0433, 0.0399, 0.0370,
        0.0321, 0.0322, 0.0331, 0.0289, 0.0264, 0.0249, 0.0216, 0.0192, 0.0166,
        0.0151, 0.0151, 0.0143, 0.0147, 0.0161, 0.0158, 0.0139, 0.0101, 0.0105,
        0.0113, 0.0142, 0.0161, 0.0116, 0.0116, 0.0118, 0.0154, 0.0166, 0.0184,
        0.0221, 0.0203, 0.0204, 0.0183, 0.0142, 0.0140, 0.0120, 0.0108, 0.0118,
        0.0133, 0.0116, 0.0119, 0.0151, 0.0112, 0.0161, 0.0189, 0.0171, 0.0181,
        0.0163, 0.0177, 0.0173, 0.0162, 0.0169, 0.0157, 0.0141, 0.0136, 0.0093,
        0.0099, 0.0097, 0.0103, 0.0112, 0.0130, 0.0150, 0.0157, 0.0184],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0075, 0.0068, 0.0080, 0.0045, 0.0079, 0.0070, 0.0081, 0.0074, 0.0073,
        0.0073, 0.0078, 0.0087, 0.0098, 0.0118, 0.0124, 0.0128, 0.0117, 0.0100,
        0.0102, 0.0104, 0.0108, 0.0130, 0.0122, 0.0115, 0.0109, 0.0127, 0.0116,
        0.0117, 0.0134, 0.0140, 0.0121, 0.0136, 0.0130, 0.0131, 0.0126, 0.0147,
        0.0168, 0.0176, 0.0177, 0.0173, 0.0159, 0.0163, 0.0170, 0.0175, 0.0193,
        0.0196, 0.0188, 0.0192, 0.0182, 0.0182, 0.0190, 0.0192, 0.0218, 0.0226,
        0.0209, 0.0213, 0.0198, 0.0187, 0.0176, 0.0188, 0.0184, 0.0178, 0.0174,
        0.0167, 0.0177, 0.0172, 0.0179, 0.0201, 0.0210, 0.0195, 0.0204, 0.0208,
        0.0219, 0.0219, 0.0206, 0.0196, 0.0192, 0.0197, 0.0192, 0.0191, 0.0188,
        0.0179, 0.0188, 0.0201, 0.0217, 0.0224, 0.0208, 0.0204, 0.0204, 0.0205,
        0.0218, 0.0220, 0.0217, 0.0201, 0.0204, 0.0210, 0.0195, 0.0194, 0.0186,
        0.0182, 0.0174, 0.0167, 0.0197, 0.0213, 0.0206, 0.0214, 0.0227, 0.0224,
        0.0215, 0.0214, 0.0228, 0.0219, 0.0223, 0.0216, 0.0214, 0.0212, 0.0217,
        0.0216, 0.0216, 0.0220, 0.0220, 0.0215, 0.0214, 0.0211, 0.0195, 0.0185,
        0.0168, 0.0173, 0.0187, 0.0201, 0.0197, 0.0205, 0.0201, 0.0195, 0.0194,
        0.0191, 0.0188, 0.0201, 0.0229, 0.0248, 0.0236, 0.0216, 0.0184, 0.0237,
        0.0192, 0.0188, 0.0176, 0.0182, 0.0194, 0.0206, 0.0206, 0.0227, 0.0207,
        0.0205, 0.0203, 0.0208, 0.0205, 0.0178, 0.0163, 0.0166, 0.0172, 0.0177,
        0.0181, 0.0205, 0.0176, 0.0179, 0.0149, 0.0166, 0.0174, 0.0170, 0.0169,
        0.0181, 0.0184, 0.0191, 0.0187, 0.0218, 0.0198, 0.0195, 0.0227, 0.0233,
        0.0202, 0.0175, 0.0178, 0.0172, 0.0158, 0.0160, 0.0172, 0.0174, 0.0184,
        0.0194, 0.0208, 0.0232, 0.0231, 0.0202, 0.0213, 0.0201, 0.0231, 0.0269,
        0.0282, 0.0277, 0.0270, 0.0247, 0.0238, 0.0269, 0.0333, 0.0272, 0.0328,
        0.0363, 0.0328, 0.0329, 0.0310, 0.0330, 0.0313, 0.0416, 0.0451, 0.0527,
        0.0559, 0.0478, 0.0532, 0.0536, 0.0551, 0.0597, 0.0588, 0.0605, 0.0647,
        0.0678, 0.0628, 0.0645, 0.0653, 0.0650, 0.0648, 0.0697, 0.0784, 0.0844,
        0.0792, 0.0887, 0.0963, 0.1094, 0.1177, 0.1147, 0.1106, 0.1161, 0.1160,
        0.1159, 0.1094, 0.1202, 0.1223, 0.1370, 0.1413, 0.1614, 0.1863, 0.2021,
        0.1931, 0.1817, 0.1679, 0.1693, 0.1632, 0.1586, 0.1297, 0.1239, 0.1189,
        0.1159, 0.1008, 0.1083, 0.1051, 0.1166, 0.1119, 0.1071, 0.0979, 0.0947,
        0.0893, 0.0857, 0.0846, 0.0811, 0.0779, 0.0720, 0.0718, 0.0693, 0.0679,
        0.0643, 0.0641, 0.0647, 0.0604, 0.0573, 0.0512, 0.0434, 0.0400, 0.0372,
        0.0322, 0.0323, 0.0332, 0.0290, 0.0265, 0.0250, 0.0217, 0.0192, 0.0166,
        0.0152, 0.0152, 0.0144, 0.0147, 0.0161, 0.0159, 0.0139, 0.0101, 0.0106,
        0.0113, 0.0142, 0.0162, 0.0116, 0.0116, 0.0118, 0.0154, 0.0165, 0.0184,
        0.0220, 0.0203, 0.0203, 0.0183, 0.0142, 0.0139, 0.0119, 0.0108, 0.0118,
        0.0133, 0.0116, 0.0119, 0.0151, 0.0112, 0.0160, 0.0188, 0.0171, 0.0181,
        0.0163, 0.0176, 0.0173, 0.0161, 0.0169, 0.0156, 0.0140, 0.0135, 0.0092,
        0.0099, 0.0097, 0.0102, 0.0111, 0.0130, 0.0149, 0.0157, 0.0184],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0005, 0.0012, 0.0025, 0.0135, 0.0203, 0.0285, 0.0300, 0.0326, 0.0334,
        0.0339, 0.0341, 0.0323, 0.0319, 0.0346, 0.0365, 0.0346, 0.0343, 0.0328,
        0.0307, 0.0282, 0.0274, 0.0281, 0.0335, 0.0330, 0.0324, 0.0349, 0.0322,
        0.0293, 0.0288, 0.0279, 0.0299, 0.0299, 0.0289, 0.0289, 0.0335, 0.0317,
        0.0310, 0.0369, 0.0393, 0.0373, 0.0339, 0.0342, 0.0347, 0.0374, 0.0421,
        0.0458, 0.0441, 0.0420, 0.0404, 0.0408, 0.0394, 0.0399, 0.0402, 0.0408,
        0.0428, 0.0439, 0.0444, 0.0424, 0.0425, 0.0409, 0.0397, 0.0402, 0.0418,
        0.0411, 0.0392, 0.0375, 0.0383, 0.0402, 0.0400, 0.0340, 0.0297, 0.0300,
        0.0337, 0.0384, 0.0394, 0.0373, 0.0386, 0.0377, 0.0386, 0.0400, 0.0412,
        0.0406, 0.0398, 0.0424, 0.0490, 0.0492, 0.0475, 0.0467, 0.0458, 0.0457,
        0.0464, 0.0470, 0.0470, 0.0454, 0.0456, 0.0454, 0.0466, 0.0450, 0.0434,
        0.0430, 0.0434, 0.0423, 0.0419, 0.0392, 0.0394, 0.0429, 0.0437, 0.0413,
        0.0406, 0.0419, 0.0415, 0.0423, 0.0438, 0.0444, 0.0439, 0.0443, 0.0440,
        0.0437, 0.0448, 0.0461, 0.0475, 0.0471, 0.0463, 0.0421, 0.0420, 0.0403,
        0.0390, 0.0376, 0.0368, 0.0357, 0.0360, 0.0385, 0.0395, 0.0403, 0.0406,
        0.0418, 0.0433, 0.0448, 0.0445, 0.0491, 0.0459, 0.0426, 0.0448, 0.0464,
        0.0473, 0.0439, 0.0433, 0.0439, 0.0419, 0.0440, 0.0423, 0.0431, 0.0420,
        0.0412, 0.0417, 0.0426, 0.0446, 0.0448, 0.0428, 0.0437, 0.0402, 0.0408,
        0.0359, 0.0387, 0.0342, 0.0327, 0.0325, 0.0329, 0.0325, 0.0314, 0.0315,
        0.0319, 0.0335, 0.0360, 0.0383, 0.0378, 0.0352, 0.0348, 0.0450, 0.0447,
        0.0404, 0.0373, 0.0339, 0.0339, 0.0282, 0.0306, 0.0315, 0.0246, 0.0336,
        0.0289, 0.0330, 0.0338, 0.0332, 0.0329, 0.0344, 0.0377, 0.0396, 0.0386,
        0.0410, 0.0398, 0.0412, 0.0424, 0.0402, 0.0341, 0.0368, 0.0304, 0.0450,
        0.0407, 0.0393, 0.0414, 0.0382, 0.0406, 0.0424, 0.0403, 0.0359, 0.0387,
        0.0571, 0.0528, 0.0540, 0.0522, 0.0497, 0.0482, 0.0457, 0.0440, 0.0499,
        0.0559, 0.0491, 0.0489, 0.0517, 0.0558, 0.0546, 0.0541, 0.0590, 0.0596,
        0.0548, 0.0564, 0.0512, 0.0570, 0.0652, 0.0659, 0.0675, 0.0764, 0.0798,
        0.0810, 0.0717, 0.0731, 0.0759, 0.0764, 0.0710, 0.0750, 0.0764, 0.0852,
        0.0879, 0.0914, 0.0921, 0.0924, 0.0950, 0.0936, 0.0876, 0.0873, 0.0873,
        0.0767, 0.0792, 0.0836, 0.0858, 0.0967, 0.1056, 0.1143, 0.1112, 0.1125,
        0.1086, 0.1038, 0.1058, 0.1066, 0.1078, 0.1075, 0.1112, 0.1112, 0.1181,
        0.1153, 0.1169, 0.1128, 0.1062, 0.1067, 0.1021, 0.1026, 0.1063, 0.1037,
        0.1076, 0.1059, 0.1056, 0.0995, 0.1034, 0.1014, 0.1035, 0.1006, 0.0991,
        0.0927, 0.0914, 0.0830, 0.0810, 0.0861, 0.0912, 0.0955, 0.0874, 0.0757,
        0.0644, 0.0673, 0.0684, 0.0588, 0.0552, 0.0490, 0.0526, 0.0626, 0.0615,
        0.0596, 0.0574, 0.0580, 0.0549, 0.0480, 0.0453, 0.0438, 0.0432, 0.0490,
        0.0497, 0.0469, 0.0489, 0.0481, 0.0412, 0.0400, 0.0398, 0.0428, 0.0427,
        0.0514, 0.0544, 0.0468, 0.0468, 0.0476, 0.0464, 0.0441, 0.0435, 0.0479,
        0.0426, 0.0392, 0.0383, 0.0350, 0.0287, 0.0270, 0.0260, 0.0295],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0080, 0.0072, 0.0084, 0.0047, 0.0078, 0.0065, 0.0075, 0.0067, 0.0067,
        0.0067, 0.0072, 0.0080, 0.0089, 0.0107, 0.0113, 0.0118, 0.0107, 0.0094,
        0.0094, 0.0097, 0.0096, 0.0119, 0.0111, 0.0106, 0.0101, 0.0111, 0.0104,
        0.0105, 0.0122, 0.0126, 0.0109, 0.0122, 0.0116, 0.0118, 0.0112, 0.0133,
        0.0153, 0.0161, 0.0161, 0.0157, 0.0144, 0.0148, 0.0154, 0.0159, 0.0176,
        0.0179, 0.0170, 0.0175, 0.0166, 0.0166, 0.0175, 0.0176, 0.0203, 0.0215,
        0.0194, 0.0197, 0.0181, 0.0171, 0.0159, 0.0171, 0.0167, 0.0161, 0.0157,
        0.0150, 0.0160, 0.0156, 0.0163, 0.0185, 0.0195, 0.0179, 0.0189, 0.0195,
        0.0206, 0.0206, 0.0193, 0.0182, 0.0178, 0.0183, 0.0176, 0.0175, 0.0172,
        0.0162, 0.0171, 0.0185, 0.0200, 0.0207, 0.0190, 0.0186, 0.0187, 0.0188,
        0.0201, 0.0204, 0.0201, 0.0186, 0.0189, 0.0194, 0.0178, 0.0177, 0.0170,
        0.0165, 0.0157, 0.0151, 0.0181, 0.0198, 0.0193, 0.0200, 0.0213, 0.0209,
        0.0200, 0.0199, 0.0214, 0.0204, 0.0208, 0.0201, 0.0200, 0.0198, 0.0203,
        0.0203, 0.0203, 0.0206, 0.0207, 0.0205, 0.0199, 0.0198, 0.0181, 0.0170,
        0.0154, 0.0158, 0.0172, 0.0186, 0.0183, 0.0192, 0.0188, 0.0180, 0.0180,
        0.0177, 0.0173, 0.0186, 0.0218, 0.0236, 0.0222, 0.0202, 0.0168, 0.0226,
        0.0176, 0.0173, 0.0161, 0.0167, 0.0181, 0.0193, 0.0191, 0.0213, 0.0193,
        0.0191, 0.0190, 0.0194, 0.0191, 0.0164, 0.0149, 0.0152, 0.0157, 0.0163,
        0.0168, 0.0193, 0.0164, 0.0166, 0.0135, 0.0153, 0.0162, 0.0157, 0.0156,
        0.0168, 0.0170, 0.0178, 0.0174, 0.0207, 0.0188, 0.0185, 0.0216, 0.0221,
        0.0191, 0.0164, 0.0166, 0.0159, 0.0144, 0.0147, 0.0160, 0.0162, 0.0171,
        0.0183, 0.0197, 0.0220, 0.0218, 0.0190, 0.0202, 0.0187, 0.0218, 0.0261,
        0.0275, 0.0269, 0.0263, 0.0238, 0.0229, 0.0259, 0.0323, 0.0261, 0.0319,
        0.0350, 0.0317, 0.0320, 0.0303, 0.0322, 0.0305, 0.0410, 0.0450, 0.0528,
        0.0554, 0.0475, 0.0531, 0.0534, 0.0553, 0.0602, 0.0595, 0.0615, 0.0656,
        0.0684, 0.0636, 0.0650, 0.0657, 0.0651, 0.0650, 0.0702, 0.0792, 0.0855,
        0.0810, 0.0908, 0.0992, 0.1123, 0.1200, 0.1167, 0.1121, 0.1172, 0.1170,
        0.1168, 0.1105, 0.1218, 0.1244, 0.1391, 0.1455, 0.1725, 0.1931, 0.2060,
        0.1936, 0.1797, 0.1652, 0.1674, 0.1600, 0.1531, 0.1256, 0.1174, 0.1149,
        0.1132, 0.1001, 0.1097, 0.1067, 0.1177, 0.1120, 0.1064, 0.0966, 0.0927,
        0.0871, 0.0833, 0.0820, 0.0784, 0.0753, 0.0700, 0.0699, 0.0674, 0.0655,
        0.0616, 0.0611, 0.0617, 0.0574, 0.0543, 0.0483, 0.0408, 0.0375, 0.0351,
        0.0305, 0.0304, 0.0313, 0.0275, 0.0251, 0.0239, 0.0207, 0.0183, 0.0157,
        0.0143, 0.0142, 0.0133, 0.0137, 0.0151, 0.0149, 0.0130, 0.0094, 0.0099,
        0.0105, 0.0133, 0.0151, 0.0104, 0.0108, 0.0108, 0.0140, 0.0150, 0.0168,
        0.0204, 0.0187, 0.0186, 0.0168, 0.0129, 0.0127, 0.0108, 0.0099, 0.0108,
        0.0122, 0.0107, 0.0110, 0.0138, 0.0096, 0.0145, 0.0173, 0.0156, 0.0165,
        0.0147, 0.0160, 0.0157, 0.0147, 0.0155, 0.0143, 0.0127, 0.0124, 0.0082,
        0.0091, 0.0091, 0.0094, 0.0101, 0.0119, 0.0138, 0.0147, 0.0168],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([-0.0094, -0.0093, -0.0084,  0.0013,  0.0054,  0.0138,  0.0152,  0.0180,
         0.0183,  0.0186,  0.0192,  0.0185,  0.0193,  0.0248,  0.0279,  0.0256,
         0.0242,  0.0224,  0.0203,  0.0178,  0.0164,  0.0171,  0.0217,  0.0205,
         0.0203,  0.0224,  0.0205,  0.0184,  0.0185,  0.0173,  0.0183,  0.0186,
         0.0177,  0.0177,  0.0208,  0.0184,  0.0173,  0.0238,  0.0258,  0.0241,
         0.0210,  0.0226,  0.0234,  0.0262,  0.0302,  0.0332,  0.0321,  0.0312,
         0.0298,  0.0298,  0.0290,  0.0297,  0.0299,  0.0303,  0.0306,  0.0319,
         0.0327,  0.0311,  0.0308,  0.0290,  0.0274,  0.0281,  0.0291,  0.0289,
         0.0281,  0.0258,  0.0268,  0.0297,  0.0303,  0.0241,  0.0201,  0.0202,
         0.0234,  0.0276,  0.0286,  0.0267,  0.0286,  0.0268,  0.0275,  0.0292,
         0.0307,  0.0301,  0.0294,  0.0315,  0.0364,  0.0364,  0.0357,  0.0354,
         0.0347,  0.0345,  0.0356,  0.0365,  0.0366,  0.0350,  0.0350,  0.0349,
         0.0354,  0.0345,  0.0334,  0.0332,  0.0335,  0.0324,  0.0330,  0.0305,
         0.0309,  0.0352,  0.0372,  0.0353,  0.0338,  0.0356,  0.0361,  0.0367,
         0.0384,  0.0385,  0.0383,  0.0389,  0.0385,  0.0374,  0.0378,  0.0387,
         0.0399,  0.0405,  0.0410,  0.0388,  0.0372,  0.0356,  0.0336,  0.0343,
         0.0347,  0.0339,  0.0329,  0.0351,  0.0353,  0.0350,  0.0345,  0.0360,
         0.0364,  0.0383,  0.0381,  0.0430,  0.0418,  0.0402,  0.0394,  0.0425,
         0.0421,  0.0393,  0.0393,  0.0401,  0.0368,  0.0385,  0.0365,  0.0367,
         0.0348,  0.0344,  0.0347,  0.0362,  0.0379,  0.0388,  0.0366,  0.0376,
         0.0351,  0.0356,  0.0311,  0.0326,  0.0296,  0.0277,  0.0273,  0.0286,
         0.0290,  0.0286,  0.0293,  0.0301,  0.0309,  0.0323,  0.0335,  0.0336,
         0.0308,  0.0317,  0.0403,  0.0405,  0.0361,  0.0335,  0.0297,  0.0304,
         0.0246,  0.0270,  0.0280,  0.0216,  0.0303,  0.0262,  0.0286,  0.0293,
         0.0290,  0.0286,  0.0299,  0.0337,  0.0352,  0.0327,  0.0342,  0.0341,
         0.0354,  0.0367,  0.0343,  0.0281,  0.0310,  0.0241,  0.0368,  0.0316,
         0.0325,  0.0357,  0.0312,  0.0354,  0.0364,  0.0337,  0.0285,  0.0292,
         0.0484,  0.0452,  0.0447,  0.0414,  0.0378,  0.0364,  0.0338,  0.0338,
         0.0376,  0.0440,  0.0364,  0.0376,  0.0404,  0.0414,  0.0392,  0.0374,
         0.0439,  0.0434,  0.0398,  0.0403,  0.0330,  0.0393,  0.0474,  0.0482,
         0.0480,  0.0529,  0.0542,  0.0572,  0.0506,  0.0527,  0.0560,  0.0558,
         0.0493,  0.0526,  0.0542,  0.0605,  0.0622,  0.0650,  0.0679,  0.0693,
         0.0735,  0.0721,  0.0704,  0.0703,  0.0711,  0.0594,  0.0633,  0.0654,
         0.0658,  0.0748,  0.0837,  0.0924,  0.0943,  0.0998,  0.0984,  0.0941,
         0.0958,  0.0961,  0.0958,  0.0955,  0.1013,  0.1022,  0.1109,  0.1077,
         0.1087,  0.1065,  0.1017,  0.1038,  0.0998,  0.1018,  0.1063,  0.1028,
         0.1084,  0.1073,  0.1079,  0.1000,  0.1036,  0.0992,  0.0997,  0.0935,
         0.0921,  0.0850,  0.0866,  0.0812,  0.0807,  0.0844,  0.0883,  0.0908,
         0.0810,  0.0749,  0.0665,  0.0721,  0.0745,  0.0663,  0.0623,  0.0578,
         0.0600,  0.0648,  0.0611,  0.0571,  0.0550,  0.0549,  0.0529,  0.0508,
         0.0472,  0.0470,  0.0437,  0.0474,  0.0498,  0.0464,  0.0534,  0.0556,
         0.0460,  0.0429,  0.0394,  0.0381,  0.0346,  0.0383,  0.0386,  0.0351,
         0.0361,  0.0358,  0.0368,  0.0372,  0.0372,  0.0399,  0.0335,  0.0301,
         0.0304,  0.0273,  0.0222,  0.0204,  0.0203,  0.0211],
       grad_fn=<SelectBackward>)
torch.Size([350, 10, 5])
tensor([0.0081, 0.0072, 0.0083, 0.0043, 0.0070, 0.0056, 0.0065, 0.0058, 0.0059,
        0.0061, 0.0064, 0.0070, 0.0076, 0.0091, 0.0097, 0.0101, 0.0090, 0.0083,
        0.0081, 0.0087, 0.0078, 0.0104, 0.0097, 0.0093, 0.0089, 0.0086, 0.0087,
        0.0088, 0.0103, 0.0105, 0.0091, 0.0102, 0.0098, 0.0099, 0.0092, 0.0114,
        0.0129, 0.0138, 0.0136, 0.0132, 0.0121, 0.0125, 0.0130, 0.0135, 0.0151,
        0.0152, 0.0143, 0.0149, 0.0140, 0.0141, 0.0149, 0.0150, 0.0178, 0.0194,
        0.0168, 0.0170, 0.0154, 0.0145, 0.0135, 0.0145, 0.0140, 0.0135, 0.0132,
        0.0125, 0.0134, 0.0130, 0.0137, 0.0158, 0.0169, 0.0153, 0.0164, 0.0172,
        0.0183, 0.0184, 0.0170, 0.0158, 0.0154, 0.0157, 0.0152, 0.0150, 0.0147,
        0.0136, 0.0146, 0.0159, 0.0174, 0.0179, 0.0162, 0.0159, 0.0160, 0.0161,
        0.0175, 0.0177, 0.0175, 0.0160, 0.0163, 0.0168, 0.0151, 0.0151, 0.0144,
        0.0140, 0.0133, 0.0128, 0.0156, 0.0173, 0.0169, 0.0177, 0.0189, 0.0184,
        0.0175, 0.0176, 0.0191, 0.0181, 0.0184, 0.0178, 0.0176, 0.0175, 0.0180,
        0.0181, 0.0180, 0.0183, 0.0184, 0.0189, 0.0175, 0.0174, 0.0158, 0.0148,
        0.0132, 0.0135, 0.0149, 0.0163, 0.0160, 0.0170, 0.0166, 0.0158, 0.0157,
        0.0154, 0.0150, 0.0163, 0.0200, 0.0215, 0.0199, 0.0178, 0.0144, 0.0207,
        0.0152, 0.0151, 0.0138, 0.0144, 0.0158, 0.0170, 0.0166, 0.0189, 0.0170,
        0.0168, 0.0167, 0.0171, 0.0168, 0.0144, 0.0128, 0.0131, 0.0135, 0.0141,
        0.0145, 0.0172, 0.0142, 0.0144, 0.0114, 0.0133, 0.0141, 0.0136, 0.0135,
        0.0145, 0.0148, 0.0156, 0.0153, 0.0186, 0.0168, 0.0165, 0.0197, 0.0202,
        0.0172, 0.0146, 0.0150, 0.0141, 0.0124, 0.0126, 0.0139, 0.0141, 0.0150,
        0.0163, 0.0177, 0.0200, 0.0199, 0.0170, 0.0182, 0.0165, 0.0198, 0.0245,
        0.0261, 0.0254, 0.0248, 0.0222, 0.0212, 0.0242, 0.0304, 0.0243, 0.0306,
        0.0334, 0.0300, 0.0305, 0.0291, 0.0309, 0.0290, 0.0396, 0.0438, 0.0521,
        0.0543, 0.0462, 0.0520, 0.0524, 0.0544, 0.0595, 0.0591, 0.0612, 0.0653,
        0.0679, 0.0632, 0.0646, 0.0652, 0.0645, 0.0645, 0.0697, 0.0789, 0.0855,
        0.0814, 0.0915, 0.1004, 0.1136, 0.1210, 0.1176, 0.1128, 0.1176, 0.1173,
        0.1168, 0.1108, 0.1223, 0.1252, 0.1403, 0.1479, 0.1780, 0.1962, 0.2079,
        0.1938, 0.1788, 0.1639, 0.1659, 0.1574, 0.1500, 0.1232, 0.1145, 0.1136,
        0.1119, 0.0997, 0.1102, 0.1072, 0.1182, 0.1119, 0.1060, 0.0959, 0.0917,
        0.0858, 0.0818, 0.0804, 0.0766, 0.0736, 0.0685, 0.0686, 0.0660, 0.0636,
        0.0594, 0.0587, 0.0592, 0.0548, 0.0516, 0.0457, 0.0386, 0.0357, 0.0337,
        0.0295, 0.0292, 0.0302, 0.0267, 0.0245, 0.0235, 0.0203, 0.0179, 0.0152,
        0.0138, 0.0135, 0.0124, 0.0130, 0.0144, 0.0141, 0.0124, 0.0089, 0.0095,
        0.0100, 0.0127, 0.0142, 0.0092, 0.0098, 0.0095, 0.0121, 0.0129, 0.0145,
        0.0178, 0.0165, 0.0163, 0.0148, 0.0111, 0.0112, 0.0095, 0.0090, 0.0097,
        0.0111, 0.0098, 0.0100, 0.0121, 0.0076, 0.0124, 0.0151, 0.0135, 0.0144,
        0.0128, 0.0138, 0.0136, 0.0129, 0.0136, 0.0125, 0.0110, 0.0110, 0.0069,
        0.0082, 0.0083, 0.0084, 0.0087, 0.0104, 0.0120, 0.0132, 0.0143],
       grad_fn=<SelectBackward>)
