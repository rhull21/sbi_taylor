Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:41, 241.83it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:41, 242.30it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:41, 242.00it/s]Running 10000 simulations.:   1%|          | 100/10000 [00:00<00:40, 242.20it/s]Running 10000 simulations.:   1%|▏         | 125/10000 [00:00<00:40, 243.66it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:40, 243.60it/s]Running 10000 simulations.:   2%|▏         | 175/10000 [00:00<00:40, 243.56it/s]Running 10000 simulations.:   2%|▏         | 200/10000 [00:00<00:40, 242.98it/s]Running 10000 simulations.:   2%|▏         | 225/10000 [00:00<00:40, 242.50it/s]Running 10000 simulations.:   2%|▎         | 250/10000 [00:01<00:40, 242.34it/s]Running 10000 simulations.:   3%|▎         | 275/10000 [00:01<00:40, 242.49it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:01<00:40, 241.82it/s]Running 10000 simulations.:   3%|▎         | 324/10000 [00:01<00:40, 241.21it/s]Running 10000 simulations.:   3%|▎         | 349/10000 [00:01<00:40, 240.99it/s]Running 10000 simulations.:   4%|▎         | 373/10000 [00:01<00:40, 240.05it/s]Running 10000 simulations.:   4%|▍         | 397/10000 [00:01<00:40, 238.93it/s]Running 10000 simulations.:   4%|▍         | 421/10000 [00:01<00:40, 239.17it/s]Running 10000 simulations.:   4%|▍         | 446/10000 [00:01<00:39, 239.80it/s]Running 10000 simulations.:   5%|▍         | 470/10000 [00:01<00:39, 239.49it/s]Running 10000 simulations.:   5%|▍         | 494/10000 [00:02<00:39, 237.66it/s]Running 10000 simulations.:   5%|▌         | 518/10000 [00:02<00:40, 236.13it/s]Running 10000 simulations.:   5%|▌         | 542/10000 [00:02<00:40, 235.98it/s]Running 10000 simulations.:   6%|▌         | 566/10000 [00:02<00:40, 235.54it/s]Running 10000 simulations.:   6%|▌         | 590/10000 [00:02<00:39, 236.75it/s]Running 10000 simulations.:   6%|▌         | 615/10000 [00:02<00:39, 237.84it/s]Running 10000 simulations.:   6%|▋         | 640/10000 [00:02<00:39, 238.48it/s]Running 10000 simulations.:   7%|▋         | 664/10000 [00:02<00:39, 238.31it/s]Running 10000 simulations.:   7%|▋         | 688/10000 [00:02<00:39, 238.02it/s]Running 10000 simulations.:   7%|▋         | 712/10000 [00:02<00:38, 238.17it/s]Running 10000 simulations.:   7%|▋         | 737/10000 [00:03<00:38, 239.30it/s]Running 10000 simulations.:   8%|▊         | 762/10000 [00:03<00:38, 240.05it/s]Running 10000 simulations.:   8%|▊         | 787/10000 [00:03<00:38, 239.96it/s]Running 10000 simulations.:   8%|▊         | 811/10000 [00:03<00:38, 239.41it/s]Running 10000 simulations.:   8%|▊         | 835/10000 [00:03<00:38, 239.51it/s]Running 10000 simulations.:   9%|▊         | 859/10000 [00:03<00:38, 239.08it/s]Running 10000 simulations.:   9%|▉         | 883/10000 [00:03<00:38, 237.93it/s]Running 10000 simulations.:   9%|▉         | 907/10000 [00:03<00:38, 237.53it/s]Running 10000 simulations.:   9%|▉         | 931/10000 [00:03<00:38, 238.14it/s]Running 10000 simulations.:  10%|▉         | 955/10000 [00:03<00:37, 238.48it/s]Running 10000 simulations.:  10%|▉         | 979/10000 [00:04<00:37, 238.63it/s]Running 10000 simulations.:  10%|█         | 1003/10000 [00:04<00:37, 238.89it/s]Running 10000 simulations.:  10%|█         | 1027/10000 [00:04<00:37, 238.25it/s]Running 10000 simulations.:  11%|█         | 1052/10000 [00:04<00:37, 238.92it/s]Running 10000 simulations.:  11%|█         | 1076/10000 [00:04<00:37, 238.71it/s]Running 10000 simulations.:  11%|█         | 1100/10000 [00:04<00:37, 238.05it/s]Running 10000 simulations.:  11%|█         | 1124/10000 [00:04<00:37, 238.43it/s]Running 10000 simulations.:  11%|█▏        | 1148/10000 [00:04<00:37, 238.70it/s]Running 10000 simulations.:  12%|█▏        | 1172/10000 [00:04<00:37, 238.59it/s]Running 10000 simulations.:  12%|█▏        | 1196/10000 [00:04<00:36, 238.01it/s]Running 10000 simulations.:  12%|█▏        | 1220/10000 [00:05<00:36, 238.56it/s]Running 10000 simulations.:  12%|█▏        | 1244/10000 [00:05<00:36, 238.86it/s]Running 10000 simulations.:  13%|█▎        | 1268/10000 [00:05<00:36, 238.71it/s]Running 10000 simulations.:  13%|█▎        | 1292/10000 [00:05<00:36, 238.24it/s]Running 10000 simulations.:  13%|█▎        | 1316/10000 [00:05<00:36, 238.26it/s]Running 10000 simulations.:  13%|█▎        | 1340/10000 [00:05<00:36, 237.99it/s]Running 10000 simulations.:  14%|█▎        | 1364/10000 [00:05<00:36, 237.99it/s]Running 10000 simulations.:  14%|█▍        | 1388/10000 [00:05<00:36, 237.48it/s]Running 10000 simulations.:  14%|█▍        | 1412/10000 [00:05<00:36, 237.50it/s]Running 10000 simulations.:  14%|█▍        | 1436/10000 [00:06<00:36, 237.72it/s]Running 10000 simulations.:  15%|█▍        | 1460/10000 [00:06<00:35, 237.59it/s]Running 10000 simulations.:  15%|█▍        | 1484/10000 [00:06<00:35, 237.05it/s]Running 10000 simulations.:  15%|█▌        | 1508/10000 [00:06<00:35, 236.57it/s]Running 10000 simulations.:  15%|█▌        | 1532/10000 [00:06<00:35, 236.18it/s]Running 10000 simulations.:  16%|█▌        | 1556/10000 [00:06<00:35, 235.61it/s]Running 10000 simulations.:  16%|█▌        | 1580/10000 [00:06<00:35, 235.72it/s]Running 10000 simulations.:  16%|█▌        | 1604/10000 [00:06<00:35, 235.55it/s]Running 10000 simulations.:  16%|█▋        | 1628/10000 [00:06<00:35, 236.11it/s]Running 10000 simulations.:  17%|█▋        | 1652/10000 [00:06<00:35, 236.44it/s]Running 10000 simulations.:  17%|█▋        | 1676/10000 [00:07<00:35, 235.64it/s]Running 10000 simulations.:  17%|█▋        | 1700/10000 [00:07<00:35, 235.36it/s]Running 10000 simulations.:  17%|█▋        | 1725/10000 [00:07<00:34, 237.26it/s]Running 10000 simulations.:  17%|█▋        | 1749/10000 [00:07<00:34, 237.15it/s]Running 10000 simulations.:  18%|█▊        | 1773/10000 [00:07<00:34, 237.09it/s]Running 10000 simulations.:  18%|█▊        | 1797/10000 [00:07<00:35, 233.01it/s]Running 10000 simulations.:  18%|█▊        | 1821/10000 [00:07<00:35, 232.84it/s]Running 10000 simulations.:  18%|█▊        | 1845/10000 [00:07<00:34, 234.03it/s]Running 10000 simulations.:  19%|█▊        | 1869/10000 [00:07<00:34, 233.93it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:07<00:34, 231.88it/s]Running 10000 simulations.:  19%|█▉        | 1917/10000 [00:08<00:35, 230.46it/s]Running 10000 simulations.:  19%|█▉        | 1941/10000 [00:08<00:35, 229.97it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:08<00:35, 228.94it/s]Running 10000 simulations.:  20%|█▉        | 1988/10000 [00:08<00:35, 228.14it/s]Running 10000 simulations.:  20%|██        | 2011/10000 [00:08<00:35, 228.03it/s]Running 10000 simulations.:  20%|██        | 2034/10000 [00:08<00:34, 227.78it/s]Running 10000 simulations.:  21%|██        | 2057/10000 [00:08<00:35, 226.49it/s]Running 10000 simulations.:  21%|██        | 2080/10000 [00:08<00:35, 224.76it/s]Running 10000 simulations.:  21%|██        | 2103/10000 [00:08<00:35, 223.89it/s]Running 10000 simulations.:  21%|██▏       | 2126/10000 [00:08<00:35, 223.08it/s]Running 10000 simulations.:  21%|██▏       | 2149/10000 [00:09<00:35, 222.47it/s]Running 10000 simulations.:  22%|██▏       | 2172/10000 [00:09<00:35, 223.01it/s]Running 10000 simulations.:  22%|██▏       | 2195/10000 [00:09<00:34, 223.24it/s]Running 10000 simulations.:  22%|██▏       | 2218/10000 [00:09<00:35, 222.31it/s]Running 10000 simulations.:  22%|██▏       | 2241/10000 [00:09<00:34, 222.26it/s]Running 10000 simulations.:  23%|██▎       | 2264/10000 [00:09<00:34, 221.90it/s]Running 10000 simulations.:  23%|██▎       | 2287/10000 [00:09<00:34, 222.19it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:09<00:34, 222.75it/s]Running 10000 simulations.:  23%|██▎       | 2333/10000 [00:09<00:34, 222.40it/s]Running 10000 simulations.:  24%|██▎       | 2356/10000 [00:10<00:34, 221.42it/s]Running 10000 simulations.:  24%|██▍       | 2379/10000 [00:10<00:34, 222.52it/s]Running 10000 simulations.:  24%|██▍       | 2402/10000 [00:10<00:34, 222.71it/s]Running 10000 simulations.:  24%|██▍       | 2425/10000 [00:10<00:34, 222.52it/s]Running 10000 simulations.:  24%|██▍       | 2448/10000 [00:10<00:33, 223.05it/s]Running 10000 simulations.:  25%|██▍       | 2471/10000 [00:10<00:33, 222.02it/s]Running 10000 simulations.:  25%|██▍       | 2494/10000 [00:10<00:33, 222.21it/s]Running 10000 simulations.:  25%|██▌       | 2517/10000 [00:10<00:33, 221.89it/s]Running 10000 simulations.:  25%|██▌       | 2540/10000 [00:10<00:33, 219.56it/s]Running 10000 simulations.:  26%|██▌       | 2563/10000 [00:10<00:33, 219.80it/s]Running 10000 simulations.:  26%|██▌       | 2586/10000 [00:11<00:33, 220.66it/s]Running 10000 simulations.:  26%|██▌       | 2609/10000 [00:11<00:33, 221.18it/s]Running 10000 simulations.:  26%|██▋       | 2632/10000 [00:11<00:33, 220.05it/s]Running 10000 simulations.:  27%|██▋       | 2655/10000 [00:11<00:33, 219.64it/s]Running 10000 simulations.:  27%|██▋       | 2678/10000 [00:11<00:33, 220.98it/s]Running 10000 simulations.:  27%|██▋       | 2701/10000 [00:11<00:33, 220.26it/s]Running 10000 simulations.:  27%|██▋       | 2724/10000 [00:11<00:32, 220.75it/s]Running 10000 simulations.:  27%|██▋       | 2747/10000 [00:11<00:32, 221.15it/s]Running 10000 simulations.:  28%|██▊       | 2770/10000 [00:11<00:32, 221.23it/s]Running 10000 simulations.:  28%|██▊       | 2793/10000 [00:11<00:32, 221.24it/s]Running 10000 simulations.:  28%|██▊       | 2816/10000 [00:12<00:32, 221.07it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:12<00:32, 221.03it/s]Running 10000 simulations.:  29%|██▊       | 2862/10000 [00:12<00:32, 220.32it/s]Running 10000 simulations.:  29%|██▉       | 2885/10000 [00:12<00:32, 220.19it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:12<00:32, 219.56it/s]Running 10000 simulations.:  29%|██▉       | 2930/10000 [00:12<00:32, 219.52it/s]Running 10000 simulations.:  30%|██▉       | 2953/10000 [00:12<00:31, 221.17it/s]Running 10000 simulations.:  30%|██▉       | 2976/10000 [00:12<00:31, 221.36it/s]Running 10000 simulations.:  30%|██▉       | 2999/10000 [00:12<00:31, 220.95it/s]Running 10000 simulations.:  30%|███       | 3022/10000 [00:13<00:31, 221.55it/s]Running 10000 simulations.:  30%|███       | 3045/10000 [00:13<00:31, 220.99it/s]Running 10000 simulations.:  31%|███       | 3068/10000 [00:13<00:31, 221.03it/s]Running 10000 simulations.:  31%|███       | 3091/10000 [00:13<00:31, 221.38it/s]Running 10000 simulations.:  31%|███       | 3114/10000 [00:13<00:30, 222.46it/s]Running 10000 simulations.:  31%|███▏      | 3137/10000 [00:13<00:30, 223.09it/s]Running 10000 simulations.:  32%|███▏      | 3160/10000 [00:13<00:30, 223.13it/s]Running 10000 simulations.:  32%|███▏      | 3183/10000 [00:13<00:30, 223.02it/s]Running 10000 simulations.:  32%|███▏      | 3206/10000 [00:13<00:30, 222.49it/s]Running 10000 simulations.:  32%|███▏      | 3229/10000 [00:13<00:30, 222.93it/s]Running 10000 simulations.:  33%|███▎      | 3252/10000 [00:14<00:30, 222.15it/s]Running 10000 simulations.:  33%|███▎      | 3275/10000 [00:14<00:30, 222.47it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:14<00:30, 221.64it/s]Running 10000 simulations.:  33%|███▎      | 3321/10000 [00:14<00:30, 221.78it/s]Running 10000 simulations.:  33%|███▎      | 3344/10000 [00:14<00:29, 222.97it/s]Running 10000 simulations.:  34%|███▎      | 3367/10000 [00:14<00:29, 222.80it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:14<00:29, 222.65it/s]Running 10000 simulations.:  34%|███▍      | 3413/10000 [00:14<00:29, 222.11it/s]Running 10000 simulations.:  34%|███▍      | 3436/10000 [00:14<00:29, 221.02it/s]Running 10000 simulations.:  35%|███▍      | 3459/10000 [00:15<00:29, 219.48it/s]Running 10000 simulations.:  35%|███▍      | 3482/10000 [00:15<00:29, 220.57it/s]Running 10000 simulations.:  35%|███▌      | 3505/10000 [00:15<00:29, 219.42it/s]Running 10000 simulations.:  35%|███▌      | 3528/10000 [00:15<00:29, 221.91it/s]Running 10000 simulations.:  36%|███▌      | 3551/10000 [00:15<00:28, 224.05it/s]Running 10000 simulations.:  36%|███▌      | 3575/10000 [00:15<00:28, 226.20it/s]Running 10000 simulations.:  36%|███▌      | 3598/10000 [00:15<00:28, 225.59it/s]Running 10000 simulations.:  36%|███▌      | 3622/10000 [00:15<00:28, 227.74it/s]Running 10000 simulations.:  36%|███▋      | 3646/10000 [00:15<00:27, 230.49it/s]Running 10000 simulations.:  37%|███▋      | 3670/10000 [00:15<00:27, 231.98it/s]Running 10000 simulations.:  37%|███▋      | 3694/10000 [00:16<00:27, 233.34it/s]Running 10000 simulations.:  37%|███▋      | 3718/10000 [00:16<00:26, 233.68it/s]Running 10000 simulations.:  37%|███▋      | 3742/10000 [00:16<00:26, 234.27it/s]Running 10000 simulations.:  38%|███▊      | 3766/10000 [00:16<00:26, 235.25it/s]Running 10000 simulations.:  38%|███▊      | 3790/10000 [00:16<00:26, 235.48it/s]Running 10000 simulations.:  38%|███▊      | 3814/10000 [00:16<00:26, 236.01it/s]Running 10000 simulations.:  38%|███▊      | 3838/10000 [00:16<00:26, 236.12it/s]Running 10000 simulations.:  39%|███▊      | 3862/10000 [00:16<00:25, 236.25it/s]Running 10000 simulations.:  39%|███▉      | 3886/10000 [00:16<00:25, 236.05it/s]Running 10000 simulations.:  39%|███▉      | 3910/10000 [00:16<00:26, 233.87it/s]Running 10000 simulations.:  39%|███▉      | 3934/10000 [00:17<00:26, 230.97it/s]Running 10000 simulations.:  40%|███▉      | 3958/10000 [00:17<00:26, 230.86it/s]Running 10000 simulations.:  40%|███▉      | 3982/10000 [00:17<00:25, 232.22it/s]Running 10000 simulations.:  40%|████      | 4006/10000 [00:17<00:25, 232.96it/s]Running 10000 simulations.:  40%|████      | 4030/10000 [00:17<00:25, 233.71it/s]Running 10000 simulations.:  41%|████      | 4054/10000 [00:17<00:25, 234.33it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:17<00:25, 235.12it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:17<00:24, 236.13it/s]Running 10000 simulations.:  41%|████▏     | 4126/10000 [00:17<00:24, 236.01it/s]Running 10000 simulations.:  42%|████▏     | 4150/10000 [00:17<00:24, 236.09it/s]Running 10000 simulations.:  42%|████▏     | 4174/10000 [00:18<00:24, 236.34it/s]Running 10000 simulations.:  42%|████▏     | 4198/10000 [00:18<00:24, 236.13it/s]Running 10000 simulations.:  42%|████▏     | 4222/10000 [00:18<00:24, 236.03it/s]Running 10000 simulations.:  42%|████▏     | 4246/10000 [00:18<00:24, 236.17it/s]Running 10000 simulations.:  43%|████▎     | 4270/10000 [00:18<00:24, 235.76it/s]Running 10000 simulations.:  43%|████▎     | 4294/10000 [00:18<00:24, 236.00it/s]Running 10000 simulations.:  43%|████▎     | 4318/10000 [00:18<00:24, 236.38it/s]Running 10000 simulations.:  43%|████▎     | 4342/10000 [00:18<00:23, 236.58it/s]Running 10000 simulations.:  44%|████▎     | 4366/10000 [00:18<00:23, 235.39it/s]Running 10000 simulations.:  44%|████▍     | 4390/10000 [00:18<00:23, 235.35it/s]Running 10000 simulations.:  44%|████▍     | 4414/10000 [00:19<00:23, 235.94it/s]Running 10000 simulations.:  44%|████▍     | 4438/10000 [00:19<00:23, 237.09it/s]Running 10000 simulations.:  45%|████▍     | 4463/10000 [00:19<00:23, 238.07it/s]Running 10000 simulations.:  45%|████▍     | 4487/10000 [00:19<00:23, 238.14it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:19<00:23, 237.76it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:19<00:23, 237.07it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:19<00:23, 233.24it/s]Running 10000 simulations.:  46%|████▌     | 4583/10000 [00:19<00:23, 234.22it/s]Running 10000 simulations.:  46%|████▌     | 4607/10000 [00:19<00:22, 235.22it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:20<00:22, 235.73it/s]Running 10000 simulations.:  47%|████▋     | 4655/10000 [00:20<00:22, 235.86it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:20<00:22, 235.83it/s]Running 10000 simulations.:  47%|████▋     | 4703/10000 [00:20<00:22, 236.49it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:20<00:22, 236.75it/s]Running 10000 simulations.:  48%|████▊     | 4752/10000 [00:20<00:22, 238.34it/s]Running 10000 simulations.:  48%|████▊     | 4776/10000 [00:20<00:21, 238.78it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:20<00:21, 238.47it/s]Running 10000 simulations.:  48%|████▊     | 4824/10000 [00:20<00:21, 237.79it/s]Running 10000 simulations.:  48%|████▊     | 4848/10000 [00:20<00:21, 237.36it/s]Running 10000 simulations.:  49%|████▊     | 4872/10000 [00:21<00:21, 236.92it/s]Running 10000 simulations.:  49%|████▉     | 4896/10000 [00:21<00:21, 236.69it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:21<00:21, 237.60it/s]Running 10000 simulations.:  49%|████▉     | 4944/10000 [00:21<00:21, 237.14it/s]Running 10000 simulations.:  50%|████▉     | 4968/10000 [00:21<00:21, 236.51it/s]Running 10000 simulations.:  50%|████▉     | 4992/10000 [00:21<00:21, 237.25it/s]Running 10000 simulations.:  50%|█████     | 5017/10000 [00:21<00:20, 238.57it/s]Running 10000 simulations.:  50%|█████     | 5041/10000 [00:21<00:20, 238.82it/s]Running 10000 simulations.:  51%|█████     | 5065/10000 [00:21<00:20, 238.46it/s]Running 10000 simulations.:  51%|█████     | 5089/10000 [00:21<00:20, 238.63it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:22<00:20, 238.45it/s]Running 10000 simulations.:  51%|█████▏    | 5137/10000 [00:22<00:20, 237.49it/s]Running 10000 simulations.:  52%|█████▏    | 5161/10000 [00:22<00:20, 236.15it/s]Running 10000 simulations.:  52%|█████▏    | 5185/10000 [00:22<00:20, 236.50it/s]Running 10000 simulations.:  52%|█████▏    | 5209/10000 [00:22<00:20, 236.44it/s]Running 10000 simulations.:  52%|█████▏    | 5233/10000 [00:22<00:20, 236.65it/s]Running 10000 simulations.:  53%|█████▎    | 5257/10000 [00:22<00:20, 236.23it/s]Running 10000 simulations.:  53%|█████▎    | 5281/10000 [00:22<00:19, 236.59it/s]Running 10000 simulations.:  53%|█████▎    | 5305/10000 [00:22<00:19, 236.79it/s]Running 10000 simulations.:  53%|█████▎    | 5329/10000 [00:22<00:19, 237.36it/s]Running 10000 simulations.:  54%|█████▎    | 5353/10000 [00:23<00:19, 237.60it/s]Running 10000 simulations.:  54%|█████▍    | 5377/10000 [00:23<00:19, 237.77it/s]Running 10000 simulations.:  54%|█████▍    | 5401/10000 [00:23<00:19, 237.96it/s]Running 10000 simulations.:  54%|█████▍    | 5425/10000 [00:23<00:19, 238.26it/s]Running 10000 simulations.:  54%|█████▍    | 5449/10000 [00:23<00:19, 238.16it/s]Running 10000 simulations.:  55%|█████▍    | 5473/10000 [00:23<00:19, 237.71it/s]Running 10000 simulations.:  55%|█████▍    | 5497/10000 [00:23<00:18, 237.22it/s]Running 10000 simulations.:  55%|█████▌    | 5521/10000 [00:23<00:18, 237.67it/s]Running 10000 simulations.:  55%|█████▌    | 5545/10000 [00:23<00:18, 238.00it/s]Running 10000 simulations.:  56%|█████▌    | 5570/10000 [00:23<00:18, 238.90it/s]Running 10000 simulations.:  56%|█████▌    | 5595/10000 [00:24<00:18, 239.44it/s]Running 10000 simulations.:  56%|█████▌    | 5620/10000 [00:24<00:18, 240.35it/s]Running 10000 simulations.:  56%|█████▋    | 5645/10000 [00:24<00:18, 239.42it/s]Running 10000 simulations.:  57%|█████▋    | 5669/10000 [00:24<00:18, 238.54it/s]Running 10000 simulations.:  57%|█████▋    | 5693/10000 [00:24<00:18, 238.25it/s]Running 10000 simulations.:  57%|█████▋    | 5717/10000 [00:24<00:18, 237.82it/s]Running 10000 simulations.:  57%|█████▋    | 5741/10000 [00:24<00:17, 237.40it/s]Running 10000 simulations.:  58%|█████▊    | 5765/10000 [00:24<00:17, 236.97it/s]Running 10000 simulations.:  58%|█████▊    | 5789/10000 [00:24<00:17, 235.36it/s]Running 10000 simulations.:  58%|█████▊    | 5813/10000 [00:24<00:17, 234.45it/s]Running 10000 simulations.:  58%|█████▊    | 5837/10000 [00:25<00:17, 234.95it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:25<00:17, 234.99it/s]Running 10000 simulations.:  59%|█████▉    | 5885/10000 [00:25<00:17, 234.87it/s]Running 10000 simulations.:  59%|█████▉    | 5909/10000 [00:25<00:17, 235.21it/s]Running 10000 simulations.:  59%|█████▉    | 5933/10000 [00:25<00:17, 236.00it/s]Running 10000 simulations.:  60%|█████▉    | 5957/10000 [00:25<00:17, 235.93it/s]Running 10000 simulations.:  60%|█████▉    | 5981/10000 [00:25<00:17, 235.57it/s]Running 10000 simulations.:  60%|██████    | 6005/10000 [00:25<00:16, 235.67it/s]Running 10000 simulations.:  60%|██████    | 6029/10000 [00:25<00:16, 235.55it/s]Running 10000 simulations.:  61%|██████    | 6053/10000 [00:26<00:16, 235.94it/s]Running 10000 simulations.:  61%|██████    | 6077/10000 [00:26<00:16, 234.95it/s]Running 10000 simulations.:  61%|██████    | 6101/10000 [00:26<00:16, 235.79it/s]Running 10000 simulations.:  61%|██████▏   | 6125/10000 [00:26<00:16, 235.22it/s]Running 10000 simulations.:  61%|██████▏   | 6149/10000 [00:26<00:16, 235.15it/s]Running 10000 simulations.:  62%|██████▏   | 6173/10000 [00:26<00:16, 235.30it/s]Running 10000 simulations.:  62%|██████▏   | 6197/10000 [00:26<00:16, 235.16it/s]Running 10000 simulations.:  62%|██████▏   | 6221/10000 [00:26<00:16, 234.83it/s]Running 10000 simulations.:  62%|██████▏   | 6245/10000 [00:26<00:15, 235.28it/s]Running 10000 simulations.:  63%|██████▎   | 6269/10000 [00:26<00:15, 234.57it/s]Running 10000 simulations.:  63%|██████▎   | 6293/10000 [00:27<00:16, 224.58it/s]Running 10000 simulations.:  63%|██████▎   | 6317/10000 [00:27<00:16, 227.18it/s]Running 10000 simulations.:  63%|██████▎   | 6341/10000 [00:27<00:15, 229.09it/s]Running 10000 simulations.:  64%|██████▎   | 6365/10000 [00:27<00:15, 229.62it/s]Running 10000 simulations.:  64%|██████▍   | 6389/10000 [00:27<00:15, 230.59it/s]Running 10000 simulations.:  64%|██████▍   | 6413/10000 [00:27<00:15, 232.53it/s]Running 10000 simulations.:  64%|██████▍   | 6438/10000 [00:27<00:15, 234.92it/s]Running 10000 simulations.:  65%|██████▍   | 6462/10000 [00:27<00:14, 235.95it/s]Running 10000 simulations.:  65%|██████▍   | 6486/10000 [00:27<00:14, 235.89it/s]Running 10000 simulations.:  65%|██████▌   | 6510/10000 [00:27<00:14, 233.68it/s]Running 10000 simulations.:  65%|██████▌   | 6534/10000 [00:28<00:14, 234.02it/s]Running 10000 simulations.:  66%|██████▌   | 6558/10000 [00:28<00:14, 235.31it/s]Running 10000 simulations.:  66%|██████▌   | 6583/10000 [00:28<00:14, 236.76it/s]Running 10000 simulations.:  66%|██████▌   | 6607/10000 [00:28<00:14, 236.79it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:28<00:14, 237.02it/s]Running 10000 simulations.:  67%|██████▋   | 6655/10000 [00:28<00:14, 236.10it/s]Running 10000 simulations.:  67%|██████▋   | 6679/10000 [00:28<00:14, 235.93it/s]Running 10000 simulations.:  67%|██████▋   | 6703/10000 [00:28<00:14, 235.47it/s]Running 10000 simulations.:  67%|██████▋   | 6727/10000 [00:28<00:13, 235.35it/s]Running 10000 simulations.:  68%|██████▊   | 6751/10000 [00:28<00:13, 235.24it/s]Running 10000 simulations.:  68%|██████▊   | 6775/10000 [00:29<00:13, 236.01it/s]Running 10000 simulations.:  68%|██████▊   | 6799/10000 [00:29<00:13, 236.79it/s]Running 10000 simulations.:  68%|██████▊   | 6823/10000 [00:29<00:13, 235.38it/s]Running 10000 simulations.:  68%|██████▊   | 6847/10000 [00:29<00:13, 234.04it/s]Running 10000 simulations.:  69%|██████▊   | 6871/10000 [00:29<00:13, 231.10it/s]Running 10000 simulations.:  69%|██████▉   | 6895/10000 [00:29<00:13, 230.06it/s]Running 10000 simulations.:  69%|██████▉   | 6919/10000 [00:29<00:13, 230.83it/s]Running 10000 simulations.:  69%|██████▉   | 6943/10000 [00:29<00:13, 232.65it/s]Running 10000 simulations.:  70%|██████▉   | 6967/10000 [00:29<00:13, 232.69it/s]Running 10000 simulations.:  70%|██████▉   | 6991/10000 [00:30<00:13, 230.25it/s]Running 10000 simulations.:  70%|███████   | 7015/10000 [00:30<00:12, 229.70it/s]Running 10000 simulations.:  70%|███████   | 7039/10000 [00:30<00:12, 231.12it/s]Running 10000 simulations.:  71%|███████   | 7063/10000 [00:30<00:12, 231.80it/s]Running 10000 simulations.:  71%|███████   | 7087/10000 [00:30<00:12, 232.21it/s]Running 10000 simulations.:  71%|███████   | 7111/10000 [00:30<00:12, 233.01it/s]Running 10000 simulations.:  71%|███████▏  | 7135/10000 [00:30<00:12, 233.64it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:30<00:12, 234.76it/s]Running 10000 simulations.:  72%|███████▏  | 7183/10000 [00:30<00:11, 235.38it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:30<00:11, 235.49it/s]Running 10000 simulations.:  72%|███████▏  | 7231/10000 [00:31<00:11, 236.43it/s]Running 10000 simulations.:  73%|███████▎  | 7255/10000 [00:31<00:11, 236.74it/s]Running 10000 simulations.:  73%|███████▎  | 7279/10000 [00:31<00:11, 236.13it/s]Running 10000 simulations.:  73%|███████▎  | 7303/10000 [00:31<00:11, 236.62it/s]Running 10000 simulations.:  73%|███████▎  | 7327/10000 [00:31<00:11, 237.01it/s]Running 10000 simulations.:  74%|███████▎  | 7351/10000 [00:31<00:11, 236.79it/s]Running 10000 simulations.:  74%|███████▍  | 7375/10000 [00:31<00:11, 236.88it/s]Running 10000 simulations.:  74%|███████▍  | 7399/10000 [00:31<00:10, 237.54it/s]Running 10000 simulations.:  74%|███████▍  | 7423/10000 [00:31<00:10, 237.36it/s]Running 10000 simulations.:  74%|███████▍  | 7447/10000 [00:31<00:10, 237.16it/s]Running 10000 simulations.:  75%|███████▍  | 7471/10000 [00:32<00:10, 236.92it/s]Running 10000 simulations.:  75%|███████▍  | 7495/10000 [00:32<00:10, 235.89it/s]Running 10000 simulations.:  75%|███████▌  | 7519/10000 [00:32<00:10, 235.73it/s]Running 10000 simulations.:  75%|███████▌  | 7543/10000 [00:32<00:10, 236.12it/s]Running 10000 simulations.:  76%|███████▌  | 7567/10000 [00:32<00:10, 233.37it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:32<00:10, 234.78it/s]Running 10000 simulations.:  76%|███████▌  | 7615/10000 [00:32<00:10, 235.72it/s]Running 10000 simulations.:  76%|███████▋  | 7639/10000 [00:32<00:09, 236.31it/s]Running 10000 simulations.:  77%|███████▋  | 7663/10000 [00:32<00:09, 236.67it/s]Running 10000 simulations.:  77%|███████▋  | 7687/10000 [00:32<00:09, 237.34it/s]Running 10000 simulations.:  77%|███████▋  | 7712/10000 [00:33<00:09, 238.79it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:33<00:09, 239.14it/s]Running 10000 simulations.:  78%|███████▊  | 7760/10000 [00:33<00:09, 238.99it/s]Running 10000 simulations.:  78%|███████▊  | 7784/10000 [00:33<00:09, 238.32it/s]Running 10000 simulations.:  78%|███████▊  | 7808/10000 [00:33<00:09, 238.34it/s]Running 10000 simulations.:  78%|███████▊  | 7832/10000 [00:33<00:09, 238.30it/s]Running 10000 simulations.:  79%|███████▊  | 7856/10000 [00:33<00:08, 238.76it/s]Running 10000 simulations.:  79%|███████▉  | 7881/10000 [00:33<00:08, 239.15it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:33<00:08, 238.99it/s]Running 10000 simulations.:  79%|███████▉  | 7929/10000 [00:33<00:08, 237.25it/s]Running 10000 simulations.:  80%|███████▉  | 7953/10000 [00:34<00:08, 237.46it/s]Running 10000 simulations.:  80%|███████▉  | 7977/10000 [00:34<00:08, 237.54it/s]Running 10000 simulations.:  80%|████████  | 8001/10000 [00:34<00:08, 237.68it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:34<00:08, 237.98it/s]Running 10000 simulations.:  80%|████████  | 8049/10000 [00:34<00:08, 237.53it/s]Running 10000 simulations.:  81%|████████  | 8073/10000 [00:34<00:08, 237.66it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:34<00:08, 237.45it/s]Running 10000 simulations.:  81%|████████  | 8121/10000 [00:34<00:07, 237.45it/s]Running 10000 simulations.:  81%|████████▏ | 8145/10000 [00:34<00:07, 237.04it/s]Running 10000 simulations.:  82%|████████▏ | 8169/10000 [00:34<00:07, 236.92it/s]Running 10000 simulations.:  82%|████████▏ | 8193/10000 [00:35<00:07, 236.33it/s]Running 10000 simulations.:  82%|████████▏ | 8217/10000 [00:35<00:07, 236.15it/s]Running 10000 simulations.:  82%|████████▏ | 8241/10000 [00:35<00:07, 235.57it/s]Running 10000 simulations.:  83%|████████▎ | 8265/10000 [00:35<00:11, 146.24it/s]Running 10000 simulations.:  83%|████████▎ | 8289/10000 [00:35<00:10, 164.94it/s]Running 10000 simulations.:  83%|████████▎ | 8313/10000 [00:35<00:09, 181.13it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:35<00:08, 195.13it/s]Running 10000 simulations.:  84%|████████▎ | 8361/10000 [00:36<00:07, 205.92it/s]Running 10000 simulations.:  84%|████████▍ | 8385/10000 [00:36<00:07, 214.62it/s]Running 10000 simulations.:  84%|████████▍ | 8409/10000 [00:36<00:07, 220.61it/s]Running 10000 simulations.:  84%|████████▍ | 8433/10000 [00:36<00:06, 225.43it/s]Running 10000 simulations.:  85%|████████▍ | 8458/10000 [00:36<00:06, 230.16it/s]Running 10000 simulations.:  85%|████████▍ | 8483/10000 [00:36<00:06, 232.99it/s]Running 10000 simulations.:  85%|████████▌ | 8507/10000 [00:36<00:06, 234.53it/s]Running 10000 simulations.:  85%|████████▌ | 8531/10000 [00:36<00:06, 235.57it/s]Running 10000 simulations.:  86%|████████▌ | 8555/10000 [00:36<00:06, 235.65it/s]Running 10000 simulations.:  86%|████████▌ | 8579/10000 [00:36<00:06, 236.71it/s]Running 10000 simulations.:  86%|████████▌ | 8603/10000 [00:37<00:05, 237.57it/s]Running 10000 simulations.:  86%|████████▋ | 8627/10000 [00:37<00:05, 237.04it/s]Running 10000 simulations.:  87%|████████▋ | 8651/10000 [00:37<00:05, 236.70it/s]Running 10000 simulations.:  87%|████████▋ | 8675/10000 [00:37<00:05, 236.42it/s]Running 10000 simulations.:  87%|████████▋ | 8699/10000 [00:37<00:05, 237.45it/s]Running 10000 simulations.:  87%|████████▋ | 8723/10000 [00:37<00:05, 237.86it/s]Running 10000 simulations.:  87%|████████▋ | 8747/10000 [00:37<00:05, 238.23it/s]Running 10000 simulations.:  88%|████████▊ | 8771/10000 [00:37<00:05, 238.02it/s]Running 10000 simulations.:  88%|████████▊ | 8795/10000 [00:37<00:05, 237.34it/s]Running 10000 simulations.:  88%|████████▊ | 8819/10000 [00:37<00:04, 236.95it/s]Running 10000 simulations.:  88%|████████▊ | 8843/10000 [00:38<00:04, 237.34it/s]Running 10000 simulations.:  89%|████████▊ | 8867/10000 [00:38<00:04, 236.69it/s]Running 10000 simulations.:  89%|████████▉ | 8891/10000 [00:38<00:04, 235.90it/s]Running 10000 simulations.:  89%|████████▉ | 8915/10000 [00:38<00:04, 235.56it/s]Running 10000 simulations.:  89%|████████▉ | 8939/10000 [00:38<00:04, 236.36it/s]Running 10000 simulations.:  90%|████████▉ | 8963/10000 [00:38<00:04, 236.60it/s]Running 10000 simulations.:  90%|████████▉ | 8987/10000 [00:38<00:04, 237.28it/s]Running 10000 simulations.:  90%|█████████ | 9011/10000 [00:38<00:04, 236.37it/s]Running 10000 simulations.:  90%|█████████ | 9035/10000 [00:38<00:04, 234.92it/s]Running 10000 simulations.:  91%|█████████ | 9059/10000 [00:38<00:04, 235.23it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [00:39<00:03, 235.47it/s]Running 10000 simulations.:  91%|█████████ | 9107/10000 [00:39<00:03, 235.81it/s]Running 10000 simulations.:  91%|█████████▏| 9131/10000 [00:39<00:03, 235.80it/s]Running 10000 simulations.:  92%|█████████▏| 9155/10000 [00:39<00:03, 235.37it/s]Running 10000 simulations.:  92%|█████████▏| 9179/10000 [00:39<00:03, 234.70it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [00:39<00:03, 234.25it/s]Running 10000 simulations.:  92%|█████████▏| 9227/10000 [00:39<00:03, 234.78it/s]Running 10000 simulations.:  93%|█████████▎| 9251/10000 [00:39<00:03, 234.70it/s]Running 10000 simulations.:  93%|█████████▎| 9275/10000 [00:39<00:03, 234.24it/s]Running 10000 simulations.:  93%|█████████▎| 9299/10000 [00:39<00:02, 234.83it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [00:40<00:02, 234.70it/s]Running 10000 simulations.:  93%|█████████▎| 9347/10000 [00:40<00:02, 235.34it/s]Running 10000 simulations.:  94%|█████████▎| 9371/10000 [00:40<00:02, 234.50it/s]Running 10000 simulations.:  94%|█████████▍| 9395/10000 [00:40<00:02, 234.19it/s]Running 10000 simulations.:  94%|█████████▍| 9419/10000 [00:40<00:02, 235.36it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [00:40<00:02, 235.79it/s]Running 10000 simulations.:  95%|█████████▍| 9467/10000 [00:40<00:02, 235.52it/s]Running 10000 simulations.:  95%|█████████▍| 9491/10000 [00:40<00:02, 235.45it/s]Running 10000 simulations.:  95%|█████████▌| 9515/10000 [00:40<00:02, 235.39it/s]Running 10000 simulations.:  95%|█████████▌| 9539/10000 [00:41<00:01, 235.94it/s]Running 10000 simulations.:  96%|█████████▌| 9563/10000 [00:41<00:01, 236.15it/s]Running 10000 simulations.:  96%|█████████▌| 9587/10000 [00:41<00:01, 236.15it/s]Running 10000 simulations.:  96%|█████████▌| 9611/10000 [00:41<00:01, 236.64it/s]Running 10000 simulations.:  96%|█████████▋| 9635/10000 [00:41<00:01, 235.83it/s]Running 10000 simulations.:  97%|█████████▋| 9659/10000 [00:41<00:01, 235.83it/s]Running 10000 simulations.:  97%|█████████▋| 9683/10000 [00:41<00:01, 236.16it/s]Running 10000 simulations.:  97%|█████████▋| 9707/10000 [00:41<00:01, 235.16it/s]Running 10000 simulations.:  97%|█████████▋| 9731/10000 [00:41<00:01, 235.43it/s]Running 10000 simulations.:  98%|█████████▊| 9755/10000 [00:41<00:01, 235.67it/s]Running 10000 simulations.:  98%|█████████▊| 9779/10000 [00:42<00:00, 236.14it/s]Running 10000 simulations.:  98%|█████████▊| 9803/10000 [00:42<00:00, 235.42it/s]Running 10000 simulations.:  98%|█████████▊| 9827/10000 [00:42<00:00, 235.73it/s]Running 10000 simulations.:  99%|█████████▊| 9851/10000 [00:42<00:00, 236.96it/s]Running 10000 simulations.:  99%|█████████▉| 9875/10000 [00:42<00:00, 237.21it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:42<00:00, 237.49it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [00:42<00:00, 237.77it/s]Running 10000 simulations.:  99%|█████████▉| 9947/10000 [00:42<00:00, 237.70it/s]Running 10000 simulations.: 100%|█████████▉| 9971/10000 [00:42<00:00, 237.17it/s]Running 10000 simulations.: 100%|█████████▉| 9995/10000 [00:42<00:00, 237.01it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 232.81it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 252.23it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<00:39, 251.36it/s]Running 10000 simulations.:   1%|          | 76/10000 [00:00<00:39, 250.84it/s]Running 10000 simulations.:   1%|          | 102/10000 [00:00<00:39, 251.04it/s]Running 10000 simulations.:   1%|▏         | 128/10000 [00:00<00:39, 251.29it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:39, 249.60it/s]Running 10000 simulations.:   2%|▏         | 178/10000 [00:00<00:39, 248.69it/s]Running 10000 simulations.:   2%|▏         | 203/10000 [00:00<00:39, 248.32it/s]Running 10000 simulations.:   2%|▏         | 228/10000 [00:00<00:39, 247.84it/s]Running 10000 simulations.:   3%|▎         | 253/10000 [00:01<00:39, 247.81it/s]Running 10000 simulations.:   3%|▎         | 278/10000 [00:01<00:39, 247.24it/s]Running 10000 simulations.:   3%|▎         | 303/10000 [00:01<00:39, 246.54it/s]Running 10000 simulations.:   3%|▎         | 328/10000 [00:01<00:39, 246.09it/s]Running 10000 simulations.:   4%|▎         | 353/10000 [00:01<00:39, 245.51it/s]Running 10000 simulations.:   4%|▍         | 378/10000 [00:01<00:39, 245.26it/s]Running 10000 simulations.:   4%|▍         | 403/10000 [00:01<00:39, 244.75it/s]Running 10000 simulations.:   4%|▍         | 428/10000 [00:01<00:39, 244.46it/s]Running 10000 simulations.:   5%|▍         | 453/10000 [00:01<00:39, 242.70it/s]Running 10000 simulations.:   5%|▍         | 478/10000 [00:01<00:40, 237.59it/s]Running 10000 simulations.:   5%|▌         | 502/10000 [00:02<00:40, 235.15it/s]Running 10000 simulations.:   5%|▌         | 527/10000 [00:02<00:39, 237.38it/s]Running 10000 simulations.:   6%|▌         | 552/10000 [00:02<00:39, 240.03it/s]Running 10000 simulations.:   6%|▌         | 577/10000 [00:02<00:39, 240.91it/s]Running 10000 simulations.:   6%|▌         | 602/10000 [00:02<00:39, 240.66it/s]Running 10000 simulations.:   6%|▋         | 627/10000 [00:02<00:39, 239.28it/s]Running 10000 simulations.:   7%|▋         | 651/10000 [00:02<00:39, 237.65it/s]Running 10000 simulations.:   7%|▋         | 675/10000 [00:02<00:39, 236.62it/s]Running 10000 simulations.:   7%|▋         | 699/10000 [00:02<00:39, 236.78it/s]Running 10000 simulations.:   7%|▋         | 723/10000 [00:02<00:39, 235.93it/s]Running 10000 simulations.:   7%|▋         | 747/10000 [00:03<00:39, 236.34it/s]Running 10000 simulations.:   8%|▊         | 771/10000 [00:03<00:39, 236.27it/s]Running 10000 simulations.:   8%|▊         | 795/10000 [00:03<00:39, 235.21it/s]Running 10000 simulations.:   8%|▊         | 819/10000 [00:03<00:39, 234.75it/s]Running 10000 simulations.:   8%|▊         | 843/10000 [00:03<00:39, 233.60it/s]Running 10000 simulations.:   9%|▊         | 867/10000 [00:03<00:39, 233.24it/s]Running 10000 simulations.:   9%|▉         | 891/10000 [00:03<00:39, 233.37it/s]Running 10000 simulations.:   9%|▉         | 915/10000 [00:03<00:38, 233.32it/s]Running 10000 simulations.:   9%|▉         | 939/10000 [00:03<00:38, 233.38it/s]Running 10000 simulations.:  10%|▉         | 963/10000 [00:04<00:38, 233.26it/s]Running 10000 simulations.:  10%|▉         | 987/10000 [00:04<00:38, 233.52it/s]Running 10000 simulations.:  10%|█         | 1011/10000 [00:04<00:38, 233.34it/s]Running 10000 simulations.:  10%|█         | 1035/10000 [00:04<00:38, 233.07it/s]Running 10000 simulations.:  11%|█         | 1059/10000 [00:04<00:38, 232.42it/s]Running 10000 simulations.:  11%|█         | 1083/10000 [00:04<00:38, 231.96it/s]Running 10000 simulations.:  11%|█         | 1107/10000 [00:04<00:38, 231.57it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:04<00:38, 231.32it/s]Running 10000 simulations.:  12%|█▏        | 1155/10000 [00:04<00:38, 232.59it/s]Running 10000 simulations.:  12%|█▏        | 1179/10000 [00:04<00:38, 230.34it/s]Running 10000 simulations.:  12%|█▏        | 1203/10000 [00:05<00:38, 229.28it/s]Running 10000 simulations.:  12%|█▏        | 1227/10000 [00:05<00:38, 229.51it/s]Running 10000 simulations.:  13%|█▎        | 1251/10000 [00:05<00:38, 229.81it/s]Running 10000 simulations.:  13%|█▎        | 1274/10000 [00:05<00:38, 229.41it/s]Running 10000 simulations.:  13%|█▎        | 1298/10000 [00:05<00:37, 229.61it/s]Running 10000 simulations.:  13%|█▎        | 1322/10000 [00:05<00:37, 229.72it/s]Running 10000 simulations.:  13%|█▎        | 1346/10000 [00:05<00:37, 229.89it/s]Running 10000 simulations.:  14%|█▎        | 1370/10000 [00:05<00:37, 230.86it/s]Running 10000 simulations.:  14%|█▍        | 1394/10000 [00:05<00:37, 230.63it/s]Running 10000 simulations.:  14%|█▍        | 1418/10000 [00:05<00:37, 230.04it/s]Running 10000 simulations.:  14%|█▍        | 1442/10000 [00:06<00:37, 229.64it/s]Running 10000 simulations.:  15%|█▍        | 1465/10000 [00:06<00:37, 229.70it/s]Running 10000 simulations.:  15%|█▍        | 1489/10000 [00:06<00:36, 230.03it/s]Running 10000 simulations.:  15%|█▌        | 1513/10000 [00:06<00:36, 230.38it/s]Running 10000 simulations.:  15%|█▌        | 1537/10000 [00:06<00:36, 230.33it/s]Running 10000 simulations.:  16%|█▌        | 1561/10000 [00:06<00:36, 229.55it/s]Running 10000 simulations.:  16%|█▌        | 1584/10000 [00:06<00:36, 229.62it/s]Running 10000 simulations.:  16%|█▌        | 1608/10000 [00:06<00:36, 230.50it/s]Running 10000 simulations.:  16%|█▋        | 1632/10000 [00:06<00:36, 231.08it/s]Running 10000 simulations.:  17%|█▋        | 1656/10000 [00:07<00:35, 231.82it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:07<00:35, 231.77it/s]Running 10000 simulations.:  17%|█▋        | 1704/10000 [00:07<00:35, 231.90it/s]Running 10000 simulations.:  17%|█▋        | 1728/10000 [00:07<00:35, 231.54it/s]Running 10000 simulations.:  18%|█▊        | 1752/10000 [00:07<00:35, 230.20it/s]Running 10000 simulations.:  18%|█▊        | 1776/10000 [00:07<00:36, 225.49it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:07<00:36, 226.65it/s]Running 10000 simulations.:  18%|█▊        | 1822/10000 [00:07<00:36, 226.99it/s]Running 10000 simulations.:  18%|█▊        | 1846/10000 [00:07<00:35, 228.63it/s]Running 10000 simulations.:  19%|█▊        | 1870/10000 [00:07<00:35, 229.07it/s]Running 10000 simulations.:  19%|█▉        | 1894/10000 [00:08<00:35, 229.56it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:08<00:35, 229.81it/s]Running 10000 simulations.:  19%|█▉        | 1942/10000 [00:08<00:35, 229.96it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:08<00:34, 229.79it/s]Running 10000 simulations.:  20%|█▉        | 1988/10000 [00:08<00:35, 228.71it/s]Running 10000 simulations.:  20%|██        | 2012/10000 [00:08<00:34, 229.24it/s]Running 10000 simulations.:  20%|██        | 2035/10000 [00:08<00:34, 228.60it/s]Running 10000 simulations.:  21%|██        | 2058/10000 [00:08<00:34, 227.74it/s]Running 10000 simulations.:  21%|██        | 2081/10000 [00:08<00:34, 227.64it/s]Running 10000 simulations.:  21%|██        | 2104/10000 [00:08<00:34, 227.31it/s]Running 10000 simulations.:  21%|██▏       | 2127/10000 [00:09<00:34, 227.70it/s]Running 10000 simulations.:  22%|██▏       | 2150/10000 [00:09<00:34, 228.14it/s]Running 10000 simulations.:  22%|██▏       | 2173/10000 [00:09<00:34, 228.38it/s]Running 10000 simulations.:  22%|██▏       | 2197/10000 [00:09<00:34, 229.03it/s]Running 10000 simulations.:  22%|██▏       | 2221/10000 [00:09<00:33, 229.64it/s]Running 10000 simulations.:  22%|██▏       | 2244/10000 [00:09<00:33, 228.78it/s]Running 10000 simulations.:  23%|██▎       | 2267/10000 [00:09<00:33, 228.89it/s]Running 10000 simulations.:  23%|██▎       | 2290/10000 [00:09<00:33, 228.76it/s]Running 10000 simulations.:  23%|██▎       | 2313/10000 [00:09<00:33, 228.53it/s]Running 10000 simulations.:  23%|██▎       | 2337/10000 [00:09<00:33, 231.03it/s]Running 10000 simulations.:  24%|██▎       | 2361/10000 [00:10<00:32, 232.59it/s]Running 10000 simulations.:  24%|██▍       | 2385/10000 [00:10<00:32, 233.86it/s]Running 10000 simulations.:  24%|██▍       | 2409/10000 [00:10<00:32, 235.37it/s]Running 10000 simulations.:  24%|██▍       | 2433/10000 [00:10<00:32, 236.03it/s]Running 10000 simulations.:  25%|██▍       | 2457/10000 [00:10<00:31, 236.14it/s]Running 10000 simulations.:  25%|██▍       | 2481/10000 [00:10<00:31, 235.62it/s]Running 10000 simulations.:  25%|██▌       | 2505/10000 [00:10<00:31, 236.27it/s]Running 10000 simulations.:  25%|██▌       | 2529/10000 [00:10<00:31, 235.46it/s]Running 10000 simulations.:  26%|██▌       | 2553/10000 [00:10<00:31, 235.62it/s]Running 10000 simulations.:  26%|██▌       | 2577/10000 [00:11<00:31, 235.53it/s]Running 10000 simulations.:  26%|██▌       | 2601/10000 [00:11<00:31, 235.93it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:11<00:31, 236.24it/s]Running 10000 simulations.:  26%|██▋       | 2649/10000 [00:11<00:31, 234.80it/s]Running 10000 simulations.:  27%|██▋       | 2673/10000 [00:11<00:31, 234.44it/s]Running 10000 simulations.:  27%|██▋       | 2697/10000 [00:11<00:31, 234.02it/s]Running 10000 simulations.:  27%|██▋       | 2721/10000 [00:11<00:31, 234.70it/s]Running 10000 simulations.:  27%|██▋       | 2745/10000 [00:11<00:30, 235.88it/s]Running 10000 simulations.:  28%|██▊       | 2769/10000 [00:11<00:30, 235.72it/s]Running 10000 simulations.:  28%|██▊       | 2793/10000 [00:11<00:30, 236.45it/s]Running 10000 simulations.:  28%|██▊       | 2817/10000 [00:12<00:30, 235.65it/s]Running 10000 simulations.:  28%|██▊       | 2841/10000 [00:12<00:30, 236.32it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:12<00:30, 237.43it/s]Running 10000 simulations.:  29%|██▉       | 2891/10000 [00:12<00:29, 238.22it/s]Running 10000 simulations.:  29%|██▉       | 2915/10000 [00:12<00:29, 238.27it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:12<00:29, 239.25it/s]Running 10000 simulations.:  30%|██▉       | 2964/10000 [00:12<00:29, 238.54it/s]Running 10000 simulations.:  30%|██▉       | 2988/10000 [00:12<00:29, 237.57it/s]Running 10000 simulations.:  30%|███       | 3012/10000 [00:12<00:29, 237.04it/s]Running 10000 simulations.:  30%|███       | 3036/10000 [00:12<00:29, 236.54it/s]Running 10000 simulations.:  31%|███       | 3061/10000 [00:13<00:29, 237.84it/s]Running 10000 simulations.:  31%|███       | 3085/10000 [00:13<00:29, 237.70it/s]Running 10000 simulations.:  31%|███       | 3110/10000 [00:13<00:28, 238.72it/s]Running 10000 simulations.:  31%|███▏      | 3134/10000 [00:13<00:28, 238.72it/s]Running 10000 simulations.:  32%|███▏      | 3158/10000 [00:13<00:28, 238.98it/s]Running 10000 simulations.:  32%|███▏      | 3182/10000 [00:13<00:28, 238.90it/s]Running 10000 simulations.:  32%|███▏      | 3206/10000 [00:13<00:28, 238.94it/s]Running 10000 simulations.:  32%|███▏      | 3231/10000 [00:13<00:28, 239.48it/s]Running 10000 simulations.:  33%|███▎      | 3255/10000 [00:13<00:28, 238.63it/s]Running 10000 simulations.:  33%|███▎      | 3279/10000 [00:13<00:28, 238.96it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:14<00:28, 238.60it/s]Running 10000 simulations.:  33%|███▎      | 3327/10000 [00:14<00:27, 238.99it/s]Running 10000 simulations.:  34%|███▎      | 3352/10000 [00:14<00:27, 239.47it/s]Running 10000 simulations.:  34%|███▍      | 3376/10000 [00:14<00:27, 239.55it/s]Running 10000 simulations.:  34%|███▍      | 3400/10000 [00:14<00:27, 239.42it/s]Running 10000 simulations.:  34%|███▍      | 3425/10000 [00:14<00:27, 239.65it/s]Running 10000 simulations.:  34%|███▍      | 3449/10000 [00:14<00:27, 239.42it/s]Running 10000 simulations.:  35%|███▍      | 3473/10000 [00:14<00:27, 238.96it/s]Running 10000 simulations.:  35%|███▍      | 3497/10000 [00:14<00:27, 239.01it/s]Running 10000 simulations.:  35%|███▌      | 3522/10000 [00:14<00:27, 239.50it/s]Running 10000 simulations.:  35%|███▌      | 3546/10000 [00:15<00:26, 239.30it/s]Running 10000 simulations.:  36%|███▌      | 3571/10000 [00:15<00:26, 239.77it/s]Running 10000 simulations.:  36%|███▌      | 3595/10000 [00:15<00:26, 239.24it/s]Running 10000 simulations.:  36%|███▌      | 3619/10000 [00:15<00:28, 226.87it/s]Running 10000 simulations.:  36%|███▋      | 3643/10000 [00:15<00:27, 230.63it/s]Running 10000 simulations.:  37%|███▋      | 3667/10000 [00:15<00:27, 232.54it/s]Running 10000 simulations.:  37%|███▋      | 3691/10000 [00:15<00:27, 233.39it/s]Running 10000 simulations.:  37%|███▋      | 3715/10000 [00:15<00:26, 234.57it/s]Running 10000 simulations.:  37%|███▋      | 3739/10000 [00:15<00:26, 235.99it/s]Running 10000 simulations.:  38%|███▊      | 3763/10000 [00:16<00:26, 236.13it/s]Running 10000 simulations.:  38%|███▊      | 3787/10000 [00:16<00:26, 235.88it/s]Running 10000 simulations.:  38%|███▊      | 3811/10000 [00:16<00:26, 236.03it/s]Running 10000 simulations.:  38%|███▊      | 3835/10000 [00:16<00:26, 236.90it/s]Running 10000 simulations.:  39%|███▊      | 3859/10000 [00:16<00:26, 236.13it/s]Running 10000 simulations.:  39%|███▉      | 3883/10000 [00:16<00:26, 233.65it/s]Running 10000 simulations.:  39%|███▉      | 3907/10000 [00:16<00:26, 233.18it/s]Running 10000 simulations.:  39%|███▉      | 3931/10000 [00:16<00:25, 234.25it/s]Running 10000 simulations.:  40%|███▉      | 3955/10000 [00:16<00:25, 235.23it/s]Running 10000 simulations.:  40%|███▉      | 3979/10000 [00:16<00:25, 235.91it/s]Running 10000 simulations.:  40%|████      | 4003/10000 [00:17<00:25, 237.05it/s]Running 10000 simulations.:  40%|████      | 4027/10000 [00:17<00:25, 237.69it/s]Running 10000 simulations.:  41%|████      | 4051/10000 [00:17<00:25, 237.54it/s]Running 10000 simulations.:  41%|████      | 4075/10000 [00:17<00:25, 236.87it/s]Running 10000 simulations.:  41%|████      | 4099/10000 [00:17<00:24, 236.43it/s]Running 10000 simulations.:  41%|████      | 4123/10000 [00:17<00:24, 236.70it/s]Running 10000 simulations.:  41%|████▏     | 4147/10000 [00:17<00:24, 236.48it/s]Running 10000 simulations.:  42%|████▏     | 4171/10000 [00:17<00:24, 237.31it/s]Running 10000 simulations.:  42%|████▏     | 4195/10000 [00:17<00:24, 237.37it/s]Running 10000 simulations.:  42%|████▏     | 4219/10000 [00:17<00:24, 237.52it/s]Running 10000 simulations.:  42%|████▏     | 4243/10000 [00:18<00:24, 237.95it/s]Running 10000 simulations.:  43%|████▎     | 4267/10000 [00:18<00:24, 238.54it/s]Running 10000 simulations.:  43%|████▎     | 4292/10000 [00:18<00:23, 239.45it/s]Running 10000 simulations.:  43%|████▎     | 4316/10000 [00:18<00:23, 239.41it/s]Running 10000 simulations.:  43%|████▎     | 4341/10000 [00:18<00:23, 240.46it/s]Running 10000 simulations.:  44%|████▎     | 4366/10000 [00:18<00:23, 240.32it/s]Running 10000 simulations.:  44%|████▍     | 4391/10000 [00:18<00:23, 239.64it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:18<00:23, 239.44it/s]Running 10000 simulations.:  44%|████▍     | 4439/10000 [00:18<00:23, 239.31it/s]Running 10000 simulations.:  45%|████▍     | 4464/10000 [00:18<00:23, 240.04it/s]Running 10000 simulations.:  45%|████▍     | 4489/10000 [00:19<00:22, 239.73it/s]Running 10000 simulations.:  45%|████▌     | 4513/10000 [00:19<00:22, 239.63it/s]Running 10000 simulations.:  45%|████▌     | 4537/10000 [00:19<00:22, 238.33it/s]Running 10000 simulations.:  46%|████▌     | 4561/10000 [00:19<00:22, 237.58it/s]Running 10000 simulations.:  46%|████▌     | 4585/10000 [00:19<00:22, 237.39it/s]Running 10000 simulations.:  46%|████▌     | 4609/10000 [00:19<00:22, 236.86it/s]Running 10000 simulations.:  46%|████▋     | 4633/10000 [00:19<00:22, 237.63it/s]Running 10000 simulations.:  47%|████▋     | 4657/10000 [00:19<00:22, 238.08it/s]Running 10000 simulations.:  47%|████▋     | 4681/10000 [00:19<00:22, 238.29it/s]Running 10000 simulations.:  47%|████▋     | 4705/10000 [00:19<00:22, 238.45it/s]Running 10000 simulations.:  47%|████▋     | 4729/10000 [00:20<00:22, 237.58it/s]Running 10000 simulations.:  48%|████▊     | 4753/10000 [00:20<00:22, 237.57it/s]Running 10000 simulations.:  48%|████▊     | 4777/10000 [00:20<00:22, 236.90it/s]Running 10000 simulations.:  48%|████▊     | 4801/10000 [00:20<00:21, 236.63it/s]Running 10000 simulations.:  48%|████▊     | 4825/10000 [00:20<00:21, 236.54it/s]Running 10000 simulations.:  48%|████▊     | 4849/10000 [00:20<00:21, 236.81it/s]Running 10000 simulations.:  49%|████▊     | 4873/10000 [00:20<00:21, 236.75it/s]Running 10000 simulations.:  49%|████▉     | 4897/10000 [00:20<00:21, 236.76it/s]Running 10000 simulations.:  49%|████▉     | 4922/10000 [00:20<00:21, 237.90it/s]Running 10000 simulations.:  49%|████▉     | 4947/10000 [00:20<00:21, 238.73it/s]Running 10000 simulations.:  50%|████▉     | 4972/10000 [00:21<00:20, 239.70it/s]Running 10000 simulations.:  50%|████▉     | 4997/10000 [00:21<00:20, 239.85it/s]Running 10000 simulations.:  50%|█████     | 5021/10000 [00:21<00:20, 239.68it/s]Running 10000 simulations.:  50%|█████     | 5045/10000 [00:21<00:20, 239.13it/s]Running 10000 simulations.:  51%|█████     | 5069/10000 [00:21<00:20, 239.28it/s]Running 10000 simulations.:  51%|█████     | 5093/10000 [00:21<00:20, 238.93it/s]Running 10000 simulations.:  51%|█████     | 5117/10000 [00:21<00:20, 236.12it/s]Running 10000 simulations.:  51%|█████▏    | 5141/10000 [00:21<00:20, 234.88it/s]Running 10000 simulations.:  52%|█████▏    | 5165/10000 [00:21<00:20, 235.72it/s]Running 10000 simulations.:  52%|█████▏    | 5189/10000 [00:22<00:20, 236.25it/s]Running 10000 simulations.:  52%|█████▏    | 5214/10000 [00:22<00:20, 237.45it/s]Running 10000 simulations.:  52%|█████▏    | 5239/10000 [00:22<00:19, 238.21it/s]Running 10000 simulations.:  53%|█████▎    | 5263/10000 [00:22<00:19, 238.41it/s]Running 10000 simulations.:  53%|█████▎    | 5287/10000 [00:22<00:19, 238.02it/s]Running 10000 simulations.:  53%|█████▎    | 5311/10000 [00:22<00:19, 238.04it/s]Running 10000 simulations.:  53%|█████▎    | 5335/10000 [00:22<00:19, 237.83it/s]Running 10000 simulations.:  54%|█████▎    | 5359/10000 [00:22<00:19, 238.17it/s]Running 10000 simulations.:  54%|█████▍    | 5384/10000 [00:22<00:19, 239.13it/s]Running 10000 simulations.:  54%|█████▍    | 5408/10000 [00:22<00:19, 239.09it/s]Running 10000 simulations.:  54%|█████▍    | 5432/10000 [00:23<00:19, 238.37it/s]Running 10000 simulations.:  55%|█████▍    | 5456/10000 [00:23<00:19, 235.98it/s]Running 10000 simulations.:  55%|█████▍    | 5480/10000 [00:23<00:19, 235.98it/s]Running 10000 simulations.:  55%|█████▌    | 5504/10000 [00:23<00:19, 236.03it/s]Running 10000 simulations.:  55%|█████▌    | 5528/10000 [00:23<00:18, 237.18it/s]Running 10000 simulations.:  56%|█████▌    | 5552/10000 [00:23<00:18, 234.17it/s]Running 10000 simulations.:  56%|█████▌    | 5576/10000 [00:23<00:18, 232.90it/s]Running 10000 simulations.:  56%|█████▌    | 5600/10000 [00:23<00:18, 234.09it/s]Running 10000 simulations.:  56%|█████▌    | 5624/10000 [00:23<00:18, 235.20it/s]Running 10000 simulations.:  56%|█████▋    | 5648/10000 [00:23<00:18, 235.70it/s]Running 10000 simulations.:  57%|█████▋    | 5672/10000 [00:24<00:18, 236.28it/s]Running 10000 simulations.:  57%|█████▋    | 5696/10000 [00:24<00:18, 236.85it/s]Running 10000 simulations.:  57%|█████▋    | 5720/10000 [00:24<00:18, 236.81it/s]Running 10000 simulations.:  57%|█████▋    | 5744/10000 [00:24<00:17, 237.23it/s]Running 10000 simulations.:  58%|█████▊    | 5769/10000 [00:24<00:17, 238.31it/s]Running 10000 simulations.:  58%|█████▊    | 5793/10000 [00:24<00:17, 237.98it/s]Running 10000 simulations.:  58%|█████▊    | 5817/10000 [00:24<00:17, 237.00it/s]Running 10000 simulations.:  58%|█████▊    | 5841/10000 [00:24<00:17, 236.89it/s]Running 10000 simulations.:  59%|█████▊    | 5865/10000 [00:24<00:17, 237.28it/s]Running 10000 simulations.:  59%|█████▉    | 5889/10000 [00:24<00:17, 237.98it/s]Running 10000 simulations.:  59%|█████▉    | 5914/10000 [00:25<00:17, 238.80it/s]Running 10000 simulations.:  59%|█████▉    | 5938/10000 [00:25<00:17, 238.65it/s]Running 10000 simulations.:  60%|█████▉    | 5962/10000 [00:25<00:16, 237.61it/s]Running 10000 simulations.:  60%|█████▉    | 5986/10000 [00:25<00:17, 234.69it/s]Running 10000 simulations.:  60%|██████    | 6010/10000 [00:25<00:16, 235.37it/s]Running 10000 simulations.:  60%|██████    | 6035/10000 [00:25<00:16, 236.93it/s]Running 10000 simulations.:  61%|██████    | 6060/10000 [00:25<00:16, 237.85it/s]Running 10000 simulations.:  61%|██████    | 6085/10000 [00:25<00:16, 238.97it/s]Running 10000 simulations.:  61%|██████    | 6109/10000 [00:25<00:16, 238.61it/s]Running 10000 simulations.:  61%|██████▏   | 6134/10000 [00:25<00:16, 239.37it/s]Running 10000 simulations.:  62%|██████▏   | 6159/10000 [00:26<00:15, 240.46it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:26<00:15, 240.98it/s]Running 10000 simulations.:  62%|██████▏   | 6209/10000 [00:26<00:15, 240.30it/s]Running 10000 simulations.:  62%|██████▏   | 6234/10000 [00:26<00:15, 239.95it/s]Running 10000 simulations.:  63%|██████▎   | 6258/10000 [00:26<00:15, 239.61it/s]Running 10000 simulations.:  63%|██████▎   | 6283/10000 [00:26<00:15, 240.09it/s]Running 10000 simulations.:  63%|██████▎   | 6308/10000 [00:26<00:15, 239.06it/s]Running 10000 simulations.:  63%|██████▎   | 6332/10000 [00:26<00:15, 239.03it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:26<00:15, 238.99it/s]Running 10000 simulations.:  64%|██████▍   | 6380/10000 [00:27<00:15, 239.15it/s]Running 10000 simulations.:  64%|██████▍   | 6404/10000 [00:27<00:15, 238.45it/s]Running 10000 simulations.:  64%|██████▍   | 6428/10000 [00:27<00:15, 237.65it/s]Running 10000 simulations.:  65%|██████▍   | 6452/10000 [00:27<00:14, 238.22it/s]Running 10000 simulations.:  65%|██████▍   | 6476/10000 [00:27<00:14, 238.51it/s]Running 10000 simulations.:  65%|██████▌   | 6500/10000 [00:27<00:14, 238.71it/s]Running 10000 simulations.:  65%|██████▌   | 6524/10000 [00:27<00:14, 238.94it/s]Running 10000 simulations.:  65%|██████▌   | 6548/10000 [00:27<00:14, 237.27it/s]Running 10000 simulations.:  66%|██████▌   | 6572/10000 [00:27<00:14, 236.60it/s]Running 10000 simulations.:  66%|██████▌   | 6596/10000 [00:27<00:14, 236.34it/s]Running 10000 simulations.:  66%|██████▌   | 6620/10000 [00:28<00:14, 236.70it/s]Running 10000 simulations.:  66%|██████▋   | 6644/10000 [00:28<00:14, 234.70it/s]Running 10000 simulations.:  67%|██████▋   | 6668/10000 [00:28<00:14, 232.46it/s]Running 10000 simulations.:  67%|██████▋   | 6692/10000 [00:28<00:14, 231.37it/s]Running 10000 simulations.:  67%|██████▋   | 6716/10000 [00:28<00:14, 231.79it/s]Running 10000 simulations.:  67%|██████▋   | 6740/10000 [00:28<00:14, 230.64it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:28<00:14, 230.37it/s]Running 10000 simulations.:  68%|██████▊   | 6788/10000 [00:28<00:14, 228.96it/s]Running 10000 simulations.:  68%|██████▊   | 6811/10000 [00:28<00:13, 228.49it/s]Running 10000 simulations.:  68%|██████▊   | 6834/10000 [00:28<00:13, 228.35it/s]Running 10000 simulations.:  69%|██████▊   | 6857/10000 [00:29<00:13, 228.50it/s]Running 10000 simulations.:  69%|██████▉   | 6880/10000 [00:29<00:13, 227.41it/s]Running 10000 simulations.:  69%|██████▉   | 6903/10000 [00:29<00:13, 226.88it/s]Running 10000 simulations.:  69%|██████▉   | 6926/10000 [00:29<00:13, 226.88it/s]Running 10000 simulations.:  69%|██████▉   | 6949/10000 [00:29<00:13, 225.51it/s]Running 10000 simulations.:  70%|██████▉   | 6972/10000 [00:29<00:13, 222.40it/s]Running 10000 simulations.:  70%|██████▉   | 6995/10000 [00:29<00:13, 221.36it/s]Running 10000 simulations.:  70%|███████   | 7018/10000 [00:29<00:13, 222.05it/s]Running 10000 simulations.:  70%|███████   | 7041/10000 [00:29<00:13, 222.26it/s]Running 10000 simulations.:  71%|███████   | 7064/10000 [00:29<00:13, 222.28it/s]Running 10000 simulations.:  71%|███████   | 7087/10000 [00:30<00:13, 222.00it/s]Running 10000 simulations.:  71%|███████   | 7110/10000 [00:30<00:13, 221.55it/s]Running 10000 simulations.:  71%|███████▏  | 7133/10000 [00:30<00:12, 222.85it/s]Running 10000 simulations.:  72%|███████▏  | 7156/10000 [00:30<00:12, 223.47it/s]Running 10000 simulations.:  72%|███████▏  | 7179/10000 [00:30<00:12, 223.45it/s]Running 10000 simulations.:  72%|███████▏  | 7202/10000 [00:30<00:12, 224.10it/s]Running 10000 simulations.:  72%|███████▏  | 7225/10000 [00:30<00:12, 224.51it/s]Running 10000 simulations.:  72%|███████▏  | 7248/10000 [00:30<00:12, 224.31it/s]Running 10000 simulations.:  73%|███████▎  | 7271/10000 [00:30<00:12, 224.26it/s]Running 10000 simulations.:  73%|███████▎  | 7294/10000 [00:31<00:12, 224.83it/s]Running 10000 simulations.:  73%|███████▎  | 7317/10000 [00:31<00:11, 225.34it/s]Running 10000 simulations.:  73%|███████▎  | 7340/10000 [00:31<00:11, 224.92it/s]Running 10000 simulations.:  74%|███████▎  | 7363/10000 [00:31<00:11, 224.69it/s]Running 10000 simulations.:  74%|███████▍  | 7386/10000 [00:31<00:11, 224.83it/s]Running 10000 simulations.:  74%|███████▍  | 7409/10000 [00:31<00:11, 225.76it/s]Running 10000 simulations.:  74%|███████▍  | 7432/10000 [00:31<00:11, 225.55it/s]Running 10000 simulations.:  75%|███████▍  | 7455/10000 [00:31<00:11, 226.61it/s]Running 10000 simulations.:  75%|███████▍  | 7479/10000 [00:31<00:11, 227.89it/s]Running 10000 simulations.:  75%|███████▌  | 7502/10000 [00:31<00:11, 225.35it/s]Running 10000 simulations.:  75%|███████▌  | 7525/10000 [00:32<00:11, 224.75it/s]Running 10000 simulations.:  75%|███████▌  | 7548/10000 [00:32<00:11, 222.37it/s]Running 10000 simulations.:  76%|███████▌  | 7571/10000 [00:32<00:10, 221.29it/s]Running 10000 simulations.:  76%|███████▌  | 7594/10000 [00:32<00:10, 219.78it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:32<00:10, 219.07it/s]Running 10000 simulations.:  76%|███████▋  | 7638/10000 [00:32<00:10, 219.27it/s]Running 10000 simulations.:  77%|███████▋  | 7660/10000 [00:32<00:10, 218.27it/s]Running 10000 simulations.:  77%|███████▋  | 7683/10000 [00:32<00:10, 219.99it/s]Running 10000 simulations.:  77%|███████▋  | 7706/10000 [00:32<00:10, 221.32it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:32<00:10, 222.93it/s]Running 10000 simulations.:  78%|███████▊  | 7752/10000 [00:33<00:10, 223.47it/s]Running 10000 simulations.:  78%|███████▊  | 7775/10000 [00:33<00:09, 223.55it/s]Running 10000 simulations.:  78%|███████▊  | 7798/10000 [00:33<00:09, 223.27it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:33<00:09, 223.87it/s]Running 10000 simulations.:  78%|███████▊  | 7844/10000 [00:33<00:09, 224.75it/s]Running 10000 simulations.:  79%|███████▊  | 7867/10000 [00:33<00:09, 225.08it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:33<00:09, 225.42it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:33<00:09, 226.51it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:33<00:09, 226.54it/s]Running 10000 simulations.:  80%|███████▉  | 7959/10000 [00:33<00:08, 227.13it/s]Running 10000 simulations.:  80%|███████▉  | 7982/10000 [00:34<00:08, 227.27it/s]Running 10000 simulations.:  80%|████████  | 8005/10000 [00:34<00:08, 227.55it/s]Running 10000 simulations.:  80%|████████  | 8028/10000 [00:34<00:08, 227.80it/s]Running 10000 simulations.:  81%|████████  | 8051/10000 [00:34<00:08, 227.55it/s]Running 10000 simulations.:  81%|████████  | 8074/10000 [00:34<00:08, 227.80it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:34<00:08, 227.60it/s]Running 10000 simulations.:  81%|████████  | 8120/10000 [00:34<00:08, 228.18it/s]Running 10000 simulations.:  81%|████████▏ | 8143/10000 [00:34<00:08, 228.66it/s]Running 10000 simulations.:  82%|████████▏ | 8166/10000 [00:34<00:08, 228.17it/s]Running 10000 simulations.:  82%|████████▏ | 8189/10000 [00:34<00:07, 227.22it/s]Running 10000 simulations.:  82%|████████▏ | 8212/10000 [00:35<00:07, 227.08it/s]Running 10000 simulations.:  82%|████████▏ | 8235/10000 [00:35<00:07, 227.40it/s]Running 10000 simulations.:  83%|████████▎ | 8258/10000 [00:35<00:07, 227.94it/s]Running 10000 simulations.:  83%|████████▎ | 8281/10000 [00:35<00:07, 228.46it/s]Running 10000 simulations.:  83%|████████▎ | 8305/10000 [00:35<00:07, 230.89it/s]Running 10000 simulations.:  83%|████████▎ | 8329/10000 [00:35<00:07, 231.19it/s]Running 10000 simulations.:  84%|████████▎ | 8353/10000 [00:35<00:07, 230.57it/s]Running 10000 simulations.:  84%|████████▍ | 8377/10000 [00:35<00:07, 230.18it/s]Running 10000 simulations.:  84%|████████▍ | 8401/10000 [00:35<00:06, 229.09it/s]Running 10000 simulations.:  84%|████████▍ | 8424/10000 [00:36<00:06, 228.48it/s]Running 10000 simulations.:  84%|████████▍ | 8447/10000 [00:36<00:06, 228.64it/s]Running 10000 simulations.:  85%|████████▍ | 8471/10000 [00:36<00:06, 229.39it/s]Running 10000 simulations.:  85%|████████▍ | 8494/10000 [00:36<00:06, 228.18it/s]Running 10000 simulations.:  85%|████████▌ | 8517/10000 [00:36<00:06, 228.38it/s]Running 10000 simulations.:  85%|████████▌ | 8540/10000 [00:36<00:06, 228.76it/s]Running 10000 simulations.:  86%|████████▌ | 8563/10000 [00:36<00:06, 226.43it/s]Running 10000 simulations.:  86%|████████▌ | 8586/10000 [00:36<00:06, 224.36it/s]Running 10000 simulations.:  86%|████████▌ | 8609/10000 [00:36<00:06, 224.35it/s]Running 10000 simulations.:  86%|████████▋ | 8632/10000 [00:36<00:06, 224.37it/s]Running 10000 simulations.:  87%|████████▋ | 8655/10000 [00:37<00:05, 224.26it/s]Running 10000 simulations.:  87%|████████▋ | 8678/10000 [00:37<00:05, 224.68it/s]Running 10000 simulations.:  87%|████████▋ | 8701/10000 [00:37<00:05, 224.28it/s]Running 10000 simulations.:  87%|████████▋ | 8724/10000 [00:37<00:05, 223.46it/s]Running 10000 simulations.:  87%|████████▋ | 8747/10000 [00:37<00:05, 222.81it/s]Running 10000 simulations.:  88%|████████▊ | 8770/10000 [00:37<00:05, 223.08it/s]Running 10000 simulations.:  88%|████████▊ | 8793/10000 [00:37<00:05, 223.21it/s]Running 10000 simulations.:  88%|████████▊ | 8816/10000 [00:37<00:05, 222.88it/s]Running 10000 simulations.:  88%|████████▊ | 8839/10000 [00:37<00:05, 223.25it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [00:37<00:05, 223.73it/s]Running 10000 simulations.:  89%|████████▉ | 8885/10000 [00:38<00:04, 223.45it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:38<00:04, 223.08it/s]Running 10000 simulations.:  89%|████████▉ | 8931/10000 [00:38<00:04, 221.67it/s]Running 10000 simulations.:  90%|████████▉ | 8954/10000 [00:38<00:04, 219.72it/s]Running 10000 simulations.:  90%|████████▉ | 8976/10000 [00:38<00:04, 219.10it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:38<00:04, 218.46it/s]Running 10000 simulations.:  90%|█████████ | 9020/10000 [00:38<00:04, 217.59it/s]Running 10000 simulations.:  90%|█████████ | 9042/10000 [00:38<00:04, 217.79it/s]Running 10000 simulations.:  91%|█████████ | 9065/10000 [00:38<00:04, 218.89it/s]Running 10000 simulations.:  91%|█████████ | 9088/10000 [00:39<00:04, 219.17it/s]Running 10000 simulations.:  91%|█████████ | 9110/10000 [00:39<00:04, 218.02it/s]Running 10000 simulations.:  91%|█████████▏| 9132/10000 [00:39<00:03, 217.57it/s]Running 10000 simulations.:  92%|█████████▏| 9154/10000 [00:39<00:03, 217.50it/s]Running 10000 simulations.:  92%|█████████▏| 9176/10000 [00:39<00:03, 218.20it/s]Running 10000 simulations.:  92%|█████████▏| 9198/10000 [00:39<00:03, 218.39it/s]Running 10000 simulations.:  92%|█████████▏| 9220/10000 [00:39<00:03, 218.48it/s]Running 10000 simulations.:  92%|█████████▏| 9243/10000 [00:39<00:03, 218.91it/s]Running 10000 simulations.:  93%|█████████▎| 9265/10000 [00:39<00:03, 218.70it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [00:39<00:03, 218.32it/s]Running 10000 simulations.:  93%|█████████▎| 9309/10000 [00:40<00:03, 218.57it/s]Running 10000 simulations.:  93%|█████████▎| 9331/10000 [00:40<00:03, 218.50it/s]Running 10000 simulations.:  94%|█████████▎| 9353/10000 [00:40<00:02, 218.01it/s]Running 10000 simulations.:  94%|█████████▍| 9375/10000 [00:40<00:02, 218.17it/s]Running 10000 simulations.:  94%|█████████▍| 9397/10000 [00:40<00:02, 217.92it/s]Running 10000 simulations.:  94%|█████████▍| 9419/10000 [00:40<00:02, 217.59it/s]Running 10000 simulations.:  94%|█████████▍| 9441/10000 [00:40<00:02, 217.87it/s]Running 10000 simulations.:  95%|█████████▍| 9464/10000 [00:40<00:02, 219.74it/s]Running 10000 simulations.:  95%|█████████▍| 9486/10000 [00:40<00:02, 217.15it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [00:40<00:02, 216.22it/s]Running 10000 simulations.:  95%|█████████▌| 9530/10000 [00:41<00:02, 215.82it/s]Running 10000 simulations.:  96%|█████████▌| 9552/10000 [00:41<00:02, 215.77it/s]Running 10000 simulations.:  96%|█████████▌| 9574/10000 [00:41<00:01, 216.52it/s]Running 10000 simulations.:  96%|█████████▌| 9596/10000 [00:41<00:01, 216.77it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [00:41<00:01, 217.43it/s]Running 10000 simulations.:  96%|█████████▋| 9640/10000 [00:41<00:01, 217.97it/s]Running 10000 simulations.:  97%|█████████▋| 9662/10000 [00:41<00:01, 218.47it/s]Running 10000 simulations.:  97%|█████████▋| 9684/10000 [00:41<00:01, 218.48it/s]Running 10000 simulations.:  97%|█████████▋| 9706/10000 [00:41<00:01, 218.36it/s]Running 10000 simulations.:  97%|█████████▋| 9728/10000 [00:41<00:01, 218.33it/s]Running 10000 simulations.:  98%|█████████▊| 9750/10000 [00:42<00:01, 218.36it/s]Running 10000 simulations.:  98%|█████████▊| 9772/10000 [00:42<00:01, 218.70it/s]Running 10000 simulations.:  98%|█████████▊| 9794/10000 [00:42<00:00, 219.00it/s]Running 10000 simulations.:  98%|█████████▊| 9816/10000 [00:42<00:00, 219.00it/s]Running 10000 simulations.:  98%|█████████▊| 9839/10000 [00:42<00:00, 219.64it/s]Running 10000 simulations.:  99%|█████████▊| 9861/10000 [00:42<00:00, 219.59it/s]Running 10000 simulations.:  99%|█████████▉| 9884/10000 [00:42<00:00, 220.18it/s]Running 10000 simulations.:  99%|█████████▉| 9907/10000 [00:42<00:00, 221.68it/s]Running 10000 simulations.:  99%|█████████▉| 9930/10000 [00:42<00:00, 221.54it/s]Running 10000 simulations.: 100%|█████████▉| 9953/10000 [00:42<00:00, 221.62it/s]Running 10000 simulations.: 100%|█████████▉| 9976/10000 [00:43<00:00, 221.38it/s]Running 10000 simulations.: 100%|█████████▉| 9999/10000 [00:43<00:00, 221.28it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:43<00:00, 231.62it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 24/10000 [00:00<00:41, 239.00it/s]Running 10000 simulations.:   0%|          | 48/10000 [00:00<00:41, 238.62it/s]Running 10000 simulations.:   1%|          | 73/10000 [00:00<00:41, 240.91it/s]Running 10000 simulations.:   1%|          | 98/10000 [00:00<00:41, 241.31it/s]Running 10000 simulations.:   1%|          | 123/10000 [00:00<00:40, 243.45it/s]Running 10000 simulations.:   1%|▏         | 148/10000 [00:00<00:40, 243.80it/s]Running 10000 simulations.:   2%|▏         | 172/10000 [00:00<00:40, 241.44it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:00<00:40, 240.76it/s]Running 10000 simulations.:   2%|▏         | 220/10000 [00:00<00:40, 240.18it/s]Running 10000 simulations.:   2%|▏         | 245/10000 [00:01<00:40, 240.20it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:01<00:40, 240.09it/s]Running 10000 simulations.:   3%|▎         | 293/10000 [00:01<00:40, 239.66it/s]Running 10000 simulations.:   3%|▎         | 317/10000 [00:01<00:40, 239.01it/s]Running 10000 simulations.:   3%|▎         | 341/10000 [00:01<00:40, 237.25it/s]Running 10000 simulations.:   4%|▎         | 365/10000 [00:01<00:40, 237.15it/s]Running 10000 simulations.:   4%|▍         | 389/10000 [00:01<00:40, 236.49it/s]Running 10000 simulations.:   4%|▍         | 414/10000 [00:01<00:40, 238.71it/s]Running 10000 simulations.:   4%|▍         | 439/10000 [00:01<00:39, 239.46it/s]Running 10000 simulations.:   5%|▍         | 464/10000 [00:01<00:39, 240.74it/s]Running 10000 simulations.:   5%|▍         | 489/10000 [00:02<00:39, 241.06it/s]Running 10000 simulations.:   5%|▌         | 514/10000 [00:02<00:39, 240.60it/s]Running 10000 simulations.:   5%|▌         | 539/10000 [00:02<00:39, 240.33it/s]Running 10000 simulations.:   6%|▌         | 564/10000 [00:02<00:39, 241.09it/s]Running 10000 simulations.:   6%|▌         | 589/10000 [00:02<00:38, 241.49it/s]Running 10000 simulations.:   6%|▌         | 614/10000 [00:02<00:38, 240.99it/s]Running 10000 simulations.:   6%|▋         | 639/10000 [00:02<00:38, 240.94it/s]Running 10000 simulations.:   7%|▋         | 664/10000 [00:02<00:38, 241.43it/s]Running 10000 simulations.:   7%|▋         | 689/10000 [00:02<00:38, 242.39it/s]Running 10000 simulations.:   7%|▋         | 714/10000 [00:02<00:38, 242.37it/s]Running 10000 simulations.:   7%|▋         | 739/10000 [00:03<00:38, 242.49it/s]Running 10000 simulations.:   8%|▊         | 764/10000 [00:03<00:38, 242.95it/s]Running 10000 simulations.:   8%|▊         | 789/10000 [00:03<00:38, 240.24it/s]Running 10000 simulations.:   8%|▊         | 814/10000 [00:03<00:38, 240.09it/s]Running 10000 simulations.:   8%|▊         | 839/10000 [00:03<00:38, 240.80it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:03<00:37, 240.77it/s]Running 10000 simulations.:   9%|▉         | 889/10000 [00:03<00:37, 240.65it/s]Running 10000 simulations.:   9%|▉         | 914/10000 [00:03<00:37, 239.55it/s]Running 10000 simulations.:   9%|▉         | 938/10000 [00:03<00:37, 239.13it/s]Running 10000 simulations.:  10%|▉         | 962/10000 [00:04<00:37, 238.97it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:04<00:38, 237.03it/s]Running 10000 simulations.:  10%|█         | 1010/10000 [00:04<00:38, 235.08it/s]Running 10000 simulations.:  10%|█         | 1035/10000 [00:04<00:37, 237.60it/s]Running 10000 simulations.:  11%|█         | 1060/10000 [00:04<00:37, 240.39it/s]Running 10000 simulations.:  11%|█         | 1085/10000 [00:04<00:37, 239.48it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:04<00:37, 239.92it/s]Running 10000 simulations.:  11%|█▏        | 1135/10000 [00:04<00:37, 238.95it/s]Running 10000 simulations.:  12%|█▏        | 1159/10000 [00:04<00:37, 237.91it/s]Running 10000 simulations.:  12%|█▏        | 1183/10000 [00:04<00:37, 237.56it/s]Running 10000 simulations.:  12%|█▏        | 1208/10000 [00:05<00:36, 238.89it/s]Running 10000 simulations.:  12%|█▏        | 1233/10000 [00:05<00:36, 239.71it/s]Running 10000 simulations.:  13%|█▎        | 1257/10000 [00:05<00:36, 238.91it/s]Running 10000 simulations.:  13%|█▎        | 1281/10000 [00:05<00:36, 239.14it/s]Running 10000 simulations.:  13%|█▎        | 1305/10000 [00:05<00:36, 238.46it/s]Running 10000 simulations.:  13%|█▎        | 1329/10000 [00:05<00:36, 237.15it/s]Running 10000 simulations.:  14%|█▎        | 1353/10000 [00:05<00:36, 236.68it/s]Running 10000 simulations.:  14%|█▍        | 1377/10000 [00:05<00:36, 237.16it/s]Running 10000 simulations.:  14%|█▍        | 1401/10000 [00:05<00:36, 236.91it/s]Running 10000 simulations.:  14%|█▍        | 1425/10000 [00:05<00:36, 237.80it/s]Running 10000 simulations.:  14%|█▍        | 1449/10000 [00:06<00:35, 238.18it/s]Running 10000 simulations.:  15%|█▍        | 1474/10000 [00:06<00:35, 238.84it/s]Running 10000 simulations.:  15%|█▍        | 1498/10000 [00:06<00:35, 238.51it/s]Running 10000 simulations.:  15%|█▌        | 1522/10000 [00:06<00:35, 238.03it/s]Running 10000 simulations.:  15%|█▌        | 1546/10000 [00:06<00:35, 236.70it/s]Running 10000 simulations.:  16%|█▌        | 1570/10000 [00:06<00:36, 234.08it/s]Running 10000 simulations.:  16%|█▌        | 1594/10000 [00:06<00:36, 232.80it/s]Running 10000 simulations.:  16%|█▌        | 1618/10000 [00:06<00:36, 231.83it/s]Running 10000 simulations.:  16%|█▋        | 1643/10000 [00:06<00:35, 234.85it/s]Running 10000 simulations.:  17%|█▋        | 1668/10000 [00:06<00:35, 237.09it/s]Running 10000 simulations.:  17%|█▋        | 1693/10000 [00:07<00:34, 238.54it/s]Running 10000 simulations.:  17%|█▋        | 1718/10000 [00:07<00:34, 239.53it/s]Running 10000 simulations.:  17%|█▋        | 1742/10000 [00:07<00:34, 238.11it/s]Running 10000 simulations.:  18%|█▊        | 1766/10000 [00:07<00:34, 237.59it/s]Running 10000 simulations.:  18%|█▊        | 1790/10000 [00:07<00:34, 237.53it/s]Running 10000 simulations.:  18%|█▊        | 1815/10000 [00:07<00:34, 238.83it/s]Running 10000 simulations.:  18%|█▊        | 1840/10000 [00:07<00:34, 239.44it/s]Running 10000 simulations.:  19%|█▊        | 1865/10000 [00:07<00:33, 241.02it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:07<00:33, 241.03it/s]Running 10000 simulations.:  19%|█▉        | 1915/10000 [00:08<00:33, 240.95it/s]Running 10000 simulations.:  19%|█▉        | 1940/10000 [00:08<00:33, 237.87it/s]Running 10000 simulations.:  20%|█▉        | 1964/10000 [00:08<00:34, 234.58it/s]Running 10000 simulations.:  20%|█▉        | 1988/10000 [00:08<00:34, 234.74it/s]Running 10000 simulations.:  20%|██        | 2012/10000 [00:08<00:33, 236.18it/s]Running 10000 simulations.:  20%|██        | 2036/10000 [00:08<00:33, 237.07it/s]Running 10000 simulations.:  21%|██        | 2060/10000 [00:08<00:33, 237.63it/s]Running 10000 simulations.:  21%|██        | 2085/10000 [00:08<00:33, 238.57it/s]Running 10000 simulations.:  21%|██        | 2109/10000 [00:08<00:33, 238.95it/s]Running 10000 simulations.:  21%|██▏       | 2134/10000 [00:08<00:32, 240.11it/s]Running 10000 simulations.:  22%|██▏       | 2159/10000 [00:09<00:32, 239.72it/s]Running 10000 simulations.:  22%|██▏       | 2183/10000 [00:09<00:32, 239.38it/s]Running 10000 simulations.:  22%|██▏       | 2207/10000 [00:09<00:32, 239.17it/s]Running 10000 simulations.:  22%|██▏       | 2231/10000 [00:09<00:32, 238.28it/s]Running 10000 simulations.:  23%|██▎       | 2255/10000 [00:09<00:32, 237.74it/s]Running 10000 simulations.:  23%|██▎       | 2279/10000 [00:09<00:32, 237.96it/s]Running 10000 simulations.:  23%|██▎       | 2303/10000 [00:09<00:32, 238.43it/s]Running 10000 simulations.:  23%|██▎       | 2328/10000 [00:09<00:32, 239.04it/s]Running 10000 simulations.:  24%|██▎       | 2353/10000 [00:09<00:31, 239.54it/s]Running 10000 simulations.:  24%|██▍       | 2377/10000 [00:09<00:31, 238.91it/s]Running 10000 simulations.:  24%|██▍       | 2401/10000 [00:10<00:31, 238.68it/s]Running 10000 simulations.:  24%|██▍       | 2426/10000 [00:10<00:31, 239.19it/s]Running 10000 simulations.:  24%|██▍       | 2450/10000 [00:10<00:31, 238.57it/s]Running 10000 simulations.:  25%|██▍       | 2474/10000 [00:10<00:31, 237.59it/s]Running 10000 simulations.:  25%|██▍       | 2498/10000 [00:10<00:31, 237.89it/s]Running 10000 simulations.:  25%|██▌       | 2523/10000 [00:10<00:31, 239.81it/s]Running 10000 simulations.:  25%|██▌       | 2548/10000 [00:10<00:31, 240.28it/s]Running 10000 simulations.:  26%|██▌       | 2573/10000 [00:10<00:31, 238.88it/s]Running 10000 simulations.:  26%|██▌       | 2597/10000 [00:10<00:31, 237.43it/s]Running 10000 simulations.:  26%|██▌       | 2621/10000 [00:10<00:31, 237.85it/s]Running 10000 simulations.:  26%|██▋       | 2646/10000 [00:11<00:30, 239.20it/s]Running 10000 simulations.:  27%|██▋       | 2671/10000 [00:11<00:30, 239.77it/s]Running 10000 simulations.:  27%|██▋       | 2696/10000 [00:11<00:30, 239.76it/s]Running 10000 simulations.:  27%|██▋       | 2720/10000 [00:11<00:30, 238.49it/s]Running 10000 simulations.:  27%|██▋       | 2744/10000 [00:11<00:30, 237.85it/s]Running 10000 simulations.:  28%|██▊       | 2768/10000 [00:11<00:30, 237.91it/s]Running 10000 simulations.:  28%|██▊       | 2792/10000 [00:11<00:30, 237.47it/s]Running 10000 simulations.:  28%|██▊       | 2816/10000 [00:11<00:30, 238.13it/s]Running 10000 simulations.:  28%|██▊       | 2841/10000 [00:11<00:29, 239.02it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:11<00:29, 240.17it/s]Running 10000 simulations.:  29%|██▉       | 2891/10000 [00:12<00:29, 239.85it/s]Running 10000 simulations.:  29%|██▉       | 2915/10000 [00:12<00:29, 238.63it/s]Running 10000 simulations.:  29%|██▉       | 2939/10000 [00:12<00:29, 237.12it/s]Running 10000 simulations.:  30%|██▉       | 2963/10000 [00:12<00:29, 236.38it/s]Running 10000 simulations.:  30%|██▉       | 2987/10000 [00:12<00:29, 236.10it/s]Running 10000 simulations.:  30%|███       | 3011/10000 [00:12<00:29, 236.36it/s]Running 10000 simulations.:  30%|███       | 3035/10000 [00:12<00:29, 235.92it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:12<00:29, 238.55it/s]Running 10000 simulations.:  31%|███       | 3084/10000 [00:12<00:29, 238.33it/s]Running 10000 simulations.:  31%|███       | 3108/10000 [00:13<00:28, 237.80it/s]Running 10000 simulations.:  31%|███▏      | 3133/10000 [00:13<00:28, 238.60it/s]Running 10000 simulations.:  32%|███▏      | 3157/10000 [00:13<00:28, 237.43it/s]Running 10000 simulations.:  32%|███▏      | 3181/10000 [00:13<00:28, 236.33it/s]Running 10000 simulations.:  32%|███▏      | 3205/10000 [00:13<00:28, 236.68it/s]Running 10000 simulations.:  32%|███▏      | 3229/10000 [00:13<00:28, 236.29it/s]Running 10000 simulations.:  33%|███▎      | 3253/10000 [00:13<00:28, 235.98it/s]Running 10000 simulations.:  33%|███▎      | 3277/10000 [00:13<00:28, 237.13it/s]Running 10000 simulations.:  33%|███▎      | 3301/10000 [00:13<00:28, 237.77it/s]Running 10000 simulations.:  33%|███▎      | 3325/10000 [00:13<00:28, 238.08it/s]Running 10000 simulations.:  33%|███▎      | 3349/10000 [00:14<00:27, 237.98it/s]Running 10000 simulations.:  34%|███▎      | 3373/10000 [00:14<00:27, 237.41it/s]Running 10000 simulations.:  34%|███▍      | 3397/10000 [00:14<00:27, 236.28it/s]Running 10000 simulations.:  34%|███▍      | 3421/10000 [00:14<00:27, 236.03it/s]Running 10000 simulations.:  34%|███▍      | 3445/10000 [00:14<00:27, 235.56it/s]Running 10000 simulations.:  35%|███▍      | 3469/10000 [00:14<00:27, 236.09it/s]Running 10000 simulations.:  35%|███▍      | 3493/10000 [00:14<00:27, 237.19it/s]Running 10000 simulations.:  35%|███▌      | 3518/10000 [00:14<00:27, 238.52it/s]Running 10000 simulations.:  35%|███▌      | 3542/10000 [00:14<00:27, 238.89it/s]Running 10000 simulations.:  36%|███▌      | 3566/10000 [00:14<00:26, 238.79it/s]Running 10000 simulations.:  36%|███▌      | 3590/10000 [00:15<00:26, 238.78it/s]Running 10000 simulations.:  36%|███▌      | 3614/10000 [00:15<00:26, 237.23it/s]Running 10000 simulations.:  36%|███▋      | 3638/10000 [00:15<00:26, 237.19it/s]Running 10000 simulations.:  37%|███▋      | 3662/10000 [00:15<00:27, 226.84it/s]Running 10000 simulations.:  37%|███▋      | 3686/10000 [00:15<00:27, 229.81it/s]Running 10000 simulations.:  37%|███▋      | 3710/10000 [00:15<00:27, 232.29it/s]Running 10000 simulations.:  37%|███▋      | 3734/10000 [00:15<00:26, 232.64it/s]Running 10000 simulations.:  38%|███▊      | 3759/10000 [00:15<00:26, 234.81it/s]Running 10000 simulations.:  38%|███▊      | 3783/10000 [00:15<00:26, 234.02it/s]Running 10000 simulations.:  38%|███▊      | 3807/10000 [00:15<00:26, 235.47it/s]Running 10000 simulations.:  38%|███▊      | 3831/10000 [00:16<00:26, 235.59it/s]Running 10000 simulations.:  39%|███▊      | 3855/10000 [00:16<00:26, 235.79it/s]Running 10000 simulations.:  39%|███▉      | 3879/10000 [00:16<00:26, 234.98it/s]Running 10000 simulations.:  39%|███▉      | 3903/10000 [00:16<00:25, 234.68it/s]Running 10000 simulations.:  39%|███▉      | 3927/10000 [00:16<00:25, 235.89it/s]Running 10000 simulations.:  40%|███▉      | 3951/10000 [00:16<00:25, 236.77it/s]Running 10000 simulations.:  40%|███▉      | 3975/10000 [00:16<00:25, 237.30it/s]Running 10000 simulations.:  40%|███▉      | 3999/10000 [00:16<00:25, 237.71it/s]Running 10000 simulations.:  40%|████      | 4024/10000 [00:16<00:25, 238.46it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:16<00:24, 238.75it/s]Running 10000 simulations.:  41%|████      | 4072/10000 [00:17<00:25, 237.12it/s]Running 10000 simulations.:  41%|████      | 4096/10000 [00:17<00:25, 235.98it/s]Running 10000 simulations.:  41%|████      | 4120/10000 [00:17<00:25, 234.29it/s]Running 10000 simulations.:  41%|████▏     | 4144/10000 [00:17<00:25, 233.46it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:17<00:25, 232.88it/s]Running 10000 simulations.:  42%|████▏     | 4192/10000 [00:17<00:24, 234.59it/s]Running 10000 simulations.:  42%|████▏     | 4216/10000 [00:17<00:24, 234.97it/s]Running 10000 simulations.:  42%|████▏     | 4240/10000 [00:17<00:24, 235.90it/s]Running 10000 simulations.:  43%|████▎     | 4265/10000 [00:17<00:24, 237.68it/s]Running 10000 simulations.:  43%|████▎     | 4289/10000 [00:18<00:24, 235.96it/s]Running 10000 simulations.:  43%|████▎     | 4313/10000 [00:18<00:24, 234.53it/s]Running 10000 simulations.:  43%|████▎     | 4337/10000 [00:18<00:24, 234.49it/s]Running 10000 simulations.:  44%|████▎     | 4361/10000 [00:18<00:23, 235.27it/s]Running 10000 simulations.:  44%|████▍     | 4385/10000 [00:18<00:23, 234.95it/s]Running 10000 simulations.:  44%|████▍     | 4409/10000 [00:18<00:23, 234.78it/s]Running 10000 simulations.:  44%|████▍     | 4433/10000 [00:18<00:23, 234.34it/s]Running 10000 simulations.:  45%|████▍     | 4457/10000 [00:18<00:23, 234.86it/s]Running 10000 simulations.:  45%|████▍     | 4481/10000 [00:18<00:23, 235.77it/s]Running 10000 simulations.:  45%|████▌     | 4505/10000 [00:18<00:23, 236.22it/s]Running 10000 simulations.:  45%|████▌     | 4529/10000 [00:19<00:23, 236.95it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:19<00:22, 237.82it/s]Running 10000 simulations.:  46%|████▌     | 4577/10000 [00:19<00:22, 236.60it/s]Running 10000 simulations.:  46%|████▌     | 4601/10000 [00:19<00:22, 236.81it/s]Running 10000 simulations.:  46%|████▋     | 4625/10000 [00:19<00:22, 236.46it/s]Running 10000 simulations.:  46%|████▋     | 4649/10000 [00:19<00:22, 236.71it/s]Running 10000 simulations.:  47%|████▋     | 4673/10000 [00:19<00:22, 236.65it/s]Running 10000 simulations.:  47%|████▋     | 4697/10000 [00:19<00:22, 237.01it/s]Running 10000 simulations.:  47%|████▋     | 4721/10000 [00:19<00:22, 236.87it/s]Running 10000 simulations.:  47%|████▋     | 4745/10000 [00:19<00:22, 236.73it/s]Running 10000 simulations.:  48%|████▊     | 4769/10000 [00:20<00:22, 237.65it/s]Running 10000 simulations.:  48%|████▊     | 4793/10000 [00:20<00:22, 235.44it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:20<00:22, 235.41it/s]Running 10000 simulations.:  48%|████▊     | 4841/10000 [00:20<00:21, 235.18it/s]Running 10000 simulations.:  49%|████▊     | 4865/10000 [00:20<00:21, 235.48it/s]Running 10000 simulations.:  49%|████▉     | 4889/10000 [00:20<00:21, 236.25it/s]Running 10000 simulations.:  49%|████▉     | 4914/10000 [00:20<00:21, 237.47it/s]Running 10000 simulations.:  49%|████▉     | 4938/10000 [00:20<00:21, 237.71it/s]Running 10000 simulations.:  50%|████▉     | 4962/10000 [00:20<00:21, 237.96it/s]Running 10000 simulations.:  50%|████▉     | 4987/10000 [00:20<00:21, 235.59it/s]Running 10000 simulations.:  50%|█████     | 5011/10000 [00:21<00:21, 233.09it/s]Running 10000 simulations.:  50%|█████     | 5035/10000 [00:21<00:21, 234.27it/s]Running 10000 simulations.:  51%|█████     | 5059/10000 [00:21<00:21, 234.07it/s]Running 10000 simulations.:  51%|█████     | 5083/10000 [00:21<00:21, 232.75it/s]Running 10000 simulations.:  51%|█████     | 5107/10000 [00:21<00:20, 233.36it/s]Running 10000 simulations.:  51%|█████▏    | 5132/10000 [00:21<00:20, 235.61it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:21<00:20, 236.34it/s]Running 10000 simulations.:  52%|█████▏    | 5180/10000 [00:21<00:20, 237.14it/s]Running 10000 simulations.:  52%|█████▏    | 5205/10000 [00:21<00:20, 238.17it/s]Running 10000 simulations.:  52%|█████▏    | 5229/10000 [00:22<00:20, 236.77it/s]Running 10000 simulations.:  53%|█████▎    | 5253/10000 [00:22<00:20, 236.19it/s]Running 10000 simulations.:  53%|█████▎    | 5277/10000 [00:22<00:20, 235.82it/s]Running 10000 simulations.:  53%|█████▎    | 5301/10000 [00:22<00:19, 235.26it/s]Running 10000 simulations.:  53%|█████▎    | 5325/10000 [00:22<00:19, 234.86it/s]Running 10000 simulations.:  53%|█████▎    | 5349/10000 [00:22<00:19, 236.11it/s]Running 10000 simulations.:  54%|█████▎    | 5373/10000 [00:22<00:19, 237.07it/s]Running 10000 simulations.:  54%|█████▍    | 5397/10000 [00:22<00:19, 237.08it/s]Running 10000 simulations.:  54%|█████▍    | 5421/10000 [00:22<00:19, 236.49it/s]Running 10000 simulations.:  54%|█████▍    | 5445/10000 [00:22<00:19, 234.79it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:23<00:19, 233.40it/s]Running 10000 simulations.:  55%|█████▍    | 5493/10000 [00:23<00:19, 233.01it/s]Running 10000 simulations.:  55%|█████▌    | 5517/10000 [00:23<00:19, 231.91it/s]Running 10000 simulations.:  55%|█████▌    | 5541/10000 [00:23<00:19, 231.54it/s]Running 10000 simulations.:  56%|█████▌    | 5565/10000 [00:23<00:19, 232.33it/s]Running 10000 simulations.:  56%|█████▌    | 5589/10000 [00:23<00:18, 233.25it/s]Running 10000 simulations.:  56%|█████▌    | 5613/10000 [00:23<00:18, 234.00it/s]Running 10000 simulations.:  56%|█████▋    | 5637/10000 [00:23<00:18, 233.59it/s]Running 10000 simulations.:  57%|█████▋    | 5661/10000 [00:23<00:18, 233.35it/s]Running 10000 simulations.:  57%|█████▋    | 5685/10000 [00:23<00:18, 233.63it/s]Running 10000 simulations.:  57%|█████▋    | 5709/10000 [00:24<00:18, 233.00it/s]Running 10000 simulations.:  57%|█████▋    | 5733/10000 [00:24<00:18, 231.63it/s]Running 10000 simulations.:  58%|█████▊    | 5757/10000 [00:24<00:18, 231.75it/s]Running 10000 simulations.:  58%|█████▊    | 5781/10000 [00:24<00:18, 232.36it/s]Running 10000 simulations.:  58%|█████▊    | 5805/10000 [00:24<00:17, 233.23it/s]Running 10000 simulations.:  58%|█████▊    | 5829/10000 [00:24<00:17, 233.64it/s]Running 10000 simulations.:  59%|█████▊    | 5853/10000 [00:24<00:17, 233.27it/s]Running 10000 simulations.:  59%|█████▉    | 5877/10000 [00:24<00:17, 231.77it/s]Running 10000 simulations.:  59%|█████▉    | 5901/10000 [00:24<00:17, 231.64it/s]Running 10000 simulations.:  59%|█████▉    | 5925/10000 [00:24<00:17, 232.29it/s]Running 10000 simulations.:  59%|█████▉    | 5949/10000 [00:25<00:17, 232.37it/s]Running 10000 simulations.:  60%|█████▉    | 5973/10000 [00:25<00:17, 229.89it/s]Running 10000 simulations.:  60%|█████▉    | 5996/10000 [00:25<00:17, 228.40it/s]Running 10000 simulations.:  60%|██████    | 6019/10000 [00:25<00:17, 227.73it/s]Running 10000 simulations.:  60%|██████    | 6042/10000 [00:25<00:17, 227.47it/s]Running 10000 simulations.:  61%|██████    | 6065/10000 [00:25<00:17, 228.12it/s]Running 10000 simulations.:  61%|██████    | 6089/10000 [00:25<00:17, 229.30it/s]Running 10000 simulations.:  61%|██████    | 6113/10000 [00:25<00:16, 231.36it/s]Running 10000 simulations.:  61%|██████▏   | 6137/10000 [00:25<00:16, 231.95it/s]Running 10000 simulations.:  62%|██████▏   | 6161/10000 [00:26<00:16, 231.72it/s]Running 10000 simulations.:  62%|██████▏   | 6185/10000 [00:26<00:16, 231.02it/s]Running 10000 simulations.:  62%|██████▏   | 6209/10000 [00:26<00:16, 230.68it/s]Running 10000 simulations.:  62%|██████▏   | 6233/10000 [00:26<00:16, 230.68it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:26<00:16, 231.19it/s]Running 10000 simulations.:  63%|██████▎   | 6281/10000 [00:26<00:16, 230.95it/s]Running 10000 simulations.:  63%|██████▎   | 6305/10000 [00:26<00:16, 230.90it/s]Running 10000 simulations.:  63%|██████▎   | 6329/10000 [00:26<00:15, 231.65it/s]Running 10000 simulations.:  64%|██████▎   | 6353/10000 [00:26<00:15, 231.91it/s]Running 10000 simulations.:  64%|██████▍   | 6377/10000 [00:26<00:15, 231.41it/s]Running 10000 simulations.:  64%|██████▍   | 6401/10000 [00:27<00:15, 230.76it/s]Running 10000 simulations.:  64%|██████▍   | 6425/10000 [00:27<00:15, 230.81it/s]Running 10000 simulations.:  64%|██████▍   | 6449/10000 [00:27<00:15, 231.17it/s]Running 10000 simulations.:  65%|██████▍   | 6473/10000 [00:27<00:15, 231.73it/s]Running 10000 simulations.:  65%|██████▍   | 6497/10000 [00:27<00:15, 232.19it/s]Running 10000 simulations.:  65%|██████▌   | 6521/10000 [00:27<00:14, 232.61it/s]Running 10000 simulations.:  65%|██████▌   | 6545/10000 [00:27<00:14, 233.84it/s]Running 10000 simulations.:  66%|██████▌   | 6569/10000 [00:27<00:14, 232.46it/s]Running 10000 simulations.:  66%|██████▌   | 6593/10000 [00:27<00:14, 230.39it/s]Running 10000 simulations.:  66%|██████▌   | 6617/10000 [00:27<00:14, 229.04it/s]Running 10000 simulations.:  66%|██████▋   | 6641/10000 [00:28<00:14, 229.50it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:28<00:14, 230.64it/s]Running 10000 simulations.:  67%|██████▋   | 6689/10000 [00:28<00:14, 231.04it/s]Running 10000 simulations.:  67%|██████▋   | 6713/10000 [00:28<00:14, 231.98it/s]Running 10000 simulations.:  67%|██████▋   | 6737/10000 [00:28<00:13, 233.46it/s]Running 10000 simulations.:  68%|██████▊   | 6761/10000 [00:28<00:13, 234.13it/s]Running 10000 simulations.:  68%|██████▊   | 6785/10000 [00:28<00:13, 233.97it/s]Running 10000 simulations.:  68%|██████▊   | 6809/10000 [00:28<00:13, 232.77it/s]Running 10000 simulations.:  68%|██████▊   | 6833/10000 [00:28<00:13, 232.14it/s]Running 10000 simulations.:  69%|██████▊   | 6857/10000 [00:29<00:13, 231.70it/s]Running 10000 simulations.:  69%|██████▉   | 6881/10000 [00:29<00:13, 232.22it/s]Running 10000 simulations.:  69%|██████▉   | 6905/10000 [00:29<00:13, 231.76it/s]Running 10000 simulations.:  69%|██████▉   | 6929/10000 [00:29<00:13, 232.89it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:29<00:13, 233.55it/s]Running 10000 simulations.:  70%|██████▉   | 6977/10000 [00:29<00:12, 233.68it/s]Running 10000 simulations.:  70%|███████   | 7001/10000 [00:29<00:12, 233.28it/s]Running 10000 simulations.:  70%|███████   | 7025/10000 [00:29<00:12, 233.12it/s]Running 10000 simulations.:  70%|███████   | 7049/10000 [00:29<00:12, 231.43it/s]Running 10000 simulations.:  71%|███████   | 7073/10000 [00:29<00:12, 230.49it/s]Running 10000 simulations.:  71%|███████   | 7097/10000 [00:30<00:12, 230.19it/s]Running 10000 simulations.:  71%|███████   | 7121/10000 [00:30<00:12, 229.61it/s]Running 10000 simulations.:  71%|███████▏  | 7145/10000 [00:30<00:12, 230.40it/s]Running 10000 simulations.:  72%|███████▏  | 7169/10000 [00:30<00:12, 231.34it/s]Running 10000 simulations.:  72%|███████▏  | 7193/10000 [00:30<00:12, 231.67it/s]Running 10000 simulations.:  72%|███████▏  | 7217/10000 [00:30<00:12, 231.03it/s]Running 10000 simulations.:  72%|███████▏  | 7241/10000 [00:30<00:11, 229.97it/s]Running 10000 simulations.:  73%|███████▎  | 7265/10000 [00:30<00:11, 230.34it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:30<00:11, 229.88it/s]Running 10000 simulations.:  73%|███████▎  | 7312/10000 [00:30<00:11, 228.94it/s]Running 10000 simulations.:  73%|███████▎  | 7335/10000 [00:31<00:11, 228.77it/s]Running 10000 simulations.:  74%|███████▎  | 7358/10000 [00:31<00:11, 228.51it/s]Running 10000 simulations.:  74%|███████▍  | 7381/10000 [00:31<00:11, 227.39it/s]Running 10000 simulations.:  74%|███████▍  | 7404/10000 [00:31<00:11, 227.95it/s]Running 10000 simulations.:  74%|███████▍  | 7428/10000 [00:31<00:11, 230.56it/s]Running 10000 simulations.:  75%|███████▍  | 7452/10000 [00:31<00:11, 231.56it/s]Running 10000 simulations.:  75%|███████▍  | 7476/10000 [00:31<00:10, 232.13it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:31<00:10, 232.82it/s]Running 10000 simulations.:  75%|███████▌  | 7524/10000 [00:31<00:10, 231.14it/s]Running 10000 simulations.:  75%|███████▌  | 7548/10000 [00:32<00:10, 230.63it/s]Running 10000 simulations.:  76%|███████▌  | 7572/10000 [00:32<00:10, 231.38it/s]Running 10000 simulations.:  76%|███████▌  | 7596/10000 [00:32<00:10, 230.33it/s]Running 10000 simulations.:  76%|███████▌  | 7620/10000 [00:32<00:10, 229.08it/s]Running 10000 simulations.:  76%|███████▋  | 7643/10000 [00:32<00:10, 228.86it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:32<00:10, 228.10it/s]Running 10000 simulations.:  77%|███████▋  | 7690/10000 [00:32<00:10, 229.92it/s]Running 10000 simulations.:  77%|███████▋  | 7714/10000 [00:32<00:09, 231.19it/s]Running 10000 simulations.:  77%|███████▋  | 7738/10000 [00:32<00:09, 231.27it/s]Running 10000 simulations.:  78%|███████▊  | 7762/10000 [00:32<00:09, 232.13it/s]Running 10000 simulations.:  78%|███████▊  | 7786/10000 [00:33<00:09, 230.46it/s]Running 10000 simulations.:  78%|███████▊  | 7810/10000 [00:33<00:09, 229.99it/s]Running 10000 simulations.:  78%|███████▊  | 7834/10000 [00:33<00:09, 228.82it/s]Running 10000 simulations.:  79%|███████▊  | 7857/10000 [00:33<00:09, 227.10it/s]Running 10000 simulations.:  79%|███████▉  | 7880/10000 [00:33<00:09, 227.01it/s]Running 10000 simulations.:  79%|███████▉  | 7904/10000 [00:33<00:09, 228.58it/s]Running 10000 simulations.:  79%|███████▉  | 7928/10000 [00:33<00:09, 229.27it/s]Running 10000 simulations.:  80%|███████▉  | 7951/10000 [00:33<00:09, 227.50it/s]Running 10000 simulations.:  80%|███████▉  | 7975/10000 [00:33<00:08, 228.36it/s]Running 10000 simulations.:  80%|███████▉  | 7999/10000 [00:33<00:08, 229.57it/s]Running 10000 simulations.:  80%|████████  | 8023/10000 [00:34<00:08, 231.51it/s]Running 10000 simulations.:  80%|████████  | 8047/10000 [00:34<00:08, 231.83it/s]Running 10000 simulations.:  81%|████████  | 8071/10000 [00:34<00:08, 231.61it/s]Running 10000 simulations.:  81%|████████  | 8095/10000 [00:34<00:08, 230.60it/s]Running 10000 simulations.:  81%|████████  | 8119/10000 [00:34<00:08, 229.98it/s]Running 10000 simulations.:  81%|████████▏ | 8143/10000 [00:34<00:08, 229.21it/s]Running 10000 simulations.:  82%|████████▏ | 8166/10000 [00:34<00:07, 229.42it/s]Running 10000 simulations.:  82%|████████▏ | 8190/10000 [00:34<00:07, 230.38it/s]Running 10000 simulations.:  82%|████████▏ | 8214/10000 [00:34<00:07, 230.97it/s]Running 10000 simulations.:  82%|████████▏ | 8238/10000 [00:35<00:07, 232.17it/s]Running 10000 simulations.:  83%|████████▎ | 8262/10000 [00:35<00:07, 233.14it/s]Running 10000 simulations.:  83%|████████▎ | 8286/10000 [00:35<00:07, 232.34it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:35<00:07, 231.19it/s]Running 10000 simulations.:  83%|████████▎ | 8334/10000 [00:35<00:07, 230.94it/s]Running 10000 simulations.:  84%|████████▎ | 8358/10000 [00:35<00:07, 230.35it/s]Running 10000 simulations.:  84%|████████▍ | 8382/10000 [00:35<00:07, 229.89it/s]Running 10000 simulations.:  84%|████████▍ | 8406/10000 [00:35<00:06, 231.35it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:35<00:06, 233.03it/s]Running 10000 simulations.:  85%|████████▍ | 8454/10000 [00:35<00:06, 232.30it/s]Running 10000 simulations.:  85%|████████▍ | 8478/10000 [00:36<00:06, 230.61it/s]Running 10000 simulations.:  85%|████████▌ | 8502/10000 [00:36<00:06, 230.71it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [00:36<00:06, 230.99it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:36<00:06, 230.78it/s]Running 10000 simulations.:  86%|████████▌ | 8574/10000 [00:36<00:06, 231.06it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [00:36<00:06, 230.52it/s]Running 10000 simulations.:  86%|████████▌ | 8622/10000 [00:36<00:05, 231.81it/s]Running 10000 simulations.:  86%|████████▋ | 8646/10000 [00:36<00:05, 233.43it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [00:36<00:05, 234.71it/s]Running 10000 simulations.:  87%|████████▋ | 8694/10000 [00:36<00:05, 235.83it/s]Running 10000 simulations.:  87%|████████▋ | 8718/10000 [00:37<00:05, 234.31it/s]Running 10000 simulations.:  87%|████████▋ | 8742/10000 [00:37<00:05, 234.02it/s]Running 10000 simulations.:  88%|████████▊ | 8766/10000 [00:37<00:05, 233.36it/s]Running 10000 simulations.:  88%|████████▊ | 8790/10000 [00:37<00:05, 232.19it/s]Running 10000 simulations.:  88%|████████▊ | 8814/10000 [00:37<00:05, 231.31it/s]Running 10000 simulations.:  88%|████████▊ | 8838/10000 [00:37<00:04, 233.22it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [00:37<00:04, 233.77it/s]Running 10000 simulations.:  89%|████████▉ | 8886/10000 [00:37<00:04, 234.90it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [00:37<00:04, 236.12it/s]Running 10000 simulations.:  89%|████████▉ | 8934/10000 [00:38<00:04, 233.60it/s]Running 10000 simulations.:  90%|████████▉ | 8958/10000 [00:38<00:04, 232.05it/s]Running 10000 simulations.:  90%|████████▉ | 8982/10000 [00:38<00:04, 231.14it/s]Running 10000 simulations.:  90%|█████████ | 9006/10000 [00:38<00:04, 231.65it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:38<00:04, 231.74it/s]Running 10000 simulations.:  91%|█████████ | 9054/10000 [00:38<00:04, 233.34it/s]Running 10000 simulations.:  91%|█████████ | 9078/10000 [00:38<00:03, 234.24it/s]Running 10000 simulations.:  91%|█████████ | 9102/10000 [00:38<00:03, 234.01it/s]Running 10000 simulations.:  91%|█████████▏| 9126/10000 [00:38<00:03, 234.67it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [00:38<00:03, 233.39it/s]Running 10000 simulations.:  92%|█████████▏| 9174/10000 [00:39<00:03, 233.64it/s]Running 10000 simulations.:  92%|█████████▏| 9198/10000 [00:39<00:03, 233.37it/s]Running 10000 simulations.:  92%|█████████▏| 9222/10000 [00:39<00:03, 232.38it/s]Running 10000 simulations.:  92%|█████████▏| 9246/10000 [00:39<00:03, 231.48it/s]Running 10000 simulations.:  93%|█████████▎| 9270/10000 [00:39<00:03, 232.66it/s]Running 10000 simulations.:  93%|█████████▎| 9294/10000 [00:39<00:03, 232.67it/s]Running 10000 simulations.:  93%|█████████▎| 9318/10000 [00:39<00:02, 233.17it/s]Running 10000 simulations.:  93%|█████████▎| 9342/10000 [00:39<00:02, 234.07it/s]Running 10000 simulations.:  94%|█████████▎| 9366/10000 [00:39<00:02, 232.65it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:39<00:02, 233.27it/s]Running 10000 simulations.:  94%|█████████▍| 9414/10000 [00:40<00:02, 230.66it/s]Running 10000 simulations.:  94%|█████████▍| 9438/10000 [00:40<00:02, 227.30it/s]Running 10000 simulations.:  95%|█████████▍| 9461/10000 [00:40<00:02, 225.62it/s]Running 10000 simulations.:  95%|█████████▍| 9485/10000 [00:40<00:02, 227.82it/s]Running 10000 simulations.:  95%|█████████▌| 9509/10000 [00:40<00:02, 228.92it/s]Running 10000 simulations.:  95%|█████████▌| 9533/10000 [00:40<00:02, 229.28it/s]Running 10000 simulations.:  96%|█████████▌| 9557/10000 [00:40<00:01, 229.32it/s]Running 10000 simulations.:  96%|█████████▌| 9580/10000 [00:40<00:01, 228.46it/s]Running 10000 simulations.:  96%|█████████▌| 9603/10000 [00:40<00:01, 228.53it/s]Running 10000 simulations.:  96%|█████████▋| 9626/10000 [00:41<00:01, 228.47it/s]Running 10000 simulations.:  96%|█████████▋| 9649/10000 [00:41<00:01, 228.09it/s]Running 10000 simulations.:  97%|█████████▋| 9673/10000 [00:41<00:01, 228.18it/s]Running 10000 simulations.:  97%|█████████▋| 9696/10000 [00:41<00:01, 225.33it/s]Running 10000 simulations.:  97%|█████████▋| 9719/10000 [00:41<00:01, 225.11it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [00:41<00:01, 226.94it/s]Running 10000 simulations.:  98%|█████████▊| 9766/10000 [00:41<00:01, 227.60it/s]Running 10000 simulations.:  98%|█████████▊| 9790/10000 [00:41<00:00, 228.93it/s]Running 10000 simulations.:  98%|█████████▊| 9814/10000 [00:41<00:00, 230.43it/s]Running 10000 simulations.:  98%|█████████▊| 9838/10000 [00:41<00:00, 232.38it/s]Running 10000 simulations.:  99%|█████████▊| 9862/10000 [00:42<00:00, 232.31it/s]Running 10000 simulations.:  99%|█████████▉| 9886/10000 [00:42<00:00, 233.24it/s]Running 10000 simulations.:  99%|█████████▉| 9910/10000 [00:42<00:00, 232.76it/s]Running 10000 simulations.:  99%|█████████▉| 9934/10000 [00:42<00:00, 231.91it/s]Running 10000 simulations.: 100%|█████████▉| 9958/10000 [00:42<00:00, 228.54it/s]Running 10000 simulations.: 100%|█████████▉| 9981/10000 [00:42<00:00, 228.49it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 234.56it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 255.00it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 253.51it/s]Running 10000 simulations.:   1%|          | 77/10000 [00:00<00:39, 251.20it/s]Running 10000 simulations.:   1%|          | 103/10000 [00:00<00:39, 251.43it/s]Running 10000 simulations.:   1%|▏         | 129/10000 [00:00<00:39, 252.61it/s]Running 10000 simulations.:   2%|▏         | 155/10000 [00:00<00:39, 252.07it/s]Running 10000 simulations.:   2%|▏         | 181/10000 [00:00<00:38, 253.77it/s]Running 10000 simulations.:   2%|▏         | 206/10000 [00:00<00:39, 250.90it/s]Running 10000 simulations.:   2%|▏         | 230/10000 [00:00<00:39, 244.80it/s]Running 10000 simulations.:   3%|▎         | 254/10000 [00:01<00:40, 242.76it/s]Running 10000 simulations.:   3%|▎         | 280/10000 [00:01<00:39, 245.09it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:39, 246.59it/s]Running 10000 simulations.:   3%|▎         | 332/10000 [00:01<00:39, 247.60it/s]Running 10000 simulations.:   4%|▎         | 357/10000 [00:01<00:38, 247.75it/s]Running 10000 simulations.:   4%|▍         | 382/10000 [00:01<00:38, 247.86it/s]Running 10000 simulations.:   4%|▍         | 408/10000 [00:01<00:38, 248.82it/s]Running 10000 simulations.:   4%|▍         | 433/10000 [00:01<00:38, 248.89it/s]Running 10000 simulations.:   5%|▍         | 458/10000 [00:01<00:39, 243.34it/s]Running 10000 simulations.:   5%|▍         | 483/10000 [00:01<00:39, 240.35it/s]Running 10000 simulations.:   5%|▌         | 508/10000 [00:02<00:39, 241.94it/s]Running 10000 simulations.:   5%|▌         | 533/10000 [00:02<00:38, 243.03it/s]Running 10000 simulations.:   6%|▌         | 558/10000 [00:02<00:38, 243.35it/s]Running 10000 simulations.:   6%|▌         | 583/10000 [00:02<00:38, 244.07it/s]Running 10000 simulations.:   6%|▌         | 608/10000 [00:02<00:38, 245.48it/s]Running 10000 simulations.:   6%|▋         | 633/10000 [00:02<00:38, 245.50it/s]Running 10000 simulations.:   7%|▋         | 658/10000 [00:02<00:37, 246.80it/s]Running 10000 simulations.:   7%|▋         | 683/10000 [00:02<00:38, 243.37it/s]Running 10000 simulations.:   7%|▋         | 708/10000 [00:02<00:39, 236.53it/s]Running 10000 simulations.:   7%|▋         | 732/10000 [00:02<00:39, 237.00it/s]Running 10000 simulations.:   8%|▊         | 757/10000 [00:03<00:38, 238.31it/s]Running 10000 simulations.:   8%|▊         | 782/10000 [00:03<00:38, 238.93it/s]Running 10000 simulations.:   8%|▊         | 807/10000 [00:03<00:38, 240.31it/s]Running 10000 simulations.:   8%|▊         | 832/10000 [00:03<00:38, 241.26it/s]Running 10000 simulations.:   9%|▊         | 857/10000 [00:03<00:37, 242.75it/s]Running 10000 simulations.:   9%|▉         | 882/10000 [00:03<00:37, 244.65it/s]Running 10000 simulations.:   9%|▉         | 907/10000 [00:03<00:37, 243.51it/s]Running 10000 simulations.:   9%|▉         | 932/10000 [00:03<00:38, 237.90it/s]Running 10000 simulations.:  10%|▉         | 956/10000 [00:03<00:38, 236.66it/s]Running 10000 simulations.:  10%|▉         | 981/10000 [00:04<00:37, 237.95it/s]Running 10000 simulations.:  10%|█         | 1006/10000 [00:04<00:37, 239.28it/s]Running 10000 simulations.:  10%|█         | 1031/10000 [00:04<00:37, 239.62it/s]Running 10000 simulations.:  11%|█         | 1056/10000 [00:04<00:37, 239.85it/s]Running 10000 simulations.:  11%|█         | 1081/10000 [00:04<00:36, 241.06it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:04<00:36, 241.99it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:04<00:36, 242.19it/s]Running 10000 simulations.:  12%|█▏        | 1156/10000 [00:04<00:36, 239.06it/s]Running 10000 simulations.:  12%|█▏        | 1180/10000 [00:04<00:37, 237.79it/s]Running 10000 simulations.:  12%|█▏        | 1205/10000 [00:04<00:36, 239.36it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:05<00:36, 239.85it/s]Running 10000 simulations.:  13%|█▎        | 1255/10000 [00:05<00:36, 240.61it/s]Running 10000 simulations.:  13%|█▎        | 1280/10000 [00:05<00:36, 241.85it/s]Running 10000 simulations.:  13%|█▎        | 1305/10000 [00:05<00:35, 242.61it/s]Running 10000 simulations.:  13%|█▎        | 1330/10000 [00:05<00:35, 240.96it/s]Running 10000 simulations.:  14%|█▎        | 1355/10000 [00:05<00:36, 238.01it/s]Running 10000 simulations.:  14%|█▍        | 1379/10000 [00:05<00:36, 234.82it/s]Running 10000 simulations.:  14%|█▍        | 1403/10000 [00:05<00:36, 233.49it/s]Running 10000 simulations.:  14%|█▍        | 1427/10000 [00:05<00:36, 231.73it/s]Running 10000 simulations.:  15%|█▍        | 1451/10000 [00:05<00:36, 231.79it/s]Running 10000 simulations.:  15%|█▍        | 1476/10000 [00:06<00:36, 234.33it/s]Running 10000 simulations.:  15%|█▌        | 1501/10000 [00:06<00:35, 236.84it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:06<00:35, 237.90it/s]Running 10000 simulations.:  16%|█▌        | 1550/10000 [00:06<00:35, 238.42it/s]Running 10000 simulations.:  16%|█▌        | 1574/10000 [00:06<00:35, 238.72it/s]Running 10000 simulations.:  16%|█▌        | 1599/10000 [00:06<00:35, 239.69it/s]Running 10000 simulations.:  16%|█▌        | 1624/10000 [00:06<00:34, 240.61it/s]Running 10000 simulations.:  16%|█▋        | 1649/10000 [00:06<00:35, 237.57it/s]Running 10000 simulations.:  17%|█▋        | 1673/10000 [00:06<00:35, 234.81it/s]Running 10000 simulations.:  17%|█▋        | 1697/10000 [00:07<00:35, 235.90it/s]Running 10000 simulations.:  17%|█▋        | 1721/10000 [00:07<00:34, 236.71it/s]Running 10000 simulations.:  17%|█▋        | 1745/10000 [00:07<00:34, 237.30it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:07<00:34, 238.85it/s]Running 10000 simulations.:  18%|█▊        | 1794/10000 [00:07<00:34, 238.60it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:07<00:34, 237.36it/s]Running 10000 simulations.:  18%|█▊        | 1843/10000 [00:07<00:34, 238.38it/s]Running 10000 simulations.:  19%|█▊        | 1868/10000 [00:07<00:33, 239.50it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:07<00:33, 240.94it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:07<00:33, 241.66it/s]Running 10000 simulations.:  19%|█▉        | 1943/10000 [00:08<00:33, 239.99it/s]Running 10000 simulations.:  20%|█▉        | 1968/10000 [00:08<00:34, 236.19it/s]Running 10000 simulations.:  20%|█▉        | 1992/10000 [00:08<00:33, 236.70it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:08<00:33, 236.86it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:08<00:33, 236.84it/s]Running 10000 simulations.:  21%|██        | 2065/10000 [00:08<00:33, 237.92it/s]Running 10000 simulations.:  21%|██        | 2090/10000 [00:08<00:33, 239.12it/s]Running 10000 simulations.:  21%|██        | 2114/10000 [00:08<00:32, 238.98it/s]Running 10000 simulations.:  21%|██▏       | 2139/10000 [00:08<00:32, 240.12it/s]Running 10000 simulations.:  22%|██▏       | 2164/10000 [00:08<00:32, 239.49it/s]Running 10000 simulations.:  22%|██▏       | 2188/10000 [00:09<00:33, 235.48it/s]Running 10000 simulations.:  22%|██▏       | 2212/10000 [00:09<00:33, 232.35it/s]Running 10000 simulations.:  22%|██▏       | 2236/10000 [00:09<00:33, 230.54it/s]Running 10000 simulations.:  23%|██▎       | 2260/10000 [00:09<00:33, 232.17it/s]Running 10000 simulations.:  23%|██▎       | 2285/10000 [00:09<00:32, 234.81it/s]Running 10000 simulations.:  23%|██▎       | 2309/10000 [00:09<00:32, 236.06it/s]Running 10000 simulations.:  23%|██▎       | 2334/10000 [00:09<00:32, 237.34it/s]Running 10000 simulations.:  24%|██▎       | 2359/10000 [00:09<00:31, 239.43it/s]Running 10000 simulations.:  24%|██▍       | 2384/10000 [00:09<00:31, 240.06it/s]Running 10000 simulations.:  24%|██▍       | 2409/10000 [00:10<00:31, 240.57it/s]Running 10000 simulations.:  24%|██▍       | 2434/10000 [00:10<00:31, 240.65it/s]Running 10000 simulations.:  25%|██▍       | 2459/10000 [00:10<00:31, 236.22it/s]Running 10000 simulations.:  25%|██▍       | 2483/10000 [00:10<00:31, 234.98it/s]Running 10000 simulations.:  25%|██▌       | 2507/10000 [00:10<00:31, 236.00it/s]Running 10000 simulations.:  25%|██▌       | 2531/10000 [00:10<00:31, 236.74it/s]Running 10000 simulations.:  26%|██▌       | 2555/10000 [00:10<00:31, 237.52it/s]Running 10000 simulations.:  26%|██▌       | 2579/10000 [00:10<00:31, 236.48it/s]Running 10000 simulations.:  26%|██▌       | 2603/10000 [00:10<00:31, 234.42it/s]Running 10000 simulations.:  26%|██▋       | 2628/10000 [00:10<00:31, 236.12it/s]Running 10000 simulations.:  27%|██▋       | 2653/10000 [00:11<00:30, 237.80it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:11<00:30, 236.71it/s]Running 10000 simulations.:  27%|██▋       | 2701/10000 [00:11<00:46, 155.97it/s]Running 10000 simulations.:  27%|██▋       | 2725/10000 [00:11<00:41, 174.03it/s]Running 10000 simulations.:  27%|██▋       | 2749/10000 [00:11<00:38, 189.65it/s]Running 10000 simulations.:  28%|██▊       | 2774/10000 [00:11<00:35, 202.69it/s]Running 10000 simulations.:  28%|██▊       | 2799/10000 [00:11<00:33, 213.16it/s]Running 10000 simulations.:  28%|██▊       | 2824/10000 [00:11<00:32, 221.70it/s]Running 10000 simulations.:  28%|██▊       | 2849/10000 [00:12<00:31, 227.47it/s]Running 10000 simulations.:  29%|██▊       | 2874/10000 [00:12<00:30, 232.13it/s]Running 10000 simulations.:  29%|██▉       | 2898/10000 [00:12<00:30, 233.31it/s]Running 10000 simulations.:  29%|██▉       | 2922/10000 [00:12<00:30, 228.59it/s]Running 10000 simulations.:  29%|██▉       | 2946/10000 [00:12<00:30, 228.24it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:12<00:30, 230.83it/s]Running 10000 simulations.:  30%|██▉       | 2994/10000 [00:12<00:30, 232.06it/s]Running 10000 simulations.:  30%|███       | 3018/10000 [00:12<00:29, 234.04it/s]Running 10000 simulations.:  30%|███       | 3042/10000 [00:12<00:29, 235.52it/s]Running 10000 simulations.:  31%|███       | 3067/10000 [00:12<00:29, 237.23it/s]Running 10000 simulations.:  31%|███       | 3092/10000 [00:13<00:28, 238.57it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:13<00:28, 237.91it/s]Running 10000 simulations.:  31%|███▏      | 3140/10000 [00:13<00:29, 232.77it/s]Running 10000 simulations.:  32%|███▏      | 3164/10000 [00:13<00:29, 228.98it/s]Running 10000 simulations.:  32%|███▏      | 3187/10000 [00:13<00:29, 227.64it/s]Running 10000 simulations.:  32%|███▏      | 3211/10000 [00:13<00:29, 228.52it/s]Running 10000 simulations.:  32%|███▏      | 3235/10000 [00:13<00:29, 231.19it/s]Running 10000 simulations.:  33%|███▎      | 3259/10000 [00:13<00:29, 230.51it/s]Running 10000 simulations.:  33%|███▎      | 3284/10000 [00:13<00:28, 233.42it/s]Running 10000 simulations.:  33%|███▎      | 3308/10000 [00:14<00:28, 235.20it/s]Running 10000 simulations.:  33%|███▎      | 3332/10000 [00:14<00:28, 236.62it/s]Running 10000 simulations.:  34%|███▎      | 3357/10000 [00:14<00:27, 237.89it/s]Running 10000 simulations.:  34%|███▍      | 3381/10000 [00:14<00:27, 237.80it/s]Running 10000 simulations.:  34%|███▍      | 3405/10000 [00:14<00:28, 234.63it/s]Running 10000 simulations.:  34%|███▍      | 3429/10000 [00:14<00:28, 230.98it/s]Running 10000 simulations.:  35%|███▍      | 3453/10000 [00:14<00:28, 228.08it/s]Running 10000 simulations.:  35%|███▍      | 3476/10000 [00:14<00:28, 228.36it/s]Running 10000 simulations.:  35%|███▌      | 3500/10000 [00:14<00:28, 231.51it/s]Running 10000 simulations.:  35%|███▌      | 3524/10000 [00:14<00:27, 233.67it/s]Running 10000 simulations.:  35%|███▌      | 3548/10000 [00:15<00:27, 235.28it/s]Running 10000 simulations.:  36%|███▌      | 3572/10000 [00:15<00:27, 236.13it/s]Running 10000 simulations.:  36%|███▌      | 3596/10000 [00:15<00:27, 236.90it/s]Running 10000 simulations.:  36%|███▌      | 3620/10000 [00:15<00:26, 236.33it/s]Running 10000 simulations.:  36%|███▋      | 3644/10000 [00:15<00:26, 237.04it/s]Running 10000 simulations.:  37%|███▋      | 3668/10000 [00:15<00:26, 237.60it/s]Running 10000 simulations.:  37%|███▋      | 3692/10000 [00:15<00:26, 238.11it/s]Running 10000 simulations.:  37%|███▋      | 3717/10000 [00:15<00:26, 239.82it/s]Running 10000 simulations.:  37%|███▋      | 3741/10000 [00:15<00:26, 237.58it/s]Running 10000 simulations.:  38%|███▊      | 3765/10000 [00:15<00:26, 235.08it/s]Running 10000 simulations.:  38%|███▊      | 3789/10000 [00:16<00:26, 231.93it/s]Running 10000 simulations.:  38%|███▊      | 3813/10000 [00:16<00:26, 230.74it/s]Running 10000 simulations.:  38%|███▊      | 3837/10000 [00:16<00:26, 232.36it/s]Running 10000 simulations.:  39%|███▊      | 3861/10000 [00:16<00:26, 234.50it/s]Running 10000 simulations.:  39%|███▉      | 3885/10000 [00:16<00:25, 235.94it/s]Running 10000 simulations.:  39%|███▉      | 3910/10000 [00:16<00:25, 237.43it/s]Running 10000 simulations.:  39%|███▉      | 3935/10000 [00:16<00:25, 238.72it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:16<00:25, 240.30it/s]Running 10000 simulations.:  40%|███▉      | 3985/10000 [00:16<00:24, 241.67it/s]Running 10000 simulations.:  40%|████      | 4010/10000 [00:16<00:25, 239.11it/s]Running 10000 simulations.:  40%|████      | 4034/10000 [00:17<00:25, 235.46it/s]Running 10000 simulations.:  41%|████      | 4058/10000 [00:17<00:25, 234.17it/s]Running 10000 simulations.:  41%|████      | 4082/10000 [00:17<00:25, 235.67it/s]Running 10000 simulations.:  41%|████      | 4106/10000 [00:17<00:24, 236.80it/s]Running 10000 simulations.:  41%|████▏     | 4131/10000 [00:17<00:24, 238.18it/s]Running 10000 simulations.:  42%|████▏     | 4156/10000 [00:17<00:24, 238.82it/s]Running 10000 simulations.:  42%|████▏     | 4181/10000 [00:17<00:24, 239.30it/s]Running 10000 simulations.:  42%|████▏     | 4206/10000 [00:17<00:24, 239.48it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:17<00:24, 238.69it/s]Running 10000 simulations.:  43%|████▎     | 4254/10000 [00:18<00:24, 235.96it/s]Running 10000 simulations.:  43%|████▎     | 4278/10000 [00:18<00:24, 233.86it/s]Running 10000 simulations.:  43%|████▎     | 4302/10000 [00:18<00:24, 235.03it/s]Running 10000 simulations.:  43%|████▎     | 4326/10000 [00:18<00:24, 235.56it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:18<00:23, 236.58it/s]Running 10000 simulations.:  44%|████▍     | 4375/10000 [00:18<00:23, 237.91it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:18<00:23, 238.39it/s]Running 10000 simulations.:  44%|████▍     | 4424/10000 [00:18<00:23, 238.97it/s]Running 10000 simulations.:  44%|████▍     | 4449/10000 [00:18<00:23, 239.46it/s]Running 10000 simulations.:  45%|████▍     | 4473/10000 [00:18<00:23, 236.95it/s]Running 10000 simulations.:  45%|████▍     | 4497/10000 [00:19<00:23, 233.42it/s]Running 10000 simulations.:  45%|████▌     | 4521/10000 [00:19<00:23, 235.35it/s]Running 10000 simulations.:  45%|████▌     | 4545/10000 [00:19<00:23, 236.36it/s]Running 10000 simulations.:  46%|████▌     | 4570/10000 [00:19<00:22, 237.49it/s]Running 10000 simulations.:  46%|████▌     | 4595/10000 [00:19<00:22, 239.35it/s]Running 10000 simulations.:  46%|████▌     | 4619/10000 [00:19<00:22, 239.40it/s]Running 10000 simulations.:  46%|████▋     | 4644/10000 [00:19<00:22, 240.52it/s]Running 10000 simulations.:  47%|████▋     | 4669/10000 [00:19<00:22, 241.28it/s]Running 10000 simulations.:  47%|████▋     | 4694/10000 [00:19<00:21, 241.40it/s]Running 10000 simulations.:  47%|████▋     | 4719/10000 [00:19<00:22, 235.70it/s]Running 10000 simulations.:  47%|████▋     | 4743/10000 [00:20<00:22, 230.65it/s]Running 10000 simulations.:  48%|████▊     | 4767/10000 [00:20<00:22, 232.77it/s]Running 10000 simulations.:  48%|████▊     | 4792/10000 [00:20<00:22, 235.21it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:20<00:21, 237.55it/s]Running 10000 simulations.:  48%|████▊     | 4842/10000 [00:20<00:21, 239.46it/s]Running 10000 simulations.:  49%|████▊     | 4867/10000 [00:20<00:21, 241.36it/s]Running 10000 simulations.:  49%|████▉     | 4892/10000 [00:20<00:21, 242.13it/s]Running 10000 simulations.:  49%|████▉     | 4917/10000 [00:20<00:21, 241.90it/s]Running 10000 simulations.:  49%|████▉     | 4942/10000 [00:20<00:21, 238.59it/s]Running 10000 simulations.:  50%|████▉     | 4966/10000 [00:21<00:21, 234.31it/s]Running 10000 simulations.:  50%|████▉     | 4990/10000 [00:21<00:21, 231.75it/s]Running 10000 simulations.:  50%|█████     | 5014/10000 [00:21<00:21, 230.80it/s]Running 10000 simulations.:  50%|█████     | 5039/10000 [00:21<00:21, 234.14it/s]Running 10000 simulations.:  51%|█████     | 5064/10000 [00:21<00:20, 235.86it/s]Running 10000 simulations.:  51%|█████     | 5089/10000 [00:21<00:20, 237.17it/s]Running 10000 simulations.:  51%|█████     | 5114/10000 [00:21<00:20, 239.05it/s]Running 10000 simulations.:  51%|█████▏    | 5139/10000 [00:21<00:20, 240.41it/s]Running 10000 simulations.:  52%|█████▏    | 5164/10000 [00:21<00:19, 241.88it/s]Running 10000 simulations.:  52%|█████▏    | 5189/10000 [00:21<00:19, 242.17it/s]Running 10000 simulations.:  52%|█████▏    | 5214/10000 [00:22<00:19, 239.61it/s]Running 10000 simulations.:  52%|█████▏    | 5238/10000 [00:22<00:20, 236.15it/s]Running 10000 simulations.:  53%|█████▎    | 5263/10000 [00:22<00:19, 237.67it/s]Running 10000 simulations.:  53%|█████▎    | 5288/10000 [00:22<00:19, 238.57it/s]Running 10000 simulations.:  53%|█████▎    | 5313/10000 [00:22<00:19, 239.76it/s]Running 10000 simulations.:  53%|█████▎    | 5338/10000 [00:22<00:19, 240.67it/s]Running 10000 simulations.:  54%|█████▎    | 5363/10000 [00:22<00:19, 240.55it/s]Running 10000 simulations.:  54%|█████▍    | 5388/10000 [00:22<00:19, 238.86it/s]Running 10000 simulations.:  54%|█████▍    | 5413/10000 [00:22<00:19, 239.92it/s]Running 10000 simulations.:  54%|█████▍    | 5438/10000 [00:22<00:18, 240.95it/s]Running 10000 simulations.:  55%|█████▍    | 5463/10000 [00:23<00:18, 241.77it/s]Running 10000 simulations.:  55%|█████▍    | 5488/10000 [00:23<00:18, 241.78it/s]Running 10000 simulations.:  55%|█████▌    | 5513/10000 [00:23<00:18, 237.80it/s]Running 10000 simulations.:  55%|█████▌    | 5537/10000 [00:23<00:19, 233.91it/s]Running 10000 simulations.:  56%|█████▌    | 5561/10000 [00:23<00:18, 235.21it/s]Running 10000 simulations.:  56%|█████▌    | 5585/10000 [00:23<00:18, 236.62it/s]Running 10000 simulations.:  56%|█████▌    | 5610/10000 [00:23<00:18, 238.04it/s]Running 10000 simulations.:  56%|█████▋    | 5635/10000 [00:23<00:18, 239.57it/s]Running 10000 simulations.:  57%|█████▋    | 5660/10000 [00:23<00:18, 241.10it/s]Running 10000 simulations.:  57%|█████▋    | 5685/10000 [00:24<00:17, 241.46it/s]Running 10000 simulations.:  57%|█████▋    | 5710/10000 [00:24<00:17, 241.92it/s]Running 10000 simulations.:  57%|█████▋    | 5735/10000 [00:24<00:17, 239.89it/s]Running 10000 simulations.:  58%|█████▊    | 5759/10000 [00:24<00:17, 235.87it/s]Running 10000 simulations.:  58%|█████▊    | 5783/10000 [00:24<00:17, 235.82it/s]Running 10000 simulations.:  58%|█████▊    | 5808/10000 [00:24<00:17, 237.66it/s]Running 10000 simulations.:  58%|█████▊    | 5833/10000 [00:24<00:17, 238.47it/s]Running 10000 simulations.:  59%|█████▊    | 5858/10000 [00:24<00:17, 240.01it/s]Running 10000 simulations.:  59%|█████▉    | 5883/10000 [00:24<00:17, 240.63it/s]Running 10000 simulations.:  59%|█████▉    | 5908/10000 [00:24<00:16, 242.44it/s]Running 10000 simulations.:  59%|█████▉    | 5933/10000 [00:25<00:16, 242.96it/s]Running 10000 simulations.:  60%|█████▉    | 5958/10000 [00:25<00:16, 242.82it/s]Running 10000 simulations.:  60%|█████▉    | 5983/10000 [00:25<00:16, 238.36it/s]Running 10000 simulations.:  60%|██████    | 6007/10000 [00:25<00:17, 234.60it/s]Running 10000 simulations.:  60%|██████    | 6031/10000 [00:25<00:16, 235.47it/s]Running 10000 simulations.:  61%|██████    | 6056/10000 [00:25<00:16, 237.16it/s]Running 10000 simulations.:  61%|██████    | 6080/10000 [00:25<00:17, 227.90it/s]Running 10000 simulations.:  61%|██████    | 6105/10000 [00:25<00:16, 232.29it/s]Running 10000 simulations.:  61%|██████▏   | 6130/10000 [00:25<00:16, 235.18it/s]Running 10000 simulations.:  62%|██████▏   | 6154/10000 [00:26<00:16, 235.91it/s]Running 10000 simulations.:  62%|██████▏   | 6178/10000 [00:26<00:16, 234.96it/s]Running 10000 simulations.:  62%|██████▏   | 6202/10000 [00:26<00:16, 234.46it/s]Running 10000 simulations.:  62%|██████▏   | 6226/10000 [00:26<00:16, 232.14it/s]Running 10000 simulations.:  62%|██████▎   | 6250/10000 [00:26<00:16, 230.24it/s]Running 10000 simulations.:  63%|██████▎   | 6274/10000 [00:26<00:16, 228.78it/s]Running 10000 simulations.:  63%|██████▎   | 6297/10000 [00:26<00:16, 228.70it/s]Running 10000 simulations.:  63%|██████▎   | 6321/10000 [00:26<00:15, 231.80it/s]Running 10000 simulations.:  63%|██████▎   | 6346/10000 [00:26<00:15, 234.82it/s]Running 10000 simulations.:  64%|██████▎   | 6371/10000 [00:26<00:15, 237.10it/s]Running 10000 simulations.:  64%|██████▍   | 6396/10000 [00:27<00:15, 237.97it/s]Running 10000 simulations.:  64%|██████▍   | 6421/10000 [00:27<00:14, 238.96it/s]Running 10000 simulations.:  64%|██████▍   | 6446/10000 [00:27<00:14, 240.36it/s]Running 10000 simulations.:  65%|██████▍   | 6471/10000 [00:27<00:14, 239.83it/s]Running 10000 simulations.:  65%|██████▍   | 6495/10000 [00:27<00:14, 237.00it/s]Running 10000 simulations.:  65%|██████▌   | 6519/10000 [00:27<00:14, 233.43it/s]Running 10000 simulations.:  65%|██████▌   | 6543/10000 [00:27<00:15, 230.38it/s]Running 10000 simulations.:  66%|██████▌   | 6567/10000 [00:27<00:14, 230.60it/s]Running 10000 simulations.:  66%|██████▌   | 6591/10000 [00:27<00:14, 232.21it/s]Running 10000 simulations.:  66%|██████▌   | 6615/10000 [00:27<00:14, 233.28it/s]Running 10000 simulations.:  66%|██████▋   | 6639/10000 [00:28<00:14, 234.80it/s]Running 10000 simulations.:  67%|██████▋   | 6663/10000 [00:28<00:14, 235.93it/s]Running 10000 simulations.:  67%|██████▋   | 6687/10000 [00:28<00:13, 237.04it/s]Running 10000 simulations.:  67%|██████▋   | 6712/10000 [00:28<00:13, 238.60it/s]Running 10000 simulations.:  67%|██████▋   | 6736/10000 [00:28<00:13, 238.76it/s]Running 10000 simulations.:  68%|██████▊   | 6760/10000 [00:28<00:13, 235.87it/s]Running 10000 simulations.:  68%|██████▊   | 6784/10000 [00:28<00:13, 233.32it/s]Running 10000 simulations.:  68%|██████▊   | 6808/10000 [00:28<00:13, 234.53it/s]Running 10000 simulations.:  68%|██████▊   | 6832/10000 [00:28<00:13, 235.62it/s]Running 10000 simulations.:  69%|██████▊   | 6856/10000 [00:28<00:13, 236.50it/s]Running 10000 simulations.:  69%|██████▉   | 6881/10000 [00:29<00:13, 238.20it/s]Running 10000 simulations.:  69%|██████▉   | 6905/10000 [00:29<00:12, 238.38it/s]Running 10000 simulations.:  69%|██████▉   | 6930/10000 [00:29<00:12, 239.55it/s]Running 10000 simulations.:  70%|██████▉   | 6955/10000 [00:29<00:12, 240.69it/s]Running 10000 simulations.:  70%|██████▉   | 6980/10000 [00:29<00:12, 238.29it/s]Running 10000 simulations.:  70%|███████   | 7004/10000 [00:29<00:12, 234.19it/s]Running 10000 simulations.:  70%|███████   | 7028/10000 [00:29<00:12, 230.73it/s]Running 10000 simulations.:  71%|███████   | 7052/10000 [00:29<00:12, 228.51it/s]Running 10000 simulations.:  71%|███████   | 7076/10000 [00:29<00:12, 231.03it/s]Running 10000 simulations.:  71%|███████   | 7100/10000 [00:30<00:12, 232.60it/s]Running 10000 simulations.:  71%|███████   | 7124/10000 [00:30<00:12, 234.68it/s]Running 10000 simulations.:  71%|███████▏  | 7149/10000 [00:30<00:12, 237.00it/s]Running 10000 simulations.:  72%|███████▏  | 7174/10000 [00:30<00:11, 238.25it/s]Running 10000 simulations.:  72%|███████▏  | 7199/10000 [00:30<00:11, 239.68it/s]Running 10000 simulations.:  72%|███████▏  | 7224/10000 [00:30<00:11, 240.52it/s]Running 10000 simulations.:  72%|███████▏  | 7249/10000 [00:30<00:11, 238.87it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:30<00:11, 234.41it/s]Running 10000 simulations.:  73%|███████▎  | 7297/10000 [00:30<00:11, 233.05it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:30<00:11, 233.85it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:31<00:11, 234.34it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:31<00:11, 233.59it/s]Running 10000 simulations.:  74%|███████▍  | 7393/10000 [00:31<00:11, 233.33it/s]Running 10000 simulations.:  74%|███████▍  | 7417/10000 [00:31<00:11, 233.84it/s]Running 10000 simulations.:  74%|███████▍  | 7442/10000 [00:31<00:10, 236.12it/s]Running 10000 simulations.:  75%|███████▍  | 7467/10000 [00:31<00:10, 237.94it/s]Running 10000 simulations.:  75%|███████▍  | 7492/10000 [00:31<00:10, 238.88it/s]Running 10000 simulations.:  75%|███████▌  | 7517/10000 [00:31<00:10, 240.11it/s]Running 10000 simulations.:  75%|███████▌  | 7542/10000 [00:31<00:10, 240.18it/s]Running 10000 simulations.:  76%|███████▌  | 7567/10000 [00:32<00:10, 234.02it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:32<00:10, 230.80it/s]Running 10000 simulations.:  76%|███████▌  | 7615/10000 [00:32<00:10, 232.86it/s]Running 10000 simulations.:  76%|███████▋  | 7639/10000 [00:32<00:10, 233.58it/s]Running 10000 simulations.:  77%|███████▋  | 7663/10000 [00:32<00:09, 235.40it/s]Running 10000 simulations.:  77%|███████▋  | 7687/10000 [00:32<00:09, 236.17it/s]Running 10000 simulations.:  77%|███████▋  | 7711/10000 [00:32<00:09, 236.82it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:32<00:09, 238.29it/s]Running 10000 simulations.:  78%|███████▊  | 7761/10000 [00:32<00:09, 239.56it/s]Running 10000 simulations.:  78%|███████▊  | 7785/10000 [00:32<00:09, 235.30it/s]Running 10000 simulations.:  78%|███████▊  | 7809/10000 [00:33<00:09, 230.10it/s]Running 10000 simulations.:  78%|███████▊  | 7833/10000 [00:33<00:09, 227.98it/s]Running 10000 simulations.:  79%|███████▊  | 7856/10000 [00:33<00:09, 228.01it/s]Running 10000 simulations.:  79%|███████▉  | 7880/10000 [00:33<00:09, 230.14it/s]Running 10000 simulations.:  79%|███████▉  | 7904/10000 [00:33<00:09, 232.70it/s]Running 10000 simulations.:  79%|███████▉  | 7928/10000 [00:33<00:08, 234.58it/s]Running 10000 simulations.:  80%|███████▉  | 7952/10000 [00:33<00:08, 235.91it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:33<00:08, 236.54it/s]Running 10000 simulations.:  80%|████████  | 8000/10000 [00:33<00:08, 236.39it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:33<00:08, 232.23it/s]Running 10000 simulations.:  80%|████████  | 8048/10000 [00:34<00:08, 231.42it/s]Running 10000 simulations.:  81%|████████  | 8072/10000 [00:34<00:08, 232.58it/s]Running 10000 simulations.:  81%|████████  | 8096/10000 [00:34<00:08, 233.81it/s]Running 10000 simulations.:  81%|████████  | 8120/10000 [00:34<00:07, 235.52it/s]Running 10000 simulations.:  81%|████████▏ | 8144/10000 [00:34<00:07, 236.35it/s]Running 10000 simulations.:  82%|████████▏ | 8168/10000 [00:34<00:07, 235.88it/s]Running 10000 simulations.:  82%|████████▏ | 8193/10000 [00:34<00:07, 237.06it/s]Running 10000 simulations.:  82%|████████▏ | 8217/10000 [00:34<00:07, 237.09it/s]Running 10000 simulations.:  82%|████████▏ | 8241/10000 [00:34<00:07, 234.34it/s]Running 10000 simulations.:  83%|████████▎ | 8265/10000 [00:34<00:07, 230.82it/s]Running 10000 simulations.:  83%|████████▎ | 8289/10000 [00:35<00:07, 233.17it/s]Running 10000 simulations.:  83%|████████▎ | 8313/10000 [00:35<00:07, 234.86it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:35<00:07, 234.91it/s]Running 10000 simulations.:  84%|████████▎ | 8361/10000 [00:35<00:06, 234.32it/s]Running 10000 simulations.:  84%|████████▍ | 8385/10000 [00:35<00:06, 233.90it/s]Running 10000 simulations.:  84%|████████▍ | 8409/10000 [00:35<00:06, 234.54it/s]Running 10000 simulations.:  84%|████████▍ | 8433/10000 [00:35<00:06, 235.63it/s]Running 10000 simulations.:  85%|████████▍ | 8457/10000 [00:35<00:06, 234.01it/s]Running 10000 simulations.:  85%|████████▍ | 8481/10000 [00:35<00:06, 226.39it/s]Running 10000 simulations.:  85%|████████▌ | 8504/10000 [00:36<00:06, 225.69it/s]Running 10000 simulations.:  85%|████████▌ | 8528/10000 [00:36<00:06, 228.68it/s]Running 10000 simulations.:  86%|████████▌ | 8553/10000 [00:36<00:06, 231.95it/s]Running 10000 simulations.:  86%|████████▌ | 8577/10000 [00:36<00:06, 234.01it/s]Running 10000 simulations.:  86%|████████▌ | 8602/10000 [00:36<00:05, 236.79it/s]Running 10000 simulations.:  86%|████████▋ | 8627/10000 [00:36<00:05, 238.38it/s]Running 10000 simulations.:  87%|████████▋ | 8652/10000 [00:36<00:05, 239.64it/s]Running 10000 simulations.:  87%|████████▋ | 8677/10000 [00:36<00:05, 239.97it/s]Running 10000 simulations.:  87%|████████▋ | 8702/10000 [00:36<00:05, 236.92it/s]Running 10000 simulations.:  87%|████████▋ | 8726/10000 [00:36<00:05, 232.92it/s]Running 10000 simulations.:  88%|████████▊ | 8750/10000 [00:37<00:05, 234.43it/s]Running 10000 simulations.:  88%|████████▊ | 8774/10000 [00:37<00:05, 235.92it/s]Running 10000 simulations.:  88%|████████▊ | 8799/10000 [00:37<00:05, 237.31it/s]Running 10000 simulations.:  88%|████████▊ | 8824/10000 [00:37<00:04, 238.75it/s]Running 10000 simulations.:  88%|████████▊ | 8849/10000 [00:37<00:04, 239.78it/s]Running 10000 simulations.:  89%|████████▊ | 8874/10000 [00:37<00:04, 240.39it/s]Running 10000 simulations.:  89%|████████▉ | 8899/10000 [00:37<00:04, 240.37it/s]Running 10000 simulations.:  89%|████████▉ | 8924/10000 [00:37<00:04, 237.07it/s]Running 10000 simulations.:  89%|████████▉ | 8948/10000 [00:37<00:04, 233.50it/s]Running 10000 simulations.:  90%|████████▉ | 8972/10000 [00:37<00:04, 234.28it/s]Running 10000 simulations.:  90%|████████▉ | 8997/10000 [00:38<00:04, 236.29it/s]Running 10000 simulations.:  90%|█████████ | 9021/10000 [00:38<00:04, 236.70it/s]Running 10000 simulations.:  90%|█████████ | 9046/10000 [00:38<00:03, 238.97it/s]Running 10000 simulations.:  91%|█████████ | 9071/10000 [00:38<00:03, 239.96it/s]Running 10000 simulations.:  91%|█████████ | 9096/10000 [00:38<00:03, 238.00it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:38<00:03, 236.66it/s]Running 10000 simulations.:  91%|█████████▏| 9145/10000 [00:38<00:03, 237.74it/s]Running 10000 simulations.:  92%|█████████▏| 9170/10000 [00:38<00:03, 239.40it/s]Running 10000 simulations.:  92%|█████████▏| 9195/10000 [00:38<00:03, 240.16it/s]Running 10000 simulations.:  92%|█████████▏| 9220/10000 [00:39<00:03, 238.57it/s]Running 10000 simulations.:  92%|█████████▏| 9244/10000 [00:39<00:03, 232.46it/s]Running 10000 simulations.:  93%|█████████▎| 9268/10000 [00:39<00:03, 232.72it/s]Running 10000 simulations.:  93%|█████████▎| 9292/10000 [00:39<00:03, 234.79it/s]Running 10000 simulations.:  93%|█████████▎| 9317/10000 [00:39<00:02, 236.46it/s]Running 10000 simulations.:  93%|█████████▎| 9342/10000 [00:39<00:02, 238.64it/s]Running 10000 simulations.:  94%|█████████▎| 9366/10000 [00:39<00:02, 238.28it/s]Running 10000 simulations.:  94%|█████████▍| 9391/10000 [00:39<00:02, 239.53it/s]Running 10000 simulations.:  94%|█████████▍| 9416/10000 [00:39<00:02, 239.86it/s]Running 10000 simulations.:  94%|█████████▍| 9441/10000 [00:39<00:02, 240.65it/s]Running 10000 simulations.:  95%|█████████▍| 9466/10000 [00:40<00:02, 236.47it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [00:40<00:02, 233.15it/s]Running 10000 simulations.:  95%|█████████▌| 9514/10000 [00:40<00:02, 234.78it/s]Running 10000 simulations.:  95%|█████████▌| 9539/10000 [00:40<00:01, 236.90it/s]Running 10000 simulations.:  96%|█████████▌| 9564/10000 [00:40<00:01, 238.07it/s]Running 10000 simulations.:  96%|█████████▌| 9589/10000 [00:40<00:01, 239.89it/s]Running 10000 simulations.:  96%|█████████▌| 9614/10000 [00:40<00:01, 240.86it/s]Running 10000 simulations.:  96%|█████████▋| 9639/10000 [00:40<00:01, 242.58it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [00:40<00:01, 243.38it/s]Running 10000 simulations.:  97%|█████████▋| 9689/10000 [00:41<00:01, 240.50it/s]Running 10000 simulations.:  97%|█████████▋| 9714/10000 [00:41<00:01, 235.42it/s]Running 10000 simulations.:  97%|█████████▋| 9738/10000 [00:41<00:01, 233.17it/s]Running 10000 simulations.:  98%|█████████▊| 9762/10000 [00:41<00:01, 231.86it/s]Running 10000 simulations.:  98%|█████████▊| 9787/10000 [00:41<00:00, 235.47it/s]Running 10000 simulations.:  98%|█████████▊| 9812/10000 [00:41<00:00, 237.82it/s]Running 10000 simulations.:  98%|█████████▊| 9837/10000 [00:41<00:00, 239.61it/s]Running 10000 simulations.:  99%|█████████▊| 9862/10000 [00:41<00:00, 241.99it/s]Running 10000 simulations.:  99%|█████████▉| 9887/10000 [00:41<00:00, 243.52it/s]Running 10000 simulations.:  99%|█████████▉| 9912/10000 [00:41<00:00, 244.47it/s]Running 10000 simulations.:  99%|█████████▉| 9937/10000 [00:42<00:00, 245.89it/s]Running 10000 simulations.: 100%|█████████▉| 9962/10000 [00:42<00:00, 242.95it/s]Running 10000 simulations.: 100%|█████████▉| 9987/10000 [00:42<00:00, 239.27it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 236.39it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 252.45it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 252.92it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:39, 252.30it/s]Running 10000 simulations.:   1%|          | 103/10000 [00:00<00:39, 250.54it/s]Running 10000 simulations.:   1%|▏         | 127/10000 [00:00<00:40, 246.22it/s]Running 10000 simulations.:   2%|▏         | 152/10000 [00:00<00:40, 244.48it/s]Running 10000 simulations.:   2%|▏         | 177/10000 [00:00<00:39, 245.66it/s]Running 10000 simulations.:   2%|▏         | 202/10000 [00:00<00:39, 245.86it/s]Running 10000 simulations.:   2%|▏         | 227/10000 [00:00<00:39, 246.88it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:01<00:39, 246.80it/s]Running 10000 simulations.:   3%|▎         | 277/10000 [00:01<00:39, 246.32it/s]Running 10000 simulations.:   3%|▎         | 302/10000 [00:01<00:39, 246.24it/s]Running 10000 simulations.:   3%|▎         | 327/10000 [00:01<00:39, 245.61it/s]Running 10000 simulations.:   4%|▎         | 352/10000 [00:01<00:40, 240.95it/s]Running 10000 simulations.:   4%|▍         | 376/10000 [00:01<00:40, 237.64it/s]Running 10000 simulations.:   4%|▍         | 400/10000 [00:01<00:40, 234.86it/s]Running 10000 simulations.:   4%|▍         | 424/10000 [00:01<00:40, 234.04it/s]Running 10000 simulations.:   4%|▍         | 449/10000 [00:01<00:40, 236.24it/s]Running 10000 simulations.:   5%|▍         | 474/10000 [00:01<00:40, 237.82it/s]Running 10000 simulations.:   5%|▍         | 499/10000 [00:02<00:39, 239.32it/s]Running 10000 simulations.:   5%|▌         | 524/10000 [00:02<00:39, 240.28it/s]Running 10000 simulations.:   5%|▌         | 549/10000 [00:02<00:39, 241.57it/s]Running 10000 simulations.:   6%|▌         | 574/10000 [00:02<00:38, 242.95it/s]Running 10000 simulations.:   6%|▌         | 599/10000 [00:02<00:38, 242.76it/s]Running 10000 simulations.:   6%|▌         | 624/10000 [00:02<00:39, 237.81it/s]Running 10000 simulations.:   6%|▋         | 648/10000 [00:02<00:40, 233.14it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:02<00:40, 230.21it/s]Running 10000 simulations.:   7%|▋         | 696/10000 [00:02<00:40, 230.34it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:02<00:39, 233.11it/s]Running 10000 simulations.:   7%|▋         | 745/10000 [00:03<00:39, 236.06it/s]Running 10000 simulations.:   8%|▊         | 770/10000 [00:03<00:38, 238.56it/s]Running 10000 simulations.:   8%|▊         | 795/10000 [00:03<00:38, 239.34it/s]Running 10000 simulations.:   8%|▊         | 820/10000 [00:03<00:38, 240.36it/s]Running 10000 simulations.:   8%|▊         | 845/10000 [00:03<00:37, 241.34it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:03<00:38, 239.54it/s]Running 10000 simulations.:   9%|▉         | 894/10000 [00:03<00:38, 235.66it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:03<00:38, 233.06it/s]Running 10000 simulations.:   9%|▉         | 942/10000 [00:03<00:39, 231.92it/s]Running 10000 simulations.:  10%|▉         | 966/10000 [00:04<00:38, 233.50it/s]Running 10000 simulations.:  10%|▉         | 991/10000 [00:04<00:38, 236.20it/s]Running 10000 simulations.:  10%|█         | 1016/10000 [00:04<00:37, 237.63it/s]Running 10000 simulations.:  10%|█         | 1041/10000 [00:04<00:37, 238.87it/s]Running 10000 simulations.:  11%|█         | 1065/10000 [00:04<00:37, 238.98it/s]Running 10000 simulations.:  11%|█         | 1090/10000 [00:04<00:37, 239.73it/s]Running 10000 simulations.:  11%|█         | 1115/10000 [00:04<00:36, 241.32it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:04<00:37, 237.92it/s]Running 10000 simulations.:  12%|█▏        | 1164/10000 [00:04<00:37, 234.31it/s]Running 10000 simulations.:  12%|█▏        | 1188/10000 [00:04<00:37, 235.34it/s]Running 10000 simulations.:  12%|█▏        | 1213/10000 [00:05<00:37, 236.87it/s]Running 10000 simulations.:  12%|█▏        | 1237/10000 [00:05<00:36, 237.40it/s]Running 10000 simulations.:  13%|█▎        | 1262/10000 [00:05<00:36, 239.11it/s]Running 10000 simulations.:  13%|█▎        | 1286/10000 [00:05<00:36, 239.29it/s]Running 10000 simulations.:  13%|█▎        | 1311/10000 [00:05<00:36, 240.35it/s]Running 10000 simulations.:  13%|█▎        | 1336/10000 [00:05<00:35, 241.93it/s]Running 10000 simulations.:  14%|█▎        | 1361/10000 [00:05<00:36, 238.64it/s]Running 10000 simulations.:  14%|█▍        | 1385/10000 [00:05<00:36, 234.61it/s]Running 10000 simulations.:  14%|█▍        | 1409/10000 [00:05<00:36, 235.03it/s]Running 10000 simulations.:  14%|█▍        | 1434/10000 [00:05<00:36, 236.69it/s]Running 10000 simulations.:  15%|█▍        | 1458/10000 [00:06<00:36, 237.21it/s]Running 10000 simulations.:  15%|█▍        | 1482/10000 [00:06<00:36, 235.44it/s]Running 10000 simulations.:  15%|█▌        | 1506/10000 [00:06<00:36, 235.42it/s]Running 10000 simulations.:  15%|█▌        | 1531/10000 [00:06<00:35, 237.24it/s]Running 10000 simulations.:  16%|█▌        | 1556/10000 [00:06<00:35, 239.52it/s]Running 10000 simulations.:  16%|█▌        | 1580/10000 [00:06<00:35, 237.38it/s]Running 10000 simulations.:  16%|█▌        | 1604/10000 [00:06<00:36, 232.77it/s]Running 10000 simulations.:  16%|█▋        | 1628/10000 [00:06<00:35, 234.30it/s]Running 10000 simulations.:  17%|█▋        | 1653/10000 [00:06<00:35, 236.65it/s]Running 10000 simulations.:  17%|█▋        | 1678/10000 [00:07<00:34, 237.86it/s]Running 10000 simulations.:  17%|█▋        | 1702/10000 [00:07<00:34, 238.32it/s]Running 10000 simulations.:  17%|█▋        | 1727/10000 [00:07<00:34, 239.08it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:07<00:34, 237.32it/s]Running 10000 simulations.:  18%|█▊        | 1775/10000 [00:07<00:34, 237.19it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:07<00:34, 236.38it/s]Running 10000 simulations.:  18%|█▊        | 1823/10000 [00:07<00:34, 234.90it/s]Running 10000 simulations.:  18%|█▊        | 1847/10000 [00:07<00:34, 234.81it/s]Running 10000 simulations.:  19%|█▊        | 1871/10000 [00:07<00:34, 232.78it/s]Running 10000 simulations.:  19%|█▉        | 1895/10000 [00:07<00:35, 228.51it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:08<00:35, 228.29it/s]Running 10000 simulations.:  19%|█▉        | 1942/10000 [00:08<00:34, 231.50it/s]Running 10000 simulations.:  20%|█▉        | 1966/10000 [00:08<00:34, 233.98it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:08<00:33, 235.90it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:08<00:33, 237.24it/s]Running 10000 simulations.:  20%|██        | 2041/10000 [00:08<00:33, 238.09it/s]Running 10000 simulations.:  21%|██        | 2066/10000 [00:08<00:33, 239.38it/s]Running 10000 simulations.:  21%|██        | 2090/10000 [00:08<00:33, 239.55it/s]Running 10000 simulations.:  21%|██        | 2114/10000 [00:08<00:33, 235.20it/s]Running 10000 simulations.:  21%|██▏       | 2138/10000 [00:08<00:33, 231.84it/s]Running 10000 simulations.:  22%|██▏       | 2162/10000 [00:09<00:34, 229.78it/s]Running 10000 simulations.:  22%|██▏       | 2186/10000 [00:09<00:33, 230.66it/s]Running 10000 simulations.:  22%|██▏       | 2211/10000 [00:09<00:33, 233.54it/s]Running 10000 simulations.:  22%|██▏       | 2236/10000 [00:09<00:32, 235.73it/s]Running 10000 simulations.:  23%|██▎       | 2261/10000 [00:09<00:32, 237.63it/s]Running 10000 simulations.:  23%|██▎       | 2286/10000 [00:09<00:32, 238.66it/s]Running 10000 simulations.:  23%|██▎       | 2311/10000 [00:09<00:32, 239.18it/s]Running 10000 simulations.:  23%|██▎       | 2336/10000 [00:09<00:31, 240.99it/s]Running 10000 simulations.:  24%|██▎       | 2361/10000 [00:09<00:32, 238.35it/s]Running 10000 simulations.:  24%|██▍       | 2385/10000 [00:10<00:32, 235.30it/s]Running 10000 simulations.:  24%|██▍       | 2409/10000 [00:10<00:32, 233.15it/s]Running 10000 simulations.:  24%|██▍       | 2433/10000 [00:10<00:32, 233.99it/s]Running 10000 simulations.:  25%|██▍       | 2457/10000 [00:10<00:32, 235.51it/s]Running 10000 simulations.:  25%|██▍       | 2481/10000 [00:10<00:31, 236.77it/s]Running 10000 simulations.:  25%|██▌       | 2505/10000 [00:10<00:31, 237.38it/s]Running 10000 simulations.:  25%|██▌       | 2529/10000 [00:10<00:31, 237.54it/s]Running 10000 simulations.:  26%|██▌       | 2554/10000 [00:10<00:31, 238.39it/s]Running 10000 simulations.:  26%|██▌       | 2579/10000 [00:10<00:30, 240.04it/s]Running 10000 simulations.:  26%|██▌       | 2604/10000 [00:10<00:31, 236.85it/s]Running 10000 simulations.:  26%|██▋       | 2628/10000 [00:11<00:31, 232.76it/s]Running 10000 simulations.:  27%|██▋       | 2652/10000 [00:11<00:31, 233.15it/s]Running 10000 simulations.:  27%|██▋       | 2676/10000 [00:11<00:31, 234.46it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:11<00:31, 234.66it/s]Running 10000 simulations.:  27%|██▋       | 2725/10000 [00:11<00:30, 236.31it/s]Running 10000 simulations.:  27%|██▋       | 2749/10000 [00:11<00:30, 236.75it/s]Running 10000 simulations.:  28%|██▊       | 2773/10000 [00:11<00:30, 237.25it/s]Running 10000 simulations.:  28%|██▊       | 2797/10000 [00:11<00:30, 237.88it/s]Running 10000 simulations.:  28%|██▊       | 2821/10000 [00:11<00:30, 232.95it/s]Running 10000 simulations.:  28%|██▊       | 2845/10000 [00:11<00:31, 225.92it/s]Running 10000 simulations.:  29%|██▊       | 2868/10000 [00:12<00:31, 226.56it/s]Running 10000 simulations.:  29%|██▉       | 2892/10000 [00:12<00:30, 229.78it/s]Running 10000 simulations.:  29%|██▉       | 2916/10000 [00:12<00:30, 232.00it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:12<00:30, 234.19it/s]Running 10000 simulations.:  30%|██▉       | 2964/10000 [00:12<00:29, 235.64it/s]Running 10000 simulations.:  30%|██▉       | 2988/10000 [00:12<00:29, 235.92it/s]Running 10000 simulations.:  30%|███       | 3012/10000 [00:12<00:29, 236.32it/s]Running 10000 simulations.:  30%|███       | 3036/10000 [00:12<00:29, 236.13it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:12<00:29, 233.51it/s]Running 10000 simulations.:  31%|███       | 3084/10000 [00:13<00:30, 230.48it/s]Running 10000 simulations.:  31%|███       | 3108/10000 [00:13<00:30, 229.26it/s]Running 10000 simulations.:  31%|███▏      | 3132/10000 [00:13<00:29, 230.19it/s]Running 10000 simulations.:  32%|███▏      | 3156/10000 [00:13<00:29, 232.00it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:13<00:29, 233.90it/s]Running 10000 simulations.:  32%|███▏      | 3204/10000 [00:13<00:28, 234.94it/s]Running 10000 simulations.:  32%|███▏      | 3228/10000 [00:13<00:28, 235.77it/s]Running 10000 simulations.:  33%|███▎      | 3252/10000 [00:13<00:28, 236.64it/s]Running 10000 simulations.:  33%|███▎      | 3276/10000 [00:13<00:28, 237.52it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:13<00:28, 237.28it/s]Running 10000 simulations.:  33%|███▎      | 3324/10000 [00:14<00:28, 234.40it/s]Running 10000 simulations.:  33%|███▎      | 3348/10000 [00:14<00:28, 231.53it/s]Running 10000 simulations.:  34%|███▎      | 3372/10000 [00:14<00:28, 229.48it/s]Running 10000 simulations.:  34%|███▍      | 3396/10000 [00:14<00:28, 230.06it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:14<00:28, 232.25it/s]Running 10000 simulations.:  34%|███▍      | 3444/10000 [00:14<00:28, 234.07it/s]Running 10000 simulations.:  35%|███▍      | 3469/10000 [00:14<00:27, 235.97it/s]Running 10000 simulations.:  35%|███▍      | 3493/10000 [00:14<00:27, 237.10it/s]Running 10000 simulations.:  35%|███▌      | 3518/10000 [00:14<00:27, 238.92it/s]Running 10000 simulations.:  35%|███▌      | 3543/10000 [00:14<00:26, 239.45it/s]Running 10000 simulations.:  36%|███▌      | 3567/10000 [00:15<00:27, 236.92it/s]Running 10000 simulations.:  36%|███▌      | 3591/10000 [00:15<00:27, 233.59it/s]Running 10000 simulations.:  36%|███▌      | 3615/10000 [00:15<00:27, 230.73it/s]Running 10000 simulations.:  36%|███▋      | 3639/10000 [00:15<00:27, 230.28it/s]Running 10000 simulations.:  37%|███▋      | 3663/10000 [00:15<00:27, 230.41it/s]Running 10000 simulations.:  37%|███▋      | 3687/10000 [00:15<00:27, 232.62it/s]Running 10000 simulations.:  37%|███▋      | 3711/10000 [00:15<00:26, 233.79it/s]Running 10000 simulations.:  37%|███▋      | 3736/10000 [00:15<00:26, 236.04it/s]Running 10000 simulations.:  38%|███▊      | 3761/10000 [00:15<00:26, 237.60it/s]Running 10000 simulations.:  38%|███▊      | 3785/10000 [00:16<00:26, 237.35it/s]Running 10000 simulations.:  38%|███▊      | 3809/10000 [00:16<00:26, 235.59it/s]Running 10000 simulations.:  38%|███▊      | 3834/10000 [00:16<00:25, 237.21it/s]Running 10000 simulations.:  39%|███▊      | 3859/10000 [00:16<00:25, 238.65it/s]Running 10000 simulations.:  39%|███▉      | 3883/10000 [00:16<00:25, 238.87it/s]Running 10000 simulations.:  39%|███▉      | 3907/10000 [00:16<00:25, 237.03it/s]Running 10000 simulations.:  39%|███▉      | 3931/10000 [00:16<00:25, 234.42it/s]Running 10000 simulations.:  40%|███▉      | 3955/10000 [00:16<00:26, 231.44it/s]Running 10000 simulations.:  40%|███▉      | 3979/10000 [00:16<00:26, 229.07it/s]Running 10000 simulations.:  40%|████      | 4003/10000 [00:16<00:26, 229.42it/s]Running 10000 simulations.:  40%|████      | 4027/10000 [00:17<00:25, 231.55it/s]Running 10000 simulations.:  41%|████      | 4051/10000 [00:17<00:25, 233.46it/s]Running 10000 simulations.:  41%|████      | 4075/10000 [00:17<00:25, 234.09it/s]Running 10000 simulations.:  41%|████      | 4099/10000 [00:17<00:25, 234.74it/s]Running 10000 simulations.:  41%|████      | 4123/10000 [00:17<00:24, 236.01it/s]Running 10000 simulations.:  41%|████▏     | 4147/10000 [00:17<00:24, 237.12it/s]Running 10000 simulations.:  42%|████▏     | 4171/10000 [00:17<00:24, 237.07it/s]Running 10000 simulations.:  42%|████▏     | 4195/10000 [00:17<00:24, 234.06it/s]Running 10000 simulations.:  42%|████▏     | 4219/10000 [00:17<00:25, 230.22it/s]Running 10000 simulations.:  42%|████▏     | 4243/10000 [00:17<00:25, 227.67it/s]Running 10000 simulations.:  43%|████▎     | 4266/10000 [00:18<00:25, 227.68it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:18<00:24, 229.94it/s]Running 10000 simulations.:  43%|████▎     | 4314/10000 [00:18<00:24, 231.82it/s]Running 10000 simulations.:  43%|████▎     | 4338/10000 [00:18<00:24, 233.50it/s]Running 10000 simulations.:  44%|████▎     | 4362/10000 [00:18<00:24, 234.69it/s]Running 10000 simulations.:  44%|████▍     | 4386/10000 [00:18<00:23, 235.59it/s]Running 10000 simulations.:  44%|████▍     | 4410/10000 [00:18<00:23, 236.84it/s]Running 10000 simulations.:  44%|████▍     | 4434/10000 [00:18<00:23, 236.39it/s]Running 10000 simulations.:  45%|████▍     | 4458/10000 [00:18<00:23, 232.49it/s]Running 10000 simulations.:  45%|████▍     | 4482/10000 [00:18<00:24, 228.93it/s]Running 10000 simulations.:  45%|████▌     | 4506/10000 [00:19<00:23, 230.34it/s]Running 10000 simulations.:  45%|████▌     | 4530/10000 [00:19<00:23, 231.69it/s]Running 10000 simulations.:  46%|████▌     | 4554/10000 [00:19<00:23, 232.76it/s]Running 10000 simulations.:  46%|████▌     | 4578/10000 [00:19<00:23, 233.99it/s]Running 10000 simulations.:  46%|████▌     | 4603/10000 [00:19<00:22, 235.77it/s]Running 10000 simulations.:  46%|████▋     | 4627/10000 [00:19<00:22, 236.92it/s]Running 10000 simulations.:  47%|████▋     | 4651/10000 [00:19<00:23, 226.32it/s]Running 10000 simulations.:  47%|████▋     | 4674/10000 [00:19<00:23, 224.63it/s]Running 10000 simulations.:  47%|████▋     | 4697/10000 [00:19<00:23, 225.66it/s]Running 10000 simulations.:  47%|████▋     | 4721/10000 [00:20<00:23, 228.51it/s]Running 10000 simulations.:  47%|████▋     | 4745/10000 [00:20<00:22, 230.89it/s]Running 10000 simulations.:  48%|████▊     | 4769/10000 [00:20<00:22, 232.69it/s]Running 10000 simulations.:  48%|████▊     | 4793/10000 [00:20<00:22, 233.93it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:20<00:22, 235.08it/s]Running 10000 simulations.:  48%|████▊     | 4841/10000 [00:20<00:21, 236.17it/s]Running 10000 simulations.:  49%|████▊     | 4865/10000 [00:20<00:21, 236.22it/s]Running 10000 simulations.:  49%|████▉     | 4889/10000 [00:20<00:21, 233.68it/s]Running 10000 simulations.:  49%|████▉     | 4913/10000 [00:20<00:22, 229.42it/s]Running 10000 simulations.:  49%|████▉     | 4936/10000 [00:20<00:22, 229.09it/s]Running 10000 simulations.:  50%|████▉     | 4960/10000 [00:21<00:21, 230.78it/s]Running 10000 simulations.:  50%|████▉     | 4984/10000 [00:21<00:21, 232.34it/s]Running 10000 simulations.:  50%|█████     | 5008/10000 [00:21<00:21, 234.43it/s]Running 10000 simulations.:  50%|█████     | 5032/10000 [00:21<00:21, 235.37it/s]Running 10000 simulations.:  51%|█████     | 5057/10000 [00:21<00:20, 236.88it/s]Running 10000 simulations.:  51%|█████     | 5081/10000 [00:21<00:20, 237.42it/s]Running 10000 simulations.:  51%|█████     | 5105/10000 [00:21<00:20, 234.59it/s]Running 10000 simulations.:  51%|█████▏    | 5129/10000 [00:21<00:20, 232.27it/s]Running 10000 simulations.:  52%|█████▏    | 5153/10000 [00:21<00:20, 232.77it/s]Running 10000 simulations.:  52%|█████▏    | 5177/10000 [00:21<00:20, 232.80it/s]Running 10000 simulations.:  52%|█████▏    | 5201/10000 [00:22<00:20, 232.85it/s]Running 10000 simulations.:  52%|█████▏    | 5226/10000 [00:22<00:20, 235.39it/s]Running 10000 simulations.:  53%|█████▎    | 5251/10000 [00:22<00:20, 237.16it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:22<00:19, 239.38it/s]Running 10000 simulations.:  53%|█████▎    | 5301/10000 [00:22<00:19, 241.29it/s]Running 10000 simulations.:  53%|█████▎    | 5326/10000 [00:22<00:19, 238.75it/s]Running 10000 simulations.:  54%|█████▎    | 5350/10000 [00:22<00:19, 235.02it/s]Running 10000 simulations.:  54%|█████▎    | 5374/10000 [00:22<00:19, 235.39it/s]Running 10000 simulations.:  54%|█████▍    | 5399/10000 [00:22<00:19, 236.80it/s]Running 10000 simulations.:  54%|█████▍    | 5424/10000 [00:23<00:19, 237.83it/s]Running 10000 simulations.:  54%|█████▍    | 5449/10000 [00:23<00:18, 240.04it/s]Running 10000 simulations.:  55%|█████▍    | 5474/10000 [00:23<00:18, 239.98it/s]Running 10000 simulations.:  55%|█████▍    | 5499/10000 [00:23<00:18, 239.95it/s]Running 10000 simulations.:  55%|█████▌    | 5524/10000 [00:23<00:18, 240.31it/s]Running 10000 simulations.:  55%|█████▌    | 5549/10000 [00:23<00:18, 240.17it/s]Running 10000 simulations.:  56%|█████▌    | 5574/10000 [00:23<00:18, 236.30it/s]Running 10000 simulations.:  56%|█████▌    | 5598/10000 [00:23<00:18, 235.36it/s]Running 10000 simulations.:  56%|█████▌    | 5622/10000 [00:23<00:18, 236.55it/s]Running 10000 simulations.:  56%|█████▋    | 5646/10000 [00:23<00:18, 236.66it/s]Running 10000 simulations.:  57%|█████▋    | 5670/10000 [00:24<00:18, 237.14it/s]Running 10000 simulations.:  57%|█████▋    | 5695/10000 [00:24<00:18, 238.83it/s]Running 10000 simulations.:  57%|█████▋    | 5719/10000 [00:24<00:17, 239.08it/s]Running 10000 simulations.:  57%|█████▋    | 5743/10000 [00:24<00:17, 238.01it/s]Running 10000 simulations.:  58%|█████▊    | 5767/10000 [00:24<00:17, 238.10it/s]Running 10000 simulations.:  58%|█████▊    | 5791/10000 [00:24<00:17, 237.89it/s]Running 10000 simulations.:  58%|█████▊    | 5816/10000 [00:24<00:17, 238.76it/s]Running 10000 simulations.:  58%|█████▊    | 5841/10000 [00:24<00:17, 239.51it/s]Running 10000 simulations.:  59%|█████▊    | 5865/10000 [00:24<00:17, 234.31it/s]Running 10000 simulations.:  59%|█████▉    | 5889/10000 [00:24<00:17, 230.28it/s]Running 10000 simulations.:  59%|█████▉    | 5913/10000 [00:25<00:17, 231.40it/s]Running 10000 simulations.:  59%|█████▉    | 5937/10000 [00:25<00:17, 233.39it/s]Running 10000 simulations.:  60%|█████▉    | 5962/10000 [00:25<00:17, 235.86it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:25<00:16, 237.62it/s]Running 10000 simulations.:  60%|██████    | 6012/10000 [00:25<00:16, 239.75it/s]Running 10000 simulations.:  60%|██████    | 6037/10000 [00:25<00:16, 240.11it/s]Running 10000 simulations.:  61%|██████    | 6062/10000 [00:25<00:16, 241.03it/s]Running 10000 simulations.:  61%|██████    | 6087/10000 [00:25<00:16, 241.62it/s]Running 10000 simulations.:  61%|██████    | 6112/10000 [00:25<00:16, 239.15it/s]Running 10000 simulations.:  61%|██████▏   | 6136/10000 [00:26<00:16, 236.75it/s]Running 10000 simulations.:  62%|██████▏   | 6160/10000 [00:26<00:16, 234.86it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:26<00:16, 234.63it/s]Running 10000 simulations.:  62%|██████▏   | 6208/10000 [00:26<00:16, 235.63it/s]Running 10000 simulations.:  62%|██████▏   | 6232/10000 [00:26<00:15, 236.11it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:26<00:15, 238.17it/s]Running 10000 simulations.:  63%|██████▎   | 6282/10000 [00:26<00:15, 239.32it/s]Running 10000 simulations.:  63%|██████▎   | 6307/10000 [00:26<00:15, 240.26it/s]Running 10000 simulations.:  63%|██████▎   | 6332/10000 [00:26<00:15, 241.43it/s]Running 10000 simulations.:  64%|██████▎   | 6357/10000 [00:26<00:15, 241.21it/s]Running 10000 simulations.:  64%|██████▍   | 6382/10000 [00:27<00:15, 237.57it/s]Running 10000 simulations.:  64%|██████▍   | 6406/10000 [00:27<00:15, 235.83it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:27<00:15, 236.08it/s]Running 10000 simulations.:  65%|██████▍   | 6454/10000 [00:27<00:14, 237.10it/s]Running 10000 simulations.:  65%|██████▍   | 6479/10000 [00:27<00:14, 238.13it/s]Running 10000 simulations.:  65%|██████▌   | 6504/10000 [00:27<00:14, 239.31it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:27<00:14, 238.15it/s]Running 10000 simulations.:  66%|██████▌   | 6552/10000 [00:27<00:14, 237.53it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:27<00:14, 238.08it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:27<00:14, 235.63it/s]Running 10000 simulations.:  66%|██████▌   | 6624/10000 [00:28<00:14, 233.70it/s]Running 10000 simulations.:  66%|██████▋   | 6649/10000 [00:28<00:14, 235.80it/s]Running 10000 simulations.:  67%|██████▋   | 6673/10000 [00:28<00:14, 236.90it/s]Running 10000 simulations.:  67%|██████▋   | 6698/10000 [00:28<00:13, 238.51it/s]Running 10000 simulations.:  67%|██████▋   | 6723/10000 [00:28<00:13, 239.71it/s]Running 10000 simulations.:  67%|██████▋   | 6748/10000 [00:28<00:13, 239.86it/s]Running 10000 simulations.:  68%|██████▊   | 6773/10000 [00:28<00:13, 240.21it/s]Running 10000 simulations.:  68%|██████▊   | 6798/10000 [00:28<00:13, 240.71it/s]Running 10000 simulations.:  68%|██████▊   | 6823/10000 [00:28<00:13, 237.80it/s]Running 10000 simulations.:  68%|██████▊   | 6847/10000 [00:29<00:13, 231.97it/s]Running 10000 simulations.:  69%|██████▊   | 6871/10000 [00:29<00:13, 227.41it/s]Running 10000 simulations.:  69%|██████▉   | 6894/10000 [00:29<00:13, 225.71it/s]Running 10000 simulations.:  69%|██████▉   | 6919/10000 [00:29<00:13, 229.93it/s]Running 10000 simulations.:  69%|██████▉   | 6944/10000 [00:29<00:13, 233.17it/s]Running 10000 simulations.:  70%|██████▉   | 6969/10000 [00:29<00:12, 235.24it/s]Running 10000 simulations.:  70%|██████▉   | 6994/10000 [00:29<00:12, 237.39it/s]Running 10000 simulations.:  70%|███████   | 7019/10000 [00:29<00:12, 238.50it/s]Running 10000 simulations.:  70%|███████   | 7044/10000 [00:29<00:12, 239.57it/s]Running 10000 simulations.:  71%|███████   | 7069/10000 [00:29<00:12, 240.89it/s]Running 10000 simulations.:  71%|███████   | 7094/10000 [00:30<00:12, 237.56it/s]Running 10000 simulations.:  71%|███████   | 7118/10000 [00:30<00:12, 235.72it/s]Running 10000 simulations.:  71%|███████▏  | 7142/10000 [00:30<00:12, 234.21it/s]Running 10000 simulations.:  72%|███████▏  | 7166/10000 [00:30<00:12, 232.14it/s]Running 10000 simulations.:  72%|███████▏  | 7190/10000 [00:30<00:12, 233.43it/s]Running 10000 simulations.:  72%|███████▏  | 7214/10000 [00:30<00:11, 235.21it/s]Running 10000 simulations.:  72%|███████▏  | 7239/10000 [00:30<00:11, 237.12it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:30<00:11, 239.45it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:30<00:11, 240.62it/s]Running 10000 simulations.:  73%|███████▎  | 7314/10000 [00:30<00:11, 241.81it/s]Running 10000 simulations.:  73%|███████▎  | 7339/10000 [00:31<00:10, 242.46it/s]Running 10000 simulations.:  74%|███████▎  | 7364/10000 [00:31<00:10, 240.44it/s]Running 10000 simulations.:  74%|███████▍  | 7389/10000 [00:31<00:11, 235.20it/s]Running 10000 simulations.:  74%|███████▍  | 7413/10000 [00:31<00:11, 232.10it/s]Running 10000 simulations.:  74%|███████▍  | 7437/10000 [00:31<00:11, 230.48it/s]Running 10000 simulations.:  75%|███████▍  | 7461/10000 [00:31<00:10, 233.07it/s]Running 10000 simulations.:  75%|███████▍  | 7485/10000 [00:31<00:10, 235.09it/s]Running 10000 simulations.:  75%|███████▌  | 7510/10000 [00:31<00:10, 236.97it/s]Running 10000 simulations.:  75%|███████▌  | 7534/10000 [00:31<00:10, 237.61it/s]Running 10000 simulations.:  76%|███████▌  | 7559/10000 [00:32<00:10, 238.79it/s]Running 10000 simulations.:  76%|███████▌  | 7584/10000 [00:32<00:10, 240.86it/s]Running 10000 simulations.:  76%|███████▌  | 7609/10000 [00:32<00:09, 242.59it/s]Running 10000 simulations.:  76%|███████▋  | 7634/10000 [00:32<00:09, 241.13it/s]Running 10000 simulations.:  77%|███████▋  | 7659/10000 [00:32<00:09, 237.39it/s]Running 10000 simulations.:  77%|███████▋  | 7683/10000 [00:32<00:09, 233.93it/s]Running 10000 simulations.:  77%|███████▋  | 7707/10000 [00:32<00:09, 231.13it/s]Running 10000 simulations.:  77%|███████▋  | 7731/10000 [00:32<00:09, 232.78it/s]Running 10000 simulations.:  78%|███████▊  | 7755/10000 [00:32<00:09, 234.09it/s]Running 10000 simulations.:  78%|███████▊  | 7780/10000 [00:32<00:09, 236.40it/s]Running 10000 simulations.:  78%|███████▊  | 7805/10000 [00:33<00:09, 238.47it/s]Running 10000 simulations.:  78%|███████▊  | 7830/10000 [00:33<00:09, 239.00it/s]Running 10000 simulations.:  79%|███████▊  | 7854/10000 [00:33<00:08, 239.19it/s]Running 10000 simulations.:  79%|███████▉  | 7878/10000 [00:33<00:08, 237.37it/s]Running 10000 simulations.:  79%|███████▉  | 7902/10000 [00:33<00:08, 238.13it/s]Running 10000 simulations.:  79%|███████▉  | 7927/10000 [00:33<00:08, 239.81it/s]Running 10000 simulations.:  80%|███████▉  | 7952/10000 [00:33<00:08, 240.32it/s]Running 10000 simulations.:  80%|███████▉  | 7977/10000 [00:33<00:08, 239.69it/s]Running 10000 simulations.:  80%|████████  | 8001/10000 [00:33<00:08, 237.50it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:33<00:08, 232.82it/s]Running 10000 simulations.:  80%|████████  | 8049/10000 [00:34<00:08, 228.30it/s]Running 10000 simulations.:  81%|████████  | 8072/10000 [00:34<00:08, 228.56it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:34<00:08, 232.38it/s]Running 10000 simulations.:  81%|████████  | 8121/10000 [00:34<00:08, 234.17it/s]Running 10000 simulations.:  81%|████████▏ | 8145/10000 [00:34<00:07, 235.41it/s]Running 10000 simulations.:  82%|████████▏ | 8170/10000 [00:34<00:07, 237.61it/s]Running 10000 simulations.:  82%|████████▏ | 8195/10000 [00:34<00:07, 239.36it/s]Running 10000 simulations.:  82%|████████▏ | 8219/10000 [00:34<00:07, 239.55it/s]Running 10000 simulations.:  82%|████████▏ | 8244/10000 [00:34<00:07, 240.56it/s]Running 10000 simulations.:  83%|████████▎ | 8269/10000 [00:35<00:07, 237.17it/s]Running 10000 simulations.:  83%|████████▎ | 8293/10000 [00:35<00:07, 233.06it/s]Running 10000 simulations.:  83%|████████▎ | 8317/10000 [00:35<00:07, 231.42it/s]Running 10000 simulations.:  83%|████████▎ | 8341/10000 [00:35<00:07, 230.07it/s]Running 10000 simulations.:  84%|████████▎ | 8365/10000 [00:35<00:07, 232.86it/s]Running 10000 simulations.:  84%|████████▍ | 8389/10000 [00:35<00:06, 234.02it/s]Running 10000 simulations.:  84%|████████▍ | 8414/10000 [00:35<00:06, 236.13it/s]Running 10000 simulations.:  84%|████████▍ | 8439/10000 [00:35<00:06, 238.95it/s]Running 10000 simulations.:  85%|████████▍ | 8464/10000 [00:35<00:06, 240.01it/s]Running 10000 simulations.:  85%|████████▍ | 8489/10000 [00:35<00:06, 241.81it/s]Running 10000 simulations.:  85%|████████▌ | 8514/10000 [00:36<00:06, 242.32it/s]Running 10000 simulations.:  85%|████████▌ | 8539/10000 [00:36<00:06, 239.44it/s]Running 10000 simulations.:  86%|████████▌ | 8563/10000 [00:36<00:06, 236.01it/s]Running 10000 simulations.:  86%|████████▌ | 8587/10000 [00:36<00:06, 232.94it/s]Running 10000 simulations.:  86%|████████▌ | 8611/10000 [00:36<00:06, 230.33it/s]Running 10000 simulations.:  86%|████████▋ | 8635/10000 [00:36<00:05, 232.19it/s]Running 10000 simulations.:  87%|████████▋ | 8660/10000 [00:36<00:05, 234.90it/s]Running 10000 simulations.:  87%|████████▋ | 8685/10000 [00:36<00:05, 236.91it/s]Running 10000 simulations.:  87%|████████▋ | 8710/10000 [00:36<00:05, 239.02it/s]Running 10000 simulations.:  87%|████████▋ | 8734/10000 [00:36<00:05, 238.99it/s]Running 10000 simulations.:  88%|████████▊ | 8759/10000 [00:37<00:05, 240.44it/s]Running 10000 simulations.:  88%|████████▊ | 8784/10000 [00:37<00:05, 241.64it/s]Running 10000 simulations.:  88%|████████▊ | 8809/10000 [00:37<00:04, 240.15it/s]Running 10000 simulations.:  88%|████████▊ | 8834/10000 [00:37<00:04, 235.72it/s]Running 10000 simulations.:  89%|████████▊ | 8858/10000 [00:37<00:04, 233.29it/s]Running 10000 simulations.:  89%|████████▉ | 8882/10000 [00:37<00:04, 230.26it/s]Running 10000 simulations.:  89%|████████▉ | 8906/10000 [00:37<00:04, 230.70it/s]Running 10000 simulations.:  89%|████████▉ | 8931/10000 [00:37<00:04, 234.15it/s]Running 10000 simulations.:  90%|████████▉ | 8956/10000 [00:37<00:04, 236.80it/s]Running 10000 simulations.:  90%|████████▉ | 8980/10000 [00:38<00:04, 237.57it/s]Running 10000 simulations.:  90%|█████████ | 9005/10000 [00:38<00:04, 238.92it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:38<00:04, 239.92it/s]Running 10000 simulations.:  91%|█████████ | 9055/10000 [00:38<00:03, 240.61it/s]Running 10000 simulations.:  91%|█████████ | 9080/10000 [00:38<00:03, 240.96it/s]Running 10000 simulations.:  91%|█████████ | 9105/10000 [00:38<00:03, 236.13it/s]Running 10000 simulations.:  91%|█████████▏| 9129/10000 [00:38<00:03, 231.65it/s]Running 10000 simulations.:  92%|█████████▏| 9153/10000 [00:38<00:03, 229.31it/s]Running 10000 simulations.:  92%|█████████▏| 9177/10000 [00:38<00:03, 230.99it/s]Running 10000 simulations.:  92%|█████████▏| 9202/10000 [00:38<00:03, 234.17it/s]Running 10000 simulations.:  92%|█████████▏| 9226/10000 [00:39<00:03, 235.38it/s]Running 10000 simulations.:  92%|█████████▎| 9250/10000 [00:39<00:03, 236.60it/s]Running 10000 simulations.:  93%|█████████▎| 9274/10000 [00:39<00:03, 237.11it/s]Running 10000 simulations.:  93%|█████████▎| 9298/10000 [00:39<00:02, 237.58it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [00:39<00:02, 238.50it/s]Running 10000 simulations.:  93%|█████████▎| 9347/10000 [00:39<00:02, 238.74it/s]Running 10000 simulations.:  94%|█████████▎| 9371/10000 [00:39<00:02, 235.80it/s]Running 10000 simulations.:  94%|█████████▍| 9395/10000 [00:39<00:02, 233.80it/s]Running 10000 simulations.:  94%|█████████▍| 9419/10000 [00:39<00:02, 232.76it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [00:40<00:02, 233.44it/s]Running 10000 simulations.:  95%|█████████▍| 9468/10000 [00:40<00:02, 235.47it/s]Running 10000 simulations.:  95%|█████████▍| 9493/10000 [00:40<00:02, 237.08it/s]Running 10000 simulations.:  95%|█████████▌| 9518/10000 [00:40<00:02, 239.37it/s]Running 10000 simulations.:  95%|█████████▌| 9543/10000 [00:40<00:01, 239.73it/s]Running 10000 simulations.:  96%|█████████▌| 9568/10000 [00:40<00:01, 241.20it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:40<00:01, 242.54it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [00:40<00:01, 243.01it/s]Running 10000 simulations.:  96%|█████████▋| 9643/10000 [00:40<00:01, 239.58it/s]Running 10000 simulations.:  97%|█████████▋| 9667/10000 [00:40<00:01, 236.78it/s]Running 10000 simulations.:  97%|█████████▋| 9691/10000 [00:41<00:01, 235.09it/s]Running 10000 simulations.:  97%|█████████▋| 9715/10000 [00:41<00:01, 234.87it/s]Running 10000 simulations.:  97%|█████████▋| 9740/10000 [00:41<00:01, 237.83it/s]Running 10000 simulations.:  98%|█████████▊| 9765/10000 [00:41<00:00, 239.60it/s]Running 10000 simulations.:  98%|█████████▊| 9790/10000 [00:41<00:00, 240.26it/s]Running 10000 simulations.:  98%|█████████▊| 9815/10000 [00:41<00:00, 240.92it/s]Running 10000 simulations.:  98%|█████████▊| 9840/10000 [00:41<00:00, 242.54it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [00:41<00:00, 244.49it/s]Running 10000 simulations.:  99%|█████████▉| 9890/10000 [00:41<00:00, 245.58it/s]Running 10000 simulations.:  99%|█████████▉| 9915/10000 [00:41<00:00, 243.71it/s]Running 10000 simulations.:  99%|█████████▉| 9940/10000 [00:42<00:00, 239.27it/s]Running 10000 simulations.: 100%|█████████▉| 9964/10000 [00:42<00:00, 236.87it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [00:42<00:00, 233.78it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 236.25it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 27/10000 [00:00<00:37, 262.73it/s]Running 10000 simulations.:   1%|          | 54/10000 [00:00<00:37, 261.99it/s]Running 10000 simulations.:   1%|          | 81/10000 [00:00<00:37, 261.68it/s]Running 10000 simulations.:   1%|          | 108/10000 [00:00<00:37, 261.88it/s]Running 10000 simulations.:   1%|▏         | 133/10000 [00:00<00:38, 258.00it/s]Running 10000 simulations.:   2%|▏         | 159/10000 [00:00<00:38, 256.62it/s]Running 10000 simulations.:   2%|▏         | 186/10000 [00:00<00:38, 257.99it/s]Running 10000 simulations.:   2%|▏         | 213/10000 [00:00<00:37, 259.06it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:00<00:37, 259.45it/s]Running 10000 simulations.:   3%|▎         | 266/10000 [00:01<00:37, 259.61it/s]Running 10000 simulations.:   3%|▎         | 292/10000 [00:01<00:37, 256.45it/s]Running 10000 simulations.:   3%|▎         | 318/10000 [00:01<00:37, 256.87it/s]Running 10000 simulations.:   3%|▎         | 344/10000 [00:01<00:37, 257.48it/s]Running 10000 simulations.:   4%|▎         | 370/10000 [00:01<00:37, 256.48it/s]Running 10000 simulations.:   4%|▍         | 397/10000 [00:01<00:37, 257.56it/s]Running 10000 simulations.:   4%|▍         | 423/10000 [00:01<00:37, 256.97it/s]Running 10000 simulations.:   4%|▍         | 449/10000 [00:01<00:37, 256.80it/s]Running 10000 simulations.:   5%|▍         | 475/10000 [00:01<00:37, 256.52it/s]Running 10000 simulations.:   5%|▌         | 501/10000 [00:01<00:37, 255.95it/s]Running 10000 simulations.:   5%|▌         | 527/10000 [00:02<00:37, 255.40it/s]Running 10000 simulations.:   6%|▌         | 553/10000 [00:02<00:36, 255.78it/s]Running 10000 simulations.:   6%|▌         | 579/10000 [00:02<00:36, 255.68it/s]Running 10000 simulations.:   6%|▌         | 605/10000 [00:02<00:36, 256.23it/s]Running 10000 simulations.:   6%|▋         | 631/10000 [00:02<00:36, 254.05it/s]Running 10000 simulations.:   7%|▋         | 657/10000 [00:02<00:36, 254.21it/s]Running 10000 simulations.:   7%|▋         | 683/10000 [00:02<00:36, 254.87it/s]Running 10000 simulations.:   7%|▋         | 709/10000 [00:02<00:36, 254.74it/s]Running 10000 simulations.:   7%|▋         | 735/10000 [00:02<00:36, 254.51it/s]Running 10000 simulations.:   8%|▊         | 761/10000 [00:02<00:36, 254.07it/s]Running 10000 simulations.:   8%|▊         | 787/10000 [00:03<00:36, 253.41it/s]Running 10000 simulations.:   8%|▊         | 813/10000 [00:03<00:36, 254.00it/s]Running 10000 simulations.:   8%|▊         | 839/10000 [00:03<00:36, 254.23it/s]Running 10000 simulations.:   9%|▊         | 865/10000 [00:03<00:35, 254.34it/s]Running 10000 simulations.:   9%|▉         | 891/10000 [00:03<00:35, 254.66it/s]Running 10000 simulations.:   9%|▉         | 917/10000 [00:03<00:35, 254.16it/s]Running 10000 simulations.:   9%|▉         | 943/10000 [00:03<00:35, 254.05it/s]Running 10000 simulations.:  10%|▉         | 969/10000 [00:03<00:35, 254.22it/s]Running 10000 simulations.:  10%|▉         | 995/10000 [00:03<00:35, 254.39it/s]Running 10000 simulations.:  10%|█         | 1021/10000 [00:03<00:35, 253.98it/s]Running 10000 simulations.:  10%|█         | 1047/10000 [00:04<00:35, 253.77it/s]Running 10000 simulations.:  11%|█         | 1073/10000 [00:04<00:35, 253.64it/s]Running 10000 simulations.:  11%|█         | 1099/10000 [00:04<00:34, 254.54it/s]Running 10000 simulations.:  11%|█▏        | 1125/10000 [00:04<00:34, 253.84it/s]Running 10000 simulations.:  12%|█▏        | 1151/10000 [00:04<00:34, 253.93it/s]Running 10000 simulations.:  12%|█▏        | 1177/10000 [00:04<00:34, 254.59it/s]Running 10000 simulations.:  12%|█▏        | 1203/10000 [00:04<00:34, 254.15it/s]Running 10000 simulations.:  12%|█▏        | 1229/10000 [00:04<00:34, 254.72it/s]Running 10000 simulations.:  13%|█▎        | 1255/10000 [00:04<00:34, 253.85it/s]Running 10000 simulations.:  13%|█▎        | 1281/10000 [00:05<00:34, 253.21it/s]Running 10000 simulations.:  13%|█▎        | 1307/10000 [00:05<00:34, 252.84it/s]Running 10000 simulations.:  13%|█▎        | 1333/10000 [00:05<00:49, 176.70it/s]Running 10000 simulations.:  14%|█▎        | 1359/10000 [00:05<00:44, 194.75it/s]Running 10000 simulations.:  14%|█▍        | 1385/10000 [00:05<00:41, 209.14it/s]Running 10000 simulations.:  14%|█▍        | 1411/10000 [00:05<00:38, 220.67it/s]Running 10000 simulations.:  14%|█▍        | 1437/10000 [00:05<00:37, 229.20it/s]Running 10000 simulations.:  15%|█▍        | 1463/10000 [00:05<00:36, 235.92it/s]Running 10000 simulations.:  15%|█▍        | 1489/10000 [00:05<00:35, 240.72it/s]Running 10000 simulations.:  15%|█▌        | 1515/10000 [00:06<00:34, 245.03it/s]Running 10000 simulations.:  15%|█▌        | 1541/10000 [00:06<00:34, 247.89it/s]Running 10000 simulations.:  16%|█▌        | 1567/10000 [00:06<00:34, 244.82it/s]Running 10000 simulations.:  16%|█▌        | 1593/10000 [00:06<00:34, 246.92it/s]Running 10000 simulations.:  16%|█▌        | 1619/10000 [00:06<00:33, 248.01it/s]Running 10000 simulations.:  16%|█▋        | 1644/10000 [00:06<00:33, 248.58it/s]Running 10000 simulations.:  17%|█▋        | 1669/10000 [00:06<00:33, 248.88it/s]Running 10000 simulations.:  17%|█▋        | 1695/10000 [00:06<00:33, 249.74it/s]Running 10000 simulations.:  17%|█▋        | 1721/10000 [00:06<00:33, 249.88it/s]Running 10000 simulations.:  17%|█▋        | 1747/10000 [00:07<00:33, 249.76it/s]Running 10000 simulations.:  18%|█▊        | 1773/10000 [00:07<00:32, 250.73it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:07<00:32, 250.99it/s]Running 10000 simulations.:  18%|█▊        | 1825/10000 [00:07<00:32, 251.51it/s]Running 10000 simulations.:  19%|█▊        | 1851/10000 [00:07<00:32, 251.43it/s]Running 10000 simulations.:  19%|█▉        | 1877/10000 [00:07<00:32, 250.67it/s]Running 10000 simulations.:  19%|█▉        | 1903/10000 [00:07<00:32, 251.17it/s]Running 10000 simulations.:  19%|█▉        | 1929/10000 [00:07<00:32, 251.27it/s]Running 10000 simulations.:  20%|█▉        | 1955/10000 [00:07<00:32, 249.73it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:07<00:32, 249.61it/s]Running 10000 simulations.:  20%|██        | 2006/10000 [00:08<00:31, 250.14it/s]Running 10000 simulations.:  20%|██        | 2032/10000 [00:08<00:31, 250.63it/s]Running 10000 simulations.:  21%|██        | 2058/10000 [00:08<00:31, 251.33it/s]Running 10000 simulations.:  21%|██        | 2084/10000 [00:08<00:31, 250.94it/s]Running 10000 simulations.:  21%|██        | 2110/10000 [00:08<00:31, 251.16it/s]Running 10000 simulations.:  21%|██▏       | 2136/10000 [00:08<00:31, 251.44it/s]Running 10000 simulations.:  22%|██▏       | 2162/10000 [00:08<00:31, 250.78it/s]Running 10000 simulations.:  22%|██▏       | 2188/10000 [00:08<00:31, 251.18it/s]Running 10000 simulations.:  22%|██▏       | 2214/10000 [00:08<00:30, 251.50it/s]Running 10000 simulations.:  22%|██▏       | 2240/10000 [00:08<00:30, 251.73it/s]Running 10000 simulations.:  23%|██▎       | 2266/10000 [00:09<00:30, 251.47it/s]Running 10000 simulations.:  23%|██▎       | 2292/10000 [00:09<00:30, 251.38it/s]Running 10000 simulations.:  23%|██▎       | 2318/10000 [00:09<00:30, 251.49it/s]Running 10000 simulations.:  23%|██▎       | 2344/10000 [00:09<00:30, 251.74it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:09<00:30, 250.45it/s]Running 10000 simulations.:  24%|██▍       | 2396/10000 [00:09<00:30, 251.63it/s]Running 10000 simulations.:  24%|██▍       | 2422/10000 [00:09<00:30, 252.25it/s]Running 10000 simulations.:  24%|██▍       | 2448/10000 [00:09<00:30, 251.17it/s]Running 10000 simulations.:  25%|██▍       | 2474/10000 [00:09<00:29, 250.90it/s]Running 10000 simulations.:  25%|██▌       | 2500/10000 [00:10<00:30, 249.47it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:10<00:29, 249.62it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:10<00:29, 249.50it/s]Running 10000 simulations.:  26%|██▌       | 2575/10000 [00:10<00:29, 249.33it/s]Running 10000 simulations.:  26%|██▌       | 2601/10000 [00:10<00:29, 250.00it/s]Running 10000 simulations.:  26%|██▋       | 2627/10000 [00:10<00:29, 250.24it/s]Running 10000 simulations.:  27%|██▋       | 2653/10000 [00:10<00:29, 250.46it/s]Running 10000 simulations.:  27%|██▋       | 2679/10000 [00:10<00:29, 251.39it/s]Running 10000 simulations.:  27%|██▋       | 2705/10000 [00:10<00:29, 251.55it/s]Running 10000 simulations.:  27%|██▋       | 2731/10000 [00:10<00:28, 250.72it/s]Running 10000 simulations.:  28%|██▊       | 2757/10000 [00:11<00:28, 250.39it/s]Running 10000 simulations.:  28%|██▊       | 2783/10000 [00:11<00:28, 249.21it/s]Running 10000 simulations.:  28%|██▊       | 2808/10000 [00:11<00:29, 246.99it/s]Running 10000 simulations.:  28%|██▊       | 2833/10000 [00:11<00:29, 246.70it/s]Running 10000 simulations.:  29%|██▊       | 2858/10000 [00:11<00:28, 247.52it/s]Running 10000 simulations.:  29%|██▉       | 2884/10000 [00:11<00:28, 248.64it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:11<00:28, 249.07it/s]Running 10000 simulations.:  29%|██▉       | 2935/10000 [00:11<00:28, 249.22it/s]Running 10000 simulations.:  30%|██▉       | 2960/10000 [00:11<00:28, 249.34it/s]Running 10000 simulations.:  30%|██▉       | 2986/10000 [00:11<00:28, 249.75it/s]Running 10000 simulations.:  30%|███       | 3012/10000 [00:12<00:27, 249.97it/s]Running 10000 simulations.:  30%|███       | 3037/10000 [00:12<00:27, 249.91it/s]Running 10000 simulations.:  31%|███       | 3062/10000 [00:12<00:27, 249.93it/s]Running 10000 simulations.:  31%|███       | 3087/10000 [00:12<00:27, 249.88it/s]Running 10000 simulations.:  31%|███       | 3113/10000 [00:12<00:27, 250.04it/s]Running 10000 simulations.:  31%|███▏      | 3139/10000 [00:12<00:27, 250.71it/s]Running 10000 simulations.:  32%|███▏      | 3165/10000 [00:12<00:27, 251.08it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:12<00:27, 251.75it/s]Running 10000 simulations.:  32%|███▏      | 3217/10000 [00:12<00:26, 251.80it/s]Running 10000 simulations.:  32%|███▏      | 3243/10000 [00:12<00:26, 250.78it/s]Running 10000 simulations.:  33%|███▎      | 3269/10000 [00:13<00:27, 247.86it/s]Running 10000 simulations.:  33%|███▎      | 3294/10000 [00:13<00:27, 246.13it/s]Running 10000 simulations.:  33%|███▎      | 3320/10000 [00:13<00:26, 247.61it/s]Running 10000 simulations.:  33%|███▎      | 3346/10000 [00:13<00:26, 248.82it/s]Running 10000 simulations.:  34%|███▎      | 3372/10000 [00:13<00:26, 249.45it/s]Running 10000 simulations.:  34%|███▍      | 3397/10000 [00:13<00:26, 249.28it/s]Running 10000 simulations.:  34%|███▍      | 3422/10000 [00:13<00:26, 249.06it/s]Running 10000 simulations.:  34%|███▍      | 3447/10000 [00:13<00:26, 249.17it/s]Running 10000 simulations.:  35%|███▍      | 3472/10000 [00:13<00:26, 249.35it/s]Running 10000 simulations.:  35%|███▍      | 3498/10000 [00:14<00:26, 249.66it/s]Running 10000 simulations.:  35%|███▌      | 3524/10000 [00:14<00:25, 250.12it/s]Running 10000 simulations.:  36%|███▌      | 3550/10000 [00:14<00:25, 250.21it/s]Running 10000 simulations.:  36%|███▌      | 3576/10000 [00:14<00:25, 249.70it/s]Running 10000 simulations.:  36%|███▌      | 3601/10000 [00:14<00:25, 248.96it/s]Running 10000 simulations.:  36%|███▋      | 3626/10000 [00:14<00:25, 247.70it/s]Running 10000 simulations.:  37%|███▋      | 3651/10000 [00:14<00:25, 248.22it/s]Running 10000 simulations.:  37%|███▋      | 3676/10000 [00:14<00:25, 248.73it/s]Running 10000 simulations.:  37%|███▋      | 3702/10000 [00:14<00:25, 249.38it/s]Running 10000 simulations.:  37%|███▋      | 3728/10000 [00:14<00:25, 250.26it/s]Running 10000 simulations.:  38%|███▊      | 3754/10000 [00:15<00:24, 250.78it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:15<00:24, 250.46it/s]Running 10000 simulations.:  38%|███▊      | 3806/10000 [00:15<00:24, 250.72it/s]Running 10000 simulations.:  38%|███▊      | 3832/10000 [00:15<00:24, 251.22it/s]Running 10000 simulations.:  39%|███▊      | 3858/10000 [00:15<00:24, 251.51it/s]Running 10000 simulations.:  39%|███▉      | 3884/10000 [00:15<00:24, 249.95it/s]Running 10000 simulations.:  39%|███▉      | 3909/10000 [00:15<00:24, 248.92it/s]Running 10000 simulations.:  39%|███▉      | 3934/10000 [00:15<00:24, 248.80it/s]Running 10000 simulations.:  40%|███▉      | 3959/10000 [00:15<00:24, 247.73it/s]Running 10000 simulations.:  40%|███▉      | 3984/10000 [00:15<00:24, 247.98it/s]Running 10000 simulations.:  40%|████      | 4009/10000 [00:16<00:24, 247.76it/s]Running 10000 simulations.:  40%|████      | 4034/10000 [00:16<00:24, 247.14it/s]Running 10000 simulations.:  41%|████      | 4059/10000 [00:16<00:24, 247.27it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:16<00:23, 248.15it/s]Running 10000 simulations.:  41%|████      | 4111/10000 [00:16<00:23, 248.83it/s]Running 10000 simulations.:  41%|████▏     | 4136/10000 [00:16<00:23, 249.03it/s]Running 10000 simulations.:  42%|████▏     | 4161/10000 [00:16<00:23, 248.36it/s]Running 10000 simulations.:  42%|████▏     | 4186/10000 [00:16<00:23, 247.29it/s]Running 10000 simulations.:  42%|████▏     | 4211/10000 [00:16<00:23, 247.93it/s]Running 10000 simulations.:  42%|████▏     | 4237/10000 [00:16<00:23, 248.87it/s]Running 10000 simulations.:  43%|████▎     | 4263/10000 [00:17<00:22, 250.03it/s]Running 10000 simulations.:  43%|████▎     | 4289/10000 [00:17<00:22, 250.78it/s]Running 10000 simulations.:  43%|████▎     | 4315/10000 [00:17<00:22, 250.95it/s]Running 10000 simulations.:  43%|████▎     | 4341/10000 [00:17<00:22, 250.66it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:17<00:22, 250.92it/s]Running 10000 simulations.:  44%|████▍     | 4393/10000 [00:17<00:22, 251.32it/s]Running 10000 simulations.:  44%|████▍     | 4419/10000 [00:17<00:22, 249.93it/s]Running 10000 simulations.:  44%|████▍     | 4445/10000 [00:17<00:22, 250.26it/s]Running 10000 simulations.:  45%|████▍     | 4471/10000 [00:17<00:22, 249.67it/s]Running 10000 simulations.:  45%|████▍     | 4497/10000 [00:18<00:22, 249.83it/s]Running 10000 simulations.:  45%|████▌     | 4522/10000 [00:18<00:22, 248.68it/s]Running 10000 simulations.:  45%|████▌     | 4547/10000 [00:18<00:21, 248.67it/s]Running 10000 simulations.:  46%|████▌     | 4573/10000 [00:18<00:21, 249.64it/s]Running 10000 simulations.:  46%|████▌     | 4599/10000 [00:18<00:21, 250.27it/s]Running 10000 simulations.:  46%|████▋     | 4625/10000 [00:18<00:21, 248.20it/s]Running 10000 simulations.:  46%|████▋     | 4650/10000 [00:18<00:21, 245.80it/s]Running 10000 simulations.:  47%|████▋     | 4675/10000 [00:18<00:21, 246.39it/s]Running 10000 simulations.:  47%|████▋     | 4701/10000 [00:18<00:21, 247.66it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:18<00:21, 248.70it/s]Running 10000 simulations.:  48%|████▊     | 4752/10000 [00:19<00:21, 248.45it/s]Running 10000 simulations.:  48%|████▊     | 4777/10000 [00:19<00:20, 248.90it/s]Running 10000 simulations.:  48%|████▊     | 4802/10000 [00:19<00:20, 248.78it/s]Running 10000 simulations.:  48%|████▊     | 4827/10000 [00:19<00:20, 247.89it/s]Running 10000 simulations.:  49%|████▊     | 4852/10000 [00:19<00:20, 247.28it/s]Running 10000 simulations.:  49%|████▉     | 4877/10000 [00:19<00:20, 247.30it/s]Running 10000 simulations.:  49%|████▉     | 4902/10000 [00:19<00:20, 247.59it/s]Running 10000 simulations.:  49%|████▉     | 4928/10000 [00:19<00:20, 248.32it/s]Running 10000 simulations.:  50%|████▉     | 4953/10000 [00:19<00:20, 247.99it/s]Running 10000 simulations.:  50%|████▉     | 4978/10000 [00:19<00:20, 247.75it/s]Running 10000 simulations.:  50%|█████     | 5003/10000 [00:20<00:20, 247.66it/s]Running 10000 simulations.:  50%|█████     | 5028/10000 [00:20<00:20, 247.18it/s]Running 10000 simulations.:  51%|█████     | 5053/10000 [00:20<00:19, 247.89it/s]Running 10000 simulations.:  51%|█████     | 5078/10000 [00:20<00:19, 248.46it/s]Running 10000 simulations.:  51%|█████     | 5103/10000 [00:20<00:19, 248.89it/s]Running 10000 simulations.:  51%|█████▏    | 5128/10000 [00:20<00:19, 248.68it/s]Running 10000 simulations.:  52%|█████▏    | 5153/10000 [00:20<00:19, 248.08it/s]Running 10000 simulations.:  52%|█████▏    | 5178/10000 [00:20<00:19, 248.42it/s]Running 10000 simulations.:  52%|█████▏    | 5203/10000 [00:20<00:20, 237.55it/s]Running 10000 simulations.:  52%|█████▏    | 5228/10000 [00:20<00:19, 240.22it/s]Running 10000 simulations.:  53%|█████▎    | 5253/10000 [00:21<00:19, 243.02it/s]Running 10000 simulations.:  53%|█████▎    | 5278/10000 [00:21<00:19, 244.69it/s]Running 10000 simulations.:  53%|█████▎    | 5303/10000 [00:21<00:19, 246.04it/s]Running 10000 simulations.:  53%|█████▎    | 5328/10000 [00:21<00:18, 246.83it/s]Running 10000 simulations.:  54%|█████▎    | 5354/10000 [00:21<00:18, 248.16it/s]Running 10000 simulations.:  54%|█████▍    | 5379/10000 [00:21<00:18, 248.35it/s]Running 10000 simulations.:  54%|█████▍    | 5404/10000 [00:21<00:18, 247.96it/s]Running 10000 simulations.:  54%|█████▍    | 5429/10000 [00:21<00:18, 245.05it/s]Running 10000 simulations.:  55%|█████▍    | 5454/10000 [00:21<00:18, 243.38it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:21<00:18, 244.36it/s]Running 10000 simulations.:  55%|█████▌    | 5504/10000 [00:22<00:18, 245.57it/s]Running 10000 simulations.:  55%|█████▌    | 5530/10000 [00:22<00:18, 247.12it/s]Running 10000 simulations.:  56%|█████▌    | 5555/10000 [00:22<00:17, 247.31it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:22<00:17, 247.66it/s]Running 10000 simulations.:  56%|█████▌    | 5605/10000 [00:22<00:17, 247.35it/s]Running 10000 simulations.:  56%|█████▋    | 5630/10000 [00:22<00:17, 243.78it/s]Running 10000 simulations.:  57%|█████▋    | 5655/10000 [00:22<00:17, 245.28it/s]Running 10000 simulations.:  57%|█████▋    | 5680/10000 [00:22<00:17, 245.51it/s]Running 10000 simulations.:  57%|█████▋    | 5705/10000 [00:22<00:17, 245.30it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:23<00:17, 246.20it/s]Running 10000 simulations.:  58%|█████▊    | 5755/10000 [00:23<00:17, 246.62it/s]Running 10000 simulations.:  58%|█████▊    | 5780/10000 [00:23<00:17, 247.25it/s]Running 10000 simulations.:  58%|█████▊    | 5805/10000 [00:23<00:16, 247.66it/s]Running 10000 simulations.:  58%|█████▊    | 5830/10000 [00:23<00:16, 248.15it/s]Running 10000 simulations.:  59%|█████▊    | 5855/10000 [00:23<00:16, 248.69it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:23<00:16, 249.07it/s]Running 10000 simulations.:  59%|█████▉    | 5906/10000 [00:23<00:16, 249.57it/s]Running 10000 simulations.:  59%|█████▉    | 5931/10000 [00:23<00:16, 249.58it/s]Running 10000 simulations.:  60%|█████▉    | 5957/10000 [00:23<00:16, 250.12it/s]Running 10000 simulations.:  60%|█████▉    | 5983/10000 [00:24<00:16, 249.71it/s]Running 10000 simulations.:  60%|██████    | 6008/10000 [00:24<00:16, 247.51it/s]Running 10000 simulations.:  60%|██████    | 6033/10000 [00:24<00:15, 247.96it/s]Running 10000 simulations.:  61%|██████    | 6059/10000 [00:24<00:15, 248.64it/s]Running 10000 simulations.:  61%|██████    | 6084/10000 [00:24<00:15, 247.91it/s]Running 10000 simulations.:  61%|██████    | 6109/10000 [00:24<00:15, 247.66it/s]Running 10000 simulations.:  61%|██████▏   | 6134/10000 [00:24<00:15, 248.04it/s]Running 10000 simulations.:  62%|██████▏   | 6159/10000 [00:24<00:15, 248.16it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:24<00:15, 248.39it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:24<00:15, 248.99it/s]Running 10000 simulations.:  62%|██████▏   | 6235/10000 [00:25<00:15, 248.00it/s]Running 10000 simulations.:  63%|██████▎   | 6260/10000 [00:25<00:15, 248.06it/s]Running 10000 simulations.:  63%|██████▎   | 6285/10000 [00:25<00:14, 247.88it/s]Running 10000 simulations.:  63%|██████▎   | 6310/10000 [00:25<00:14, 247.54it/s]Running 10000 simulations.:  63%|██████▎   | 6335/10000 [00:25<00:14, 247.86it/s]Running 10000 simulations.:  64%|██████▎   | 6360/10000 [00:25<00:14, 248.00it/s]Running 10000 simulations.:  64%|██████▍   | 6385/10000 [00:25<00:14, 248.46it/s]Running 10000 simulations.:  64%|██████▍   | 6410/10000 [00:25<00:14, 246.77it/s]Running 10000 simulations.:  64%|██████▍   | 6435/10000 [00:25<00:14, 247.33it/s]Running 10000 simulations.:  65%|██████▍   | 6460/10000 [00:25<00:14, 247.38it/s]Running 10000 simulations.:  65%|██████▍   | 6485/10000 [00:26<00:14, 247.40it/s]Running 10000 simulations.:  65%|██████▌   | 6510/10000 [00:26<00:14, 247.25it/s]Running 10000 simulations.:  65%|██████▌   | 6535/10000 [00:26<00:13, 247.64it/s]Running 10000 simulations.:  66%|██████▌   | 6560/10000 [00:26<00:13, 247.69it/s]Running 10000 simulations.:  66%|██████▌   | 6585/10000 [00:26<00:13, 247.99it/s]Running 10000 simulations.:  66%|██████▌   | 6610/10000 [00:26<00:13, 248.58it/s]Running 10000 simulations.:  66%|██████▋   | 6636/10000 [00:26<00:13, 249.17it/s]Running 10000 simulations.:  67%|██████▋   | 6661/10000 [00:26<00:13, 248.24it/s]Running 10000 simulations.:  67%|██████▋   | 6686/10000 [00:26<00:13, 246.25it/s]Running 10000 simulations.:  67%|██████▋   | 6711/10000 [00:26<00:13, 242.94it/s]Running 10000 simulations.:  67%|██████▋   | 6736/10000 [00:27<00:13, 242.96it/s]Running 10000 simulations.:  68%|██████▊   | 6761/10000 [00:27<00:13, 244.51it/s]Running 10000 simulations.:  68%|██████▊   | 6786/10000 [00:27<00:13, 244.32it/s]Running 10000 simulations.:  68%|██████▊   | 6811/10000 [00:27<00:13, 242.30it/s]Running 10000 simulations.:  68%|██████▊   | 6836/10000 [00:27<00:13, 242.67it/s]Running 10000 simulations.:  69%|██████▊   | 6861/10000 [00:27<00:12, 243.48it/s]Running 10000 simulations.:  69%|██████▉   | 6886/10000 [00:27<00:12, 244.37it/s]Running 10000 simulations.:  69%|██████▉   | 6911/10000 [00:27<00:12, 245.68it/s]Running 10000 simulations.:  69%|██████▉   | 6936/10000 [00:27<00:12, 245.46it/s]Running 10000 simulations.:  70%|██████▉   | 6961/10000 [00:27<00:12, 245.45it/s]Running 10000 simulations.:  70%|██████▉   | 6986/10000 [00:28<00:12, 245.77it/s]Running 10000 simulations.:  70%|███████   | 7011/10000 [00:28<00:12, 246.11it/s]Running 10000 simulations.:  70%|███████   | 7036/10000 [00:28<00:12, 246.60it/s]Running 10000 simulations.:  71%|███████   | 7061/10000 [00:28<00:11, 247.28it/s]Running 10000 simulations.:  71%|███████   | 7086/10000 [00:28<00:11, 247.44it/s]Running 10000 simulations.:  71%|███████   | 7111/10000 [00:28<00:11, 246.99it/s]Running 10000 simulations.:  71%|███████▏  | 7136/10000 [00:28<00:11, 246.43it/s]Running 10000 simulations.:  72%|███████▏  | 7161/10000 [00:28<00:11, 247.08it/s]Running 10000 simulations.:  72%|███████▏  | 7186/10000 [00:28<00:11, 247.68it/s]Running 10000 simulations.:  72%|███████▏  | 7211/10000 [00:29<00:11, 247.96it/s]Running 10000 simulations.:  72%|███████▏  | 7236/10000 [00:29<00:11, 247.40it/s]Running 10000 simulations.:  73%|███████▎  | 7261/10000 [00:29<00:11, 247.08it/s]Running 10000 simulations.:  73%|███████▎  | 7286/10000 [00:29<00:10, 247.54it/s]Running 10000 simulations.:  73%|███████▎  | 7311/10000 [00:29<00:10, 247.37it/s]Running 10000 simulations.:  73%|███████▎  | 7336/10000 [00:29<00:10, 246.56it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:29<00:10, 246.00it/s]Running 10000 simulations.:  74%|███████▍  | 7386/10000 [00:29<00:10, 246.69it/s]Running 10000 simulations.:  74%|███████▍  | 7411/10000 [00:29<00:10, 246.47it/s]Running 10000 simulations.:  74%|███████▍  | 7436/10000 [00:29<00:10, 246.85it/s]Running 10000 simulations.:  75%|███████▍  | 7461/10000 [00:30<00:10, 247.22it/s]Running 10000 simulations.:  75%|███████▍  | 7486/10000 [00:30<00:10, 247.00it/s]Running 10000 simulations.:  75%|███████▌  | 7511/10000 [00:30<00:10, 246.94it/s]Running 10000 simulations.:  75%|███████▌  | 7536/10000 [00:30<00:09, 246.99it/s]Running 10000 simulations.:  76%|███████▌  | 7561/10000 [00:30<00:09, 246.84it/s]Running 10000 simulations.:  76%|███████▌  | 7586/10000 [00:30<00:09, 247.35it/s]Running 10000 simulations.:  76%|███████▌  | 7611/10000 [00:30<00:09, 247.24it/s]Running 10000 simulations.:  76%|███████▋  | 7636/10000 [00:30<00:09, 246.12it/s]Running 10000 simulations.:  77%|███████▋  | 7661/10000 [00:30<00:09, 246.39it/s]Running 10000 simulations.:  77%|███████▋  | 7686/10000 [00:30<00:09, 246.00it/s]Running 10000 simulations.:  77%|███████▋  | 7711/10000 [00:31<00:09, 244.79it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:31<00:09, 244.76it/s]Running 10000 simulations.:  78%|███████▊  | 7761/10000 [00:31<00:09, 245.88it/s]Running 10000 simulations.:  78%|███████▊  | 7786/10000 [00:31<00:08, 246.59it/s]Running 10000 simulations.:  78%|███████▊  | 7811/10000 [00:31<00:08, 246.53it/s]Running 10000 simulations.:  78%|███████▊  | 7836/10000 [00:31<00:08, 246.04it/s]Running 10000 simulations.:  79%|███████▊  | 7861/10000 [00:31<00:08, 245.77it/s]Running 10000 simulations.:  79%|███████▉  | 7886/10000 [00:31<00:08, 245.85it/s]Running 10000 simulations.:  79%|███████▉  | 7911/10000 [00:31<00:08, 244.78it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:31<00:08, 244.85it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:32<00:08, 244.40it/s]Running 10000 simulations.:  80%|███████▉  | 7986/10000 [00:32<00:08, 245.35it/s]Running 10000 simulations.:  80%|████████  | 8011/10000 [00:32<00:08, 246.39it/s]Running 10000 simulations.:  80%|████████  | 8036/10000 [00:32<00:08, 245.37it/s]Running 10000 simulations.:  81%|████████  | 8061/10000 [00:32<00:07, 246.31it/s]Running 10000 simulations.:  81%|████████  | 8086/10000 [00:32<00:07, 246.92it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:32<00:07, 247.74it/s]Running 10000 simulations.:  81%|████████▏ | 8136/10000 [00:32<00:07, 248.11it/s]Running 10000 simulations.:  82%|████████▏ | 8161/10000 [00:32<00:07, 248.12it/s]Running 10000 simulations.:  82%|████████▏ | 8187/10000 [00:32<00:07, 248.99it/s]Running 10000 simulations.:  82%|████████▏ | 8213/10000 [00:33<00:07, 249.46it/s]Running 10000 simulations.:  82%|████████▏ | 8238/10000 [00:33<00:07, 249.00it/s]Running 10000 simulations.:  83%|████████▎ | 8263/10000 [00:33<00:06, 248.44it/s]Running 10000 simulations.:  83%|████████▎ | 8288/10000 [00:33<00:06, 248.89it/s]Running 10000 simulations.:  83%|████████▎ | 8314/10000 [00:33<00:06, 249.41it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:33<00:06, 249.72it/s]Running 10000 simulations.:  84%|████████▎ | 8365/10000 [00:33<00:06, 249.78it/s]Running 10000 simulations.:  84%|████████▍ | 8390/10000 [00:33<00:06, 249.11it/s]Running 10000 simulations.:  84%|████████▍ | 8415/10000 [00:33<00:06, 249.28it/s]Running 10000 simulations.:  84%|████████▍ | 8440/10000 [00:33<00:06, 247.82it/s]Running 10000 simulations.:  85%|████████▍ | 8465/10000 [00:34<00:06, 247.87it/s]Running 10000 simulations.:  85%|████████▍ | 8490/10000 [00:34<00:06, 247.67it/s]Running 10000 simulations.:  85%|████████▌ | 8515/10000 [00:34<00:05, 247.70it/s]Running 10000 simulations.:  85%|████████▌ | 8540/10000 [00:34<00:05, 247.59it/s]Running 10000 simulations.:  86%|████████▌ | 8565/10000 [00:34<00:05, 246.60it/s]Running 10000 simulations.:  86%|████████▌ | 8590/10000 [00:34<00:05, 245.95it/s]Running 10000 simulations.:  86%|████████▌ | 8615/10000 [00:34<00:05, 246.24it/s]Running 10000 simulations.:  86%|████████▋ | 8640/10000 [00:34<00:05, 245.75it/s]Running 10000 simulations.:  87%|████████▋ | 8665/10000 [00:34<00:05, 246.12it/s]Running 10000 simulations.:  87%|████████▋ | 8690/10000 [00:34<00:05, 245.64it/s]Running 10000 simulations.:  87%|████████▋ | 8715/10000 [00:35<00:05, 246.26it/s]Running 10000 simulations.:  87%|████████▋ | 8740/10000 [00:35<00:05, 246.81it/s]Running 10000 simulations.:  88%|████████▊ | 8765/10000 [00:35<00:04, 247.13it/s]Running 10000 simulations.:  88%|████████▊ | 8790/10000 [00:35<00:04, 246.00it/s]Running 10000 simulations.:  88%|████████▊ | 8815/10000 [00:35<00:04, 246.13it/s]Running 10000 simulations.:  88%|████████▊ | 8840/10000 [00:35<00:04, 245.57it/s]Running 10000 simulations.:  89%|████████▊ | 8865/10000 [00:35<00:04, 246.18it/s]Running 10000 simulations.:  89%|████████▉ | 8890/10000 [00:35<00:04, 245.15it/s]Running 10000 simulations.:  89%|████████▉ | 8915/10000 [00:35<00:04, 244.69it/s]Running 10000 simulations.:  89%|████████▉ | 8940/10000 [00:36<00:04, 244.59it/s]Running 10000 simulations.:  90%|████████▉ | 8965/10000 [00:36<00:04, 240.36it/s]Running 10000 simulations.:  90%|████████▉ | 8990/10000 [00:36<00:04, 241.91it/s]Running 10000 simulations.:  90%|█████████ | 9015/10000 [00:36<00:04, 243.72it/s]Running 10000 simulations.:  90%|█████████ | 9040/10000 [00:36<00:03, 244.88it/s]Running 10000 simulations.:  91%|█████████ | 9065/10000 [00:36<00:03, 245.85it/s]Running 10000 simulations.:  91%|█████████ | 9090/10000 [00:36<00:03, 246.93it/s]Running 10000 simulations.:  91%|█████████ | 9115/10000 [00:36<00:03, 247.12it/s]Running 10000 simulations.:  91%|█████████▏| 9140/10000 [00:36<00:03, 247.58it/s]Running 10000 simulations.:  92%|█████████▏| 9165/10000 [00:36<00:03, 247.87it/s]Running 10000 simulations.:  92%|█████████▏| 9190/10000 [00:37<00:03, 247.15it/s]Running 10000 simulations.:  92%|█████████▏| 9215/10000 [00:37<00:03, 247.89it/s]Running 10000 simulations.:  92%|█████████▏| 9240/10000 [00:37<00:03, 247.28it/s]Running 10000 simulations.:  93%|█████████▎| 9265/10000 [00:37<00:02, 247.74it/s]Running 10000 simulations.:  93%|█████████▎| 9290/10000 [00:37<00:02, 248.30it/s]Running 10000 simulations.:  93%|█████████▎| 9315/10000 [00:37<00:02, 248.71it/s]Running 10000 simulations.:  93%|█████████▎| 9340/10000 [00:37<00:02, 248.76it/s]Running 10000 simulations.:  94%|█████████▎| 9365/10000 [00:37<00:02, 249.03it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:37<00:02, 249.06it/s]Running 10000 simulations.:  94%|█████████▍| 9415/10000 [00:37<00:02, 249.30it/s]Running 10000 simulations.:  94%|█████████▍| 9440/10000 [00:38<00:02, 247.34it/s]Running 10000 simulations.:  95%|█████████▍| 9465/10000 [00:38<00:02, 244.40it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [00:38<00:02, 243.36it/s]Running 10000 simulations.:  95%|█████████▌| 9515/10000 [00:38<00:01, 245.24it/s]Running 10000 simulations.:  95%|█████████▌| 9541/10000 [00:38<00:01, 247.08it/s]Running 10000 simulations.:  96%|█████████▌| 9567/10000 [00:38<00:01, 249.00it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:38<00:01, 249.28it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [00:38<00:01, 249.03it/s]Running 10000 simulations.:  96%|█████████▋| 9643/10000 [00:38<00:01, 248.89it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [00:38<00:01, 248.63it/s]Running 10000 simulations.:  97%|█████████▋| 9693/10000 [00:39<00:01, 248.07it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [00:39<00:01, 248.53it/s]Running 10000 simulations.:  97%|█████████▋| 9744/10000 [00:39<00:01, 249.12it/s]Running 10000 simulations.:  98%|█████████▊| 9770/10000 [00:39<00:00, 249.76it/s]Running 10000 simulations.:  98%|█████████▊| 9795/10000 [00:39<00:00, 249.67it/s]Running 10000 simulations.:  98%|█████████▊| 9820/10000 [00:39<00:00, 248.41it/s]Running 10000 simulations.:  98%|█████████▊| 9845/10000 [00:39<00:00, 246.06it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [00:39<00:00, 247.04it/s]Running 10000 simulations.:  99%|█████████▉| 9895/10000 [00:39<00:00, 247.05it/s]Running 10000 simulations.:  99%|█████████▉| 9921/10000 [00:39<00:00, 247.94it/s]Running 10000 simulations.:  99%|█████████▉| 9946/10000 [00:40<00:00, 247.64it/s]Running 10000 simulations.: 100%|█████████▉| 9971/10000 [00:40<00:00, 247.50it/s]Running 10000 simulations.: 100%|█████████▉| 9996/10000 [00:40<00:00, 247.70it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:40<00:00, 248.13it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:38, 257.42it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:38, 256.92it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:38, 257.12it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:38, 256.40it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:38, 255.70it/s]Running 10000 simulations.:   2%|▏         | 156/10000 [00:00<00:38, 255.30it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:00<00:38, 255.78it/s]Running 10000 simulations.:   2%|▏         | 208/10000 [00:00<00:38, 254.76it/s]Running 10000 simulations.:   2%|▏         | 234/10000 [00:00<00:38, 253.63it/s]Running 10000 simulations.:   3%|▎         | 260/10000 [00:01<00:38, 253.48it/s]Running 10000 simulations.:   3%|▎         | 286/10000 [00:01<00:38, 253.03it/s]Running 10000 simulations.:   3%|▎         | 311/10000 [00:01<00:38, 252.05it/s]Running 10000 simulations.:   3%|▎         | 337/10000 [00:01<00:38, 251.45it/s]Running 10000 simulations.:   4%|▎         | 362/10000 [00:01<00:38, 250.09it/s]Running 10000 simulations.:   4%|▍         | 388/10000 [00:01<00:38, 250.17it/s]Running 10000 simulations.:   4%|▍         | 414/10000 [00:01<00:38, 250.31it/s]Running 10000 simulations.:   4%|▍         | 439/10000 [00:01<00:38, 249.93it/s]Running 10000 simulations.:   5%|▍         | 465/10000 [00:01<00:38, 250.62it/s]Running 10000 simulations.:   5%|▍         | 491/10000 [00:01<00:37, 251.09it/s]Running 10000 simulations.:   5%|▌         | 517/10000 [00:02<00:37, 251.65it/s]Running 10000 simulations.:   5%|▌         | 543/10000 [00:02<00:37, 251.68it/s]Running 10000 simulations.:   6%|▌         | 569/10000 [00:02<00:37, 252.51it/s]Running 10000 simulations.:   6%|▌         | 595/10000 [00:02<00:37, 252.69it/s]Running 10000 simulations.:   6%|▌         | 621/10000 [00:02<00:37, 252.76it/s]Running 10000 simulations.:   6%|▋         | 647/10000 [00:02<00:37, 252.25it/s]Running 10000 simulations.:   7%|▋         | 673/10000 [00:02<00:36, 252.62it/s]Running 10000 simulations.:   7%|▋         | 699/10000 [00:02<00:36, 252.84it/s]Running 10000 simulations.:   7%|▋         | 725/10000 [00:02<00:36, 251.57it/s]Running 10000 simulations.:   8%|▊         | 751/10000 [00:02<00:36, 250.41it/s]Running 10000 simulations.:   8%|▊         | 777/10000 [00:03<00:36, 250.16it/s]Running 10000 simulations.:   8%|▊         | 803/10000 [00:03<00:36, 250.52it/s]Running 10000 simulations.:   8%|▊         | 829/10000 [00:03<00:36, 251.09it/s]Running 10000 simulations.:   9%|▊         | 855/10000 [00:03<00:36, 251.34it/s]Running 10000 simulations.:   9%|▉         | 881/10000 [00:03<00:36, 249.79it/s]Running 10000 simulations.:   9%|▉         | 906/10000 [00:03<00:36, 249.77it/s]Running 10000 simulations.:   9%|▉         | 931/10000 [00:03<00:36, 248.86it/s]Running 10000 simulations.:  10%|▉         | 957/10000 [00:03<00:36, 249.60it/s]Running 10000 simulations.:  10%|▉         | 983/10000 [00:03<00:36, 250.41it/s]Running 10000 simulations.:  10%|█         | 1009/10000 [00:04<00:35, 251.06it/s]Running 10000 simulations.:  10%|█         | 1035/10000 [00:04<00:35, 251.10it/s]Running 10000 simulations.:  11%|█         | 1061/10000 [00:04<00:35, 251.29it/s]Running 10000 simulations.:  11%|█         | 1087/10000 [00:04<00:35, 249.90it/s]Running 10000 simulations.:  11%|█         | 1112/10000 [00:04<00:35, 249.52it/s]Running 10000 simulations.:  11%|█▏        | 1137/10000 [00:04<00:35, 248.07it/s]Running 10000 simulations.:  12%|█▏        | 1162/10000 [00:04<00:35, 245.55it/s]Running 10000 simulations.:  12%|█▏        | 1187/10000 [00:04<00:35, 246.22it/s]Running 10000 simulations.:  12%|█▏        | 1212/10000 [00:04<00:35, 246.78it/s]Running 10000 simulations.:  12%|█▏        | 1237/10000 [00:04<00:35, 246.97it/s]Running 10000 simulations.:  13%|█▎        | 1262/10000 [00:05<00:35, 246.88it/s]Running 10000 simulations.:  13%|█▎        | 1287/10000 [00:05<00:35, 247.31it/s]Running 10000 simulations.:  13%|█▎        | 1313/10000 [00:05<00:34, 248.29it/s]Running 10000 simulations.:  13%|█▎        | 1338/10000 [00:05<00:34, 247.56it/s]Running 10000 simulations.:  14%|█▎        | 1363/10000 [00:05<00:34, 247.65it/s]Running 10000 simulations.:  14%|█▍        | 1388/10000 [00:05<00:34, 246.48it/s]Running 10000 simulations.:  14%|█▍        | 1413/10000 [00:05<00:34, 245.40it/s]Running 10000 simulations.:  14%|█▍        | 1438/10000 [00:05<00:34, 244.92it/s]Running 10000 simulations.:  15%|█▍        | 1463/10000 [00:05<00:34, 244.43it/s]Running 10000 simulations.:  15%|█▍        | 1488/10000 [00:05<00:34, 244.43it/s]Running 10000 simulations.:  15%|█▌        | 1513/10000 [00:06<00:34, 244.95it/s]Running 10000 simulations.:  15%|█▌        | 1538/10000 [00:06<00:34, 244.57it/s]Running 10000 simulations.:  16%|█▌        | 1563/10000 [00:06<00:34, 243.93it/s]Running 10000 simulations.:  16%|█▌        | 1588/10000 [00:06<00:34, 244.18it/s]Running 10000 simulations.:  16%|█▌        | 1613/10000 [00:06<00:34, 243.98it/s]Running 10000 simulations.:  16%|█▋        | 1638/10000 [00:06<00:34, 243.60it/s]Running 10000 simulations.:  17%|█▋        | 1663/10000 [00:06<00:34, 243.58it/s]Running 10000 simulations.:  17%|█▋        | 1688/10000 [00:06<00:34, 243.08it/s]Running 10000 simulations.:  17%|█▋        | 1713/10000 [00:06<00:33, 244.37it/s]Running 10000 simulations.:  17%|█▋        | 1739/10000 [00:06<00:33, 247.63it/s]Running 10000 simulations.:  18%|█▊        | 1764/10000 [00:07<00:33, 247.85it/s]Running 10000 simulations.:  18%|█▊        | 1790/10000 [00:07<00:33, 248.57it/s]Running 10000 simulations.:  18%|█▊        | 1815/10000 [00:07<00:33, 247.60it/s]Running 10000 simulations.:  18%|█▊        | 1840/10000 [00:07<00:32, 247.56it/s]Running 10000 simulations.:  19%|█▊        | 1865/10000 [00:07<00:32, 247.90it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:07<00:32, 248.38it/s]Running 10000 simulations.:  19%|█▉        | 1915/10000 [00:07<00:32, 247.86it/s]Running 10000 simulations.:  19%|█▉        | 1940/10000 [00:07<00:32, 248.04it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:07<00:32, 248.48it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:07<00:32, 249.71it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:08<00:32, 249.45it/s]Running 10000 simulations.:  20%|██        | 2041/10000 [00:08<00:32, 248.33it/s]Running 10000 simulations.:  21%|██        | 2066/10000 [00:08<00:31, 248.07it/s]Running 10000 simulations.:  21%|██        | 2091/10000 [00:08<00:31, 247.76it/s]Running 10000 simulations.:  21%|██        | 2116/10000 [00:08<00:31, 247.34it/s]Running 10000 simulations.:  21%|██▏       | 2141/10000 [00:08<00:31, 246.91it/s]Running 10000 simulations.:  22%|██▏       | 2166/10000 [00:08<00:31, 247.20it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:08<00:31, 247.73it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:08<00:31, 247.49it/s]Running 10000 simulations.:  22%|██▏       | 2241/10000 [00:08<00:31, 247.67it/s]Running 10000 simulations.:  23%|██▎       | 2267/10000 [00:09<00:31, 248.71it/s]Running 10000 simulations.:  23%|██▎       | 2293/10000 [00:09<00:30, 249.84it/s]Running 10000 simulations.:  23%|██▎       | 2319/10000 [00:09<00:30, 250.38it/s]Running 10000 simulations.:  23%|██▎       | 2345/10000 [00:09<00:30, 250.75it/s]Running 10000 simulations.:  24%|██▎       | 2371/10000 [00:09<00:30, 249.83it/s]Running 10000 simulations.:  24%|██▍       | 2396/10000 [00:09<00:30, 249.28it/s]Running 10000 simulations.:  24%|██▍       | 2421/10000 [00:09<00:30, 248.76it/s]Running 10000 simulations.:  24%|██▍       | 2446/10000 [00:09<00:30, 248.52it/s]Running 10000 simulations.:  25%|██▍       | 2471/10000 [00:09<00:30, 248.41it/s]Running 10000 simulations.:  25%|██▍       | 2496/10000 [00:10<00:30, 248.16it/s]Running 10000 simulations.:  25%|██▌       | 2521/10000 [00:10<00:30, 248.16it/s]Running 10000 simulations.:  25%|██▌       | 2546/10000 [00:10<00:30, 248.22it/s]Running 10000 simulations.:  26%|██▌       | 2571/10000 [00:10<00:29, 247.97it/s]Running 10000 simulations.:  26%|██▌       | 2596/10000 [00:10<00:29, 248.12it/s]Running 10000 simulations.:  26%|██▌       | 2621/10000 [00:10<00:29, 246.12it/s]Running 10000 simulations.:  26%|██▋       | 2646/10000 [00:10<00:29, 245.71it/s]Running 10000 simulations.:  27%|██▋       | 2671/10000 [00:10<00:29, 245.74it/s]Running 10000 simulations.:  27%|██▋       | 2696/10000 [00:10<00:29, 246.13it/s]Running 10000 simulations.:  27%|██▋       | 2721/10000 [00:10<00:29, 246.10it/s]Running 10000 simulations.:  27%|██▋       | 2746/10000 [00:11<00:29, 245.68it/s]Running 10000 simulations.:  28%|██▊       | 2771/10000 [00:11<00:29, 245.59it/s]Running 10000 simulations.:  28%|██▊       | 2796/10000 [00:11<00:29, 246.83it/s]Running 10000 simulations.:  28%|██▊       | 2821/10000 [00:11<00:29, 246.97it/s]Running 10000 simulations.:  28%|██▊       | 2846/10000 [00:11<00:28, 247.02it/s]Running 10000 simulations.:  29%|██▊       | 2872/10000 [00:11<00:28, 248.07it/s]Running 10000 simulations.:  29%|██▉       | 2897/10000 [00:11<00:28, 248.27it/s]Running 10000 simulations.:  29%|██▉       | 2922/10000 [00:11<00:28, 248.78it/s]Running 10000 simulations.:  29%|██▉       | 2947/10000 [00:11<00:28, 247.70it/s]Running 10000 simulations.:  30%|██▉       | 2972/10000 [00:11<00:28, 247.61it/s]Running 10000 simulations.:  30%|██▉       | 2997/10000 [00:12<00:28, 247.31it/s]Running 10000 simulations.:  30%|███       | 3022/10000 [00:12<00:28, 245.25it/s]Running 10000 simulations.:  30%|███       | 3047/10000 [00:12<00:28, 242.53it/s]Running 10000 simulations.:  31%|███       | 3072/10000 [00:12<00:28, 244.63it/s]Running 10000 simulations.:  31%|███       | 3098/10000 [00:12<00:28, 246.33it/s]Running 10000 simulations.:  31%|███       | 3123/10000 [00:12<00:27, 247.10it/s]Running 10000 simulations.:  31%|███▏      | 3149/10000 [00:12<00:27, 247.98it/s]Running 10000 simulations.:  32%|███▏      | 3174/10000 [00:12<00:27, 248.53it/s]Running 10000 simulations.:  32%|███▏      | 3199/10000 [00:12<00:27, 248.54it/s]Running 10000 simulations.:  32%|███▏      | 3224/10000 [00:12<00:27, 248.22it/s]Running 10000 simulations.:  32%|███▏      | 3249/10000 [00:13<00:27, 248.05it/s]Running 10000 simulations.:  33%|███▎      | 3274/10000 [00:13<00:27, 244.30it/s]Running 10000 simulations.:  33%|███▎      | 3299/10000 [00:13<00:27, 244.87it/s]Running 10000 simulations.:  33%|███▎      | 3325/10000 [00:13<00:27, 246.84it/s]Running 10000 simulations.:  34%|███▎      | 3351/10000 [00:13<00:26, 248.21it/s]Running 10000 simulations.:  34%|███▍      | 3376/10000 [00:13<00:26, 248.69it/s]Running 10000 simulations.:  34%|███▍      | 3401/10000 [00:13<00:26, 248.83it/s]Running 10000 simulations.:  34%|███▍      | 3426/10000 [00:13<00:26, 248.05it/s]Running 10000 simulations.:  35%|███▍      | 3451/10000 [00:13<00:26, 248.42it/s]Running 10000 simulations.:  35%|███▍      | 3476/10000 [00:13<00:26, 246.83it/s]Running 10000 simulations.:  35%|███▌      | 3501/10000 [00:14<00:26, 246.80it/s]Running 10000 simulations.:  35%|███▌      | 3526/10000 [00:14<00:26, 246.01it/s]Running 10000 simulations.:  36%|███▌      | 3551/10000 [00:14<00:26, 245.83it/s]Running 10000 simulations.:  36%|███▌      | 3576/10000 [00:14<00:26, 245.55it/s]Running 10000 simulations.:  36%|███▌      | 3601/10000 [00:14<00:26, 245.85it/s]Running 10000 simulations.:  36%|███▋      | 3626/10000 [00:14<00:25, 246.26it/s]Running 10000 simulations.:  37%|███▋      | 3651/10000 [00:14<00:25, 246.05it/s]Running 10000 simulations.:  37%|███▋      | 3676/10000 [00:14<00:25, 246.57it/s]Running 10000 simulations.:  37%|███▋      | 3701/10000 [00:14<00:25, 246.32it/s]Running 10000 simulations.:  37%|███▋      | 3726/10000 [00:15<00:25, 246.00it/s]Running 10000 simulations.:  38%|███▊      | 3751/10000 [00:15<00:25, 245.61it/s]Running 10000 simulations.:  38%|███▊      | 3776/10000 [00:15<00:25, 246.06it/s]Running 10000 simulations.:  38%|███▊      | 3801/10000 [00:15<00:25, 245.86it/s]Running 10000 simulations.:  38%|███▊      | 3826/10000 [00:15<00:25, 245.30it/s]Running 10000 simulations.:  39%|███▊      | 3851/10000 [00:15<00:25, 242.16it/s]Running 10000 simulations.:  39%|███▉      | 3876/10000 [00:15<00:25, 240.52it/s]Running 10000 simulations.:  39%|███▉      | 3901/10000 [00:15<00:25, 242.59it/s]Running 10000 simulations.:  39%|███▉      | 3926/10000 [00:15<00:24, 244.17it/s]Running 10000 simulations.:  40%|███▉      | 3951/10000 [00:15<00:24, 244.67it/s]Running 10000 simulations.:  40%|███▉      | 3976/10000 [00:16<00:24, 244.80it/s]Running 10000 simulations.:  40%|████      | 4001/10000 [00:16<00:24, 245.54it/s]Running 10000 simulations.:  40%|████      | 4026/10000 [00:16<00:24, 246.44it/s]Running 10000 simulations.:  41%|████      | 4051/10000 [00:16<00:24, 246.33it/s]Running 10000 simulations.:  41%|████      | 4076/10000 [00:16<00:24, 245.01it/s]Running 10000 simulations.:  41%|████      | 4101/10000 [00:16<00:24, 245.68it/s]Running 10000 simulations.:  41%|████▏     | 4126/10000 [00:16<00:23, 246.73it/s]Running 10000 simulations.:  42%|████▏     | 4151/10000 [00:16<00:23, 247.33it/s]Running 10000 simulations.:  42%|████▏     | 4176/10000 [00:16<00:23, 247.37it/s]Running 10000 simulations.:  42%|████▏     | 4201/10000 [00:16<00:23, 247.62it/s]Running 10000 simulations.:  42%|████▏     | 4226/10000 [00:17<00:23, 247.44it/s]Running 10000 simulations.:  43%|████▎     | 4251/10000 [00:17<00:23, 247.49it/s]Running 10000 simulations.:  43%|████▎     | 4276/10000 [00:17<00:23, 247.68it/s]Running 10000 simulations.:  43%|████▎     | 4301/10000 [00:17<00:22, 248.17it/s]Running 10000 simulations.:  43%|████▎     | 4327/10000 [00:17<00:22, 248.91it/s]Running 10000 simulations.:  44%|████▎     | 4352/10000 [00:17<00:22, 249.11it/s]Running 10000 simulations.:  44%|████▍     | 4378/10000 [00:17<00:22, 249.84it/s]Running 10000 simulations.:  44%|████▍     | 4403/10000 [00:17<00:22, 249.27it/s]Running 10000 simulations.:  44%|████▍     | 4428/10000 [00:17<00:22, 248.17it/s]Running 10000 simulations.:  45%|████▍     | 4453/10000 [00:17<00:22, 248.05it/s]Running 10000 simulations.:  45%|████▍     | 4478/10000 [00:18<00:22, 248.38it/s]Running 10000 simulations.:  45%|████▌     | 4503/10000 [00:18<00:22, 248.57it/s]Running 10000 simulations.:  45%|████▌     | 4528/10000 [00:18<00:22, 248.05it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:18<00:21, 248.25it/s]Running 10000 simulations.:  46%|████▌     | 4578/10000 [00:18<00:21, 247.23it/s]Running 10000 simulations.:  46%|████▌     | 4603/10000 [00:18<00:21, 247.18it/s]Running 10000 simulations.:  46%|████▋     | 4628/10000 [00:18<00:21, 247.29it/s]Running 10000 simulations.:  47%|████▋     | 4653/10000 [00:18<00:21, 247.13it/s]Running 10000 simulations.:  47%|████▋     | 4678/10000 [00:18<00:21, 246.66it/s]Running 10000 simulations.:  47%|████▋     | 4703/10000 [00:18<00:21, 246.49it/s]Running 10000 simulations.:  47%|████▋     | 4728/10000 [00:19<00:21, 247.25it/s]Running 10000 simulations.:  48%|████▊     | 4753/10000 [00:19<00:21, 248.03it/s]Running 10000 simulations.:  48%|████▊     | 4778/10000 [00:19<00:21, 247.96it/s]Running 10000 simulations.:  48%|████▊     | 4803/10000 [00:19<00:20, 248.12it/s]Running 10000 simulations.:  48%|████▊     | 4828/10000 [00:19<00:20, 248.10it/s]Running 10000 simulations.:  49%|████▊     | 4853/10000 [00:19<00:20, 247.63it/s]Running 10000 simulations.:  49%|████▉     | 4878/10000 [00:19<00:20, 247.81it/s]Running 10000 simulations.:  49%|████▉     | 4903/10000 [00:19<00:20, 248.18it/s]Running 10000 simulations.:  49%|████▉     | 4929/10000 [00:19<00:20, 248.83it/s]Running 10000 simulations.:  50%|████▉     | 4955/10000 [00:19<00:20, 249.23it/s]Running 10000 simulations.:  50%|████▉     | 4980/10000 [00:20<00:20, 248.76it/s]Running 10000 simulations.:  50%|█████     | 5005/10000 [00:20<00:20, 248.34it/s]Running 10000 simulations.:  50%|█████     | 5030/10000 [00:20<00:20, 248.14it/s]Running 10000 simulations.:  51%|█████     | 5055/10000 [00:20<00:19, 247.53it/s]Running 10000 simulations.:  51%|█████     | 5080/10000 [00:20<00:19, 247.39it/s]Running 10000 simulations.:  51%|█████     | 5105/10000 [00:20<00:19, 247.40it/s]Running 10000 simulations.:  51%|█████▏    | 5130/10000 [00:20<00:19, 247.19it/s]Running 10000 simulations.:  52%|█████▏    | 5155/10000 [00:20<00:19, 247.90it/s]Running 10000 simulations.:  52%|█████▏    | 5180/10000 [00:20<00:19, 247.61it/s]Running 10000 simulations.:  52%|█████▏    | 5205/10000 [00:20<00:19, 247.47it/s]Running 10000 simulations.:  52%|█████▏    | 5230/10000 [00:21<00:19, 247.29it/s]Running 10000 simulations.:  53%|█████▎    | 5255/10000 [00:21<00:19, 246.92it/s]Running 10000 simulations.:  53%|█████▎    | 5280/10000 [00:21<00:19, 246.03it/s]Running 10000 simulations.:  53%|█████▎    | 5305/10000 [00:21<00:19, 242.02it/s]Running 10000 simulations.:  53%|█████▎    | 5330/10000 [00:21<00:19, 243.17it/s]Running 10000 simulations.:  54%|█████▎    | 5355/10000 [00:21<00:19, 244.15it/s]Running 10000 simulations.:  54%|█████▍    | 5380/10000 [00:21<00:18, 244.95it/s]Running 10000 simulations.:  54%|█████▍    | 5405/10000 [00:21<00:18, 245.06it/s]Running 10000 simulations.:  54%|█████▍    | 5430/10000 [00:21<00:18, 245.33it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:22<00:18, 245.05it/s]Running 10000 simulations.:  55%|█████▍    | 5480/10000 [00:22<00:18, 244.91it/s]Running 10000 simulations.:  55%|█████▌    | 5505/10000 [00:22<00:18, 244.30it/s]Running 10000 simulations.:  55%|█████▌    | 5530/10000 [00:22<00:18, 244.35it/s]Running 10000 simulations.:  56%|█████▌    | 5555/10000 [00:22<00:18, 244.25it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:22<00:18, 245.08it/s]Running 10000 simulations.:  56%|█████▌    | 5605/10000 [00:22<00:17, 246.08it/s]Running 10000 simulations.:  56%|█████▋    | 5630/10000 [00:22<00:17, 246.45it/s]Running 10000 simulations.:  57%|█████▋    | 5655/10000 [00:22<00:17, 246.56it/s]Running 10000 simulations.:  57%|█████▋    | 5680/10000 [00:22<00:17, 246.43it/s]Running 10000 simulations.:  57%|█████▋    | 5705/10000 [00:23<00:17, 245.92it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:23<00:18, 234.66it/s]Running 10000 simulations.:  58%|█████▊    | 5755/10000 [00:23<00:17, 238.02it/s]Running 10000 simulations.:  58%|█████▊    | 5780/10000 [00:23<00:17, 240.27it/s]Running 10000 simulations.:  58%|█████▊    | 5805/10000 [00:23<00:17, 241.51it/s]Running 10000 simulations.:  58%|█████▊    | 5830/10000 [00:23<00:17, 242.89it/s]Running 10000 simulations.:  59%|█████▊    | 5855/10000 [00:23<00:17, 242.89it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:23<00:16, 244.83it/s]Running 10000 simulations.:  59%|█████▉    | 5905/10000 [00:23<00:16, 245.02it/s]Running 10000 simulations.:  59%|█████▉    | 5930/10000 [00:23<00:16, 245.81it/s]Running 10000 simulations.:  60%|█████▉    | 5955/10000 [00:24<00:16, 246.09it/s]Running 10000 simulations.:  60%|█████▉    | 5980/10000 [00:24<00:16, 246.07it/s]Running 10000 simulations.:  60%|██████    | 6005/10000 [00:24<00:16, 246.44it/s]Running 10000 simulations.:  60%|██████    | 6030/10000 [00:24<00:16, 247.39it/s]Running 10000 simulations.:  61%|██████    | 6055/10000 [00:24<00:15, 248.05it/s]Running 10000 simulations.:  61%|██████    | 6080/10000 [00:24<00:15, 248.04it/s]Running 10000 simulations.:  61%|██████    | 6105/10000 [00:24<00:15, 247.17it/s]Running 10000 simulations.:  61%|██████▏   | 6130/10000 [00:24<00:15, 246.68it/s]Running 10000 simulations.:  62%|██████▏   | 6155/10000 [00:24<00:15, 245.58it/s]Running 10000 simulations.:  62%|██████▏   | 6180/10000 [00:24<00:15, 245.56it/s]Running 10000 simulations.:  62%|██████▏   | 6205/10000 [00:25<00:15, 245.94it/s]Running 10000 simulations.:  62%|██████▏   | 6230/10000 [00:25<00:15, 246.51it/s]Running 10000 simulations.:  63%|██████▎   | 6255/10000 [00:25<00:15, 244.99it/s]Running 10000 simulations.:  63%|██████▎   | 6280/10000 [00:25<00:15, 245.44it/s]Running 10000 simulations.:  63%|██████▎   | 6305/10000 [00:25<00:15, 245.35it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:25<00:14, 245.15it/s]Running 10000 simulations.:  64%|██████▎   | 6355/10000 [00:25<00:14, 245.49it/s]Running 10000 simulations.:  64%|██████▍   | 6380/10000 [00:25<00:14, 245.60it/s]Running 10000 simulations.:  64%|██████▍   | 6405/10000 [00:25<00:14, 246.13it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:25<00:14, 246.39it/s]Running 10000 simulations.:  65%|██████▍   | 6455/10000 [00:26<00:14, 246.35it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:26<00:14, 246.26it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:26<00:14, 245.98it/s]Running 10000 simulations.:  65%|██████▌   | 6530/10000 [00:26<00:14, 246.34it/s]Running 10000 simulations.:  66%|██████▌   | 6555/10000 [00:26<00:14, 245.87it/s]Running 10000 simulations.:  66%|██████▌   | 6580/10000 [00:26<00:13, 246.20it/s]Running 10000 simulations.:  66%|██████▌   | 6605/10000 [00:26<00:13, 246.11it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:26<00:13, 246.59it/s]Running 10000 simulations.:  67%|██████▋   | 6655/10000 [00:26<00:13, 246.05it/s]Running 10000 simulations.:  67%|██████▋   | 6680/10000 [00:27<00:13, 246.79it/s]Running 10000 simulations.:  67%|██████▋   | 6705/10000 [00:27<00:13, 247.25it/s]Running 10000 simulations.:  67%|██████▋   | 6730/10000 [00:27<00:13, 247.92it/s]Running 10000 simulations.:  68%|██████▊   | 6755/10000 [00:27<00:13, 248.05it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:27<00:12, 248.24it/s]Running 10000 simulations.:  68%|██████▊   | 6806/10000 [00:27<00:12, 248.97it/s]Running 10000 simulations.:  68%|██████▊   | 6831/10000 [00:27<00:12, 249.25it/s]Running 10000 simulations.:  69%|██████▊   | 6856/10000 [00:27<00:12, 249.01it/s]Running 10000 simulations.:  69%|██████▉   | 6882/10000 [00:27<00:12, 249.54it/s]Running 10000 simulations.:  69%|██████▉   | 6907/10000 [00:27<00:12, 248.89it/s]Running 10000 simulations.:  69%|██████▉   | 6932/10000 [00:28<00:12, 245.53it/s]Running 10000 simulations.:  70%|██████▉   | 6957/10000 [00:28<00:12, 244.43it/s]Running 10000 simulations.:  70%|██████▉   | 6982/10000 [00:28<00:12, 245.16it/s]Running 10000 simulations.:  70%|███████   | 7007/10000 [00:28<00:12, 246.08it/s]Running 10000 simulations.:  70%|███████   | 7032/10000 [00:28<00:12, 246.06it/s]Running 10000 simulations.:  71%|███████   | 7057/10000 [00:28<00:11, 246.25it/s]Running 10000 simulations.:  71%|███████   | 7082/10000 [00:28<00:11, 246.38it/s]Running 10000 simulations.:  71%|███████   | 7107/10000 [00:28<00:11, 246.92it/s]Running 10000 simulations.:  71%|███████▏  | 7132/10000 [00:28<00:11, 247.04it/s]Running 10000 simulations.:  72%|███████▏  | 7157/10000 [00:28<00:11, 247.45it/s]Running 10000 simulations.:  72%|███████▏  | 7182/10000 [00:29<00:11, 247.65it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:29<00:11, 247.84it/s]Running 10000 simulations.:  72%|███████▏  | 7232/10000 [00:29<00:11, 247.95it/s]Running 10000 simulations.:  73%|███████▎  | 7258/10000 [00:29<00:11, 248.72it/s]Running 10000 simulations.:  73%|███████▎  | 7283/10000 [00:29<00:10, 248.84it/s]Running 10000 simulations.:  73%|███████▎  | 7309/10000 [00:29<00:10, 249.47it/s]Running 10000 simulations.:  73%|███████▎  | 7334/10000 [00:29<00:10, 249.40it/s]Running 10000 simulations.:  74%|███████▎  | 7360/10000 [00:29<00:10, 250.41it/s]Running 10000 simulations.:  74%|███████▍  | 7386/10000 [00:29<00:10, 251.38it/s]Running 10000 simulations.:  74%|███████▍  | 7412/10000 [00:29<00:10, 251.58it/s]Running 10000 simulations.:  74%|███████▍  | 7438/10000 [00:30<00:10, 249.49it/s]Running 10000 simulations.:  75%|███████▍  | 7463/10000 [00:30<00:10, 246.65it/s]Running 10000 simulations.:  75%|███████▍  | 7488/10000 [00:30<00:10, 242.28it/s]Running 10000 simulations.:  75%|███████▌  | 7513/10000 [00:30<00:10, 243.49it/s]Running 10000 simulations.:  75%|███████▌  | 7539/10000 [00:30<00:10, 245.45it/s]Running 10000 simulations.:  76%|███████▌  | 7564/10000 [00:30<00:09, 246.08it/s]Running 10000 simulations.:  76%|███████▌  | 7589/10000 [00:30<00:09, 246.92it/s]Running 10000 simulations.:  76%|███████▌  | 7615/10000 [00:30<00:09, 247.97it/s]Running 10000 simulations.:  76%|███████▋  | 7641/10000 [00:30<00:09, 248.62it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:30<00:09, 248.91it/s]Running 10000 simulations.:  77%|███████▋  | 7692/10000 [00:31<00:09, 249.31it/s]Running 10000 simulations.:  77%|███████▋  | 7718/10000 [00:31<00:09, 249.56it/s]Running 10000 simulations.:  77%|███████▋  | 7744/10000 [00:31<00:09, 250.13it/s]Running 10000 simulations.:  78%|███████▊  | 7770/10000 [00:31<00:08, 251.11it/s]Running 10000 simulations.:  78%|███████▊  | 7796/10000 [00:31<00:08, 251.21it/s]Running 10000 simulations.:  78%|███████▊  | 7822/10000 [00:31<00:08, 251.00it/s]Running 10000 simulations.:  78%|███████▊  | 7848/10000 [00:31<00:08, 250.65it/s]Running 10000 simulations.:  79%|███████▊  | 7874/10000 [00:31<00:08, 250.61it/s]Running 10000 simulations.:  79%|███████▉  | 7900/10000 [00:31<00:08, 249.51it/s]Running 10000 simulations.:  79%|███████▉  | 7925/10000 [00:32<00:08, 249.47it/s]Running 10000 simulations.:  80%|███████▉  | 7951/10000 [00:32<00:08, 249.79it/s]Running 10000 simulations.:  80%|███████▉  | 7977/10000 [00:32<00:08, 250.35it/s]Running 10000 simulations.:  80%|████████  | 8003/10000 [00:32<00:07, 250.45it/s]Running 10000 simulations.:  80%|████████  | 8029/10000 [00:32<00:07, 249.93it/s]Running 10000 simulations.:  81%|████████  | 8055/10000 [00:32<00:07, 249.93it/s]Running 10000 simulations.:  81%|████████  | 8080/10000 [00:32<00:07, 249.79it/s]Running 10000 simulations.:  81%|████████  | 8105/10000 [00:32<00:07, 249.71it/s]Running 10000 simulations.:  81%|████████▏ | 8130/10000 [00:32<00:07, 249.49it/s]Running 10000 simulations.:  82%|████████▏ | 8155/10000 [00:32<00:07, 248.88it/s]Running 10000 simulations.:  82%|████████▏ | 8180/10000 [00:33<00:07, 248.10it/s]Running 10000 simulations.:  82%|████████▏ | 8205/10000 [00:33<00:07, 248.26it/s]Running 10000 simulations.:  82%|████████▏ | 8230/10000 [00:33<00:07, 248.13it/s]Running 10000 simulations.:  83%|████████▎ | 8255/10000 [00:33<00:07, 248.03it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:33<00:06, 248.20it/s]Running 10000 simulations.:  83%|████████▎ | 8305/10000 [00:33<00:06, 248.06it/s]Running 10000 simulations.:  83%|████████▎ | 8331/10000 [00:33<00:06, 249.57it/s]Running 10000 simulations.:  84%|████████▎ | 8357/10000 [00:33<00:06, 250.29it/s]Running 10000 simulations.:  84%|████████▍ | 8383/10000 [00:33<00:06, 250.76it/s]Running 10000 simulations.:  84%|████████▍ | 8409/10000 [00:33<00:06, 251.56it/s]Running 10000 simulations.:  84%|████████▍ | 8435/10000 [00:34<00:06, 250.85it/s]Running 10000 simulations.:  85%|████████▍ | 8461/10000 [00:34<00:06, 251.02it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [00:34<00:06, 250.02it/s]Running 10000 simulations.:  85%|████████▌ | 8513/10000 [00:34<00:05, 250.30it/s]Running 10000 simulations.:  85%|████████▌ | 8539/10000 [00:34<00:05, 250.74it/s]Running 10000 simulations.:  86%|████████▌ | 8565/10000 [00:34<00:05, 249.30it/s]Running 10000 simulations.:  86%|████████▌ | 8590/10000 [00:34<00:05, 249.25it/s]Running 10000 simulations.:  86%|████████▌ | 8616/10000 [00:34<00:05, 250.26it/s]Running 10000 simulations.:  86%|████████▋ | 8642/10000 [00:34<00:05, 250.67it/s]Running 10000 simulations.:  87%|████████▋ | 8668/10000 [00:34<00:05, 250.29it/s]Running 10000 simulations.:  87%|████████▋ | 8694/10000 [00:35<00:05, 248.55it/s]Running 10000 simulations.:  87%|████████▋ | 8719/10000 [00:35<00:05, 247.97it/s]Running 10000 simulations.:  87%|████████▋ | 8745/10000 [00:35<00:05, 249.05it/s]Running 10000 simulations.:  88%|████████▊ | 8771/10000 [00:35<00:04, 249.40it/s]Running 10000 simulations.:  88%|████████▊ | 8796/10000 [00:35<00:04, 248.97it/s]Running 10000 simulations.:  88%|████████▊ | 8822/10000 [00:35<00:04, 249.85it/s]Running 10000 simulations.:  88%|████████▊ | 8848/10000 [00:35<00:04, 249.97it/s]Running 10000 simulations.:  89%|████████▊ | 8874/10000 [00:35<00:04, 250.45it/s]Running 10000 simulations.:  89%|████████▉ | 8900/10000 [00:35<00:04, 250.78it/s]Running 10000 simulations.:  89%|████████▉ | 8926/10000 [00:36<00:04, 250.71it/s]Running 10000 simulations.:  90%|████████▉ | 8952/10000 [00:36<00:04, 250.38it/s]Running 10000 simulations.:  90%|████████▉ | 8978/10000 [00:36<00:04, 249.64it/s]Running 10000 simulations.:  90%|█████████ | 9004/10000 [00:36<00:03, 250.73it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:36<00:03, 250.47it/s]Running 10000 simulations.:  91%|█████████ | 9056/10000 [00:36<00:03, 250.82it/s]Running 10000 simulations.:  91%|█████████ | 9082/10000 [00:36<00:03, 250.50it/s]Running 10000 simulations.:  91%|█████████ | 9108/10000 [00:36<00:03, 248.92it/s]Running 10000 simulations.:  91%|█████████▏| 9134/10000 [00:36<00:03, 249.68it/s]Running 10000 simulations.:  92%|█████████▏| 9159/10000 [00:36<00:03, 249.62it/s]Running 10000 simulations.:  92%|█████████▏| 9185/10000 [00:37<00:03, 249.84it/s]Running 10000 simulations.:  92%|█████████▏| 9211/10000 [00:37<00:03, 250.46it/s]Running 10000 simulations.:  92%|█████████▏| 9237/10000 [00:37<00:03, 249.80it/s]Running 10000 simulations.:  93%|█████████▎| 9262/10000 [00:37<00:02, 249.48it/s]Running 10000 simulations.:  93%|█████████▎| 9288/10000 [00:37<00:02, 249.91it/s]Running 10000 simulations.:  93%|█████████▎| 9314/10000 [00:37<00:02, 250.10it/s]Running 10000 simulations.:  93%|█████████▎| 9340/10000 [00:37<00:02, 246.25it/s]Running 10000 simulations.:  94%|█████████▎| 9365/10000 [00:37<00:02, 246.32it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:37<00:02, 246.81it/s]Running 10000 simulations.:  94%|█████████▍| 9415/10000 [00:37<00:02, 246.83it/s]Running 10000 simulations.:  94%|█████████▍| 9440/10000 [00:38<00:02, 247.26it/s]Running 10000 simulations.:  95%|█████████▍| 9465/10000 [00:38<00:02, 247.12it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [00:38<00:02, 245.98it/s]Running 10000 simulations.:  95%|█████████▌| 9515/10000 [00:38<00:01, 246.86it/s]Running 10000 simulations.:  95%|█████████▌| 9540/10000 [00:38<00:01, 247.67it/s]Running 10000 simulations.:  96%|█████████▌| 9566/10000 [00:38<00:01, 248.86it/s]Running 10000 simulations.:  96%|█████████▌| 9591/10000 [00:38<00:01, 249.04it/s]Running 10000 simulations.:  96%|█████████▌| 9617/10000 [00:38<00:01, 249.39it/s]Running 10000 simulations.:  96%|█████████▋| 9643/10000 [00:38<00:01, 249.66it/s]Running 10000 simulations.:  97%|█████████▋| 9669/10000 [00:39<00:01, 250.60it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:39<00:01, 251.53it/s]Running 10000 simulations.:  97%|█████████▋| 9721/10000 [00:39<00:01, 251.64it/s]Running 10000 simulations.:  97%|█████████▋| 9747/10000 [00:39<00:01, 246.90it/s]Running 10000 simulations.:  98%|█████████▊| 9772/10000 [00:39<00:00, 246.59it/s]Running 10000 simulations.:  98%|█████████▊| 9798/10000 [00:39<00:00, 248.73it/s]Running 10000 simulations.:  98%|█████████▊| 9824/10000 [00:39<00:00, 249.25it/s]Running 10000 simulations.:  98%|█████████▊| 9850/10000 [00:39<00:00, 249.91it/s]Running 10000 simulations.:  99%|█████████▉| 9876/10000 [00:39<00:00, 250.13it/s]Running 10000 simulations.:  99%|█████████▉| 9902/10000 [00:39<00:00, 249.86it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [00:40<00:00, 251.31it/s]Running 10000 simulations.: 100%|█████████▉| 9954/10000 [00:40<00:00, 252.17it/s]Running 10000 simulations.: 100%|█████████▉| 9980/10000 [00:40<00:00, 253.16it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:40<00:00, 247.95it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:38, 257.61it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:38, 257.85it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:38, 255.95it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:38, 255.46it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:38, 254.40it/s]Running 10000 simulations.:   2%|▏         | 156/10000 [00:00<00:38, 255.27it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:00<00:38, 254.66it/s]Running 10000 simulations.:   2%|▏         | 208/10000 [00:00<00:38, 255.04it/s]Running 10000 simulations.:   2%|▏         | 233/10000 [00:00<00:38, 250.85it/s]Running 10000 simulations.:   3%|▎         | 258/10000 [00:01<00:39, 249.32it/s]Running 10000 simulations.:   3%|▎         | 283/10000 [00:01<00:39, 249.10it/s]Running 10000 simulations.:   3%|▎         | 309/10000 [00:01<00:38, 249.71it/s]Running 10000 simulations.:   3%|▎         | 335/10000 [00:01<00:38, 250.47it/s]Running 10000 simulations.:   4%|▎         | 361/10000 [00:01<00:38, 250.10it/s]Running 10000 simulations.:   4%|▍         | 386/10000 [00:01<00:38, 248.41it/s]Running 10000 simulations.:   4%|▍         | 411/10000 [00:01<00:38, 247.83it/s]Running 10000 simulations.:   4%|▍         | 436/10000 [00:01<00:38, 247.10it/s]Running 10000 simulations.:   5%|▍         | 461/10000 [00:01<00:38, 246.48it/s]Running 10000 simulations.:   5%|▍         | 486/10000 [00:01<00:38, 246.95it/s]Running 10000 simulations.:   5%|▌         | 511/10000 [00:02<00:38, 247.81it/s]Running 10000 simulations.:   5%|▌         | 536/10000 [00:02<00:38, 246.92it/s]Running 10000 simulations.:   6%|▌         | 561/10000 [00:02<00:38, 246.97it/s]Running 10000 simulations.:   6%|▌         | 586/10000 [00:02<00:38, 245.87it/s]Running 10000 simulations.:   6%|▌         | 611/10000 [00:02<00:38, 245.54it/s]Running 10000 simulations.:   6%|▋         | 636/10000 [00:02<00:38, 246.14it/s]Running 10000 simulations.:   7%|▋         | 662/10000 [00:02<00:37, 248.24it/s]Running 10000 simulations.:   7%|▋         | 687/10000 [00:02<00:37, 248.06it/s]Running 10000 simulations.:   7%|▋         | 712/10000 [00:02<00:37, 247.09it/s]Running 10000 simulations.:   7%|▋         | 737/10000 [00:02<00:37, 247.55it/s]Running 10000 simulations.:   8%|▊         | 762/10000 [00:03<00:37, 244.96it/s]Running 10000 simulations.:   8%|▊         | 787/10000 [00:03<00:38, 240.63it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:03<00:38, 241.26it/s]Running 10000 simulations.:   8%|▊         | 838/10000 [00:03<00:37, 244.51it/s]Running 10000 simulations.:   9%|▊         | 863/10000 [00:03<00:37, 244.92it/s]Running 10000 simulations.:   9%|▉         | 888/10000 [00:03<00:37, 245.24it/s]Running 10000 simulations.:   9%|▉         | 913/10000 [00:03<00:37, 244.45it/s]Running 10000 simulations.:   9%|▉         | 938/10000 [00:03<00:37, 244.80it/s]Running 10000 simulations.:  10%|▉         | 963/10000 [00:03<00:37, 243.60it/s]Running 10000 simulations.:  10%|▉         | 988/10000 [00:03<00:36, 245.22it/s]Running 10000 simulations.:  10%|█         | 1013/10000 [00:04<00:36, 246.16it/s]Running 10000 simulations.:  10%|█         | 1039/10000 [00:04<00:36, 247.64it/s]Running 10000 simulations.:  11%|█         | 1064/10000 [00:04<00:36, 247.80it/s]Running 10000 simulations.:  11%|█         | 1089/10000 [00:04<00:36, 246.27it/s]Running 10000 simulations.:  11%|█         | 1114/10000 [00:04<00:36, 244.94it/s]Running 10000 simulations.:  11%|█▏        | 1139/10000 [00:04<00:36, 244.44it/s]Running 10000 simulations.:  12%|█▏        | 1164/10000 [00:04<00:35, 245.90it/s]Running 10000 simulations.:  12%|█▏        | 1189/10000 [00:04<00:35, 246.93it/s]Running 10000 simulations.:  12%|█▏        | 1214/10000 [00:04<00:35, 247.40it/s]Running 10000 simulations.:  12%|█▏        | 1239/10000 [00:05<00:35, 247.01it/s]Running 10000 simulations.:  13%|█▎        | 1264/10000 [00:05<00:35, 246.75it/s]Running 10000 simulations.:  13%|█▎        | 1289/10000 [00:05<00:35, 246.36it/s]Running 10000 simulations.:  13%|█▎        | 1314/10000 [00:05<00:35, 245.50it/s]Running 10000 simulations.:  13%|█▎        | 1339/10000 [00:05<00:35, 245.12it/s]Running 10000 simulations.:  14%|█▎        | 1364/10000 [00:05<00:35, 244.33it/s]Running 10000 simulations.:  14%|█▍        | 1389/10000 [00:05<00:35, 244.24it/s]Running 10000 simulations.:  14%|█▍        | 1414/10000 [00:05<00:35, 244.30it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:05<00:34, 245.55it/s]Running 10000 simulations.:  15%|█▍        | 1464/10000 [00:05<00:34, 246.74it/s]Running 10000 simulations.:  15%|█▍        | 1489/10000 [00:06<00:34, 245.96it/s]Running 10000 simulations.:  15%|█▌        | 1514/10000 [00:06<00:34, 246.26it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:06<00:34, 246.23it/s]Running 10000 simulations.:  16%|█▌        | 1564/10000 [00:06<00:34, 245.66it/s]Running 10000 simulations.:  16%|█▌        | 1589/10000 [00:06<00:34, 245.48it/s]Running 10000 simulations.:  16%|█▌        | 1614/10000 [00:06<00:34, 246.25it/s]Running 10000 simulations.:  16%|█▋        | 1639/10000 [00:06<00:34, 245.84it/s]Running 10000 simulations.:  17%|█▋        | 1665/10000 [00:06<00:33, 247.24it/s]Running 10000 simulations.:  17%|█▋        | 1690/10000 [00:06<00:35, 233.86it/s]Running 10000 simulations.:  17%|█▋        | 1715/10000 [00:06<00:34, 236.76it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:07<00:34, 238.27it/s]Running 10000 simulations.:  18%|█▊        | 1765/10000 [00:07<00:34, 240.46it/s]Running 10000 simulations.:  18%|█▊        | 1790/10000 [00:07<00:33, 242.76it/s]Running 10000 simulations.:  18%|█▊        | 1815/10000 [00:07<00:33, 243.62it/s]Running 10000 simulations.:  18%|█▊        | 1840/10000 [00:07<00:33, 243.94it/s]Running 10000 simulations.:  19%|█▊        | 1865/10000 [00:07<00:33, 242.57it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:07<00:33, 242.99it/s]Running 10000 simulations.:  19%|█▉        | 1915/10000 [00:07<00:33, 243.92it/s]Running 10000 simulations.:  19%|█▉        | 1940/10000 [00:07<00:32, 244.67it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:07<00:33, 242.85it/s]Running 10000 simulations.:  20%|█▉        | 1990/10000 [00:08<00:33, 242.37it/s]Running 10000 simulations.:  20%|██        | 2015/10000 [00:08<00:33, 241.61it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:08<00:32, 241.88it/s]Running 10000 simulations.:  21%|██        | 2065/10000 [00:08<00:32, 242.62it/s]Running 10000 simulations.:  21%|██        | 2090/10000 [00:08<00:32, 243.48it/s]Running 10000 simulations.:  21%|██        | 2115/10000 [00:08<00:32, 242.50it/s]Running 10000 simulations.:  21%|██▏       | 2140/10000 [00:08<00:32, 242.30it/s]Running 10000 simulations.:  22%|██▏       | 2165/10000 [00:08<00:32, 242.03it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:08<00:32, 242.15it/s]Running 10000 simulations.:  22%|██▏       | 2215/10000 [00:09<00:32, 242.43it/s]Running 10000 simulations.:  22%|██▏       | 2240/10000 [00:09<00:32, 240.83it/s]Running 10000 simulations.:  23%|██▎       | 2265/10000 [00:09<00:31, 241.80it/s]Running 10000 simulations.:  23%|██▎       | 2290/10000 [00:09<00:31, 243.30it/s]Running 10000 simulations.:  23%|██▎       | 2315/10000 [00:09<00:31, 243.11it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:09<00:31, 241.92it/s]Running 10000 simulations.:  24%|██▎       | 2365/10000 [00:09<00:31, 240.94it/s]Running 10000 simulations.:  24%|██▍       | 2390/10000 [00:09<00:31, 241.08it/s]Running 10000 simulations.:  24%|██▍       | 2415/10000 [00:09<00:31, 242.21it/s]Running 10000 simulations.:  24%|██▍       | 2440/10000 [00:09<00:31, 242.59it/s]Running 10000 simulations.:  25%|██▍       | 2465/10000 [00:10<00:31, 243.03it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:10<00:30, 243.00it/s]Running 10000 simulations.:  25%|██▌       | 2515/10000 [00:10<00:30, 242.81it/s]Running 10000 simulations.:  25%|██▌       | 2540/10000 [00:10<00:30, 243.66it/s]Running 10000 simulations.:  26%|██▌       | 2565/10000 [00:10<00:30, 243.86it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:10<00:30, 245.10it/s]Running 10000 simulations.:  26%|██▌       | 2615/10000 [00:10<00:30, 243.92it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:10<00:30, 242.85it/s]Running 10000 simulations.:  27%|██▋       | 2665/10000 [00:10<00:30, 241.85it/s]Running 10000 simulations.:  27%|██▋       | 2690/10000 [00:10<00:30, 242.07it/s]Running 10000 simulations.:  27%|██▋       | 2715/10000 [00:11<00:30, 241.85it/s]Running 10000 simulations.:  27%|██▋       | 2740/10000 [00:11<00:29, 244.17it/s]Running 10000 simulations.:  28%|██▊       | 2765/10000 [00:11<00:29, 241.78it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:11<00:29, 241.53it/s]Running 10000 simulations.:  28%|██▊       | 2815/10000 [00:11<00:29, 242.25it/s]Running 10000 simulations.:  28%|██▊       | 2840/10000 [00:11<00:29, 241.96it/s]Running 10000 simulations.:  29%|██▊       | 2865/10000 [00:11<00:29, 242.61it/s]Running 10000 simulations.:  29%|██▉       | 2890/10000 [00:11<00:29, 242.32it/s]Running 10000 simulations.:  29%|██▉       | 2915/10000 [00:11<00:29, 242.32it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:12<00:29, 242.54it/s]Running 10000 simulations.:  30%|██▉       | 2965/10000 [00:12<00:28, 243.13it/s]Running 10000 simulations.:  30%|██▉       | 2990/10000 [00:12<00:28, 243.56it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:12<00:28, 244.33it/s]Running 10000 simulations.:  30%|███       | 3040/10000 [00:12<00:28, 243.06it/s]Running 10000 simulations.:  31%|███       | 3065/10000 [00:12<00:28, 242.83it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:12<00:28, 242.45it/s]Running 10000 simulations.:  31%|███       | 3115/10000 [00:12<00:28, 242.20it/s]Running 10000 simulations.:  31%|███▏      | 3140/10000 [00:12<00:28, 242.46it/s]Running 10000 simulations.:  32%|███▏      | 3165/10000 [00:12<00:28, 243.05it/s]Running 10000 simulations.:  32%|███▏      | 3190/10000 [00:13<00:28, 242.13it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:13<00:28, 239.78it/s]Running 10000 simulations.:  32%|███▏      | 3239/10000 [00:13<00:28, 238.44it/s]Running 10000 simulations.:  33%|███▎      | 3264/10000 [00:13<00:28, 240.37it/s]Running 10000 simulations.:  33%|███▎      | 3289/10000 [00:13<00:27, 242.57it/s]Running 10000 simulations.:  33%|███▎      | 3314/10000 [00:13<00:27, 243.89it/s]Running 10000 simulations.:  33%|███▎      | 3339/10000 [00:13<00:27, 242.35it/s]Running 10000 simulations.:  34%|███▎      | 3364/10000 [00:13<00:27, 241.44it/s]Running 10000 simulations.:  34%|███▍      | 3389/10000 [00:13<00:27, 240.67it/s]Running 10000 simulations.:  34%|███▍      | 3414/10000 [00:13<00:27, 242.14it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:14<00:27, 242.00it/s]Running 10000 simulations.:  35%|███▍      | 3464/10000 [00:14<00:27, 241.65it/s]Running 10000 simulations.:  35%|███▍      | 3489/10000 [00:14<00:26, 242.58it/s]Running 10000 simulations.:  35%|███▌      | 3514/10000 [00:14<00:26, 244.32it/s]Running 10000 simulations.:  35%|███▌      | 3539/10000 [00:14<00:26, 243.89it/s]Running 10000 simulations.:  36%|███▌      | 3564/10000 [00:14<00:26, 242.62it/s]Running 10000 simulations.:  36%|███▌      | 3589/10000 [00:14<00:26, 241.58it/s]Running 10000 simulations.:  36%|███▌      | 3614/10000 [00:14<00:26, 242.86it/s]Running 10000 simulations.:  36%|███▋      | 3639/10000 [00:14<00:26, 243.47it/s]Running 10000 simulations.:  37%|███▋      | 3664/10000 [00:14<00:25, 245.28it/s]Running 10000 simulations.:  37%|███▋      | 3689/10000 [00:15<00:25, 244.17it/s]Running 10000 simulations.:  37%|███▋      | 3714/10000 [00:15<00:25, 243.78it/s]Running 10000 simulations.:  37%|███▋      | 3739/10000 [00:15<00:25, 243.17it/s]Running 10000 simulations.:  38%|███▊      | 3764/10000 [00:15<00:25, 243.11it/s]Running 10000 simulations.:  38%|███▊      | 3789/10000 [00:15<00:25, 243.88it/s]Running 10000 simulations.:  38%|███▊      | 3814/10000 [00:15<00:25, 243.60it/s]Running 10000 simulations.:  38%|███▊      | 3839/10000 [00:15<00:25, 240.99it/s]Running 10000 simulations.:  39%|███▊      | 3864/10000 [00:15<00:25, 240.64it/s]Running 10000 simulations.:  39%|███▉      | 3889/10000 [00:15<00:25, 240.92it/s]Running 10000 simulations.:  39%|███▉      | 3914/10000 [00:16<00:25, 240.55it/s]Running 10000 simulations.:  39%|███▉      | 3939/10000 [00:16<00:25, 240.95it/s]Running 10000 simulations.:  40%|███▉      | 3964/10000 [00:16<00:25, 240.18it/s]Running 10000 simulations.:  40%|███▉      | 3989/10000 [00:16<00:25, 239.95it/s]Running 10000 simulations.:  40%|████      | 4013/10000 [00:16<00:25, 238.99it/s]Running 10000 simulations.:  40%|████      | 4037/10000 [00:16<00:24, 238.80it/s]Running 10000 simulations.:  41%|████      | 4062/10000 [00:16<00:24, 239.46it/s]Running 10000 simulations.:  41%|████      | 4087/10000 [00:16<00:24, 240.13it/s]Running 10000 simulations.:  41%|████      | 4112/10000 [00:16<00:24, 239.89it/s]Running 10000 simulations.:  41%|████▏     | 4136/10000 [00:16<00:24, 239.35it/s]Running 10000 simulations.:  42%|████▏     | 4160/10000 [00:17<00:24, 238.61it/s]Running 10000 simulations.:  42%|████▏     | 4184/10000 [00:17<00:24, 239.01it/s]Running 10000 simulations.:  42%|████▏     | 4209/10000 [00:17<00:24, 240.92it/s]Running 10000 simulations.:  42%|████▏     | 4234/10000 [00:17<00:23, 242.25it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:17<00:23, 242.50it/s]Running 10000 simulations.:  43%|████▎     | 4284/10000 [00:17<00:23, 241.36it/s]Running 10000 simulations.:  43%|████▎     | 4309/10000 [00:17<00:23, 241.61it/s]Running 10000 simulations.:  43%|████▎     | 4334/10000 [00:17<00:23, 242.57it/s]Running 10000 simulations.:  44%|████▎     | 4359/10000 [00:17<00:23, 243.75it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:17<00:23, 243.75it/s]Running 10000 simulations.:  44%|████▍     | 4409/10000 [00:18<00:22, 243.99it/s]Running 10000 simulations.:  44%|████▍     | 4434/10000 [00:18<00:22, 243.57it/s]Running 10000 simulations.:  45%|████▍     | 4459/10000 [00:18<00:22, 244.10it/s]Running 10000 simulations.:  45%|████▍     | 4484/10000 [00:18<00:22, 244.48it/s]Running 10000 simulations.:  45%|████▌     | 4509/10000 [00:18<00:22, 245.83it/s]Running 10000 simulations.:  45%|████▌     | 4534/10000 [00:18<00:22, 245.12it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:18<00:22, 244.57it/s]Running 10000 simulations.:  46%|████▌     | 4584/10000 [00:18<00:22, 242.60it/s]Running 10000 simulations.:  46%|████▌     | 4609/10000 [00:18<00:22, 241.80it/s]Running 10000 simulations.:  46%|████▋     | 4634/10000 [00:19<00:22, 240.18it/s]Running 10000 simulations.:  47%|████▋     | 4659/10000 [00:19<00:22, 242.00it/s]Running 10000 simulations.:  47%|████▋     | 4684/10000 [00:19<00:21, 242.51it/s]Running 10000 simulations.:  47%|████▋     | 4709/10000 [00:19<00:21, 243.92it/s]Running 10000 simulations.:  47%|████▋     | 4734/10000 [00:19<00:21, 244.04it/s]Running 10000 simulations.:  48%|████▊     | 4759/10000 [00:19<00:21, 244.18it/s]Running 10000 simulations.:  48%|████▊     | 4784/10000 [00:19<00:21, 243.27it/s]Running 10000 simulations.:  48%|████▊     | 4809/10000 [00:19<00:21, 243.74it/s]Running 10000 simulations.:  48%|████▊     | 4834/10000 [00:19<00:21, 243.74it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:19<00:21, 242.66it/s]Running 10000 simulations.:  49%|████▉     | 4884/10000 [00:20<00:21, 238.72it/s]Running 10000 simulations.:  49%|████▉     | 4909/10000 [00:20<00:21, 239.34it/s]Running 10000 simulations.:  49%|████▉     | 4934/10000 [00:20<00:21, 241.22it/s]Running 10000 simulations.:  50%|████▉     | 4959/10000 [00:20<00:20, 242.86it/s]Running 10000 simulations.:  50%|████▉     | 4984/10000 [00:20<00:20, 244.23it/s]Running 10000 simulations.:  50%|█████     | 5009/10000 [00:20<00:20, 245.10it/s]Running 10000 simulations.:  50%|█████     | 5034/10000 [00:20<00:20, 245.14it/s]Running 10000 simulations.:  51%|█████     | 5059/10000 [00:20<00:20, 243.71it/s]Running 10000 simulations.:  51%|█████     | 5084/10000 [00:20<00:20, 243.76it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:20<00:20, 243.99it/s]Running 10000 simulations.:  51%|█████▏    | 5134/10000 [00:21<00:19, 244.83it/s]Running 10000 simulations.:  52%|█████▏    | 5159/10000 [00:21<00:19, 243.52it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:21<00:19, 242.85it/s]Running 10000 simulations.:  52%|█████▏    | 5209/10000 [00:21<00:19, 243.38it/s]Running 10000 simulations.:  52%|█████▏    | 5234/10000 [00:21<00:19, 244.10it/s]Running 10000 simulations.:  53%|█████▎    | 5259/10000 [00:21<00:19, 244.57it/s]Running 10000 simulations.:  53%|█████▎    | 5284/10000 [00:21<00:19, 244.63it/s]Running 10000 simulations.:  53%|█████▎    | 5309/10000 [00:21<00:19, 241.33it/s]Running 10000 simulations.:  53%|█████▎    | 5334/10000 [00:21<00:19, 241.06it/s]Running 10000 simulations.:  54%|█████▎    | 5359/10000 [00:21<00:19, 242.15it/s]Running 10000 simulations.:  54%|█████▍    | 5384/10000 [00:22<00:19, 242.89it/s]Running 10000 simulations.:  54%|█████▍    | 5409/10000 [00:22<00:18, 244.11it/s]Running 10000 simulations.:  54%|█████▍    | 5434/10000 [00:22<00:18, 242.60it/s]Running 10000 simulations.:  55%|█████▍    | 5459/10000 [00:22<00:18, 241.86it/s]Running 10000 simulations.:  55%|█████▍    | 5484/10000 [00:22<00:18, 242.74it/s]Running 10000 simulations.:  55%|█████▌    | 5509/10000 [00:22<00:18, 244.51it/s]Running 10000 simulations.:  55%|█████▌    | 5534/10000 [00:22<00:18, 245.77it/s]Running 10000 simulations.:  56%|█████▌    | 5559/10000 [00:22<00:18, 246.17it/s]Running 10000 simulations.:  56%|█████▌    | 5584/10000 [00:22<00:18, 244.39it/s]Running 10000 simulations.:  56%|█████▌    | 5609/10000 [00:23<00:17, 244.41it/s]Running 10000 simulations.:  56%|█████▋    | 5634/10000 [00:23<00:17, 243.89it/s]Running 10000 simulations.:  57%|█████▋    | 5659/10000 [00:23<00:17, 244.57it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:23<00:17, 243.38it/s]Running 10000 simulations.:  57%|█████▋    | 5709/10000 [00:23<00:17, 242.24it/s]Running 10000 simulations.:  57%|█████▋    | 5734/10000 [00:23<00:17, 242.84it/s]Running 10000 simulations.:  58%|█████▊    | 5759/10000 [00:23<00:17, 243.87it/s]Running 10000 simulations.:  58%|█████▊    | 5784/10000 [00:23<00:17, 243.02it/s]Running 10000 simulations.:  58%|█████▊    | 5809/10000 [00:23<00:17, 243.02it/s]Running 10000 simulations.:  58%|█████▊    | 5834/10000 [00:23<00:17, 243.01it/s]Running 10000 simulations.:  59%|█████▊    | 5859/10000 [00:24<00:16, 244.33it/s]Running 10000 simulations.:  59%|█████▉    | 5884/10000 [00:24<00:16, 245.04it/s]Running 10000 simulations.:  59%|█████▉    | 5909/10000 [00:24<00:16, 245.55it/s]Running 10000 simulations.:  59%|█████▉    | 5934/10000 [00:24<00:16, 244.13it/s]Running 10000 simulations.:  60%|█████▉    | 5959/10000 [00:24<00:16, 244.22it/s]Running 10000 simulations.:  60%|█████▉    | 5984/10000 [00:24<00:16, 243.65it/s]Running 10000 simulations.:  60%|██████    | 6009/10000 [00:24<00:16, 244.32it/s]Running 10000 simulations.:  60%|██████    | 6034/10000 [00:24<00:16, 244.88it/s]Running 10000 simulations.:  61%|██████    | 6059/10000 [00:24<00:16, 244.77it/s]Running 10000 simulations.:  61%|██████    | 6084/10000 [00:24<00:16, 244.11it/s]Running 10000 simulations.:  61%|██████    | 6109/10000 [00:25<00:16, 242.27it/s]Running 10000 simulations.:  61%|██████▏   | 6134/10000 [00:25<00:15, 241.90it/s]Running 10000 simulations.:  62%|██████▏   | 6159/10000 [00:25<00:15, 243.03it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:25<00:15, 244.02it/s]Running 10000 simulations.:  62%|██████▏   | 6209/10000 [00:25<00:15, 243.29it/s]Running 10000 simulations.:  62%|██████▏   | 6234/10000 [00:25<00:15, 243.30it/s]Running 10000 simulations.:  63%|██████▎   | 6259/10000 [00:25<00:15, 243.52it/s]Running 10000 simulations.:  63%|██████▎   | 6284/10000 [00:25<00:15, 243.26it/s]Running 10000 simulations.:  63%|██████▎   | 6309/10000 [00:25<00:15, 243.80it/s]Running 10000 simulations.:  63%|██████▎   | 6334/10000 [00:25<00:14, 245.47it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:26<00:15, 241.78it/s]Running 10000 simulations.:  64%|██████▍   | 6384/10000 [00:26<00:15, 239.77it/s]Running 10000 simulations.:  64%|██████▍   | 6409/10000 [00:26<00:14, 240.14it/s]Running 10000 simulations.:  64%|██████▍   | 6434/10000 [00:26<00:14, 241.19it/s]Running 10000 simulations.:  65%|██████▍   | 6459/10000 [00:26<00:14, 242.18it/s]Running 10000 simulations.:  65%|██████▍   | 6484/10000 [00:26<00:14, 243.73it/s]Running 10000 simulations.:  65%|██████▌   | 6509/10000 [00:26<00:14, 242.11it/s]Running 10000 simulations.:  65%|██████▌   | 6534/10000 [00:26<00:14, 242.54it/s]Running 10000 simulations.:  66%|██████▌   | 6559/10000 [00:26<00:14, 242.53it/s]Running 10000 simulations.:  66%|██████▌   | 6584/10000 [00:27<00:14, 242.95it/s]Running 10000 simulations.:  66%|██████▌   | 6609/10000 [00:27<00:13, 242.94it/s]Running 10000 simulations.:  66%|██████▋   | 6634/10000 [00:27<00:13, 243.76it/s]Running 10000 simulations.:  67%|██████▋   | 6659/10000 [00:27<00:13, 243.49it/s]Running 10000 simulations.:  67%|██████▋   | 6684/10000 [00:27<00:13, 244.59it/s]Running 10000 simulations.:  67%|██████▋   | 6709/10000 [00:27<00:13, 243.38it/s]Running 10000 simulations.:  67%|██████▋   | 6734/10000 [00:27<00:13, 243.55it/s]Running 10000 simulations.:  68%|██████▊   | 6759/10000 [00:27<00:13, 244.42it/s]Running 10000 simulations.:  68%|██████▊   | 6784/10000 [00:27<00:13, 245.82it/s]Running 10000 simulations.:  68%|██████▊   | 6809/10000 [00:27<00:13, 243.38it/s]Running 10000 simulations.:  68%|██████▊   | 6834/10000 [00:28<00:13, 242.37it/s]Running 10000 simulations.:  69%|██████▊   | 6859/10000 [00:28<00:12, 242.09it/s]Running 10000 simulations.:  69%|██████▉   | 6884/10000 [00:28<00:12, 241.22it/s]Running 10000 simulations.:  69%|██████▉   | 6909/10000 [00:28<00:12, 239.08it/s]Running 10000 simulations.:  69%|██████▉   | 6934/10000 [00:28<00:12, 240.89it/s]Running 10000 simulations.:  70%|██████▉   | 6959/10000 [00:28<00:12, 243.01it/s]Running 10000 simulations.:  70%|██████▉   | 6984/10000 [00:28<00:12, 244.80it/s]Running 10000 simulations.:  70%|███████   | 7009/10000 [00:28<00:12, 244.33it/s]Running 10000 simulations.:  70%|███████   | 7034/10000 [00:28<00:12, 243.28it/s]Running 10000 simulations.:  71%|███████   | 7059/10000 [00:28<00:12, 242.90it/s]Running 10000 simulations.:  71%|███████   | 7084/10000 [00:29<00:11, 243.08it/s]Running 10000 simulations.:  71%|███████   | 7109/10000 [00:29<00:11, 243.70it/s]Running 10000 simulations.:  71%|███████▏  | 7134/10000 [00:29<00:11, 245.04it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:29<00:11, 243.43it/s]Running 10000 simulations.:  72%|███████▏  | 7184/10000 [00:29<00:11, 243.26it/s]Running 10000 simulations.:  72%|███████▏  | 7209/10000 [00:29<00:11, 242.58it/s]Running 10000 simulations.:  72%|███████▏  | 7234/10000 [00:29<00:11, 243.77it/s]Running 10000 simulations.:  73%|███████▎  | 7259/10000 [00:29<00:11, 244.32it/s]Running 10000 simulations.:  73%|███████▎  | 7284/10000 [00:29<00:11, 244.80it/s]Running 10000 simulations.:  73%|███████▎  | 7309/10000 [00:29<00:11, 242.98it/s]Running 10000 simulations.:  73%|███████▎  | 7334/10000 [00:30<00:11, 241.54it/s]Running 10000 simulations.:  74%|███████▎  | 7359/10000 [00:30<00:10, 241.11it/s]Running 10000 simulations.:  74%|███████▍  | 7384/10000 [00:30<00:10, 241.86it/s]Running 10000 simulations.:  74%|███████▍  | 7409/10000 [00:30<00:10, 243.65it/s]Running 10000 simulations.:  74%|███████▍  | 7435/10000 [00:30<00:10, 245.38it/s]Running 10000 simulations.:  75%|███████▍  | 7460/10000 [00:30<00:10, 243.39it/s]Running 10000 simulations.:  75%|███████▍  | 7485/10000 [00:30<00:10, 242.60it/s]Running 10000 simulations.:  75%|███████▌  | 7510/10000 [00:30<00:10, 241.92it/s]Running 10000 simulations.:  75%|███████▌  | 7535/10000 [00:30<00:10, 243.23it/s]Running 10000 simulations.:  76%|███████▌  | 7560/10000 [00:31<00:09, 244.30it/s]Running 10000 simulations.:  76%|███████▌  | 7585/10000 [00:31<00:09, 244.39it/s]Running 10000 simulations.:  76%|███████▌  | 7610/10000 [00:31<00:09, 243.08it/s]Running 10000 simulations.:  76%|███████▋  | 7635/10000 [00:31<00:09, 242.89it/s]Running 10000 simulations.:  77%|███████▋  | 7660/10000 [00:31<00:09, 239.41it/s]Running 10000 simulations.:  77%|███████▋  | 7685/10000 [00:31<00:09, 240.90it/s]Running 10000 simulations.:  77%|███████▋  | 7710/10000 [00:31<00:09, 242.31it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:31<00:09, 244.64it/s]Running 10000 simulations.:  78%|███████▊  | 7761/10000 [00:31<00:09, 241.67it/s]Running 10000 simulations.:  78%|███████▊  | 7786/10000 [00:31<00:09, 241.95it/s]Running 10000 simulations.:  78%|███████▊  | 7811/10000 [00:32<00:09, 241.54it/s]Running 10000 simulations.:  78%|███████▊  | 7836/10000 [00:32<00:08, 243.85it/s]Running 10000 simulations.:  79%|███████▊  | 7861/10000 [00:32<00:08, 244.77it/s]Running 10000 simulations.:  79%|███████▉  | 7886/10000 [00:32<00:08, 244.45it/s]Running 10000 simulations.:  79%|███████▉  | 7911/10000 [00:32<00:08, 242.40it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:32<00:08, 241.74it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:32<00:08, 241.85it/s]Running 10000 simulations.:  80%|███████▉  | 7986/10000 [00:32<00:08, 242.51it/s]Running 10000 simulations.:  80%|████████  | 8011/10000 [00:32<00:08, 243.70it/s]Running 10000 simulations.:  80%|████████  | 8036/10000 [00:32<00:08, 243.29it/s]Running 10000 simulations.:  81%|████████  | 8061/10000 [00:33<00:08, 242.01it/s]Running 10000 simulations.:  81%|████████  | 8086/10000 [00:33<00:07, 242.33it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:33<00:07, 243.39it/s]Running 10000 simulations.:  81%|████████▏ | 8136/10000 [00:33<00:07, 242.37it/s]Running 10000 simulations.:  82%|████████▏ | 8161/10000 [00:33<00:07, 241.86it/s]Running 10000 simulations.:  82%|████████▏ | 8186/10000 [00:33<00:07, 241.96it/s]Running 10000 simulations.:  82%|████████▏ | 8211/10000 [00:33<00:07, 241.93it/s]Running 10000 simulations.:  82%|████████▏ | 8236/10000 [00:33<00:07, 240.28it/s]Running 10000 simulations.:  83%|████████▎ | 8261/10000 [00:33<00:07, 241.24it/s]Running 10000 simulations.:  83%|████████▎ | 8286/10000 [00:34<00:07, 242.41it/s]Running 10000 simulations.:  83%|████████▎ | 8311/10000 [00:34<00:06, 244.00it/s]Running 10000 simulations.:  83%|████████▎ | 8336/10000 [00:34<00:06, 243.53it/s]Running 10000 simulations.:  84%|████████▎ | 8361/10000 [00:34<00:06, 243.22it/s]Running 10000 simulations.:  84%|████████▍ | 8386/10000 [00:34<00:06, 243.32it/s]Running 10000 simulations.:  84%|████████▍ | 8411/10000 [00:34<00:06, 244.17it/s]Running 10000 simulations.:  84%|████████▍ | 8436/10000 [00:34<00:06, 244.16it/s]Running 10000 simulations.:  85%|████████▍ | 8461/10000 [00:34<00:06, 245.19it/s]Running 10000 simulations.:  85%|████████▍ | 8486/10000 [00:34<00:06, 243.41it/s]Running 10000 simulations.:  85%|████████▌ | 8511/10000 [00:34<00:06, 243.06it/s]Running 10000 simulations.:  85%|████████▌ | 8536/10000 [00:35<00:06, 242.14it/s]Running 10000 simulations.:  86%|████████▌ | 8561/10000 [00:35<00:05, 243.19it/s]Running 10000 simulations.:  86%|████████▌ | 8586/10000 [00:35<00:05, 243.38it/s]Running 10000 simulations.:  86%|████████▌ | 8612/10000 [00:35<00:05, 245.38it/s]Running 10000 simulations.:  86%|████████▋ | 8637/10000 [00:35<00:05, 244.68it/s]Running 10000 simulations.:  87%|████████▋ | 8662/10000 [00:35<00:05, 244.57it/s]Running 10000 simulations.:  87%|████████▋ | 8687/10000 [00:35<00:05, 244.32it/s]Running 10000 simulations.:  87%|████████▋ | 8712/10000 [00:35<00:05, 244.22it/s]Running 10000 simulations.:  87%|████████▋ | 8737/10000 [00:35<00:05, 245.37it/s]Running 10000 simulations.:  88%|████████▊ | 8762/10000 [00:35<00:05, 245.31it/s]Running 10000 simulations.:  88%|████████▊ | 8787/10000 [00:36<00:04, 243.78it/s]Running 10000 simulations.:  88%|████████▊ | 8812/10000 [00:36<00:04, 243.53it/s]Running 10000 simulations.:  88%|████████▊ | 8837/10000 [00:36<00:04, 243.46it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [00:36<00:04, 243.90it/s]Running 10000 simulations.:  89%|████████▉ | 8887/10000 [00:36<00:04, 243.53it/s]Running 10000 simulations.:  89%|████████▉ | 8912/10000 [00:36<00:04, 242.65it/s]Running 10000 simulations.:  89%|████████▉ | 8937/10000 [00:36<00:04, 242.66it/s]Running 10000 simulations.:  90%|████████▉ | 8962/10000 [00:36<00:04, 242.99it/s]Running 10000 simulations.:  90%|████████▉ | 8987/10000 [00:36<00:04, 232.99it/s]Running 10000 simulations.:  90%|█████████ | 9012/10000 [00:37<00:04, 236.76it/s]Running 10000 simulations.:  90%|█████████ | 9037/10000 [00:37<00:04, 239.98it/s]Running 10000 simulations.:  91%|█████████ | 9062/10000 [00:37<00:03, 239.28it/s]Running 10000 simulations.:  91%|█████████ | 9087/10000 [00:37<00:03, 240.59it/s]Running 10000 simulations.:  91%|█████████ | 9112/10000 [00:37<00:03, 240.13it/s]Running 10000 simulations.:  91%|█████████▏| 9137/10000 [00:37<00:03, 240.77it/s]Running 10000 simulations.:  92%|█████████▏| 9162/10000 [00:37<00:03, 240.93it/s]Running 10000 simulations.:  92%|█████████▏| 9187/10000 [00:37<00:03, 241.59it/s]Running 10000 simulations.:  92%|█████████▏| 9212/10000 [00:37<00:03, 241.10it/s]Running 10000 simulations.:  92%|█████████▏| 9237/10000 [00:37<00:03, 241.27it/s]Running 10000 simulations.:  93%|█████████▎| 9262/10000 [00:38<00:03, 241.48it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [00:38<00:02, 239.91it/s]Running 10000 simulations.:  93%|█████████▎| 9311/10000 [00:38<00:02, 236.62it/s]Running 10000 simulations.:  93%|█████████▎| 9336/10000 [00:38<00:02, 237.74it/s]Running 10000 simulations.:  94%|█████████▎| 9361/10000 [00:38<00:02, 240.20it/s]Running 10000 simulations.:  94%|█████████▍| 9387/10000 [00:38<00:02, 243.22it/s]Running 10000 simulations.:  94%|█████████▍| 9412/10000 [00:38<00:02, 243.37it/s]Running 10000 simulations.:  94%|█████████▍| 9437/10000 [00:38<00:02, 244.18it/s]Running 10000 simulations.:  95%|█████████▍| 9462/10000 [00:38<00:02, 243.29it/s]Running 10000 simulations.:  95%|█████████▍| 9487/10000 [00:38<00:02, 243.66it/s]Running 10000 simulations.:  95%|█████████▌| 9512/10000 [00:39<00:01, 244.56it/s]Running 10000 simulations.:  95%|█████████▌| 9538/10000 [00:39<00:01, 247.02it/s]Running 10000 simulations.:  96%|█████████▌| 9563/10000 [00:39<00:01, 246.60it/s]Running 10000 simulations.:  96%|█████████▌| 9588/10000 [00:39<00:01, 246.33it/s]Running 10000 simulations.:  96%|█████████▌| 9613/10000 [00:39<00:01, 246.41it/s]Running 10000 simulations.:  96%|█████████▋| 9638/10000 [00:39<00:01, 243.97it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [00:39<00:01, 245.94it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [00:39<00:01, 247.48it/s]Running 10000 simulations.:  97%|█████████▋| 9715/10000 [00:39<00:01, 245.23it/s]Running 10000 simulations.:  97%|█████████▋| 9740/10000 [00:40<00:01, 243.84it/s]Running 10000 simulations.:  98%|█████████▊| 9765/10000 [00:40<00:00, 243.73it/s]Running 10000 simulations.:  98%|█████████▊| 9790/10000 [00:40<00:00, 240.93it/s]Running 10000 simulations.:  98%|█████████▊| 9815/10000 [00:40<00:00, 241.53it/s]Running 10000 simulations.:  98%|█████████▊| 9840/10000 [00:40<00:00, 243.84it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [00:40<00:00, 244.34it/s]Running 10000 simulations.:  99%|█████████▉| 9890/10000 [00:40<00:00, 244.79it/s]Running 10000 simulations.:  99%|█████████▉| 9915/10000 [00:40<00:00, 245.17it/s]Running 10000 simulations.:  99%|█████████▉| 9940/10000 [00:40<00:00, 245.09it/s]Running 10000 simulations.: 100%|█████████▉| 9965/10000 [00:40<00:00, 246.20it/s]Running 10000 simulations.: 100%|█████████▉| 9991/10000 [00:41<00:00, 247.44it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 243.48it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 24/10000 [00:00<00:41, 237.54it/s]Running 10000 simulations.:   0%|          | 49/10000 [00:00<00:41, 239.03it/s]Running 10000 simulations.:   1%|          | 74/10000 [00:00<00:41, 241.56it/s]Running 10000 simulations.:   1%|          | 100/10000 [00:00<00:40, 246.35it/s]Running 10000 simulations.:   1%|▏         | 126/10000 [00:00<00:39, 250.16it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:38, 253.28it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:00<00:38, 255.97it/s]Running 10000 simulations.:   2%|▏         | 205/10000 [00:00<00:38, 254.10it/s]Running 10000 simulations.:   2%|▏         | 230/10000 [00:00<00:39, 249.34it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<00:39, 245.54it/s]Running 10000 simulations.:   3%|▎         | 280/10000 [00:01<00:39, 245.93it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:38, 248.93it/s]Running 10000 simulations.:   3%|▎         | 332/10000 [00:01<00:38, 250.99it/s]Running 10000 simulations.:   4%|▎         | 358/10000 [00:01<00:38, 252.56it/s]Running 10000 simulations.:   4%|▍         | 384/10000 [00:01<00:37, 254.60it/s]Running 10000 simulations.:   4%|▍         | 410/10000 [00:01<00:38, 250.40it/s]Running 10000 simulations.:   4%|▍         | 435/10000 [00:01<00:38, 245.40it/s]Running 10000 simulations.:   5%|▍         | 460/10000 [00:01<00:39, 243.32it/s]Running 10000 simulations.:   5%|▍         | 486/10000 [00:01<00:38, 246.28it/s]Running 10000 simulations.:   5%|▌         | 512/10000 [00:02<00:37, 250.00it/s]Running 10000 simulations.:   5%|▌         | 538/10000 [00:02<00:37, 252.56it/s]Running 10000 simulations.:   6%|▌         | 564/10000 [00:02<00:37, 251.06it/s]Running 10000 simulations.:   6%|▌         | 590/10000 [00:02<00:37, 251.85it/s]Running 10000 simulations.:   6%|▌         | 616/10000 [00:02<00:36, 253.92it/s]Running 10000 simulations.:   6%|▋         | 642/10000 [00:02<00:36, 254.74it/s]Running 10000 simulations.:   7%|▋         | 668/10000 [00:02<00:37, 248.51it/s]Running 10000 simulations.:   7%|▋         | 693/10000 [00:02<00:38, 243.45it/s]Running 10000 simulations.:   7%|▋         | 718/10000 [00:02<00:38, 242.37it/s]Running 10000 simulations.:   7%|▋         | 743/10000 [00:02<00:38, 242.69it/s]Running 10000 simulations.:   8%|▊         | 769/10000 [00:03<00:37, 245.67it/s]Running 10000 simulations.:   8%|▊         | 795/10000 [00:03<00:37, 248.53it/s]Running 10000 simulations.:   8%|▊         | 821/10000 [00:03<00:36, 251.81it/s]Running 10000 simulations.:   8%|▊         | 847/10000 [00:03<00:36, 250.87it/s]Running 10000 simulations.:   9%|▊         | 873/10000 [00:03<00:37, 245.27it/s]Running 10000 simulations.:   9%|▉         | 898/10000 [00:03<00:37, 242.16it/s]Running 10000 simulations.:   9%|▉         | 923/10000 [00:03<00:37, 243.31it/s]Running 10000 simulations.:   9%|▉         | 949/10000 [00:03<00:36, 246.92it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:03<00:36, 249.50it/s]Running 10000 simulations.:  10%|█         | 1001/10000 [00:04<00:35, 250.63it/s]Running 10000 simulations.:  10%|█         | 1027/10000 [00:04<00:35, 252.52it/s]Running 10000 simulations.:  11%|█         | 1053/10000 [00:04<00:36, 247.88it/s]Running 10000 simulations.:  11%|█         | 1078/10000 [00:04<00:36, 242.73it/s]Running 10000 simulations.:  11%|█         | 1103/10000 [00:04<00:37, 238.07it/s]Running 10000 simulations.:  11%|█▏        | 1129/10000 [00:04<00:36, 241.95it/s]Running 10000 simulations.:  12%|█▏        | 1155/10000 [00:04<00:35, 245.77it/s]Running 10000 simulations.:  12%|█▏        | 1181/10000 [00:04<00:35, 249.14it/s]Running 10000 simulations.:  12%|█▏        | 1207/10000 [00:04<00:34, 252.12it/s]Running 10000 simulations.:  12%|█▏        | 1233/10000 [00:04<00:34, 250.84it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:05<00:35, 245.84it/s]Running 10000 simulations.:  13%|█▎        | 1284/10000 [00:05<00:35, 242.57it/s]Running 10000 simulations.:  13%|█▎        | 1309/10000 [00:05<00:35, 242.86it/s]Running 10000 simulations.:  13%|█▎        | 1335/10000 [00:05<00:35, 245.20it/s]Running 10000 simulations.:  14%|█▎        | 1361/10000 [00:05<00:34, 247.89it/s]Running 10000 simulations.:  14%|█▍        | 1387/10000 [00:05<00:34, 250.60it/s]Running 10000 simulations.:  14%|█▍        | 1413/10000 [00:05<00:33, 253.33it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:05<00:34, 249.23it/s]Running 10000 simulations.:  15%|█▍        | 1464/10000 [00:05<00:34, 244.95it/s]Running 10000 simulations.:  15%|█▍        | 1489/10000 [00:06<00:35, 241.41it/s]Running 10000 simulations.:  15%|█▌        | 1514/10000 [00:06<00:34, 243.68it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:06<00:34, 245.34it/s]Running 10000 simulations.:  16%|█▌        | 1565/10000 [00:06<00:34, 247.58it/s]Running 10000 simulations.:  16%|█▌        | 1591/10000 [00:06<00:33, 248.98it/s]Running 10000 simulations.:  16%|█▌        | 1617/10000 [00:06<00:33, 249.55it/s]Running 10000 simulations.:  16%|█▋        | 1642/10000 [00:06<00:34, 244.97it/s]Running 10000 simulations.:  17%|█▋        | 1667/10000 [00:06<00:34, 240.12it/s]Running 10000 simulations.:  17%|█▋        | 1692/10000 [00:06<00:34, 239.01it/s]Running 10000 simulations.:  17%|█▋        | 1717/10000 [00:06<00:34, 242.03it/s]Running 10000 simulations.:  17%|█▋        | 1743/10000 [00:07<00:33, 244.96it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:07<00:33, 247.00it/s]Running 10000 simulations.:  18%|█▊        | 1795/10000 [00:07<00:32, 249.07it/s]Running 10000 simulations.:  18%|█▊        | 1820/10000 [00:07<00:33, 247.01it/s]Running 10000 simulations.:  18%|█▊        | 1845/10000 [00:07<00:33, 241.32it/s]Running 10000 simulations.:  19%|█▊        | 1870/10000 [00:07<00:34, 238.24it/s]Running 10000 simulations.:  19%|█▉        | 1895/10000 [00:07<00:33, 240.44it/s]Running 10000 simulations.:  19%|█▉        | 1921/10000 [00:07<00:33, 243.40it/s]Running 10000 simulations.:  19%|█▉        | 1947/10000 [00:07<00:32, 245.62it/s]Running 10000 simulations.:  20%|█▉        | 1973/10000 [00:07<00:32, 248.10it/s]Running 10000 simulations.:  20%|█▉        | 1999/10000 [00:08<00:32, 249.24it/s]Running 10000 simulations.:  20%|██        | 2024/10000 [00:08<00:32, 244.94it/s]Running 10000 simulations.:  20%|██        | 2049/10000 [00:08<00:32, 241.44it/s]Running 10000 simulations.:  21%|██        | 2074/10000 [00:08<00:34, 228.97it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:08<00:33, 236.09it/s]Running 10000 simulations.:  21%|██▏       | 2126/10000 [00:08<00:32, 241.46it/s]Running 10000 simulations.:  22%|██▏       | 2152/10000 [00:08<00:31, 245.41it/s]Running 10000 simulations.:  22%|██▏       | 2177/10000 [00:08<00:31, 245.82it/s]Running 10000 simulations.:  22%|██▏       | 2203/10000 [00:08<00:31, 247.25it/s]Running 10000 simulations.:  22%|██▏       | 2229/10000 [00:09<00:31, 248.66it/s]Running 10000 simulations.:  23%|██▎       | 2254/10000 [00:09<00:31, 247.84it/s]Running 10000 simulations.:  23%|██▎       | 2279/10000 [00:09<00:31, 241.61it/s]Running 10000 simulations.:  23%|██▎       | 2304/10000 [00:09<00:32, 239.30it/s]Running 10000 simulations.:  23%|██▎       | 2328/10000 [00:09<00:32, 239.39it/s]Running 10000 simulations.:  24%|██▎       | 2354/10000 [00:09<00:31, 242.69it/s]Running 10000 simulations.:  24%|██▍       | 2380/10000 [00:09<00:31, 245.78it/s]Running 10000 simulations.:  24%|██▍       | 2406/10000 [00:09<00:30, 248.61it/s]Running 10000 simulations.:  24%|██▍       | 2432/10000 [00:09<00:30, 251.06it/s]Running 10000 simulations.:  25%|██▍       | 2458/10000 [00:09<00:30, 247.57it/s]Running 10000 simulations.:  25%|██▍       | 2483/10000 [00:10<00:31, 241.91it/s]Running 10000 simulations.:  25%|██▌       | 2508/10000 [00:10<00:31, 238.92it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:10<00:30, 241.33it/s]Running 10000 simulations.:  26%|██▌       | 2559/10000 [00:10<00:30, 244.38it/s]Running 10000 simulations.:  26%|██▌       | 2585/10000 [00:10<00:30, 247.13it/s]Running 10000 simulations.:  26%|██▌       | 2611/10000 [00:10<00:29, 250.14it/s]Running 10000 simulations.:  26%|██▋       | 2637/10000 [00:10<00:29, 251.65it/s]Running 10000 simulations.:  27%|██▋       | 2663/10000 [00:10<00:29, 245.34it/s]Running 10000 simulations.:  27%|██▋       | 2688/10000 [00:10<00:30, 239.07it/s]Running 10000 simulations.:  27%|██▋       | 2712/10000 [00:11<00:30, 237.72it/s]Running 10000 simulations.:  27%|██▋       | 2738/10000 [00:11<00:30, 241.83it/s]Running 10000 simulations.:  28%|██▊       | 2764/10000 [00:11<00:29, 245.16it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:11<00:29, 247.38it/s]Running 10000 simulations.:  28%|██▊       | 2816/10000 [00:11<00:28, 249.53it/s]Running 10000 simulations.:  28%|██▊       | 2841/10000 [00:11<00:29, 246.76it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:11<00:29, 240.32it/s]Running 10000 simulations.:  29%|██▉       | 2891/10000 [00:11<00:30, 236.42it/s]Running 10000 simulations.:  29%|██▉       | 2915/10000 [00:11<00:30, 235.75it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:11<00:29, 238.05it/s]Running 10000 simulations.:  30%|██▉       | 2966/10000 [00:12<00:29, 242.35it/s]Running 10000 simulations.:  30%|██▉       | 2992/10000 [00:12<00:28, 246.34it/s]Running 10000 simulations.:  30%|███       | 3018/10000 [00:12<00:27, 249.67it/s]Running 10000 simulations.:  30%|███       | 3044/10000 [00:12<00:28, 244.27it/s]Running 10000 simulations.:  31%|███       | 3069/10000 [00:12<00:29, 238.59it/s]Running 10000 simulations.:  31%|███       | 3093/10000 [00:12<00:29, 234.92it/s]Running 10000 simulations.:  31%|███       | 3117/10000 [00:12<00:29, 236.25it/s]Running 10000 simulations.:  31%|███▏      | 3142/10000 [00:12<00:28, 240.06it/s]Running 10000 simulations.:  32%|███▏      | 3168/10000 [00:12<00:28, 243.53it/s]Running 10000 simulations.:  32%|███▏      | 3194/10000 [00:12<00:27, 246.98it/s]Running 10000 simulations.:  32%|███▏      | 3220/10000 [00:13<00:27, 247.92it/s]Running 10000 simulations.:  32%|███▏      | 3245/10000 [00:13<00:27, 242.81it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:13<00:28, 237.53it/s]Running 10000 simulations.:  33%|███▎      | 3294/10000 [00:13<00:28, 235.74it/s]Running 10000 simulations.:  33%|███▎      | 3320/10000 [00:13<00:27, 239.89it/s]Running 10000 simulations.:  33%|███▎      | 3345/10000 [00:13<00:27, 242.79it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:13<00:27, 245.21it/s]Running 10000 simulations.:  34%|███▍      | 3397/10000 [00:13<00:26, 246.89it/s]Running 10000 simulations.:  34%|███▍      | 3422/10000 [00:13<00:26, 247.07it/s]Running 10000 simulations.:  34%|███▍      | 3447/10000 [00:14<00:27, 241.28it/s]Running 10000 simulations.:  35%|███▍      | 3472/10000 [00:14<00:27, 240.63it/s]Running 10000 simulations.:  35%|███▍      | 3497/10000 [00:14<00:26, 242.70it/s]Running 10000 simulations.:  35%|███▌      | 3522/10000 [00:14<00:26, 244.61it/s]Running 10000 simulations.:  35%|███▌      | 3547/10000 [00:14<00:26, 246.07it/s]Running 10000 simulations.:  36%|███▌      | 3573/10000 [00:14<00:25, 248.16it/s]Running 10000 simulations.:  36%|███▌      | 3598/10000 [00:14<00:26, 243.43it/s]Running 10000 simulations.:  36%|███▌      | 3623/10000 [00:14<00:26, 238.98it/s]Running 10000 simulations.:  36%|███▋      | 3647/10000 [00:14<00:26, 236.57it/s]Running 10000 simulations.:  37%|███▋      | 3672/10000 [00:14<00:26, 239.00it/s]Running 10000 simulations.:  37%|███▋      | 3697/10000 [00:15<00:26, 241.70it/s]Running 10000 simulations.:  37%|███▋      | 3722/10000 [00:15<00:25, 241.77it/s]Running 10000 simulations.:  37%|███▋      | 3747/10000 [00:15<00:25, 243.23it/s]Running 10000 simulations.:  38%|███▊      | 3773/10000 [00:15<00:25, 245.88it/s]Running 10000 simulations.:  38%|███▊      | 3799/10000 [00:15<00:24, 248.51it/s]Running 10000 simulations.:  38%|███▊      | 3825/10000 [00:15<00:24, 249.39it/s]Running 10000 simulations.:  38%|███▊      | 3850/10000 [00:15<00:25, 244.40it/s]Running 10000 simulations.:  39%|███▉      | 3875/10000 [00:15<00:25, 240.93it/s]Running 10000 simulations.:  39%|███▉      | 3900/10000 [00:15<00:25, 243.56it/s]Running 10000 simulations.:  39%|███▉      | 3926/10000 [00:16<00:24, 245.64it/s]Running 10000 simulations.:  40%|███▉      | 3951/10000 [00:16<00:24, 246.17it/s]Running 10000 simulations.:  40%|███▉      | 3977/10000 [00:16<00:24, 248.76it/s]Running 10000 simulations.:  40%|████      | 4002/10000 [00:16<00:24, 246.32it/s]Running 10000 simulations.:  40%|████      | 4027/10000 [00:16<00:24, 241.24it/s]Running 10000 simulations.:  41%|████      | 4052/10000 [00:16<00:24, 241.49it/s]Running 10000 simulations.:  41%|████      | 4077/10000 [00:16<00:24, 241.92it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:16<00:24, 244.23it/s]Running 10000 simulations.:  41%|████▏     | 4127/10000 [00:16<00:23, 245.09it/s]Running 10000 simulations.:  42%|████▏     | 4152/10000 [00:16<00:23, 246.22it/s]Running 10000 simulations.:  42%|████▏     | 4177/10000 [00:17<00:24, 241.83it/s]Running 10000 simulations.:  42%|████▏     | 4202/10000 [00:17<00:24, 238.34it/s]Running 10000 simulations.:  42%|████▏     | 4226/10000 [00:17<00:24, 236.66it/s]Running 10000 simulations.:  43%|████▎     | 4251/10000 [00:17<00:23, 240.12it/s]Running 10000 simulations.:  43%|████▎     | 4276/10000 [00:17<00:23, 242.34it/s]Running 10000 simulations.:  43%|████▎     | 4301/10000 [00:17<00:23, 244.44it/s]Running 10000 simulations.:  43%|████▎     | 4327/10000 [00:17<00:23, 246.63it/s]Running 10000 simulations.:  44%|████▎     | 4352/10000 [00:17<00:22, 245.80it/s]Running 10000 simulations.:  44%|████▍     | 4377/10000 [00:17<00:23, 240.03it/s]Running 10000 simulations.:  44%|████▍     | 4402/10000 [00:17<00:23, 237.14it/s]Running 10000 simulations.:  44%|████▍     | 4426/10000 [00:18<00:23, 237.86it/s]Running 10000 simulations.:  45%|████▍     | 4451/10000 [00:18<00:23, 240.36it/s]Running 10000 simulations.:  45%|████▍     | 4477/10000 [00:18<00:22, 243.71it/s]Running 10000 simulations.:  45%|████▌     | 4503/10000 [00:18<00:22, 246.25it/s]Running 10000 simulations.:  45%|████▌     | 4529/10000 [00:18<00:22, 248.13it/s]Running 10000 simulations.:  46%|████▌     | 4554/10000 [00:18<00:22, 243.30it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:18<00:22, 240.57it/s]Running 10000 simulations.:  46%|████▌     | 4604/10000 [00:18<00:22, 243.13it/s]Running 10000 simulations.:  46%|████▋     | 4630/10000 [00:18<00:21, 245.75it/s]Running 10000 simulations.:  47%|████▋     | 4656/10000 [00:19<00:21, 247.24it/s]Running 10000 simulations.:  47%|████▋     | 4682/10000 [00:19<00:21, 249.62it/s]Running 10000 simulations.:  47%|████▋     | 4707/10000 [00:19<00:21, 247.80it/s]Running 10000 simulations.:  47%|████▋     | 4732/10000 [00:19<00:21, 241.12it/s]Running 10000 simulations.:  48%|████▊     | 4757/10000 [00:19<00:21, 239.36it/s]Running 10000 simulations.:  48%|████▊     | 4782/10000 [00:19<00:21, 240.53it/s]Running 10000 simulations.:  48%|████▊     | 4808/10000 [00:19<00:21, 243.49it/s]Running 10000 simulations.:  48%|████▊     | 4834/10000 [00:19<00:20, 246.70it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:19<00:20, 248.33it/s]Running 10000 simulations.:  49%|████▉     | 4885/10000 [00:19<00:21, 243.15it/s]Running 10000 simulations.:  49%|████▉     | 4910/10000 [00:20<00:21, 241.46it/s]Running 10000 simulations.:  49%|████▉     | 4936/10000 [00:20<00:20, 244.49it/s]Running 10000 simulations.:  50%|████▉     | 4962/10000 [00:20<00:20, 247.03it/s]Running 10000 simulations.:  50%|████▉     | 4987/10000 [00:20<00:20, 247.44it/s]Running 10000 simulations.:  50%|█████     | 5012/10000 [00:20<00:20, 244.15it/s]Running 10000 simulations.:  50%|█████     | 5038/10000 [00:20<00:20, 246.18it/s]Running 10000 simulations.:  51%|█████     | 5064/10000 [00:20<00:19, 249.39it/s]Running 10000 simulations.:  51%|█████     | 5089/10000 [00:20<00:19, 247.24it/s]Running 10000 simulations.:  51%|█████     | 5114/10000 [00:20<00:20, 241.03it/s]Running 10000 simulations.:  51%|█████▏    | 5139/10000 [00:20<00:20, 241.40it/s]Running 10000 simulations.:  52%|█████▏    | 5165/10000 [00:21<00:19, 243.99it/s]Running 10000 simulations.:  52%|█████▏    | 5190/10000 [00:21<00:19, 245.73it/s]Running 10000 simulations.:  52%|█████▏    | 5216/10000 [00:21<00:19, 247.73it/s]Running 10000 simulations.:  52%|█████▏    | 5242/10000 [00:21<00:19, 248.82it/s]Running 10000 simulations.:  53%|█████▎    | 5267/10000 [00:21<00:19, 243.81it/s]Running 10000 simulations.:  53%|█████▎    | 5292/10000 [00:21<00:19, 239.89it/s]Running 10000 simulations.:  53%|█████▎    | 5317/10000 [00:21<00:19, 239.00it/s]Running 10000 simulations.:  53%|█████▎    | 5342/10000 [00:21<00:19, 241.47it/s]Running 10000 simulations.:  54%|█████▎    | 5368/10000 [00:21<00:18, 244.17it/s]Running 10000 simulations.:  54%|█████▍    | 5393/10000 [00:22<00:18, 245.69it/s]Running 10000 simulations.:  54%|█████▍    | 5419/10000 [00:22<00:18, 247.77it/s]Running 10000 simulations.:  54%|█████▍    | 5444/10000 [00:22<00:18, 245.42it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:22<00:18, 240.13it/s]Running 10000 simulations.:  55%|█████▍    | 5494/10000 [00:22<00:18, 240.67it/s]Running 10000 simulations.:  55%|█████▌    | 5519/10000 [00:22<00:18, 243.40it/s]Running 10000 simulations.:  55%|█████▌    | 5545/10000 [00:22<00:18, 246.45it/s]Running 10000 simulations.:  56%|█████▌    | 5571/10000 [00:22<00:17, 248.70it/s]Running 10000 simulations.:  56%|█████▌    | 5597/10000 [00:22<00:17, 250.16it/s]Running 10000 simulations.:  56%|█████▌    | 5623/10000 [00:22<00:17, 244.43it/s]Running 10000 simulations.:  56%|█████▋    | 5648/10000 [00:23<00:17, 243.08it/s]Running 10000 simulations.:  57%|█████▋    | 5673/10000 [00:23<00:17, 244.91it/s]Running 10000 simulations.:  57%|█████▋    | 5698/10000 [00:23<00:17, 246.40it/s]Running 10000 simulations.:  57%|█████▋    | 5723/10000 [00:23<00:17, 247.02it/s]Running 10000 simulations.:  57%|█████▋    | 5749/10000 [00:23<00:17, 248.97it/s]Running 10000 simulations.:  58%|█████▊    | 5774/10000 [00:23<00:17, 248.06it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:23<00:17, 241.98it/s]Running 10000 simulations.:  58%|█████▊    | 5824/10000 [00:23<00:17, 241.93it/s]Running 10000 simulations.:  58%|█████▊    | 5849/10000 [00:23<00:17, 243.33it/s]Running 10000 simulations.:  59%|█████▊    | 5874/10000 [00:23<00:16, 244.49it/s]Running 10000 simulations.:  59%|█████▉    | 5899/10000 [00:24<00:16, 246.09it/s]Running 10000 simulations.:  59%|█████▉    | 5924/10000 [00:24<00:16, 247.16it/s]Running 10000 simulations.:  59%|█████▉    | 5949/10000 [00:24<00:16, 243.14it/s]Running 10000 simulations.:  60%|█████▉    | 5974/10000 [00:24<00:16, 239.77it/s]Running 10000 simulations.:  60%|█████▉    | 5999/10000 [00:24<00:16, 241.89it/s]Running 10000 simulations.:  60%|██████    | 6024/10000 [00:24<00:16, 243.60it/s]Running 10000 simulations.:  60%|██████    | 6049/10000 [00:24<00:16, 245.23it/s]Running 10000 simulations.:  61%|██████    | 6074/10000 [00:24<00:15, 246.61it/s]Running 10000 simulations.:  61%|██████    | 6099/10000 [00:24<00:15, 245.58it/s]Running 10000 simulations.:  61%|██████    | 6124/10000 [00:25<00:16, 240.66it/s]Running 10000 simulations.:  61%|██████▏   | 6149/10000 [00:25<00:16, 237.37it/s]Running 10000 simulations.:  62%|██████▏   | 6173/10000 [00:25<00:16, 237.93it/s]Running 10000 simulations.:  62%|██████▏   | 6198/10000 [00:25<00:15, 240.90it/s]Running 10000 simulations.:  62%|██████▏   | 6223/10000 [00:25<00:15, 243.27it/s]Running 10000 simulations.:  62%|██████▏   | 6249/10000 [00:25<00:15, 245.68it/s]Running 10000 simulations.:  63%|██████▎   | 6275/10000 [00:25<00:14, 248.79it/s]Running 10000 simulations.:  63%|██████▎   | 6300/10000 [00:25<00:15, 244.72it/s]Running 10000 simulations.:  63%|██████▎   | 6325/10000 [00:25<00:15, 241.01it/s]Running 10000 simulations.:  64%|██████▎   | 6351/10000 [00:25<00:14, 244.16it/s]Running 10000 simulations.:  64%|██████▍   | 6377/10000 [00:26<00:14, 246.99it/s]Running 10000 simulations.:  64%|██████▍   | 6402/10000 [00:26<00:14, 245.79it/s]Running 10000 simulations.:  64%|██████▍   | 6427/10000 [00:26<00:14, 245.83it/s]Running 10000 simulations.:  65%|██████▍   | 6453/10000 [00:26<00:14, 247.43it/s]Running 10000 simulations.:  65%|██████▍   | 6479/10000 [00:26<00:14, 249.23it/s]Running 10000 simulations.:  65%|██████▌   | 6504/10000 [00:26<00:14, 246.84it/s]Running 10000 simulations.:  65%|██████▌   | 6529/10000 [00:26<00:14, 241.06it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:26<00:14, 240.91it/s]Running 10000 simulations.:  66%|██████▌   | 6579/10000 [00:26<00:14, 243.03it/s]Running 10000 simulations.:  66%|██████▌   | 6605/10000 [00:26<00:13, 245.32it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:27<00:13, 246.05it/s]Running 10000 simulations.:  67%|██████▋   | 6655/10000 [00:27<00:13, 246.81it/s]Running 10000 simulations.:  67%|██████▋   | 6680/10000 [00:27<00:13, 242.84it/s]Running 10000 simulations.:  67%|██████▋   | 6705/10000 [00:27<00:13, 238.65it/s]Running 10000 simulations.:  67%|██████▋   | 6729/10000 [00:27<00:13, 236.86it/s]Running 10000 simulations.:  68%|██████▊   | 6754/10000 [00:27<00:13, 240.17it/s]Running 10000 simulations.:  68%|██████▊   | 6779/10000 [00:27<00:13, 242.37it/s]Running 10000 simulations.:  68%|██████▊   | 6804/10000 [00:27<00:13, 243.91it/s]Running 10000 simulations.:  68%|██████▊   | 6830/10000 [00:27<00:12, 246.04it/s]Running 10000 simulations.:  69%|██████▊   | 6855/10000 [00:28<00:12, 245.95it/s]Running 10000 simulations.:  69%|██████▉   | 6880/10000 [00:28<00:12, 241.72it/s]Running 10000 simulations.:  69%|██████▉   | 6905/10000 [00:28<00:12, 241.07it/s]Running 10000 simulations.:  69%|██████▉   | 6930/10000 [00:28<00:12, 242.12it/s]Running 10000 simulations.:  70%|██████▉   | 6955/10000 [00:28<00:12, 244.23it/s]Running 10000 simulations.:  70%|██████▉   | 6981/10000 [00:28<00:12, 246.48it/s]Running 10000 simulations.:  70%|███████   | 7007/10000 [00:28<00:12, 248.11it/s]Running 10000 simulations.:  70%|███████   | 7032/10000 [00:28<00:12, 243.03it/s]Running 10000 simulations.:  71%|███████   | 7057/10000 [00:28<00:12, 239.60it/s]Running 10000 simulations.:  71%|███████   | 7082/10000 [00:28<00:12, 241.66it/s]Running 10000 simulations.:  71%|███████   | 7107/10000 [00:29<00:11, 243.59it/s]Running 10000 simulations.:  71%|███████▏  | 7133/10000 [00:29<00:11, 246.28it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:29<00:11, 247.59it/s]Running 10000 simulations.:  72%|███████▏  | 7184/10000 [00:29<00:11, 244.93it/s]Running 10000 simulations.:  72%|███████▏  | 7209/10000 [00:29<00:11, 239.92it/s]Running 10000 simulations.:  72%|███████▏  | 7234/10000 [00:29<00:11, 240.95it/s]Running 10000 simulations.:  73%|███████▎  | 7260/10000 [00:29<00:11, 243.73it/s]Running 10000 simulations.:  73%|███████▎  | 7285/10000 [00:29<00:11, 244.98it/s]Running 10000 simulations.:  73%|███████▎  | 7310/10000 [00:29<00:10, 245.74it/s]Running 10000 simulations.:  73%|███████▎  | 7335/10000 [00:29<00:10, 246.50it/s]Running 10000 simulations.:  74%|███████▎  | 7360/10000 [00:30<00:10, 241.83it/s]Running 10000 simulations.:  74%|███████▍  | 7385/10000 [00:30<00:10, 238.42it/s]Running 10000 simulations.:  74%|███████▍  | 7410/10000 [00:30<00:10, 240.45it/s]Running 10000 simulations.:  74%|███████▍  | 7435/10000 [00:30<00:10, 242.48it/s]Running 10000 simulations.:  75%|███████▍  | 7460/10000 [00:30<00:10, 244.14it/s]Running 10000 simulations.:  75%|███████▍  | 7486/10000 [00:30<00:10, 246.59it/s]Running 10000 simulations.:  75%|███████▌  | 7511/10000 [00:30<00:10, 242.88it/s]Running 10000 simulations.:  75%|███████▌  | 7536/10000 [00:30<00:10, 237.78it/s]Running 10000 simulations.:  76%|███████▌  | 7561/10000 [00:30<00:10, 239.81it/s]Running 10000 simulations.:  76%|███████▌  | 7586/10000 [00:31<00:09, 241.55it/s]Running 10000 simulations.:  76%|███████▌  | 7611/10000 [00:31<00:09, 243.24it/s]Running 10000 simulations.:  76%|███████▋  | 7636/10000 [00:31<00:09, 241.78it/s]Running 10000 simulations.:  77%|███████▋  | 7661/10000 [00:31<00:09, 242.83it/s]Running 10000 simulations.:  77%|███████▋  | 7686/10000 [00:31<00:09, 244.82it/s]Running 10000 simulations.:  77%|███████▋  | 7711/10000 [00:31<00:09, 245.85it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:31<00:09, 240.55it/s]Running 10000 simulations.:  78%|███████▊  | 7761/10000 [00:31<00:09, 234.03it/s]Running 10000 simulations.:  78%|███████▊  | 7786/10000 [00:31<00:09, 237.14it/s]Running 10000 simulations.:  78%|███████▊  | 7811/10000 [00:31<00:09, 240.85it/s]Running 10000 simulations.:  78%|███████▊  | 7836/10000 [00:32<00:08, 243.35it/s]Running 10000 simulations.:  79%|███████▊  | 7862/10000 [00:32<00:08, 246.15it/s]Running 10000 simulations.:  79%|███████▉  | 7887/10000 [00:32<00:08, 245.02it/s]Running 10000 simulations.:  79%|███████▉  | 7912/10000 [00:32<00:08, 238.22it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:32<00:08, 237.63it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:32<00:08, 240.60it/s]Running 10000 simulations.:  80%|███████▉  | 7986/10000 [00:32<00:08, 242.90it/s]Running 10000 simulations.:  80%|████████  | 8011/10000 [00:32<00:08, 244.58it/s]Running 10000 simulations.:  80%|████████  | 8037/10000 [00:32<00:07, 246.01it/s]Running 10000 simulations.:  81%|████████  | 8062/10000 [00:32<00:08, 240.68it/s]Running 10000 simulations.:  81%|████████  | 8087/10000 [00:33<00:08, 236.53it/s]Running 10000 simulations.:  81%|████████  | 8112/10000 [00:33<00:07, 238.94it/s]Running 10000 simulations.:  81%|████████▏ | 8137/10000 [00:33<00:07, 240.72it/s]Running 10000 simulations.:  82%|████████▏ | 8162/10000 [00:33<00:07, 242.16it/s]Running 10000 simulations.:  82%|████████▏ | 8187/10000 [00:33<00:07, 244.37it/s]Running 10000 simulations.:  82%|████████▏ | 8212/10000 [00:33<00:07, 242.37it/s]Running 10000 simulations.:  82%|████████▏ | 8237/10000 [00:33<00:07, 236.25it/s]Running 10000 simulations.:  83%|████████▎ | 8261/10000 [00:33<00:07, 236.63it/s]Running 10000 simulations.:  83%|████████▎ | 8286/10000 [00:33<00:07, 238.91it/s]Running 10000 simulations.:  83%|████████▎ | 8311/10000 [00:34<00:07, 240.94it/s]Running 10000 simulations.:  83%|████████▎ | 8336/10000 [00:34<00:06, 242.29it/s]Running 10000 simulations.:  84%|████████▎ | 8361/10000 [00:34<00:06, 242.16it/s]Running 10000 simulations.:  84%|████████▍ | 8386/10000 [00:34<00:06, 236.14it/s]Running 10000 simulations.:  84%|████████▍ | 8410/10000 [00:34<00:06, 231.14it/s]Running 10000 simulations.:  84%|████████▍ | 8435/10000 [00:34<00:06, 234.71it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:34<00:06, 237.58it/s]Running 10000 simulations.:  85%|████████▍ | 8485/10000 [00:34<00:06, 240.57it/s]Running 10000 simulations.:  85%|████████▌ | 8510/10000 [00:34<00:06, 243.03it/s]Running 10000 simulations.:  85%|████████▌ | 8535/10000 [00:34<00:06, 242.20it/s]Running 10000 simulations.:  86%|████████▌ | 8560/10000 [00:35<00:06, 236.74it/s]Running 10000 simulations.:  86%|████████▌ | 8584/10000 [00:35<00:06, 233.21it/s]Running 10000 simulations.:  86%|████████▌ | 8608/10000 [00:35<00:05, 232.45it/s]Running 10000 simulations.:  86%|████████▋ | 8633/10000 [00:35<00:05, 235.86it/s]Running 10000 simulations.:  87%|████████▋ | 8658/10000 [00:35<00:05, 237.91it/s]Running 10000 simulations.:  87%|████████▋ | 8683/10000 [00:35<00:05, 239.98it/s]Running 10000 simulations.:  87%|████████▋ | 8708/10000 [00:35<00:05, 242.22it/s]Running 10000 simulations.:  87%|████████▋ | 8733/10000 [00:35<00:05, 240.25it/s]Running 10000 simulations.:  88%|████████▊ | 8758/10000 [00:35<00:05, 234.40it/s]Running 10000 simulations.:  88%|████████▊ | 8783/10000 [00:36<00:05, 236.33it/s]Running 10000 simulations.:  88%|████████▊ | 8808/10000 [00:36<00:04, 239.37it/s]Running 10000 simulations.:  88%|████████▊ | 8833/10000 [00:36<00:04, 241.37it/s]Running 10000 simulations.:  89%|████████▊ | 8858/10000 [00:36<00:04, 243.07it/s]Running 10000 simulations.:  89%|████████▉ | 8883/10000 [00:36<00:04, 243.81it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:36<00:04, 237.96it/s]Running 10000 simulations.:  89%|████████▉ | 8932/10000 [00:36<00:04, 233.85it/s]Running 10000 simulations.:  90%|████████▉ | 8956/10000 [00:36<00:04, 232.31it/s]Running 10000 simulations.:  90%|████████▉ | 8981/10000 [00:36<00:04, 236.57it/s]Running 10000 simulations.:  90%|█████████ | 9006/10000 [00:36<00:04, 240.01it/s]Running 10000 simulations.:  90%|█████████ | 9031/10000 [00:37<00:04, 238.80it/s]Running 10000 simulations.:  91%|█████████ | 9056/10000 [00:37<00:03, 240.18it/s]Running 10000 simulations.:  91%|█████████ | 9081/10000 [00:37<00:03, 242.30it/s]Running 10000 simulations.:  91%|█████████ | 9106/10000 [00:37<00:03, 243.77it/s]Running 10000 simulations.:  91%|█████████▏| 9131/10000 [00:37<00:03, 244.53it/s]Running 10000 simulations.:  92%|█████████▏| 9156/10000 [00:37<00:03, 238.80it/s]Running 10000 simulations.:  92%|█████████▏| 9180/10000 [00:37<00:03, 239.01it/s]Running 10000 simulations.:  92%|█████████▏| 9206/10000 [00:37<00:03, 242.73it/s]Running 10000 simulations.:  92%|█████████▏| 9232/10000 [00:37<00:03, 246.22it/s]Running 10000 simulations.:  93%|█████████▎| 9258/10000 [00:37<00:02, 247.41it/s]Running 10000 simulations.:  93%|█████████▎| 9284/10000 [00:38<00:02, 250.63it/s]Running 10000 simulations.:  93%|█████████▎| 9310/10000 [00:38<00:02, 245.21it/s]Running 10000 simulations.:  93%|█████████▎| 9335/10000 [00:38<00:02, 240.80it/s]Running 10000 simulations.:  94%|█████████▎| 9360/10000 [00:38<00:02, 226.40it/s]Running 10000 simulations.:  94%|█████████▍| 9386/10000 [00:38<00:02, 233.51it/s]Running 10000 simulations.:  94%|█████████▍| 9412/10000 [00:38<00:02, 239.46it/s]Running 10000 simulations.:  94%|█████████▍| 9438/10000 [00:38<00:02, 243.07it/s]Running 10000 simulations.:  95%|█████████▍| 9464/10000 [00:38<00:02, 247.03it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [00:38<00:02, 248.21it/s]Running 10000 simulations.:  95%|█████████▌| 9515/10000 [00:39<00:01, 243.25it/s]Running 10000 simulations.:  95%|█████████▌| 9540/10000 [00:39<00:01, 238.83it/s]Running 10000 simulations.:  96%|█████████▌| 9565/10000 [00:39<00:01, 239.84it/s]Running 10000 simulations.:  96%|█████████▌| 9591/10000 [00:39<00:01, 243.58it/s]Running 10000 simulations.:  96%|█████████▌| 9617/10000 [00:39<00:01, 247.14it/s]Running 10000 simulations.:  96%|█████████▋| 9643/10000 [00:39<00:01, 250.79it/s]Running 10000 simulations.:  97%|█████████▋| 9670/10000 [00:39<00:01, 254.60it/s]Running 10000 simulations.:  97%|█████████▋| 9696/10000 [00:39<00:01, 249.31it/s]Running 10000 simulations.:  97%|█████████▋| 9721/10000 [00:39<00:01, 243.93it/s]Running 10000 simulations.:  97%|█████████▋| 9746/10000 [00:39<00:01, 240.98it/s]Running 10000 simulations.:  98%|█████████▊| 9772/10000 [00:40<00:00, 243.81it/s]Running 10000 simulations.:  98%|█████████▊| 9798/10000 [00:40<00:00, 247.16it/s]Running 10000 simulations.:  98%|█████████▊| 9824/10000 [00:40<00:00, 249.95it/s]Running 10000 simulations.:  98%|█████████▊| 9850/10000 [00:40<00:00, 252.25it/s]Running 10000 simulations.:  99%|█████████▉| 9876/10000 [00:40<00:00, 253.93it/s]Running 10000 simulations.:  99%|█████████▉| 9902/10000 [00:40<00:00, 247.76it/s]Running 10000 simulations.:  99%|█████████▉| 9927/10000 [00:40<00:00, 245.86it/s]Running 10000 simulations.: 100%|█████████▉| 9953/10000 [00:40<00:00, 247.83it/s]Running 10000 simulations.: 100%|█████████▉| 9979/10000 [00:40<00:00, 250.68it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:40<00:00, 243.91it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 273.61it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<00:36, 273.71it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<00:36, 273.10it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<00:36, 272.40it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:36, 271.80it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:36, 272.40it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:00<00:35, 272.54it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:00<00:35, 272.46it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:00<00:35, 272.53it/s]Running 10000 simulations.:   3%|▎         | 279/10000 [00:01<00:35, 271.63it/s]Running 10000 simulations.:   3%|▎         | 307/10000 [00:01<00:35, 271.38it/s]Running 10000 simulations.:   3%|▎         | 335/10000 [00:01<00:35, 271.02it/s]Running 10000 simulations.:   4%|▎         | 363/10000 [00:01<00:35, 270.76it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:35, 270.36it/s]Running 10000 simulations.:   4%|▍         | 418/10000 [00:01<00:35, 270.79it/s]Running 10000 simulations.:   4%|▍         | 446/10000 [00:01<00:35, 270.74it/s]Running 10000 simulations.:   5%|▍         | 473/10000 [00:01<00:35, 270.07it/s]Running 10000 simulations.:   5%|▌         | 501/10000 [00:01<00:35, 270.20it/s]Running 10000 simulations.:   5%|▌         | 529/10000 [00:01<00:35, 270.35it/s]Running 10000 simulations.:   6%|▌         | 557/10000 [00:02<00:34, 270.07it/s]Running 10000 simulations.:   6%|▌         | 585/10000 [00:02<00:34, 270.35it/s]Running 10000 simulations.:   6%|▌         | 613/10000 [00:02<00:34, 270.46it/s]Running 10000 simulations.:   6%|▋         | 641/10000 [00:02<00:34, 270.42it/s]Running 10000 simulations.:   7%|▋         | 669/10000 [00:02<00:34, 270.09it/s]Running 10000 simulations.:   7%|▋         | 697/10000 [00:02<00:34, 269.99it/s]Running 10000 simulations.:   7%|▋         | 724/10000 [00:02<00:34, 269.91it/s]Running 10000 simulations.:   8%|▊         | 752/10000 [00:02<00:34, 270.32it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:02<00:34, 269.92it/s]Running 10000 simulations.:   8%|▊         | 808/10000 [00:02<00:34, 270.18it/s]Running 10000 simulations.:   8%|▊         | 836/10000 [00:03<00:33, 269.81it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:03<00:33, 270.08it/s]Running 10000 simulations.:   9%|▉         | 892/10000 [00:03<00:33, 269.28it/s]Running 10000 simulations.:   9%|▉         | 920/10000 [00:03<00:33, 269.53it/s]Running 10000 simulations.:   9%|▉         | 947/10000 [00:03<00:33, 269.09it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:03<00:33, 269.46it/s]Running 10000 simulations.:  10%|█         | 1002/10000 [00:03<00:33, 269.32it/s]Running 10000 simulations.:  10%|█         | 1030/10000 [00:03<00:33, 269.47it/s]Running 10000 simulations.:  11%|█         | 1058/10000 [00:03<00:33, 269.71it/s]Running 10000 simulations.:  11%|█         | 1086/10000 [00:04<00:32, 270.32it/s]Running 10000 simulations.:  11%|█         | 1114/10000 [00:04<00:32, 269.98it/s]Running 10000 simulations.:  11%|█▏        | 1142/10000 [00:04<00:32, 270.10it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:04<00:32, 270.26it/s]Running 10000 simulations.:  12%|█▏        | 1198/10000 [00:04<00:32, 270.49it/s]Running 10000 simulations.:  12%|█▏        | 1226/10000 [00:04<00:32, 270.54it/s]Running 10000 simulations.:  13%|█▎        | 1254/10000 [00:04<00:32, 270.98it/s]Running 10000 simulations.:  13%|█▎        | 1282/10000 [00:04<00:32, 271.34it/s]Running 10000 simulations.:  13%|█▎        | 1310/10000 [00:04<00:32, 271.04it/s]Running 10000 simulations.:  13%|█▎        | 1338/10000 [00:04<00:32, 270.10it/s]Running 10000 simulations.:  14%|█▎        | 1366/10000 [00:05<00:32, 269.36it/s]Running 10000 simulations.:  14%|█▍        | 1394/10000 [00:05<00:31, 269.51it/s]Running 10000 simulations.:  14%|█▍        | 1421/10000 [00:05<00:32, 266.79it/s]Running 10000 simulations.:  14%|█▍        | 1448/10000 [00:05<00:32, 263.21it/s]Running 10000 simulations.:  15%|█▍        | 1475/10000 [00:05<00:32, 264.84it/s]Running 10000 simulations.:  15%|█▌        | 1502/10000 [00:05<00:31, 266.22it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:05<00:31, 268.02it/s]Running 10000 simulations.:  16%|█▌        | 1557/10000 [00:05<00:31, 268.47it/s]Running 10000 simulations.:  16%|█▌        | 1584/10000 [00:05<00:31, 268.42it/s]Running 10000 simulations.:  16%|█▌        | 1611/10000 [00:05<00:31, 268.82it/s]Running 10000 simulations.:  16%|█▋        | 1638/10000 [00:06<00:31, 267.20it/s]Running 10000 simulations.:  17%|█▋        | 1665/10000 [00:06<00:31, 267.60it/s]Running 10000 simulations.:  17%|█▋        | 1693/10000 [00:06<00:30, 268.40it/s]Running 10000 simulations.:  17%|█▋        | 1720/10000 [00:06<00:30, 268.84it/s]Running 10000 simulations.:  17%|█▋        | 1747/10000 [00:06<00:30, 268.50it/s]Running 10000 simulations.:  18%|█▊        | 1774/10000 [00:06<00:30, 268.46it/s]Running 10000 simulations.:  18%|█▊        | 1801/10000 [00:06<00:30, 268.64it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:06<00:30, 269.50it/s]Running 10000 simulations.:  19%|█▊        | 1857/10000 [00:06<00:30, 269.69it/s]Running 10000 simulations.:  19%|█▉        | 1884/10000 [00:06<00:30, 269.75it/s]Running 10000 simulations.:  19%|█▉        | 1911/10000 [00:07<00:30, 269.42it/s]Running 10000 simulations.:  19%|█▉        | 1938/10000 [00:07<00:29, 269.45it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:07<00:29, 269.53it/s]Running 10000 simulations.:  20%|█▉        | 1992/10000 [00:07<00:29, 269.34it/s]Running 10000 simulations.:  20%|██        | 2019/10000 [00:07<00:29, 269.17it/s]Running 10000 simulations.:  20%|██        | 2046/10000 [00:07<00:29, 269.40it/s]Running 10000 simulations.:  21%|██        | 2073/10000 [00:07<00:29, 269.27it/s]Running 10000 simulations.:  21%|██        | 2101/10000 [00:07<00:29, 269.61it/s]Running 10000 simulations.:  21%|██▏       | 2128/10000 [00:07<00:29, 269.48it/s]Running 10000 simulations.:  22%|██▏       | 2155/10000 [00:07<00:29, 268.49it/s]Running 10000 simulations.:  22%|██▏       | 2182/10000 [00:08<00:29, 267.70it/s]Running 10000 simulations.:  22%|██▏       | 2209/10000 [00:08<00:29, 267.31it/s]Running 10000 simulations.:  22%|██▏       | 2236/10000 [00:08<00:30, 255.20it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:08<00:29, 258.76it/s]Running 10000 simulations.:  23%|██▎       | 2290/10000 [00:08<00:29, 261.43it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:08<00:29, 263.27it/s]Running 10000 simulations.:  23%|██▎       | 2344/10000 [00:08<00:28, 264.62it/s]Running 10000 simulations.:  24%|██▎       | 2371/10000 [00:08<00:28, 265.29it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:08<00:28, 265.79it/s]Running 10000 simulations.:  24%|██▍       | 2425/10000 [00:09<00:28, 266.14it/s]Running 10000 simulations.:  25%|██▍       | 2452/10000 [00:09<00:28, 266.29it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:09<00:28, 266.43it/s]Running 10000 simulations.:  25%|██▌       | 2506/10000 [00:09<00:28, 266.21it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:09<00:28, 266.39it/s]Running 10000 simulations.:  26%|██▌       | 2560/10000 [00:09<00:27, 266.09it/s]Running 10000 simulations.:  26%|██▌       | 2587/10000 [00:09<00:27, 266.34it/s]Running 10000 simulations.:  26%|██▌       | 2614/10000 [00:09<00:27, 266.22it/s]Running 10000 simulations.:  26%|██▋       | 2641/10000 [00:09<00:27, 266.57it/s]Running 10000 simulations.:  27%|██▋       | 2668/10000 [00:09<00:27, 266.44it/s]Running 10000 simulations.:  27%|██▋       | 2695/10000 [00:10<00:27, 266.79it/s]Running 10000 simulations.:  27%|██▋       | 2722/10000 [00:10<00:27, 266.27it/s]Running 10000 simulations.:  27%|██▋       | 2749/10000 [00:10<00:27, 266.65it/s]Running 10000 simulations.:  28%|██▊       | 2776/10000 [00:10<00:27, 266.66it/s]Running 10000 simulations.:  28%|██▊       | 2803/10000 [00:10<00:27, 266.07it/s]Running 10000 simulations.:  28%|██▊       | 2830/10000 [00:10<00:26, 266.54it/s]Running 10000 simulations.:  29%|██▊       | 2857/10000 [00:10<00:26, 266.22it/s]Running 10000 simulations.:  29%|██▉       | 2884/10000 [00:10<00:26, 266.14it/s]Running 10000 simulations.:  29%|██▉       | 2911/10000 [00:10<00:26, 266.16it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:10<00:26, 265.77it/s]Running 10000 simulations.:  30%|██▉       | 2965/10000 [00:11<00:26, 265.81it/s]Running 10000 simulations.:  30%|██▉       | 2992/10000 [00:11<00:26, 261.81it/s]Running 10000 simulations.:  30%|███       | 3019/10000 [00:11<00:26, 262.81it/s]Running 10000 simulations.:  30%|███       | 3046/10000 [00:11<00:26, 264.60it/s]Running 10000 simulations.:  31%|███       | 3073/10000 [00:11<00:26, 265.45it/s]Running 10000 simulations.:  31%|███       | 3100/10000 [00:11<00:25, 266.21it/s]Running 10000 simulations.:  31%|███▏      | 3127/10000 [00:11<00:25, 266.38it/s]Running 10000 simulations.:  32%|███▏      | 3154/10000 [00:11<00:25, 266.66it/s]Running 10000 simulations.:  32%|███▏      | 3182/10000 [00:11<00:25, 267.65it/s]Running 10000 simulations.:  32%|███▏      | 3209/10000 [00:11<00:25, 267.26it/s]Running 10000 simulations.:  32%|███▏      | 3236/10000 [00:12<00:25, 267.21it/s]Running 10000 simulations.:  33%|███▎      | 3263/10000 [00:12<00:25, 267.16it/s]Running 10000 simulations.:  33%|███▎      | 3290/10000 [00:12<00:25, 266.73it/s]Running 10000 simulations.:  33%|███▎      | 3317/10000 [00:12<00:25, 267.07it/s]Running 10000 simulations.:  33%|███▎      | 3344/10000 [00:12<00:24, 266.34it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:12<00:24, 265.88it/s]Running 10000 simulations.:  34%|███▍      | 3398/10000 [00:12<00:24, 265.02it/s]Running 10000 simulations.:  34%|███▍      | 3425/10000 [00:12<00:24, 265.26it/s]Running 10000 simulations.:  35%|███▍      | 3452/10000 [00:12<00:24, 266.59it/s]Running 10000 simulations.:  35%|███▍      | 3479/10000 [00:12<00:24, 267.21it/s]Running 10000 simulations.:  35%|███▌      | 3506/10000 [00:13<00:24, 266.93it/s]Running 10000 simulations.:  35%|███▌      | 3533/10000 [00:13<00:24, 267.09it/s]Running 10000 simulations.:  36%|███▌      | 3560/10000 [00:13<00:24, 266.55it/s]Running 10000 simulations.:  36%|███▌      | 3587/10000 [00:13<00:24, 266.48it/s]Running 10000 simulations.:  36%|███▌      | 3614/10000 [00:13<00:23, 266.83it/s]Running 10000 simulations.:  36%|███▋      | 3641/10000 [00:13<00:23, 266.95it/s]Running 10000 simulations.:  37%|███▋      | 3668/10000 [00:13<00:23, 266.74it/s]Running 10000 simulations.:  37%|███▋      | 3695/10000 [00:13<00:23, 267.24it/s]Running 10000 simulations.:  37%|███▋      | 3722/10000 [00:13<00:23, 267.66it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:13<00:23, 267.86it/s]Running 10000 simulations.:  38%|███▊      | 3776/10000 [00:14<00:23, 267.80it/s]Running 10000 simulations.:  38%|███▊      | 3803/10000 [00:14<00:23, 267.75it/s]Running 10000 simulations.:  38%|███▊      | 3830/10000 [00:14<00:23, 266.54it/s]Running 10000 simulations.:  39%|███▊      | 3857/10000 [00:14<00:23, 266.72it/s]Running 10000 simulations.:  39%|███▉      | 3884/10000 [00:14<00:22, 266.93it/s]Running 10000 simulations.:  39%|███▉      | 3912/10000 [00:14<00:22, 267.99it/s]Running 10000 simulations.:  39%|███▉      | 3939/10000 [00:14<00:22, 268.29it/s]Running 10000 simulations.:  40%|███▉      | 3966/10000 [00:14<00:22, 268.17it/s]Running 10000 simulations.:  40%|███▉      | 3994/10000 [00:14<00:22, 268.79it/s]Running 10000 simulations.:  40%|████      | 4021/10000 [00:15<00:22, 269.02it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:15<00:22, 268.12it/s]Running 10000 simulations.:  41%|████      | 4075/10000 [00:15<00:22, 268.36it/s]Running 10000 simulations.:  41%|████      | 4103/10000 [00:15<00:21, 269.22it/s]Running 10000 simulations.:  41%|████▏     | 4130/10000 [00:15<00:21, 269.01it/s]Running 10000 simulations.:  42%|████▏     | 4157/10000 [00:15<00:21, 269.25it/s]Running 10000 simulations.:  42%|████▏     | 4184/10000 [00:15<00:21, 269.19it/s]Running 10000 simulations.:  42%|████▏     | 4211/10000 [00:15<00:21, 269.06it/s]Running 10000 simulations.:  42%|████▏     | 4238/10000 [00:15<00:21, 267.48it/s]Running 10000 simulations.:  43%|████▎     | 4265/10000 [00:15<00:21, 267.69it/s]Running 10000 simulations.:  43%|████▎     | 4292/10000 [00:16<00:21, 267.13it/s]Running 10000 simulations.:  43%|████▎     | 4319/10000 [00:16<00:21, 267.39it/s]Running 10000 simulations.:  43%|████▎     | 4346/10000 [00:16<00:21, 268.01it/s]Running 10000 simulations.:  44%|████▎     | 4373/10000 [00:16<00:20, 268.19it/s]Running 10000 simulations.:  44%|████▍     | 4400/10000 [00:16<00:20, 267.98it/s]Running 10000 simulations.:  44%|████▍     | 4427/10000 [00:16<00:20, 268.55it/s]Running 10000 simulations.:  45%|████▍     | 4454/10000 [00:16<00:20, 267.95it/s]Running 10000 simulations.:  45%|████▍     | 4481/10000 [00:16<00:20, 267.53it/s]Running 10000 simulations.:  45%|████▌     | 4508/10000 [00:16<00:20, 266.83it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:16<00:20, 266.35it/s]Running 10000 simulations.:  46%|████▌     | 4562/10000 [00:17<00:20, 266.73it/s]Running 10000 simulations.:  46%|████▌     | 4589/10000 [00:17<00:20, 265.60it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:17<00:20, 260.30it/s]Running 10000 simulations.:  46%|████▋     | 4643/10000 [00:17<00:20, 261.27it/s]Running 10000 simulations.:  47%|████▋     | 4670/10000 [00:17<00:20, 262.56it/s]Running 10000 simulations.:  47%|████▋     | 4697/10000 [00:17<00:20, 263.55it/s]Running 10000 simulations.:  47%|████▋     | 4724/10000 [00:17<00:19, 264.85it/s]Running 10000 simulations.:  48%|████▊     | 4751/10000 [00:17<00:19, 265.83it/s]Running 10000 simulations.:  48%|████▊     | 4778/10000 [00:17<00:19, 266.22it/s]Running 10000 simulations.:  48%|████▊     | 4805/10000 [00:17<00:19, 266.57it/s]Running 10000 simulations.:  48%|████▊     | 4832/10000 [00:18<00:19, 265.78it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:18<00:19, 266.37it/s]Running 10000 simulations.:  49%|████▉     | 4886/10000 [00:18<00:19, 265.58it/s]Running 10000 simulations.:  49%|████▉     | 4913/10000 [00:18<00:19, 265.28it/s]Running 10000 simulations.:  49%|████▉     | 4940/10000 [00:18<00:19, 265.55it/s]Running 10000 simulations.:  50%|████▉     | 4967/10000 [00:18<00:18, 265.92it/s]Running 10000 simulations.:  50%|████▉     | 4994/10000 [00:18<00:18, 266.80it/s]Running 10000 simulations.:  50%|█████     | 5021/10000 [00:18<00:18, 267.07it/s]Running 10000 simulations.:  50%|█████     | 5048/10000 [00:18<00:18, 266.62it/s]Running 10000 simulations.:  51%|█████     | 5075/10000 [00:18<00:18, 266.62it/s]Running 10000 simulations.:  51%|█████     | 5102/10000 [00:19<00:18, 266.48it/s]Running 10000 simulations.:  51%|█████▏    | 5129/10000 [00:19<00:18, 265.76it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:19<00:18, 265.48it/s]Running 10000 simulations.:  52%|█████▏    | 5183/10000 [00:19<00:18, 265.64it/s]Running 10000 simulations.:  52%|█████▏    | 5210/10000 [00:19<00:18, 266.08it/s]Running 10000 simulations.:  52%|█████▏    | 5237/10000 [00:19<00:17, 267.23it/s]Running 10000 simulations.:  53%|█████▎    | 5264/10000 [00:19<00:17, 266.78it/s]Running 10000 simulations.:  53%|█████▎    | 5291/10000 [00:19<00:17, 266.40it/s]Running 10000 simulations.:  53%|█████▎    | 5318/10000 [00:19<00:17, 266.36it/s]Running 10000 simulations.:  53%|█████▎    | 5345/10000 [00:19<00:17, 266.95it/s]Running 10000 simulations.:  54%|█████▎    | 5372/10000 [00:20<00:17, 266.59it/s]Running 10000 simulations.:  54%|█████▍    | 5399/10000 [00:20<00:17, 266.66it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:20<00:17, 267.01it/s]Running 10000 simulations.:  55%|█████▍    | 5453/10000 [00:20<00:17, 266.29it/s]Running 10000 simulations.:  55%|█████▍    | 5481/10000 [00:20<00:16, 267.46it/s]Running 10000 simulations.:  55%|█████▌    | 5509/10000 [00:20<00:16, 268.20it/s]Running 10000 simulations.:  55%|█████▌    | 5536/10000 [00:20<00:16, 268.37it/s]Running 10000 simulations.:  56%|█████▌    | 5563/10000 [00:20<00:16, 268.18it/s]Running 10000 simulations.:  56%|█████▌    | 5590/10000 [00:20<00:16, 268.48it/s]Running 10000 simulations.:  56%|█████▌    | 5617/10000 [00:20<00:16, 268.44it/s]Running 10000 simulations.:  56%|█████▋    | 5644/10000 [00:21<00:16, 268.31it/s]Running 10000 simulations.:  57%|█████▋    | 5671/10000 [00:21<00:16, 268.49it/s]Running 10000 simulations.:  57%|█████▋    | 5698/10000 [00:21<00:16, 268.50it/s]Running 10000 simulations.:  57%|█████▋    | 5725/10000 [00:21<00:16, 267.03it/s]Running 10000 simulations.:  58%|█████▊    | 5752/10000 [00:21<00:15, 267.03it/s]Running 10000 simulations.:  58%|█████▊    | 5779/10000 [00:21<00:15, 266.79it/s]Running 10000 simulations.:  58%|█████▊    | 5806/10000 [00:21<00:15, 266.71it/s]Running 10000 simulations.:  58%|█████▊    | 5833/10000 [00:21<00:15, 266.15it/s]Running 10000 simulations.:  59%|█████▊    | 5860/10000 [00:21<00:15, 265.12it/s]Running 10000 simulations.:  59%|█████▉    | 5887/10000 [00:22<00:15, 264.31it/s]Running 10000 simulations.:  59%|█████▉    | 5914/10000 [00:22<00:15, 264.56it/s]Running 10000 simulations.:  59%|█████▉    | 5941/10000 [00:22<00:15, 264.66it/s]Running 10000 simulations.:  60%|█████▉    | 5968/10000 [00:22<00:15, 265.60it/s]Running 10000 simulations.:  60%|█████▉    | 5995/10000 [00:22<00:15, 265.16it/s]Running 10000 simulations.:  60%|██████    | 6022/10000 [00:22<00:14, 265.89it/s]Running 10000 simulations.:  60%|██████    | 6049/10000 [00:22<00:14, 266.68it/s]Running 10000 simulations.:  61%|██████    | 6076/10000 [00:22<00:14, 266.71it/s]Running 10000 simulations.:  61%|██████    | 6103/10000 [00:22<00:14, 266.98it/s]Running 10000 simulations.:  61%|██████▏   | 6130/10000 [00:22<00:14, 267.12it/s]Running 10000 simulations.:  62%|██████▏   | 6157/10000 [00:23<00:14, 266.40it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:23<00:14, 266.69it/s]Running 10000 simulations.:  62%|██████▏   | 6211/10000 [00:23<00:14, 266.85it/s]Running 10000 simulations.:  62%|██████▏   | 6238/10000 [00:23<00:14, 266.77it/s]Running 10000 simulations.:  63%|██████▎   | 6265/10000 [00:23<00:14, 266.62it/s]Running 10000 simulations.:  63%|██████▎   | 6292/10000 [00:23<00:13, 266.82it/s]Running 10000 simulations.:  63%|██████▎   | 6319/10000 [00:23<00:13, 267.36it/s]Running 10000 simulations.:  63%|██████▎   | 6346/10000 [00:23<00:13, 267.30it/s]Running 10000 simulations.:  64%|██████▎   | 6373/10000 [00:23<00:13, 267.28it/s]Running 10000 simulations.:  64%|██████▍   | 6400/10000 [00:23<00:13, 266.60it/s]Running 10000 simulations.:  64%|██████▍   | 6427/10000 [00:24<00:13, 266.11it/s]Running 10000 simulations.:  65%|██████▍   | 6454/10000 [00:24<00:13, 265.61it/s]Running 10000 simulations.:  65%|██████▍   | 6481/10000 [00:24<00:13, 266.44it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:24<00:13, 265.76it/s]Running 10000 simulations.:  65%|██████▌   | 6535/10000 [00:24<00:13, 266.25it/s]Running 10000 simulations.:  66%|██████▌   | 6562/10000 [00:24<00:12, 266.59it/s]Running 10000 simulations.:  66%|██████▌   | 6589/10000 [00:24<00:12, 266.60it/s]Running 10000 simulations.:  66%|██████▌   | 6616/10000 [00:24<00:12, 266.39it/s]Running 10000 simulations.:  66%|██████▋   | 6643/10000 [00:24<00:12, 265.85it/s]Running 10000 simulations.:  67%|██████▋   | 6670/10000 [00:24<00:12, 265.36it/s]Running 10000 simulations.:  67%|██████▋   | 6697/10000 [00:25<00:12, 265.62it/s]Running 10000 simulations.:  67%|██████▋   | 6724/10000 [00:25<00:12, 266.02it/s]Running 10000 simulations.:  68%|██████▊   | 6751/10000 [00:25<00:12, 266.23it/s]Running 10000 simulations.:  68%|██████▊   | 6778/10000 [00:25<00:12, 266.36it/s]Running 10000 simulations.:  68%|██████▊   | 6805/10000 [00:25<00:11, 266.74it/s]Running 10000 simulations.:  68%|██████▊   | 6832/10000 [00:25<00:11, 266.08it/s]Running 10000 simulations.:  69%|██████▊   | 6859/10000 [00:25<00:11, 267.01it/s]Running 10000 simulations.:  69%|██████▉   | 6886/10000 [00:25<00:11, 266.57it/s]Running 10000 simulations.:  69%|██████▉   | 6913/10000 [00:25<00:11, 266.76it/s]Running 10000 simulations.:  69%|██████▉   | 6940/10000 [00:25<00:11, 265.90it/s]Running 10000 simulations.:  70%|██████▉   | 6967/10000 [00:26<00:11, 265.64it/s]Running 10000 simulations.:  70%|██████▉   | 6994/10000 [00:26<00:11, 265.28it/s]Running 10000 simulations.:  70%|███████   | 7021/10000 [00:26<00:11, 266.31it/s]Running 10000 simulations.:  70%|███████   | 7048/10000 [00:26<00:11, 266.01it/s]Running 10000 simulations.:  71%|███████   | 7075/10000 [00:26<00:11, 261.84it/s]Running 10000 simulations.:  71%|███████   | 7102/10000 [00:26<00:11, 261.74it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:26<00:10, 263.58it/s]Running 10000 simulations.:  72%|███████▏  | 7156/10000 [00:26<00:10, 264.31it/s]Running 10000 simulations.:  72%|███████▏  | 7183/10000 [00:26<00:10, 265.15it/s]Running 10000 simulations.:  72%|███████▏  | 7210/10000 [00:26<00:10, 264.38it/s]Running 10000 simulations.:  72%|███████▏  | 7237/10000 [00:27<00:10, 264.07it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:27<00:10, 264.85it/s]Running 10000 simulations.:  73%|███████▎  | 7291/10000 [00:27<00:10, 265.10it/s]Running 10000 simulations.:  73%|███████▎  | 7318/10000 [00:27<00:10, 264.71it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:27<00:09, 265.85it/s]Running 10000 simulations.:  74%|███████▎  | 7372/10000 [00:27<00:09, 265.85it/s]Running 10000 simulations.:  74%|███████▍  | 7399/10000 [00:27<00:09, 265.52it/s]Running 10000 simulations.:  74%|███████▍  | 7426/10000 [00:27<00:09, 265.10it/s]Running 10000 simulations.:  75%|███████▍  | 7453/10000 [00:27<00:09, 264.67it/s]Running 10000 simulations.:  75%|███████▍  | 7480/10000 [00:27<00:09, 264.44it/s]Running 10000 simulations.:  75%|███████▌  | 7507/10000 [00:28<00:09, 263.56it/s]Running 10000 simulations.:  75%|███████▌  | 7534/10000 [00:28<00:09, 263.00it/s]Running 10000 simulations.:  76%|███████▌  | 7561/10000 [00:28<00:09, 262.77it/s]Running 10000 simulations.:  76%|███████▌  | 7588/10000 [00:28<00:09, 263.49it/s]Running 10000 simulations.:  76%|███████▌  | 7615/10000 [00:28<00:09, 263.68it/s]Running 10000 simulations.:  76%|███████▋  | 7642/10000 [00:28<00:08, 265.21it/s]Running 10000 simulations.:  77%|███████▋  | 7669/10000 [00:28<00:08, 265.66it/s]Running 10000 simulations.:  77%|███████▋  | 7696/10000 [00:28<00:08, 265.71it/s]Running 10000 simulations.:  77%|███████▋  | 7723/10000 [00:28<00:08, 265.85it/s]Running 10000 simulations.:  78%|███████▊  | 7750/10000 [00:29<00:08, 266.18it/s]Running 10000 simulations.:  78%|███████▊  | 7777/10000 [00:29<00:08, 266.25it/s]Running 10000 simulations.:  78%|███████▊  | 7804/10000 [00:29<00:08, 266.31it/s]Running 10000 simulations.:  78%|███████▊  | 7831/10000 [00:29<00:08, 266.16it/s]Running 10000 simulations.:  79%|███████▊  | 7858/10000 [00:29<00:08, 265.97it/s]Running 10000 simulations.:  79%|███████▉  | 7885/10000 [00:29<00:07, 266.30it/s]Running 10000 simulations.:  79%|███████▉  | 7912/10000 [00:29<00:07, 266.15it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:29<00:07, 266.69it/s]Running 10000 simulations.:  80%|███████▉  | 7966/10000 [00:29<00:07, 267.10it/s]Running 10000 simulations.:  80%|███████▉  | 7993/10000 [00:29<00:07, 267.41it/s]Running 10000 simulations.:  80%|████████  | 8020/10000 [00:30<00:07, 267.58it/s]Running 10000 simulations.:  80%|████████  | 8047/10000 [00:30<00:07, 265.77it/s]Running 10000 simulations.:  81%|████████  | 8074/10000 [00:30<00:07, 260.19it/s]Running 10000 simulations.:  81%|████████  | 8101/10000 [00:30<00:07, 261.24it/s]Running 10000 simulations.:  81%|████████▏ | 8128/10000 [00:30<00:07, 263.17it/s]Running 10000 simulations.:  82%|████████▏ | 8155/10000 [00:30<00:06, 264.57it/s]Running 10000 simulations.:  82%|████████▏ | 8182/10000 [00:30<00:06, 264.72it/s]Running 10000 simulations.:  82%|████████▏ | 8209/10000 [00:30<00:06, 265.35it/s]Running 10000 simulations.:  82%|████████▏ | 8236/10000 [00:30<00:06, 265.81it/s]Running 10000 simulations.:  83%|████████▎ | 8263/10000 [00:30<00:06, 266.18it/s]Running 10000 simulations.:  83%|████████▎ | 8290/10000 [00:31<00:06, 266.47it/s]Running 10000 simulations.:  83%|████████▎ | 8317/10000 [00:31<00:06, 265.65it/s]Running 10000 simulations.:  83%|████████▎ | 8344/10000 [00:31<00:06, 265.86it/s]Running 10000 simulations.:  84%|████████▎ | 8371/10000 [00:31<00:06, 265.61it/s]Running 10000 simulations.:  84%|████████▍ | 8398/10000 [00:31<00:06, 265.25it/s]Running 10000 simulations.:  84%|████████▍ | 8425/10000 [00:31<00:05, 265.42it/s]Running 10000 simulations.:  85%|████████▍ | 8452/10000 [00:31<00:05, 265.26it/s]Running 10000 simulations.:  85%|████████▍ | 8479/10000 [00:31<00:05, 265.33it/s]Running 10000 simulations.:  85%|████████▌ | 8506/10000 [00:31<00:05, 264.55it/s]Running 10000 simulations.:  85%|████████▌ | 8533/10000 [00:31<00:05, 264.12it/s]Running 10000 simulations.:  86%|████████▌ | 8560/10000 [00:32<00:05, 264.11it/s]Running 10000 simulations.:  86%|████████▌ | 8587/10000 [00:32<00:05, 264.01it/s]Running 10000 simulations.:  86%|████████▌ | 8614/10000 [00:32<00:05, 264.24it/s]Running 10000 simulations.:  86%|████████▋ | 8641/10000 [00:32<00:05, 264.50it/s]Running 10000 simulations.:  87%|████████▋ | 8668/10000 [00:32<00:05, 264.46it/s]Running 10000 simulations.:  87%|████████▋ | 8695/10000 [00:32<00:04, 264.68it/s]Running 10000 simulations.:  87%|████████▋ | 8722/10000 [00:32<00:04, 264.66it/s]Running 10000 simulations.:  87%|████████▋ | 8749/10000 [00:32<00:04, 265.73it/s]Running 10000 simulations.:  88%|████████▊ | 8776/10000 [00:32<00:04, 265.22it/s]Running 10000 simulations.:  88%|████████▊ | 8803/10000 [00:32<00:04, 265.34it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [00:33<00:04, 265.66it/s]Running 10000 simulations.:  89%|████████▊ | 8857/10000 [00:33<00:04, 265.53it/s]Running 10000 simulations.:  89%|████████▉ | 8884/10000 [00:33<00:04, 265.38it/s]Running 10000 simulations.:  89%|████████▉ | 8911/10000 [00:33<00:04, 265.31it/s]Running 10000 simulations.:  89%|████████▉ | 8938/10000 [00:33<00:04, 265.16it/s]Running 10000 simulations.:  90%|████████▉ | 8965/10000 [00:33<00:03, 265.62it/s]Running 10000 simulations.:  90%|████████▉ | 8992/10000 [00:33<00:03, 265.50it/s]Running 10000 simulations.:  90%|█████████ | 9019/10000 [00:33<00:03, 265.08it/s]Running 10000 simulations.:  90%|█████████ | 9046/10000 [00:33<00:03, 265.81it/s]Running 10000 simulations.:  91%|█████████ | 9073/10000 [00:34<00:03, 266.22it/s]Running 10000 simulations.:  91%|█████████ | 9100/10000 [00:34<00:03, 265.88it/s]Running 10000 simulations.:  91%|█████████▏| 9127/10000 [00:34<00:03, 265.67it/s]Running 10000 simulations.:  92%|█████████▏| 9154/10000 [00:34<00:03, 265.73it/s]Running 10000 simulations.:  92%|█████████▏| 9181/10000 [00:34<00:03, 266.15it/s]Running 10000 simulations.:  92%|█████████▏| 9208/10000 [00:34<00:02, 266.21it/s]Running 10000 simulations.:  92%|█████████▏| 9235/10000 [00:34<00:02, 266.49it/s]Running 10000 simulations.:  93%|█████████▎| 9262/10000 [00:34<00:02, 267.07it/s]Running 10000 simulations.:  93%|█████████▎| 9289/10000 [00:34<00:02, 267.72it/s]Running 10000 simulations.:  93%|█████████▎| 9316/10000 [00:34<00:02, 267.25it/s]Running 10000 simulations.:  93%|█████████▎| 9343/10000 [00:35<00:02, 267.08it/s]Running 10000 simulations.:  94%|█████████▎| 9370/10000 [00:35<00:02, 266.79it/s]Running 10000 simulations.:  94%|█████████▍| 9397/10000 [00:35<00:02, 267.07it/s]Running 10000 simulations.:  94%|█████████▍| 9424/10000 [00:35<00:02, 267.67it/s]Running 10000 simulations.:  95%|█████████▍| 9452/10000 [00:35<00:02, 268.86it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [00:35<00:01, 268.55it/s]Running 10000 simulations.:  95%|█████████▌| 9506/10000 [00:35<00:01, 268.02it/s]Running 10000 simulations.:  95%|█████████▌| 9533/10000 [00:35<00:01, 267.57it/s]Running 10000 simulations.:  96%|█████████▌| 9560/10000 [00:35<00:01, 268.29it/s]Running 10000 simulations.:  96%|█████████▌| 9587/10000 [00:35<00:01, 268.47it/s]Running 10000 simulations.:  96%|█████████▌| 9614/10000 [00:36<00:01, 268.88it/s]Running 10000 simulations.:  96%|█████████▋| 9641/10000 [00:36<00:01, 267.86it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [00:36<00:01, 268.25it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:36<00:01, 268.18it/s]Running 10000 simulations.:  97%|█████████▋| 9722/10000 [00:36<00:01, 267.94it/s]Running 10000 simulations.:  98%|█████████▊| 9750/10000 [00:36<00:00, 268.85it/s]Running 10000 simulations.:  98%|█████████▊| 9777/10000 [00:36<00:00, 268.94it/s]Running 10000 simulations.:  98%|█████████▊| 9805/10000 [00:36<00:00, 270.21it/s]Running 10000 simulations.:  98%|█████████▊| 9833/10000 [00:36<00:00, 269.62it/s]Running 10000 simulations.:  99%|█████████▊| 9861/10000 [00:36<00:00, 270.23it/s]Running 10000 simulations.:  99%|█████████▉| 9889/10000 [00:37<00:00, 269.50it/s]Running 10000 simulations.:  99%|█████████▉| 9916/10000 [00:37<00:00, 268.76it/s]Running 10000 simulations.:  99%|█████████▉| 9943/10000 [00:37<00:00, 268.27it/s]Running 10000 simulations.: 100%|█████████▉| 9970/10000 [00:37<00:00, 268.30it/s]Running 10000 simulations.: 100%|█████████▉| 9997/10000 [00:37<00:00, 268.75it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:37<00:00, 266.95it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18364/50000 [00:00<00:00, 141284.99it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36751/50000 [00:00<00:00, 143802.84it/s]Drawing 50000 posterior samples: 55103it [00:00, 145338.35it/s]                           Drawing 50000 posterior samples: 55103it [00:00, 146502.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▍      | 17402/50000 [00:00<00:00, 141909.44it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34804/50000 [00:00<00:00, 142401.57it/s]Drawing 50000 posterior samples: 52278it [00:00, 142653.95it/s]                           Drawing 50000 posterior samples: 52278it [00:00, 142726.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18337/50000 [00:00<00:00, 143421.55it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36736/50000 [00:00<00:00, 145271.59it/s]Drawing 50000 posterior samples: 55118it [00:00, 146544.52it/s]                           Drawing 50000 posterior samples: 55118it [00:00, 147369.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18392/50000 [00:00<00:00, 150202.87it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36732/50000 [00:00<00:00, 150259.37it/s]Drawing 50000 posterior samples: 55092it [00:00, 150458.03it/s]                           Drawing 50000 posterior samples: 55092it [00:00, 150315.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▌      | 17669/50000 [00:00<00:00, 141446.97it/s]Drawing 50000 posterior samples:  71%|███████   | 35381/50000 [00:00<00:00, 141816.92it/s]Drawing 50000 posterior samples: 53046it [00:00, 142650.54it/s]                           Drawing 50000 posterior samples: 53046it [00:00, 142738.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18348/50000 [00:00<00:00, 150317.39it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36676/50000 [00:00<00:00, 150112.20it/s]Drawing 50000 posterior samples: 55020it [00:00, 150108.69it/s]                           Drawing 50000 posterior samples: 55020it [00:00, 149841.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18313/50000 [00:00<00:00, 149795.99it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36688/50000 [00:00<00:00, 148587.71it/s]Drawing 50000 posterior samples: 55007it [00:00, 148892.98it/s]                           Drawing 50000 posterior samples: 55007it [00:00, 148143.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18347/50000 [00:00<00:00, 152198.43it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36729/50000 [00:00<00:00, 151728.44it/s]Drawing 50000 posterior samples: 55066it [00:00, 151150.89it/s]                           Drawing 50000 posterior samples: 55066it [00:00, 150672.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18334/50000 [00:00<00:00, 152272.49it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36642/50000 [00:00<00:00, 152075.80it/s]Drawing 50000 posterior samples: 55047it [00:00, 152552.68it/s]                           Drawing 50000 posterior samples: 55047it [00:00, 152292.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18408/50000 [00:00<00:00, 149104.60it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36783/50000 [00:00<00:00, 148976.00it/s]Drawing 50000 posterior samples: 55133it [00:00, 148862.33it/s]                           Drawing 50000 posterior samples: 55133it [00:00, 148587.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18345/50000 [00:00<00:00, 147841.13it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36724/50000 [00:00<00:00, 147851.64it/s]Drawing 50000 posterior samples: 55097it [00:00, 148104.94it/s]                           Drawing 50000 posterior samples: 55097it [00:00, 147923.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18345/50000 [00:00<00:00, 139607.70it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36711/50000 [00:00<00:00, 142824.40it/s]Drawing 50000 posterior samples: 55083it [00:00, 145231.12it/s]                           Drawing 50000 posterior samples: 55083it [00:00, 146854.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18409/50000 [00:00<00:00, 139763.82it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36798/50000 [00:00<00:00, 142880.28it/s]Drawing 50000 posterior samples: 55153it [00:00, 145517.16it/s]                           Drawing 50000 posterior samples: 55153it [00:00, 147090.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18407/50000 [00:00<00:00, 143866.30it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36770/50000 [00:00<00:00, 145979.61it/s]Drawing 50000 posterior samples: 55176it [00:00, 148280.56it/s]                           Drawing 50000 posterior samples: 55176it [00:00, 149251.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18302/50000 [00:00<00:00, 152085.02it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36734/50000 [00:00<00:00, 152509.06it/s]Drawing 50000 posterior samples: 55057it [00:00, 152865.72it/s]                           Drawing 50000 posterior samples: 55057it [00:00, 152815.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18340/50000 [00:00<00:00, 152567.94it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36689/50000 [00:00<00:00, 151338.35it/s]Drawing 50000 posterior samples: 54975it [00:00, 151846.83it/s]                           Drawing 50000 posterior samples: 54975it [00:00, 151147.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18416/50000 [00:00<00:00, 145156.55it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36749/50000 [00:00<00:00, 147389.01it/s]Drawing 50000 posterior samples: 55108it [00:00, 148882.62it/s]                           Drawing 50000 posterior samples: 55108it [00:00, 149868.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18277/50000 [00:00<00:00, 141185.66it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36612/50000 [00:00<00:00, 144648.52it/s]Drawing 50000 posterior samples: 54959it [00:00, 146806.18it/s]                           Drawing 50000 posterior samples: 54959it [00:00, 148515.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18373/50000 [00:00<00:00, 142465.91it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36723/50000 [00:00<00:00, 145585.55it/s]Drawing 50000 posterior samples: 55127it [00:00, 147986.50it/s]                           Drawing 50000 posterior samples: 55127it [00:00, 149567.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18386/50000 [00:00<00:00, 139535.91it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36706/50000 [00:00<00:00, 142700.58it/s]Drawing 50000 posterior samples: 55054it [00:00, 145316.62it/s]                           Drawing 50000 posterior samples: 55054it [00:00, 146923.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18343/50000 [00:00<00:00, 139685.50it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36645/50000 [00:00<00:00, 139082.57it/s]Drawing 50000 posterior samples: 54971it [00:00, 138894.90it/s]                           Drawing 50000 posterior samples: 54971it [00:00, 138426.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18395/50000 [00:00<00:00, 129015.26it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36771/50000 [00:00<00:00, 133356.19it/s]Drawing 50000 posterior samples: 55147it [00:00, 132941.73it/s]                           Drawing 50000 posterior samples: 55147it [00:00, 134747.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18355/50000 [00:00<00:00, 139753.79it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36713/50000 [00:00<00:00, 136047.51it/s]Drawing 50000 posterior samples: 55049it [00:00, 140183.08it/s]                           Drawing 50000 posterior samples: 55049it [00:00, 138785.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18325/50000 [00:00<00:00, 128792.87it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36665/50000 [00:00<00:00, 131410.50it/s]Drawing 50000 posterior samples: 55003it [00:00, 134163.72it/s]                           Drawing 50000 posterior samples: 55003it [00:00, 135578.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18301/50000 [00:00<00:00, 135186.94it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36660/50000 [00:00<00:00, 135376.85it/s]Drawing 50000 posterior samples: 55024it [00:00, 133792.98it/s]                           Drawing 50000 posterior samples: 55024it [00:00, 133548.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18427/50000 [00:00<00:00, 131179.45it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36764/50000 [00:00<00:00, 130347.04it/s]Drawing 50000 posterior samples: 55178it [00:00, 135507.73it/s]                           Drawing 50000 posterior samples: 55178it [00:00, 135563.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18355/50000 [00:00<00:00, 136004.53it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36706/50000 [00:00<00:00, 140457.03it/s]Drawing 50000 posterior samples: 55051it [00:00, 143532.38it/s]                           Drawing 50000 posterior samples: 55051it [00:00, 145896.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18326/50000 [00:00<00:00, 147089.14it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36746/50000 [00:00<00:00, 148084.25it/s]Drawing 50000 posterior samples: 55106it [00:00, 148347.19it/s]                           Drawing 50000 posterior samples: 55106it [00:00, 148609.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18379/50000 [00:00<00:00, 137954.63it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36761/50000 [00:00<00:00, 141838.65it/s]Drawing 50000 posterior samples: 55157it [00:00, 141950.30it/s]                           Drawing 50000 posterior samples: 55157it [00:00, 143583.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18347/50000 [00:00<00:00, 140100.56it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36746/50000 [00:00<00:00, 143317.70it/s]Drawing 50000 posterior samples: 55130it [00:00, 146033.08it/s]                           Drawing 50000 posterior samples: 55130it [00:00, 147707.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18330/50000 [00:00<00:00, 138007.92it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36622/50000 [00:00<00:00, 141786.56it/s]Drawing 50000 posterior samples: 54987it [00:00, 144510.96it/s]                           Drawing 50000 posterior samples: 54987it [00:00, 146433.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▋      | 18245/50000 [00:00<00:00, 138710.03it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36588/50000 [00:00<00:00, 142329.32it/s]Drawing 50000 posterior samples: 54899it [00:00, 144943.35it/s]                           Drawing 50000 posterior samples: 54899it [00:00, 146806.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18321/50000 [00:00<00:00, 140275.91it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36692/50000 [00:00<00:00, 137482.12it/s]Drawing 50000 posterior samples: 55017it [00:00, 135571.42it/s]                           Drawing 50000 posterior samples: 55017it [00:00, 133983.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18310/50000 [00:00<00:00, 132511.96it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36590/50000 [00:00<00:00, 131042.23it/s]Drawing 50000 posterior samples: 54888it [00:00, 131727.85it/s]                           Drawing 50000 posterior samples: 54888it [00:00, 131011.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  33%|███▎      | 16518/50000 [00:00<00:00, 125986.32it/s]Drawing 50000 posterior samples:  66%|██████▌   | 33007/50000 [00:00<00:00, 125902.55it/s]Drawing 50000 posterior samples:  99%|█████████▉| 49569/50000 [00:00<00:00, 128957.50it/s]Drawing 50000 posterior samples: 57866it [00:00, 127645.64it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18274/50000 [00:00<00:00, 139002.82it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36628/50000 [00:00<00:00, 137917.52it/s]Drawing 50000 posterior samples: 54916it [00:00, 136281.31it/s]                           Drawing 50000 posterior samples: 54916it [00:00, 135454.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18381/50000 [00:00<00:00, 131802.73it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36734/50000 [00:00<00:00, 134480.88it/s]Drawing 50000 posterior samples: 55043it [00:00, 132924.41it/s]                           Drawing 50000 posterior samples: 55043it [00:00, 133774.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18283/50000 [00:00<00:00, 151612.04it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36571/50000 [00:00<00:00, 151555.09it/s]Drawing 50000 posterior samples: 54877it [00:00, 150914.13it/s]                           Drawing 50000 posterior samples: 54877it [00:00, 150580.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18312/50000 [00:00<00:00, 150747.39it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36651/50000 [00:00<00:00, 150574.86it/s]Drawing 50000 posterior samples: 54945it [00:00, 150544.67it/s]                           Drawing 50000 posterior samples: 54945it [00:00, 150256.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▋      | 18227/50000 [00:00<00:00, 150768.50it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36560/50000 [00:00<00:00, 150777.98it/s]Drawing 50000 posterior samples: 54903it [00:00, 150950.06it/s]                           Drawing 50000 posterior samples: 54903it [00:00, 150741.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18276/50000 [00:00<00:00, 150479.68it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36560/50000 [00:00<00:00, 150475.51it/s]Drawing 50000 posterior samples: 54882it [00:00, 150697.82it/s]                           Drawing 50000 posterior samples: 54882it [00:00, 150514.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18375/50000 [00:00<00:00, 151390.21it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36717/50000 [00:00<00:00, 151222.53it/s]Drawing 50000 posterior samples: 55114it [00:00, 151422.28it/s]                           Drawing 50000 posterior samples: 55114it [00:00, 151197.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18313/50000 [00:00<00:00, 151134.42it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36646/50000 [00:00<00:00, 150967.25it/s]Drawing 50000 posterior samples: 54963it [00:00, 150790.08it/s]                           Drawing 50000 posterior samples: 54963it [00:00, 150486.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18332/50000 [00:00<00:00, 150284.94it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36653/50000 [00:00<00:00, 150396.29it/s]Drawing 50000 posterior samples: 54930it [00:00, 150241.40it/s]                           Drawing 50000 posterior samples: 54930it [00:00, 150059.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18344/50000 [00:00<00:00, 151128.87it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36639/50000 [00:00<00:00, 151216.62it/s]Drawing 50000 posterior samples: 54975it [00:00, 151713.89it/s]                           Drawing 50000 posterior samples: 54975it [00:00, 151599.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18295/50000 [00:00<00:00, 151131.28it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36597/50000 [00:00<00:00, 150245.59it/s]Drawing 50000 posterior samples: 55001it [00:00, 149862.13it/s]                           Drawing 50000 posterior samples: 55001it [00:00, 149211.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18313/50000 [00:00<00:00, 133092.18it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36629/50000 [00:00<00:00, 138863.78it/s]Drawing 50000 posterior samples: 54889it [00:00, 142690.36it/s]                           Drawing 50000 posterior samples: 54889it [00:00, 145812.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18303/50000 [00:00<00:00, 154694.43it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36588/50000 [00:00<00:00, 154860.00it/s]Drawing 50000 posterior samples: 54895it [00:00, 154327.28it/s]                           Drawing 50000 posterior samples: 54895it [00:00, 154120.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18345/50000 [00:00<00:00, 152920.42it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36662/50000 [00:00<00:00, 153092.01it/s]Drawing 50000 posterior samples: 55027it [00:00, 153094.74it/s]                           Drawing 50000 posterior samples: 55027it [00:00, 152957.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18336/50000 [00:00<00:00, 152473.58it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36687/50000 [00:00<00:00, 152149.48it/s]Drawing 50000 posterior samples: 54988it [00:00, 151760.85it/s]                           Drawing 50000 posterior samples: 54988it [00:00, 151351.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18318/50000 [00:00<00:00, 151924.81it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36646/50000 [00:00<00:00, 151732.39it/s]Drawing 50000 posterior samples: 54979it [00:00, 151672.41it/s]                           Drawing 50000 posterior samples: 54979it [00:00, 151354.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18284/50000 [00:00<00:00, 150268.85it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36524/50000 [00:00<00:00, 150515.40it/s]Drawing 50000 posterior samples: 54817it [00:00, 150345.86it/s]                           Drawing 50000 posterior samples: 54817it [00:00, 150221.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18359/50000 [00:00<00:00, 154288.18it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36693/50000 [00:00<00:00, 154006.88it/s]Drawing 50000 posterior samples: 55021it [00:00, 153618.86it/s]                           Drawing 50000 posterior samples: 55021it [00:00, 153229.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18319/50000 [00:00<00:00, 149988.10it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36687/50000 [00:00<00:00, 150044.82it/s]Drawing 50000 posterior samples: 55004it [00:00, 149651.26it/s]                           Drawing 50000 posterior samples: 55004it [00:00, 149421.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18310/50000 [00:00<00:00, 150256.71it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36644/50000 [00:00<00:00, 150122.94it/s]Drawing 50000 posterior samples: 55012it [00:00, 149854.34it/s]                           Drawing 50000 posterior samples: 55012it [00:00, 149544.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18305/50000 [00:00<00:00, 154195.54it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36594/50000 [00:00<00:00, 154077.43it/s]Drawing 50000 posterior samples: 54927it [00:00, 153479.20it/s]                           Drawing 50000 posterior samples: 54927it [00:00, 153129.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18310/50000 [00:00<00:00, 152405.13it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36642/50000 [00:00<00:00, 152041.36it/s]Drawing 50000 posterior samples: 54902it [00:00, 151795.94it/s]                           Drawing 50000 posterior samples: 54902it [00:00, 151395.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18376/50000 [00:00<00:00, 152540.67it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36609/50000 [00:00<00:00, 152647.09it/s]Drawing 50000 posterior samples: 54901it [00:00, 152292.18it/s]                           Drawing 50000 posterior samples: 54901it [00:00, 152092.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▋      | 18250/50000 [00:00<00:00, 152486.12it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36598/50000 [00:00<00:00, 152243.27it/s]Drawing 50000 posterior samples: 54888it [00:00, 151622.99it/s]                           Drawing 50000 posterior samples: 54888it [00:00, 151229.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18276/50000 [00:00<00:00, 150518.38it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36584/50000 [00:00<00:00, 150663.92it/s]Drawing 50000 posterior samples: 54922it [00:00, 150636.40it/s]                           Drawing 50000 posterior samples: 54922it [00:00, 150448.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165453.82it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165120.17it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164878.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19756/50000 [00:00<00:00, 163642.50it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39501/50000 [00:00<00:00, 163353.94it/s]Drawing 50000 posterior samples: 59235it [00:00, 163446.51it/s]                           Drawing 50000 posterior samples: 59235it [00:00, 163086.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164195.97it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 160869.88it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 160179.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167590.49it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167669.58it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167197.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▍      | 17436/50000 [00:00<00:00, 145209.26it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34822/50000 [00:00<00:00, 144995.90it/s]Drawing 50000 posterior samples: 52318it [00:00, 145190.89it/s]                           Drawing 50000 posterior samples: 52318it [00:00, 144898.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▌      | 17734/50000 [00:00<00:00, 146037.92it/s]Drawing 50000 posterior samples:  71%|███████   | 35337/50000 [00:00<00:00, 145864.52it/s]Drawing 50000 posterior samples: 53041it [00:00, 145756.28it/s]                           Drawing 50000 posterior samples: 53041it [00:00, 145468.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165283.32it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165473.66it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165316.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166608.23it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166395.87it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165795.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166982.33it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167015.95it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166436.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163955.60it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164825.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165254.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19994/50000 [00:00<00:00, 164700.88it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39993/50000 [00:00<00:00, 164671.53it/s]Drawing 50000 posterior samples: 59992it [00:00, 164986.94it/s]                           Drawing 50000 posterior samples: 59992it [00:00, 164773.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164276.36it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 155333.43it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 152273.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164735.43it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164476.90it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164441.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 159586.34it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 159337.99it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 158152.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 162015.11it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 162078.97it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161878.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19811/50000 [00:00<00:00, 165660.91it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39603/50000 [00:00<00:00, 164706.00it/s]Drawing 50000 posterior samples: 59404it [00:00, 164045.00it/s]                           Drawing 50000 posterior samples: 59404it [00:00, 163327.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19999/50000 [00:00<00:00, 165565.39it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39999/50000 [00:00<00:00, 164909.94it/s]Drawing 50000 posterior samples: 59999it [00:00, 164367.10it/s]                           Drawing 50000 posterior samples: 59999it [00:00, 163801.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163598.12it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163310.42it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161437.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19910/50000 [00:00<00:00, 166786.35it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39816/50000 [00:00<00:00, 166130.59it/s]Drawing 50000 posterior samples: 59708it [00:00, 165505.36it/s]                           Drawing 50000 posterior samples: 59708it [00:00, 164907.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166364.05it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166429.21it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166521.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166223.29it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165809.70it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165205.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165311.34it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164963.07it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163943.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163887.69it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163869.54it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163501.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 156070.90it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 156239.29it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 156228.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168964.71it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168910.92it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168175.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167023.89it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167663.35it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168154.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164928.79it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165495.34it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165969.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165545.57it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165833.24it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165491.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167819.49it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167817.57it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166726.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18590/50000 [00:00<00:00, 151043.76it/s]Drawing 50000 posterior samples:  74%|███████▍  | 37124/50000 [00:00<00:00, 151743.85it/s]Drawing 50000 posterior samples: 55713it [00:00, 152298.43it/s]                           Drawing 50000 posterior samples: 55713it [00:00, 152434.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18323/50000 [00:00<00:00, 150957.64it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36665/50000 [00:00<00:00, 151009.28it/s]Drawing 50000 posterior samples: 54988it [00:00, 151087.38it/s]                           Drawing 50000 posterior samples: 54988it [00:00, 150916.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18380/50000 [00:00<00:00, 151611.88it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36659/50000 [00:00<00:00, 151637.78it/s]Drawing 50000 posterior samples: 54974it [00:00, 151755.71it/s]                           Drawing 50000 posterior samples: 54974it [00:00, 151556.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18435/50000 [00:00<00:00, 155386.11it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36804/50000 [00:00<00:00, 155170.97it/s]Drawing 50000 posterior samples: 55085it [00:00, 154838.97it/s]                           Drawing 50000 posterior samples: 55085it [00:00, 154496.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18357/50000 [00:00<00:00, 152104.49it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36751/50000 [00:00<00:00, 152143.48it/s]Drawing 50000 posterior samples: 55118it [00:00, 152332.65it/s]                           Drawing 50000 posterior samples: 55118it [00:00, 152126.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▌      | 17604/50000 [00:00<00:00, 148099.28it/s]Drawing 50000 posterior samples:  71%|███████   | 35259/50000 [00:00<00:00, 147935.91it/s]Drawing 50000 posterior samples: 52855it [00:00, 147800.88it/s]                           Drawing 50000 posterior samples: 52855it [00:00, 147474.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18394/50000 [00:00<00:00, 150672.47it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36779/50000 [00:00<00:00, 150865.12it/s]Drawing 50000 posterior samples: 55207it [00:00, 151588.58it/s]                           Drawing 50000 posterior samples: 55207it [00:00, 151536.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18371/50000 [00:00<00:00, 156454.24it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36654/50000 [00:00<00:00, 156173.58it/s]Drawing 50000 posterior samples: 55042it [00:00, 156077.12it/s]                           Drawing 50000 posterior samples: 55042it [00:00, 155677.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18367/50000 [00:00<00:00, 154753.55it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36719/50000 [00:00<00:00, 154104.45it/s]Drawing 50000 posterior samples: 55106it [00:00, 153992.76it/s]                           Drawing 50000 posterior samples: 55106it [00:00, 153471.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18411/50000 [00:00<00:00, 157391.87it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36782/50000 [00:00<00:00, 157332.20it/s]Drawing 50000 posterior samples: 55150it [00:00, 157217.94it/s]                           Drawing 50000 posterior samples: 55150it [00:00, 156920.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18340/50000 [00:00<00:00, 154742.72it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36706/50000 [00:00<00:00, 154606.11it/s]Drawing 50000 posterior samples: 55097it [00:00, 154810.51it/s]                           Drawing 50000 posterior samples: 55097it [00:00, 154525.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18376/50000 [00:00<00:00, 150961.95it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36696/50000 [00:00<00:00, 150897.75it/s]Drawing 50000 posterior samples: 55068it [00:00, 150902.27it/s]                           Drawing 50000 posterior samples: 55068it [00:00, 150663.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18273/50000 [00:00<00:00, 155153.71it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36673/50000 [00:00<00:00, 155225.25it/s]Drawing 50000 posterior samples: 55053it [00:00, 155423.30it/s]                           Drawing 50000 posterior samples: 55053it [00:00, 155228.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18322/50000 [00:00<00:00, 156019.20it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36725/50000 [00:00<00:00, 156191.82it/s]Drawing 50000 posterior samples: 55156it [00:00, 155831.07it/s]                           Drawing 50000 posterior samples: 55156it [00:00, 155644.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18336/50000 [00:00<00:00, 152358.19it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36719/50000 [00:00<00:00, 152029.86it/s]Drawing 50000 posterior samples: 55042it [00:00, 151686.39it/s]                           Drawing 50000 posterior samples: 55042it [00:00, 151248.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18359/50000 [00:00<00:00, 156221.99it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36690/50000 [00:00<00:00, 156194.69it/s]Drawing 50000 posterior samples: 55016it [00:00, 155770.50it/s]                           Drawing 50000 posterior samples: 55016it [00:00, 155438.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18377/50000 [00:00<00:00, 154592.47it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36788/50000 [00:00<00:00, 154281.18it/s]Drawing 50000 posterior samples: 55152it [00:00, 154009.52it/s]                           Drawing 50000 posterior samples: 55152it [00:00, 153620.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18301/50000 [00:00<00:00, 154664.12it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36641/50000 [00:00<00:00, 154396.62it/s]Drawing 50000 posterior samples: 54983it [00:00, 153895.04it/s]                           Drawing 50000 posterior samples: 54983it [00:00, 153477.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18398/50000 [00:00<00:00, 155875.22it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36699/50000 [00:00<00:00, 155184.13it/s]Drawing 50000 posterior samples: 55141it [00:00, 155141.44it/s]                           Drawing 50000 posterior samples: 55141it [00:00, 154622.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18373/50000 [00:00<00:00, 155581.70it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36733/50000 [00:00<00:00, 155721.53it/s]Drawing 50000 posterior samples: 55102it [00:00, 155224.24it/s]                           Drawing 50000 posterior samples: 55102it [00:00, 154939.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18361/50000 [00:00<00:00, 157846.59it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36716/50000 [00:00<00:00, 157396.17it/s]Drawing 50000 posterior samples: 55110it [00:00, 156939.40it/s]                           Drawing 50000 posterior samples: 55110it [00:00, 156453.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18294/50000 [00:00<00:00, 155469.24it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36696/50000 [00:00<00:00, 155506.79it/s]Drawing 50000 posterior samples: 55077it [00:00, 155954.33it/s]                           Drawing 50000 posterior samples: 55077it [00:00, 155791.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18383/50000 [00:00<00:00, 155235.44it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36737/50000 [00:00<00:00, 154079.94it/s]Drawing 50000 posterior samples: 55074it [00:00, 152915.77it/s]                           Drawing 50000 posterior samples: 55074it [00:00, 152039.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18301/50000 [00:00<00:00, 153988.35it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36594/50000 [00:00<00:00, 153931.08it/s]Drawing 50000 posterior samples: 54930it [00:00, 154075.32it/s]                           Drawing 50000 posterior samples: 54930it [00:00, 153836.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18291/50000 [00:00<00:00, 153309.09it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36579/50000 [00:00<00:00, 153355.15it/s]Drawing 50000 posterior samples: 55003it [00:00, 151933.95it/s]                           Drawing 50000 posterior samples: 55003it [00:00, 151459.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18363/50000 [00:00<00:00, 151180.88it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36651/50000 [00:00<00:00, 150720.87it/s]Drawing 50000 posterior samples: 55021it [00:00, 150485.93it/s]                           Drawing 50000 posterior samples: 55021it [00:00, 150039.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18331/50000 [00:00<00:00, 151980.33it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36611/50000 [00:00<00:00, 152083.93it/s]Drawing 50000 posterior samples: 54953it [00:00, 152374.35it/s]                           Drawing 50000 posterior samples: 54953it [00:00, 152193.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18289/50000 [00:00<00:00, 151662.09it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36706/50000 [00:00<00:00, 151454.41it/s]Drawing 50000 posterior samples: 55052it [00:00, 151331.20it/s]                           Drawing 50000 posterior samples: 55052it [00:00, 150972.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18367/50000 [00:00<00:00, 151504.65it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36715/50000 [00:00<00:00, 151501.07it/s]Drawing 50000 posterior samples: 55060it [00:00, 151275.26it/s]                           Drawing 50000 posterior samples: 55060it [00:00, 151028.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18273/50000 [00:00<00:00, 152110.44it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36597/50000 [00:00<00:00, 152094.93it/s]Drawing 50000 posterior samples: 54970it [00:00, 152005.92it/s]                           Drawing 50000 posterior samples: 54970it [00:00, 151751.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18391/50000 [00:00<00:00, 152908.80it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36754/50000 [00:00<00:00, 152602.05it/s]Drawing 50000 posterior samples: 55153it [00:00, 152758.73it/s]                           Drawing 50000 posterior samples: 55153it [00:00, 152409.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166893.96it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166044.14it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165020.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19982/50000 [00:00<00:00, 166986.28it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39960/50000 [00:00<00:00, 166537.01it/s]Drawing 50000 posterior samples: 59937it [00:00, 166849.50it/s]                           Drawing 50000 posterior samples: 59937it [00:00, 166388.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165078.41it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165411.80it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165762.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168595.92it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168825.46it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168208.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 19185/50000 [00:00<00:00, 162202.90it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38437/50000 [00:00<00:00, 162295.96it/s]Drawing 50000 posterior samples: 57661it [00:00, 162537.35it/s]                           Drawing 50000 posterior samples: 57661it [00:00, 162369.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 19063/50000 [00:00<00:00, 156950.07it/s]Drawing 50000 posterior samples:  76%|███████▌  | 38027/50000 [00:00<00:00, 156434.77it/s]Drawing 50000 posterior samples: 57044it [00:00, 156078.71it/s]                           Drawing 50000 posterior samples: 57044it [00:00, 155541.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165119.35it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165144.12it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165044.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165582.50it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165949.83it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165819.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169562.40it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167933.75it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166366.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165934.27it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166358.08it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166583.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167723.86it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168178.31it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168186.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166271.06it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166702.96it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165994.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169160.97it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169196.49it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169077.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169334.78it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168651.10it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168057.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166583.75it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166693.39it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167146.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19971/50000 [00:00<00:00, 168696.61it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39951/50000 [00:00<00:00, 168415.46it/s]Drawing 50000 posterior samples: 59933it [00:00, 168007.48it/s]                           Drawing 50000 posterior samples: 59933it [00:00, 167541.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165934.27it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165927.67it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165807.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166445.59it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165084.00it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163863.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19886/50000 [00:00<00:00, 165452.20it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39760/50000 [00:00<00:00, 165554.70it/s]Drawing 50000 posterior samples: 59648it [00:00, 165624.97it/s]                           Drawing 50000 posterior samples: 59648it [00:00, 165427.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166567.87it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166506.48it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166482.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166222.63it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166024.26it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165565.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165799.48it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165767.63it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165978.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163522.54it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163191.38it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 162629.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163967.46it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163550.27it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 162965.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166902.60it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167065.74it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167252.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 150181.41it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 154623.33it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 159116.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168025.88it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168681.39it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168655.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168736.32it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169198.13it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161164.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169623.09it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170031.54it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 170049.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 18949/50000 [00:00<00:00, 160119.16it/s]Drawing 50000 posterior samples:  76%|███████▌  | 37972/50000 [00:00<00:00, 160769.53it/s]Drawing 50000 posterior samples: 56976it [00:00, 160275.21it/s]                           Drawing 50000 posterior samples: 56976it [00:00, 160276.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18340/50000 [00:00<00:00, 154563.94it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36662/50000 [00:00<00:00, 154954.34it/s]Drawing 50000 posterior samples: 54956it [00:00, 154748.55it/s]                           Drawing 50000 posterior samples: 54956it [00:00, 154667.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18305/50000 [00:00<00:00, 155521.12it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36595/50000 [00:00<00:00, 155877.62it/s]Drawing 50000 posterior samples: 54862it [00:00, 155657.35it/s]                           Drawing 50000 posterior samples: 54862it [00:00, 155560.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18315/50000 [00:00<00:00, 155893.13it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36633/50000 [00:00<00:00, 155366.14it/s]Drawing 50000 posterior samples: 55048it [00:00, 155098.18it/s]                           Drawing 50000 posterior samples: 55048it [00:00, 154596.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18371/50000 [00:00<00:00, 152917.42it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36691/50000 [00:00<00:00, 152689.81it/s]Drawing 50000 posterior samples: 55099it [00:00, 152870.34it/s]                           Drawing 50000 posterior samples: 55099it [00:00, 152551.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▋      | 18234/50000 [00:00<00:00, 152089.75it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36457/50000 [00:00<00:00, 152221.02it/s]Drawing 50000 posterior samples: 54751it [00:00, 153032.94it/s]                           Drawing 50000 posterior samples: 54751it [00:00, 152955.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18330/50000 [00:00<00:00, 152384.71it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36715/50000 [00:00<00:00, 152524.85it/s]Drawing 50000 posterior samples: 55058it [00:00, 153115.22it/s]                           Drawing 50000 posterior samples: 55058it [00:00, 153017.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18276/50000 [00:00<00:00, 152717.66it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36622/50000 [00:00<00:00, 153370.80it/s]Drawing 50000 posterior samples: 54985it [00:00, 154046.06it/s]                           Drawing 50000 posterior samples: 54985it [00:00, 154183.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18324/50000 [00:00<00:00, 152207.82it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36628/50000 [00:00<00:00, 152147.36it/s]Drawing 50000 posterior samples: 54991it [00:00, 152204.44it/s]                           Drawing 50000 posterior samples: 54991it [00:00, 151967.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18310/50000 [00:00<00:00, 154783.22it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36725/50000 [00:00<00:00, 154626.05it/s]Drawing 50000 posterior samples: 55050it [00:00, 154035.09it/s]                           Drawing 50000 posterior samples: 55050it [00:00, 153704.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18374/50000 [00:00<00:00, 153697.93it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36702/50000 [00:00<00:00, 153299.76it/s]Drawing 50000 posterior samples: 55013it [00:00, 152755.47it/s]                           Drawing 50000 posterior samples: 55013it [00:00, 152295.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18337/50000 [00:00<00:00, 154331.82it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36753/50000 [00:00<00:00, 154091.30it/s]Drawing 50000 posterior samples: 55113it [00:00, 154294.04it/s]                           Drawing 50000 posterior samples: 55113it [00:00, 153982.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18297/50000 [00:00<00:00, 151948.34it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36589/50000 [00:00<00:00, 151606.68it/s]Drawing 50000 posterior samples: 54847it [00:00, 151584.10it/s]                           Drawing 50000 posterior samples: 54847it [00:00, 151216.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18339/50000 [00:00<00:00, 156132.58it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36601/50000 [00:00<00:00, 155364.97it/s]Drawing 50000 posterior samples: 54895it [00:00, 154992.63it/s]                           Drawing 50000 posterior samples: 54895it [00:00, 154388.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18251/50000 [00:00<00:00, 154504.00it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36603/50000 [00:00<00:00, 154572.86it/s]Drawing 50000 posterior samples: 54956it [00:00, 154021.27it/s]                           Drawing 50000 posterior samples: 54956it [00:00, 153750.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18264/50000 [00:00<00:00, 155832.19it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36605/50000 [00:00<00:00, 156030.79it/s]Drawing 50000 posterior samples: 55009it [00:00, 156214.35it/s]                           Drawing 50000 posterior samples: 55009it [00:00, 156097.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18361/50000 [00:00<00:00, 155334.88it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36756/50000 [00:00<00:00, 155202.15it/s]Drawing 50000 posterior samples: 55077it [00:00, 154981.94it/s]                           Drawing 50000 posterior samples: 55077it [00:00, 154647.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18362/50000 [00:00<00:00, 154652.39it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36777/50000 [00:00<00:00, 154827.18it/s]Drawing 50000 posterior samples: 55138it [00:00, 155028.00it/s]                           Drawing 50000 posterior samples: 55138it [00:00, 154884.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18368/50000 [00:00<00:00, 152726.66it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36689/50000 [00:00<00:00, 152521.24it/s]Drawing 50000 posterior samples: 55027it [00:00, 152566.48it/s]                           Drawing 50000 posterior samples: 55027it [00:00, 152236.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18350/50000 [00:00<00:00, 150584.96it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36715/50000 [00:00<00:00, 150780.37it/s]Drawing 50000 posterior samples: 55034it [00:00, 150925.22it/s]                           Drawing 50000 posterior samples: 55034it [00:00, 150801.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18305/50000 [00:00<00:00, 153849.78it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36624/50000 [00:00<00:00, 153915.68it/s]Drawing 50000 posterior samples: 54956it [00:00, 154292.34it/s]                           Drawing 50000 posterior samples: 54956it [00:00, 154129.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18350/50000 [00:00<00:00, 152223.01it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36666/50000 [00:00<00:00, 152129.98it/s]Drawing 50000 posterior samples: 54991it [00:00, 151917.89it/s]                           Drawing 50000 posterior samples: 54991it [00:00, 151638.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18342/50000 [00:00<00:00, 151593.88it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36695/50000 [00:00<00:00, 151753.14it/s]Drawing 50000 posterior samples: 55054it [00:00, 151885.08it/s]                           Drawing 50000 posterior samples: 55054it [00:00, 151757.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18338/50000 [00:00<00:00, 151740.22it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36634/50000 [00:00<00:00, 150749.66it/s]Drawing 50000 posterior samples: 54908it [00:00, 147385.13it/s]                           Drawing 50000 posterior samples: 54908it [00:00, 146405.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18380/50000 [00:00<00:00, 154065.22it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36753/50000 [00:00<00:00, 154022.67it/s]Drawing 50000 posterior samples: 55064it [00:00, 153405.98it/s]                           Drawing 50000 posterior samples: 55064it [00:00, 153093.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18363/50000 [00:00<00:00, 152978.04it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36716/50000 [00:00<00:00, 152592.65it/s]Drawing 50000 posterior samples: 54997it [00:00, 152495.57it/s]                           Drawing 50000 posterior samples: 54997it [00:00, 152095.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18395/50000 [00:00<00:00, 153846.60it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36768/50000 [00:00<00:00, 153451.70it/s]Drawing 50000 posterior samples: 55147it [00:00, 153300.67it/s]                           Drawing 50000 posterior samples: 55147it [00:00, 152885.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18338/50000 [00:00<00:00, 152389.00it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36624/50000 [00:00<00:00, 152270.08it/s]Drawing 50000 posterior samples: 54988it [00:00, 152197.81it/s]                           Drawing 50000 posterior samples: 54988it [00:00, 151908.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▋      | 18247/50000 [00:00<00:00, 152350.27it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36589/50000 [00:00<00:00, 152591.27it/s]Drawing 50000 posterior samples: 54927it [00:00, 152567.75it/s]                           Drawing 50000 posterior samples: 54927it [00:00, 152456.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18307/50000 [00:00<00:00, 153700.58it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36650/50000 [00:00<00:00, 153504.11it/s]Drawing 50000 posterior samples: 55009it [00:00, 152789.86it/s]                           Drawing 50000 posterior samples: 55009it [00:00, 152400.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18341/50000 [00:00<00:00, 152726.81it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36744/50000 [00:00<00:00, 152608.47it/s]Drawing 50000 posterior samples: 55058it [00:00, 151888.10it/s]                           Drawing 50000 posterior samples: 55058it [00:00, 151546.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165942.48it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165668.37it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165380.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19771/50000 [00:00<00:00, 163174.13it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39541/50000 [00:00<00:00, 163271.03it/s]Drawing 50000 posterior samples: 59314it [00:00, 163644.27it/s]                           Drawing 50000 posterior samples: 59314it [00:00, 163501.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166155.80it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165974.33it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165587.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168199.39it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167525.53it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166475.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 18976/50000 [00:00<00:00, 157801.46it/s]Drawing 50000 posterior samples:  76%|███████▌  | 37952/50000 [00:00<00:00, 157863.15it/s]Drawing 50000 posterior samples: 56988it [00:00, 157977.95it/s]                           Drawing 50000 posterior samples: 56988it [00:00, 157793.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18615/50000 [00:00<00:00, 155769.50it/s]Drawing 50000 posterior samples:  74%|███████▍  | 37210/50000 [00:00<00:00, 155423.31it/s]Drawing 50000 posterior samples: 55833it [00:00, 155168.99it/s]                           Drawing 50000 posterior samples: 55833it [00:00, 154739.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167037.86it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167023.19it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166687.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166552.33it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166328.13it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165286.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165019.96it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165356.92it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165535.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169236.73it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168471.79it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167708.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19999/50000 [00:00<00:00, 165913.83it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39997/50000 [00:00<00:00, 166556.64it/s]Drawing 50000 posterior samples: 59995it [00:00, 167219.64it/s]                           Drawing 50000 posterior samples: 59995it [00:00, 167356.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168009.39it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168142.44it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167954.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168457.11it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167920.64it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167094.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164184.08it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164394.32it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164122.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164927.17it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165004.54it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164452.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19894/50000 [00:00<00:00, 168359.14it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39777/50000 [00:00<00:00, 167980.47it/s]Drawing 50000 posterior samples: 59678it [00:00, 168015.78it/s]                           Drawing 50000 posterior samples: 59678it [00:00, 167597.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19989/50000 [00:00<00:00, 169034.19it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39971/50000 [00:00<00:00, 169092.74it/s]Drawing 50000 posterior samples: 59948it [00:00, 168287.61it/s]                           Drawing 50000 posterior samples: 59948it [00:00, 167990.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166372.96it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166043.88it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 156583.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 19086/50000 [00:00<00:00, 159788.59it/s]Drawing 50000 posterior samples:  76%|███████▋  | 38178/50000 [00:00<00:00, 159508.10it/s]Drawing 50000 posterior samples: 57276it [00:00, 159664.19it/s]                           Drawing 50000 posterior samples: 57276it [00:00, 159332.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168484.17it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168110.60it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168113.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169662.20it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168921.06it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168111.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168151.85it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168125.76it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167767.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167355.44it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167453.66it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167287.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164047.94it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165748.21it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167298.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 157657.78it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 157509.21it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 158043.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169097.55it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168908.47it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168776.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167555.01it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168382.17it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168783.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169751.46it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169163.33it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168210.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168012.42it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168100.39it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167749.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▍      | 17460/50000 [00:00<00:00, 145842.06it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34978/50000 [00:00<00:00, 146294.27it/s]Drawing 50000 posterior samples: 52510it [00:00, 146421.78it/s]                           Drawing 50000 posterior samples: 52510it [00:00, 146431.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168118.48it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167847.73it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167274.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19967/50000 [00:00<00:00, 166287.75it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39929/50000 [00:00<00:00, 166247.13it/s]Drawing 50000 posterior samples: 59894it [00:00, 166364.21it/s]                           Drawing 50000 posterior samples: 59894it [00:00, 166076.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169802.32it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170008.18it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169947.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170364.08it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168480.96it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166763.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  32%|███▏      | 16149/50000 [00:00<00:00, 135967.72it/s]Drawing 50000 posterior samples:  65%|██████▍   | 32421/50000 [00:00<00:00, 135848.96it/s]Drawing 50000 posterior samples:  97%|█████████▋| 48659/50000 [00:00<00:00, 135872.48it/s]Drawing 50000 posterior samples: 56759it [00:00, 135503.36it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 18814/50000 [00:00<00:00, 157418.70it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37631/50000 [00:00<00:00, 157060.35it/s]Drawing 50000 posterior samples: 56522it [00:00, 157547.91it/s]                           Drawing 50000 posterior samples: 56522it [00:00, 157222.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167230.67it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167097.85it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167128.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167193.67it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167617.72it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167957.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164483.80it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163869.57it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163735.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168294.21it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167812.74it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167165.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19990/50000 [00:00<00:00, 166637.46it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39986/50000 [00:00<00:00, 166289.16it/s]Drawing 50000 posterior samples: 59986it [00:00, 166799.53it/s]                           Drawing 50000 posterior samples: 59986it [00:00, 166453.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166732.09it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166885.93it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166963.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167564.38it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167402.37it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166886.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167363.46it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167382.69it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167001.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166972.36it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 160398.85it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 158037.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19914/50000 [00:00<00:00, 166465.78it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39806/50000 [00:00<00:00, 166222.19it/s]Drawing 50000 posterior samples: 59706it [00:00, 166120.86it/s]                           Drawing 50000 posterior samples: 59706it [00:00, 165751.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19906/50000 [00:00<00:00, 166174.69it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39855/50000 [00:00<00:00, 166943.10it/s]Drawing 50000 posterior samples: 59794it [00:00, 167878.33it/s]                           Drawing 50000 posterior samples: 59794it [00:00, 168093.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166808.01it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166824.53it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166710.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19888/50000 [00:00<00:00, 166024.43it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39765/50000 [00:00<00:00, 165891.04it/s]Drawing 50000 posterior samples: 59656it [00:00, 165642.62it/s]                           Drawing 50000 posterior samples: 59656it [00:00, 165326.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167483.08it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167544.80it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166949.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164999.83it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165210.80it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165247.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168633.54it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168227.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167684.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167092.43it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166926.24it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166562.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166341.29it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166189.24it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165965.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169086.64it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169095.84it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168974.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168449.33it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168221.11it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167602.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169765.55it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169426.82it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168871.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168023.86it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168225.43it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168012.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166811.99it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165162.59it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164468.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 17970/50000 [00:00<00:00, 150147.50it/s]Drawing 50000 posterior samples:  72%|███████▏  | 35978/50000 [00:00<00:00, 149987.79it/s]Drawing 50000 posterior samples: 54048it [00:00, 150828.89it/s]                           Drawing 50000 posterior samples: 54048it [00:00, 150638.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166793.42it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167349.94it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167746.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19892/50000 [00:00<00:00, 162938.40it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39789/50000 [00:00<00:00, 163183.25it/s]Drawing 50000 posterior samples: 59703it [00:00, 163057.59it/s]                           Drawing 50000 posterior samples: 59703it [00:00, 162924.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165415.65it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165355.98it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164868.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165710.72it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165410.56it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164427.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18298/50000 [00:00<00:00, 150758.19it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36572/50000 [00:00<00:00, 150754.56it/s]Drawing 50000 posterior samples: 54844it [00:00, 149996.67it/s]                           Drawing 50000 posterior samples: 54844it [00:00, 149675.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▌      | 17647/50000 [00:00<00:00, 144840.04it/s]Drawing 50000 posterior samples:  71%|███████   | 35287/50000 [00:00<00:00, 144776.72it/s]Drawing 50000 posterior samples: 52897it [00:00, 144375.89it/s]                           Drawing 50000 posterior samples: 52897it [00:00, 144093.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163495.76it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164074.83it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163953.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164200.79it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164136.79it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163520.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164162.55it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164071.82it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163681.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166073.23it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165749.26it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165259.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19993/50000 [00:00<00:00, 165747.67it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39984/50000 [00:00<00:00, 165761.87it/s]Drawing 50000 posterior samples: 59978it [00:00, 165827.94it/s]                           Drawing 50000 posterior samples: 59978it [00:00, 165593.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167494.12it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166510.77it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165575.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167502.82it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167415.67it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167102.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166410.92it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166124.70it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165594.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165171.37it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165116.07it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164946.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19913/50000 [00:00<00:00, 163241.12it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39828/50000 [00:00<00:00, 163478.47it/s]Drawing 50000 posterior samples: 59747it [00:00, 162962.86it/s]                           Drawing 50000 posterior samples: 59747it [00:00, 162759.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165330.88it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164844.81it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163998.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167913.54it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167641.84it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166537.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19944/50000 [00:00<00:00, 166804.99it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39901/50000 [00:00<00:00, 166719.36it/s]Drawing 50000 posterior samples: 59844it [00:00, 165878.41it/s]                           Drawing 50000 posterior samples: 59844it [00:00, 165518.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168215.24it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168241.45it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167665.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167927.66it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167575.63it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167037.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167648.10it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167207.20it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166785.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167833.25it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168378.19it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168715.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170511.25it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169963.81it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169386.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170325.34it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170191.40it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169659.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169444.92it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169490.32it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169111.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166529.85it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166464.71it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166234.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167268.35it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166763.28it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165784.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164428.67it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163976.15it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163830.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 18121/50000 [00:00<00:00, 149741.68it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36231/50000 [00:00<00:00, 149912.78it/s]Drawing 50000 posterior samples: 54336it [00:00, 150001.27it/s]                           Drawing 50000 posterior samples: 54336it [00:00, 149889.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166190.69it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165667.55it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165175.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19940/50000 [00:00<00:00, 167557.04it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39872/50000 [00:00<00:00, 167690.81it/s]Drawing 50000 posterior samples: 59812it [00:00, 167370.04it/s]                           Drawing 50000 posterior samples: 59812it [00:00, 167182.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 162921.97it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163367.54it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163449.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165079.71it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164323.41it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163760.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 19089/50000 [00:00<00:00, 152652.89it/s]Drawing 50000 posterior samples:  76%|███████▌  | 38109/50000 [00:00<00:00, 153068.53it/s]Drawing 50000 posterior samples: 57204it [00:00, 154574.77it/s]                           Drawing 50000 posterior samples: 57204it [00:00, 154705.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 17982/50000 [00:00<00:00, 139460.62it/s]Drawing 50000 posterior samples:  72%|███████▏  | 35824/50000 [00:00<00:00, 141110.59it/s]Drawing 50000 posterior samples: 53732it [00:00, 143383.23it/s]                           Drawing 50000 posterior samples: 53732it [00:00, 144204.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166279.30it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166295.82it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165915.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167638.38it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167098.82it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166320.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167850.04it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167381.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166665.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167499.14it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167415.30it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166697.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19981/50000 [00:00<00:00, 166200.41it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39964/50000 [00:00<00:00, 166340.27it/s]Drawing 50000 posterior samples: 59938it [00:00, 166601.91it/s]                           Drawing 50000 posterior samples: 59938it [00:00, 166475.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167938.76it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168002.42it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167930.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168118.48it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167749.75it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167107.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167229.00it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167434.18it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167242.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168052.13it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168032.95it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168097.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▉      | 19685/50000 [00:00<00:00, 164863.33it/s]Drawing 50000 posterior samples:  79%|███████▊  | 39373/50000 [00:00<00:00, 164535.10it/s]Drawing 50000 posterior samples: 59042it [00:00, 164536.89it/s]                           Drawing 50000 posterior samples: 59042it [00:00, 164179.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167367.80it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167526.93it/s]Drawing 50000 posterior samples: 59999it [00:00, 167888.44it/s]                           Drawing 50000 posterior samples: 59999it [00:00, 167791.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167969.69it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167879.64it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167251.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▉      | 19591/50000 [00:00<00:00, 164897.58it/s]Drawing 50000 posterior samples:  78%|███████▊  | 39214/50000 [00:00<00:00, 165167.40it/s]Drawing 50000 posterior samples: 58820it [00:00, 164805.43it/s]                           Drawing 50000 posterior samples: 58820it [00:00, 164684.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166812.99it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166823.93it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166664.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166099.87it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165681.20it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165303.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165876.85it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165933.35it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166060.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167852.39it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167412.83it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167004.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165624.67it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165417.54it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165237.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165010.87it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165184.19it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165272.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167639.05it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167467.97it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167027.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165776.21it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166215.62it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166807.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167722.51it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167921.14it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167893.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165756.89it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165003.82it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164484.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 18036/50000 [00:00<00:00, 148127.31it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36111/50000 [00:00<00:00, 148612.45it/s]Drawing 50000 posterior samples: 54188it [00:00, 148928.15it/s]                           Drawing 50000 posterior samples: 54188it [00:00, 148981.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
30
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Neural network successfully converged after 143 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Neural network successfully converged after 259 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Neural network successfully converged after 317 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Neural network successfully converged after 235 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Neural network successfully converged after 307 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Neural network successfully converged after 165 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Neural network successfully converged after 191 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Neural network successfully converged after 204 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Neural network successfully converged after 249 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Neural network successfully converged after 238 epochs.
log prob true 4.2695227
log prob true 3.2396865
log prob true 4.1058664
log prob true 2.8630269
log prob true 2.9071076
log prob true 2.927453
log prob true 3.4352913
log prob true 4.0244513
log prob true 3.6302063
log prob true 3.4536853
log prob true 2.9881456
log prob true 3.668403
log prob true 4.165228
log prob true 3.694365
log prob true 3.195948
log prob true 2.9280713
log prob true 3.6069517
log prob true 3.98022
log prob true 2.2442627
log prob true 4.0019746
log prob true 3.8605087
log prob true 3.5684447
log prob true 4.19937
log prob true 3.5508223
log prob true 4.1502943
log prob true 3.7372746
log prob true 2.9424472
log prob true 3.4466953
log prob true 4.06068
log prob true 2.2952511
log prob true 4.339749
log prob true 3.9527378
log prob true 4.255306
log prob true 2.9295497
log prob true 3.0924957
log prob true 2.8745205
log prob true 3.6306715
log prob true 4.242012
log prob true 3.831957
log prob true 3.7958336
log prob true 3.2484083
log prob true 4.0951877
log prob true 4.2540507
log prob true 4.0039186
log prob true 2.9950168
log prob true 3.0207305
log prob true 3.6836812
log prob true 4.029347
log prob true 2.3374503
log prob true 4.2389836
log prob true 3.9853904
log prob true 3.7446477
log prob true 4.3389263
log prob true 3.780409
log prob true 4.317319
log prob true 4.013859
log prob true 3.133803
log prob true 3.6940432
log prob true 4.12349
log prob true 1.5618782
log prob true 7.6366224
log prob true 7.0952463
log prob true 7.400525
log prob true 7.0256763
log prob true 6.848236
log prob true 7.02001
log prob true 6.94342
log prob true 7.3970704
log prob true 6.975835
log prob true 7.0832
log prob true 6.861217
log prob true 7.24076
log prob true 7.812517
log prob true 7.317389
log prob true 6.7468553
log prob true 6.4910154
log prob true 6.850745
log prob true 7.217838
log prob true 6.908523
log prob true 7.3981223
log prob true 7.5441723
log prob true 7.3317494
log prob true 7.5642743
log prob true 7.0305676
log prob true 7.3938775
log prob true 7.2460437
log prob true 6.496781
log prob true 6.910208
log prob true 7.509022
log prob true 6.8760266
log prob true 4.4005404
log prob true 4.1829867
log prob true 4.2788916
log prob true 3.018143
log prob true 3.5239484
log prob true 3.1281896
log prob true 3.8144515
log prob true 4.3199396
log prob true 3.8159945
log prob true 3.8017836
log prob true 3.1870766
log prob true 4.3007317
log prob true 4.3887796
log prob true 4.0210085
log prob true 3.4038405
log prob true 3.0607417
log prob true 3.885714
log prob true 4.144479
log prob true 2.9229677
log prob true 4.423006
log prob true 3.9978702
log prob true 3.7833374
log prob true 4.435317
log prob true 4.018099
log prob true 4.293875
log prob true 4.241336
log prob true 3.3720994
log prob true 3.664766
log prob true 4.202096
log prob true 1.3547351
log prob true 7.5951552
log prob true 7.1491632
log prob true 7.3246226
log prob true 6.927802
log prob true 5.282943
log prob true 6.945609
log prob true 6.7520976
log prob true 7.4340463
log prob true 6.799061
log prob true 7.3182893
log prob true 7.0097485
log prob true 7.1943254
log prob true 7.5951734
log prob true 7.237879
log prob true 6.710143
log prob true 6.670801
log prob true 6.9585447
log prob true 7.021411
log prob true 6.704887
log prob true 7.4087305
log prob true 7.246438
log prob true 7.1478367
log prob true 7.5025377
log prob true 7.093884
log prob true 7.3533254
log prob true 7.1908684
log prob true 6.6193814
log prob true 6.9657826
log prob true 7.357664
log prob true 6.395209
log prob true 4.372811
log prob true 3.8761568
log prob true 4.132114
log prob true 2.9109018
log prob true 3.066597
log prob true 2.9812365
log prob true 3.606627
log prob true 4.1823516
log prob true 3.6816843
log prob true 3.7391808
log prob true 2.9860158
log prob true 4.1170344
log prob true 4.144135
log prob true 3.9964943
log prob true 3.2999053
log prob true 2.9650908
log prob true 3.7132711
log prob true 4.031605
log prob true 2.2961586
log prob true 4.2354736
log prob true 3.8676302
log prob true 3.5485232
log prob true 4.3496284
log prob true 3.8196793
log prob true 4.203493
log prob true 4.040401
log prob true 3.148469
log prob true 3.579536
log prob true 3.9575756
log prob true 1.8827789
log prob true 7.3870792
log prob true 6.8457
log prob true 7.1312056
log prob true 6.750475
log prob true 6.003359
log prob true 6.5027375
log prob true 6.6088514
log prob true 7.1185665
log prob true 6.682617
log prob true 6.9451623
log prob true 6.696398
log prob true 7.028383
log prob true 7.334037
log prob true 7.0452952
log prob true 6.5365367
log prob true 6.3045044
log prob true 6.534455
log prob true 6.815033
log prob true 6.2382884
log prob true 7.1119137
log prob true 7.079722
log prob true 6.884992
log prob true 7.305222
log prob true 6.7337394
log prob true 7.113936
log prob true 6.929467
log prob true 6.293214
log prob true 6.6060734
log prob true 7.065854
log prob true 6.499254
log prob true 7.2294364
log prob true 6.809244
log prob true 6.8681226
log prob true 6.7423124
log prob true 6.45403
log prob true 6.418018
log prob true 6.5346212
log prob true 7.0163307
log prob true 6.6564646
log prob true 6.860631
log prob true 6.565312
log prob true 6.905349
log prob true 7.4500036
log prob true 7.006691
log prob true 6.3962135
log prob true 6.225743
log prob true 6.378416
log prob true 6.8327923
log prob true 6.1815453
log prob true 7.1460786
log prob true 7.055893
log prob true 6.8610168
log prob true 7.134287
log prob true 6.5320897
log prob true 7.110835
log prob true 6.771891
log prob true 6.251945
log prob true 6.5761604
log prob true 6.923489
log prob true 6.4840097
log prob true 7.4767985
log prob true 6.912956
log prob true 7.1678824
log prob true 6.813603
log prob true 6.309254
log prob true 6.7699647
log prob true 6.7469487
log prob true 7.1401014
log prob true 6.8268423
log prob true 6.9017243
log prob true 6.6121154
log prob true 7.1212554
log prob true 7.52184
log prob true 7.1195107
log prob true 6.5844464
log prob true 6.3468623
log prob true 6.553383
log prob true 6.920161
log prob true 6.4774055
log prob true 7.252139
log prob true 7.1826043
log prob true 6.8827906
log prob true 7.2264504
log prob true 6.740726
log prob true 7.219821
log prob true 7.0402465
log prob true 6.3198185
log prob true 6.607398
log prob true 7.1267486
log prob true 6.6766934
log prob true 7.4142923
log prob true 6.930925
log prob true 7.0513635
log prob true 6.7239895
log prob true 6.0660005
log prob true 6.733643
log prob true 6.5246673
log prob true 7.163741
log prob true 6.671244
log prob true 6.879557
log prob true 6.761996
log prob true 7.081395
log prob true 7.5092034
log prob true 6.87755
log prob true 6.4902005
log prob true 6.4176946
log prob true 6.7087536
log prob true 6.884858
log prob true 5.815288
log prob true 7.231982
log prob true 6.9777164
log prob true 6.8522453
log prob true 7.2176027
log prob true 6.717437
log prob true 7.21872
log prob true 6.9274573
log prob true 6.3378954
log prob true 6.695974
log prob true 7.1101727
log prob true 6.206441
script complete
