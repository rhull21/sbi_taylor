Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
warning: file exists
100
warning: file exists
tensor([[0.0324],
        [0.0279],
        [0.0290],
        [0.0222],
        [0.0252],
        [0.0267],
        [0.0250],
        [0.0241],
        [0.0231],
        [0.0218],
        [0.0215],
        [0.0217],
        [0.0204],
        [0.0197],
        [0.0178],
        [0.0217],
        [0.0189],
        [0.0185],
        [0.0188],
        [0.0249],
        [0.0248],
        [0.0268],
        [0.0273],
        [0.0256],
        [0.0271],
        [0.0248],
        [0.0257],
        [0.0293],
        [0.0307],
        [0.0336],
        [0.0263],
        [0.0303],
        [0.0265],
        [0.0290],
        [0.0279],
        [0.0308],
        [0.0328],
        [0.0336],
        [0.0327],
        [0.0311],
        [0.0261],
        [0.0279],
        [0.0279],
        [0.0307],
        [0.0322],
        [0.0323],
        [0.0330],
        [0.0317],
        [0.0300],
        [0.0297],
        [0.0279],
        [0.0273],
        [0.0283],
        [0.0298],
        [0.0320],
        [0.0331],
        [0.0325],
        [0.0311],
        [0.0299],
        [0.0300],
        [0.0287],
        [0.0311],
        [0.0308],
        [0.0307],
        [0.0289],
        [0.0270],
        [0.0293],
        [0.0281],
        [0.0274],
        [0.0253],
        [0.0254],
        [0.0270],
        [0.0308],
        [0.0315],
        [0.0296],
        [0.0294],
        [0.0280],
        [0.0316],
        [0.0334],
        [0.0312],
        [0.0288],
        [0.0300],
        [0.0303],
        [0.0319],
        [0.0328],
        [0.0316],
        [0.0319],
        [0.0298],
        [0.0290],
        [0.0298],
        [0.0329],
        [0.0321],
        [0.0314],
        [0.0313],
        [0.0315],
        [0.0339],
        [0.0332],
        [0.0335],
        [0.0334],
        [0.0314],
        [0.0313],
        [0.0286],
        [0.0298],
        [0.0276],
        [0.0293],
        [0.0293],
        [0.0305],
        [0.0308],
        [0.0288],
        [0.0290],
        [0.0283],
        [0.0277],
        [0.0278],
        [0.0260],
        [0.0263],
        [0.0252],
        [0.0264],
        [0.0254],
        [0.0259],
        [0.0270],
        [0.0285],
        [0.0314],
        [0.0329],
        [0.0323],
        [0.0282],
        [0.0273],
        [0.0236],
        [0.0270],
        [0.0266],
        [0.0269],
        [0.0266],
        [0.0263],
        [0.0249],
        [0.0240],
        [0.0248],
        [0.0268],
        [0.0267],
        [0.0279],
        [0.0265],
        [0.0297],
        [0.0307],
        [0.0308],
        [0.0325],
        [0.0335],
        [0.0316],
        [0.0305],
        [0.0283],
        [0.0285],
        [0.0275],
        [0.0292],
        [0.0273],
        [0.0289],
        [0.0258],
        [0.0240],
        [0.0222],
        [0.0224],
        [0.0271],
        [0.0278],
        [0.0305],
        [0.0202],
        [0.0199],
        [0.0206],
        [0.0246],
        [0.0257],
        [0.0249],
        [0.0275],
        [0.0272],
        [0.0280],
        [0.0272],
        [0.0283],
        [0.0268],
        [0.0259],
        [0.0233],
        [0.0224],
        [0.0302],
        [0.0529],
        [0.0497],
        [0.0272],
        [0.0270],
        [0.0265],
        [0.0279],
        [0.0244],
        [0.0229],
        [0.0243],
        [0.0233],
        [0.0217],
        [0.0255],
        [0.0250],
        [0.0260],
        [0.0274],
        [0.0273],
        [0.0274],
        [0.0273],
        [0.0241],
        [0.0237],
        [0.0285],
        [0.0626],
        [0.1133],
        [0.0536],
        [0.0805],
        [0.0749],
        [0.0568],
        [0.0914],
        [0.0902],
        [0.0411],
        [0.0518],
        [0.0263],
        [0.0552],
        [0.1094],
        [0.1154],
        [0.0683],
        [0.1015],
        [0.2398],
        [0.2527],
        [0.2192],
        [0.1162],
        [0.1473],
        [0.1412],
        [0.1961],
        [0.2607],
        [0.2310],
        [0.1452],
        [0.1875],
        [0.1730],
        [0.1285],
        [0.0471],
        [0.1145],
        [0.1440],
        [0.1420],
        [0.3072],
        [0.3280],
        [0.3528],
        [0.3240],
        [0.3422],
        [0.4343],
        [0.3106],
        [0.2773],
        [0.1950],
        [0.1269],
        [0.2413],
        [0.3483],
        [0.4321],
        [0.4790],
        [0.4686],
        [0.5582],
        [0.5453],
        [0.3858],
        [0.2310],
        [0.2564],
        [0.2332],
        [0.2078],
        [0.1729],
        [0.1682],
        [0.1628],
        [0.1472],
        [0.1531],
        [0.2248],
        [0.2589],
        [0.3687],
        [0.4271],
        [0.1991],
        [0.2024],
        [0.1355],
        [0.0826],
        [0.1061],
        [0.0894],
        [0.0887],
        [0.0855],
        [0.0801],
        [0.0830],
        [0.0765],
        [0.0641],
        [0.0712],
        [0.0651],
        [0.0532],
        [0.0488],
        [0.0471],
        [0.0389],
        [0.0338],
        [0.0248],
        [0.0251],
        [0.0228],
        [0.0256],
        [0.0206],
        [0.0172],
        [0.0175],
        [0.0156],
        [0.0125],
        [0.0133],
        [0.0162],
        [0.0208],
        [0.0213],
        [0.0155],
        [0.0084],
        [0.0097],
        [0.0081],
        [0.0057],
        [0.0054],
        [0.0067],
        [0.0096],
        [0.0096],
        [0.0145],
        [0.0188],
        [0.0137],
        [0.0162],
        [0.0152],
        [0.0130],
        [0.0185],
        [0.0236],
        [0.0438],
        [0.0495],
        [0.0437],
        [0.0486],
        [0.0437],
        [0.0492],
        [0.0476],
        [0.0405],
        [0.0492],
        [0.0400],
        [0.0431],
        [0.0335],
        [0.0253],
        [0.0231],
        [0.0254],
        [0.0252],
        [0.0245],
        [0.0264],
        [0.0363],
        [0.0510],
        [0.0401],
        [0.0312],
        [0.0288],
        [0.0208],
        [0.0186],
        [0.0158],
        [0.0117],
        [0.0151],
        [0.0143],
        [0.0132],
        [0.0171],
        [0.0162],
        [0.0179],
        [0.0231],
        [0.0204],
        [0.0188],
        [0.0178],
        [0.0161],
        [0.0203],
        [0.0554],
        [0.0920]], grad_fn=<AddmmBackward>)
Traceback (most recent call last):
  File "lstm_sbi.py", line 337, in <module>
    posterior, end_time = buildPosterior(prior_type, prior_arg1, prior_arg2, num_dim,
  File "/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/03_sbi_lstm/sbi_build.py", line 140, in buildPosterior
    simulator_wrapper, prior = prepare_for_sbi(simulator, prior)
  File "/home/qh8373/.local/lib/python3.8/site-packages/sbi/utils/user_input_checks.py", line 501, in prepare_for_sbi
    check_sbi_inputs(simulator, prior)
  File "/home/qh8373/.local/lib/python3.8/site-packages/sbi/utils/user_input_checks.py", line 518, in check_sbi_inputs
    simulation = simulator(theta)
  File "/home/qh8373/.local/lib/python3.8/site-packages/sbi/utils/user_input_checks.py", line 434, in batch_loop_simulator
    xs = list(map(simulator, theta))
  File "/home/qh8373/.local/lib/python3.8/site-packages/sbi/utils/user_input_checks.py", line 399, in pytorch_simulator
    return torch.as_tensor(simulator(theta), dtype=float32)
  File "/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/03_sbi_lstm/sbi_build.py", line 121, in simulator
    y_o = y_o + y_o * np.random.randn(y_o.shape[0]) * f_noise
  File "/home/qh8373/.local/lib/python3.8/site-packages/torch/_tensor.py", line 643, in __array__
    return self.numpy()
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
