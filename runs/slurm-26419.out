Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:41, 240.77it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:41, 241.33it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:41, 241.17it/s]Running 10000 simulations.:   1%|          | 99/10000 [00:00<00:41, 240.78it/s]Running 10000 simulations.:   1%|          | 123/10000 [00:00<00:41, 240.27it/s]Running 10000 simulations.:   1%|▏         | 148/10000 [00:00<00:40, 240.34it/s]Running 10000 simulations.:   2%|▏         | 173/10000 [00:00<00:40, 240.63it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:00<00:40, 240.17it/s]Running 10000 simulations.:   2%|▏         | 221/10000 [00:00<00:40, 239.84it/s]Running 10000 simulations.:   2%|▏         | 245/10000 [00:01<00:40, 238.54it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:01<00:40, 237.48it/s]Running 10000 simulations.:   3%|▎         | 293/10000 [00:01<00:41, 236.71it/s]Running 10000 simulations.:   3%|▎         | 317/10000 [00:01<00:40, 236.98it/s]Running 10000 simulations.:   3%|▎         | 342/10000 [00:01<00:40, 237.90it/s]Running 10000 simulations.:   4%|▎         | 366/10000 [00:01<00:40, 237.14it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:40, 236.69it/s]Running 10000 simulations.:   4%|▍         | 414/10000 [00:01<00:40, 235.73it/s]Running 10000 simulations.:   4%|▍         | 438/10000 [00:01<00:40, 235.56it/s]Running 10000 simulations.:   5%|▍         | 462/10000 [00:01<00:40, 234.98it/s]Running 10000 simulations.:   5%|▍         | 486/10000 [00:02<00:40, 234.60it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:02<00:40, 234.96it/s]Running 10000 simulations.:   5%|▌         | 534/10000 [00:02<00:40, 235.43it/s]Running 10000 simulations.:   6%|▌         | 558/10000 [00:02<00:40, 235.14it/s]Running 10000 simulations.:   6%|▌         | 582/10000 [00:02<00:40, 235.23it/s]Running 10000 simulations.:   6%|▌         | 606/10000 [00:02<00:39, 235.40it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:02<00:39, 235.22it/s]Running 10000 simulations.:   7%|▋         | 654/10000 [00:02<00:39, 235.11it/s]Running 10000 simulations.:   7%|▋         | 678/10000 [00:02<00:39, 234.15it/s]Running 10000 simulations.:   7%|▋         | 702/10000 [00:02<00:39, 232.76it/s]Running 10000 simulations.:   7%|▋         | 726/10000 [00:03<00:39, 232.16it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:03<00:39, 232.20it/s]Running 10000 simulations.:   8%|▊         | 774/10000 [00:03<00:39, 233.23it/s]Running 10000 simulations.:   8%|▊         | 798/10000 [00:03<00:39, 233.35it/s]Running 10000 simulations.:   8%|▊         | 822/10000 [00:03<00:39, 232.22it/s]Running 10000 simulations.:   8%|▊         | 846/10000 [00:03<00:39, 231.52it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:03<00:39, 231.59it/s]Running 10000 simulations.:   9%|▉         | 894/10000 [00:03<00:39, 231.48it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:03<00:39, 231.25it/s]Running 10000 simulations.:   9%|▉         | 942/10000 [00:04<00:39, 231.80it/s]Running 10000 simulations.:  10%|▉         | 966/10000 [00:04<00:38, 232.08it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:04<00:39, 230.21it/s]Running 10000 simulations.:  10%|█         | 1014/10000 [00:04<00:39, 229.09it/s]Running 10000 simulations.:  10%|█         | 1038/10000 [00:04<00:38, 230.56it/s]Running 10000 simulations.:  11%|█         | 1062/10000 [00:04<00:38, 230.61it/s]Running 10000 simulations.:  11%|█         | 1086/10000 [00:04<00:38, 230.86it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:04<00:38, 230.52it/s]Running 10000 simulations.:  11%|█▏        | 1134/10000 [00:04<00:38, 230.52it/s]Running 10000 simulations.:  12%|█▏        | 1158/10000 [00:04<00:38, 230.47it/s]Running 10000 simulations.:  12%|█▏        | 1182/10000 [00:05<00:38, 230.60it/s]Running 10000 simulations.:  12%|█▏        | 1206/10000 [00:05<00:38, 231.21it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:05<00:37, 231.34it/s]Running 10000 simulations.:  13%|█▎        | 1254/10000 [00:05<00:37, 231.59it/s]Running 10000 simulations.:  13%|█▎        | 1278/10000 [00:05<00:37, 231.93it/s]Running 10000 simulations.:  13%|█▎        | 1302/10000 [00:05<00:37, 231.82it/s]Running 10000 simulations.:  13%|█▎        | 1326/10000 [00:05<00:37, 230.76it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:05<00:37, 230.83it/s]Running 10000 simulations.:  14%|█▎        | 1374/10000 [00:05<00:37, 230.41it/s]Running 10000 simulations.:  14%|█▍        | 1398/10000 [00:05<00:37, 229.93it/s]Running 10000 simulations.:  14%|█▍        | 1421/10000 [00:06<00:37, 229.41it/s]Running 10000 simulations.:  14%|█▍        | 1444/10000 [00:06<00:37, 228.06it/s]Running 10000 simulations.:  15%|█▍        | 1467/10000 [00:06<00:37, 227.84it/s]Running 10000 simulations.:  15%|█▍        | 1490/10000 [00:06<00:37, 228.37it/s]Running 10000 simulations.:  15%|█▌        | 1514/10000 [00:06<00:37, 229.26it/s]Running 10000 simulations.:  15%|█▌        | 1537/10000 [00:06<00:36, 229.38it/s]Running 10000 simulations.:  16%|█▌        | 1561/10000 [00:06<00:36, 229.62it/s]Running 10000 simulations.:  16%|█▌        | 1585/10000 [00:06<00:36, 230.06it/s]Running 10000 simulations.:  16%|█▌        | 1609/10000 [00:06<00:36, 231.04it/s]Running 10000 simulations.:  16%|█▋        | 1633/10000 [00:07<00:36, 230.57it/s]Running 10000 simulations.:  17%|█▋        | 1657/10000 [00:07<00:36, 230.01it/s]Running 10000 simulations.:  17%|█▋        | 1681/10000 [00:07<00:36, 229.83it/s]Running 10000 simulations.:  17%|█▋        | 1705/10000 [00:07<00:35, 230.82it/s]Running 10000 simulations.:  17%|█▋        | 1729/10000 [00:07<00:35, 230.18it/s]Running 10000 simulations.:  18%|█▊        | 1753/10000 [00:07<00:35, 230.05it/s]Running 10000 simulations.:  18%|█▊        | 1777/10000 [00:07<00:35, 229.79it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:07<00:35, 228.80it/s]Running 10000 simulations.:  18%|█▊        | 1824/10000 [00:07<00:35, 229.91it/s]Running 10000 simulations.:  18%|█▊        | 1848/10000 [00:07<00:35, 230.24it/s]Running 10000 simulations.:  19%|█▊        | 1872/10000 [00:08<00:35, 230.49it/s]Running 10000 simulations.:  19%|█▉        | 1896/10000 [00:08<00:35, 229.99it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:08<00:35, 230.16it/s]Running 10000 simulations.:  19%|█▉        | 1944/10000 [00:08<00:35, 230.11it/s]Running 10000 simulations.:  20%|█▉        | 1968/10000 [00:08<00:34, 230.94it/s]Running 10000 simulations.:  20%|█▉        | 1992/10000 [00:08<00:34, 230.73it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:08<00:34, 230.09it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:08<00:34, 230.38it/s]Running 10000 simulations.:  21%|██        | 2064/10000 [00:08<00:34, 230.94it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:08<00:34, 230.88it/s]Running 10000 simulations.:  21%|██        | 2112/10000 [00:09<00:34, 230.39it/s]Running 10000 simulations.:  21%|██▏       | 2136/10000 [00:09<00:34, 229.57it/s]Running 10000 simulations.:  22%|██▏       | 2159/10000 [00:09<00:34, 229.50it/s]Running 10000 simulations.:  22%|██▏       | 2183/10000 [00:09<00:34, 229.70it/s]Running 10000 simulations.:  22%|██▏       | 2207/10000 [00:09<00:33, 229.91it/s]Running 10000 simulations.:  22%|██▏       | 2231/10000 [00:09<00:33, 230.07it/s]Running 10000 simulations.:  23%|██▎       | 2255/10000 [00:09<00:33, 229.87it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:09<00:33, 229.79it/s]Running 10000 simulations.:  23%|██▎       | 2301/10000 [00:09<00:33, 229.38it/s]Running 10000 simulations.:  23%|██▎       | 2325/10000 [00:10<00:33, 229.81it/s]Running 10000 simulations.:  23%|██▎       | 2349/10000 [00:10<00:33, 230.07it/s]Running 10000 simulations.:  24%|██▎       | 2373/10000 [00:10<00:33, 229.82it/s]Running 10000 simulations.:  24%|██▍       | 2396/10000 [00:10<00:33, 229.62it/s]Running 10000 simulations.:  24%|██▍       | 2419/10000 [00:10<00:33, 229.63it/s]Running 10000 simulations.:  24%|██▍       | 2442/10000 [00:10<00:32, 229.34it/s]Running 10000 simulations.:  25%|██▍       | 2466/10000 [00:10<00:32, 230.01it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:10<00:32, 230.77it/s]Running 10000 simulations.:  25%|██▌       | 2514/10000 [00:10<00:32, 230.48it/s]Running 10000 simulations.:  25%|██▌       | 2538/10000 [00:10<00:32, 230.50it/s]Running 10000 simulations.:  26%|██▌       | 2562/10000 [00:11<00:32, 230.19it/s]Running 10000 simulations.:  26%|██▌       | 2586/10000 [00:11<00:32, 230.71it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:11<00:32, 230.45it/s]Running 10000 simulations.:  26%|██▋       | 2634/10000 [00:11<00:31, 230.61it/s]Running 10000 simulations.:  27%|██▋       | 2658/10000 [00:11<00:31, 231.24it/s]Running 10000 simulations.:  27%|██▋       | 2682/10000 [00:11<00:31, 232.91it/s]Running 10000 simulations.:  27%|██▋       | 2706/10000 [00:11<00:31, 233.81it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:11<00:31, 232.28it/s]Running 10000 simulations.:  28%|██▊       | 2754/10000 [00:11<00:31, 232.57it/s]Running 10000 simulations.:  28%|██▊       | 2778/10000 [00:11<00:30, 233.51it/s]Running 10000 simulations.:  28%|██▊       | 2802/10000 [00:12<00:30, 234.13it/s]Running 10000 simulations.:  28%|██▊       | 2826/10000 [00:12<00:30, 234.00it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:12<00:30, 234.34it/s]Running 10000 simulations.:  29%|██▊       | 2874/10000 [00:12<00:30, 234.72it/s]Running 10000 simulations.:  29%|██▉       | 2898/10000 [00:12<00:30, 235.14it/s]Running 10000 simulations.:  29%|██▉       | 2922/10000 [00:12<00:30, 235.45it/s]Running 10000 simulations.:  29%|██▉       | 2946/10000 [00:12<00:30, 230.71it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:12<00:31, 221.72it/s]Running 10000 simulations.:  30%|██▉       | 2993/10000 [00:12<00:32, 215.93it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:13<00:32, 212.37it/s]Running 10000 simulations.:  30%|███       | 3037/10000 [00:13<00:33, 209.51it/s]Running 10000 simulations.:  31%|███       | 3059/10000 [00:13<00:33, 206.92it/s]Running 10000 simulations.:  31%|███       | 3080/10000 [00:13<00:33, 205.61it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:13<00:33, 204.39it/s]Running 10000 simulations.:  31%|███       | 3122/10000 [00:13<00:33, 203.68it/s]Running 10000 simulations.:  31%|███▏      | 3143/10000 [00:13<00:33, 202.83it/s]Running 10000 simulations.:  32%|███▏      | 3164/10000 [00:13<00:33, 202.88it/s]Running 10000 simulations.:  32%|███▏      | 3185/10000 [00:13<00:33, 202.90it/s]Running 10000 simulations.:  32%|███▏      | 3206/10000 [00:13<00:33, 203.18it/s]Running 10000 simulations.:  32%|███▏      | 3227/10000 [00:14<00:33, 203.22it/s]Running 10000 simulations.:  32%|███▏      | 3248/10000 [00:14<00:33, 203.88it/s]Running 10000 simulations.:  33%|███▎      | 3269/10000 [00:14<00:32, 204.27it/s]Running 10000 simulations.:  33%|███▎      | 3290/10000 [00:14<00:32, 204.44it/s]Running 10000 simulations.:  33%|███▎      | 3311/10000 [00:14<00:32, 204.81it/s]Running 10000 simulations.:  33%|███▎      | 3332/10000 [00:14<00:32, 205.92it/s]Running 10000 simulations.:  34%|███▎      | 3353/10000 [00:14<00:32, 205.48it/s]Running 10000 simulations.:  34%|███▍      | 3375/10000 [00:14<00:31, 207.19it/s]Running 10000 simulations.:  34%|███▍      | 3396/10000 [00:14<00:32, 206.37it/s]Running 10000 simulations.:  34%|███▍      | 3417/10000 [00:14<00:32, 205.13it/s]Running 10000 simulations.:  34%|███▍      | 3438/10000 [00:15<00:32, 204.18it/s]Running 10000 simulations.:  35%|███▍      | 3459/10000 [00:15<00:32, 203.87it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:15<00:31, 204.82it/s]Running 10000 simulations.:  35%|███▌      | 3501/10000 [00:15<00:31, 205.99it/s]Running 10000 simulations.:  35%|███▌      | 3523/10000 [00:15<00:30, 209.12it/s]Running 10000 simulations.:  35%|███▌      | 3545/10000 [00:15<00:30, 210.74it/s]Running 10000 simulations.:  36%|███▌      | 3567/10000 [00:15<00:30, 211.79it/s]Running 10000 simulations.:  36%|███▌      | 3589/10000 [00:15<00:30, 212.76it/s]Running 10000 simulations.:  36%|███▌      | 3611/10000 [00:15<00:29, 213.51it/s]Running 10000 simulations.:  36%|███▋      | 3633/10000 [00:16<00:29, 213.78it/s]Running 10000 simulations.:  37%|███▋      | 3655/10000 [00:16<00:29, 214.23it/s]Running 10000 simulations.:  37%|███▋      | 3677/10000 [00:16<00:29, 214.14it/s]Running 10000 simulations.:  37%|███▋      | 3699/10000 [00:16<00:29, 214.65it/s]Running 10000 simulations.:  37%|███▋      | 3721/10000 [00:16<00:29, 214.50it/s]Running 10000 simulations.:  37%|███▋      | 3743/10000 [00:16<00:29, 214.38it/s]Running 10000 simulations.:  38%|███▊      | 3765/10000 [00:16<00:29, 214.64it/s]Running 10000 simulations.:  38%|███▊      | 3787/10000 [00:16<00:29, 214.20it/s]Running 10000 simulations.:  38%|███▊      | 3809/10000 [00:16<00:28, 214.16it/s]Running 10000 simulations.:  38%|███▊      | 3831/10000 [00:16<00:28, 213.96it/s]Running 10000 simulations.:  39%|███▊      | 3853/10000 [00:17<00:28, 213.99it/s]Running 10000 simulations.:  39%|███▉      | 3875/10000 [00:17<00:28, 214.01it/s]Running 10000 simulations.:  39%|███▉      | 3897/10000 [00:17<00:28, 213.81it/s]Running 10000 simulations.:  39%|███▉      | 3919/10000 [00:17<00:28, 213.67it/s]Running 10000 simulations.:  39%|███▉      | 3941/10000 [00:17<00:28, 213.52it/s]Running 10000 simulations.:  40%|███▉      | 3963/10000 [00:17<00:28, 213.47it/s]Running 10000 simulations.:  40%|███▉      | 3985/10000 [00:17<00:28, 213.70it/s]Running 10000 simulations.:  40%|████      | 4007/10000 [00:17<00:28, 214.03it/s]Running 10000 simulations.:  40%|████      | 4029/10000 [00:17<00:27, 213.97it/s]Running 10000 simulations.:  41%|████      | 4051/10000 [00:17<00:27, 214.28it/s]Running 10000 simulations.:  41%|████      | 4073/10000 [00:18<00:27, 214.38it/s]Running 10000 simulations.:  41%|████      | 4095/10000 [00:18<00:27, 214.27it/s]Running 10000 simulations.:  41%|████      | 4117/10000 [00:18<00:27, 214.16it/s]Running 10000 simulations.:  41%|████▏     | 4139/10000 [00:18<00:27, 214.06it/s]Running 10000 simulations.:  42%|████▏     | 4161/10000 [00:18<00:27, 213.61it/s]Running 10000 simulations.:  42%|████▏     | 4183/10000 [00:18<00:27, 213.53it/s]Running 10000 simulations.:  42%|████▏     | 4205/10000 [00:18<00:27, 213.95it/s]Running 10000 simulations.:  42%|████▏     | 4227/10000 [00:18<00:26, 214.21it/s]Running 10000 simulations.:  42%|████▏     | 4249/10000 [00:18<00:26, 213.89it/s]Running 10000 simulations.:  43%|████▎     | 4271/10000 [00:19<00:26, 214.63it/s]Running 10000 simulations.:  43%|████▎     | 4293/10000 [00:19<00:26, 214.91it/s]Running 10000 simulations.:  43%|████▎     | 4315/10000 [00:19<00:26, 215.26it/s]Running 10000 simulations.:  43%|████▎     | 4337/10000 [00:19<00:26, 215.03it/s]Running 10000 simulations.:  44%|████▎     | 4359/10000 [00:19<00:26, 214.80it/s]Running 10000 simulations.:  44%|████▍     | 4381/10000 [00:19<00:26, 214.40it/s]Running 10000 simulations.:  44%|████▍     | 4403/10000 [00:19<00:26, 214.35it/s]Running 10000 simulations.:  44%|████▍     | 4425/10000 [00:19<00:26, 214.09it/s]Running 10000 simulations.:  44%|████▍     | 4447/10000 [00:19<00:25, 213.84it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:19<00:25, 213.81it/s]Running 10000 simulations.:  45%|████▍     | 4491/10000 [00:20<00:25, 214.30it/s]Running 10000 simulations.:  45%|████▌     | 4513/10000 [00:20<00:25, 214.52it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:20<00:25, 214.48it/s]Running 10000 simulations.:  46%|████▌     | 4557/10000 [00:20<00:25, 214.61it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:20<00:25, 214.38it/s]Running 10000 simulations.:  46%|████▌     | 4601/10000 [00:20<00:25, 213.78it/s]Running 10000 simulations.:  46%|████▌     | 4623/10000 [00:20<00:25, 213.69it/s]Running 10000 simulations.:  46%|████▋     | 4645/10000 [00:20<00:25, 213.71it/s]Running 10000 simulations.:  47%|████▋     | 4667/10000 [00:20<00:24, 213.66it/s]Running 10000 simulations.:  47%|████▋     | 4689/10000 [00:20<00:24, 213.44it/s]Running 10000 simulations.:  47%|████▋     | 4711/10000 [00:21<00:24, 213.50it/s]Running 10000 simulations.:  47%|████▋     | 4733/10000 [00:21<00:24, 213.34it/s]Running 10000 simulations.:  48%|████▊     | 4755/10000 [00:21<00:24, 213.59it/s]Running 10000 simulations.:  48%|████▊     | 4777/10000 [00:21<00:24, 213.79it/s]Running 10000 simulations.:  48%|████▊     | 4799/10000 [00:21<00:24, 213.75it/s]Running 10000 simulations.:  48%|████▊     | 4821/10000 [00:21<00:24, 213.79it/s]Running 10000 simulations.:  48%|████▊     | 4843/10000 [00:21<00:24, 213.45it/s]Running 10000 simulations.:  49%|████▊     | 4865/10000 [00:21<00:24, 213.20it/s]Running 10000 simulations.:  49%|████▉     | 4887/10000 [00:21<00:23, 213.05it/s]Running 10000 simulations.:  49%|████▉     | 4909/10000 [00:21<00:23, 213.15it/s]Running 10000 simulations.:  49%|████▉     | 4931/10000 [00:22<00:23, 213.33it/s]Running 10000 simulations.:  50%|████▉     | 4953/10000 [00:22<00:23, 212.90it/s]Running 10000 simulations.:  50%|████▉     | 4975/10000 [00:22<00:23, 212.92it/s]Running 10000 simulations.:  50%|████▉     | 4997/10000 [00:22<00:23, 212.97it/s]Running 10000 simulations.:  50%|█████     | 5019/10000 [00:22<00:23, 213.15it/s]Running 10000 simulations.:  50%|█████     | 5041/10000 [00:22<00:23, 213.04it/s]Running 10000 simulations.:  51%|█████     | 5063/10000 [00:22<00:23, 212.97it/s]Running 10000 simulations.:  51%|█████     | 5085/10000 [00:22<00:23, 212.90it/s]Running 10000 simulations.:  51%|█████     | 5107/10000 [00:22<00:22, 213.05it/s]Running 10000 simulations.:  51%|█████▏    | 5129/10000 [00:23<00:22, 213.19it/s]Running 10000 simulations.:  52%|█████▏    | 5151/10000 [00:23<00:22, 213.44it/s]Running 10000 simulations.:  52%|█████▏    | 5173/10000 [00:23<00:22, 213.62it/s]Running 10000 simulations.:  52%|█████▏    | 5195/10000 [00:23<00:22, 213.77it/s]Running 10000 simulations.:  52%|█████▏    | 5217/10000 [00:23<00:22, 213.72it/s]Running 10000 simulations.:  52%|█████▏    | 5239/10000 [00:23<00:22, 213.60it/s]Running 10000 simulations.:  53%|█████▎    | 5261/10000 [00:23<00:22, 213.48it/s]Running 10000 simulations.:  53%|█████▎    | 5283/10000 [00:23<00:22, 213.54it/s]Running 10000 simulations.:  53%|█████▎    | 5305/10000 [00:23<00:22, 212.77it/s]Running 10000 simulations.:  53%|█████▎    | 5327/10000 [00:23<00:22, 212.13it/s]Running 10000 simulations.:  53%|█████▎    | 5349/10000 [00:24<00:21, 213.11it/s]Running 10000 simulations.:  54%|█████▎    | 5371/10000 [00:24<00:21, 212.96it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:24<00:21, 215.44it/s]Running 10000 simulations.:  54%|█████▍    | 5418/10000 [00:24<00:20, 220.56it/s]Running 10000 simulations.:  54%|█████▍    | 5442/10000 [00:24<00:20, 224.34it/s]Running 10000 simulations.:  55%|█████▍    | 5466/10000 [00:24<00:20, 226.39it/s]Running 10000 simulations.:  55%|█████▍    | 5490/10000 [00:24<00:19, 227.91it/s]Running 10000 simulations.:  55%|█████▌    | 5513/10000 [00:24<00:19, 228.46it/s]Running 10000 simulations.:  55%|█████▌    | 5537/10000 [00:24<00:19, 229.35it/s]Running 10000 simulations.:  56%|█████▌    | 5561/10000 [00:24<00:19, 230.64it/s]Running 10000 simulations.:  56%|█████▌    | 5585/10000 [00:25<00:19, 231.59it/s]Running 10000 simulations.:  56%|█████▌    | 5609/10000 [00:25<00:18, 232.36it/s]Running 10000 simulations.:  56%|█████▋    | 5633/10000 [00:25<00:18, 232.84it/s]Running 10000 simulations.:  57%|█████▋    | 5657/10000 [00:25<00:18, 229.64it/s]Running 10000 simulations.:  57%|█████▋    | 5680/10000 [00:25<00:18, 227.51it/s]Running 10000 simulations.:  57%|█████▋    | 5703/10000 [00:25<00:19, 226.08it/s]Running 10000 simulations.:  57%|█████▋    | 5726/10000 [00:25<00:19, 224.91it/s]Running 10000 simulations.:  57%|█████▋    | 5749/10000 [00:25<00:18, 224.12it/s]Running 10000 simulations.:  58%|█████▊    | 5772/10000 [00:25<00:18, 223.74it/s]Running 10000 simulations.:  58%|█████▊    | 5795/10000 [00:26<00:18, 223.41it/s]Running 10000 simulations.:  58%|█████▊    | 5818/10000 [00:26<00:18, 223.34it/s]Running 10000 simulations.:  58%|█████▊    | 5841/10000 [00:26<00:18, 223.09it/s]Running 10000 simulations.:  59%|█████▊    | 5864/10000 [00:26<00:18, 223.77it/s]Running 10000 simulations.:  59%|█████▉    | 5887/10000 [00:26<00:18, 223.56it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:26<00:18, 223.91it/s]Running 10000 simulations.:  59%|█████▉    | 5933/10000 [00:26<00:18, 223.70it/s]Running 10000 simulations.:  60%|█████▉    | 5956/10000 [00:26<00:18, 223.64it/s]Running 10000 simulations.:  60%|█████▉    | 5979/10000 [00:26<00:18, 223.37it/s]Running 10000 simulations.:  60%|██████    | 6002/10000 [00:26<00:17, 223.01it/s]Running 10000 simulations.:  60%|██████    | 6025/10000 [00:27<00:17, 223.12it/s]Running 10000 simulations.:  60%|██████    | 6048/10000 [00:27<00:17, 223.35it/s]Running 10000 simulations.:  61%|██████    | 6071/10000 [00:27<00:18, 215.85it/s]Running 10000 simulations.:  61%|██████    | 6094/10000 [00:27<00:17, 218.87it/s]Running 10000 simulations.:  61%|██████    | 6117/10000 [00:27<00:17, 221.06it/s]Running 10000 simulations.:  61%|██████▏   | 6140/10000 [00:27<00:17, 221.98it/s]Running 10000 simulations.:  62%|██████▏   | 6163/10000 [00:27<00:17, 222.02it/s]Running 10000 simulations.:  62%|██████▏   | 6186/10000 [00:27<00:17, 222.32it/s]Running 10000 simulations.:  62%|██████▏   | 6209/10000 [00:27<00:17, 222.39it/s]Running 10000 simulations.:  62%|██████▏   | 6232/10000 [00:27<00:17, 219.02it/s]Running 10000 simulations.:  63%|██████▎   | 6255/10000 [00:28<00:17, 219.74it/s]Running 10000 simulations.:  63%|██████▎   | 6278/10000 [00:28<00:16, 220.43it/s]Running 10000 simulations.:  63%|██████▎   | 6301/10000 [00:28<00:16, 220.67it/s]Running 10000 simulations.:  63%|██████▎   | 6324/10000 [00:28<00:16, 220.86it/s]Running 10000 simulations.:  63%|██████▎   | 6347/10000 [00:28<00:16, 220.99it/s]Running 10000 simulations.:  64%|██████▎   | 6370/10000 [00:28<00:16, 221.05it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:28<00:16, 221.23it/s]Running 10000 simulations.:  64%|██████▍   | 6416/10000 [00:28<00:16, 221.56it/s]Running 10000 simulations.:  64%|██████▍   | 6439/10000 [00:28<00:16, 221.60it/s]Running 10000 simulations.:  65%|██████▍   | 6462/10000 [00:29<00:15, 221.56it/s]Running 10000 simulations.:  65%|██████▍   | 6485/10000 [00:29<00:15, 221.52it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:29<00:15, 221.57it/s]Running 10000 simulations.:  65%|██████▌   | 6531/10000 [00:29<00:15, 221.77it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:29<00:15, 221.71it/s]Running 10000 simulations.:  66%|██████▌   | 6577/10000 [00:29<00:15, 221.83it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:29<00:15, 222.05it/s]Running 10000 simulations.:  66%|██████▌   | 6623/10000 [00:29<00:15, 221.94it/s]Running 10000 simulations.:  66%|██████▋   | 6646/10000 [00:29<00:15, 221.78it/s]Running 10000 simulations.:  67%|██████▋   | 6669/10000 [00:29<00:15, 221.59it/s]Running 10000 simulations.:  67%|██████▋   | 6692/10000 [00:30<00:14, 221.51it/s]Running 10000 simulations.:  67%|██████▋   | 6715/10000 [00:30<00:14, 221.50it/s]Running 10000 simulations.:  67%|██████▋   | 6738/10000 [00:30<00:14, 221.76it/s]Running 10000 simulations.:  68%|██████▊   | 6761/10000 [00:30<00:14, 221.86it/s]Running 10000 simulations.:  68%|██████▊   | 6784/10000 [00:30<00:14, 222.04it/s]Running 10000 simulations.:  68%|██████▊   | 6807/10000 [00:30<00:14, 222.09it/s]Running 10000 simulations.:  68%|██████▊   | 6830/10000 [00:30<00:14, 222.11it/s]Running 10000 simulations.:  69%|██████▊   | 6853/10000 [00:30<00:14, 223.23it/s]Running 10000 simulations.:  69%|██████▉   | 6876/10000 [00:30<00:13, 224.08it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:30<00:13, 224.29it/s]Running 10000 simulations.:  69%|██████▉   | 6922/10000 [00:31<00:13, 224.43it/s]Running 10000 simulations.:  69%|██████▉   | 6945/10000 [00:31<00:13, 223.49it/s]Running 10000 simulations.:  70%|██████▉   | 6968/10000 [00:31<00:13, 223.16it/s]Running 10000 simulations.:  70%|██████▉   | 6991/10000 [00:31<00:13, 222.88it/s]Running 10000 simulations.:  70%|███████   | 7014/10000 [00:31<00:13, 223.15it/s]Running 10000 simulations.:  70%|███████   | 7037/10000 [00:31<00:13, 223.54it/s]Running 10000 simulations.:  71%|███████   | 7060/10000 [00:31<00:13, 223.46it/s]Running 10000 simulations.:  71%|███████   | 7083/10000 [00:31<00:13, 223.03it/s]Running 10000 simulations.:  71%|███████   | 7106/10000 [00:31<00:12, 222.83it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:32<00:12, 222.64it/s]Running 10000 simulations.:  72%|███████▏  | 7152/10000 [00:32<00:12, 222.85it/s]Running 10000 simulations.:  72%|███████▏  | 7175/10000 [00:32<00:12, 222.44it/s]Running 10000 simulations.:  72%|███████▏  | 7198/10000 [00:32<00:12, 221.52it/s]Running 10000 simulations.:  72%|███████▏  | 7221/10000 [00:32<00:12, 221.53it/s]Running 10000 simulations.:  72%|███████▏  | 7244/10000 [00:32<00:12, 221.61it/s]Running 10000 simulations.:  73%|███████▎  | 7267/10000 [00:32<00:12, 221.82it/s]Running 10000 simulations.:  73%|███████▎  | 7290/10000 [00:32<00:12, 221.88it/s]Running 10000 simulations.:  73%|███████▎  | 7313/10000 [00:32<00:12, 221.91it/s]Running 10000 simulations.:  73%|███████▎  | 7336/10000 [00:32<00:12, 221.87it/s]Running 10000 simulations.:  74%|███████▎  | 7359/10000 [00:33<00:12, 219.53it/s]Running 10000 simulations.:  74%|███████▍  | 7382/10000 [00:33<00:11, 220.10it/s]Running 10000 simulations.:  74%|███████▍  | 7405/10000 [00:33<00:11, 221.01it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:33<00:11, 223.84it/s]Running 10000 simulations.:  75%|███████▍  | 7453/10000 [00:33<00:11, 227.40it/s]Running 10000 simulations.:  75%|███████▍  | 7476/10000 [00:33<00:11, 227.40it/s]Running 10000 simulations.:  75%|███████▍  | 7499/10000 [00:33<00:10, 227.58it/s]Running 10000 simulations.:  75%|███████▌  | 7523/10000 [00:33<00:10, 229.42it/s]Running 10000 simulations.:  75%|███████▌  | 7547/10000 [00:33<00:10, 230.75it/s]Running 10000 simulations.:  76%|███████▌  | 7571/10000 [00:33<00:10, 231.39it/s]Running 10000 simulations.:  76%|███████▌  | 7595/10000 [00:34<00:10, 231.04it/s]Running 10000 simulations.:  76%|███████▌  | 7619/10000 [00:34<00:10, 229.76it/s]Running 10000 simulations.:  76%|███████▋  | 7643/10000 [00:34<00:10, 229.69it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:34<00:10, 226.14it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:34<00:10, 224.48it/s]Running 10000 simulations.:  77%|███████▋  | 7712/10000 [00:34<00:10, 223.47it/s]Running 10000 simulations.:  77%|███████▋  | 7735/10000 [00:34<00:10, 222.69it/s]Running 10000 simulations.:  78%|███████▊  | 7758/10000 [00:34<00:10, 222.09it/s]Running 10000 simulations.:  78%|███████▊  | 7781/10000 [00:34<00:09, 222.20it/s]Running 10000 simulations.:  78%|███████▊  | 7804/10000 [00:35<00:09, 222.33it/s]Running 10000 simulations.:  78%|███████▊  | 7827/10000 [00:35<00:09, 222.43it/s]Running 10000 simulations.:  78%|███████▊  | 7850/10000 [00:35<00:09, 222.55it/s]Running 10000 simulations.:  79%|███████▊  | 7873/10000 [00:35<00:09, 222.51it/s]Running 10000 simulations.:  79%|███████▉  | 7896/10000 [00:35<00:09, 222.66it/s]Running 10000 simulations.:  79%|███████▉  | 7919/10000 [00:35<00:09, 222.86it/s]Running 10000 simulations.:  79%|███████▉  | 7942/10000 [00:35<00:09, 222.70it/s]Running 10000 simulations.:  80%|███████▉  | 7965/10000 [00:35<00:09, 218.54it/s]Running 10000 simulations.:  80%|███████▉  | 7987/10000 [00:35<00:09, 215.26it/s]Running 10000 simulations.:  80%|████████  | 8009/10000 [00:35<00:09, 213.18it/s]Running 10000 simulations.:  80%|████████  | 8031/10000 [00:36<00:09, 211.49it/s]Running 10000 simulations.:  81%|████████  | 8053/10000 [00:36<00:14, 138.75it/s]Running 10000 simulations.:  81%|████████  | 8074/10000 [00:36<00:12, 154.06it/s]Running 10000 simulations.:  81%|████████  | 8095/10000 [00:36<00:11, 167.03it/s]Running 10000 simulations.:  81%|████████  | 8116/10000 [00:36<00:10, 177.26it/s]Running 10000 simulations.:  81%|████████▏ | 8137/10000 [00:36<00:10, 185.26it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:36<00:09, 191.09it/s]Running 10000 simulations.:  82%|████████▏ | 8179/10000 [00:36<00:09, 195.40it/s]Running 10000 simulations.:  82%|████████▏ | 8200/10000 [00:37<00:09, 199.00it/s]Running 10000 simulations.:  82%|████████▏ | 8221/10000 [00:37<00:08, 201.24it/s]Running 10000 simulations.:  82%|████████▏ | 8242/10000 [00:37<00:08, 202.93it/s]Running 10000 simulations.:  83%|████████▎ | 8263/10000 [00:37<00:08, 203.93it/s]Running 10000 simulations.:  83%|████████▎ | 8284/10000 [00:37<00:08, 204.42it/s]Running 10000 simulations.:  83%|████████▎ | 8305/10000 [00:37<00:08, 205.30it/s]Running 10000 simulations.:  83%|████████▎ | 8327/10000 [00:37<00:08, 206.82it/s]Running 10000 simulations.:  83%|████████▎ | 8349/10000 [00:37<00:07, 208.08it/s]Running 10000 simulations.:  84%|████████▎ | 8370/10000 [00:37<00:07, 207.22it/s]Running 10000 simulations.:  84%|████████▍ | 8391/10000 [00:37<00:07, 206.96it/s]Running 10000 simulations.:  84%|████████▍ | 8412/10000 [00:38<00:07, 206.26it/s]Running 10000 simulations.:  84%|████████▍ | 8433/10000 [00:38<00:07, 204.99it/s]Running 10000 simulations.:  85%|████████▍ | 8454/10000 [00:38<00:07, 204.27it/s]Running 10000 simulations.:  85%|████████▍ | 8475/10000 [00:38<00:07, 203.83it/s]Running 10000 simulations.:  85%|████████▍ | 8496/10000 [00:38<00:07, 203.58it/s]Running 10000 simulations.:  85%|████████▌ | 8517/10000 [00:38<00:07, 203.17it/s]Running 10000 simulations.:  85%|████████▌ | 8538/10000 [00:38<00:07, 203.34it/s]Running 10000 simulations.:  86%|████████▌ | 8559/10000 [00:38<00:07, 202.97it/s]Running 10000 simulations.:  86%|████████▌ | 8580/10000 [00:38<00:06, 202.99it/s]Running 10000 simulations.:  86%|████████▌ | 8601/10000 [00:39<00:06, 202.69it/s]Running 10000 simulations.:  86%|████████▌ | 8622/10000 [00:39<00:06, 202.10it/s]Running 10000 simulations.:  86%|████████▋ | 8643/10000 [00:39<00:06, 202.21it/s]Running 10000 simulations.:  87%|████████▋ | 8664/10000 [00:39<00:06, 202.31it/s]Running 10000 simulations.:  87%|████████▋ | 8685/10000 [00:39<00:06, 201.99it/s]Running 10000 simulations.:  87%|████████▋ | 8707/10000 [00:39<00:06, 206.17it/s]Running 10000 simulations.:  87%|████████▋ | 8730/10000 [00:39<00:06, 211.03it/s]Running 10000 simulations.:  88%|████████▊ | 8753/10000 [00:39<00:05, 214.99it/s]Running 10000 simulations.:  88%|████████▊ | 8776/10000 [00:39<00:05, 217.96it/s]Running 10000 simulations.:  88%|████████▊ | 8799/10000 [00:39<00:05, 219.91it/s]Running 10000 simulations.:  88%|████████▊ | 8822/10000 [00:40<00:05, 220.96it/s]Running 10000 simulations.:  88%|████████▊ | 8845/10000 [00:40<00:05, 221.49it/s]Running 10000 simulations.:  89%|████████▊ | 8868/10000 [00:40<00:05, 221.80it/s]Running 10000 simulations.:  89%|████████▉ | 8891/10000 [00:40<00:04, 222.33it/s]Running 10000 simulations.:  89%|████████▉ | 8914/10000 [00:40<00:04, 223.15it/s]Running 10000 simulations.:  89%|████████▉ | 8937/10000 [00:40<00:04, 223.91it/s]Running 10000 simulations.:  90%|████████▉ | 8960/10000 [00:40<00:04, 224.89it/s]Running 10000 simulations.:  90%|████████▉ | 8983/10000 [00:40<00:04, 225.60it/s]Running 10000 simulations.:  90%|█████████ | 9006/10000 [00:40<00:04, 225.30it/s]Running 10000 simulations.:  90%|█████████ | 9029/10000 [00:40<00:04, 225.68it/s]Running 10000 simulations.:  91%|█████████ | 9052/10000 [00:41<00:04, 225.61it/s]Running 10000 simulations.:  91%|█████████ | 9075/10000 [00:41<00:04, 225.24it/s]Running 10000 simulations.:  91%|█████████ | 9098/10000 [00:41<00:04, 225.32it/s]Running 10000 simulations.:  91%|█████████ | 9121/10000 [00:41<00:03, 226.01it/s]Running 10000 simulations.:  91%|█████████▏| 9144/10000 [00:41<00:03, 225.56it/s]Running 10000 simulations.:  92%|█████████▏| 9167/10000 [00:41<00:03, 225.88it/s]Running 10000 simulations.:  92%|█████████▏| 9190/10000 [00:41<00:03, 225.61it/s]Running 10000 simulations.:  92%|█████████▏| 9213/10000 [00:41<00:03, 225.61it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [00:41<00:03, 225.12it/s]Running 10000 simulations.:  93%|█████████▎| 9259/10000 [00:41<00:03, 224.53it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [00:42<00:03, 224.29it/s]Running 10000 simulations.:  93%|█████████▎| 9305/10000 [00:42<00:03, 224.02it/s]Running 10000 simulations.:  93%|█████████▎| 9328/10000 [00:42<00:03, 223.66it/s]Running 10000 simulations.:  94%|█████████▎| 9351/10000 [00:42<00:02, 224.55it/s]Running 10000 simulations.:  94%|█████████▎| 9374/10000 [00:42<00:02, 225.43it/s]Running 10000 simulations.:  94%|█████████▍| 9397/10000 [00:42<00:02, 226.01it/s]Running 10000 simulations.:  94%|█████████▍| 9420/10000 [00:42<00:02, 225.99it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [00:42<00:02, 225.04it/s]Running 10000 simulations.:  95%|█████████▍| 9466/10000 [00:42<00:02, 224.35it/s]Running 10000 simulations.:  95%|█████████▍| 9489/10000 [00:43<00:02, 224.44it/s]Running 10000 simulations.:  95%|█████████▌| 9512/10000 [00:43<00:02, 224.51it/s]Running 10000 simulations.:  95%|█████████▌| 9535/10000 [00:43<00:02, 225.14it/s]Running 10000 simulations.:  96%|█████████▌| 9558/10000 [00:43<00:01, 225.05it/s]Running 10000 simulations.:  96%|█████████▌| 9581/10000 [00:43<00:01, 225.63it/s]Running 10000 simulations.:  96%|█████████▌| 9604/10000 [00:43<00:01, 225.85it/s]Running 10000 simulations.:  96%|█████████▋| 9627/10000 [00:43<00:01, 226.00it/s]Running 10000 simulations.:  96%|█████████▋| 9650/10000 [00:43<00:01, 226.43it/s]Running 10000 simulations.:  97%|█████████▋| 9673/10000 [00:43<00:01, 227.13it/s]Running 10000 simulations.:  97%|█████████▋| 9696/10000 [00:43<00:01, 226.97it/s]Running 10000 simulations.:  97%|█████████▋| 9719/10000 [00:44<00:01, 225.93it/s]Running 10000 simulations.:  97%|█████████▋| 9742/10000 [00:44<00:01, 220.66it/s]Running 10000 simulations.:  98%|█████████▊| 9765/10000 [00:44<00:01, 221.48it/s]Running 10000 simulations.:  98%|█████████▊| 9788/10000 [00:44<00:00, 222.18it/s]Running 10000 simulations.:  98%|█████████▊| 9811/10000 [00:44<00:00, 222.53it/s]Running 10000 simulations.:  98%|█████████▊| 9834/10000 [00:44<00:00, 223.23it/s]Running 10000 simulations.:  99%|█████████▊| 9857/10000 [00:44<00:00, 223.64it/s]Running 10000 simulations.:  99%|█████████▉| 9880/10000 [00:44<00:00, 224.10it/s]Running 10000 simulations.:  99%|█████████▉| 9903/10000 [00:44<00:00, 225.23it/s]Running 10000 simulations.:  99%|█████████▉| 9926/10000 [00:44<00:00, 226.31it/s]Running 10000 simulations.:  99%|█████████▉| 9949/10000 [00:45<00:00, 225.71it/s]Running 10000 simulations.: 100%|█████████▉| 9972/10000 [00:45<00:00, 226.33it/s]Running 10000 simulations.: 100%|█████████▉| 9995/10000 [00:45<00:00, 226.88it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:45<00:00, 220.80it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:08, 146.33it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<01:08, 146.31it/s]Running 10000 simulations.:   0%|          | 45/10000 [00:00<01:08, 145.82it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<01:08, 145.29it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<01:08, 145.13it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<01:08, 145.58it/s]Running 10000 simulations.:   1%|          | 105/10000 [00:00<01:07, 146.30it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<01:08, 145.10it/s]Running 10000 simulations.:   1%|▏         | 135/10000 [00:00<01:07, 145.10it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:01<01:07, 145.46it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:01<01:07, 145.75it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:01<01:07, 146.35it/s]Running 10000 simulations.:   2%|▏         | 195/10000 [00:01<01:06, 146.49it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:01<01:06, 146.84it/s]Running 10000 simulations.:   2%|▏         | 225/10000 [00:01<01:06, 146.75it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:01<01:10, 139.18it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<01:09, 140.60it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:01<01:08, 141.87it/s]Running 10000 simulations.:   3%|▎         | 285/10000 [00:01<01:07, 143.07it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:02<01:07, 143.60it/s]Running 10000 simulations.:   3%|▎         | 315/10000 [00:02<01:07, 144.20it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:02<01:06, 144.36it/s]Running 10000 simulations.:   3%|▎         | 345/10000 [00:02<01:06, 144.43it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:02<01:06, 144.10it/s]Running 10000 simulations.:   4%|▍         | 375/10000 [00:02<01:06, 144.21it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:02<01:06, 144.91it/s]Running 10000 simulations.:   4%|▍         | 405/10000 [00:02<01:06, 145.33it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:02<01:05, 145.59it/s]Running 10000 simulations.:   4%|▍         | 435/10000 [00:03<01:05, 145.53it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:03<01:05, 145.00it/s]Running 10000 simulations.:   5%|▍         | 465/10000 [00:03<01:05, 144.78it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:03<01:05, 144.29it/s]Running 10000 simulations.:   5%|▍         | 495/10000 [00:03<01:05, 144.07it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:03<01:06, 143.37it/s]Running 10000 simulations.:   5%|▌         | 525/10000 [00:03<01:06, 142.54it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:03<01:06, 142.67it/s]Running 10000 simulations.:   6%|▌         | 555/10000 [00:03<01:06, 142.80it/s]Running 10000 simulations.:   6%|▌         | 570/10000 [00:03<01:05, 143.01it/s]Running 10000 simulations.:   6%|▌         | 585/10000 [00:04<01:05, 143.03it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:04<01:05, 142.80it/s]Running 10000 simulations.:   6%|▌         | 615/10000 [00:04<01:05, 142.76it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:04<01:05, 142.95it/s]Running 10000 simulations.:   6%|▋         | 645/10000 [00:04<01:05, 143.15it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:04<01:05, 143.02it/s]Running 10000 simulations.:   7%|▋         | 675/10000 [00:04<01:05, 142.94it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:04<01:05, 142.96it/s]Running 10000 simulations.:   7%|▋         | 705/10000 [00:04<01:05, 142.85it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:04<01:04, 143.14it/s]Running 10000 simulations.:   7%|▋         | 735/10000 [00:05<01:04, 142.84it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:05<01:04, 142.90it/s]Running 10000 simulations.:   8%|▊         | 765/10000 [00:05<01:04, 143.26it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:05<01:04, 143.35it/s]Running 10000 simulations.:   8%|▊         | 795/10000 [00:05<01:04, 143.22it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:05<01:04, 143.02it/s]Running 10000 simulations.:   8%|▊         | 825/10000 [00:05<01:04, 142.98it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:05<01:03, 143.37it/s]Running 10000 simulations.:   9%|▊         | 855/10000 [00:05<01:03, 143.10it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:06<01:03, 143.42it/s]Running 10000 simulations.:   9%|▉         | 885/10000 [00:06<01:03, 143.21it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:06<01:03, 142.81it/s]Running 10000 simulations.:   9%|▉         | 915/10000 [00:06<01:03, 142.96it/s]Running 10000 simulations.:   9%|▉         | 930/10000 [00:06<01:03, 142.66it/s]Running 10000 simulations.:   9%|▉         | 945/10000 [00:06<01:03, 142.63it/s]Running 10000 simulations.:  10%|▉         | 960/10000 [00:06<01:03, 142.95it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:06<01:03, 143.08it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:06<01:03, 142.84it/s]Running 10000 simulations.:  10%|█         | 1005/10000 [00:06<01:02, 142.85it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:07<01:02, 142.95it/s]Running 10000 simulations.:  10%|█         | 1035/10000 [00:07<01:02, 142.64it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:07<01:02, 142.83it/s]Running 10000 simulations.:  11%|█         | 1065/10000 [00:07<01:02, 142.69it/s]Running 10000 simulations.:  11%|█         | 1080/10000 [00:07<01:02, 142.55it/s]Running 10000 simulations.:  11%|█         | 1095/10000 [00:07<01:02, 142.13it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:07<01:02, 142.20it/s]Running 10000 simulations.:  11%|█▏        | 1125/10000 [00:07<01:02, 142.42it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:07<01:02, 142.63it/s]Running 10000 simulations.:  12%|█▏        | 1155/10000 [00:08<01:02, 142.41it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:08<01:01, 142.53it/s]Running 10000 simulations.:  12%|█▏        | 1185/10000 [00:08<01:01, 142.63it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:08<01:01, 142.39it/s]Running 10000 simulations.:  12%|█▏        | 1215/10000 [00:08<01:01, 142.29it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:08<01:01, 141.62it/s]Running 10000 simulations.:  12%|█▏        | 1245/10000 [00:08<01:01, 142.09it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:08<01:01, 142.42it/s]Running 10000 simulations.:  13%|█▎        | 1275/10000 [00:08<01:00, 143.17it/s]Running 10000 simulations.:  13%|█▎        | 1290/10000 [00:08<01:00, 143.43it/s]Running 10000 simulations.:  13%|█▎        | 1305/10000 [00:09<01:00, 143.57it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:09<01:00, 143.38it/s]Running 10000 simulations.:  13%|█▎        | 1335/10000 [00:09<01:00, 143.43it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:09<01:00, 143.31it/s]Running 10000 simulations.:  14%|█▎        | 1365/10000 [00:09<01:00, 143.43it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:09<01:00, 143.49it/s]Running 10000 simulations.:  14%|█▍        | 1395/10000 [00:09<00:59, 143.96it/s]Running 10000 simulations.:  14%|█▍        | 1410/10000 [00:09<00:59, 143.92it/s]Running 10000 simulations.:  14%|█▍        | 1425/10000 [00:09<00:59, 144.41it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:10<00:59, 144.29it/s]Running 10000 simulations.:  15%|█▍        | 1455/10000 [00:10<00:59, 144.37it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:10<00:59, 143.82it/s]Running 10000 simulations.:  15%|█▍        | 1485/10000 [00:10<00:59, 143.82it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:10<00:59, 143.63it/s]Running 10000 simulations.:  15%|█▌        | 1515/10000 [00:10<00:59, 143.44it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:10<00:59, 143.45it/s]Running 10000 simulations.:  15%|█▌        | 1545/10000 [00:10<00:58, 143.65it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:10<00:58, 143.86it/s]Running 10000 simulations.:  16%|█▌        | 1575/10000 [00:10<00:58, 143.97it/s]Running 10000 simulations.:  16%|█▌        | 1590/10000 [00:11<00:58, 143.89it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:11<00:58, 143.67it/s]Running 10000 simulations.:  16%|█▌        | 1620/10000 [00:11<00:58, 143.85it/s]Running 10000 simulations.:  16%|█▋        | 1635/10000 [00:11<00:57, 144.28it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:11<00:57, 144.72it/s]Running 10000 simulations.:  17%|█▋        | 1665/10000 [00:11<00:57, 144.76it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:11<00:57, 144.68it/s]Running 10000 simulations.:  17%|█▋        | 1695/10000 [00:11<00:57, 144.29it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:11<00:57, 144.18it/s]Running 10000 simulations.:  17%|█▋        | 1725/10000 [00:12<00:57, 143.74it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:12<00:57, 143.35it/s]Running 10000 simulations.:  18%|█▊        | 1755/10000 [00:12<00:57, 143.17it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:12<00:57, 142.86it/s]Running 10000 simulations.:  18%|█▊        | 1785/10000 [00:12<00:57, 143.03it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:12<00:57, 143.09it/s]Running 10000 simulations.:  18%|█▊        | 1815/10000 [00:12<00:57, 142.81it/s]Running 10000 simulations.:  18%|█▊        | 1830/10000 [00:12<00:57, 142.98it/s]Running 10000 simulations.:  18%|█▊        | 1845/10000 [00:12<00:56, 143.47it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:12<00:56, 143.96it/s]Running 10000 simulations.:  19%|█▉        | 1875/10000 [00:13<00:56, 144.39it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:13<00:56, 144.45it/s]Running 10000 simulations.:  19%|█▉        | 1905/10000 [00:13<00:56, 144.46it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:13<00:55, 144.66it/s]Running 10000 simulations.:  19%|█▉        | 1935/10000 [00:13<00:55, 144.84it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:13<00:55, 144.95it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:13<00:55, 144.90it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:13<00:55, 144.30it/s]Running 10000 simulations.:  20%|█▉        | 1995/10000 [00:13<00:55, 144.40it/s]Running 10000 simulations.:  20%|██        | 2010/10000 [00:13<00:55, 144.32it/s]Running 10000 simulations.:  20%|██        | 2025/10000 [00:14<00:55, 144.28it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:14<00:55, 144.00it/s]Running 10000 simulations.:  21%|██        | 2055/10000 [00:14<00:55, 143.67it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:14<00:55, 143.72it/s]Running 10000 simulations.:  21%|██        | 2085/10000 [00:14<00:55, 143.24it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:14<00:55, 143.15it/s]Running 10000 simulations.:  21%|██        | 2115/10000 [00:14<00:55, 142.88it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:14<00:55, 142.69it/s]Running 10000 simulations.:  21%|██▏       | 2145/10000 [00:14<00:55, 142.73it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:15<00:55, 142.48it/s]Running 10000 simulations.:  22%|██▏       | 2175/10000 [00:15<00:54, 142.47it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:15<00:54, 142.50it/s]Running 10000 simulations.:  22%|██▏       | 2205/10000 [00:15<00:54, 142.54it/s]Running 10000 simulations.:  22%|██▏       | 2220/10000 [00:15<00:54, 142.78it/s]Running 10000 simulations.:  22%|██▏       | 2235/10000 [00:15<00:54, 142.73it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:15<00:54, 142.46it/s]Running 10000 simulations.:  23%|██▎       | 2265/10000 [00:15<00:54, 142.80it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:15<00:54, 142.87it/s]Running 10000 simulations.:  23%|██▎       | 2295/10000 [00:15<00:53, 142.79it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:16<00:53, 143.18it/s]Running 10000 simulations.:  23%|██▎       | 2325/10000 [00:16<00:53, 143.13it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:16<00:53, 143.67it/s]Running 10000 simulations.:  24%|██▎       | 2355/10000 [00:16<00:53, 143.36it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:16<00:53, 142.85it/s]Running 10000 simulations.:  24%|██▍       | 2385/10000 [00:16<00:53, 142.79it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:16<00:53, 142.90it/s]Running 10000 simulations.:  24%|██▍       | 2415/10000 [00:16<00:53, 142.80it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:16<00:53, 142.18it/s]Running 10000 simulations.:  24%|██▍       | 2445/10000 [00:17<00:53, 141.71it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:17<00:53, 141.85it/s]Running 10000 simulations.:  25%|██▍       | 2475/10000 [00:17<00:52, 142.14it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:17<00:52, 142.14it/s]Running 10000 simulations.:  25%|██▌       | 2505/10000 [00:17<00:52, 141.94it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:17<00:52, 142.59it/s]Running 10000 simulations.:  25%|██▌       | 2535/10000 [00:17<00:52, 142.94it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:17<00:52, 142.98it/s]Running 10000 simulations.:  26%|██▌       | 2565/10000 [00:17<00:52, 142.65it/s]Running 10000 simulations.:  26%|██▌       | 2580/10000 [00:17<00:51, 142.93it/s]Running 10000 simulations.:  26%|██▌       | 2595/10000 [00:18<00:51, 142.69it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:18<00:51, 142.60it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:18<00:51, 142.28it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:18<00:51, 142.22it/s]Running 10000 simulations.:  27%|██▋       | 2655/10000 [00:18<00:51, 142.13it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:18<00:51, 142.30it/s]Running 10000 simulations.:  27%|██▋       | 2685/10000 [00:18<00:51, 142.62it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:18<00:51, 142.56it/s]Running 10000 simulations.:  27%|██▋       | 2715/10000 [00:18<00:51, 142.53it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:19<00:51, 142.44it/s]Running 10000 simulations.:  27%|██▋       | 2745/10000 [00:19<00:50, 142.41it/s]Running 10000 simulations.:  28%|██▊       | 2760/10000 [00:19<00:50, 142.58it/s]Running 10000 simulations.:  28%|██▊       | 2775/10000 [00:19<00:50, 142.51it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:19<00:50, 142.49it/s]Running 10000 simulations.:  28%|██▊       | 2805/10000 [00:19<00:50, 142.35it/s]Running 10000 simulations.:  28%|██▊       | 2820/10000 [00:19<00:50, 142.29it/s]Running 10000 simulations.:  28%|██▊       | 2835/10000 [00:19<00:50, 142.33it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:19<00:50, 142.54it/s]Running 10000 simulations.:  29%|██▊       | 2865/10000 [00:19<00:49, 142.81it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:20<00:49, 142.58it/s]Running 10000 simulations.:  29%|██▉       | 2895/10000 [00:20<00:49, 142.91it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:20<00:49, 143.39it/s]Running 10000 simulations.:  29%|██▉       | 2925/10000 [00:20<00:49, 143.32it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:20<00:49, 143.16it/s]Running 10000 simulations.:  30%|██▉       | 2955/10000 [00:20<00:49, 143.22it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:20<00:49, 143.05it/s]Running 10000 simulations.:  30%|██▉       | 2985/10000 [00:20<00:48, 143.27it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:20<00:48, 143.31it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:21<00:48, 143.44it/s]Running 10000 simulations.:  30%|███       | 3030/10000 [00:21<00:48, 143.03it/s]Running 10000 simulations.:  30%|███       | 3045/10000 [00:21<00:48, 143.01it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:21<00:48, 142.85it/s]Running 10000 simulations.:  31%|███       | 3075/10000 [00:21<00:48, 142.49it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:21<00:48, 142.48it/s]Running 10000 simulations.:  31%|███       | 3105/10000 [00:21<00:48, 143.23it/s]Running 10000 simulations.:  31%|███       | 3120/10000 [00:21<00:47, 144.00it/s]Running 10000 simulations.:  31%|███▏      | 3135/10000 [00:21<00:47, 143.82it/s]Running 10000 simulations.:  32%|███▏      | 3150/10000 [00:21<00:47, 144.07it/s]Running 10000 simulations.:  32%|███▏      | 3165/10000 [00:22<00:47, 143.66it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:22<00:47, 143.78it/s]Running 10000 simulations.:  32%|███▏      | 3195/10000 [00:22<00:47, 144.23it/s]Running 10000 simulations.:  32%|███▏      | 3210/10000 [00:22<00:46, 144.57it/s]Running 10000 simulations.:  32%|███▏      | 3225/10000 [00:22<00:46, 144.73it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:22<00:46, 144.19it/s]Running 10000 simulations.:  33%|███▎      | 3255/10000 [00:22<00:46, 144.04it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:22<00:46, 144.59it/s]Running 10000 simulations.:  33%|███▎      | 3285/10000 [00:22<00:46, 144.80it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:23<00:46, 144.58it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:23<00:46, 144.90it/s]Running 10000 simulations.:  33%|███▎      | 3330/10000 [00:23<00:45, 145.06it/s]Running 10000 simulations.:  33%|███▎      | 3345/10000 [00:23<00:46, 144.56it/s]Running 10000 simulations.:  34%|███▎      | 3360/10000 [00:23<00:46, 144.19it/s]Running 10000 simulations.:  34%|███▍      | 3375/10000 [00:23<00:45, 144.29it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:23<00:45, 144.19it/s]Running 10000 simulations.:  34%|███▍      | 3405/10000 [00:23<00:45, 144.15it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:23<00:45, 144.40it/s]Running 10000 simulations.:  34%|███▍      | 3435/10000 [00:23<00:45, 144.67it/s]Running 10000 simulations.:  34%|███▍      | 3450/10000 [00:24<00:45, 144.83it/s]Running 10000 simulations.:  35%|███▍      | 3465/10000 [00:24<00:45, 144.96it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:24<00:44, 145.01it/s]Running 10000 simulations.:  35%|███▍      | 3495/10000 [00:24<00:44, 144.98it/s]Running 10000 simulations.:  35%|███▌      | 3510/10000 [00:24<00:44, 144.67it/s]Running 10000 simulations.:  35%|███▌      | 3525/10000 [00:24<00:44, 144.23it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:24<00:44, 144.11it/s]Running 10000 simulations.:  36%|███▌      | 3555/10000 [00:24<00:44, 143.98it/s]Running 10000 simulations.:  36%|███▌      | 3570/10000 [00:24<00:44, 143.97it/s]Running 10000 simulations.:  36%|███▌      | 3585/10000 [00:24<00:44, 144.33it/s]Running 10000 simulations.:  36%|███▌      | 3600/10000 [00:25<00:44, 144.30it/s]Running 10000 simulations.:  36%|███▌      | 3615/10000 [00:25<00:44, 144.25it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:25<00:44, 144.28it/s]Running 10000 simulations.:  36%|███▋      | 3645/10000 [00:25<00:44, 144.02it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:25<00:44, 143.90it/s]Running 10000 simulations.:  37%|███▋      | 3675/10000 [00:25<00:43, 143.83it/s]Running 10000 simulations.:  37%|███▋      | 3690/10000 [00:25<00:43, 143.76it/s]Running 10000 simulations.:  37%|███▋      | 3705/10000 [00:25<00:43, 143.59it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:25<00:43, 143.86it/s]Running 10000 simulations.:  37%|███▋      | 3735/10000 [00:26<00:43, 143.54it/s]Running 10000 simulations.:  38%|███▊      | 3750/10000 [00:26<00:43, 143.33it/s]Running 10000 simulations.:  38%|███▊      | 3765/10000 [00:26<00:43, 143.39it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:26<00:43, 143.30it/s]Running 10000 simulations.:  38%|███▊      | 3795/10000 [00:26<00:43, 143.51it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:26<00:43, 143.31it/s]Running 10000 simulations.:  38%|███▊      | 3825/10000 [00:26<00:43, 143.13it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:26<00:42, 143.33it/s]Running 10000 simulations.:  39%|███▊      | 3855/10000 [00:26<00:42, 143.70it/s]Running 10000 simulations.:  39%|███▊      | 3870/10000 [00:26<00:42, 143.99it/s]Running 10000 simulations.:  39%|███▉      | 3885/10000 [00:27<00:42, 144.51it/s]Running 10000 simulations.:  39%|███▉      | 3900/10000 [00:27<00:42, 144.45it/s]Running 10000 simulations.:  39%|███▉      | 3915/10000 [00:27<00:42, 144.25it/s]Running 10000 simulations.:  39%|███▉      | 3930/10000 [00:27<00:42, 143.87it/s]Running 10000 simulations.:  39%|███▉      | 3945/10000 [00:27<00:42, 143.10it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:27<00:42, 143.07it/s]Running 10000 simulations.:  40%|███▉      | 3975/10000 [00:27<00:42, 143.26it/s]Running 10000 simulations.:  40%|███▉      | 3990/10000 [00:27<00:41, 143.28it/s]Running 10000 simulations.:  40%|████      | 4005/10000 [00:27<00:41, 143.79it/s]Running 10000 simulations.:  40%|████      | 4020/10000 [00:28<00:41, 143.81it/s]Running 10000 simulations.:  40%|████      | 4035/10000 [00:28<00:41, 143.62it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:28<00:41, 143.50it/s]Running 10000 simulations.:  41%|████      | 4065/10000 [00:28<00:41, 143.34it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:28<00:41, 142.97it/s]Running 10000 simulations.:  41%|████      | 4095/10000 [00:28<00:41, 142.83it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:28<00:41, 142.75it/s]Running 10000 simulations.:  41%|████▏     | 4125/10000 [00:28<00:41, 142.96it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:28<00:40, 143.30it/s]Running 10000 simulations.:  42%|████▏     | 4155/10000 [00:28<00:40, 142.85it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:29<00:41, 141.99it/s]Running 10000 simulations.:  42%|████▏     | 4185/10000 [00:29<00:40, 142.06it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:29<00:40, 142.55it/s]Running 10000 simulations.:  42%|████▏     | 4215/10000 [00:29<00:40, 142.95it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:29<00:40, 143.31it/s]Running 10000 simulations.:  42%|████▏     | 4245/10000 [00:29<00:40, 143.66it/s]Running 10000 simulations.:  43%|████▎     | 4260/10000 [00:29<00:39, 144.07it/s]Running 10000 simulations.:  43%|████▎     | 4275/10000 [00:29<00:39, 143.61it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:29<00:39, 142.82it/s]Running 10000 simulations.:  43%|████▎     | 4305/10000 [00:30<00:40, 141.42it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:30<00:40, 140.10it/s]Running 10000 simulations.:  43%|████▎     | 4335/10000 [00:30<00:40, 140.10it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:30<00:40, 140.04it/s]Running 10000 simulations.:  44%|████▎     | 4365/10000 [00:30<00:40, 139.94it/s]Running 10000 simulations.:  44%|████▍     | 4379/10000 [00:30<00:40, 139.67it/s]Running 10000 simulations.:  44%|████▍     | 4393/10000 [00:30<00:40, 139.42it/s]Running 10000 simulations.:  44%|████▍     | 4407/10000 [00:30<00:40, 139.33it/s]Running 10000 simulations.:  44%|████▍     | 4421/10000 [00:30<00:40, 139.28it/s]Running 10000 simulations.:  44%|████▍     | 4435/10000 [00:30<00:40, 139.01it/s]Running 10000 simulations.:  44%|████▍     | 4449/10000 [00:31<00:39, 139.05it/s]Running 10000 simulations.:  45%|████▍     | 4463/10000 [00:31<00:39, 139.15it/s]Running 10000 simulations.:  45%|████▍     | 4477/10000 [00:31<00:39, 139.05it/s]Running 10000 simulations.:  45%|████▍     | 4492/10000 [00:31<00:39, 139.64it/s]Running 10000 simulations.:  45%|████▌     | 4506/10000 [00:31<00:39, 138.74it/s]Running 10000 simulations.:  45%|████▌     | 4520/10000 [00:31<00:39, 138.11it/s]Running 10000 simulations.:  45%|████▌     | 4534/10000 [00:31<00:41, 130.90it/s]Running 10000 simulations.:  45%|████▌     | 4548/10000 [00:31<00:41, 132.93it/s]Running 10000 simulations.:  46%|████▌     | 4562/10000 [00:31<00:40, 134.33it/s]Running 10000 simulations.:  46%|████▌     | 4576/10000 [00:31<00:40, 135.13it/s]Running 10000 simulations.:  46%|████▌     | 4590/10000 [00:32<00:39, 135.71it/s]Running 10000 simulations.:  46%|████▌     | 4604/10000 [00:32<00:39, 136.40it/s]Running 10000 simulations.:  46%|████▌     | 4618/10000 [00:32<00:39, 136.79it/s]Running 10000 simulations.:  46%|████▋     | 4632/10000 [00:32<00:39, 137.49it/s]Running 10000 simulations.:  46%|████▋     | 4646/10000 [00:32<00:38, 137.67it/s]Running 10000 simulations.:  47%|████▋     | 4660/10000 [00:32<00:38, 138.23it/s]Running 10000 simulations.:  47%|████▋     | 4674/10000 [00:32<00:38, 138.44it/s]Running 10000 simulations.:  47%|████▋     | 4688/10000 [00:32<00:38, 138.11it/s]Running 10000 simulations.:  47%|████▋     | 4702/10000 [00:32<00:38, 138.49it/s]Running 10000 simulations.:  47%|████▋     | 4716/10000 [00:32<00:38, 138.57it/s]Running 10000 simulations.:  47%|████▋     | 4730/10000 [00:33<00:37, 138.91it/s]Running 10000 simulations.:  47%|████▋     | 4745/10000 [00:33<00:37, 139.28it/s]Running 10000 simulations.:  48%|████▊     | 4759/10000 [00:33<00:37, 139.36it/s]Running 10000 simulations.:  48%|████▊     | 4773/10000 [00:33<00:37, 139.45it/s]Running 10000 simulations.:  48%|████▊     | 4787/10000 [00:33<00:37, 139.51it/s]Running 10000 simulations.:  48%|████▊     | 4802/10000 [00:33<00:37, 139.73it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:33<00:37, 139.88it/s]Running 10000 simulations.:  48%|████▊     | 4831/10000 [00:33<00:36, 139.86it/s]Running 10000 simulations.:  48%|████▊     | 4846/10000 [00:33<00:36, 139.94it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:34<00:36, 139.82it/s]Running 10000 simulations.:  49%|████▊     | 4874/10000 [00:34<00:36, 139.72it/s]Running 10000 simulations.:  49%|████▉     | 4888/10000 [00:34<00:36, 139.60it/s]Running 10000 simulations.:  49%|████▉     | 4902/10000 [00:34<00:36, 139.38it/s]Running 10000 simulations.:  49%|████▉     | 4916/10000 [00:34<00:36, 139.37it/s]Running 10000 simulations.:  49%|████▉     | 4930/10000 [00:34<00:36, 139.38it/s]Running 10000 simulations.:  49%|████▉     | 4944/10000 [00:34<00:36, 139.43it/s]Running 10000 simulations.:  50%|████▉     | 4959/10000 [00:34<00:36, 139.66it/s]Running 10000 simulations.:  50%|████▉     | 4973/10000 [00:34<00:36, 139.63it/s]Running 10000 simulations.:  50%|████▉     | 4987/10000 [00:34<00:35, 139.67it/s]Running 10000 simulations.:  50%|█████     | 5002/10000 [00:35<00:35, 139.81it/s]Running 10000 simulations.:  50%|█████     | 5016/10000 [00:35<00:35, 139.86it/s]Running 10000 simulations.:  50%|█████     | 5030/10000 [00:35<00:35, 139.71it/s]Running 10000 simulations.:  50%|█████     | 5044/10000 [00:35<00:35, 139.68it/s]Running 10000 simulations.:  51%|█████     | 5058/10000 [00:35<00:35, 139.68it/s]Running 10000 simulations.:  51%|█████     | 5072/10000 [00:35<00:35, 139.61it/s]Running 10000 simulations.:  51%|█████     | 5086/10000 [00:35<00:35, 139.40it/s]Running 10000 simulations.:  51%|█████     | 5100/10000 [00:35<00:35, 139.53it/s]Running 10000 simulations.:  51%|█████     | 5115/10000 [00:35<00:34, 140.25it/s]Running 10000 simulations.:  51%|█████▏    | 5130/10000 [00:35<00:34, 140.56it/s]Running 10000 simulations.:  51%|█████▏    | 5145/10000 [00:36<00:34, 140.37it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:36<00:34, 140.09it/s]Running 10000 simulations.:  52%|█████▏    | 5175/10000 [00:36<00:34, 140.51it/s]Running 10000 simulations.:  52%|█████▏    | 5190/10000 [00:36<00:34, 140.21it/s]Running 10000 simulations.:  52%|█████▏    | 5205/10000 [00:36<00:34, 139.33it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:36<00:34, 139.10it/s]Running 10000 simulations.:  52%|█████▏    | 5233/10000 [00:36<00:34, 138.92it/s]Running 10000 simulations.:  52%|█████▏    | 5247/10000 [00:36<00:34, 138.88it/s]Running 10000 simulations.:  53%|█████▎    | 5261/10000 [00:36<00:34, 138.92it/s]Running 10000 simulations.:  53%|█████▎    | 5275/10000 [00:37<00:34, 138.76it/s]Running 10000 simulations.:  53%|█████▎    | 5289/10000 [00:37<00:33, 138.68it/s]Running 10000 simulations.:  53%|█████▎    | 5303/10000 [00:37<00:33, 138.62it/s]Running 10000 simulations.:  53%|█████▎    | 5317/10000 [00:37<00:33, 138.65it/s]Running 10000 simulations.:  53%|█████▎    | 5331/10000 [00:37<00:33, 138.33it/s]Running 10000 simulations.:  53%|█████▎    | 5345/10000 [00:37<00:33, 138.65it/s]Running 10000 simulations.:  54%|█████▎    | 5359/10000 [00:37<00:33, 138.82it/s]Running 10000 simulations.:  54%|█████▎    | 5373/10000 [00:37<00:33, 138.95it/s]Running 10000 simulations.:  54%|█████▍    | 5387/10000 [00:37<00:33, 138.68it/s]Running 10000 simulations.:  54%|█████▍    | 5401/10000 [00:37<00:33, 138.81it/s]Running 10000 simulations.:  54%|█████▍    | 5415/10000 [00:38<00:33, 138.38it/s]Running 10000 simulations.:  54%|█████▍    | 5429/10000 [00:38<00:33, 138.40it/s]Running 10000 simulations.:  54%|█████▍    | 5443/10000 [00:38<00:32, 138.25it/s]Running 10000 simulations.:  55%|█████▍    | 5457/10000 [00:38<00:32, 138.21it/s]Running 10000 simulations.:  55%|█████▍    | 5471/10000 [00:38<00:32, 138.19it/s]Running 10000 simulations.:  55%|█████▍    | 5485/10000 [00:38<00:32, 138.04it/s]Running 10000 simulations.:  55%|█████▍    | 5499/10000 [00:38<00:32, 138.39it/s]Running 10000 simulations.:  55%|█████▌    | 5513/10000 [00:38<00:32, 138.43it/s]Running 10000 simulations.:  55%|█████▌    | 5527/10000 [00:38<00:32, 138.38it/s]Running 10000 simulations.:  55%|█████▌    | 5541/10000 [00:38<00:32, 138.34it/s]Running 10000 simulations.:  56%|█████▌    | 5555/10000 [00:39<00:32, 138.38it/s]Running 10000 simulations.:  56%|█████▌    | 5569/10000 [00:39<00:31, 138.54it/s]Running 10000 simulations.:  56%|█████▌    | 5583/10000 [00:39<00:31, 138.68it/s]Running 10000 simulations.:  56%|█████▌    | 5598/10000 [00:39<00:31, 139.26it/s]Running 10000 simulations.:  56%|█████▌    | 5612/10000 [00:39<00:31, 138.86it/s]Running 10000 simulations.:  56%|█████▋    | 5626/10000 [00:39<00:31, 138.08it/s]Running 10000 simulations.:  56%|█████▋    | 5640/10000 [00:39<00:31, 138.13it/s]Running 10000 simulations.:  57%|█████▋    | 5654/10000 [00:39<00:31, 138.21it/s]Running 10000 simulations.:  57%|█████▋    | 5668/10000 [00:39<00:31, 138.10it/s]Running 10000 simulations.:  57%|█████▋    | 5682/10000 [00:39<00:31, 138.27it/s]Running 10000 simulations.:  57%|█████▋    | 5696/10000 [00:40<00:31, 137.93it/s]Running 10000 simulations.:  57%|█████▋    | 5710/10000 [00:40<00:31, 138.05it/s]Running 10000 simulations.:  57%|█████▋    | 5724/10000 [00:40<00:30, 137.98it/s]Running 10000 simulations.:  57%|█████▋    | 5738/10000 [00:40<00:30, 138.20it/s]Running 10000 simulations.:  58%|█████▊    | 5752/10000 [00:40<00:30, 138.58it/s]Running 10000 simulations.:  58%|█████▊    | 5766/10000 [00:40<00:30, 137.96it/s]Running 10000 simulations.:  58%|█████▊    | 5780/10000 [00:40<00:30, 137.86it/s]Running 10000 simulations.:  58%|█████▊    | 5794/10000 [00:40<00:30, 137.85it/s]Running 10000 simulations.:  58%|█████▊    | 5808/10000 [00:40<00:30, 137.46it/s]Running 10000 simulations.:  58%|█████▊    | 5822/10000 [00:40<00:30, 137.56it/s]Running 10000 simulations.:  58%|█████▊    | 5836/10000 [00:41<00:30, 137.55it/s]Running 10000 simulations.:  58%|█████▊    | 5850/10000 [00:41<00:30, 137.92it/s]Running 10000 simulations.:  59%|█████▊    | 5864/10000 [00:41<00:30, 137.05it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:41<00:30, 136.81it/s]Running 10000 simulations.:  59%|█████▉    | 5892/10000 [00:41<00:30, 136.59it/s]Running 10000 simulations.:  59%|█████▉    | 5906/10000 [00:41<00:29, 137.38it/s]Running 10000 simulations.:  59%|█████▉    | 5920/10000 [00:41<00:29, 138.15it/s]Running 10000 simulations.:  59%|█████▉    | 5935/10000 [00:41<00:29, 139.86it/s]Running 10000 simulations.:  60%|█████▉    | 5950/10000 [00:41<00:28, 140.75it/s]Running 10000 simulations.:  60%|█████▉    | 5965/10000 [00:41<00:28, 141.31it/s]Running 10000 simulations.:  60%|█████▉    | 5980/10000 [00:42<00:28, 141.54it/s]Running 10000 simulations.:  60%|█████▉    | 5995/10000 [00:42<00:28, 142.12it/s]Running 10000 simulations.:  60%|██████    | 6010/10000 [00:42<00:28, 142.16it/s]Running 10000 simulations.:  60%|██████    | 6025/10000 [00:42<00:27, 142.16it/s]Running 10000 simulations.:  60%|██████    | 6040/10000 [00:42<00:27, 142.36it/s]Running 10000 simulations.:  61%|██████    | 6055/10000 [00:42<00:27, 142.45it/s]Running 10000 simulations.:  61%|██████    | 6070/10000 [00:42<00:27, 142.80it/s]Running 10000 simulations.:  61%|██████    | 6085/10000 [00:42<00:27, 143.28it/s]Running 10000 simulations.:  61%|██████    | 6100/10000 [00:42<00:29, 134.10it/s]Running 10000 simulations.:  61%|██████    | 6114/10000 [00:43<00:30, 126.62it/s]Running 10000 simulations.:  61%|██████▏   | 6127/10000 [00:43<00:31, 121.70it/s]Running 10000 simulations.:  61%|██████▏   | 6140/10000 [00:43<00:32, 120.13it/s]Running 10000 simulations.:  62%|██████▏   | 6153/10000 [00:43<00:32, 119.23it/s]Running 10000 simulations.:  62%|██████▏   | 6166/10000 [00:43<00:32, 117.08it/s]Running 10000 simulations.:  62%|██████▏   | 6178/10000 [00:43<00:32, 116.08it/s]Running 10000 simulations.:  62%|██████▏   | 6190/10000 [00:43<00:32, 116.31it/s]Running 10000 simulations.:  62%|██████▏   | 6202/10000 [00:43<00:32, 116.63it/s]Running 10000 simulations.:  62%|██████▏   | 6215/10000 [00:43<00:32, 117.59it/s]Running 10000 simulations.:  62%|██████▏   | 6227/10000 [00:44<00:31, 118.26it/s]Running 10000 simulations.:  62%|██████▏   | 6239/10000 [00:44<00:31, 118.60it/s]Running 10000 simulations.:  63%|██████▎   | 6251/10000 [00:44<00:31, 118.72it/s]Running 10000 simulations.:  63%|██████▎   | 6264/10000 [00:44<00:31, 119.15it/s]Running 10000 simulations.:  63%|██████▎   | 6276/10000 [00:44<00:31, 119.21it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:44<00:31, 119.17it/s]Running 10000 simulations.:  63%|██████▎   | 6300/10000 [00:44<00:31, 119.24it/s]Running 10000 simulations.:  63%|██████▎   | 6313/10000 [00:44<00:30, 119.76it/s]Running 10000 simulations.:  63%|██████▎   | 6326/10000 [00:44<00:30, 120.28it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:44<00:30, 119.53it/s]Running 10000 simulations.:  64%|██████▎   | 6351/10000 [00:45<00:30, 118.76it/s]Running 10000 simulations.:  64%|██████▎   | 6363/10000 [00:45<00:31, 117.29it/s]Running 10000 simulations.:  64%|██████▍   | 6375/10000 [00:45<00:31, 116.45it/s]Running 10000 simulations.:  64%|██████▍   | 6387/10000 [00:45<00:30, 116.83it/s]Running 10000 simulations.:  64%|██████▍   | 6399/10000 [00:45<00:30, 117.39it/s]Running 10000 simulations.:  64%|██████▍   | 6411/10000 [00:45<00:30, 117.81it/s]Running 10000 simulations.:  64%|██████▍   | 6423/10000 [00:45<00:30, 117.52it/s]Running 10000 simulations.:  64%|██████▍   | 6435/10000 [00:45<00:30, 118.25it/s]Running 10000 simulations.:  64%|██████▍   | 6449/10000 [00:45<00:29, 122.24it/s]Running 10000 simulations.:  65%|██████▍   | 6463/10000 [00:46<00:27, 126.56it/s]Running 10000 simulations.:  65%|██████▍   | 6477/10000 [00:46<00:27, 130.01it/s]Running 10000 simulations.:  65%|██████▍   | 6491/10000 [00:46<00:26, 132.11it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:46<00:26, 133.20it/s]Running 10000 simulations.:  65%|██████▌   | 6519/10000 [00:46<00:25, 133.90it/s]Running 10000 simulations.:  65%|██████▌   | 6533/10000 [00:46<00:25, 134.71it/s]Running 10000 simulations.:  65%|██████▌   | 6547/10000 [00:46<00:25, 135.17it/s]Running 10000 simulations.:  66%|██████▌   | 6561/10000 [00:46<00:25, 135.49it/s]Running 10000 simulations.:  66%|██████▌   | 6575/10000 [00:46<00:25, 135.61it/s]Running 10000 simulations.:  66%|██████▌   | 6589/10000 [00:46<00:25, 134.57it/s]Running 10000 simulations.:  66%|██████▌   | 6603/10000 [00:47<00:25, 134.95it/s]Running 10000 simulations.:  66%|██████▌   | 6617/10000 [00:47<00:24, 135.69it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:47<00:24, 135.89it/s]Running 10000 simulations.:  66%|██████▋   | 6645/10000 [00:47<00:24, 136.34it/s]Running 10000 simulations.:  67%|██████▋   | 6659/10000 [00:47<00:24, 136.25it/s]Running 10000 simulations.:  67%|██████▋   | 6673/10000 [00:47<00:24, 136.25it/s]Running 10000 simulations.:  67%|██████▋   | 6687/10000 [00:47<00:24, 136.37it/s]Running 10000 simulations.:  67%|██████▋   | 6701/10000 [00:47<00:24, 137.04it/s]Running 10000 simulations.:  67%|██████▋   | 6715/10000 [00:47<00:23, 137.58it/s]Running 10000 simulations.:  67%|██████▋   | 6729/10000 [00:47<00:23, 137.32it/s]Running 10000 simulations.:  67%|██████▋   | 6743/10000 [00:48<00:23, 136.99it/s]Running 10000 simulations.:  68%|██████▊   | 6757/10000 [00:48<00:23, 136.99it/s]Running 10000 simulations.:  68%|██████▊   | 6771/10000 [00:48<00:23, 136.71it/s]Running 10000 simulations.:  68%|██████▊   | 6785/10000 [00:48<00:23, 136.47it/s]Running 10000 simulations.:  68%|██████▊   | 6799/10000 [00:48<00:23, 136.32it/s]Running 10000 simulations.:  68%|██████▊   | 6813/10000 [00:48<00:23, 136.07it/s]Running 10000 simulations.:  68%|██████▊   | 6827/10000 [00:48<00:23, 136.19it/s]Running 10000 simulations.:  68%|██████▊   | 6841/10000 [00:48<00:23, 136.01it/s]Running 10000 simulations.:  69%|██████▊   | 6855/10000 [00:48<00:23, 136.33it/s]Running 10000 simulations.:  69%|██████▊   | 6869/10000 [00:48<00:23, 135.88it/s]Running 10000 simulations.:  69%|██████▉   | 6883/10000 [00:49<00:22, 135.97it/s]Running 10000 simulations.:  69%|██████▉   | 6897/10000 [00:49<00:22, 136.29it/s]Running 10000 simulations.:  69%|██████▉   | 6911/10000 [00:49<00:22, 136.49it/s]Running 10000 simulations.:  69%|██████▉   | 6925/10000 [00:49<00:22, 136.52it/s]Running 10000 simulations.:  69%|██████▉   | 6939/10000 [00:49<00:22, 136.39it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:49<00:22, 136.97it/s]Running 10000 simulations.:  70%|██████▉   | 6967/10000 [00:49<00:22, 136.97it/s]Running 10000 simulations.:  70%|██████▉   | 6981/10000 [00:49<00:22, 136.49it/s]Running 10000 simulations.:  70%|██████▉   | 6995/10000 [00:49<00:21, 136.65it/s]Running 10000 simulations.:  70%|███████   | 7009/10000 [00:50<00:21, 136.47it/s]Running 10000 simulations.:  70%|███████   | 7023/10000 [00:50<00:21, 136.63it/s]Running 10000 simulations.:  70%|███████   | 7037/10000 [00:50<00:21, 136.88it/s]Running 10000 simulations.:  71%|███████   | 7051/10000 [00:50<00:21, 137.06it/s]Running 10000 simulations.:  71%|███████   | 7065/10000 [00:50<00:21, 136.93it/s]Running 10000 simulations.:  71%|███████   | 7079/10000 [00:50<00:21, 137.30it/s]Running 10000 simulations.:  71%|███████   | 7093/10000 [00:50<00:21, 137.31it/s]Running 10000 simulations.:  71%|███████   | 7107/10000 [00:50<00:21, 137.56it/s]Running 10000 simulations.:  71%|███████   | 7121/10000 [00:50<00:20, 137.36it/s]Running 10000 simulations.:  71%|███████▏  | 7135/10000 [00:50<00:20, 137.26it/s]Running 10000 simulations.:  71%|███████▏  | 7149/10000 [00:51<00:20, 136.97it/s]Running 10000 simulations.:  72%|███████▏  | 7163/10000 [00:51<00:20, 136.70it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:51<00:20, 136.95it/s]Running 10000 simulations.:  72%|███████▏  | 7191/10000 [00:51<00:20, 136.86it/s]Running 10000 simulations.:  72%|███████▏  | 7205/10000 [00:51<00:20, 137.09it/s]Running 10000 simulations.:  72%|███████▏  | 7219/10000 [00:51<00:20, 137.42it/s]Running 10000 simulations.:  72%|███████▏  | 7233/10000 [00:51<00:20, 137.48it/s]Running 10000 simulations.:  72%|███████▏  | 7247/10000 [00:51<00:20, 137.50it/s]Running 10000 simulations.:  73%|███████▎  | 7261/10000 [00:51<00:19, 137.45it/s]Running 10000 simulations.:  73%|███████▎  | 7275/10000 [00:51<00:20, 133.92it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:52<00:20, 134.59it/s]Running 10000 simulations.:  73%|███████▎  | 7303/10000 [00:52<00:19, 135.36it/s]Running 10000 simulations.:  73%|███████▎  | 7317/10000 [00:52<00:19, 135.65it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:52<00:19, 136.27it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:52<00:19, 136.38it/s]Running 10000 simulations.:  74%|███████▎  | 7359/10000 [00:52<00:19, 136.12it/s]Running 10000 simulations.:  74%|███████▎  | 7373/10000 [00:52<00:19, 136.11it/s]Running 10000 simulations.:  74%|███████▍  | 7387/10000 [00:52<00:19, 136.27it/s]Running 10000 simulations.:  74%|███████▍  | 7401/10000 [00:52<00:19, 136.54it/s]Running 10000 simulations.:  74%|███████▍  | 7415/10000 [00:52<00:18, 137.13it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:53<00:18, 137.21it/s]Running 10000 simulations.:  74%|███████▍  | 7443/10000 [00:53<00:18, 137.34it/s]Running 10000 simulations.:  75%|███████▍  | 7457/10000 [00:53<00:18, 137.74it/s]Running 10000 simulations.:  75%|███████▍  | 7471/10000 [00:53<00:18, 137.54it/s]Running 10000 simulations.:  75%|███████▍  | 7485/10000 [00:53<00:18, 137.31it/s]Running 10000 simulations.:  75%|███████▍  | 7499/10000 [00:53<00:18, 137.63it/s]Running 10000 simulations.:  75%|███████▌  | 7513/10000 [00:53<00:18, 137.75it/s]Running 10000 simulations.:  75%|███████▌  | 7527/10000 [00:53<00:17, 137.52it/s]Running 10000 simulations.:  75%|███████▌  | 7541/10000 [00:53<00:17, 137.57it/s]Running 10000 simulations.:  76%|███████▌  | 7555/10000 [00:54<00:17, 137.66it/s]Running 10000 simulations.:  76%|███████▌  | 7569/10000 [00:54<00:17, 137.64it/s]Running 10000 simulations.:  76%|███████▌  | 7583/10000 [00:54<00:17, 137.93it/s]Running 10000 simulations.:  76%|███████▌  | 7597/10000 [00:54<00:17, 137.52it/s]Running 10000 simulations.:  76%|███████▌  | 7611/10000 [00:54<00:17, 137.86it/s]Running 10000 simulations.:  76%|███████▋  | 7625/10000 [00:54<00:17, 137.80it/s]Running 10000 simulations.:  76%|███████▋  | 7639/10000 [00:54<00:17, 137.52it/s]Running 10000 simulations.:  77%|███████▋  | 7653/10000 [00:54<00:17, 137.38it/s]Running 10000 simulations.:  77%|███████▋  | 7667/10000 [00:54<00:16, 137.79it/s]Running 10000 simulations.:  77%|███████▋  | 7681/10000 [00:54<00:16, 137.73it/s]Running 10000 simulations.:  77%|███████▋  | 7695/10000 [00:55<00:16, 137.69it/s]Running 10000 simulations.:  77%|███████▋  | 7709/10000 [00:55<00:16, 137.47it/s]Running 10000 simulations.:  77%|███████▋  | 7723/10000 [00:55<00:16, 137.57it/s]Running 10000 simulations.:  77%|███████▋  | 7737/10000 [00:55<00:16, 137.37it/s]Running 10000 simulations.:  78%|███████▊  | 7751/10000 [00:55<00:16, 137.33it/s]Running 10000 simulations.:  78%|███████▊  | 7765/10000 [00:55<00:16, 137.62it/s]Running 10000 simulations.:  78%|███████▊  | 7779/10000 [00:55<00:16, 138.03it/s]Running 10000 simulations.:  78%|███████▊  | 7793/10000 [00:55<00:16, 137.77it/s]Running 10000 simulations.:  78%|███████▊  | 7807/10000 [00:55<00:15, 137.78it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:55<00:15, 137.79it/s]Running 10000 simulations.:  78%|███████▊  | 7835/10000 [00:56<00:15, 137.92it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:56<00:15, 138.09it/s]Running 10000 simulations.:  79%|███████▊  | 7863/10000 [00:56<00:15, 138.10it/s]Running 10000 simulations.:  79%|███████▉  | 7877/10000 [00:56<00:15, 138.28it/s]Running 10000 simulations.:  79%|███████▉  | 7891/10000 [00:56<00:15, 137.78it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:56<00:15, 137.04it/s]Running 10000 simulations.:  79%|███████▉  | 7919/10000 [00:56<00:15, 136.80it/s]Running 10000 simulations.:  79%|███████▉  | 7933/10000 [00:56<00:15, 136.30it/s]Running 10000 simulations.:  79%|███████▉  | 7947/10000 [00:56<00:15, 135.65it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:56<00:15, 135.56it/s]Running 10000 simulations.:  80%|███████▉  | 7975/10000 [00:57<00:14, 135.32it/s]Running 10000 simulations.:  80%|███████▉  | 7989/10000 [00:57<00:14, 135.28it/s]Running 10000 simulations.:  80%|████████  | 8003/10000 [00:57<00:14, 135.37it/s]Running 10000 simulations.:  80%|████████  | 8017/10000 [00:57<00:14, 135.90it/s]Running 10000 simulations.:  80%|████████  | 8031/10000 [00:57<00:14, 136.34it/s]Running 10000 simulations.:  80%|████████  | 8045/10000 [00:57<00:14, 136.19it/s]Running 10000 simulations.:  81%|████████  | 8059/10000 [00:57<00:14, 136.04it/s]Running 10000 simulations.:  81%|████████  | 8073/10000 [00:57<00:14, 136.17it/s]Running 10000 simulations.:  81%|████████  | 8087/10000 [00:57<00:14, 136.30it/s]Running 10000 simulations.:  81%|████████  | 8101/10000 [00:57<00:13, 136.26it/s]Running 10000 simulations.:  81%|████████  | 8115/10000 [00:58<00:13, 136.42it/s]Running 10000 simulations.:  81%|████████▏ | 8129/10000 [00:58<00:13, 136.37it/s]Running 10000 simulations.:  81%|████████▏ | 8143/10000 [00:58<00:13, 136.32it/s]Running 10000 simulations.:  82%|████████▏ | 8157/10000 [00:58<00:13, 136.11it/s]Running 10000 simulations.:  82%|████████▏ | 8172/10000 [00:58<00:13, 138.50it/s]Running 10000 simulations.:  82%|████████▏ | 8187/10000 [00:58<00:12, 139.96it/s]Running 10000 simulations.:  82%|████████▏ | 8202/10000 [00:58<00:12, 140.77it/s]Running 10000 simulations.:  82%|████████▏ | 8217/10000 [00:58<00:12, 140.75it/s]Running 10000 simulations.:  82%|████████▏ | 8232/10000 [00:58<00:12, 141.46it/s]Running 10000 simulations.:  82%|████████▏ | 8247/10000 [00:59<00:12, 142.41it/s]Running 10000 simulations.:  83%|████████▎ | 8262/10000 [00:59<00:12, 143.06it/s]Running 10000 simulations.:  83%|████████▎ | 8277/10000 [00:59<00:12, 143.53it/s]Running 10000 simulations.:  83%|████████▎ | 8292/10000 [00:59<00:11, 143.83it/s]Running 10000 simulations.:  83%|████████▎ | 8307/10000 [00:59<00:11, 143.46it/s]Running 10000 simulations.:  83%|████████▎ | 8322/10000 [00:59<00:11, 141.78it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:59<00:11, 140.59it/s]Running 10000 simulations.:  84%|████████▎ | 8352/10000 [00:59<00:11, 139.71it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [00:59<00:11, 139.01it/s]Running 10000 simulations.:  84%|████████▍ | 8380/10000 [00:59<00:11, 138.97it/s]Running 10000 simulations.:  84%|████████▍ | 8394/10000 [01:00<00:11, 138.60it/s]Running 10000 simulations.:  84%|████████▍ | 8408/10000 [01:00<00:11, 138.63it/s]Running 10000 simulations.:  84%|████████▍ | 8423/10000 [01:00<00:11, 139.01it/s]Running 10000 simulations.:  84%|████████▍ | 8437/10000 [01:00<00:11, 138.39it/s]Running 10000 simulations.:  85%|████████▍ | 8451/10000 [01:00<00:11, 137.74it/s]Running 10000 simulations.:  85%|████████▍ | 8465/10000 [01:00<00:11, 138.06it/s]Running 10000 simulations.:  85%|████████▍ | 8479/10000 [01:00<00:10, 138.61it/s]Running 10000 simulations.:  85%|████████▍ | 8494/10000 [01:00<00:10, 139.26it/s]Running 10000 simulations.:  85%|████████▌ | 8508/10000 [01:00<00:10, 139.26it/s]Running 10000 simulations.:  85%|████████▌ | 8522/10000 [01:00<00:10, 139.07it/s]Running 10000 simulations.:  85%|████████▌ | 8536/10000 [01:01<00:10, 138.70it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [01:01<00:10, 138.43it/s]Running 10000 simulations.:  86%|████████▌ | 8564/10000 [01:01<00:10, 138.77it/s]Running 10000 simulations.:  86%|████████▌ | 8578/10000 [01:01<00:10, 138.86it/s]Running 10000 simulations.:  86%|████████▌ | 8592/10000 [01:01<00:10, 138.67it/s]Running 10000 simulations.:  86%|████████▌ | 8606/10000 [01:01<00:10, 131.52it/s]Running 10000 simulations.:  86%|████████▌ | 8620/10000 [01:01<00:10, 133.49it/s]Running 10000 simulations.:  86%|████████▋ | 8634/10000 [01:01<00:10, 135.37it/s]Running 10000 simulations.:  86%|████████▋ | 8648/10000 [01:01<00:09, 136.06it/s]Running 10000 simulations.:  87%|████████▋ | 8662/10000 [01:02<00:09, 136.48it/s]Running 10000 simulations.:  87%|████████▋ | 8676/10000 [01:02<00:09, 137.00it/s]Running 10000 simulations.:  87%|████████▋ | 8690/10000 [01:02<00:09, 137.30it/s]Running 10000 simulations.:  87%|████████▋ | 8704/10000 [01:02<00:09, 137.95it/s]Running 10000 simulations.:  87%|████████▋ | 8718/10000 [01:02<00:09, 138.46it/s]Running 10000 simulations.:  87%|████████▋ | 8732/10000 [01:02<00:09, 138.85it/s]Running 10000 simulations.:  87%|████████▋ | 8747/10000 [01:02<00:08, 141.23it/s]Running 10000 simulations.:  88%|████████▊ | 8763/10000 [01:02<00:08, 144.98it/s]Running 10000 simulations.:  88%|████████▊ | 8779/10000 [01:02<00:08, 147.75it/s]Running 10000 simulations.:  88%|████████▊ | 8794/10000 [01:02<00:08, 147.74it/s]Running 10000 simulations.:  88%|████████▊ | 8809/10000 [01:03<00:08, 145.58it/s]Running 10000 simulations.:  88%|████████▊ | 8824/10000 [01:03<00:08, 144.03it/s]Running 10000 simulations.:  88%|████████▊ | 8839/10000 [01:03<00:08, 142.79it/s]Running 10000 simulations.:  89%|████████▊ | 8854/10000 [01:03<00:08, 142.19it/s]Running 10000 simulations.:  89%|████████▊ | 8869/10000 [01:03<00:07, 141.67it/s]Running 10000 simulations.:  89%|████████▉ | 8884/10000 [01:03<00:07, 141.74it/s]Running 10000 simulations.:  89%|████████▉ | 8899/10000 [01:03<00:07, 141.42it/s]Running 10000 simulations.:  89%|████████▉ | 8914/10000 [01:03<00:07, 141.17it/s]Running 10000 simulations.:  89%|████████▉ | 8929/10000 [01:03<00:07, 139.88it/s]Running 10000 simulations.:  89%|████████▉ | 8943/10000 [01:04<00:07, 139.21it/s]Running 10000 simulations.:  90%|████████▉ | 8957/10000 [01:04<00:07, 138.60it/s]Running 10000 simulations.:  90%|████████▉ | 8971/10000 [01:04<00:07, 138.28it/s]Running 10000 simulations.:  90%|████████▉ | 8985/10000 [01:04<00:07, 138.22it/s]Running 10000 simulations.:  90%|████████▉ | 8999/10000 [01:04<00:07, 138.05it/s]Running 10000 simulations.:  90%|█████████ | 9013/10000 [01:04<00:07, 138.11it/s]Running 10000 simulations.:  90%|█████████ | 9027/10000 [01:04<00:07, 138.15it/s]Running 10000 simulations.:  90%|█████████ | 9041/10000 [01:04<00:06, 137.89it/s]Running 10000 simulations.:  91%|█████████ | 9055/10000 [01:04<00:06, 137.64it/s]Running 10000 simulations.:  91%|█████████ | 9069/10000 [01:04<00:06, 137.50it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [01:05<00:06, 137.69it/s]Running 10000 simulations.:  91%|█████████ | 9097/10000 [01:05<00:06, 137.54it/s]Running 10000 simulations.:  91%|█████████ | 9112/10000 [01:05<00:06, 138.31it/s]Running 10000 simulations.:  91%|█████████▏| 9127/10000 [01:05<00:06, 138.88it/s]Running 10000 simulations.:  91%|█████████▏| 9141/10000 [01:05<00:06, 139.10it/s]Running 10000 simulations.:  92%|█████████▏| 9156/10000 [01:05<00:06, 139.76it/s]Running 10000 simulations.:  92%|█████████▏| 9170/10000 [01:05<00:05, 138.88it/s]Running 10000 simulations.:  92%|█████████▏| 9184/10000 [01:05<00:05, 138.99it/s]Running 10000 simulations.:  92%|█████████▏| 9199/10000 [01:05<00:05, 140.18it/s]Running 10000 simulations.:  92%|█████████▏| 9214/10000 [01:05<00:05, 139.87it/s]Running 10000 simulations.:  92%|█████████▏| 9229/10000 [01:06<00:05, 140.02it/s]Running 10000 simulations.:  92%|█████████▏| 9244/10000 [01:06<00:05, 140.14it/s]Running 10000 simulations.:  93%|█████████▎| 9259/10000 [01:06<00:05, 139.87it/s]Running 10000 simulations.:  93%|█████████▎| 9274/10000 [01:06<00:05, 140.13it/s]Running 10000 simulations.:  93%|█████████▎| 9289/10000 [01:06<00:05, 139.43it/s]Running 10000 simulations.:  93%|█████████▎| 9303/10000 [01:06<00:05, 139.13it/s]Running 10000 simulations.:  93%|█████████▎| 9317/10000 [01:06<00:04, 139.32it/s]Running 10000 simulations.:  93%|█████████▎| 9331/10000 [01:06<00:04, 139.36it/s]Running 10000 simulations.:  93%|█████████▎| 9345/10000 [01:06<00:04, 139.15it/s]Running 10000 simulations.:  94%|█████████▎| 9359/10000 [01:06<00:04, 139.22it/s]Running 10000 simulations.:  94%|█████████▎| 9373/10000 [01:07<00:04, 139.35it/s]Running 10000 simulations.:  94%|█████████▍| 9387/10000 [01:07<00:04, 139.17it/s]Running 10000 simulations.:  94%|█████████▍| 9401/10000 [01:07<00:04, 138.93it/s]Running 10000 simulations.:  94%|█████████▍| 9415/10000 [01:07<00:04, 138.25it/s]Running 10000 simulations.:  94%|█████████▍| 9429/10000 [01:07<00:04, 137.70it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [01:07<00:04, 137.49it/s]Running 10000 simulations.:  95%|█████████▍| 9457/10000 [01:07<00:03, 137.27it/s]Running 10000 simulations.:  95%|█████████▍| 9471/10000 [01:07<00:03, 137.77it/s]Running 10000 simulations.:  95%|█████████▍| 9486/10000 [01:07<00:03, 139.71it/s]Running 10000 simulations.:  95%|█████████▌| 9501/10000 [01:08<00:03, 141.88it/s]Running 10000 simulations.:  95%|█████████▌| 9516/10000 [01:08<00:03, 142.27it/s]Running 10000 simulations.:  95%|█████████▌| 9531/10000 [01:08<00:03, 143.24it/s]Running 10000 simulations.:  95%|█████████▌| 9546/10000 [01:08<00:03, 144.47it/s]Running 10000 simulations.:  96%|█████████▌| 9561/10000 [01:08<00:03, 145.56it/s]Running 10000 simulations.:  96%|█████████▌| 9576/10000 [01:08<00:02, 145.96it/s]Running 10000 simulations.:  96%|█████████▌| 9591/10000 [01:08<00:02, 144.92it/s]Running 10000 simulations.:  96%|█████████▌| 9606/10000 [01:08<00:02, 144.99it/s]Running 10000 simulations.:  96%|█████████▌| 9621/10000 [01:08<00:02, 144.10it/s]Running 10000 simulations.:  96%|█████████▋| 9636/10000 [01:08<00:02, 142.10it/s]Running 10000 simulations.:  97%|█████████▋| 9651/10000 [01:09<00:02, 141.92it/s]Running 10000 simulations.:  97%|█████████▋| 9666/10000 [01:09<00:02, 141.87it/s]Running 10000 simulations.:  97%|█████████▋| 9681/10000 [01:09<00:02, 141.74it/s]Running 10000 simulations.:  97%|█████████▋| 9696/10000 [01:09<00:02, 141.51it/s]Running 10000 simulations.:  97%|█████████▋| 9711/10000 [01:09<00:02, 141.73it/s]Running 10000 simulations.:  97%|█████████▋| 9726/10000 [01:09<00:01, 141.34it/s]Running 10000 simulations.:  97%|█████████▋| 9741/10000 [01:09<00:01, 141.31it/s]Running 10000 simulations.:  98%|█████████▊| 9756/10000 [01:09<00:01, 140.92it/s]Running 10000 simulations.:  98%|█████████▊| 9771/10000 [01:09<00:01, 141.13it/s]Running 10000 simulations.:  98%|█████████▊| 9786/10000 [01:10<00:01, 139.92it/s]Running 10000 simulations.:  98%|█████████▊| 9800/10000 [01:10<00:01, 139.16it/s]Running 10000 simulations.:  98%|█████████▊| 9814/10000 [01:10<00:01, 138.80it/s]Running 10000 simulations.:  98%|█████████▊| 9828/10000 [01:10<00:01, 138.82it/s]Running 10000 simulations.:  98%|█████████▊| 9842/10000 [01:10<00:01, 138.31it/s]Running 10000 simulations.:  99%|█████████▊| 9856/10000 [01:10<00:01, 138.24it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [01:10<00:00, 137.99it/s]Running 10000 simulations.:  99%|█████████▉| 9884/10000 [01:10<00:00, 137.91it/s]Running 10000 simulations.:  99%|█████████▉| 9898/10000 [01:10<00:00, 137.86it/s]Running 10000 simulations.:  99%|█████████▉| 9913/10000 [01:10<00:00, 139.04it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [01:11<00:00, 139.50it/s]Running 10000 simulations.:  99%|█████████▉| 9942/10000 [01:11<00:00, 139.62it/s]Running 10000 simulations.: 100%|█████████▉| 9956/10000 [01:11<00:00, 139.62it/s]Running 10000 simulations.: 100%|█████████▉| 9970/10000 [01:11<00:00, 139.54it/s]Running 10000 simulations.: 100%|█████████▉| 9985/10000 [01:11<00:00, 139.98it/s]Running 10000 simulations.: 100%|█████████▉| 9999/10000 [01:11<00:00, 135.68it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:11<00:00, 139.72it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 251.94it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<00:39, 251.02it/s]Running 10000 simulations.:   1%|          | 76/10000 [00:00<00:39, 250.56it/s]Running 10000 simulations.:   1%|          | 101/10000 [00:00<00:39, 250.08it/s]Running 10000 simulations.:   1%|▏         | 126/10000 [00:00<00:39, 248.76it/s]Running 10000 simulations.:   2%|▏         | 151/10000 [00:00<00:39, 247.82it/s]Running 10000 simulations.:   2%|▏         | 176/10000 [00:00<00:39, 247.40it/s]Running 10000 simulations.:   2%|▏         | 201/10000 [00:00<00:39, 246.70it/s]Running 10000 simulations.:   2%|▏         | 226/10000 [00:00<00:39, 245.94it/s]Running 10000 simulations.:   3%|▎         | 251/10000 [00:01<00:39, 244.75it/s]Running 10000 simulations.:   3%|▎         | 276/10000 [00:01<00:39, 245.11it/s]Running 10000 simulations.:   3%|▎         | 301/10000 [00:01<00:39, 244.69it/s]Running 10000 simulations.:   3%|▎         | 326/10000 [00:01<00:39, 244.58it/s]Running 10000 simulations.:   4%|▎         | 351/10000 [00:01<00:39, 244.04it/s]Running 10000 simulations.:   4%|▍         | 376/10000 [00:01<00:39, 243.85it/s]Running 10000 simulations.:   4%|▍         | 401/10000 [00:01<00:39, 242.82it/s]Running 10000 simulations.:   4%|▍         | 426/10000 [00:01<00:39, 242.41it/s]Running 10000 simulations.:   5%|▍         | 451/10000 [00:01<00:39, 242.16it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:01<00:39, 241.44it/s]Running 10000 simulations.:   5%|▌         | 501/10000 [00:02<00:39, 241.13it/s]Running 10000 simulations.:   5%|▌         | 526/10000 [00:02<00:39, 237.35it/s]Running 10000 simulations.:   6%|▌         | 550/10000 [00:02<00:39, 237.19it/s]Running 10000 simulations.:   6%|▌         | 575/10000 [00:02<00:39, 238.35it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:02<00:39, 239.13it/s]Running 10000 simulations.:   6%|▋         | 625/10000 [00:02<00:39, 239.49it/s]Running 10000 simulations.:   6%|▋         | 649/10000 [00:02<00:39, 239.55it/s]Running 10000 simulations.:   7%|▋         | 673/10000 [00:02<00:38, 239.44it/s]Running 10000 simulations.:   7%|▋         | 697/10000 [00:02<00:38, 239.16it/s]Running 10000 simulations.:   7%|▋         | 721/10000 [00:02<00:38, 238.83it/s]Running 10000 simulations.:   7%|▋         | 745/10000 [00:03<00:38, 238.97it/s]Running 10000 simulations.:   8%|▊         | 769/10000 [00:03<00:38, 238.79it/s]Running 10000 simulations.:   8%|▊         | 793/10000 [00:03<00:38, 238.09it/s]Running 10000 simulations.:   8%|▊         | 817/10000 [00:03<00:38, 237.86it/s]Running 10000 simulations.:   8%|▊         | 842/10000 [00:03<00:38, 238.81it/s]Running 10000 simulations.:   9%|▊         | 867/10000 [00:03<00:38, 239.84it/s]Running 10000 simulations.:   9%|▉         | 892/10000 [00:03<00:37, 239.98it/s]Running 10000 simulations.:   9%|▉         | 916/10000 [00:03<00:38, 238.91it/s]Running 10000 simulations.:   9%|▉         | 940/10000 [00:03<00:37, 238.47it/s]Running 10000 simulations.:  10%|▉         | 965/10000 [00:03<00:37, 239.34it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:04<00:37, 239.62it/s]Running 10000 simulations.:  10%|█         | 1015/10000 [00:04<00:37, 240.35it/s]Running 10000 simulations.:  10%|█         | 1040/10000 [00:04<00:37, 239.92it/s]Running 10000 simulations.:  11%|█         | 1064/10000 [00:04<00:37, 239.37it/s]Running 10000 simulations.:  11%|█         | 1088/10000 [00:04<00:37, 238.99it/s]Running 10000 simulations.:  11%|█         | 1112/10000 [00:04<00:37, 238.87it/s]Running 10000 simulations.:  11%|█▏        | 1136/10000 [00:04<00:37, 238.70it/s]Running 10000 simulations.:  12%|█▏        | 1160/10000 [00:04<00:37, 238.89it/s]Running 10000 simulations.:  12%|█▏        | 1184/10000 [00:04<00:36, 238.52it/s]Running 10000 simulations.:  12%|█▏        | 1208/10000 [00:05<00:36, 238.32it/s]Running 10000 simulations.:  12%|█▏        | 1232/10000 [00:05<00:36, 238.08it/s]Running 10000 simulations.:  13%|█▎        | 1256/10000 [00:05<00:36, 238.14it/s]Running 10000 simulations.:  13%|█▎        | 1280/10000 [00:05<00:36, 238.11it/s]Running 10000 simulations.:  13%|█▎        | 1304/10000 [00:05<00:36, 237.83it/s]Running 10000 simulations.:  13%|█▎        | 1328/10000 [00:05<00:36, 237.93it/s]Running 10000 simulations.:  14%|█▎        | 1352/10000 [00:05<00:36, 237.73it/s]Running 10000 simulations.:  14%|█▍        | 1376/10000 [00:05<00:36, 237.79it/s]Running 10000 simulations.:  14%|█▍        | 1400/10000 [00:05<00:36, 237.23it/s]Running 10000 simulations.:  14%|█▍        | 1424/10000 [00:05<00:36, 237.58it/s]Running 10000 simulations.:  14%|█▍        | 1448/10000 [00:06<00:35, 237.76it/s]Running 10000 simulations.:  15%|█▍        | 1472/10000 [00:06<00:35, 238.28it/s]Running 10000 simulations.:  15%|█▍        | 1496/10000 [00:06<00:35, 237.83it/s]Running 10000 simulations.:  15%|█▌        | 1520/10000 [00:06<00:35, 237.62it/s]Running 10000 simulations.:  15%|█▌        | 1544/10000 [00:06<00:35, 238.28it/s]Running 10000 simulations.:  16%|█▌        | 1568/10000 [00:06<00:35, 237.98it/s]Running 10000 simulations.:  16%|█▌        | 1592/10000 [00:06<00:35, 238.12it/s]Running 10000 simulations.:  16%|█▌        | 1616/10000 [00:06<00:35, 236.53it/s]Running 10000 simulations.:  16%|█▋        | 1640/10000 [00:06<00:35, 233.69it/s]Running 10000 simulations.:  17%|█▋        | 1664/10000 [00:06<00:35, 232.14it/s]Running 10000 simulations.:  17%|█▋        | 1688/10000 [00:07<00:36, 230.79it/s]Running 10000 simulations.:  17%|█▋        | 1712/10000 [00:07<00:36, 230.01it/s]Running 10000 simulations.:  17%|█▋        | 1736/10000 [00:07<00:36, 229.33it/s]Running 10000 simulations.:  18%|█▊        | 1760/10000 [00:07<00:35, 229.80it/s]Running 10000 simulations.:  18%|█▊        | 1783/10000 [00:07<00:35, 229.40it/s]Running 10000 simulations.:  18%|█▊        | 1807/10000 [00:07<00:35, 231.83it/s]Running 10000 simulations.:  18%|█▊        | 1831/10000 [00:07<00:34, 234.19it/s]Running 10000 simulations.:  19%|█▊        | 1855/10000 [00:07<00:34, 234.25it/s]Running 10000 simulations.:  19%|█▉        | 1879/10000 [00:07<00:34, 233.34it/s]Running 10000 simulations.:  19%|█▉        | 1903/10000 [00:07<00:34, 234.13it/s]Running 10000 simulations.:  19%|█▉        | 1927/10000 [00:08<00:35, 226.42it/s]Running 10000 simulations.:  20%|█▉        | 1951/10000 [00:08<00:35, 229.76it/s]Running 10000 simulations.:  20%|█▉        | 1975/10000 [00:08<00:34, 232.34it/s]Running 10000 simulations.:  20%|█▉        | 1999/10000 [00:08<00:34, 233.36it/s]Running 10000 simulations.:  20%|██        | 2023/10000 [00:08<00:33, 235.14it/s]Running 10000 simulations.:  20%|██        | 2047/10000 [00:08<00:33, 235.28it/s]Running 10000 simulations.:  21%|██        | 2071/10000 [00:08<00:33, 235.76it/s]Running 10000 simulations.:  21%|██        | 2095/10000 [00:08<00:33, 235.72it/s]Running 10000 simulations.:  21%|██        | 2119/10000 [00:08<00:33, 235.54it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:08<00:33, 235.92it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:09<00:33, 236.05it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:09<00:33, 236.13it/s]Running 10000 simulations.:  22%|██▏       | 2215/10000 [00:09<00:32, 236.14it/s]Running 10000 simulations.:  22%|██▏       | 2239/10000 [00:09<00:32, 236.21it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:09<00:32, 236.21it/s]Running 10000 simulations.:  23%|██▎       | 2287/10000 [00:09<00:32, 236.27it/s]Running 10000 simulations.:  23%|██▎       | 2311/10000 [00:09<00:32, 236.02it/s]Running 10000 simulations.:  23%|██▎       | 2335/10000 [00:09<00:32, 236.21it/s]Running 10000 simulations.:  24%|██▎       | 2359/10000 [00:09<00:32, 236.15it/s]Running 10000 simulations.:  24%|██▍       | 2383/10000 [00:10<00:32, 235.26it/s]Running 10000 simulations.:  24%|██▍       | 2407/10000 [00:10<00:32, 235.14it/s]Running 10000 simulations.:  24%|██▍       | 2431/10000 [00:10<00:32, 236.19it/s]Running 10000 simulations.:  25%|██▍       | 2455/10000 [00:10<00:32, 235.67it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:10<00:31, 235.86it/s]Running 10000 simulations.:  25%|██▌       | 2503/10000 [00:10<00:31, 235.42it/s]Running 10000 simulations.:  25%|██▌       | 2527/10000 [00:10<00:31, 235.14it/s]Running 10000 simulations.:  26%|██▌       | 2551/10000 [00:10<00:31, 234.93it/s]Running 10000 simulations.:  26%|██▌       | 2575/10000 [00:10<00:31, 235.03it/s]Running 10000 simulations.:  26%|██▌       | 2599/10000 [00:10<00:31, 234.90it/s]Running 10000 simulations.:  26%|██▌       | 2623/10000 [00:11<00:31, 234.83it/s]Running 10000 simulations.:  26%|██▋       | 2647/10000 [00:11<00:31, 234.91it/s]Running 10000 simulations.:  27%|██▋       | 2671/10000 [00:11<00:31, 234.67it/s]Running 10000 simulations.:  27%|██▋       | 2695/10000 [00:11<00:31, 234.73it/s]Running 10000 simulations.:  27%|██▋       | 2719/10000 [00:11<00:30, 235.02it/s]Running 10000 simulations.:  27%|██▋       | 2743/10000 [00:11<00:30, 235.42it/s]Running 10000 simulations.:  28%|██▊       | 2767/10000 [00:11<00:30, 235.88it/s]Running 10000 simulations.:  28%|██▊       | 2791/10000 [00:11<00:30, 236.14it/s]Running 10000 simulations.:  28%|██▊       | 2815/10000 [00:11<00:30, 235.42it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:11<00:30, 236.10it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:12<00:30, 236.75it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:12<00:30, 235.33it/s]Running 10000 simulations.:  29%|██▉       | 2911/10000 [00:12<00:30, 232.64it/s]Running 10000 simulations.:  29%|██▉       | 2935/10000 [00:12<00:30, 233.02it/s]Running 10000 simulations.:  30%|██▉       | 2959/10000 [00:12<00:30, 234.53it/s]Running 10000 simulations.:  30%|██▉       | 2983/10000 [00:12<00:29, 235.63it/s]Running 10000 simulations.:  30%|███       | 3007/10000 [00:12<00:29, 235.55it/s]Running 10000 simulations.:  30%|███       | 3031/10000 [00:12<00:29, 235.07it/s]Running 10000 simulations.:  31%|███       | 3055/10000 [00:12<00:29, 234.67it/s]Running 10000 simulations.:  31%|███       | 3079/10000 [00:12<00:29, 234.43it/s]Running 10000 simulations.:  31%|███       | 3103/10000 [00:13<00:29, 234.39it/s]Running 10000 simulations.:  31%|███▏      | 3127/10000 [00:13<00:29, 234.15it/s]Running 10000 simulations.:  32%|███▏      | 3151/10000 [00:13<00:29, 230.85it/s]Running 10000 simulations.:  32%|███▏      | 3175/10000 [00:13<00:29, 230.59it/s]Running 10000 simulations.:  32%|███▏      | 3199/10000 [00:13<00:29, 231.45it/s]Running 10000 simulations.:  32%|███▏      | 3223/10000 [00:13<00:29, 232.24it/s]Running 10000 simulations.:  32%|███▏      | 3247/10000 [00:13<00:29, 232.84it/s]Running 10000 simulations.:  33%|███▎      | 3271/10000 [00:13<00:28, 233.24it/s]Running 10000 simulations.:  33%|███▎      | 3295/10000 [00:13<00:28, 233.61it/s]Running 10000 simulations.:  33%|███▎      | 3319/10000 [00:14<00:28, 233.40it/s]Running 10000 simulations.:  33%|███▎      | 3343/10000 [00:14<00:28, 233.64it/s]Running 10000 simulations.:  34%|███▎      | 3367/10000 [00:14<00:28, 233.80it/s]Running 10000 simulations.:  34%|███▍      | 3391/10000 [00:14<00:28, 233.95it/s]Running 10000 simulations.:  34%|███▍      | 3415/10000 [00:14<00:28, 233.67it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:14<00:28, 233.32it/s]Running 10000 simulations.:  35%|███▍      | 3463/10000 [00:14<00:27, 233.72it/s]Running 10000 simulations.:  35%|███▍      | 3487/10000 [00:14<00:27, 234.44it/s]Running 10000 simulations.:  35%|███▌      | 3511/10000 [00:14<00:27, 234.66it/s]Running 10000 simulations.:  35%|███▌      | 3535/10000 [00:14<00:27, 234.02it/s]Running 10000 simulations.:  36%|███▌      | 3559/10000 [00:15<00:27, 234.06it/s]Running 10000 simulations.:  36%|███▌      | 3583/10000 [00:15<00:27, 234.36it/s]Running 10000 simulations.:  36%|███▌      | 3607/10000 [00:15<00:27, 233.83it/s]Running 10000 simulations.:  36%|███▋      | 3631/10000 [00:15<00:27, 232.71it/s]Running 10000 simulations.:  37%|███▋      | 3655/10000 [00:15<00:27, 233.00it/s]Running 10000 simulations.:  37%|███▋      | 3679/10000 [00:15<00:27, 230.13it/s]Running 10000 simulations.:  37%|███▋      | 3703/10000 [00:15<00:27, 230.58it/s]Running 10000 simulations.:  37%|███▋      | 3727/10000 [00:15<00:27, 231.95it/s]Running 10000 simulations.:  38%|███▊      | 3751/10000 [00:15<00:26, 232.81it/s]Running 10000 simulations.:  38%|███▊      | 3775/10000 [00:15<00:26, 233.22it/s]Running 10000 simulations.:  38%|███▊      | 3799/10000 [00:16<00:26, 233.19it/s]Running 10000 simulations.:  38%|███▊      | 3823/10000 [00:16<00:26, 233.84it/s]Running 10000 simulations.:  38%|███▊      | 3847/10000 [00:16<00:26, 235.18it/s]Running 10000 simulations.:  39%|███▊      | 3871/10000 [00:16<00:25, 235.87it/s]Running 10000 simulations.:  39%|███▉      | 3895/10000 [00:16<00:25, 235.40it/s]Running 10000 simulations.:  39%|███▉      | 3919/10000 [00:16<00:25, 235.54it/s]Running 10000 simulations.:  39%|███▉      | 3943/10000 [00:16<00:25, 235.23it/s]Running 10000 simulations.:  40%|███▉      | 3967/10000 [00:16<00:25, 234.51it/s]Running 10000 simulations.:  40%|███▉      | 3991/10000 [00:16<00:25, 234.27it/s]Running 10000 simulations.:  40%|████      | 4015/10000 [00:16<00:25, 233.78it/s]Running 10000 simulations.:  40%|████      | 4039/10000 [00:17<00:25, 233.84it/s]Running 10000 simulations.:  41%|████      | 4063/10000 [00:17<00:25, 233.83it/s]Running 10000 simulations.:  41%|████      | 4087/10000 [00:17<00:25, 234.10it/s]Running 10000 simulations.:  41%|████      | 4111/10000 [00:17<00:25, 234.50it/s]Running 10000 simulations.:  41%|████▏     | 4135/10000 [00:17<00:24, 235.02it/s]Running 10000 simulations.:  42%|████▏     | 4159/10000 [00:17<00:24, 234.48it/s]Running 10000 simulations.:  42%|████▏     | 4183/10000 [00:17<00:24, 235.36it/s]Running 10000 simulations.:  42%|████▏     | 4207/10000 [00:17<00:24, 234.77it/s]Running 10000 simulations.:  42%|████▏     | 4231/10000 [00:17<00:24, 234.47it/s]Running 10000 simulations.:  43%|████▎     | 4255/10000 [00:18<00:24, 233.43it/s]Running 10000 simulations.:  43%|████▎     | 4279/10000 [00:18<00:24, 233.15it/s]Running 10000 simulations.:  43%|████▎     | 4303/10000 [00:18<00:24, 232.64it/s]Running 10000 simulations.:  43%|████▎     | 4327/10000 [00:18<00:24, 232.70it/s]Running 10000 simulations.:  44%|████▎     | 4351/10000 [00:18<00:24, 232.83it/s]Running 10000 simulations.:  44%|████▍     | 4375/10000 [00:18<00:24, 233.36it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:18<00:24, 233.18it/s]Running 10000 simulations.:  44%|████▍     | 4423/10000 [00:18<00:23, 233.54it/s]Running 10000 simulations.:  44%|████▍     | 4447/10000 [00:18<00:23, 233.53it/s]Running 10000 simulations.:  45%|████▍     | 4471/10000 [00:18<00:23, 232.75it/s]Running 10000 simulations.:  45%|████▍     | 4495/10000 [00:19<00:23, 232.99it/s]Running 10000 simulations.:  45%|████▌     | 4519/10000 [00:19<00:23, 233.03it/s]Running 10000 simulations.:  45%|████▌     | 4543/10000 [00:19<00:23, 232.88it/s]Running 10000 simulations.:  46%|████▌     | 4567/10000 [00:19<00:23, 232.93it/s]Running 10000 simulations.:  46%|████▌     | 4591/10000 [00:19<00:23, 232.92it/s]Running 10000 simulations.:  46%|████▌     | 4615/10000 [00:19<00:23, 233.44it/s]Running 10000 simulations.:  46%|████▋     | 4639/10000 [00:19<00:22, 233.56it/s]Running 10000 simulations.:  47%|████▋     | 4663/10000 [00:19<00:22, 233.50it/s]Running 10000 simulations.:  47%|████▋     | 4687/10000 [00:19<00:22, 232.71it/s]Running 10000 simulations.:  47%|████▋     | 4711/10000 [00:19<00:22, 233.44it/s]Running 10000 simulations.:  47%|████▋     | 4735/10000 [00:20<00:22, 233.96it/s]Running 10000 simulations.:  48%|████▊     | 4759/10000 [00:20<00:22, 234.57it/s]Running 10000 simulations.:  48%|████▊     | 4783/10000 [00:20<00:22, 234.11it/s]Running 10000 simulations.:  48%|████▊     | 4807/10000 [00:20<00:22, 234.00it/s]Running 10000 simulations.:  48%|████▊     | 4831/10000 [00:20<00:22, 233.82it/s]Running 10000 simulations.:  49%|████▊     | 4855/10000 [00:20<00:21, 233.99it/s]Running 10000 simulations.:  49%|████▉     | 4879/10000 [00:20<00:21, 234.05it/s]Running 10000 simulations.:  49%|████▉     | 4903/10000 [00:20<00:21, 233.85it/s]Running 10000 simulations.:  49%|████▉     | 4927/10000 [00:20<00:21, 233.77it/s]Running 10000 simulations.:  50%|████▉     | 4951/10000 [00:20<00:21, 233.75it/s]Running 10000 simulations.:  50%|████▉     | 4975/10000 [00:21<00:21, 233.24it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:21<00:21, 233.50it/s]Running 10000 simulations.:  50%|█████     | 5023/10000 [00:21<00:21, 233.44it/s]Running 10000 simulations.:  50%|█████     | 5047/10000 [00:21<00:21, 233.50it/s]Running 10000 simulations.:  51%|█████     | 5071/10000 [00:21<00:21, 233.21it/s]Running 10000 simulations.:  51%|█████     | 5095/10000 [00:21<00:21, 233.54it/s]Running 10000 simulations.:  51%|█████     | 5119/10000 [00:21<00:20, 233.46it/s]Running 10000 simulations.:  51%|█████▏    | 5143/10000 [00:21<00:20, 233.67it/s]Running 10000 simulations.:  52%|█████▏    | 5167/10000 [00:21<00:20, 233.33it/s]Running 10000 simulations.:  52%|█████▏    | 5191/10000 [00:22<00:20, 233.08it/s]Running 10000 simulations.:  52%|█████▏    | 5215/10000 [00:22<00:20, 231.89it/s]Running 10000 simulations.:  52%|█████▏    | 5239/10000 [00:22<00:20, 233.03it/s]Running 10000 simulations.:  53%|█████▎    | 5263/10000 [00:22<00:20, 233.18it/s]Running 10000 simulations.:  53%|█████▎    | 5287/10000 [00:22<00:20, 232.99it/s]Running 10000 simulations.:  53%|█████▎    | 5311/10000 [00:22<00:20, 232.76it/s]Running 10000 simulations.:  53%|█████▎    | 5335/10000 [00:22<00:20, 230.81it/s]Running 10000 simulations.:  54%|█████▎    | 5359/10000 [00:22<00:20, 230.10it/s]Running 10000 simulations.:  54%|█████▍    | 5383/10000 [00:22<00:19, 230.93it/s]Running 10000 simulations.:  54%|█████▍    | 5407/10000 [00:22<00:19, 231.45it/s]Running 10000 simulations.:  54%|█████▍    | 5431/10000 [00:23<00:19, 231.68it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:23<00:19, 232.32it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:23<00:19, 232.70it/s]Running 10000 simulations.:  55%|█████▌    | 5503/10000 [00:23<00:19, 232.99it/s]Running 10000 simulations.:  55%|█████▌    | 5527/10000 [00:23<00:19, 233.06it/s]Running 10000 simulations.:  56%|█████▌    | 5551/10000 [00:23<00:19, 233.14it/s]Running 10000 simulations.:  56%|█████▌    | 5575/10000 [00:23<00:19, 232.72it/s]Running 10000 simulations.:  56%|█████▌    | 5599/10000 [00:23<00:18, 233.12it/s]Running 10000 simulations.:  56%|█████▌    | 5623/10000 [00:23<00:18, 232.74it/s]Running 10000 simulations.:  56%|█████▋    | 5647/10000 [00:23<00:18, 232.95it/s]Running 10000 simulations.:  57%|█████▋    | 5671/10000 [00:24<00:18, 233.05it/s]Running 10000 simulations.:  57%|█████▋    | 5695/10000 [00:24<00:18, 232.97it/s]Running 10000 simulations.:  57%|█████▋    | 5719/10000 [00:24<00:18, 232.89it/s]Running 10000 simulations.:  57%|█████▋    | 5743/10000 [00:24<00:18, 231.35it/s]Running 10000 simulations.:  58%|█████▊    | 5767/10000 [00:24<00:18, 228.84it/s]Running 10000 simulations.:  58%|█████▊    | 5791/10000 [00:24<00:18, 229.76it/s]Running 10000 simulations.:  58%|█████▊    | 5815/10000 [00:24<00:18, 230.48it/s]Running 10000 simulations.:  58%|█████▊    | 5839/10000 [00:24<00:17, 231.24it/s]Running 10000 simulations.:  59%|█████▊    | 5863/10000 [00:24<00:17, 231.34it/s]Running 10000 simulations.:  59%|█████▉    | 5887/10000 [00:25<00:17, 231.45it/s]Running 10000 simulations.:  59%|█████▉    | 5911/10000 [00:25<00:17, 231.65it/s]Running 10000 simulations.:  59%|█████▉    | 5935/10000 [00:25<00:17, 232.89it/s]Running 10000 simulations.:  60%|█████▉    | 5959/10000 [00:25<00:17, 233.22it/s]Running 10000 simulations.:  60%|█████▉    | 5983/10000 [00:25<00:17, 232.96it/s]Running 10000 simulations.:  60%|██████    | 6007/10000 [00:25<00:17, 232.78it/s]Running 10000 simulations.:  60%|██████    | 6031/10000 [00:25<00:17, 233.03it/s]Running 10000 simulations.:  61%|██████    | 6055/10000 [00:25<00:16, 232.82it/s]Running 10000 simulations.:  61%|██████    | 6079/10000 [00:25<00:16, 232.80it/s]Running 10000 simulations.:  61%|██████    | 6103/10000 [00:25<00:16, 232.74it/s]Running 10000 simulations.:  61%|██████▏   | 6127/10000 [00:26<00:16, 232.36it/s]Running 10000 simulations.:  62%|██████▏   | 6151/10000 [00:26<00:16, 231.99it/s]Running 10000 simulations.:  62%|██████▏   | 6175/10000 [00:26<00:16, 232.47it/s]Running 10000 simulations.:  62%|██████▏   | 6199/10000 [00:26<00:16, 232.66it/s]Running 10000 simulations.:  62%|██████▏   | 6223/10000 [00:26<00:16, 232.50it/s]Running 10000 simulations.:  62%|██████▏   | 6247/10000 [00:26<00:16, 232.50it/s]Running 10000 simulations.:  63%|██████▎   | 6271/10000 [00:26<00:16, 232.59it/s]Running 10000 simulations.:  63%|██████▎   | 6295/10000 [00:26<00:15, 232.52it/s]Running 10000 simulations.:  63%|██████▎   | 6319/10000 [00:26<00:15, 231.90it/s]Running 10000 simulations.:  63%|██████▎   | 6343/10000 [00:26<00:15, 231.31it/s]Running 10000 simulations.:  64%|██████▎   | 6367/10000 [00:27<00:15, 231.13it/s]Running 10000 simulations.:  64%|██████▍   | 6391/10000 [00:27<00:15, 231.30it/s]Running 10000 simulations.:  64%|██████▍   | 6415/10000 [00:27<00:15, 231.89it/s]Running 10000 simulations.:  64%|██████▍   | 6439/10000 [00:27<00:15, 231.88it/s]Running 10000 simulations.:  65%|██████▍   | 6463/10000 [00:27<00:15, 231.36it/s]Running 10000 simulations.:  65%|██████▍   | 6487/10000 [00:27<00:15, 231.20it/s]Running 10000 simulations.:  65%|██████▌   | 6511/10000 [00:27<00:15, 230.87it/s]Running 10000 simulations.:  65%|██████▌   | 6535/10000 [00:27<00:15, 230.88it/s]Running 10000 simulations.:  66%|██████▌   | 6559/10000 [00:27<00:14, 230.98it/s]Running 10000 simulations.:  66%|██████▌   | 6583/10000 [00:28<00:14, 231.28it/s]Running 10000 simulations.:  66%|██████▌   | 6607/10000 [00:28<00:14, 231.58it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:28<00:14, 231.66it/s]Running 10000 simulations.:  67%|██████▋   | 6655/10000 [00:28<00:14, 231.34it/s]Running 10000 simulations.:  67%|██████▋   | 6679/10000 [00:28<00:14, 226.69it/s]Running 10000 simulations.:  67%|██████▋   | 6702/10000 [00:28<00:14, 223.82it/s]Running 10000 simulations.:  67%|██████▋   | 6725/10000 [00:28<00:14, 220.97it/s]Running 10000 simulations.:  67%|██████▋   | 6748/10000 [00:28<00:15, 216.58it/s]Running 10000 simulations.:  68%|██████▊   | 6770/10000 [00:28<00:15, 213.76it/s]Running 10000 simulations.:  68%|██████▊   | 6792/10000 [00:28<00:15, 211.61it/s]Running 10000 simulations.:  68%|██████▊   | 6814/10000 [00:29<00:15, 210.77it/s]Running 10000 simulations.:  68%|██████▊   | 6836/10000 [00:29<00:15, 210.30it/s]Running 10000 simulations.:  69%|██████▊   | 6858/10000 [00:29<00:14, 210.05it/s]Running 10000 simulations.:  69%|██████▉   | 6880/10000 [00:29<00:14, 211.48it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:29<00:14, 212.02it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:29<00:14, 211.20it/s]Running 10000 simulations.:  69%|██████▉   | 6946/10000 [00:29<00:14, 211.58it/s]Running 10000 simulations.:  70%|██████▉   | 6968/10000 [00:29<00:14, 210.79it/s]Running 10000 simulations.:  70%|██████▉   | 6990/10000 [00:29<00:14, 209.64it/s]Running 10000 simulations.:  70%|███████   | 7012/10000 [00:30<00:14, 210.17it/s]Running 10000 simulations.:  70%|███████   | 7034/10000 [00:30<00:14, 211.12it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:30<00:14, 209.04it/s]Running 10000 simulations.:  71%|███████   | 7078/10000 [00:30<00:13, 209.97it/s]Running 10000 simulations.:  71%|███████   | 7100/10000 [00:30<00:13, 211.56it/s]Running 10000 simulations.:  71%|███████   | 7122/10000 [00:30<00:13, 211.24it/s]Running 10000 simulations.:  71%|███████▏  | 7144/10000 [00:30<00:13, 208.05it/s]Running 10000 simulations.:  72%|███████▏  | 7166/10000 [00:30<00:13, 209.72it/s]Running 10000 simulations.:  72%|███████▏  | 7188/10000 [00:30<00:13, 210.69it/s]Running 10000 simulations.:  72%|███████▏  | 7210/10000 [00:30<00:13, 211.07it/s]Running 10000 simulations.:  72%|███████▏  | 7232/10000 [00:31<00:13, 212.07it/s]Running 10000 simulations.:  73%|███████▎  | 7254/10000 [00:31<00:12, 212.42it/s]Running 10000 simulations.:  73%|███████▎  | 7276/10000 [00:31<00:12, 212.03it/s]Running 10000 simulations.:  73%|███████▎  | 7298/10000 [00:31<00:12, 212.44it/s]Running 10000 simulations.:  73%|███████▎  | 7320/10000 [00:31<00:12, 211.39it/s]Running 10000 simulations.:  73%|███████▎  | 7342/10000 [00:31<00:12, 210.52it/s]Running 10000 simulations.:  74%|███████▎  | 7364/10000 [00:31<00:12, 210.77it/s]Running 10000 simulations.:  74%|███████▍  | 7386/10000 [00:31<00:12, 211.17it/s]Running 10000 simulations.:  74%|███████▍  | 7408/10000 [00:31<00:12, 211.40it/s]Running 10000 simulations.:  74%|███████▍  | 7430/10000 [00:32<00:12, 211.93it/s]Running 10000 simulations.:  75%|███████▍  | 7452/10000 [00:32<00:11, 212.95it/s]Running 10000 simulations.:  75%|███████▍  | 7474/10000 [00:32<00:11, 212.08it/s]Running 10000 simulations.:  75%|███████▍  | 7496/10000 [00:32<00:11, 211.77it/s]Running 10000 simulations.:  75%|███████▌  | 7518/10000 [00:32<00:11, 211.91it/s]Running 10000 simulations.:  75%|███████▌  | 7540/10000 [00:32<00:11, 212.45it/s]Running 10000 simulations.:  76%|███████▌  | 7562/10000 [00:32<00:11, 212.61it/s]Running 10000 simulations.:  76%|███████▌  | 7584/10000 [00:32<00:11, 212.96it/s]Running 10000 simulations.:  76%|███████▌  | 7606/10000 [00:32<00:11, 213.16it/s]Running 10000 simulations.:  76%|███████▋  | 7628/10000 [00:32<00:11, 212.50it/s]Running 10000 simulations.:  76%|███████▋  | 7650/10000 [00:33<00:11, 213.47it/s]Running 10000 simulations.:  77%|███████▋  | 7672/10000 [00:33<00:10, 213.36it/s]Running 10000 simulations.:  77%|███████▋  | 7694/10000 [00:33<00:10, 212.34it/s]Running 10000 simulations.:  77%|███████▋  | 7716/10000 [00:33<00:10, 211.42it/s]Running 10000 simulations.:  77%|███████▋  | 7738/10000 [00:33<00:10, 212.27it/s]Running 10000 simulations.:  78%|███████▊  | 7760/10000 [00:33<00:10, 212.23it/s]Running 10000 simulations.:  78%|███████▊  | 7782/10000 [00:33<00:10, 212.47it/s]Running 10000 simulations.:  78%|███████▊  | 7804/10000 [00:33<00:10, 213.59it/s]Running 10000 simulations.:  78%|███████▊  | 7826/10000 [00:33<00:10, 214.26it/s]Running 10000 simulations.:  78%|███████▊  | 7848/10000 [00:33<00:10, 214.43it/s]Running 10000 simulations.:  79%|███████▊  | 7870/10000 [00:34<00:09, 214.27it/s]Running 10000 simulations.:  79%|███████▉  | 7892/10000 [00:34<00:09, 212.70it/s]Running 10000 simulations.:  79%|███████▉  | 7914/10000 [00:34<00:09, 211.75it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:34<00:09, 212.58it/s]Running 10000 simulations.:  80%|███████▉  | 7958/10000 [00:34<00:09, 212.94it/s]Running 10000 simulations.:  80%|███████▉  | 7980/10000 [00:34<00:09, 214.00it/s]Running 10000 simulations.:  80%|████████  | 8002/10000 [00:34<00:09, 214.97it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:34<00:09, 215.87it/s]Running 10000 simulations.:  80%|████████  | 8046/10000 [00:34<00:09, 216.38it/s]Running 10000 simulations.:  81%|████████  | 8068/10000 [00:34<00:08, 216.20it/s]Running 10000 simulations.:  81%|████████  | 8090/10000 [00:35<00:08, 214.89it/s]Running 10000 simulations.:  81%|████████  | 8112/10000 [00:35<00:08, 212.50it/s]Running 10000 simulations.:  81%|████████▏ | 8134/10000 [00:35<00:08, 212.42it/s]Running 10000 simulations.:  82%|████████▏ | 8156/10000 [00:35<00:08, 212.62it/s]Running 10000 simulations.:  82%|████████▏ | 8178/10000 [00:35<00:08, 213.04it/s]Running 10000 simulations.:  82%|████████▏ | 8200/10000 [00:35<00:08, 213.34it/s]Running 10000 simulations.:  82%|████████▏ | 8222/10000 [00:35<00:08, 214.14it/s]Running 10000 simulations.:  82%|████████▏ | 8244/10000 [00:35<00:08, 214.93it/s]Running 10000 simulations.:  83%|████████▎ | 8266/10000 [00:35<00:08, 215.08it/s]Running 10000 simulations.:  83%|████████▎ | 8288/10000 [00:36<00:07, 215.39it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:36<00:07, 213.46it/s]Running 10000 simulations.:  83%|████████▎ | 8332/10000 [00:36<00:07, 212.00it/s]Running 10000 simulations.:  84%|████████▎ | 8354/10000 [00:36<00:07, 212.30it/s]Running 10000 simulations.:  84%|████████▍ | 8376/10000 [00:36<00:07, 213.81it/s]Running 10000 simulations.:  84%|████████▍ | 8398/10000 [00:36<00:07, 214.69it/s]Running 10000 simulations.:  84%|████████▍ | 8421/10000 [00:36<00:07, 217.94it/s]Running 10000 simulations.:  84%|████████▍ | 8443/10000 [00:36<00:07, 216.60it/s]Running 10000 simulations.:  85%|████████▍ | 8465/10000 [00:36<00:07, 217.09it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [00:36<00:06, 217.75it/s]Running 10000 simulations.:  85%|████████▌ | 8510/10000 [00:37<00:06, 218.34it/s]Running 10000 simulations.:  85%|████████▌ | 8532/10000 [00:37<00:06, 218.72it/s]Running 10000 simulations.:  86%|████████▌ | 8554/10000 [00:37<00:06, 218.10it/s]Running 10000 simulations.:  86%|████████▌ | 8576/10000 [00:37<00:06, 217.49it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [00:37<00:06, 217.66it/s]Running 10000 simulations.:  86%|████████▌ | 8620/10000 [00:37<00:06, 217.86it/s]Running 10000 simulations.:  86%|████████▋ | 8642/10000 [00:37<00:06, 217.51it/s]Running 10000 simulations.:  87%|████████▋ | 8664/10000 [00:37<00:06, 215.17it/s]Running 10000 simulations.:  87%|████████▋ | 8686/10000 [00:37<00:06, 215.14it/s]Running 10000 simulations.:  87%|████████▋ | 8708/10000 [00:37<00:06, 214.49it/s]Running 10000 simulations.:  87%|████████▋ | 8730/10000 [00:38<00:06, 204.81it/s]Running 10000 simulations.:  88%|████████▊ | 8751/10000 [00:38<00:06, 204.26it/s]Running 10000 simulations.:  88%|████████▊ | 8772/10000 [00:38<00:05, 205.53it/s]Running 10000 simulations.:  88%|████████▊ | 8793/10000 [00:38<00:05, 206.48it/s]Running 10000 simulations.:  88%|████████▊ | 8814/10000 [00:38<00:05, 207.14it/s]Running 10000 simulations.:  88%|████████▊ | 8836/10000 [00:38<00:05, 208.54it/s]Running 10000 simulations.:  89%|████████▊ | 8857/10000 [00:38<00:05, 208.51it/s]Running 10000 simulations.:  89%|████████▉ | 8878/10000 [00:38<00:05, 207.18it/s]Running 10000 simulations.:  89%|████████▉ | 8899/10000 [00:38<00:05, 207.74it/s]Running 10000 simulations.:  89%|████████▉ | 8920/10000 [00:38<00:05, 207.38it/s]Running 10000 simulations.:  89%|████████▉ | 8941/10000 [00:39<00:05, 207.81it/s]Running 10000 simulations.:  90%|████████▉ | 8962/10000 [00:39<00:04, 207.79it/s]Running 10000 simulations.:  90%|████████▉ | 8984/10000 [00:39<00:04, 208.46it/s]Running 10000 simulations.:  90%|█████████ | 9005/10000 [00:39<00:04, 208.09it/s]Running 10000 simulations.:  90%|█████████ | 9026/10000 [00:39<00:04, 207.66it/s]Running 10000 simulations.:  90%|█████████ | 9047/10000 [00:39<00:04, 206.34it/s]Running 10000 simulations.:  91%|█████████ | 9068/10000 [00:39<00:04, 206.97it/s]Running 10000 simulations.:  91%|█████████ | 9089/10000 [00:39<00:04, 207.28it/s]Running 10000 simulations.:  91%|█████████ | 9110/10000 [00:39<00:04, 207.99it/s]Running 10000 simulations.:  91%|█████████▏| 9132/10000 [00:40<00:04, 208.96it/s]Running 10000 simulations.:  92%|█████████▏| 9153/10000 [00:40<00:04, 208.07it/s]Running 10000 simulations.:  92%|█████████▏| 9174/10000 [00:40<00:03, 207.39it/s]Running 10000 simulations.:  92%|█████████▏| 9195/10000 [00:40<00:03, 208.09it/s]Running 10000 simulations.:  92%|█████████▏| 9216/10000 [00:40<00:03, 206.94it/s]Running 10000 simulations.:  92%|█████████▏| 9237/10000 [00:40<00:03, 206.80it/s]Running 10000 simulations.:  93%|█████████▎| 9259/10000 [00:40<00:03, 208.05it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [00:40<00:03, 214.04it/s]Running 10000 simulations.:  93%|█████████▎| 9306/10000 [00:40<00:03, 218.73it/s]Running 10000 simulations.:  93%|█████████▎| 9329/10000 [00:40<00:03, 221.94it/s]Running 10000 simulations.:  94%|█████████▎| 9352/10000 [00:41<00:02, 223.80it/s]Running 10000 simulations.:  94%|█████████▍| 9375/10000 [00:41<00:02, 225.07it/s]Running 10000 simulations.:  94%|█████████▍| 9398/10000 [00:41<00:02, 226.16it/s]Running 10000 simulations.:  94%|█████████▍| 9421/10000 [00:41<00:02, 226.85it/s]Running 10000 simulations.:  94%|█████████▍| 9444/10000 [00:41<00:02, 226.85it/s]Running 10000 simulations.:  95%|█████████▍| 9467/10000 [00:41<00:02, 227.46it/s]Running 10000 simulations.:  95%|█████████▍| 9491/10000 [00:41<00:02, 228.30it/s]Running 10000 simulations.:  95%|█████████▌| 9515/10000 [00:41<00:02, 229.34it/s]Running 10000 simulations.:  95%|█████████▌| 9539/10000 [00:41<00:02, 229.70it/s]Running 10000 simulations.:  96%|█████████▌| 9562/10000 [00:41<00:02, 208.86it/s]Running 10000 simulations.:  96%|█████████▌| 9584/10000 [00:42<00:02, 191.50it/s]Running 10000 simulations.:  96%|█████████▌| 9604/10000 [00:42<00:02, 181.19it/s]Running 10000 simulations.:  96%|█████████▌| 9623/10000 [00:42<00:02, 176.43it/s]Running 10000 simulations.:  96%|█████████▋| 9642/10000 [00:42<00:02, 171.51it/s]Running 10000 simulations.:  97%|█████████▋| 9660/10000 [00:42<00:02, 168.47it/s]Running 10000 simulations.:  97%|█████████▋| 9678/10000 [00:42<00:01, 167.36it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:42<00:01, 166.97it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [00:42<00:01, 166.69it/s]Running 10000 simulations.:  97%|█████████▋| 9729/10000 [00:43<00:01, 166.15it/s]Running 10000 simulations.:  97%|█████████▋| 9746/10000 [00:43<00:01, 165.84it/s]Running 10000 simulations.:  98%|█████████▊| 9764/10000 [00:43<00:01, 168.86it/s]Running 10000 simulations.:  98%|█████████▊| 9782/10000 [00:43<00:01, 169.87it/s]Running 10000 simulations.:  98%|█████████▊| 9800/10000 [00:43<00:01, 167.06it/s]Running 10000 simulations.:  98%|█████████▊| 9817/10000 [00:43<00:01, 166.43it/s]Running 10000 simulations.:  98%|█████████▊| 9834/10000 [00:43<00:01, 165.81it/s]Running 10000 simulations.:  99%|█████████▊| 9852/10000 [00:43<00:00, 168.01it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [00:43<00:00, 169.68it/s]Running 10000 simulations.:  99%|█████████▉| 9887/10000 [00:43<00:00, 169.66it/s]Running 10000 simulations.:  99%|█████████▉| 9904/10000 [00:44<00:00, 168.22it/s]Running 10000 simulations.:  99%|█████████▉| 9921/10000 [00:44<00:00, 167.92it/s]Running 10000 simulations.:  99%|█████████▉| 9938/10000 [00:44<00:00, 167.66it/s]Running 10000 simulations.: 100%|█████████▉| 9955/10000 [00:44<00:00, 168.21it/s]Running 10000 simulations.: 100%|█████████▉| 9972/10000 [00:44<00:00, 168.60it/s]Running 10000 simulations.: 100%|█████████▉| 9989/10000 [00:44<00:00, 165.65it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:44<00:00, 224.10it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 24/10000 [00:00<00:42, 237.49it/s]Running 10000 simulations.:   0%|          | 48/10000 [00:00<00:41, 236.99it/s]Running 10000 simulations.:   1%|          | 72/10000 [00:00<00:42, 236.16it/s]Running 10000 simulations.:   1%|          | 96/10000 [00:00<00:42, 234.41it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<00:42, 234.09it/s]Running 10000 simulations.:   1%|▏         | 144/10000 [00:00<00:42, 234.06it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:41, 234.64it/s]Running 10000 simulations.:   2%|▏         | 192/10000 [00:00<00:41, 234.49it/s]Running 10000 simulations.:   2%|▏         | 216/10000 [00:00<00:41, 234.38it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:01<00:41, 234.57it/s]Running 10000 simulations.:   3%|▎         | 263/10000 [00:01<00:41, 232.96it/s]Running 10000 simulations.:   3%|▎         | 286/10000 [00:01<00:42, 231.04it/s]Running 10000 simulations.:   3%|▎         | 309/10000 [00:01<00:42, 230.25it/s]Running 10000 simulations.:   3%|▎         | 332/10000 [00:01<00:42, 229.48it/s]Running 10000 simulations.:   4%|▎         | 355/10000 [00:01<00:42, 229.51it/s]Running 10000 simulations.:   4%|▍         | 379/10000 [00:01<00:41, 229.98it/s]Running 10000 simulations.:   4%|▍         | 402/10000 [00:01<00:41, 228.93it/s]Running 10000 simulations.:   4%|▍         | 425/10000 [00:01<00:41, 228.55it/s]Running 10000 simulations.:   4%|▍         | 448/10000 [00:01<00:41, 227.96it/s]Running 10000 simulations.:   5%|▍         | 471/10000 [00:02<00:41, 227.56it/s]Running 10000 simulations.:   5%|▍         | 494/10000 [00:02<00:41, 228.00it/s]Running 10000 simulations.:   5%|▌         | 517/10000 [00:02<00:41, 228.03it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:02<00:41, 227.40it/s]Running 10000 simulations.:   6%|▌         | 563/10000 [00:02<00:41, 227.07it/s]Running 10000 simulations.:   6%|▌         | 586/10000 [00:02<00:41, 227.79it/s]Running 10000 simulations.:   6%|▌         | 610/10000 [00:02<00:41, 228.56it/s]Running 10000 simulations.:   6%|▋         | 633/10000 [00:02<00:40, 228.76it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:02<00:40, 228.43it/s]Running 10000 simulations.:   7%|▋         | 679/10000 [00:02<00:40, 228.27it/s]Running 10000 simulations.:   7%|▋         | 702/10000 [00:03<00:40, 228.28it/s]Running 10000 simulations.:   7%|▋         | 725/10000 [00:03<00:40, 228.66it/s]Running 10000 simulations.:   7%|▋         | 748/10000 [00:03<00:40, 227.79it/s]Running 10000 simulations.:   8%|▊         | 771/10000 [00:03<00:40, 226.82it/s]Running 10000 simulations.:   8%|▊         | 794/10000 [00:03<00:40, 226.35it/s]Running 10000 simulations.:   8%|▊         | 817/10000 [00:03<00:40, 226.11it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:03<00:40, 225.57it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:03<00:40, 227.06it/s]Running 10000 simulations.:   9%|▉         | 889/10000 [00:03<00:39, 231.16it/s]Running 10000 simulations.:   9%|▉         | 914/10000 [00:03<00:38, 234.81it/s]Running 10000 simulations.:   9%|▉         | 939/10000 [00:04<00:38, 237.40it/s]Running 10000 simulations.:  10%|▉         | 964/10000 [00:04<00:37, 238.72it/s]Running 10000 simulations.:  10%|▉         | 988/10000 [00:04<00:37, 238.41it/s]Running 10000 simulations.:  10%|█         | 1013/10000 [00:04<00:37, 238.99it/s]Running 10000 simulations.:  10%|█         | 1038/10000 [00:04<00:37, 239.91it/s]Running 10000 simulations.:  11%|█         | 1063/10000 [00:04<00:37, 240.42it/s]Running 10000 simulations.:  11%|█         | 1088/10000 [00:04<00:36, 241.19it/s]Running 10000 simulations.:  11%|█         | 1113/10000 [00:04<00:36, 241.86it/s]Running 10000 simulations.:  11%|█▏        | 1138/10000 [00:04<00:36, 241.75it/s]Running 10000 simulations.:  12%|█▏        | 1163/10000 [00:04<00:36, 242.41it/s]Running 10000 simulations.:  12%|█▏        | 1188/10000 [00:05<00:39, 223.87it/s]Running 10000 simulations.:  12%|█▏        | 1211/10000 [00:05<00:41, 212.52it/s]Running 10000 simulations.:  12%|█▏        | 1233/10000 [00:05<00:43, 202.67it/s]Running 10000 simulations.:  13%|█▎        | 1254/10000 [00:05<00:45, 193.43it/s]Running 10000 simulations.:  13%|█▎        | 1274/10000 [00:05<00:45, 191.17it/s]Running 10000 simulations.:  13%|█▎        | 1294/10000 [00:05<00:45, 190.98it/s]Running 10000 simulations.:  13%|█▎        | 1314/10000 [00:05<00:45, 191.00it/s]Running 10000 simulations.:  13%|█▎        | 1334/10000 [00:05<00:45, 191.95it/s]Running 10000 simulations.:  14%|█▎        | 1354/10000 [00:06<00:45, 192.08it/s]Running 10000 simulations.:  14%|█▎        | 1374/10000 [00:06<00:44, 192.21it/s]Running 10000 simulations.:  14%|█▍        | 1394/10000 [00:06<00:44, 193.89it/s]Running 10000 simulations.:  14%|█▍        | 1415/10000 [00:06<00:43, 195.74it/s]Running 10000 simulations.:  14%|█▍        | 1437/10000 [00:06<00:42, 201.73it/s]Running 10000 simulations.:  15%|█▍        | 1459/10000 [00:06<00:41, 204.71it/s]Running 10000 simulations.:  15%|█▍        | 1480/10000 [00:06<00:41, 205.76it/s]Running 10000 simulations.:  15%|█▌        | 1501/10000 [00:06<00:41, 205.92it/s]Running 10000 simulations.:  15%|█▌        | 1523/10000 [00:06<00:40, 208.20it/s]Running 10000 simulations.:  15%|█▌        | 1545/10000 [00:06<00:40, 211.19it/s]Running 10000 simulations.:  16%|█▌        | 1567/10000 [00:07<00:39, 212.52it/s]Running 10000 simulations.:  16%|█▌        | 1589/10000 [00:07<00:39, 212.74it/s]Running 10000 simulations.:  16%|█▌        | 1611/10000 [00:07<00:39, 214.39it/s]Running 10000 simulations.:  16%|█▋        | 1633/10000 [00:07<00:38, 216.02it/s]Running 10000 simulations.:  17%|█▋        | 1655/10000 [00:07<00:38, 215.00it/s]Running 10000 simulations.:  17%|█▋        | 1677/10000 [00:07<00:39, 209.04it/s]Running 10000 simulations.:  17%|█▋        | 1698/10000 [00:07<00:41, 202.07it/s]Running 10000 simulations.:  17%|█▋        | 1719/10000 [00:07<00:41, 200.11it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:07<00:43, 191.80it/s]Running 10000 simulations.:  18%|█▊        | 1760/10000 [00:08<00:42, 191.69it/s]Running 10000 simulations.:  18%|█▊        | 1780/10000 [00:08<00:43, 191.09it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:08<00:42, 193.14it/s]Running 10000 simulations.:  18%|█▊        | 1820/10000 [00:08<00:42, 192.10it/s]Running 10000 simulations.:  18%|█▊        | 1840/10000 [00:08<00:42, 190.30it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:08<00:42, 190.21it/s]Running 10000 simulations.:  19%|█▉        | 1880/10000 [00:08<00:43, 188.79it/s]Running 10000 simulations.:  19%|█▉        | 1901/10000 [00:08<00:42, 192.32it/s]Running 10000 simulations.:  19%|█▉        | 1923/10000 [00:08<00:40, 198.71it/s]Running 10000 simulations.:  19%|█▉        | 1945/10000 [00:08<00:39, 204.31it/s]Running 10000 simulations.:  20%|█▉        | 1967/10000 [00:09<00:38, 208.62it/s]Running 10000 simulations.:  20%|█▉        | 1989/10000 [00:09<00:37, 211.45it/s]Running 10000 simulations.:  20%|██        | 2012/10000 [00:09<00:37, 214.00it/s]Running 10000 simulations.:  20%|██        | 2034/10000 [00:09<00:36, 215.54it/s]Running 10000 simulations.:  21%|██        | 2056/10000 [00:09<00:36, 216.19it/s]Running 10000 simulations.:  21%|██        | 2078/10000 [00:09<00:36, 216.22it/s]Running 10000 simulations.:  21%|██        | 2101/10000 [00:09<00:36, 217.58it/s]Running 10000 simulations.:  21%|██        | 2123/10000 [00:09<00:36, 218.21it/s]Running 10000 simulations.:  21%|██▏       | 2145/10000 [00:09<00:35, 218.48it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:09<00:35, 218.60it/s]Running 10000 simulations.:  22%|██▏       | 2189/10000 [00:10<00:35, 218.67it/s]Running 10000 simulations.:  22%|██▏       | 2211/10000 [00:10<00:35, 218.83it/s]Running 10000 simulations.:  22%|██▏       | 2233/10000 [00:10<00:35, 218.06it/s]Running 10000 simulations.:  23%|██▎       | 2255/10000 [00:10<00:35, 217.24it/s]Running 10000 simulations.:  23%|██▎       | 2277/10000 [00:10<00:35, 217.71it/s]Running 10000 simulations.:  23%|██▎       | 2299/10000 [00:10<00:35, 218.32it/s]Running 10000 simulations.:  23%|██▎       | 2321/10000 [00:10<00:35, 217.39it/s]Running 10000 simulations.:  23%|██▎       | 2343/10000 [00:10<00:35, 217.45it/s]Running 10000 simulations.:  24%|██▎       | 2365/10000 [00:10<00:35, 217.50it/s]Running 10000 simulations.:  24%|██▍       | 2387/10000 [00:10<00:34, 217.74it/s]Running 10000 simulations.:  24%|██▍       | 2409/10000 [00:11<00:34, 217.62it/s]Running 10000 simulations.:  24%|██▍       | 2431/10000 [00:11<00:34, 216.45it/s]Running 10000 simulations.:  25%|██▍       | 2453/10000 [00:11<00:35, 215.28it/s]Running 10000 simulations.:  25%|██▍       | 2476/10000 [00:11<00:34, 216.75it/s]Running 10000 simulations.:  25%|██▍       | 2499/10000 [00:11<00:34, 217.85it/s]Running 10000 simulations.:  25%|██▌       | 2521/10000 [00:11<00:34, 218.46it/s]Running 10000 simulations.:  25%|██▌       | 2544/10000 [00:11<00:34, 219.03it/s]Running 10000 simulations.:  26%|██▌       | 2566/10000 [00:11<00:33, 218.89it/s]Running 10000 simulations.:  26%|██▌       | 2589/10000 [00:11<00:33, 219.78it/s]Running 10000 simulations.:  26%|██▌       | 2612/10000 [00:11<00:33, 220.43it/s]Running 10000 simulations.:  26%|██▋       | 2635/10000 [00:12<00:33, 220.95it/s]Running 10000 simulations.:  27%|██▋       | 2658/10000 [00:12<00:33, 221.41it/s]Running 10000 simulations.:  27%|██▋       | 2681/10000 [00:12<00:32, 222.29it/s]Running 10000 simulations.:  27%|██▋       | 2704/10000 [00:12<00:32, 223.12it/s]Running 10000 simulations.:  27%|██▋       | 2727/10000 [00:12<00:32, 223.26it/s]Running 10000 simulations.:  28%|██▊       | 2750/10000 [00:12<00:32, 222.50it/s]Running 10000 simulations.:  28%|██▊       | 2773/10000 [00:12<00:32, 220.00it/s]Running 10000 simulations.:  28%|██▊       | 2796/10000 [00:12<00:32, 219.03it/s]Running 10000 simulations.:  28%|██▊       | 2818/10000 [00:12<00:32, 218.94it/s]Running 10000 simulations.:  28%|██▊       | 2840/10000 [00:13<00:32, 218.70it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:13<00:32, 219.30it/s]Running 10000 simulations.:  29%|██▉       | 2886/10000 [00:13<00:32, 219.89it/s]Running 10000 simulations.:  29%|██▉       | 2909/10000 [00:13<00:32, 220.39it/s]Running 10000 simulations.:  29%|██▉       | 2932/10000 [00:13<00:31, 221.35it/s]Running 10000 simulations.:  30%|██▉       | 2955/10000 [00:13<00:31, 221.82it/s]Running 10000 simulations.:  30%|██▉       | 2978/10000 [00:13<00:31, 221.48it/s]Running 10000 simulations.:  30%|███       | 3001/10000 [00:13<00:31, 221.48it/s]Running 10000 simulations.:  30%|███       | 3024/10000 [00:13<00:31, 221.80it/s]Running 10000 simulations.:  30%|███       | 3047/10000 [00:13<00:31, 222.19it/s]Running 10000 simulations.:  31%|███       | 3070/10000 [00:14<00:31, 221.87it/s]Running 10000 simulations.:  31%|███       | 3093/10000 [00:14<00:31, 221.93it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:14<00:30, 222.12it/s]Running 10000 simulations.:  31%|███▏      | 3139/10000 [00:14<00:30, 221.92it/s]Running 10000 simulations.:  32%|███▏      | 3162/10000 [00:14<00:30, 222.11it/s]Running 10000 simulations.:  32%|███▏      | 3185/10000 [00:14<00:30, 221.57it/s]Running 10000 simulations.:  32%|███▏      | 3208/10000 [00:14<00:30, 221.71it/s]Running 10000 simulations.:  32%|███▏      | 3231/10000 [00:14<00:30, 221.36it/s]Running 10000 simulations.:  33%|███▎      | 3254/10000 [00:14<00:30, 221.59it/s]Running 10000 simulations.:  33%|███▎      | 3277/10000 [00:14<00:30, 221.93it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:15<00:30, 222.64it/s]Running 10000 simulations.:  33%|███▎      | 3323/10000 [00:15<00:29, 223.12it/s]Running 10000 simulations.:  33%|███▎      | 3346/10000 [00:15<00:29, 222.62it/s]Running 10000 simulations.:  34%|███▎      | 3369/10000 [00:15<00:29, 221.76it/s]Running 10000 simulations.:  34%|███▍      | 3392/10000 [00:15<00:29, 221.12it/s]Running 10000 simulations.:  34%|███▍      | 3415/10000 [00:15<00:29, 221.37it/s]Running 10000 simulations.:  34%|███▍      | 3438/10000 [00:15<00:29, 221.59it/s]Running 10000 simulations.:  35%|███▍      | 3461/10000 [00:15<00:29, 220.83it/s]Running 10000 simulations.:  35%|███▍      | 3484/10000 [00:15<00:29, 220.53it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:16<00:29, 220.46it/s]Running 10000 simulations.:  35%|███▌      | 3530/10000 [00:16<00:29, 220.82it/s]Running 10000 simulations.:  36%|███▌      | 3553/10000 [00:16<00:29, 221.36it/s]Running 10000 simulations.:  36%|███▌      | 3576/10000 [00:16<00:28, 221.60it/s]Running 10000 simulations.:  36%|███▌      | 3599/10000 [00:16<00:28, 221.58it/s]Running 10000 simulations.:  36%|███▌      | 3622/10000 [00:16<00:28, 220.36it/s]Running 10000 simulations.:  36%|███▋      | 3645/10000 [00:16<00:28, 220.33it/s]Running 10000 simulations.:  37%|███▋      | 3668/10000 [00:16<00:28, 220.74it/s]Running 10000 simulations.:  37%|███▋      | 3691/10000 [00:16<00:28, 220.77it/s]Running 10000 simulations.:  37%|███▋      | 3714/10000 [00:16<00:28, 220.98it/s]Running 10000 simulations.:  37%|███▋      | 3737/10000 [00:17<00:28, 221.76it/s]Running 10000 simulations.:  38%|███▊      | 3760/10000 [00:17<00:28, 221.57it/s]Running 10000 simulations.:  38%|███▊      | 3783/10000 [00:17<00:28, 220.77it/s]Running 10000 simulations.:  38%|███▊      | 3806/10000 [00:17<00:28, 219.03it/s]Running 10000 simulations.:  38%|███▊      | 3828/10000 [00:17<00:28, 218.77it/s]Running 10000 simulations.:  39%|███▊      | 3851/10000 [00:17<00:27, 219.88it/s]Running 10000 simulations.:  39%|███▊      | 3874/10000 [00:17<00:27, 220.33it/s]Running 10000 simulations.:  39%|███▉      | 3897/10000 [00:17<00:27, 220.75it/s]Running 10000 simulations.:  39%|███▉      | 3920/10000 [00:17<00:27, 221.18it/s]Running 10000 simulations.:  39%|███▉      | 3943/10000 [00:18<00:27, 221.36it/s]Running 10000 simulations.:  40%|███▉      | 3966/10000 [00:18<00:27, 222.34it/s]Running 10000 simulations.:  40%|███▉      | 3989/10000 [00:18<00:26, 223.18it/s]Running 10000 simulations.:  40%|████      | 4012/10000 [00:18<00:26, 223.06it/s]Running 10000 simulations.:  40%|████      | 4035/10000 [00:18<00:26, 222.42it/s]Running 10000 simulations.:  41%|████      | 4058/10000 [00:18<00:26, 221.75it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:18<00:26, 221.17it/s]Running 10000 simulations.:  41%|████      | 4104/10000 [00:18<00:26, 220.63it/s]Running 10000 simulations.:  41%|████▏     | 4127/10000 [00:18<00:26, 221.53it/s]Running 10000 simulations.:  42%|████▏     | 4150/10000 [00:18<00:26, 221.73it/s]Running 10000 simulations.:  42%|████▏     | 4173/10000 [00:19<00:26, 222.19it/s]Running 10000 simulations.:  42%|████▏     | 4196/10000 [00:19<00:26, 222.82it/s]Running 10000 simulations.:  42%|████▏     | 4219/10000 [00:19<00:26, 222.18it/s]Running 10000 simulations.:  42%|████▏     | 4242/10000 [00:19<00:25, 222.26it/s]Running 10000 simulations.:  43%|████▎     | 4265/10000 [00:19<00:25, 222.03it/s]Running 10000 simulations.:  43%|████▎     | 4288/10000 [00:19<00:25, 221.55it/s]Running 10000 simulations.:  43%|████▎     | 4311/10000 [00:19<00:25, 221.74it/s]Running 10000 simulations.:  43%|████▎     | 4334/10000 [00:19<00:25, 221.95it/s]Running 10000 simulations.:  44%|████▎     | 4357/10000 [00:19<00:25, 223.04it/s]Running 10000 simulations.:  44%|████▍     | 4380/10000 [00:19<00:25, 223.73it/s]Running 10000 simulations.:  44%|████▍     | 4403/10000 [00:20<00:25, 223.51it/s]Running 10000 simulations.:  44%|████▍     | 4426/10000 [00:20<00:24, 223.05it/s]Running 10000 simulations.:  44%|████▍     | 4449/10000 [00:20<00:24, 222.55it/s]Running 10000 simulations.:  45%|████▍     | 4472/10000 [00:20<00:24, 223.05it/s]Running 10000 simulations.:  45%|████▍     | 4495/10000 [00:20<00:24, 223.12it/s]Running 10000 simulations.:  45%|████▌     | 4518/10000 [00:20<00:24, 222.78it/s]Running 10000 simulations.:  45%|████▌     | 4541/10000 [00:20<00:24, 223.18it/s]Running 10000 simulations.:  46%|████▌     | 4564/10000 [00:20<00:24, 222.73it/s]Running 10000 simulations.:  46%|████▌     | 4587/10000 [00:20<00:24, 220.64it/s]Running 10000 simulations.:  46%|████▌     | 4610/10000 [00:21<00:24, 219.53it/s]Running 10000 simulations.:  46%|████▋     | 4633/10000 [00:21<00:24, 221.39it/s]Running 10000 simulations.:  47%|████▋     | 4656/10000 [00:21<00:24, 222.35it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:21<00:23, 222.53it/s]Running 10000 simulations.:  47%|████▋     | 4704/10000 [00:21<00:23, 229.34it/s]Running 10000 simulations.:  47%|████▋     | 4729/10000 [00:21<00:22, 233.77it/s]Running 10000 simulations.:  48%|████▊     | 4754/10000 [00:21<00:22, 236.38it/s]Running 10000 simulations.:  48%|████▊     | 4779/10000 [00:21<00:21, 238.97it/s]Running 10000 simulations.:  48%|████▊     | 4804/10000 [00:21<00:21, 240.85it/s]Running 10000 simulations.:  48%|████▊     | 4829/10000 [00:21<00:21, 242.97it/s]Running 10000 simulations.:  49%|████▊     | 4854/10000 [00:22<00:21, 243.94it/s]Running 10000 simulations.:  49%|████▉     | 4879/10000 [00:22<00:20, 244.94it/s]Running 10000 simulations.:  49%|████▉     | 4904/10000 [00:22<00:20, 246.03it/s]Running 10000 simulations.:  49%|████▉     | 4929/10000 [00:22<00:20, 246.84it/s]Running 10000 simulations.:  50%|████▉     | 4954/10000 [00:22<00:20, 244.68it/s]Running 10000 simulations.:  50%|████▉     | 4979/10000 [00:22<00:20, 239.21it/s]Running 10000 simulations.:  50%|█████     | 5003/10000 [00:22<00:21, 236.10it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:22<00:21, 233.91it/s]Running 10000 simulations.:  51%|█████     | 5051/10000 [00:22<00:21, 232.90it/s]Running 10000 simulations.:  51%|█████     | 5075/10000 [00:22<00:21, 232.16it/s]Running 10000 simulations.:  51%|█████     | 5099/10000 [00:23<00:21, 231.94it/s]Running 10000 simulations.:  51%|█████     | 5123/10000 [00:23<00:21, 231.17it/s]Running 10000 simulations.:  51%|█████▏    | 5147/10000 [00:23<00:20, 231.37it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:23<00:20, 231.40it/s]Running 10000 simulations.:  52%|█████▏    | 5195/10000 [00:23<00:20, 230.98it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:23<00:20, 229.30it/s]Running 10000 simulations.:  52%|█████▏    | 5242/10000 [00:23<00:20, 228.38it/s]Running 10000 simulations.:  53%|█████▎    | 5265/10000 [00:23<00:20, 227.84it/s]Running 10000 simulations.:  53%|█████▎    | 5288/10000 [00:23<00:20, 227.89it/s]Running 10000 simulations.:  53%|█████▎    | 5311/10000 [00:24<00:20, 227.75it/s]Running 10000 simulations.:  53%|█████▎    | 5335/10000 [00:24<00:20, 228.61it/s]Running 10000 simulations.:  54%|█████▎    | 5358/10000 [00:24<00:20, 228.80it/s]Running 10000 simulations.:  54%|█████▍    | 5381/10000 [00:24<00:20, 229.05it/s]Running 10000 simulations.:  54%|█████▍    | 5405/10000 [00:24<00:20, 229.63it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:24<00:19, 229.51it/s]Running 10000 simulations.:  55%|█████▍    | 5451/10000 [00:24<00:19, 229.05it/s]Running 10000 simulations.:  55%|█████▍    | 5474/10000 [00:24<00:19, 228.16it/s]Running 10000 simulations.:  55%|█████▍    | 5497/10000 [00:24<00:19, 228.04it/s]Running 10000 simulations.:  55%|█████▌    | 5520/10000 [00:24<00:19, 228.12it/s]Running 10000 simulations.:  55%|█████▌    | 5543/10000 [00:25<00:19, 228.58it/s]Running 10000 simulations.:  56%|█████▌    | 5566/10000 [00:25<00:19, 228.91it/s]Running 10000 simulations.:  56%|█████▌    | 5589/10000 [00:25<00:19, 228.49it/s]Running 10000 simulations.:  56%|█████▌    | 5612/10000 [00:25<00:19, 228.63it/s]Running 10000 simulations.:  56%|█████▋    | 5635/10000 [00:25<00:19, 229.01it/s]Running 10000 simulations.:  57%|█████▋    | 5658/10000 [00:25<00:19, 228.51it/s]Running 10000 simulations.:  57%|█████▋    | 5681/10000 [00:25<00:18, 227.58it/s]Running 10000 simulations.:  57%|█████▋    | 5705/10000 [00:25<00:18, 228.26it/s]Running 10000 simulations.:  57%|█████▋    | 5728/10000 [00:25<00:18, 228.16it/s]Running 10000 simulations.:  58%|█████▊    | 5752/10000 [00:25<00:18, 228.85it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:26<00:18, 229.21it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:26<00:18, 228.96it/s]Running 10000 simulations.:  58%|█████▊    | 5822/10000 [00:26<00:18, 227.40it/s]Running 10000 simulations.:  58%|█████▊    | 5845/10000 [00:26<00:18, 226.91it/s]Running 10000 simulations.:  59%|█████▊    | 5868/10000 [00:26<00:18, 227.02it/s]Running 10000 simulations.:  59%|█████▉    | 5891/10000 [00:26<00:18, 226.37it/s]Running 10000 simulations.:  59%|█████▉    | 5914/10000 [00:26<00:18, 226.65it/s]Running 10000 simulations.:  59%|█████▉    | 5937/10000 [00:26<00:17, 226.96it/s]Running 10000 simulations.:  60%|█████▉    | 5960/10000 [00:26<00:17, 226.92it/s]Running 10000 simulations.:  60%|█████▉    | 5983/10000 [00:26<00:17, 227.72it/s]Running 10000 simulations.:  60%|██████    | 6007/10000 [00:27<00:17, 228.87it/s]Running 10000 simulations.:  60%|██████    | 6030/10000 [00:27<00:17, 229.02it/s]Running 10000 simulations.:  61%|██████    | 6054/10000 [00:27<00:17, 229.63it/s]Running 10000 simulations.:  61%|██████    | 6077/10000 [00:27<00:17, 228.80it/s]Running 10000 simulations.:  61%|██████    | 6100/10000 [00:27<00:17, 228.97it/s]Running 10000 simulations.:  61%|██████    | 6123/10000 [00:27<00:16, 228.62it/s]Running 10000 simulations.:  61%|██████▏   | 6146/10000 [00:27<00:16, 228.24it/s]Running 10000 simulations.:  62%|██████▏   | 6169/10000 [00:27<00:16, 228.71it/s]Running 10000 simulations.:  62%|██████▏   | 6193/10000 [00:27<00:16, 229.12it/s]Running 10000 simulations.:  62%|██████▏   | 6216/10000 [00:27<00:16, 227.87it/s]Running 10000 simulations.:  62%|██████▏   | 6239/10000 [00:28<00:16, 227.53it/s]Running 10000 simulations.:  63%|██████▎   | 6262/10000 [00:28<00:16, 228.15it/s]Running 10000 simulations.:  63%|██████▎   | 6286/10000 [00:28<00:16, 229.74it/s]Running 10000 simulations.:  63%|██████▎   | 6310/10000 [00:28<00:15, 231.06it/s]Running 10000 simulations.:  63%|██████▎   | 6334/10000 [00:28<00:15, 231.59it/s]Running 10000 simulations.:  64%|██████▎   | 6358/10000 [00:28<00:15, 231.73it/s]Running 10000 simulations.:  64%|██████▍   | 6382/10000 [00:28<00:15, 230.94it/s]Running 10000 simulations.:  64%|██████▍   | 6406/10000 [00:28<00:15, 230.15it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:28<00:15, 229.77it/s]Running 10000 simulations.:  65%|██████▍   | 6453/10000 [00:28<00:15, 229.37it/s]Running 10000 simulations.:  65%|██████▍   | 6476/10000 [00:29<00:15, 228.86it/s]Running 10000 simulations.:  65%|██████▌   | 6500/10000 [00:29<00:15, 229.33it/s]Running 10000 simulations.:  65%|██████▌   | 6523/10000 [00:29<00:15, 229.23it/s]Running 10000 simulations.:  65%|██████▌   | 6547/10000 [00:29<00:15, 229.57it/s]Running 10000 simulations.:  66%|██████▌   | 6570/10000 [00:29<00:14, 229.04it/s]Running 10000 simulations.:  66%|██████▌   | 6593/10000 [00:29<00:14, 229.18it/s]Running 10000 simulations.:  66%|██████▌   | 6617/10000 [00:29<00:14, 229.86it/s]Running 10000 simulations.:  66%|██████▋   | 6641/10000 [00:29<00:14, 230.25it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:29<00:14, 230.09it/s]Running 10000 simulations.:  67%|██████▋   | 6689/10000 [00:30<00:14, 229.51it/s]Running 10000 simulations.:  67%|██████▋   | 6713/10000 [00:30<00:14, 230.23it/s]Running 10000 simulations.:  67%|██████▋   | 6738/10000 [00:30<00:13, 235.63it/s]Running 10000 simulations.:  68%|██████▊   | 6763/10000 [00:30<00:13, 237.48it/s]Running 10000 simulations.:  68%|██████▊   | 6787/10000 [00:30<00:13, 236.59it/s]Running 10000 simulations.:  68%|██████▊   | 6812/10000 [00:30<00:13, 240.06it/s]Running 10000 simulations.:  68%|██████▊   | 6838/10000 [00:30<00:12, 243.44it/s]Running 10000 simulations.:  69%|██████▊   | 6863/10000 [00:30<00:12, 245.24it/s]Running 10000 simulations.:  69%|██████▉   | 6889/10000 [00:30<00:12, 247.02it/s]Running 10000 simulations.:  69%|██████▉   | 6914/10000 [00:30<00:12, 243.60it/s]Running 10000 simulations.:  69%|██████▉   | 6939/10000 [00:31<00:12, 244.01it/s]Running 10000 simulations.:  70%|██████▉   | 6964/10000 [00:31<00:12, 242.31it/s]Running 10000 simulations.:  70%|██████▉   | 6989/10000 [00:31<00:12, 238.80it/s]Running 10000 simulations.:  70%|███████   | 7013/10000 [00:31<00:12, 236.33it/s]Running 10000 simulations.:  70%|███████   | 7037/10000 [00:31<00:12, 234.69it/s]Running 10000 simulations.:  71%|███████   | 7061/10000 [00:31<00:12, 233.23it/s]Running 10000 simulations.:  71%|███████   | 7085/10000 [00:31<00:12, 232.47it/s]Running 10000 simulations.:  71%|███████   | 7109/10000 [00:31<00:12, 232.03it/s]Running 10000 simulations.:  71%|███████▏  | 7133/10000 [00:31<00:12, 232.36it/s]Running 10000 simulations.:  72%|███████▏  | 7157/10000 [00:31<00:12, 231.90it/s]Running 10000 simulations.:  72%|███████▏  | 7181/10000 [00:32<00:12, 231.48it/s]Running 10000 simulations.:  72%|███████▏  | 7205/10000 [00:32<00:12, 231.78it/s]Running 10000 simulations.:  72%|███████▏  | 7229/10000 [00:32<00:11, 231.47it/s]Running 10000 simulations.:  73%|███████▎  | 7253/10000 [00:32<00:11, 230.60it/s]Running 10000 simulations.:  73%|███████▎  | 7277/10000 [00:32<00:11, 230.27it/s]Running 10000 simulations.:  73%|███████▎  | 7301/10000 [00:32<00:11, 230.70it/s]Running 10000 simulations.:  73%|███████▎  | 7325/10000 [00:32<00:11, 230.88it/s]Running 10000 simulations.:  73%|███████▎  | 7349/10000 [00:32<00:11, 230.96it/s]Running 10000 simulations.:  74%|███████▎  | 7373/10000 [00:32<00:11, 230.82it/s]Running 10000 simulations.:  74%|███████▍  | 7397/10000 [00:33<00:11, 231.06it/s]Running 10000 simulations.:  74%|███████▍  | 7421/10000 [00:33<00:11, 230.78it/s]Running 10000 simulations.:  74%|███████▍  | 7445/10000 [00:33<00:11, 231.43it/s]Running 10000 simulations.:  75%|███████▍  | 7469/10000 [00:33<00:10, 232.39it/s]Running 10000 simulations.:  75%|███████▍  | 7493/10000 [00:33<00:10, 233.34it/s]Running 10000 simulations.:  75%|███████▌  | 7517/10000 [00:33<00:10, 234.15it/s]Running 10000 simulations.:  75%|███████▌  | 7541/10000 [00:33<00:10, 233.54it/s]Running 10000 simulations.:  76%|███████▌  | 7565/10000 [00:33<00:10, 233.17it/s]Running 10000 simulations.:  76%|███████▌  | 7589/10000 [00:33<00:10, 233.09it/s]Running 10000 simulations.:  76%|███████▌  | 7613/10000 [00:33<00:10, 232.71it/s]Running 10000 simulations.:  76%|███████▋  | 7637/10000 [00:34<00:10, 232.19it/s]Running 10000 simulations.:  77%|███████▋  | 7661/10000 [00:34<00:10, 232.12it/s]Running 10000 simulations.:  77%|███████▋  | 7685/10000 [00:34<00:09, 232.85it/s]Running 10000 simulations.:  77%|███████▋  | 7709/10000 [00:34<00:09, 233.58it/s]Running 10000 simulations.:  77%|███████▋  | 7733/10000 [00:34<00:09, 233.84it/s]Running 10000 simulations.:  78%|███████▊  | 7757/10000 [00:34<00:09, 232.87it/s]Running 10000 simulations.:  78%|███████▊  | 7781/10000 [00:34<00:09, 232.75it/s]Running 10000 simulations.:  78%|███████▊  | 7805/10000 [00:34<00:09, 232.65it/s]Running 10000 simulations.:  78%|███████▊  | 7829/10000 [00:34<00:09, 232.42it/s]Running 10000 simulations.:  79%|███████▊  | 7853/10000 [00:34<00:09, 232.37it/s]Running 10000 simulations.:  79%|███████▉  | 7877/10000 [00:35<00:09, 232.13it/s]Running 10000 simulations.:  79%|███████▉  | 7901/10000 [00:35<00:09, 232.17it/s]Running 10000 simulations.:  79%|███████▉  | 7925/10000 [00:35<00:08, 232.07it/s]Running 10000 simulations.:  79%|███████▉  | 7949/10000 [00:35<00:08, 232.41it/s]Running 10000 simulations.:  80%|███████▉  | 7973/10000 [00:35<00:08, 233.14it/s]Running 10000 simulations.:  80%|███████▉  | 7997/10000 [00:35<00:08, 232.54it/s]Running 10000 simulations.:  80%|████████  | 8021/10000 [00:35<00:08, 233.04it/s]Running 10000 simulations.:  80%|████████  | 8045/10000 [00:35<00:08, 232.50it/s]Running 10000 simulations.:  81%|████████  | 8069/10000 [00:35<00:08, 232.13it/s]Running 10000 simulations.:  81%|████████  | 8093/10000 [00:36<00:08, 232.43it/s]Running 10000 simulations.:  81%|████████  | 8117/10000 [00:36<00:08, 232.18it/s]Running 10000 simulations.:  81%|████████▏ | 8141/10000 [00:36<00:08, 232.12it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:36<00:07, 231.36it/s]Running 10000 simulations.:  82%|████████▏ | 8189/10000 [00:36<00:07, 231.26it/s]Running 10000 simulations.:  82%|████████▏ | 8213/10000 [00:36<00:07, 231.76it/s]Running 10000 simulations.:  82%|████████▏ | 8237/10000 [00:36<00:07, 231.29it/s]Running 10000 simulations.:  83%|████████▎ | 8261/10000 [00:36<00:07, 230.95it/s]Running 10000 simulations.:  83%|████████▎ | 8285/10000 [00:36<00:07, 230.83it/s]Running 10000 simulations.:  83%|████████▎ | 8309/10000 [00:36<00:07, 231.38it/s]Running 10000 simulations.:  83%|████████▎ | 8333/10000 [00:37<00:07, 231.21it/s]Running 10000 simulations.:  84%|████████▎ | 8357/10000 [00:37<00:07, 231.64it/s]Running 10000 simulations.:  84%|████████▍ | 8381/10000 [00:37<00:06, 231.35it/s]Running 10000 simulations.:  84%|████████▍ | 8405/10000 [00:37<00:06, 231.18it/s]Running 10000 simulations.:  84%|████████▍ | 8429/10000 [00:37<00:06, 231.34it/s]Running 10000 simulations.:  85%|████████▍ | 8453/10000 [00:37<00:06, 231.92it/s]Running 10000 simulations.:  85%|████████▍ | 8477/10000 [00:37<00:06, 232.17it/s]Running 10000 simulations.:  85%|████████▌ | 8501/10000 [00:37<00:06, 232.05it/s]Running 10000 simulations.:  85%|████████▌ | 8525/10000 [00:37<00:06, 226.41it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:37<00:06, 226.39it/s]Running 10000 simulations.:  86%|████████▌ | 8571/10000 [00:38<00:06, 227.30it/s]Running 10000 simulations.:  86%|████████▌ | 8595/10000 [00:38<00:06, 229.27it/s]Running 10000 simulations.:  86%|████████▌ | 8619/10000 [00:38<00:05, 230.63it/s]Running 10000 simulations.:  86%|████████▋ | 8643/10000 [00:38<00:05, 230.53it/s]Running 10000 simulations.:  87%|████████▋ | 8667/10000 [00:38<00:05, 230.48it/s]Running 10000 simulations.:  87%|████████▋ | 8691/10000 [00:38<00:05, 230.52it/s]Running 10000 simulations.:  87%|████████▋ | 8715/10000 [00:38<00:05, 230.69it/s]Running 10000 simulations.:  87%|████████▋ | 8739/10000 [00:38<00:05, 231.49it/s]Running 10000 simulations.:  88%|████████▊ | 8763/10000 [00:38<00:05, 231.32it/s]Running 10000 simulations.:  88%|████████▊ | 8787/10000 [00:39<00:05, 226.25it/s]Running 10000 simulations.:  88%|████████▊ | 8810/10000 [00:39<00:05, 215.67it/s]Running 10000 simulations.:  88%|████████▊ | 8832/10000 [00:39<00:05, 210.45it/s]Running 10000 simulations.:  89%|████████▊ | 8854/10000 [00:39<00:05, 208.09it/s]Running 10000 simulations.:  89%|████████▉ | 8875/10000 [00:39<00:05, 204.64it/s]Running 10000 simulations.:  89%|████████▉ | 8896/10000 [00:39<00:05, 202.10it/s]Running 10000 simulations.:  89%|████████▉ | 8917/10000 [00:39<00:05, 199.24it/s]Running 10000 simulations.:  89%|████████▉ | 8937/10000 [00:39<00:05, 198.28it/s]Running 10000 simulations.:  90%|████████▉ | 8957/10000 [00:39<00:05, 198.25it/s]Running 10000 simulations.:  90%|████████▉ | 8978/10000 [00:39<00:05, 199.42it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:40<00:05, 199.50it/s]Running 10000 simulations.:  90%|█████████ | 9018/10000 [00:40<00:04, 199.06it/s]Running 10000 simulations.:  90%|█████████ | 9039/10000 [00:40<00:04, 199.55it/s]Running 10000 simulations.:  91%|█████████ | 9060/10000 [00:40<00:04, 199.91it/s]Running 10000 simulations.:  91%|█████████ | 9081/10000 [00:40<00:04, 200.47it/s]Running 10000 simulations.:  91%|█████████ | 9102/10000 [00:40<00:04, 201.86it/s]Running 10000 simulations.:  91%|█████████ | 9123/10000 [00:40<00:04, 202.32it/s]Running 10000 simulations.:  91%|█████████▏| 9144/10000 [00:40<00:04, 202.23it/s]Running 10000 simulations.:  92%|█████████▏| 9167/10000 [00:40<00:03, 209.09it/s]Running 10000 simulations.:  92%|█████████▏| 9191/10000 [00:41<00:03, 215.46it/s]Running 10000 simulations.:  92%|█████████▏| 9215/10000 [00:41<00:03, 220.09it/s]Running 10000 simulations.:  92%|█████████▏| 9239/10000 [00:41<00:03, 224.36it/s]Running 10000 simulations.:  93%|█████████▎| 9263/10000 [00:41<00:03, 226.79it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [00:41<00:03, 228.75it/s]Running 10000 simulations.:  93%|█████████▎| 9311/10000 [00:41<00:02, 229.86it/s]Running 10000 simulations.:  93%|█████████▎| 9335/10000 [00:41<00:02, 230.31it/s]Running 10000 simulations.:  94%|█████████▎| 9359/10000 [00:41<00:02, 230.95it/s]Running 10000 simulations.:  94%|█████████▍| 9383/10000 [00:41<00:02, 231.75it/s]Running 10000 simulations.:  94%|█████████▍| 9407/10000 [00:41<00:02, 231.91it/s]Running 10000 simulations.:  94%|█████████▍| 9431/10000 [00:42<00:02, 232.69it/s]Running 10000 simulations.:  95%|█████████▍| 9455/10000 [00:42<00:02, 232.82it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [00:42<00:02, 232.37it/s]Running 10000 simulations.:  95%|█████████▌| 9503/10000 [00:42<00:02, 231.67it/s]Running 10000 simulations.:  95%|█████████▌| 9527/10000 [00:42<00:02, 231.14it/s]Running 10000 simulations.:  96%|█████████▌| 9551/10000 [00:42<00:01, 231.89it/s]Running 10000 simulations.:  96%|█████████▌| 9575/10000 [00:42<00:01, 232.34it/s]Running 10000 simulations.:  96%|█████████▌| 9599/10000 [00:42<00:01, 232.99it/s]Running 10000 simulations.:  96%|█████████▌| 9623/10000 [00:42<00:01, 233.23it/s]Running 10000 simulations.:  96%|█████████▋| 9647/10000 [00:42<00:01, 234.65it/s]Running 10000 simulations.:  97%|█████████▋| 9671/10000 [00:43<00:01, 235.50it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:43<00:01, 235.75it/s]Running 10000 simulations.:  97%|█████████▋| 9719/10000 [00:43<00:01, 236.40it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [00:43<00:01, 236.20it/s]Running 10000 simulations.:  98%|█████████▊| 9767/10000 [00:43<00:00, 235.45it/s]Running 10000 simulations.:  98%|█████████▊| 9791/10000 [00:43<00:00, 235.01it/s]Running 10000 simulations.:  98%|█████████▊| 9815/10000 [00:43<00:00, 236.02it/s]Running 10000 simulations.:  98%|█████████▊| 9839/10000 [00:43<00:00, 236.99it/s]Running 10000 simulations.:  99%|█████████▊| 9863/10000 [00:43<00:00, 236.93it/s]Running 10000 simulations.:  99%|█████████▉| 9887/10000 [00:43<00:00, 236.80it/s]Running 10000 simulations.:  99%|█████████▉| 9911/10000 [00:44<00:00, 236.62it/s]Running 10000 simulations.:  99%|█████████▉| 9935/10000 [00:44<00:00, 236.71it/s]Running 10000 simulations.: 100%|█████████▉| 9959/10000 [00:44<00:00, 236.39it/s]Running 10000 simulations.: 100%|█████████▉| 9983/10000 [00:44<00:00, 236.17it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:44<00:00, 224.83it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:38, 256.78it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:38, 256.76it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:38, 257.33it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:38, 257.61it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:38, 257.36it/s]Running 10000 simulations.:   2%|▏         | 156/10000 [00:00<00:38, 256.09it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:00<00:38, 255.62it/s]Running 10000 simulations.:   2%|▏         | 208/10000 [00:00<00:38, 254.21it/s]Running 10000 simulations.:   2%|▏         | 234/10000 [00:00<00:38, 253.57it/s]Running 10000 simulations.:   3%|▎         | 260/10000 [00:01<00:38, 252.43it/s]Running 10000 simulations.:   3%|▎         | 286/10000 [00:01<00:38, 252.54it/s]Running 10000 simulations.:   3%|▎         | 312/10000 [00:01<00:38, 252.70it/s]Running 10000 simulations.:   3%|▎         | 338/10000 [00:01<00:38, 252.49it/s]Running 10000 simulations.:   4%|▎         | 364/10000 [00:01<00:38, 251.61it/s]Running 10000 simulations.:   4%|▍         | 389/10000 [00:01<00:38, 250.89it/s]Running 10000 simulations.:   4%|▍         | 415/10000 [00:01<00:38, 251.25it/s]Running 10000 simulations.:   4%|▍         | 441/10000 [00:01<00:38, 250.68it/s]Running 10000 simulations.:   5%|▍         | 467/10000 [00:01<00:37, 251.16it/s]Running 10000 simulations.:   5%|▍         | 493/10000 [00:01<00:38, 250.05it/s]Running 10000 simulations.:   5%|▌         | 519/10000 [00:02<00:37, 250.04it/s]Running 10000 simulations.:   5%|▌         | 544/10000 [00:02<00:37, 249.03it/s]Running 10000 simulations.:   6%|▌         | 569/10000 [00:02<00:37, 249.29it/s]Running 10000 simulations.:   6%|▌         | 594/10000 [00:02<00:37, 248.45it/s]Running 10000 simulations.:   6%|▌         | 619/10000 [00:02<00:37, 248.42it/s]Running 10000 simulations.:   6%|▋         | 644/10000 [00:02<00:37, 248.63it/s]Running 10000 simulations.:   7%|▋         | 669/10000 [00:02<00:37, 248.86it/s]Running 10000 simulations.:   7%|▋         | 694/10000 [00:02<00:37, 248.84it/s]Running 10000 simulations.:   7%|▋         | 719/10000 [00:02<00:37, 247.65it/s]Running 10000 simulations.:   7%|▋         | 745/10000 [00:02<00:37, 248.93it/s]Running 10000 simulations.:   8%|▊         | 770/10000 [00:03<00:37, 248.94it/s]Running 10000 simulations.:   8%|▊         | 796/10000 [00:03<00:36, 249.73it/s]Running 10000 simulations.:   8%|▊         | 821/10000 [00:03<00:36, 249.78it/s]Running 10000 simulations.:   8%|▊         | 846/10000 [00:03<00:36, 249.63it/s]Running 10000 simulations.:   9%|▊         | 871/10000 [00:03<00:36, 249.17it/s]Running 10000 simulations.:   9%|▉         | 896/10000 [00:03<00:36, 248.22it/s]Running 10000 simulations.:   9%|▉         | 921/10000 [00:03<00:36, 247.88it/s]Running 10000 simulations.:   9%|▉         | 946/10000 [00:03<00:36, 246.96it/s]Running 10000 simulations.:  10%|▉         | 971/10000 [00:03<00:36, 246.85it/s]Running 10000 simulations.:  10%|▉         | 996/10000 [00:03<00:36, 245.96it/s]Running 10000 simulations.:  10%|█         | 1021/10000 [00:04<00:36, 246.42it/s]Running 10000 simulations.:  10%|█         | 1046/10000 [00:04<00:36, 246.97it/s]Running 10000 simulations.:  11%|█         | 1071/10000 [00:04<00:36, 246.60it/s]Running 10000 simulations.:  11%|█         | 1096/10000 [00:04<00:36, 246.78it/s]Running 10000 simulations.:  11%|█         | 1121/10000 [00:04<00:35, 246.82it/s]Running 10000 simulations.:  11%|█▏        | 1146/10000 [00:04<00:35, 247.76it/s]Running 10000 simulations.:  12%|█▏        | 1171/10000 [00:04<00:35, 247.75it/s]Running 10000 simulations.:  12%|█▏        | 1196/10000 [00:04<00:35, 247.52it/s]Running 10000 simulations.:  12%|█▏        | 1221/10000 [00:04<00:35, 247.30it/s]Running 10000 simulations.:  12%|█▏        | 1246/10000 [00:04<00:35, 247.22it/s]Running 10000 simulations.:  13%|█▎        | 1271/10000 [00:05<00:35, 247.70it/s]Running 10000 simulations.:  13%|█▎        | 1296/10000 [00:05<00:35, 247.79it/s]Running 10000 simulations.:  13%|█▎        | 1321/10000 [00:05<00:35, 247.36it/s]Running 10000 simulations.:  13%|█▎        | 1346/10000 [00:05<00:35, 246.66it/s]Running 10000 simulations.:  14%|█▎        | 1371/10000 [00:05<00:34, 246.87it/s]Running 10000 simulations.:  14%|█▍        | 1396/10000 [00:05<00:34, 246.50it/s]Running 10000 simulations.:  14%|█▍        | 1421/10000 [00:05<00:34, 246.15it/s]Running 10000 simulations.:  14%|█▍        | 1446/10000 [00:05<00:34, 246.58it/s]Running 10000 simulations.:  15%|█▍        | 1471/10000 [00:05<00:34, 246.07it/s]Running 10000 simulations.:  15%|█▍        | 1496/10000 [00:06<00:34, 246.30it/s]Running 10000 simulations.:  15%|█▌        | 1521/10000 [00:06<00:34, 245.85it/s]Running 10000 simulations.:  15%|█▌        | 1546/10000 [00:06<00:34, 245.98it/s]Running 10000 simulations.:  16%|█▌        | 1571/10000 [00:06<00:34, 245.42it/s]Running 10000 simulations.:  16%|█▌        | 1596/10000 [00:06<00:34, 245.41it/s]Running 10000 simulations.:  16%|█▌        | 1621/10000 [00:06<00:34, 245.66it/s]Running 10000 simulations.:  16%|█▋        | 1646/10000 [00:06<00:34, 245.62it/s]Running 10000 simulations.:  17%|█▋        | 1671/10000 [00:06<00:33, 246.29it/s]Running 10000 simulations.:  17%|█▋        | 1696/10000 [00:06<00:33, 245.98it/s]Running 10000 simulations.:  17%|█▋        | 1721/10000 [00:06<00:33, 246.93it/s]Running 10000 simulations.:  17%|█▋        | 1746/10000 [00:07<00:33, 245.64it/s]Running 10000 simulations.:  18%|█▊        | 1771/10000 [00:07<00:33, 246.82it/s]Running 10000 simulations.:  18%|█▊        | 1796/10000 [00:07<00:33, 247.63it/s]Running 10000 simulations.:  18%|█▊        | 1821/10000 [00:07<00:33, 245.23it/s]Running 10000 simulations.:  18%|█▊        | 1846/10000 [00:07<00:33, 243.71it/s]Running 10000 simulations.:  19%|█▊        | 1871/10000 [00:07<00:33, 240.71it/s]Running 10000 simulations.:  19%|█▉        | 1896/10000 [00:07<00:34, 238.28it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:07<00:34, 237.23it/s]Running 10000 simulations.:  19%|█▉        | 1944/10000 [00:07<00:34, 236.08it/s]Running 10000 simulations.:  20%|█▉        | 1968/10000 [00:07<00:34, 235.65it/s]Running 10000 simulations.:  20%|█▉        | 1992/10000 [00:08<00:33, 236.64it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:08<00:33, 235.50it/s]Running 10000 simulations.:  20%|██        | 2041/10000 [00:08<00:33, 237.13it/s]Running 10000 simulations.:  21%|██        | 2066/10000 [00:08<00:33, 239.26it/s]Running 10000 simulations.:  21%|██        | 2091/10000 [00:08<00:32, 240.36it/s]Running 10000 simulations.:  21%|██        | 2116/10000 [00:08<00:33, 235.69it/s]Running 10000 simulations.:  21%|██▏       | 2141/10000 [00:08<00:32, 238.30it/s]Running 10000 simulations.:  22%|██▏       | 2165/10000 [00:08<00:33, 237.29it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:08<00:32, 239.01it/s]Running 10000 simulations.:  22%|██▏       | 2215/10000 [00:08<00:32, 240.45it/s]Running 10000 simulations.:  22%|██▏       | 2240/10000 [00:09<00:32, 241.14it/s]Running 10000 simulations.:  23%|██▎       | 2265/10000 [00:09<00:32, 241.41it/s]Running 10000 simulations.:  23%|██▎       | 2290/10000 [00:09<00:31, 242.87it/s]Running 10000 simulations.:  23%|██▎       | 2315/10000 [00:09<00:31, 243.71it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:09<00:31, 243.54it/s]Running 10000 simulations.:  24%|██▎       | 2365/10000 [00:09<00:31, 243.50it/s]Running 10000 simulations.:  24%|██▍       | 2390/10000 [00:09<00:31, 243.69it/s]Running 10000 simulations.:  24%|██▍       | 2415/10000 [00:09<00:31, 243.72it/s]Running 10000 simulations.:  24%|██▍       | 2440/10000 [00:09<00:30, 244.45it/s]Running 10000 simulations.:  25%|██▍       | 2465/10000 [00:10<00:30, 244.50it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:10<00:30, 244.89it/s]Running 10000 simulations.:  25%|██▌       | 2515/10000 [00:10<00:30, 244.78it/s]Running 10000 simulations.:  25%|██▌       | 2540/10000 [00:10<00:30, 244.57it/s]Running 10000 simulations.:  26%|██▌       | 2565/10000 [00:10<00:30, 244.86it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:10<00:30, 244.59it/s]Running 10000 simulations.:  26%|██▌       | 2615/10000 [00:10<00:30, 245.74it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:10<00:30, 244.54it/s]Running 10000 simulations.:  27%|██▋       | 2665/10000 [00:10<00:29, 245.00it/s]Running 10000 simulations.:  27%|██▋       | 2690/10000 [00:10<00:29, 244.22it/s]Running 10000 simulations.:  27%|██▋       | 2715/10000 [00:11<00:29, 244.08it/s]Running 10000 simulations.:  27%|██▋       | 2740/10000 [00:11<00:29, 244.31it/s]Running 10000 simulations.:  28%|██▊       | 2765/10000 [00:11<00:29, 244.48it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:11<00:29, 244.48it/s]Running 10000 simulations.:  28%|██▊       | 2815/10000 [00:11<00:29, 243.94it/s]Running 10000 simulations.:  28%|██▊       | 2840/10000 [00:11<00:29, 244.16it/s]Running 10000 simulations.:  29%|██▊       | 2865/10000 [00:11<00:29, 243.89it/s]Running 10000 simulations.:  29%|██▉       | 2890/10000 [00:11<00:29, 244.86it/s]Running 10000 simulations.:  29%|██▉       | 2915/10000 [00:11<00:28, 244.40it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:11<00:28, 245.22it/s]Running 10000 simulations.:  30%|██▉       | 2965/10000 [00:12<00:28, 245.14it/s]Running 10000 simulations.:  30%|██▉       | 2990/10000 [00:12<00:28, 245.85it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:12<00:28, 245.21it/s]Running 10000 simulations.:  30%|███       | 3040/10000 [00:12<00:28, 245.23it/s]Running 10000 simulations.:  31%|███       | 3065/10000 [00:12<00:28, 244.92it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:12<00:28, 245.58it/s]Running 10000 simulations.:  31%|███       | 3115/10000 [00:12<00:27, 246.86it/s]Running 10000 simulations.:  31%|███▏      | 3140/10000 [00:12<00:27, 246.61it/s]Running 10000 simulations.:  32%|███▏      | 3165/10000 [00:12<00:27, 247.00it/s]Running 10000 simulations.:  32%|███▏      | 3190/10000 [00:12<00:27, 245.85it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:13<00:27, 245.44it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:13<00:27, 245.09it/s]Running 10000 simulations.:  33%|███▎      | 3265/10000 [00:13<00:27, 245.36it/s]Running 10000 simulations.:  33%|███▎      | 3290/10000 [00:13<00:27, 244.68it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:13<00:27, 244.71it/s]Running 10000 simulations.:  33%|███▎      | 3340/10000 [00:13<00:27, 243.97it/s]Running 10000 simulations.:  34%|███▎      | 3365/10000 [00:13<00:27, 244.38it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:13<00:27, 244.51it/s]Running 10000 simulations.:  34%|███▍      | 3415/10000 [00:13<00:26, 244.03it/s]Running 10000 simulations.:  34%|███▍      | 3440/10000 [00:13<00:26, 243.52it/s]Running 10000 simulations.:  35%|███▍      | 3465/10000 [00:14<00:26, 243.17it/s]Running 10000 simulations.:  35%|███▍      | 3490/10000 [00:14<00:26, 243.83it/s]Running 10000 simulations.:  35%|███▌      | 3515/10000 [00:14<00:26, 243.49it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:14<00:26, 243.10it/s]Running 10000 simulations.:  36%|███▌      | 3565/10000 [00:14<00:27, 236.83it/s]Running 10000 simulations.:  36%|███▌      | 3589/10000 [00:14<00:27, 233.25it/s]Running 10000 simulations.:  36%|███▌      | 3613/10000 [00:14<00:27, 231.08it/s]Running 10000 simulations.:  36%|███▋      | 3637/10000 [00:14<00:27, 229.60it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:14<00:27, 228.08it/s]Running 10000 simulations.:  37%|███▋      | 3683/10000 [00:15<00:27, 227.57it/s]Running 10000 simulations.:  37%|███▋      | 3706/10000 [00:15<00:27, 227.07it/s]Running 10000 simulations.:  37%|███▋      | 3729/10000 [00:15<00:27, 227.22it/s]Running 10000 simulations.:  38%|███▊      | 3752/10000 [00:15<00:27, 226.24it/s]Running 10000 simulations.:  38%|███▊      | 3775/10000 [00:15<00:27, 225.90it/s]Running 10000 simulations.:  38%|███▊      | 3798/10000 [00:15<00:27, 225.29it/s]Running 10000 simulations.:  38%|███▊      | 3821/10000 [00:15<00:27, 224.54it/s]Running 10000 simulations.:  38%|███▊      | 3844/10000 [00:15<00:27, 224.40it/s]Running 10000 simulations.:  39%|███▊      | 3867/10000 [00:15<00:27, 224.57it/s]Running 10000 simulations.:  39%|███▉      | 3890/10000 [00:15<00:27, 223.69it/s]Running 10000 simulations.:  39%|███▉      | 3913/10000 [00:16<00:27, 222.69it/s]Running 10000 simulations.:  39%|███▉      | 3936/10000 [00:16<00:27, 224.08it/s]Running 10000 simulations.:  40%|███▉      | 3959/10000 [00:16<00:26, 225.20it/s]Running 10000 simulations.:  40%|███▉      | 3982/10000 [00:16<00:26, 225.43it/s]Running 10000 simulations.:  40%|████      | 4005/10000 [00:16<00:26, 226.58it/s]Running 10000 simulations.:  40%|████      | 4028/10000 [00:16<00:26, 226.39it/s]Running 10000 simulations.:  41%|████      | 4051/10000 [00:16<00:26, 226.78it/s]Running 10000 simulations.:  41%|████      | 4074/10000 [00:16<00:26, 226.53it/s]Running 10000 simulations.:  41%|████      | 4097/10000 [00:16<00:26, 226.95it/s]Running 10000 simulations.:  41%|████      | 4120/10000 [00:16<00:25, 226.84it/s]Running 10000 simulations.:  41%|████▏     | 4143/10000 [00:17<00:25, 226.27it/s]Running 10000 simulations.:  42%|████▏     | 4166/10000 [00:17<00:25, 226.26it/s]Running 10000 simulations.:  42%|████▏     | 4189/10000 [00:17<00:25, 225.99it/s]Running 10000 simulations.:  42%|████▏     | 4212/10000 [00:17<00:25, 225.95it/s]Running 10000 simulations.:  42%|████▏     | 4235/10000 [00:17<00:25, 225.37it/s]Running 10000 simulations.:  43%|████▎     | 4258/10000 [00:17<00:25, 226.15it/s]Running 10000 simulations.:  43%|████▎     | 4281/10000 [00:17<00:25, 226.46it/s]Running 10000 simulations.:  43%|████▎     | 4304/10000 [00:17<00:25, 227.03it/s]Running 10000 simulations.:  43%|████▎     | 4327/10000 [00:17<00:25, 225.82it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:17<00:25, 225.13it/s]Running 10000 simulations.:  44%|████▎     | 4373/10000 [00:18<00:25, 224.81it/s]Running 10000 simulations.:  44%|████▍     | 4396/10000 [00:18<00:24, 225.60it/s]Running 10000 simulations.:  44%|████▍     | 4419/10000 [00:18<00:24, 226.02it/s]Running 10000 simulations.:  44%|████▍     | 4442/10000 [00:18<00:24, 225.92it/s]Running 10000 simulations.:  45%|████▍     | 4465/10000 [00:18<00:24, 226.23it/s]Running 10000 simulations.:  45%|████▍     | 4488/10000 [00:18<00:24, 226.04it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:18<00:24, 225.85it/s]Running 10000 simulations.:  45%|████▌     | 4534/10000 [00:18<00:24, 224.55it/s]Running 10000 simulations.:  46%|████▌     | 4557/10000 [00:18<00:24, 224.85it/s]Running 10000 simulations.:  46%|████▌     | 4580/10000 [00:19<00:24, 225.65it/s]Running 10000 simulations.:  46%|████▌     | 4603/10000 [00:19<00:23, 225.69it/s]Running 10000 simulations.:  46%|████▋     | 4626/10000 [00:19<00:23, 225.48it/s]Running 10000 simulations.:  46%|████▋     | 4649/10000 [00:19<00:23, 225.92it/s]Running 10000 simulations.:  47%|████▋     | 4672/10000 [00:19<00:23, 227.12it/s]Running 10000 simulations.:  47%|████▋     | 4695/10000 [00:19<00:23, 227.16it/s]Running 10000 simulations.:  47%|████▋     | 4718/10000 [00:19<00:23, 227.90it/s]Running 10000 simulations.:  47%|████▋     | 4741/10000 [00:19<00:23, 227.91it/s]Running 10000 simulations.:  48%|████▊     | 4764/10000 [00:19<00:22, 227.83it/s]Running 10000 simulations.:  48%|████▊     | 4787/10000 [00:19<00:22, 228.30it/s]Running 10000 simulations.:  48%|████▊     | 4810/10000 [00:20<00:22, 228.48it/s]Running 10000 simulations.:  48%|████▊     | 4833/10000 [00:20<00:22, 227.90it/s]Running 10000 simulations.:  49%|████▊     | 4856/10000 [00:20<00:22, 227.66it/s]Running 10000 simulations.:  49%|████▉     | 4879/10000 [00:20<00:22, 227.83it/s]Running 10000 simulations.:  49%|████▉     | 4902/10000 [00:20<00:22, 227.25it/s]Running 10000 simulations.:  49%|████▉     | 4925/10000 [00:20<00:22, 227.02it/s]Running 10000 simulations.:  49%|████▉     | 4948/10000 [00:20<00:22, 227.07it/s]Running 10000 simulations.:  50%|████▉     | 4971/10000 [00:20<00:22, 227.54it/s]Running 10000 simulations.:  50%|████▉     | 4994/10000 [00:20<00:22, 226.15it/s]Running 10000 simulations.:  50%|█████     | 5017/10000 [00:20<00:22, 226.16it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:21<00:21, 226.28it/s]Running 10000 simulations.:  51%|█████     | 5063/10000 [00:21<00:21, 225.20it/s]Running 10000 simulations.:  51%|█████     | 5086/10000 [00:21<00:21, 224.33it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:21<00:21, 222.47it/s]Running 10000 simulations.:  51%|█████▏    | 5132/10000 [00:21<00:21, 223.77it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:21<00:21, 225.56it/s]Running 10000 simulations.:  52%|█████▏    | 5179/10000 [00:21<00:21, 226.87it/s]Running 10000 simulations.:  52%|█████▏    | 5203/10000 [00:21<00:20, 229.64it/s]Running 10000 simulations.:  52%|█████▏    | 5227/10000 [00:21<00:20, 229.96it/s]Running 10000 simulations.:  53%|█████▎    | 5251/10000 [00:21<00:20, 231.45it/s]Running 10000 simulations.:  53%|█████▎    | 5275/10000 [00:22<00:20, 233.36it/s]Running 10000 simulations.:  53%|█████▎    | 5299/10000 [00:22<00:20, 235.04it/s]Running 10000 simulations.:  53%|█████▎    | 5323/10000 [00:22<00:19, 235.38it/s]Running 10000 simulations.:  53%|█████▎    | 5347/10000 [00:22<00:19, 234.72it/s]Running 10000 simulations.:  54%|█████▎    | 5371/10000 [00:22<00:19, 235.22it/s]Running 10000 simulations.:  54%|█████▍    | 5395/10000 [00:22<00:19, 234.91it/s]Running 10000 simulations.:  54%|█████▍    | 5419/10000 [00:22<00:19, 235.00it/s]Running 10000 simulations.:  54%|█████▍    | 5443/10000 [00:22<00:19, 234.21it/s]Running 10000 simulations.:  55%|█████▍    | 5467/10000 [00:22<00:19, 234.94it/s]Running 10000 simulations.:  55%|█████▍    | 5491/10000 [00:22<00:19, 234.99it/s]Running 10000 simulations.:  55%|█████▌    | 5515/10000 [00:23<00:19, 235.25it/s]Running 10000 simulations.:  55%|█████▌    | 5539/10000 [00:23<00:18, 236.21it/s]Running 10000 simulations.:  56%|█████▌    | 5563/10000 [00:23<00:18, 236.73it/s]Running 10000 simulations.:  56%|█████▌    | 5587/10000 [00:23<00:18, 235.87it/s]Running 10000 simulations.:  56%|█████▌    | 5612/10000 [00:23<00:18, 237.13it/s]Running 10000 simulations.:  56%|█████▋    | 5636/10000 [00:23<00:18, 237.49it/s]Running 10000 simulations.:  57%|█████▋    | 5660/10000 [00:23<00:18, 236.57it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:23<00:18, 235.72it/s]Running 10000 simulations.:  57%|█████▋    | 5708/10000 [00:23<00:18, 234.68it/s]Running 10000 simulations.:  57%|█████▋    | 5732/10000 [00:23<00:18, 235.50it/s]Running 10000 simulations.:  58%|█████▊    | 5756/10000 [00:24<00:18, 235.29it/s]Running 10000 simulations.:  58%|█████▊    | 5780/10000 [00:24<00:17, 235.01it/s]Running 10000 simulations.:  58%|█████▊    | 5804/10000 [00:24<00:17, 234.17it/s]Running 10000 simulations.:  58%|█████▊    | 5828/10000 [00:24<00:17, 234.33it/s]Running 10000 simulations.:  59%|█████▊    | 5852/10000 [00:24<00:17, 233.68it/s]Running 10000 simulations.:  59%|█████▉    | 5876/10000 [00:24<00:17, 233.79it/s]Running 10000 simulations.:  59%|█████▉    | 5900/10000 [00:24<00:17, 234.04it/s]Running 10000 simulations.:  59%|█████▉    | 5924/10000 [00:24<00:17, 233.49it/s]Running 10000 simulations.:  59%|█████▉    | 5948/10000 [00:24<00:17, 234.20it/s]Running 10000 simulations.:  60%|█████▉    | 5974/10000 [00:25<00:16, 240.33it/s]Running 10000 simulations.:  60%|██████    | 6000/10000 [00:25<00:16, 244.15it/s]Running 10000 simulations.:  60%|██████    | 6026/10000 [00:25<00:16, 245.80it/s]Running 10000 simulations.:  61%|██████    | 6051/10000 [00:25<00:16, 243.86it/s]Running 10000 simulations.:  61%|██████    | 6076/10000 [00:25<00:15, 245.26it/s]Running 10000 simulations.:  61%|██████    | 6101/10000 [00:25<00:15, 246.44it/s]Running 10000 simulations.:  61%|██████▏   | 6127/10000 [00:25<00:15, 248.03it/s]Running 10000 simulations.:  62%|██████▏   | 6153/10000 [00:25<00:15, 249.43it/s]Running 10000 simulations.:  62%|██████▏   | 6179/10000 [00:25<00:15, 250.87it/s]Running 10000 simulations.:  62%|██████▏   | 6205/10000 [00:25<00:15, 252.42it/s]Running 10000 simulations.:  62%|██████▏   | 6231/10000 [00:26<00:14, 253.69it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:26<00:14, 253.97it/s]Running 10000 simulations.:  63%|██████▎   | 6283/10000 [00:26<00:15, 247.53it/s]Running 10000 simulations.:  63%|██████▎   | 6308/10000 [00:26<00:15, 244.55it/s]Running 10000 simulations.:  63%|██████▎   | 6333/10000 [00:26<00:15, 239.75it/s]Running 10000 simulations.:  64%|██████▎   | 6358/10000 [00:26<00:15, 238.13it/s]Running 10000 simulations.:  64%|██████▍   | 6382/10000 [00:26<00:15, 237.61it/s]Running 10000 simulations.:  64%|██████▍   | 6406/10000 [00:26<00:15, 236.99it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:26<00:15, 236.77it/s]Running 10000 simulations.:  65%|██████▍   | 6454/10000 [00:26<00:15, 235.66it/s]Running 10000 simulations.:  65%|██████▍   | 6478/10000 [00:27<00:14, 234.85it/s]Running 10000 simulations.:  65%|██████▌   | 6502/10000 [00:27<00:14, 233.89it/s]Running 10000 simulations.:  65%|██████▌   | 6526/10000 [00:27<00:14, 235.16it/s]Running 10000 simulations.:  66%|██████▌   | 6550/10000 [00:27<00:14, 235.52it/s]Running 10000 simulations.:  66%|██████▌   | 6574/10000 [00:27<00:14, 236.58it/s]Running 10000 simulations.:  66%|██████▌   | 6598/10000 [00:27<00:14, 235.36it/s]Running 10000 simulations.:  66%|██████▌   | 6622/10000 [00:27<00:14, 236.71it/s]Running 10000 simulations.:  66%|██████▋   | 6646/10000 [00:27<00:14, 236.84it/s]Running 10000 simulations.:  67%|██████▋   | 6670/10000 [00:27<00:14, 237.53it/s]Running 10000 simulations.:  67%|██████▋   | 6694/10000 [00:28<00:13, 237.51it/s]Running 10000 simulations.:  67%|██████▋   | 6718/10000 [00:28<00:13, 238.16it/s]Running 10000 simulations.:  67%|██████▋   | 6742/10000 [00:28<00:13, 237.70it/s]Running 10000 simulations.:  68%|██████▊   | 6766/10000 [00:28<00:13, 237.05it/s]Running 10000 simulations.:  68%|██████▊   | 6790/10000 [00:28<00:13, 236.85it/s]Running 10000 simulations.:  68%|██████▊   | 6814/10000 [00:28<00:13, 236.49it/s]Running 10000 simulations.:  68%|██████▊   | 6839/10000 [00:28<00:13, 237.52it/s]Running 10000 simulations.:  69%|██████▊   | 6863/10000 [00:28<00:13, 230.49it/s]Running 10000 simulations.:  69%|██████▉   | 6887/10000 [00:28<00:14, 218.53it/s]Running 10000 simulations.:  69%|██████▉   | 6910/10000 [00:28<00:14, 211.85it/s]Running 10000 simulations.:  69%|██████▉   | 6932/10000 [00:29<00:14, 210.51it/s]Running 10000 simulations.:  70%|██████▉   | 6954/10000 [00:29<00:14, 208.28it/s]Running 10000 simulations.:  70%|██████▉   | 6975/10000 [00:29<00:14, 206.90it/s]Running 10000 simulations.:  70%|██████▉   | 6996/10000 [00:29<00:14, 204.43it/s]Running 10000 simulations.:  70%|███████   | 7017/10000 [00:29<00:14, 202.02it/s]Running 10000 simulations.:  70%|███████   | 7038/10000 [00:29<00:14, 202.30it/s]Running 10000 simulations.:  71%|███████   | 7059/10000 [00:29<00:14, 201.40it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:29<00:14, 201.39it/s]Running 10000 simulations.:  71%|███████   | 7101/10000 [00:29<00:14, 199.64it/s]Running 10000 simulations.:  71%|███████   | 7121/10000 [00:30<00:14, 198.64it/s]Running 10000 simulations.:  71%|███████▏  | 7141/10000 [00:30<00:14, 197.17it/s]Running 10000 simulations.:  72%|███████▏  | 7161/10000 [00:30<00:14, 196.92it/s]Running 10000 simulations.:  72%|███████▏  | 7181/10000 [00:30<00:14, 196.23it/s]Running 10000 simulations.:  72%|███████▏  | 7201/10000 [00:30<00:14, 195.36it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:30<00:13, 199.93it/s]Running 10000 simulations.:  72%|███████▏  | 7246/10000 [00:30<00:13, 206.69it/s]Running 10000 simulations.:  73%|███████▎  | 7269/10000 [00:30<00:12, 211.65it/s]Running 10000 simulations.:  73%|███████▎  | 7292/10000 [00:30<00:12, 215.62it/s]Running 10000 simulations.:  73%|███████▎  | 7315/10000 [00:30<00:12, 218.23it/s]Running 10000 simulations.:  73%|███████▎  | 7338/10000 [00:31<00:12, 220.14it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:31<00:11, 221.42it/s]Running 10000 simulations.:  74%|███████▍  | 7384/10000 [00:31<00:11, 222.20it/s]Running 10000 simulations.:  74%|███████▍  | 7407/10000 [00:31<00:11, 222.34it/s]Running 10000 simulations.:  74%|███████▍  | 7430/10000 [00:31<00:11, 222.35it/s]Running 10000 simulations.:  75%|███████▍  | 7453/10000 [00:31<00:11, 222.41it/s]Running 10000 simulations.:  75%|███████▍  | 7476/10000 [00:31<00:11, 223.30it/s]Running 10000 simulations.:  75%|███████▍  | 7499/10000 [00:31<00:11, 223.96it/s]Running 10000 simulations.:  75%|███████▌  | 7522/10000 [00:31<00:11, 224.58it/s]Running 10000 simulations.:  75%|███████▌  | 7545/10000 [00:31<00:10, 224.99it/s]Running 10000 simulations.:  76%|███████▌  | 7568/10000 [00:32<00:10, 224.31it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:32<00:10, 224.17it/s]Running 10000 simulations.:  76%|███████▌  | 7614/10000 [00:32<00:10, 224.24it/s]Running 10000 simulations.:  76%|███████▋  | 7637/10000 [00:32<00:10, 224.21it/s]Running 10000 simulations.:  77%|███████▋  | 7660/10000 [00:32<00:10, 224.40it/s]Running 10000 simulations.:  77%|███████▋  | 7683/10000 [00:32<00:10, 225.14it/s]Running 10000 simulations.:  77%|███████▋  | 7706/10000 [00:32<00:10, 225.01it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:32<00:10, 224.53it/s]Running 10000 simulations.:  78%|███████▊  | 7752/10000 [00:32<00:10, 222.86it/s]Running 10000 simulations.:  78%|███████▊  | 7775/10000 [00:32<00:09, 223.76it/s]Running 10000 simulations.:  78%|███████▊  | 7798/10000 [00:33<00:09, 223.74it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:33<00:09, 224.81it/s]Running 10000 simulations.:  78%|███████▊  | 7844/10000 [00:33<00:09, 225.67it/s]Running 10000 simulations.:  79%|███████▊  | 7867/10000 [00:33<00:09, 225.84it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:33<00:09, 225.60it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:33<00:09, 225.74it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:33<00:09, 225.27it/s]Running 10000 simulations.:  80%|███████▉  | 7959/10000 [00:33<00:09, 225.08it/s]Running 10000 simulations.:  80%|███████▉  | 7982/10000 [00:33<00:08, 225.51it/s]Running 10000 simulations.:  80%|████████  | 8005/10000 [00:34<00:08, 225.35it/s]Running 10000 simulations.:  80%|████████  | 8028/10000 [00:34<00:08, 224.64it/s]Running 10000 simulations.:  81%|████████  | 8051/10000 [00:34<00:08, 224.61it/s]Running 10000 simulations.:  81%|████████  | 8074/10000 [00:34<00:08, 224.90it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:34<00:08, 225.17it/s]Running 10000 simulations.:  81%|████████  | 8120/10000 [00:34<00:08, 224.94it/s]Running 10000 simulations.:  81%|████████▏ | 8143/10000 [00:34<00:08, 225.03it/s]Running 10000 simulations.:  82%|████████▏ | 8166/10000 [00:34<00:08, 225.28it/s]Running 10000 simulations.:  82%|████████▏ | 8189/10000 [00:34<00:08, 225.25it/s]Running 10000 simulations.:  82%|████████▏ | 8212/10000 [00:34<00:07, 224.94it/s]Running 10000 simulations.:  82%|████████▏ | 8235/10000 [00:35<00:07, 224.85it/s]Running 10000 simulations.:  83%|████████▎ | 8258/10000 [00:35<00:07, 224.75it/s]Running 10000 simulations.:  83%|████████▎ | 8281/10000 [00:35<00:07, 225.60it/s]Running 10000 simulations.:  83%|████████▎ | 8304/10000 [00:35<00:07, 225.90it/s]Running 10000 simulations.:  83%|████████▎ | 8328/10000 [00:35<00:07, 227.63it/s]Running 10000 simulations.:  84%|████████▎ | 8352/10000 [00:35<00:07, 228.95it/s]Running 10000 simulations.:  84%|████████▍ | 8376/10000 [00:35<00:07, 229.65it/s]Running 10000 simulations.:  84%|████████▍ | 8400/10000 [00:35<00:06, 230.24it/s]Running 10000 simulations.:  84%|████████▍ | 8424/10000 [00:35<00:06, 230.91it/s]Running 10000 simulations.:  84%|████████▍ | 8448/10000 [00:35<00:06, 231.63it/s]Running 10000 simulations.:  85%|████████▍ | 8472/10000 [00:36<00:06, 231.21it/s]Running 10000 simulations.:  85%|████████▍ | 8496/10000 [00:36<00:06, 231.33it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:36<00:06, 231.36it/s]Running 10000 simulations.:  85%|████████▌ | 8544/10000 [00:36<00:06, 231.32it/s]Running 10000 simulations.:  86%|████████▌ | 8568/10000 [00:36<00:06, 230.96it/s]Running 10000 simulations.:  86%|████████▌ | 8592/10000 [00:36<00:06, 232.05it/s]Running 10000 simulations.:  86%|████████▌ | 8616/10000 [00:36<00:05, 232.76it/s]Running 10000 simulations.:  86%|████████▋ | 8640/10000 [00:36<00:05, 233.14it/s]Running 10000 simulations.:  87%|████████▋ | 8664/10000 [00:36<00:05, 232.92it/s]Running 10000 simulations.:  87%|████████▋ | 8688/10000 [00:36<00:05, 233.22it/s]Running 10000 simulations.:  87%|████████▋ | 8712/10000 [00:37<00:05, 234.20it/s]Running 10000 simulations.:  87%|████████▋ | 8736/10000 [00:37<00:05, 234.60it/s]Running 10000 simulations.:  88%|████████▊ | 8760/10000 [00:37<00:05, 233.79it/s]Running 10000 simulations.:  88%|████████▊ | 8784/10000 [00:37<00:05, 233.31it/s]Running 10000 simulations.:  88%|████████▊ | 8808/10000 [00:37<00:05, 232.99it/s]Running 10000 simulations.:  88%|████████▊ | 8832/10000 [00:37<00:05, 233.43it/s]Running 10000 simulations.:  89%|████████▊ | 8856/10000 [00:37<00:04, 233.62it/s]Running 10000 simulations.:  89%|████████▉ | 8880/10000 [00:37<00:04, 234.26it/s]Running 10000 simulations.:  89%|████████▉ | 8905/10000 [00:37<00:04, 235.94it/s]Running 10000 simulations.:  89%|████████▉ | 8929/10000 [00:38<00:04, 235.27it/s]Running 10000 simulations.:  90%|████████▉ | 8953/10000 [00:38<00:04, 236.27it/s]Running 10000 simulations.:  90%|████████▉ | 8977/10000 [00:38<00:04, 235.85it/s]Running 10000 simulations.:  90%|█████████ | 9001/10000 [00:38<00:04, 234.75it/s]Running 10000 simulations.:  90%|█████████ | 9025/10000 [00:38<00:04, 232.07it/s]Running 10000 simulations.:  90%|█████████ | 9049/10000 [00:38<00:04, 224.57it/s]Running 10000 simulations.:  91%|█████████ | 9073/10000 [00:38<00:04, 227.05it/s]Running 10000 simulations.:  91%|█████████ | 9097/10000 [00:38<00:03, 228.82it/s]Running 10000 simulations.:  91%|█████████ | 9121/10000 [00:38<00:03, 230.30it/s]Running 10000 simulations.:  91%|█████████▏| 9145/10000 [00:38<00:03, 231.43it/s]Running 10000 simulations.:  92%|█████████▏| 9169/10000 [00:39<00:03, 231.93it/s]Running 10000 simulations.:  92%|█████████▏| 9193/10000 [00:39<00:03, 232.53it/s]Running 10000 simulations.:  92%|█████████▏| 9217/10000 [00:39<00:03, 232.55it/s]Running 10000 simulations.:  92%|█████████▏| 9241/10000 [00:39<00:03, 232.51it/s]Running 10000 simulations.:  93%|█████████▎| 9265/10000 [00:39<00:03, 231.73it/s]Running 10000 simulations.:  93%|█████████▎| 9289/10000 [00:39<00:03, 231.89it/s]Running 10000 simulations.:  93%|█████████▎| 9313/10000 [00:39<00:02, 232.51it/s]Running 10000 simulations.:  93%|█████████▎| 9337/10000 [00:39<00:02, 232.95it/s]Running 10000 simulations.:  94%|█████████▎| 9361/10000 [00:39<00:02, 233.31it/s]Running 10000 simulations.:  94%|█████████▍| 9385/10000 [00:39<00:02, 233.34it/s]Running 10000 simulations.:  94%|█████████▍| 9409/10000 [00:40<00:02, 233.45it/s]Running 10000 simulations.:  94%|█████████▍| 9433/10000 [00:40<00:02, 233.45it/s]Running 10000 simulations.:  95%|█████████▍| 9457/10000 [00:40<00:02, 232.37it/s]Running 10000 simulations.:  95%|█████████▍| 9481/10000 [00:40<00:02, 232.07it/s]Running 10000 simulations.:  95%|█████████▌| 9505/10000 [00:40<00:02, 231.84it/s]Running 10000 simulations.:  95%|█████████▌| 9529/10000 [00:40<00:02, 231.81it/s]Running 10000 simulations.:  96%|█████████▌| 9553/10000 [00:40<00:01, 231.70it/s]Running 10000 simulations.:  96%|█████████▌| 9577/10000 [00:40<00:01, 231.58it/s]Running 10000 simulations.:  96%|█████████▌| 9601/10000 [00:40<00:01, 231.78it/s]Running 10000 simulations.:  96%|█████████▋| 9625/10000 [00:41<00:01, 232.46it/s]Running 10000 simulations.:  96%|█████████▋| 9649/10000 [00:41<00:01, 233.15it/s]Running 10000 simulations.:  97%|█████████▋| 9673/10000 [00:41<00:01, 234.14it/s]Running 10000 simulations.:  97%|█████████▋| 9697/10000 [00:41<00:01, 234.21it/s]Running 10000 simulations.:  97%|█████████▋| 9721/10000 [00:41<00:01, 233.62it/s]Running 10000 simulations.:  97%|█████████▋| 9745/10000 [00:41<00:01, 233.33it/s]Running 10000 simulations.:  98%|█████████▊| 9769/10000 [00:41<00:00, 233.68it/s]Running 10000 simulations.:  98%|█████████▊| 9793/10000 [00:41<00:00, 233.64it/s]Running 10000 simulations.:  98%|█████████▊| 9817/10000 [00:41<00:00, 231.57it/s]Running 10000 simulations.:  98%|█████████▊| 9841/10000 [00:41<00:00, 230.73it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [00:42<00:00, 232.10it/s]Running 10000 simulations.:  99%|█████████▉| 9889/10000 [00:42<00:00, 233.11it/s]Running 10000 simulations.:  99%|█████████▉| 9913/10000 [00:42<00:00, 233.06it/s]Running 10000 simulations.:  99%|█████████▉| 9937/10000 [00:42<00:00, 233.90it/s]Running 10000 simulations.: 100%|█████████▉| 9961/10000 [00:42<00:00, 234.56it/s]Running 10000 simulations.: 100%|█████████▉| 9985/10000 [00:42<00:00, 234.60it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 234.57it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 275.39it/s]Running 10000 simulations.:   1%|          | 55/10000 [00:00<00:36, 272.31it/s]Running 10000 simulations.:   1%|          | 83/10000 [00:00<00:36, 273.66it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<00:35, 275.96it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:35, 276.95it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:35, 277.60it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:00<00:35, 276.83it/s]Running 10000 simulations.:   2%|▏         | 223/10000 [00:00<00:35, 274.06it/s]Running 10000 simulations.:   3%|▎         | 251/10000 [00:00<00:35, 273.77it/s]Running 10000 simulations.:   3%|▎         | 278/10000 [00:01<00:36, 264.56it/s]Running 10000 simulations.:   3%|▎         | 304/10000 [00:01<00:37, 258.81it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:01<00:37, 255.72it/s]Running 10000 simulations.:   4%|▎         | 356/10000 [00:01<00:38, 253.16it/s]Running 10000 simulations.:   4%|▍         | 382/10000 [00:01<00:38, 252.12it/s]Running 10000 simulations.:   4%|▍         | 408/10000 [00:01<00:38, 251.06it/s]Running 10000 simulations.:   4%|▍         | 434/10000 [00:01<00:38, 250.80it/s]Running 10000 simulations.:   5%|▍         | 460/10000 [00:01<00:38, 250.22it/s]Running 10000 simulations.:   5%|▍         | 486/10000 [00:01<00:38, 250.25it/s]Running 10000 simulations.:   5%|▌         | 511/10000 [00:01<00:38, 249.38it/s]Running 10000 simulations.:   5%|▌         | 536/10000 [00:02<00:38, 248.94it/s]Running 10000 simulations.:   6%|▌         | 561/10000 [00:02<00:37, 248.63it/s]Running 10000 simulations.:   6%|▌         | 586/10000 [00:02<00:37, 248.96it/s]Running 10000 simulations.:   6%|▌         | 611/10000 [00:02<00:37, 248.88it/s]Running 10000 simulations.:   6%|▋         | 636/10000 [00:02<00:37, 248.74it/s]Running 10000 simulations.:   7%|▋         | 661/10000 [00:02<00:37, 248.34it/s]Running 10000 simulations.:   7%|▋         | 686/10000 [00:02<00:37, 247.64it/s]Running 10000 simulations.:   7%|▋         | 711/10000 [00:02<00:37, 246.68it/s]Running 10000 simulations.:   7%|▋         | 737/10000 [00:02<00:37, 248.14it/s]Running 10000 simulations.:   8%|▊         | 763/10000 [00:02<00:37, 248.82it/s]Running 10000 simulations.:   8%|▊         | 789/10000 [00:03<00:36, 249.56it/s]Running 10000 simulations.:   8%|▊         | 815/10000 [00:03<00:36, 249.63it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:03<00:36, 248.92it/s]Running 10000 simulations.:   9%|▊         | 865/10000 [00:03<00:36, 248.13it/s]Running 10000 simulations.:   9%|▉         | 891/10000 [00:03<00:36, 248.80it/s]Running 10000 simulations.:   9%|▉         | 916/10000 [00:03<00:36, 248.56it/s]Running 10000 simulations.:   9%|▉         | 942/10000 [00:03<00:36, 249.34it/s]Running 10000 simulations.:  10%|▉         | 967/10000 [00:03<00:37, 242.03it/s]Running 10000 simulations.:  10%|▉         | 992/10000 [00:03<00:36, 244.15it/s]Running 10000 simulations.:  10%|█         | 1017/10000 [00:04<00:36, 245.46it/s]Running 10000 simulations.:  10%|█         | 1042/10000 [00:04<00:36, 245.79it/s]Running 10000 simulations.:  11%|█         | 1067/10000 [00:04<00:36, 246.69it/s]Running 10000 simulations.:  11%|█         | 1092/10000 [00:04<00:36, 246.17it/s]Running 10000 simulations.:  11%|█         | 1117/10000 [00:04<00:36, 246.60it/s]Running 10000 simulations.:  11%|█▏        | 1142/10000 [00:04<00:35, 247.24it/s]Running 10000 simulations.:  12%|█▏        | 1167/10000 [00:04<00:35, 247.30it/s]Running 10000 simulations.:  12%|█▏        | 1192/10000 [00:04<00:35, 247.67it/s]Running 10000 simulations.:  12%|█▏        | 1217/10000 [00:04<00:35, 247.56it/s]Running 10000 simulations.:  12%|█▏        | 1242/10000 [00:04<00:35, 247.75it/s]Running 10000 simulations.:  13%|█▎        | 1267/10000 [00:05<00:35, 247.29it/s]Running 10000 simulations.:  13%|█▎        | 1292/10000 [00:05<00:35, 247.18it/s]Running 10000 simulations.:  13%|█▎        | 1317/10000 [00:05<00:35, 247.09it/s]Running 10000 simulations.:  13%|█▎        | 1342/10000 [00:05<00:35, 246.91it/s]Running 10000 simulations.:  14%|█▎        | 1367/10000 [00:05<00:35, 245.81it/s]Running 10000 simulations.:  14%|█▍        | 1392/10000 [00:05<00:35, 243.56it/s]Running 10000 simulations.:  14%|█▍        | 1417/10000 [00:05<00:35, 245.10it/s]Running 10000 simulations.:  14%|█▍        | 1442/10000 [00:05<00:34, 244.60it/s]Running 10000 simulations.:  15%|█▍        | 1467/10000 [00:05<00:34, 244.76it/s]Running 10000 simulations.:  15%|█▍        | 1492/10000 [00:05<00:34, 245.68it/s]Running 10000 simulations.:  15%|█▌        | 1517/10000 [00:06<00:34, 246.60it/s]Running 10000 simulations.:  15%|█▌        | 1542/10000 [00:06<00:34, 246.40it/s]Running 10000 simulations.:  16%|█▌        | 1567/10000 [00:06<00:34, 246.05it/s]Running 10000 simulations.:  16%|█▌        | 1592/10000 [00:06<00:34, 245.96it/s]Running 10000 simulations.:  16%|█▌        | 1617/10000 [00:06<00:34, 246.47it/s]Running 10000 simulations.:  16%|█▋        | 1642/10000 [00:06<00:33, 246.92it/s]Running 10000 simulations.:  17%|█▋        | 1668/10000 [00:06<00:33, 247.97it/s]Running 10000 simulations.:  17%|█▋        | 1693/10000 [00:06<00:33, 248.08it/s]Running 10000 simulations.:  17%|█▋        | 1718/10000 [00:06<00:33, 248.05it/s]Running 10000 simulations.:  17%|█▋        | 1743/10000 [00:06<00:33, 247.22it/s]Running 10000 simulations.:  18%|█▊        | 1768/10000 [00:07<00:33, 246.24it/s]Running 10000 simulations.:  18%|█▊        | 1793/10000 [00:07<00:33, 246.32it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:07<00:33, 245.94it/s]Running 10000 simulations.:  18%|█▊        | 1843/10000 [00:07<00:33, 246.86it/s]Running 10000 simulations.:  19%|█▊        | 1868/10000 [00:07<00:32, 247.22it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:07<00:32, 247.10it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:07<00:32, 246.11it/s]Running 10000 simulations.:  19%|█▉        | 1943/10000 [00:07<00:32, 245.83it/s]Running 10000 simulations.:  20%|█▉        | 1968/10000 [00:07<00:32, 245.81it/s]Running 10000 simulations.:  20%|█▉        | 1993/10000 [00:07<00:32, 245.88it/s]Running 10000 simulations.:  20%|██        | 2018/10000 [00:08<00:32, 245.42it/s]Running 10000 simulations.:  20%|██        | 2043/10000 [00:08<00:32, 246.07it/s]Running 10000 simulations.:  21%|██        | 2068/10000 [00:08<00:32, 246.73it/s]Running 10000 simulations.:  21%|██        | 2093/10000 [00:08<00:31, 247.13it/s]Running 10000 simulations.:  21%|██        | 2118/10000 [00:08<00:31, 246.38it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:08<00:31, 246.09it/s]Running 10000 simulations.:  22%|██▏       | 2168/10000 [00:08<00:31, 246.03it/s]Running 10000 simulations.:  22%|██▏       | 2193/10000 [00:08<00:31, 245.17it/s]Running 10000 simulations.:  22%|██▏       | 2218/10000 [00:08<00:33, 234.01it/s]Running 10000 simulations.:  22%|██▏       | 2242/10000 [00:09<00:34, 226.68it/s]Running 10000 simulations.:  23%|██▎       | 2265/10000 [00:09<00:34, 223.01it/s]Running 10000 simulations.:  23%|██▎       | 2288/10000 [00:09<00:35, 220.18it/s]Running 10000 simulations.:  23%|██▎       | 2311/10000 [00:09<00:35, 217.90it/s]Running 10000 simulations.:  23%|██▎       | 2333/10000 [00:09<00:35, 215.92it/s]Running 10000 simulations.:  24%|██▎       | 2355/10000 [00:09<00:35, 214.36it/s]Running 10000 simulations.:  24%|██▍       | 2377/10000 [00:09<00:35, 213.87it/s]Running 10000 simulations.:  24%|██▍       | 2399/10000 [00:09<00:35, 213.25it/s]Running 10000 simulations.:  24%|██▍       | 2421/10000 [00:09<00:35, 211.98it/s]Running 10000 simulations.:  24%|██▍       | 2443/10000 [00:09<00:35, 211.66it/s]Running 10000 simulations.:  25%|██▍       | 2465/10000 [00:10<00:35, 211.14it/s]Running 10000 simulations.:  25%|██▍       | 2487/10000 [00:10<00:35, 211.36it/s]Running 10000 simulations.:  25%|██▌       | 2509/10000 [00:10<00:35, 210.73it/s]Running 10000 simulations.:  25%|██▌       | 2531/10000 [00:10<00:35, 210.76it/s]Running 10000 simulations.:  26%|██▌       | 2553/10000 [00:10<00:35, 209.90it/s]Running 10000 simulations.:  26%|██▌       | 2574/10000 [00:10<00:35, 207.76it/s]Running 10000 simulations.:  26%|██▌       | 2599/10000 [00:10<00:34, 217.59it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:10<00:32, 227.02it/s]Running 10000 simulations.:  27%|██▋       | 2651/10000 [00:10<00:31, 234.46it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:10<00:30, 240.75it/s]Running 10000 simulations.:  27%|██▋       | 2703/10000 [00:11<00:29, 244.79it/s]Running 10000 simulations.:  27%|██▋       | 2729/10000 [00:11<00:29, 248.43it/s]Running 10000 simulations.:  28%|██▊       | 2755/10000 [00:11<00:28, 251.02it/s]Running 10000 simulations.:  28%|██▊       | 2781/10000 [00:11<00:28, 252.83it/s]Running 10000 simulations.:  28%|██▊       | 2807/10000 [00:11<00:28, 253.05it/s]Running 10000 simulations.:  28%|██▊       | 2833/10000 [00:11<00:28, 253.49it/s]Running 10000 simulations.:  29%|██▊       | 2859/10000 [00:11<00:28, 253.92it/s]Running 10000 simulations.:  29%|██▉       | 2885/10000 [00:11<00:27, 254.47it/s]Running 10000 simulations.:  29%|██▉       | 2911/10000 [00:11<00:27, 254.14it/s]Running 10000 simulations.:  29%|██▉       | 2937/10000 [00:12<00:27, 254.67it/s]Running 10000 simulations.:  30%|██▉       | 2963/10000 [00:12<00:27, 255.74it/s]Running 10000 simulations.:  30%|██▉       | 2989/10000 [00:12<00:27, 255.73it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:12<00:27, 255.62it/s]Running 10000 simulations.:  30%|███       | 3041/10000 [00:12<00:27, 255.74it/s]Running 10000 simulations.:  31%|███       | 3067/10000 [00:12<00:27, 256.24it/s]Running 10000 simulations.:  31%|███       | 3093/10000 [00:12<00:27, 255.74it/s]Running 10000 simulations.:  31%|███       | 3119/10000 [00:12<00:26, 255.88it/s]Running 10000 simulations.:  31%|███▏      | 3145/10000 [00:12<00:26, 255.18it/s]Running 10000 simulations.:  32%|███▏      | 3171/10000 [00:12<00:26, 254.64it/s]Running 10000 simulations.:  32%|███▏      | 3197/10000 [00:13<00:26, 255.74it/s]Running 10000 simulations.:  32%|███▏      | 3223/10000 [00:13<00:26, 256.11it/s]Running 10000 simulations.:  32%|███▏      | 3249/10000 [00:13<00:26, 256.46it/s]Running 10000 simulations.:  33%|███▎      | 3275/10000 [00:13<00:26, 256.62it/s]Running 10000 simulations.:  33%|███▎      | 3301/10000 [00:13<00:26, 255.88it/s]Running 10000 simulations.:  33%|███▎      | 3327/10000 [00:13<00:26, 255.79it/s]Running 10000 simulations.:  34%|███▎      | 3353/10000 [00:13<00:26, 255.26it/s]Running 10000 simulations.:  34%|███▍      | 3379/10000 [00:13<00:25, 255.03it/s]Running 10000 simulations.:  34%|███▍      | 3405/10000 [00:13<00:25, 255.41it/s]Running 10000 simulations.:  34%|███▍      | 3431/10000 [00:13<00:25, 255.38it/s]Running 10000 simulations.:  35%|███▍      | 3457/10000 [00:14<00:25, 255.10it/s]Running 10000 simulations.:  35%|███▍      | 3483/10000 [00:14<00:25, 254.75it/s]Running 10000 simulations.:  35%|███▌      | 3509/10000 [00:14<00:25, 255.01it/s]Running 10000 simulations.:  35%|███▌      | 3535/10000 [00:14<00:25, 255.26it/s]Running 10000 simulations.:  36%|███▌      | 3561/10000 [00:14<00:25, 255.65it/s]Running 10000 simulations.:  36%|███▌      | 3587/10000 [00:14<00:25, 255.51it/s]Running 10000 simulations.:  36%|███▌      | 3613/10000 [00:14<00:24, 255.85it/s]Running 10000 simulations.:  36%|███▋      | 3639/10000 [00:14<00:24, 255.97it/s]Running 10000 simulations.:  37%|███▋      | 3665/10000 [00:14<00:24, 256.31it/s]Running 10000 simulations.:  37%|███▋      | 3691/10000 [00:14<00:24, 256.39it/s]Running 10000 simulations.:  37%|███▋      | 3717/10000 [00:15<00:24, 256.64it/s]Running 10000 simulations.:  37%|███▋      | 3743/10000 [00:15<00:24, 256.30it/s]Running 10000 simulations.:  38%|███▊      | 3769/10000 [00:15<00:24, 255.54it/s]Running 10000 simulations.:  38%|███▊      | 3795/10000 [00:15<00:24, 255.64it/s]Running 10000 simulations.:  38%|███▊      | 3821/10000 [00:15<00:24, 256.16it/s]Running 10000 simulations.:  38%|███▊      | 3847/10000 [00:15<00:24, 256.26it/s]Running 10000 simulations.:  39%|███▊      | 3873/10000 [00:15<00:23, 256.06it/s]Running 10000 simulations.:  39%|███▉      | 3899/10000 [00:15<00:23, 254.51it/s]Running 10000 simulations.:  39%|███▉      | 3925/10000 [00:15<00:23, 254.51it/s]Running 10000 simulations.:  40%|███▉      | 3951/10000 [00:15<00:23, 255.00it/s]Running 10000 simulations.:  40%|███▉      | 3977/10000 [00:16<00:23, 255.59it/s]Running 10000 simulations.:  40%|████      | 4003/10000 [00:16<00:23, 255.58it/s]Running 10000 simulations.:  40%|████      | 4029/10000 [00:16<00:23, 255.93it/s]Running 10000 simulations.:  41%|████      | 4055/10000 [00:16<00:23, 256.11it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:16<00:23, 255.88it/s]Running 10000 simulations.:  41%|████      | 4107/10000 [00:16<00:23, 255.01it/s]Running 10000 simulations.:  41%|████▏     | 4133/10000 [00:16<00:23, 254.70it/s]Running 10000 simulations.:  42%|████▏     | 4159/10000 [00:16<00:22, 255.11it/s]Running 10000 simulations.:  42%|████▏     | 4185/10000 [00:16<00:22, 255.25it/s]Running 10000 simulations.:  42%|████▏     | 4211/10000 [00:16<00:22, 255.72it/s]Running 10000 simulations.:  42%|████▏     | 4237/10000 [00:17<00:22, 254.92it/s]Running 10000 simulations.:  43%|████▎     | 4263/10000 [00:17<00:22, 255.27it/s]Running 10000 simulations.:  43%|████▎     | 4289/10000 [00:17<00:22, 255.40it/s]Running 10000 simulations.:  43%|████▎     | 4315/10000 [00:17<00:22, 256.20it/s]Running 10000 simulations.:  43%|████▎     | 4341/10000 [00:17<00:22, 253.56it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:17<00:22, 249.96it/s]Running 10000 simulations.:  44%|████▍     | 4393/10000 [00:17<00:22, 251.04it/s]Running 10000 simulations.:  44%|████▍     | 4419/10000 [00:17<00:22, 253.41it/s]Running 10000 simulations.:  44%|████▍     | 4445/10000 [00:17<00:21, 254.35it/s]Running 10000 simulations.:  45%|████▍     | 4471/10000 [00:18<00:21, 254.75it/s]Running 10000 simulations.:  45%|████▍     | 4497/10000 [00:18<00:21, 255.81it/s]Running 10000 simulations.:  45%|████▌     | 4523/10000 [00:18<00:21, 254.90it/s]Running 10000 simulations.:  45%|████▌     | 4549/10000 [00:18<00:21, 254.89it/s]Running 10000 simulations.:  46%|████▌     | 4575/10000 [00:18<00:21, 254.94it/s]Running 10000 simulations.:  46%|████▌     | 4601/10000 [00:18<00:21, 255.27it/s]Running 10000 simulations.:  46%|████▋     | 4627/10000 [00:18<00:21, 255.66it/s]Running 10000 simulations.:  47%|████▋     | 4653/10000 [00:18<00:20, 255.61it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:18<00:20, 255.34it/s]Running 10000 simulations.:  47%|████▋     | 4705/10000 [00:18<00:20, 255.28it/s]Running 10000 simulations.:  47%|████▋     | 4731/10000 [00:19<00:20, 255.39it/s]Running 10000 simulations.:  48%|████▊     | 4757/10000 [00:19<00:20, 255.31it/s]Running 10000 simulations.:  48%|████▊     | 4783/10000 [00:19<00:20, 256.18it/s]Running 10000 simulations.:  48%|████▊     | 4809/10000 [00:19<00:20, 256.15it/s]Running 10000 simulations.:  48%|████▊     | 4835/10000 [00:19<00:20, 254.95it/s]Running 10000 simulations.:  49%|████▊     | 4861/10000 [00:19<00:20, 255.29it/s]Running 10000 simulations.:  49%|████▉     | 4887/10000 [00:19<00:19, 256.16it/s]Running 10000 simulations.:  49%|████▉     | 4913/10000 [00:19<00:19, 255.42it/s]Running 10000 simulations.:  49%|████▉     | 4939/10000 [00:19<00:19, 254.69it/s]Running 10000 simulations.:  50%|████▉     | 4965/10000 [00:19<00:19, 254.93it/s]Running 10000 simulations.:  50%|████▉     | 4991/10000 [00:20<00:19, 253.94it/s]Running 10000 simulations.:  50%|█████     | 5017/10000 [00:20<00:19, 251.60it/s]Running 10000 simulations.:  50%|█████     | 5043/10000 [00:20<00:20, 236.26it/s]Running 10000 simulations.:  51%|█████     | 5067/10000 [00:20<00:21, 226.33it/s]Running 10000 simulations.:  51%|█████     | 5090/10000 [00:20<00:22, 219.52it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:20<00:22, 215.65it/s]Running 10000 simulations.:  51%|█████▏    | 5135/10000 [00:20<00:22, 212.90it/s]Running 10000 simulations.:  52%|█████▏    | 5157/10000 [00:20<00:22, 211.78it/s]Running 10000 simulations.:  52%|█████▏    | 5179/10000 [00:20<00:22, 211.46it/s]Running 10000 simulations.:  52%|█████▏    | 5201/10000 [00:21<00:22, 210.10it/s]Running 10000 simulations.:  52%|█████▏    | 5223/10000 [00:21<00:23, 207.08it/s]Running 10000 simulations.:  52%|█████▏    | 5244/10000 [00:21<00:23, 205.23it/s]Running 10000 simulations.:  53%|█████▎    | 5265/10000 [00:21<00:23, 203.93it/s]Running 10000 simulations.:  53%|█████▎    | 5286/10000 [00:21<00:23, 202.16it/s]Running 10000 simulations.:  53%|█████▎    | 5307/10000 [00:21<00:23, 200.39it/s]Running 10000 simulations.:  53%|█████▎    | 5328/10000 [00:21<00:23, 200.07it/s]Running 10000 simulations.:  53%|█████▎    | 5349/10000 [00:21<00:23, 199.96it/s]Running 10000 simulations.:  54%|█████▎    | 5370/10000 [00:21<00:23, 197.98it/s]Running 10000 simulations.:  54%|█████▍    | 5391/10000 [00:22<00:22, 200.44it/s]Running 10000 simulations.:  54%|█████▍    | 5412/10000 [00:22<00:22, 202.49it/s]Running 10000 simulations.:  54%|█████▍    | 5433/10000 [00:22<00:22, 203.51it/s]Running 10000 simulations.:  55%|█████▍    | 5454/10000 [00:22<00:22, 204.97it/s]Running 10000 simulations.:  55%|█████▍    | 5475/10000 [00:22<00:22, 205.40it/s]Running 10000 simulations.:  55%|█████▍    | 5496/10000 [00:22<00:22, 203.40it/s]Running 10000 simulations.:  55%|█████▌    | 5517/10000 [00:22<00:22, 202.82it/s]Running 10000 simulations.:  55%|█████▌    | 5538/10000 [00:22<00:22, 202.02it/s]Running 10000 simulations.:  56%|█████▌    | 5559/10000 [00:22<00:21, 203.90it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:22<00:21, 204.63it/s]Running 10000 simulations.:  56%|█████▌    | 5601/10000 [00:23<00:21, 205.74it/s]Running 10000 simulations.:  56%|█████▌    | 5622/10000 [00:23<00:21, 205.09it/s]Running 10000 simulations.:  56%|█████▋    | 5643/10000 [00:23<00:21, 205.32it/s]Running 10000 simulations.:  57%|█████▋    | 5664/10000 [00:23<00:21, 205.72it/s]Running 10000 simulations.:  57%|█████▋    | 5685/10000 [00:23<00:21, 205.44it/s]Running 10000 simulations.:  57%|█████▋    | 5706/10000 [00:23<00:20, 205.52it/s]Running 10000 simulations.:  57%|█████▋    | 5727/10000 [00:23<00:20, 205.96it/s]Running 10000 simulations.:  57%|█████▋    | 5748/10000 [00:23<00:20, 206.32it/s]Running 10000 simulations.:  58%|█████▊    | 5769/10000 [00:23<00:20, 205.89it/s]Running 10000 simulations.:  58%|█████▊    | 5790/10000 [00:23<00:20, 205.15it/s]Running 10000 simulations.:  58%|█████▊    | 5811/10000 [00:24<00:20, 204.62it/s]Running 10000 simulations.:  58%|█████▊    | 5832/10000 [00:24<00:20, 204.34it/s]Running 10000 simulations.:  59%|█████▊    | 5853/10000 [00:24<00:20, 204.45it/s]Running 10000 simulations.:  59%|█████▊    | 5874/10000 [00:24<00:20, 204.80it/s]Running 10000 simulations.:  59%|█████▉    | 5895/10000 [00:24<00:20, 205.23it/s]Running 10000 simulations.:  59%|█████▉    | 5916/10000 [00:24<00:19, 204.77it/s]Running 10000 simulations.:  59%|█████▉    | 5940/10000 [00:24<00:19, 212.71it/s]Running 10000 simulations.:  60%|█████▉    | 5967/10000 [00:24<00:17, 225.87it/s]Running 10000 simulations.:  60%|█████▉    | 5994/10000 [00:24<00:16, 235.82it/s]Running 10000 simulations.:  60%|██████    | 6021/10000 [00:24<00:16, 243.85it/s]Running 10000 simulations.:  60%|██████    | 6048/10000 [00:25<00:15, 249.19it/s]Running 10000 simulations.:  61%|██████    | 6075/10000 [00:25<00:15, 253.63it/s]Running 10000 simulations.:  61%|██████    | 6102/10000 [00:25<00:15, 256.28it/s]Running 10000 simulations.:  61%|██████▏   | 6129/10000 [00:25<00:14, 258.65it/s]Running 10000 simulations.:  62%|██████▏   | 6156/10000 [00:25<00:14, 260.27it/s]Running 10000 simulations.:  62%|██████▏   | 6183/10000 [00:25<00:14, 261.78it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:25<00:14, 263.69it/s]Running 10000 simulations.:  62%|██████▏   | 6238/10000 [00:25<00:14, 265.79it/s]Running 10000 simulations.:  63%|██████▎   | 6265/10000 [00:25<00:14, 260.46it/s]Running 10000 simulations.:  63%|██████▎   | 6292/10000 [00:26<00:14, 253.72it/s]Running 10000 simulations.:  63%|██████▎   | 6318/10000 [00:26<00:14, 248.60it/s]Running 10000 simulations.:  63%|██████▎   | 6343/10000 [00:26<00:14, 246.06it/s]Running 10000 simulations.:  64%|██████▎   | 6368/10000 [00:26<00:14, 244.07it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:26<00:14, 243.40it/s]Running 10000 simulations.:  64%|██████▍   | 6418/10000 [00:26<00:14, 242.26it/s]Running 10000 simulations.:  64%|██████▍   | 6443/10000 [00:26<00:14, 241.75it/s]Running 10000 simulations.:  65%|██████▍   | 6468/10000 [00:26<00:14, 240.96it/s]Running 10000 simulations.:  65%|██████▍   | 6493/10000 [00:26<00:14, 240.36it/s]Running 10000 simulations.:  65%|██████▌   | 6518/10000 [00:26<00:14, 239.52it/s]Running 10000 simulations.:  65%|██████▌   | 6543/10000 [00:27<00:14, 240.19it/s]Running 10000 simulations.:  66%|██████▌   | 6568/10000 [00:27<00:14, 240.73it/s]Running 10000 simulations.:  66%|██████▌   | 6593/10000 [00:27<00:14, 242.39it/s]Running 10000 simulations.:  66%|██████▌   | 6618/10000 [00:27<00:13, 244.52it/s]Running 10000 simulations.:  66%|██████▋   | 6644/10000 [00:27<00:13, 246.21it/s]Running 10000 simulations.:  67%|██████▋   | 6669/10000 [00:27<00:13, 247.18it/s]Running 10000 simulations.:  67%|██████▋   | 6695/10000 [00:27<00:13, 248.10it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:27<00:13, 248.40it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:27<00:13, 249.09it/s]Running 10000 simulations.:  68%|██████▊   | 6772/10000 [00:27<00:12, 249.75it/s]Running 10000 simulations.:  68%|██████▊   | 6797/10000 [00:28<00:12, 249.76it/s]Running 10000 simulations.:  68%|██████▊   | 6822/10000 [00:28<00:12, 249.57it/s]Running 10000 simulations.:  68%|██████▊   | 6848/10000 [00:28<00:12, 249.82it/s]Running 10000 simulations.:  69%|██████▊   | 6873/10000 [00:28<00:12, 249.29it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:28<00:12, 249.85it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:28<00:12, 249.05it/s]Running 10000 simulations.:  69%|██████▉   | 6949/10000 [00:28<00:12, 248.20it/s]Running 10000 simulations.:  70%|██████▉   | 6975/10000 [00:28<00:12, 248.77it/s]Running 10000 simulations.:  70%|███████   | 7000/10000 [00:28<00:12, 248.77it/s]Running 10000 simulations.:  70%|███████   | 7025/10000 [00:28<00:11, 248.87it/s]Running 10000 simulations.:  70%|███████   | 7050/10000 [00:29<00:11, 248.60it/s]Running 10000 simulations.:  71%|███████   | 7075/10000 [00:29<00:11, 248.52it/s]Running 10000 simulations.:  71%|███████   | 7100/10000 [00:29<00:11, 248.95it/s]Running 10000 simulations.:  71%|███████▏  | 7125/10000 [00:29<00:11, 249.25it/s]Running 10000 simulations.:  72%|███████▏  | 7151/10000 [00:29<00:11, 250.19it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:29<00:11, 250.86it/s]Running 10000 simulations.:  72%|███████▏  | 7203/10000 [00:29<00:11, 250.85it/s]Running 10000 simulations.:  72%|███████▏  | 7229/10000 [00:29<00:11, 235.56it/s]Running 10000 simulations.:  73%|███████▎  | 7253/10000 [00:29<00:12, 223.86it/s]Running 10000 simulations.:  73%|███████▎  | 7276/10000 [00:30<00:12, 215.80it/s]Running 10000 simulations.:  73%|███████▎  | 7298/10000 [00:30<00:12, 212.26it/s]Running 10000 simulations.:  73%|███████▎  | 7320/10000 [00:30<00:12, 208.55it/s]Running 10000 simulations.:  73%|███████▎  | 7341/10000 [00:30<00:12, 207.30it/s]Running 10000 simulations.:  74%|███████▎  | 7362/10000 [00:30<00:12, 206.13it/s]Running 10000 simulations.:  74%|███████▍  | 7383/10000 [00:30<00:12, 204.52it/s]Running 10000 simulations.:  74%|███████▍  | 7404/10000 [00:30<00:12, 203.82it/s]Running 10000 simulations.:  74%|███████▍  | 7425/10000 [00:30<00:12, 202.67it/s]Running 10000 simulations.:  74%|███████▍  | 7448/10000 [00:30<00:12, 208.87it/s]Running 10000 simulations.:  75%|███████▍  | 7475/10000 [00:31<00:11, 222.75it/s]Running 10000 simulations.:  75%|███████▌  | 7502/10000 [00:31<00:10, 234.44it/s]Running 10000 simulations.:  75%|███████▌  | 7529/10000 [00:31<00:10, 243.54it/s]Running 10000 simulations.:  76%|███████▌  | 7556/10000 [00:31<00:09, 248.77it/s]Running 10000 simulations.:  76%|███████▌  | 7584/10000 [00:31<00:09, 255.72it/s]Running 10000 simulations.:  76%|███████▌  | 7610/10000 [00:31<00:09, 253.92it/s]Running 10000 simulations.:  76%|███████▋  | 7636/10000 [00:31<00:09, 254.65it/s]Running 10000 simulations.:  77%|███████▋  | 7663/10000 [00:31<00:09, 256.71it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:31<00:08, 257.47it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:31<00:08, 258.11it/s]Running 10000 simulations.:  77%|███████▋  | 7742/10000 [00:32<00:08, 258.93it/s]Running 10000 simulations.:  78%|███████▊  | 7768/10000 [00:32<00:08, 258.94it/s]Running 10000 simulations.:  78%|███████▊  | 7794/10000 [00:32<00:08, 258.89it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:32<00:08, 260.18it/s]Running 10000 simulations.:  78%|███████▊  | 7848/10000 [00:32<00:08, 253.82it/s]Running 10000 simulations.:  79%|███████▊  | 7874/10000 [00:32<00:08, 248.76it/s]Running 10000 simulations.:  79%|███████▉  | 7899/10000 [00:32<00:08, 248.84it/s]Running 10000 simulations.:  79%|███████▉  | 7925/10000 [00:32<00:08, 249.37it/s]Running 10000 simulations.:  80%|███████▉  | 7951/10000 [00:32<00:08, 251.27it/s]Running 10000 simulations.:  80%|███████▉  | 7977/10000 [00:32<00:08, 251.01it/s]Running 10000 simulations.:  80%|████████  | 8003/10000 [00:33<00:07, 251.45it/s]Running 10000 simulations.:  80%|████████  | 8030/10000 [00:33<00:07, 253.97it/s]Running 10000 simulations.:  81%|████████  | 8057/10000 [00:33<00:07, 256.20it/s]Running 10000 simulations.:  81%|████████  | 8084/10000 [00:33<00:07, 258.55it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:33<00:07, 259.80it/s]Running 10000 simulations.:  81%|████████▏ | 8137/10000 [00:33<00:07, 258.28it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:33<00:07, 261.87it/s]Running 10000 simulations.:  82%|████████▏ | 8192/10000 [00:33<00:07, 256.81it/s]Running 10000 simulations.:  82%|████████▏ | 8219/10000 [00:33<00:06, 260.10it/s]Running 10000 simulations.:  82%|████████▏ | 8246/10000 [00:34<00:06, 255.40it/s]Running 10000 simulations.:  83%|████████▎ | 8272/10000 [00:34<00:06, 250.16it/s]Running 10000 simulations.:  83%|████████▎ | 8298/10000 [00:34<00:06, 247.10it/s]Running 10000 simulations.:  83%|████████▎ | 8323/10000 [00:34<00:06, 244.73it/s]Running 10000 simulations.:  83%|████████▎ | 8348/10000 [00:34<00:06, 243.20it/s]Running 10000 simulations.:  84%|████████▎ | 8373/10000 [00:34<00:06, 242.61it/s]Running 10000 simulations.:  84%|████████▍ | 8398/10000 [00:34<00:06, 242.71it/s]Running 10000 simulations.:  84%|████████▍ | 8423/10000 [00:34<00:06, 241.35it/s]Running 10000 simulations.:  84%|████████▍ | 8448/10000 [00:34<00:06, 241.70it/s]Running 10000 simulations.:  85%|████████▍ | 8473/10000 [00:34<00:06, 240.72it/s]Running 10000 simulations.:  85%|████████▍ | 8498/10000 [00:35<00:06, 240.60it/s]Running 10000 simulations.:  85%|████████▌ | 8523/10000 [00:35<00:06, 240.66it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:35<00:06, 239.77it/s]Running 10000 simulations.:  86%|████████▌ | 8572/10000 [00:35<00:05, 239.29it/s]Running 10000 simulations.:  86%|████████▌ | 8596/10000 [00:35<00:05, 239.13it/s]Running 10000 simulations.:  86%|████████▌ | 8620/10000 [00:35<00:05, 232.35it/s]Running 10000 simulations.:  86%|████████▋ | 8644/10000 [00:35<00:06, 222.95it/s]Running 10000 simulations.:  87%|████████▋ | 8667/10000 [00:35<00:06, 216.12it/s]Running 10000 simulations.:  87%|████████▋ | 8689/10000 [00:35<00:06, 212.71it/s]Running 10000 simulations.:  87%|████████▋ | 8711/10000 [00:36<00:06, 210.50it/s]Running 10000 simulations.:  87%|████████▋ | 8733/10000 [00:36<00:06, 208.93it/s]Running 10000 simulations.:  88%|████████▊ | 8754/10000 [00:36<00:05, 207.72it/s]Running 10000 simulations.:  88%|████████▊ | 8775/10000 [00:36<00:05, 206.90it/s]Running 10000 simulations.:  88%|████████▊ | 8796/10000 [00:36<00:05, 205.93it/s]Running 10000 simulations.:  88%|████████▊ | 8817/10000 [00:36<00:05, 205.29it/s]Running 10000 simulations.:  88%|████████▊ | 8838/10000 [00:36<00:05, 204.98it/s]Running 10000 simulations.:  89%|████████▊ | 8861/10000 [00:36<00:05, 211.72it/s]Running 10000 simulations.:  89%|████████▉ | 8886/10000 [00:36<00:05, 219.99it/s]Running 10000 simulations.:  89%|████████▉ | 8911/10000 [00:36<00:04, 226.03it/s]Running 10000 simulations.:  89%|████████▉ | 8936/10000 [00:37<00:04, 230.19it/s]Running 10000 simulations.:  90%|████████▉ | 8960/10000 [00:37<00:04, 232.69it/s]Running 10000 simulations.:  90%|████████▉ | 8984/10000 [00:37<00:04, 234.83it/s]Running 10000 simulations.:  90%|█████████ | 9008/10000 [00:37<00:04, 236.06it/s]Running 10000 simulations.:  90%|█████████ | 9032/10000 [00:37<00:04, 237.08it/s]Running 10000 simulations.:  91%|█████████ | 9056/10000 [00:37<00:03, 237.42it/s]Running 10000 simulations.:  91%|█████████ | 9080/10000 [00:37<00:03, 238.08it/s]Running 10000 simulations.:  91%|█████████ | 9105/10000 [00:37<00:03, 239.50it/s]Running 10000 simulations.:  91%|█████████▏| 9130/10000 [00:37<00:03, 240.37it/s]Running 10000 simulations.:  92%|█████████▏| 9155/10000 [00:37<00:03, 239.43it/s]Running 10000 simulations.:  92%|█████████▏| 9179/10000 [00:38<00:03, 239.53it/s]Running 10000 simulations.:  92%|█████████▏| 9204/10000 [00:38<00:03, 239.82it/s]Running 10000 simulations.:  92%|█████████▏| 9229/10000 [00:38<00:03, 240.48it/s]Running 10000 simulations.:  93%|█████████▎| 9254/10000 [00:38<00:03, 237.23it/s]Running 10000 simulations.:  93%|█████████▎| 9278/10000 [00:38<00:03, 234.82it/s]Running 10000 simulations.:  93%|█████████▎| 9302/10000 [00:38<00:03, 232.50it/s]Running 10000 simulations.:  93%|█████████▎| 9326/10000 [00:38<00:02, 230.80it/s]Running 10000 simulations.:  94%|█████████▎| 9350/10000 [00:38<00:02, 228.96it/s]Running 10000 simulations.:  94%|█████████▎| 9373/10000 [00:38<00:02, 227.24it/s]Running 10000 simulations.:  94%|█████████▍| 9396/10000 [00:39<00:02, 227.39it/s]Running 10000 simulations.:  94%|█████████▍| 9419/10000 [00:39<00:02, 227.38it/s]Running 10000 simulations.:  94%|█████████▍| 9442/10000 [00:39<00:02, 227.25it/s]Running 10000 simulations.:  95%|█████████▍| 9465/10000 [00:39<00:02, 227.03it/s]Running 10000 simulations.:  95%|█████████▍| 9488/10000 [00:39<00:02, 227.03it/s]Running 10000 simulations.:  95%|█████████▌| 9511/10000 [00:39<00:02, 226.83it/s]Running 10000 simulations.:  95%|█████████▌| 9534/10000 [00:39<00:02, 226.49it/s]Running 10000 simulations.:  96%|█████████▌| 9557/10000 [00:39<00:02, 217.90it/s]Running 10000 simulations.:  96%|█████████▌| 9579/10000 [00:39<00:02, 209.25it/s]Running 10000 simulations.:  96%|█████████▌| 9601/10000 [00:39<00:01, 204.47it/s]Running 10000 simulations.:  96%|█████████▋| 9626/10000 [00:40<00:01, 215.03it/s]Running 10000 simulations.:  97%|█████████▋| 9653/10000 [00:40<00:01, 226.97it/s]Running 10000 simulations.:  97%|█████████▋| 9679/10000 [00:40<00:01, 235.74it/s]Running 10000 simulations.:  97%|█████████▋| 9706/10000 [00:40<00:01, 242.81it/s]Running 10000 simulations.:  97%|█████████▋| 9733/10000 [00:40<00:01, 248.14it/s]Running 10000 simulations.:  98%|█████████▊| 9760/10000 [00:40<00:00, 252.90it/s]Running 10000 simulations.:  98%|█████████▊| 9787/10000 [00:40<00:00, 256.49it/s]Running 10000 simulations.:  98%|█████████▊| 9814/10000 [00:40<00:00, 258.44it/s]Running 10000 simulations.:  98%|█████████▊| 9841/10000 [00:40<00:00, 259.80it/s]Running 10000 simulations.:  99%|█████████▊| 9868/10000 [00:40<00:00, 261.18it/s]Running 10000 simulations.:  99%|█████████▉| 9895/10000 [00:41<00:00, 261.15it/s]Running 10000 simulations.:  99%|█████████▉| 9922/10000 [00:41<00:00, 262.21it/s]Running 10000 simulations.:  99%|█████████▉| 9949/10000 [00:41<00:00, 263.13it/s]Running 10000 simulations.: 100%|█████████▉| 9976/10000 [00:41<00:00, 263.68it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 241.05it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 27/10000 [00:00<00:37, 266.72it/s]Running 10000 simulations.:   1%|          | 54/10000 [00:00<00:37, 266.45it/s]Running 10000 simulations.:   1%|          | 81/10000 [00:00<00:37, 265.96it/s]Running 10000 simulations.:   1%|          | 108/10000 [00:00<00:37, 265.24it/s]Running 10000 simulations.:   1%|▏         | 135/10000 [00:00<00:37, 264.34it/s]Running 10000 simulations.:   2%|▏         | 162/10000 [00:00<00:37, 264.20it/s]Running 10000 simulations.:   2%|▏         | 189/10000 [00:00<00:37, 263.74it/s]Running 10000 simulations.:   2%|▏         | 215/10000 [00:00<00:37, 262.06it/s]Running 10000 simulations.:   2%|▏         | 242/10000 [00:00<00:37, 261.94it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:01<00:37, 261.80it/s]Running 10000 simulations.:   3%|▎         | 296/10000 [00:01<00:37, 261.78it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:36, 261.81it/s]Running 10000 simulations.:   4%|▎         | 350/10000 [00:01<00:36, 261.65it/s]Running 10000 simulations.:   4%|▍         | 377/10000 [00:01<00:36, 261.35it/s]Running 10000 simulations.:   4%|▍         | 404/10000 [00:01<00:36, 261.07it/s]Running 10000 simulations.:   4%|▍         | 430/10000 [00:01<00:36, 260.57it/s]Running 10000 simulations.:   5%|▍         | 457/10000 [00:01<00:36, 260.67it/s]Running 10000 simulations.:   5%|▍         | 484/10000 [00:01<00:36, 260.04it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:01<00:36, 256.73it/s]Running 10000 simulations.:   5%|▌         | 536/10000 [00:02<00:37, 253.42it/s]Running 10000 simulations.:   6%|▌         | 562/10000 [00:02<00:37, 254.50it/s]Running 10000 simulations.:   6%|▌         | 588/10000 [00:02<00:36, 255.79it/s]Running 10000 simulations.:   6%|▌         | 614/10000 [00:02<00:36, 256.44it/s]Running 10000 simulations.:   6%|▋         | 641/10000 [00:02<00:36, 257.67it/s]Running 10000 simulations.:   7%|▋         | 667/10000 [00:02<00:36, 257.79it/s]Running 10000 simulations.:   7%|▋         | 694/10000 [00:02<00:35, 258.58it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:02<00:36, 257.63it/s]Running 10000 simulations.:   7%|▋         | 746/10000 [00:02<00:35, 257.79it/s]Running 10000 simulations.:   8%|▊         | 772/10000 [00:02<00:35, 257.84it/s]Running 10000 simulations.:   8%|▊         | 798/10000 [00:03<00:35, 257.56it/s]Running 10000 simulations.:   8%|▊         | 824/10000 [00:03<00:35, 257.15it/s]Running 10000 simulations.:   8%|▊         | 850/10000 [00:03<00:35, 256.60it/s]Running 10000 simulations.:   9%|▉         | 876/10000 [00:03<00:35, 256.75it/s]Running 10000 simulations.:   9%|▉         | 902/10000 [00:03<00:35, 257.44it/s]Running 10000 simulations.:   9%|▉         | 928/10000 [00:03<00:35, 257.83it/s]Running 10000 simulations.:  10%|▉         | 954/10000 [00:03<00:35, 257.37it/s]Running 10000 simulations.:  10%|▉         | 980/10000 [00:03<00:34, 257.72it/s]Running 10000 simulations.:  10%|█         | 1006/10000 [00:03<00:34, 257.61it/s]Running 10000 simulations.:  10%|█         | 1032/10000 [00:03<00:34, 256.75it/s]Running 10000 simulations.:  11%|█         | 1058/10000 [00:04<00:34, 256.64it/s]Running 10000 simulations.:  11%|█         | 1084/10000 [00:04<00:34, 256.57it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:04<00:34, 256.41it/s]Running 10000 simulations.:  11%|█▏        | 1136/10000 [00:04<00:34, 256.69it/s]Running 10000 simulations.:  12%|█▏        | 1162/10000 [00:04<00:34, 256.71it/s]Running 10000 simulations.:  12%|█▏        | 1188/10000 [00:04<00:34, 256.64it/s]Running 10000 simulations.:  12%|█▏        | 1214/10000 [00:04<00:34, 256.71it/s]Running 10000 simulations.:  12%|█▏        | 1240/10000 [00:04<00:34, 256.55it/s]Running 10000 simulations.:  13%|█▎        | 1266/10000 [00:04<00:34, 256.38it/s]Running 10000 simulations.:  13%|█▎        | 1292/10000 [00:04<00:33, 256.30it/s]Running 10000 simulations.:  13%|█▎        | 1318/10000 [00:05<00:33, 256.45it/s]Running 10000 simulations.:  13%|█▎        | 1344/10000 [00:05<00:33, 255.90it/s]Running 10000 simulations.:  14%|█▎        | 1370/10000 [00:05<00:33, 255.95it/s]Running 10000 simulations.:  14%|█▍        | 1396/10000 [00:05<00:33, 255.40it/s]Running 10000 simulations.:  14%|█▍        | 1422/10000 [00:05<00:33, 255.71it/s]Running 10000 simulations.:  14%|█▍        | 1448/10000 [00:05<00:33, 255.88it/s]Running 10000 simulations.:  15%|█▍        | 1474/10000 [00:05<00:33, 255.58it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:05<00:33, 255.57it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:05<00:33, 255.76it/s]Running 10000 simulations.:  16%|█▌        | 1552/10000 [00:06<00:33, 255.49it/s]Running 10000 simulations.:  16%|█▌        | 1578/10000 [00:06<00:32, 255.40it/s]Running 10000 simulations.:  16%|█▌        | 1604/10000 [00:06<00:32, 255.57it/s]Running 10000 simulations.:  16%|█▋        | 1630/10000 [00:06<00:32, 255.14it/s]Running 10000 simulations.:  17%|█▋        | 1656/10000 [00:06<00:32, 255.09it/s]Running 10000 simulations.:  17%|█▋        | 1682/10000 [00:06<00:32, 254.50it/s]Running 10000 simulations.:  17%|█▋        | 1708/10000 [00:06<00:32, 254.36it/s]Running 10000 simulations.:  17%|█▋        | 1734/10000 [00:06<00:32, 254.56it/s]Running 10000 simulations.:  18%|█▊        | 1760/10000 [00:06<00:32, 254.66it/s]Running 10000 simulations.:  18%|█▊        | 1786/10000 [00:06<00:32, 255.18it/s]Running 10000 simulations.:  18%|█▊        | 1812/10000 [00:07<00:32, 255.06it/s]Running 10000 simulations.:  18%|█▊        | 1839/10000 [00:07<00:31, 257.15it/s]Running 10000 simulations.:  19%|█▊        | 1866/10000 [00:07<00:31, 260.78it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:07<00:30, 262.39it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:07<00:30, 264.19it/s]Running 10000 simulations.:  19%|█▉        | 1947/10000 [00:07<00:30, 265.10it/s]Running 10000 simulations.:  20%|█▉        | 1974/10000 [00:07<00:30, 265.54it/s]Running 10000 simulations.:  20%|██        | 2001/10000 [00:07<00:30, 265.32it/s]Running 10000 simulations.:  20%|██        | 2028/10000 [00:07<00:29, 265.86it/s]Running 10000 simulations.:  21%|██        | 2055/10000 [00:07<00:29, 265.86it/s]Running 10000 simulations.:  21%|██        | 2082/10000 [00:08<00:29, 265.78it/s]Running 10000 simulations.:  21%|██        | 2109/10000 [00:08<00:29, 266.63it/s]Running 10000 simulations.:  21%|██▏       | 2137/10000 [00:08<00:29, 267.85it/s]Running 10000 simulations.:  22%|██▏       | 2164/10000 [00:08<00:30, 260.66it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:08<00:32, 240.77it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:08<00:34, 226.20it/s]Running 10000 simulations.:  22%|██▏       | 2240/10000 [00:08<00:35, 217.50it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:08<00:36, 214.34it/s]Running 10000 simulations.:  23%|██▎       | 2285/10000 [00:08<00:36, 212.48it/s]Running 10000 simulations.:  23%|██▎       | 2307/10000 [00:09<00:36, 209.57it/s]Running 10000 simulations.:  23%|██▎       | 2329/10000 [00:09<00:36, 208.38it/s]Running 10000 simulations.:  24%|██▎       | 2350/10000 [00:09<00:36, 208.53it/s]Running 10000 simulations.:  24%|██▎       | 2372/10000 [00:09<00:36, 209.30it/s]Running 10000 simulations.:  24%|██▍       | 2394/10000 [00:09<00:35, 211.59it/s]Running 10000 simulations.:  24%|██▍       | 2416/10000 [00:09<00:36, 209.40it/s]Running 10000 simulations.:  24%|██▍       | 2437/10000 [00:09<00:36, 209.27it/s]Running 10000 simulations.:  25%|██▍       | 2458/10000 [00:09<00:36, 209.45it/s]Running 10000 simulations.:  25%|██▍       | 2480/10000 [00:09<00:35, 212.35it/s]Running 10000 simulations.:  25%|██▌       | 2502/10000 [00:09<00:35, 212.56it/s]Running 10000 simulations.:  25%|██▌       | 2524/10000 [00:10<00:35, 213.56it/s]Running 10000 simulations.:  25%|██▌       | 2546/10000 [00:10<00:35, 210.78it/s]Running 10000 simulations.:  26%|██▌       | 2568/10000 [00:10<00:35, 206.76it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:10<00:35, 207.78it/s]Running 10000 simulations.:  26%|██▌       | 2611/10000 [00:10<00:35, 207.77it/s]Running 10000 simulations.:  26%|██▋       | 2633/10000 [00:10<00:35, 208.62it/s]Running 10000 simulations.:  27%|██▋       | 2655/10000 [00:10<00:35, 209.28it/s]Running 10000 simulations.:  27%|██▋       | 2676/10000 [00:10<00:35, 207.11it/s]Running 10000 simulations.:  27%|██▋       | 2697/10000 [00:10<00:35, 206.27it/s]Running 10000 simulations.:  27%|██▋       | 2718/10000 [00:11<00:35, 206.42it/s]Running 10000 simulations.:  27%|██▋       | 2739/10000 [00:11<00:35, 204.57it/s]Running 10000 simulations.:  28%|██▊       | 2760/10000 [00:11<00:35, 205.65it/s]Running 10000 simulations.:  28%|██▊       | 2784/10000 [00:11<00:33, 212.87it/s]Running 10000 simulations.:  28%|██▊       | 2807/10000 [00:11<00:33, 217.50it/s]Running 10000 simulations.:  28%|██▊       | 2831/10000 [00:11<00:32, 221.63it/s]Running 10000 simulations.:  29%|██▊       | 2855/10000 [00:11<00:31, 225.12it/s]Running 10000 simulations.:  29%|██▉       | 2879/10000 [00:11<00:31, 227.57it/s]Running 10000 simulations.:  29%|██▉       | 2903/10000 [00:11<00:30, 229.11it/s]Running 10000 simulations.:  29%|██▉       | 2927/10000 [00:11<00:30, 230.50it/s]Running 10000 simulations.:  30%|██▉       | 2951/10000 [00:12<00:30, 231.12it/s]Running 10000 simulations.:  30%|██▉       | 2975/10000 [00:12<00:30, 230.90it/s]Running 10000 simulations.:  30%|██▉       | 2999/10000 [00:12<00:30, 230.67it/s]Running 10000 simulations.:  30%|███       | 3023/10000 [00:12<00:30, 231.06it/s]Running 10000 simulations.:  30%|███       | 3047/10000 [00:12<00:30, 231.37it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:12<00:29, 231.54it/s]Running 10000 simulations.:  31%|███       | 3095/10000 [00:12<00:29, 231.78it/s]Running 10000 simulations.:  31%|███       | 3119/10000 [00:12<00:29, 231.89it/s]Running 10000 simulations.:  31%|███▏      | 3143/10000 [00:12<00:29, 230.64it/s]Running 10000 simulations.:  32%|███▏      | 3167/10000 [00:12<00:29, 230.66it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:13<00:29, 230.74it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:13<00:29, 231.01it/s]Running 10000 simulations.:  32%|███▏      | 3239/10000 [00:13<00:29, 231.53it/s]Running 10000 simulations.:  33%|███▎      | 3263/10000 [00:13<00:29, 232.01it/s]Running 10000 simulations.:  33%|███▎      | 3287/10000 [00:13<00:28, 232.52it/s]Running 10000 simulations.:  33%|███▎      | 3311/10000 [00:13<00:28, 232.56it/s]Running 10000 simulations.:  33%|███▎      | 3335/10000 [00:13<00:28, 232.13it/s]Running 10000 simulations.:  34%|███▎      | 3359/10000 [00:13<00:28, 231.94it/s]Running 10000 simulations.:  34%|███▍      | 3383/10000 [00:13<00:28, 231.04it/s]Running 10000 simulations.:  34%|███▍      | 3407/10000 [00:14<00:28, 231.36it/s]Running 10000 simulations.:  34%|███▍      | 3431/10000 [00:14<00:28, 230.76it/s]Running 10000 simulations.:  35%|███▍      | 3455/10000 [00:14<00:28, 228.62it/s]Running 10000 simulations.:  35%|███▍      | 3479/10000 [00:14<00:28, 229.36it/s]Running 10000 simulations.:  35%|███▌      | 3503/10000 [00:14<00:28, 229.86it/s]Running 10000 simulations.:  35%|███▌      | 3527/10000 [00:14<00:28, 230.01it/s]Running 10000 simulations.:  36%|███▌      | 3551/10000 [00:14<00:28, 230.01it/s]Running 10000 simulations.:  36%|███▌      | 3575/10000 [00:14<00:27, 230.34it/s]Running 10000 simulations.:  36%|███▌      | 3599/10000 [00:14<00:27, 231.14it/s]Running 10000 simulations.:  36%|███▌      | 3623/10000 [00:14<00:27, 231.67it/s]Running 10000 simulations.:  36%|███▋      | 3647/10000 [00:15<00:27, 232.04it/s]Running 10000 simulations.:  37%|███▋      | 3671/10000 [00:15<00:27, 231.82it/s]Running 10000 simulations.:  37%|███▋      | 3695/10000 [00:15<00:27, 231.35it/s]Running 10000 simulations.:  37%|███▋      | 3719/10000 [00:15<00:27, 231.51it/s]Running 10000 simulations.:  37%|███▋      | 3744/10000 [00:15<00:26, 235.13it/s]Running 10000 simulations.:  38%|███▊      | 3768/10000 [00:15<00:26, 236.02it/s]Running 10000 simulations.:  38%|███▊      | 3792/10000 [00:15<00:26, 235.50it/s]Running 10000 simulations.:  38%|███▊      | 3816/10000 [00:15<00:26, 236.04it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:15<00:26, 235.99it/s]Running 10000 simulations.:  39%|███▊      | 3864/10000 [00:15<00:26, 235.92it/s]Running 10000 simulations.:  39%|███▉      | 3888/10000 [00:16<00:25, 235.43it/s]Running 10000 simulations.:  39%|███▉      | 3912/10000 [00:16<00:25, 236.22it/s]Running 10000 simulations.:  39%|███▉      | 3936/10000 [00:16<00:25, 236.00it/s]Running 10000 simulations.:  40%|███▉      | 3961/10000 [00:16<00:25, 237.33it/s]Running 10000 simulations.:  40%|███▉      | 3985/10000 [00:16<00:25, 236.95it/s]Running 10000 simulations.:  40%|████      | 4009/10000 [00:16<00:25, 236.18it/s]Running 10000 simulations.:  40%|████      | 4033/10000 [00:16<00:25, 235.26it/s]Running 10000 simulations.:  41%|████      | 4057/10000 [00:16<00:26, 228.06it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:16<00:25, 229.33it/s]Running 10000 simulations.:  41%|████      | 4105/10000 [00:17<00:25, 230.76it/s]Running 10000 simulations.:  41%|████▏     | 4129/10000 [00:17<00:25, 231.10it/s]Running 10000 simulations.:  42%|████▏     | 4153/10000 [00:17<00:25, 230.88it/s]Running 10000 simulations.:  42%|████▏     | 4177/10000 [00:17<00:25, 231.53it/s]Running 10000 simulations.:  42%|████▏     | 4201/10000 [00:17<00:25, 231.93it/s]Running 10000 simulations.:  42%|████▏     | 4225/10000 [00:17<00:24, 232.06it/s]Running 10000 simulations.:  42%|████▏     | 4249/10000 [00:17<00:24, 232.23it/s]Running 10000 simulations.:  43%|████▎     | 4273/10000 [00:17<00:24, 232.37it/s]Running 10000 simulations.:  43%|████▎     | 4297/10000 [00:17<00:24, 232.15it/s]Running 10000 simulations.:  43%|████▎     | 4321/10000 [00:17<00:24, 231.94it/s]Running 10000 simulations.:  43%|████▎     | 4345/10000 [00:18<00:24, 231.77it/s]Running 10000 simulations.:  44%|████▎     | 4369/10000 [00:18<00:24, 232.04it/s]Running 10000 simulations.:  44%|████▍     | 4393/10000 [00:18<00:24, 231.93it/s]Running 10000 simulations.:  44%|████▍     | 4417/10000 [00:18<00:24, 232.21it/s]Running 10000 simulations.:  44%|████▍     | 4441/10000 [00:18<00:23, 232.56it/s]Running 10000 simulations.:  45%|████▍     | 4465/10000 [00:18<00:23, 232.40it/s]Running 10000 simulations.:  45%|████▍     | 4489/10000 [00:18<00:23, 232.38it/s]Running 10000 simulations.:  45%|████▌     | 4513/10000 [00:18<00:23, 231.59it/s]Running 10000 simulations.:  45%|████▌     | 4537/10000 [00:18<00:23, 232.03it/s]Running 10000 simulations.:  46%|████▌     | 4561/10000 [00:18<00:23, 231.92it/s]Running 10000 simulations.:  46%|████▌     | 4585/10000 [00:19<00:23, 232.53it/s]Running 10000 simulations.:  46%|████▌     | 4609/10000 [00:19<00:23, 233.13it/s]Running 10000 simulations.:  46%|████▋     | 4633/10000 [00:19<00:23, 233.30it/s]Running 10000 simulations.:  47%|████▋     | 4657/10000 [00:19<00:22, 232.54it/s]Running 10000 simulations.:  47%|████▋     | 4681/10000 [00:19<00:22, 231.99it/s]Running 10000 simulations.:  47%|████▋     | 4705/10000 [00:19<00:22, 231.80it/s]Running 10000 simulations.:  47%|████▋     | 4729/10000 [00:19<00:22, 231.72it/s]Running 10000 simulations.:  48%|████▊     | 4753/10000 [00:19<00:22, 231.70it/s]Running 10000 simulations.:  48%|████▊     | 4777/10000 [00:19<00:22, 232.13it/s]Running 10000 simulations.:  48%|████▊     | 4801/10000 [00:20<00:22, 232.37it/s]Running 10000 simulations.:  48%|████▊     | 4825/10000 [00:20<00:22, 232.35it/s]Running 10000 simulations.:  48%|████▊     | 4849/10000 [00:20<00:22, 232.14it/s]Running 10000 simulations.:  49%|████▊     | 4873/10000 [00:20<00:22, 232.35it/s]Running 10000 simulations.:  49%|████▉     | 4897/10000 [00:20<00:21, 232.27it/s]Running 10000 simulations.:  49%|████▉     | 4921/10000 [00:20<00:21, 231.28it/s]Running 10000 simulations.:  49%|████▉     | 4945/10000 [00:20<00:21, 231.59it/s]Running 10000 simulations.:  50%|████▉     | 4969/10000 [00:20<00:21, 232.04it/s]Running 10000 simulations.:  50%|████▉     | 4993/10000 [00:20<00:21, 231.41it/s]Running 10000 simulations.:  50%|█████     | 5017/10000 [00:20<00:21, 230.57it/s]Running 10000 simulations.:  50%|█████     | 5041/10000 [00:21<00:21, 230.47it/s]Running 10000 simulations.:  51%|█████     | 5065/10000 [00:21<00:21, 230.46it/s]Running 10000 simulations.:  51%|█████     | 5089/10000 [00:21<00:21, 230.21it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:21<00:21, 231.28it/s]Running 10000 simulations.:  51%|█████▏    | 5137/10000 [00:21<00:20, 232.24it/s]Running 10000 simulations.:  52%|█████▏    | 5161/10000 [00:21<00:20, 233.03it/s]Running 10000 simulations.:  52%|█████▏    | 5185/10000 [00:21<00:20, 232.82it/s]Running 10000 simulations.:  52%|█████▏    | 5209/10000 [00:21<00:20, 232.24it/s]Running 10000 simulations.:  52%|█████▏    | 5233/10000 [00:21<00:20, 232.32it/s]Running 10000 simulations.:  53%|█████▎    | 5257/10000 [00:21<00:20, 232.59it/s]Running 10000 simulations.:  53%|█████▎    | 5281/10000 [00:22<00:20, 232.78it/s]Running 10000 simulations.:  53%|█████▎    | 5305/10000 [00:22<00:20, 233.19it/s]Running 10000 simulations.:  53%|█████▎    | 5329/10000 [00:22<00:20, 233.06it/s]Running 10000 simulations.:  54%|█████▎    | 5353/10000 [00:22<00:19, 233.05it/s]Running 10000 simulations.:  54%|█████▍    | 5377/10000 [00:22<00:19, 232.72it/s]Running 10000 simulations.:  54%|█████▍    | 5401/10000 [00:22<00:19, 232.94it/s]Running 10000 simulations.:  54%|█████▍    | 5425/10000 [00:22<00:19, 232.64it/s]Running 10000 simulations.:  54%|█████▍    | 5449/10000 [00:22<00:19, 232.56it/s]Running 10000 simulations.:  55%|█████▍    | 5473/10000 [00:22<00:19, 232.51it/s]Running 10000 simulations.:  55%|█████▍    | 5497/10000 [00:23<00:19, 231.64it/s]Running 10000 simulations.:  55%|█████▌    | 5521/10000 [00:23<00:19, 231.97it/s]Running 10000 simulations.:  55%|█████▌    | 5545/10000 [00:23<00:19, 232.53it/s]Running 10000 simulations.:  56%|█████▌    | 5569/10000 [00:23<00:19, 232.70it/s]Running 10000 simulations.:  56%|█████▌    | 5593/10000 [00:23<00:18, 232.69it/s]Running 10000 simulations.:  56%|█████▌    | 5617/10000 [00:23<00:18, 232.32it/s]Running 10000 simulations.:  56%|█████▋    | 5641/10000 [00:23<00:18, 231.91it/s]Running 10000 simulations.:  57%|█████▋    | 5665/10000 [00:23<00:18, 232.04it/s]Running 10000 simulations.:  57%|█████▋    | 5689/10000 [00:23<00:18, 232.28it/s]Running 10000 simulations.:  57%|█████▋    | 5713/10000 [00:23<00:18, 232.36it/s]Running 10000 simulations.:  57%|█████▋    | 5737/10000 [00:24<00:18, 232.72it/s]Running 10000 simulations.:  58%|█████▊    | 5764/10000 [00:24<00:17, 242.24it/s]Running 10000 simulations.:  58%|█████▊    | 5791/10000 [00:24<00:16, 248.78it/s]Running 10000 simulations.:  58%|█████▊    | 5818/10000 [00:24<00:16, 252.12it/s]Running 10000 simulations.:  58%|█████▊    | 5845/10000 [00:24<00:16, 254.82it/s]Running 10000 simulations.:  59%|█████▊    | 5872/10000 [00:24<00:16, 257.15it/s]Running 10000 simulations.:  59%|█████▉    | 5899/10000 [00:24<00:15, 259.69it/s]Running 10000 simulations.:  59%|█████▉    | 5926/10000 [00:24<00:15, 261.48it/s]Running 10000 simulations.:  60%|█████▉    | 5953/10000 [00:24<00:15, 263.18it/s]Running 10000 simulations.:  60%|█████▉    | 5980/10000 [00:24<00:15, 265.00it/s]Running 10000 simulations.:  60%|██████    | 6007/10000 [00:25<00:14, 266.37it/s]Running 10000 simulations.:  60%|██████    | 6034/10000 [00:25<00:15, 259.06it/s]Running 10000 simulations.:  61%|██████    | 6060/10000 [00:25<00:15, 252.85it/s]Running 10000 simulations.:  61%|██████    | 6086/10000 [00:25<00:15, 248.95it/s]Running 10000 simulations.:  61%|██████    | 6111/10000 [00:25<00:15, 245.88it/s]Running 10000 simulations.:  61%|██████▏   | 6136/10000 [00:25<00:15, 243.81it/s]Running 10000 simulations.:  62%|██████▏   | 6161/10000 [00:25<00:15, 242.00it/s]Running 10000 simulations.:  62%|██████▏   | 6186/10000 [00:25<00:15, 240.76it/s]Running 10000 simulations.:  62%|██████▏   | 6211/10000 [00:25<00:15, 240.62it/s]Running 10000 simulations.:  62%|██████▏   | 6236/10000 [00:26<00:15, 240.43it/s]Running 10000 simulations.:  63%|██████▎   | 6261/10000 [00:26<00:15, 239.89it/s]Running 10000 simulations.:  63%|██████▎   | 6285/10000 [00:26<00:15, 239.82it/s]Running 10000 simulations.:  63%|██████▎   | 6309/10000 [00:26<00:15, 239.18it/s]Running 10000 simulations.:  63%|██████▎   | 6333/10000 [00:26<00:15, 238.96it/s]Running 10000 simulations.:  64%|██████▎   | 6357/10000 [00:26<00:15, 239.17it/s]Running 10000 simulations.:  64%|██████▍   | 6381/10000 [00:26<00:15, 239.27it/s]Running 10000 simulations.:  64%|██████▍   | 6406/10000 [00:26<00:14, 239.62it/s]Running 10000 simulations.:  64%|██████▍   | 6431/10000 [00:26<00:14, 239.89it/s]Running 10000 simulations.:  65%|██████▍   | 6455/10000 [00:26<00:14, 239.81it/s]Running 10000 simulations.:  65%|██████▍   | 6479/10000 [00:27<00:14, 239.56it/s]Running 10000 simulations.:  65%|██████▌   | 6503/10000 [00:27<00:14, 239.23it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:27<00:14, 239.48it/s]Running 10000 simulations.:  66%|██████▌   | 6552/10000 [00:27<00:14, 239.61it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:27<00:14, 239.26it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:27<00:14, 239.21it/s]Running 10000 simulations.:  66%|██████▌   | 6624/10000 [00:27<00:14, 239.37it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:27<00:14, 239.04it/s]Running 10000 simulations.:  67%|██████▋   | 6672/10000 [00:27<00:13, 239.30it/s]Running 10000 simulations.:  67%|██████▋   | 6696/10000 [00:27<00:13, 239.49it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:28<00:13, 237.10it/s]Running 10000 simulations.:  67%|██████▋   | 6744/10000 [00:28<00:13, 236.33it/s]Running 10000 simulations.:  68%|██████▊   | 6769/10000 [00:28<00:13, 237.53it/s]Running 10000 simulations.:  68%|██████▊   | 6793/10000 [00:28<00:13, 237.95it/s]Running 10000 simulations.:  68%|██████▊   | 6817/10000 [00:28<00:13, 237.96it/s]Running 10000 simulations.:  68%|██████▊   | 6841/10000 [00:28<00:13, 238.31it/s]Running 10000 simulations.:  69%|██████▊   | 6866/10000 [00:28<00:13, 239.17it/s]Running 10000 simulations.:  69%|██████▉   | 6891/10000 [00:28<00:12, 239.40it/s]Running 10000 simulations.:  69%|██████▉   | 6915/10000 [00:28<00:12, 239.45it/s]Running 10000 simulations.:  69%|██████▉   | 6939/10000 [00:28<00:12, 238.78it/s]Running 10000 simulations.:  70%|██████▉   | 6963/10000 [00:29<00:12, 233.89it/s]Running 10000 simulations.:  70%|██████▉   | 6987/10000 [00:29<00:13, 226.56it/s]Running 10000 simulations.:  70%|███████   | 7010/10000 [00:29<00:13, 221.47it/s]Running 10000 simulations.:  70%|███████   | 7033/10000 [00:29<00:13, 218.44it/s]Running 10000 simulations.:  71%|███████   | 7055/10000 [00:29<00:13, 216.51it/s]Running 10000 simulations.:  71%|███████   | 7077/10000 [00:29<00:13, 215.37it/s]Running 10000 simulations.:  71%|███████   | 7099/10000 [00:29<00:13, 214.67it/s]Running 10000 simulations.:  71%|███████   | 7121/10000 [00:29<00:13, 213.50it/s]Running 10000 simulations.:  71%|███████▏  | 7143/10000 [00:29<00:13, 213.32it/s]Running 10000 simulations.:  72%|███████▏  | 7165/10000 [00:30<00:13, 212.38it/s]Running 10000 simulations.:  72%|███████▏  | 7187/10000 [00:30<00:13, 212.12it/s]Running 10000 simulations.:  72%|███████▏  | 7209/10000 [00:30<00:13, 212.03it/s]Running 10000 simulations.:  72%|███████▏  | 7231/10000 [00:30<00:13, 211.65it/s]Running 10000 simulations.:  73%|███████▎  | 7253/10000 [00:30<00:12, 211.86it/s]Running 10000 simulations.:  73%|███████▎  | 7275/10000 [00:30<00:12, 211.90it/s]Running 10000 simulations.:  73%|███████▎  | 7297/10000 [00:30<00:12, 211.27it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:30<00:12, 217.07it/s]Running 10000 simulations.:  73%|███████▎  | 7346/10000 [00:30<00:11, 225.80it/s]Running 10000 simulations.:  74%|███████▎  | 7373/10000 [00:30<00:11, 237.15it/s]Running 10000 simulations.:  74%|███████▍  | 7399/10000 [00:31<00:10, 242.07it/s]Running 10000 simulations.:  74%|███████▍  | 7425/10000 [00:31<00:10, 244.81it/s]Running 10000 simulations.:  75%|███████▍  | 7452/10000 [00:31<00:10, 251.44it/s]Running 10000 simulations.:  75%|███████▍  | 7479/10000 [00:31<00:09, 256.68it/s]Running 10000 simulations.:  75%|███████▌  | 7506/10000 [00:31<00:09, 260.44it/s]Running 10000 simulations.:  75%|███████▌  | 7534/10000 [00:31<00:09, 263.58it/s]Running 10000 simulations.:  76%|███████▌  | 7561/10000 [00:31<00:09, 260.23it/s]Running 10000 simulations.:  76%|███████▌  | 7588/10000 [00:31<00:09, 261.16it/s]Running 10000 simulations.:  76%|███████▌  | 7615/10000 [00:31<00:09, 257.63it/s]Running 10000 simulations.:  76%|███████▋  | 7641/10000 [00:31<00:09, 251.00it/s]Running 10000 simulations.:  77%|███████▋  | 7667/10000 [00:32<00:09, 247.02it/s]Running 10000 simulations.:  77%|███████▋  | 7692/10000 [00:32<00:09, 244.23it/s]Running 10000 simulations.:  77%|███████▋  | 7717/10000 [00:32<00:09, 242.74it/s]Running 10000 simulations.:  77%|███████▋  | 7742/10000 [00:32<00:09, 242.09it/s]Running 10000 simulations.:  78%|███████▊  | 7767/10000 [00:32<00:09, 241.97it/s]Running 10000 simulations.:  78%|███████▊  | 7792/10000 [00:32<00:09, 241.06it/s]Running 10000 simulations.:  78%|███████▊  | 7817/10000 [00:32<00:09, 240.59it/s]Running 10000 simulations.:  78%|███████▊  | 7842/10000 [00:32<00:08, 240.84it/s]Running 10000 simulations.:  79%|███████▊  | 7867/10000 [00:32<00:08, 241.31it/s]Running 10000 simulations.:  79%|███████▉  | 7892/10000 [00:33<00:08, 241.42it/s]Running 10000 simulations.:  79%|███████▉  | 7917/10000 [00:33<00:08, 241.45it/s]Running 10000 simulations.:  79%|███████▉  | 7942/10000 [00:33<00:08, 237.01it/s]Running 10000 simulations.:  80%|███████▉  | 7966/10000 [00:33<00:08, 230.88it/s]Running 10000 simulations.:  80%|███████▉  | 7990/10000 [00:33<00:08, 226.86it/s]Running 10000 simulations.:  80%|████████  | 8013/10000 [00:33<00:08, 222.26it/s]Running 10000 simulations.:  80%|████████  | 8036/10000 [00:33<00:08, 221.36it/s]Running 10000 simulations.:  81%|████████  | 8059/10000 [00:33<00:08, 221.03it/s]Running 10000 simulations.:  81%|████████  | 8082/10000 [00:33<00:08, 220.59it/s]Running 10000 simulations.:  81%|████████  | 8105/10000 [00:34<00:08, 220.16it/s]Running 10000 simulations.:  81%|████████▏ | 8128/10000 [00:34<00:08, 219.74it/s]Running 10000 simulations.:  82%|████████▏ | 8150/10000 [00:34<00:08, 218.64it/s]Running 10000 simulations.:  82%|████████▏ | 8172/10000 [00:34<00:08, 218.91it/s]Running 10000 simulations.:  82%|████████▏ | 8194/10000 [00:34<00:08, 218.84it/s]Running 10000 simulations.:  82%|████████▏ | 8216/10000 [00:34<00:08, 218.39it/s]Running 10000 simulations.:  82%|████████▏ | 8238/10000 [00:34<00:08, 218.56it/s]Running 10000 simulations.:  83%|████████▎ | 8260/10000 [00:34<00:07, 218.17it/s]Running 10000 simulations.:  83%|████████▎ | 8282/10000 [00:34<00:07, 218.02it/s]Running 10000 simulations.:  83%|████████▎ | 8304/10000 [00:34<00:07, 218.12it/s]Running 10000 simulations.:  83%|████████▎ | 8326/10000 [00:35<00:07, 217.47it/s]Running 10000 simulations.:  83%|████████▎ | 8348/10000 [00:35<00:07, 218.10it/s]Running 10000 simulations.:  84%|████████▎ | 8370/10000 [00:35<00:07, 218.29it/s]Running 10000 simulations.:  84%|████████▍ | 8393/10000 [00:35<00:07, 220.48it/s]Running 10000 simulations.:  84%|████████▍ | 8416/10000 [00:35<00:07, 217.91it/s]Running 10000 simulations.:  84%|████████▍ | 8438/10000 [00:35<00:07, 216.76it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:35<00:07, 215.57it/s]Running 10000 simulations.:  85%|████████▍ | 8482/10000 [00:35<00:07, 214.29it/s]Running 10000 simulations.:  85%|████████▌ | 8504/10000 [00:35<00:07, 213.30it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [00:35<00:06, 213.15it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:36<00:06, 213.38it/s]Running 10000 simulations.:  86%|████████▌ | 8570/10000 [00:36<00:06, 214.03it/s]Running 10000 simulations.:  86%|████████▌ | 8592/10000 [00:36<00:06, 213.95it/s]Running 10000 simulations.:  86%|████████▌ | 8614/10000 [00:36<00:06, 214.27it/s]Running 10000 simulations.:  86%|████████▋ | 8636/10000 [00:36<00:06, 212.86it/s]Running 10000 simulations.:  87%|████████▋ | 8658/10000 [00:36<00:06, 211.98it/s]Running 10000 simulations.:  87%|████████▋ | 8680/10000 [00:36<00:06, 212.32it/s]Running 10000 simulations.:  87%|████████▋ | 8702/10000 [00:36<00:06, 212.40it/s]Running 10000 simulations.:  87%|████████▋ | 8724/10000 [00:36<00:06, 212.50it/s]Running 10000 simulations.:  87%|████████▋ | 8746/10000 [00:36<00:05, 213.13it/s]Running 10000 simulations.:  88%|████████▊ | 8768/10000 [00:37<00:05, 213.33it/s]Running 10000 simulations.:  88%|████████▊ | 8792/10000 [00:37<00:05, 220.38it/s]Running 10000 simulations.:  88%|████████▊ | 8818/10000 [00:37<00:05, 228.96it/s]Running 10000 simulations.:  88%|████████▊ | 8844/10000 [00:37<00:04, 235.23it/s]Running 10000 simulations.:  89%|████████▊ | 8870/10000 [00:37<00:04, 239.97it/s]Running 10000 simulations.:  89%|████████▉ | 8896/10000 [00:37<00:04, 243.48it/s]Running 10000 simulations.:  89%|████████▉ | 8922/10000 [00:37<00:04, 246.33it/s]Running 10000 simulations.:  89%|████████▉ | 8948/10000 [00:37<00:04, 248.28it/s]Running 10000 simulations.:  90%|████████▉ | 8974/10000 [00:37<00:04, 249.23it/s]Running 10000 simulations.:  90%|█████████ | 9000/10000 [00:38<00:03, 250.02it/s]Running 10000 simulations.:  90%|█████████ | 9026/10000 [00:38<00:03, 251.16it/s]Running 10000 simulations.:  91%|█████████ | 9052/10000 [00:38<00:03, 251.77it/s]Running 10000 simulations.:  91%|█████████ | 9078/10000 [00:38<00:03, 251.83it/s]Running 10000 simulations.:  91%|█████████ | 9104/10000 [00:38<00:03, 251.64it/s]Running 10000 simulations.:  91%|█████████▏| 9130/10000 [00:38<00:03, 251.19it/s]Running 10000 simulations.:  92%|█████████▏| 9156/10000 [00:38<00:03, 251.30it/s]Running 10000 simulations.:  92%|█████████▏| 9182/10000 [00:38<00:03, 251.68it/s]Running 10000 simulations.:  92%|█████████▏| 9208/10000 [00:38<00:03, 251.84it/s]Running 10000 simulations.:  92%|█████████▏| 9234/10000 [00:38<00:03, 251.95it/s]Running 10000 simulations.:  93%|█████████▎| 9260/10000 [00:39<00:02, 252.35it/s]Running 10000 simulations.:  93%|█████████▎| 9286/10000 [00:39<00:02, 251.98it/s]Running 10000 simulations.:  93%|█████████▎| 9312/10000 [00:39<00:02, 252.52it/s]Running 10000 simulations.:  93%|█████████▎| 9338/10000 [00:39<00:02, 252.18it/s]Running 10000 simulations.:  94%|█████████▎| 9364/10000 [00:39<00:02, 252.20it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:39<00:02, 252.53it/s]Running 10000 simulations.:  94%|█████████▍| 9416/10000 [00:39<00:02, 252.79it/s]Running 10000 simulations.:  94%|█████████▍| 9442/10000 [00:39<00:02, 252.25it/s]Running 10000 simulations.:  95%|█████████▍| 9468/10000 [00:39<00:02, 252.01it/s]Running 10000 simulations.:  95%|█████████▍| 9494/10000 [00:39<00:02, 252.52it/s]Running 10000 simulations.:  95%|█████████▌| 9520/10000 [00:40<00:01, 252.10it/s]Running 10000 simulations.:  95%|█████████▌| 9546/10000 [00:40<00:01, 252.68it/s]Running 10000 simulations.:  96%|█████████▌| 9572/10000 [00:40<00:01, 253.47it/s]Running 10000 simulations.:  96%|█████████▌| 9598/10000 [00:40<00:01, 253.53it/s]Running 10000 simulations.:  96%|█████████▌| 9624/10000 [00:40<00:01, 253.95it/s]Running 10000 simulations.:  96%|█████████▋| 9650/10000 [00:40<00:01, 253.96it/s]Running 10000 simulations.:  97%|█████████▋| 9676/10000 [00:40<00:01, 253.75it/s]Running 10000 simulations.:  97%|█████████▋| 9702/10000 [00:40<00:01, 251.21it/s]Running 10000 simulations.:  97%|█████████▋| 9728/10000 [00:40<00:01, 247.97it/s]Running 10000 simulations.:  98%|█████████▊| 9754/10000 [00:41<00:00, 249.52it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [00:41<00:00, 251.23it/s]Running 10000 simulations.:  98%|█████████▊| 9806/10000 [00:41<00:00, 252.48it/s]Running 10000 simulations.:  98%|█████████▊| 9832/10000 [00:41<00:00, 253.49it/s]Running 10000 simulations.:  99%|█████████▊| 9858/10000 [00:41<00:00, 253.19it/s]Running 10000 simulations.:  99%|█████████▉| 9884/10000 [00:41<00:00, 253.62it/s]Running 10000 simulations.:  99%|█████████▉| 9910/10000 [00:41<00:00, 253.19it/s]Running 10000 simulations.:  99%|█████████▉| 9936/10000 [00:41<00:00, 253.49it/s]Running 10000 simulations.: 100%|█████████▉| 9962/10000 [00:41<00:00, 254.30it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [00:41<00:00, 254.88it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 238.27it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 270.22it/s]Running 10000 simulations.:   1%|          | 55/10000 [00:00<00:36, 269.42it/s]Running 10000 simulations.:   1%|          | 82/10000 [00:00<00:36, 269.27it/s]Running 10000 simulations.:   1%|          | 110/10000 [00:00<00:36, 269.76it/s]Running 10000 simulations.:   1%|▏         | 137/10000 [00:00<00:36, 269.53it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:00<00:36, 269.83it/s]Running 10000 simulations.:   2%|▏         | 192/10000 [00:00<00:36, 269.82it/s]Running 10000 simulations.:   2%|▏         | 220/10000 [00:00<00:36, 270.17it/s]Running 10000 simulations.:   2%|▏         | 247/10000 [00:00<00:36, 270.08it/s]Running 10000 simulations.:   3%|▎         | 274/10000 [00:01<00:36, 269.68it/s]Running 10000 simulations.:   3%|▎         | 301/10000 [00:01<00:36, 268.90it/s]Running 10000 simulations.:   3%|▎         | 328/10000 [00:01<00:36, 268.25it/s]Running 10000 simulations.:   4%|▎         | 355/10000 [00:01<00:35, 268.45it/s]Running 10000 simulations.:   4%|▍         | 382/10000 [00:01<00:35, 267.94it/s]Running 10000 simulations.:   4%|▍         | 409/10000 [00:01<00:35, 268.00it/s]Running 10000 simulations.:   4%|▍         | 436/10000 [00:01<00:35, 267.44it/s]Running 10000 simulations.:   5%|▍         | 463/10000 [00:01<00:35, 266.91it/s]Running 10000 simulations.:   5%|▍         | 490/10000 [00:01<00:35, 266.95it/s]Running 10000 simulations.:   5%|▌         | 517/10000 [00:01<00:35, 267.09it/s]Running 10000 simulations.:   5%|▌         | 544/10000 [00:02<00:35, 267.05it/s]Running 10000 simulations.:   6%|▌         | 571/10000 [00:02<00:35, 267.11it/s]Running 10000 simulations.:   6%|▌         | 598/10000 [00:02<00:35, 267.37it/s]Running 10000 simulations.:   6%|▋         | 625/10000 [00:02<00:35, 267.27it/s]Running 10000 simulations.:   7%|▋         | 652/10000 [00:02<00:35, 266.17it/s]Running 10000 simulations.:   7%|▋         | 679/10000 [00:02<00:35, 265.88it/s]Running 10000 simulations.:   7%|▋         | 706/10000 [00:02<00:35, 265.45it/s]Running 10000 simulations.:   7%|▋         | 733/10000 [00:02<00:34, 266.42it/s]Running 10000 simulations.:   8%|▊         | 760/10000 [00:02<00:34, 265.94it/s]Running 10000 simulations.:   8%|▊         | 787/10000 [00:02<00:34, 265.08it/s]Running 10000 simulations.:   8%|▊         | 814/10000 [00:03<00:34, 264.93it/s]Running 10000 simulations.:   8%|▊         | 841/10000 [00:03<00:34, 262.31it/s]Running 10000 simulations.:   9%|▊         | 868/10000 [00:03<00:35, 256.44it/s]Running 10000 simulations.:   9%|▉         | 894/10000 [00:03<00:36, 252.76it/s]Running 10000 simulations.:   9%|▉         | 920/10000 [00:03<00:36, 250.25it/s]Running 10000 simulations.:   9%|▉         | 946/10000 [00:03<00:36, 246.71it/s]Running 10000 simulations.:  10%|▉         | 971/10000 [00:03<00:36, 244.91it/s]Running 10000 simulations.:  10%|▉         | 996/10000 [00:03<00:36, 243.38it/s]Running 10000 simulations.:  10%|█         | 1021/10000 [00:03<00:36, 242.84it/s]Running 10000 simulations.:  10%|█         | 1046/10000 [00:03<00:36, 242.97it/s]Running 10000 simulations.:  11%|█         | 1071/10000 [00:04<00:36, 241.97it/s]Running 10000 simulations.:  11%|█         | 1096/10000 [00:04<00:37, 239.50it/s]Running 10000 simulations.:  11%|█         | 1120/10000 [00:04<00:37, 238.78it/s]Running 10000 simulations.:  11%|█▏        | 1145/10000 [00:04<00:36, 239.33it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:04<00:36, 240.59it/s]Running 10000 simulations.:  12%|█▏        | 1195/10000 [00:04<00:36, 241.20it/s]Running 10000 simulations.:  12%|█▏        | 1220/10000 [00:04<00:36, 241.34it/s]Running 10000 simulations.:  12%|█▏        | 1245/10000 [00:04<00:36, 240.57it/s]Running 10000 simulations.:  13%|█▎        | 1270/10000 [00:04<00:36, 239.74it/s]Running 10000 simulations.:  13%|█▎        | 1294/10000 [00:05<00:36, 239.23it/s]Running 10000 simulations.:  13%|█▎        | 1319/10000 [00:05<00:36, 240.05it/s]Running 10000 simulations.:  13%|█▎        | 1344/10000 [00:05<00:36, 239.97it/s]Running 10000 simulations.:  14%|█▎        | 1369/10000 [00:05<00:35, 241.19it/s]Running 10000 simulations.:  14%|█▍        | 1394/10000 [00:05<00:35, 241.20it/s]Running 10000 simulations.:  14%|█▍        | 1419/10000 [00:05<00:35, 239.55it/s]Running 10000 simulations.:  14%|█▍        | 1444/10000 [00:05<00:35, 240.11it/s]Running 10000 simulations.:  15%|█▍        | 1469/10000 [00:05<00:35, 239.88it/s]Running 10000 simulations.:  15%|█▍        | 1494/10000 [00:05<00:35, 240.40it/s]Running 10000 simulations.:  15%|█▌        | 1519/10000 [00:05<00:35, 241.33it/s]Running 10000 simulations.:  15%|█▌        | 1544/10000 [00:06<00:35, 241.40it/s]Running 10000 simulations.:  16%|█▌        | 1569/10000 [00:06<00:35, 240.71it/s]Running 10000 simulations.:  16%|█▌        | 1597/10000 [00:06<00:33, 249.68it/s]Running 10000 simulations.:  16%|█▌        | 1624/10000 [00:06<00:32, 254.55it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:06<00:32, 255.24it/s]Running 10000 simulations.:  17%|█▋        | 1677/10000 [00:06<00:32, 257.48it/s]Running 10000 simulations.:  17%|█▋        | 1703/10000 [00:06<00:34, 241.01it/s]Running 10000 simulations.:  17%|█▋        | 1728/10000 [00:06<00:36, 226.50it/s]Running 10000 simulations.:  18%|█▊        | 1752/10000 [00:06<00:37, 217.93it/s]Running 10000 simulations.:  18%|█▊        | 1775/10000 [00:07<00:39, 208.48it/s]Running 10000 simulations.:  18%|█▊        | 1797/10000 [00:07<00:39, 205.35it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:07<00:40, 203.21it/s]Running 10000 simulations.:  18%|█▊        | 1839/10000 [00:07<00:40, 201.87it/s]Running 10000 simulations.:  19%|█▊        | 1861/10000 [00:07<00:39, 204.88it/s]Running 10000 simulations.:  19%|█▉        | 1883/10000 [00:07<00:39, 206.85it/s]Running 10000 simulations.:  19%|█▉        | 1904/10000 [00:07<00:39, 203.46it/s]Running 10000 simulations.:  19%|█▉        | 1925/10000 [00:07<00:39, 204.17it/s]Running 10000 simulations.:  19%|█▉        | 1946/10000 [00:07<00:39, 204.92it/s]Running 10000 simulations.:  20%|█▉        | 1967/10000 [00:08<00:39, 204.72it/s]Running 10000 simulations.:  20%|█▉        | 1988/10000 [00:08<00:39, 204.55it/s]Running 10000 simulations.:  20%|██        | 2009/10000 [00:08<00:39, 203.71it/s]Running 10000 simulations.:  20%|██        | 2030/10000 [00:08<00:40, 198.39it/s]Running 10000 simulations.:  20%|██        | 2050/10000 [00:08<00:40, 198.32it/s]Running 10000 simulations.:  21%|██        | 2071/10000 [00:08<00:39, 199.90it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:08<00:39, 201.73it/s]Running 10000 simulations.:  21%|██        | 2113/10000 [00:08<00:38, 202.72it/s]Running 10000 simulations.:  21%|██▏       | 2134/10000 [00:08<00:38, 202.71it/s]Running 10000 simulations.:  22%|██▏       | 2161/10000 [00:08<00:36, 217.19it/s]Running 10000 simulations.:  22%|██▏       | 2188/10000 [00:09<00:34, 229.28it/s]Running 10000 simulations.:  22%|██▏       | 2215/10000 [00:09<00:32, 238.33it/s]Running 10000 simulations.:  22%|██▏       | 2240/10000 [00:09<00:32, 240.22it/s]Running 10000 simulations.:  23%|██▎       | 2265/10000 [00:09<00:32, 239.73it/s]Running 10000 simulations.:  23%|██▎       | 2290/10000 [00:09<00:32, 239.25it/s]Running 10000 simulations.:  23%|██▎       | 2315/10000 [00:09<00:32, 238.25it/s]Running 10000 simulations.:  23%|██▎       | 2339/10000 [00:09<00:32, 238.71it/s]Running 10000 simulations.:  24%|██▎       | 2364/10000 [00:09<00:31, 239.53it/s]Running 10000 simulations.:  24%|██▍       | 2389/10000 [00:09<00:31, 239.89it/s]Running 10000 simulations.:  24%|██▍       | 2414/10000 [00:09<00:31, 240.02it/s]Running 10000 simulations.:  24%|██▍       | 2439/10000 [00:10<00:31, 240.23it/s]Running 10000 simulations.:  25%|██▍       | 2464/10000 [00:10<00:31, 238.16it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:10<00:31, 237.89it/s]Running 10000 simulations.:  25%|██▌       | 2512/10000 [00:10<00:31, 238.24it/s]Running 10000 simulations.:  25%|██▌       | 2536/10000 [00:10<00:31, 238.41it/s]Running 10000 simulations.:  26%|██▌       | 2560/10000 [00:10<00:31, 238.85it/s]Running 10000 simulations.:  26%|██▌       | 2584/10000 [00:10<00:31, 238.91it/s]Running 10000 simulations.:  26%|██▌       | 2608/10000 [00:10<00:31, 237.57it/s]Running 10000 simulations.:  26%|██▋       | 2632/10000 [00:10<00:30, 238.27it/s]Running 10000 simulations.:  27%|██▋       | 2657/10000 [00:11<00:30, 239.43it/s]Running 10000 simulations.:  27%|██▋       | 2682/10000 [00:11<00:30, 239.68it/s]Running 10000 simulations.:  27%|██▋       | 2707/10000 [00:11<00:30, 239.87it/s]Running 10000 simulations.:  27%|██▋       | 2732/10000 [00:11<00:30, 240.12it/s]Running 10000 simulations.:  28%|██▊       | 2757/10000 [00:11<00:30, 238.22it/s]Running 10000 simulations.:  28%|██▊       | 2781/10000 [00:11<00:30, 237.98it/s]Running 10000 simulations.:  28%|██▊       | 2805/10000 [00:11<00:30, 237.74it/s]Running 10000 simulations.:  28%|██▊       | 2829/10000 [00:11<00:30, 237.41it/s]Running 10000 simulations.:  29%|██▊       | 2853/10000 [00:11<00:30, 236.96it/s]Running 10000 simulations.:  29%|██▉       | 2877/10000 [00:11<00:30, 236.81it/s]Running 10000 simulations.:  29%|██▉       | 2901/10000 [00:12<00:29, 237.37it/s]Running 10000 simulations.:  29%|██▉       | 2926/10000 [00:12<00:29, 238.38it/s]Running 10000 simulations.:  30%|██▉       | 2951/10000 [00:12<00:29, 240.10it/s]Running 10000 simulations.:  30%|██▉       | 2976/10000 [00:12<00:29, 240.45it/s]Running 10000 simulations.:  30%|███       | 3001/10000 [00:12<00:29, 240.04it/s]Running 10000 simulations.:  30%|███       | 3026/10000 [00:12<00:29, 239.97it/s]Running 10000 simulations.:  30%|███       | 3050/10000 [00:12<00:28, 239.87it/s]Running 10000 simulations.:  31%|███       | 3074/10000 [00:12<00:28, 239.50it/s]Running 10000 simulations.:  31%|███       | 3098/10000 [00:12<00:28, 239.30it/s]Running 10000 simulations.:  31%|███       | 3122/10000 [00:12<00:28, 238.73it/s]Running 10000 simulations.:  31%|███▏      | 3146/10000 [00:13<00:28, 236.35it/s]Running 10000 simulations.:  32%|███▏      | 3170/10000 [00:13<00:28, 236.47it/s]Running 10000 simulations.:  32%|███▏      | 3194/10000 [00:13<00:28, 236.98it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:13<00:28, 237.95it/s]Running 10000 simulations.:  32%|███▏      | 3243/10000 [00:13<00:28, 238.25it/s]Running 10000 simulations.:  33%|███▎      | 3268/10000 [00:13<00:28, 238.87it/s]Running 10000 simulations.:  33%|███▎      | 3292/10000 [00:13<00:28, 237.18it/s]Running 10000 simulations.:  33%|███▎      | 3316/10000 [00:13<00:28, 237.91it/s]Running 10000 simulations.:  33%|███▎      | 3341/10000 [00:13<00:27, 238.84it/s]Running 10000 simulations.:  34%|███▎      | 3365/10000 [00:13<00:27, 238.79it/s]Running 10000 simulations.:  34%|███▍      | 3389/10000 [00:14<00:27, 238.58it/s]Running 10000 simulations.:  34%|███▍      | 3413/10000 [00:14<00:27, 238.74it/s]Running 10000 simulations.:  34%|███▍      | 3437/10000 [00:14<00:27, 237.09it/s]Running 10000 simulations.:  35%|███▍      | 3461/10000 [00:14<00:27, 236.95it/s]Running 10000 simulations.:  35%|███▍      | 3485/10000 [00:14<00:27, 237.33it/s]Running 10000 simulations.:  35%|███▌      | 3509/10000 [00:14<00:27, 238.03it/s]Running 10000 simulations.:  35%|███▌      | 3534/10000 [00:14<00:27, 238.57it/s]Running 10000 simulations.:  36%|███▌      | 3558/10000 [00:14<00:26, 238.64it/s]Running 10000 simulations.:  36%|███▌      | 3583/10000 [00:14<00:26, 238.98it/s]Running 10000 simulations.:  36%|███▌      | 3607/10000 [00:14<00:26, 239.16it/s]Running 10000 simulations.:  36%|███▋      | 3631/10000 [00:15<00:26, 239.17it/s]Running 10000 simulations.:  37%|███▋      | 3655/10000 [00:15<00:26, 238.62it/s]Running 10000 simulations.:  37%|███▋      | 3679/10000 [00:15<00:26, 237.77it/s]Running 10000 simulations.:  37%|███▋      | 3703/10000 [00:15<00:26, 237.40it/s]Running 10000 simulations.:  37%|███▋      | 3727/10000 [00:15<00:27, 231.91it/s]Running 10000 simulations.:  38%|███▊      | 3751/10000 [00:15<00:27, 228.67it/s]Running 10000 simulations.:  38%|███▊      | 3774/10000 [00:15<00:27, 227.69it/s]Running 10000 simulations.:  38%|███▊      | 3797/10000 [00:15<00:27, 227.11it/s]Running 10000 simulations.:  38%|███▊      | 3820/10000 [00:15<00:27, 226.84it/s]Running 10000 simulations.:  38%|███▊      | 3843/10000 [00:16<00:27, 226.46it/s]Running 10000 simulations.:  39%|███▊      | 3866/10000 [00:16<00:27, 224.18it/s]Running 10000 simulations.:  39%|███▉      | 3889/10000 [00:16<00:27, 223.62it/s]Running 10000 simulations.:  39%|███▉      | 3912/10000 [00:16<00:27, 224.32it/s]Running 10000 simulations.:  39%|███▉      | 3935/10000 [00:16<00:26, 224.86it/s]Running 10000 simulations.:  40%|███▉      | 3958/10000 [00:16<00:26, 224.53it/s]Running 10000 simulations.:  40%|███▉      | 3981/10000 [00:16<00:26, 224.80it/s]Running 10000 simulations.:  40%|████      | 4004/10000 [00:16<00:26, 222.20it/s]Running 10000 simulations.:  40%|████      | 4027/10000 [00:16<00:26, 222.29it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:16<00:26, 222.75it/s]Running 10000 simulations.:  41%|████      | 4073/10000 [00:17<00:26, 223.20it/s]Running 10000 simulations.:  41%|████      | 4096/10000 [00:17<00:26, 223.94it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:17<00:26, 224.60it/s]Running 10000 simulations.:  41%|████▏     | 4142/10000 [00:17<00:26, 225.03it/s]Running 10000 simulations.:  42%|████▏     | 4165/10000 [00:17<00:25, 225.52it/s]Running 10000 simulations.:  42%|████▏     | 4188/10000 [00:17<00:25, 226.32it/s]Running 10000 simulations.:  42%|████▏     | 4211/10000 [00:17<00:25, 226.58it/s]Running 10000 simulations.:  42%|████▏     | 4234/10000 [00:17<00:25, 224.65it/s]Running 10000 simulations.:  43%|████▎     | 4257/10000 [00:17<00:25, 225.43it/s]Running 10000 simulations.:  43%|████▎     | 4280/10000 [00:17<00:25, 225.53it/s]Running 10000 simulations.:  43%|████▎     | 4303/10000 [00:18<00:25, 225.13it/s]Running 10000 simulations.:  43%|████▎     | 4326/10000 [00:18<00:25, 225.21it/s]Running 10000 simulations.:  43%|████▎     | 4349/10000 [00:18<00:25, 223.57it/s]Running 10000 simulations.:  44%|████▎     | 4372/10000 [00:18<00:25, 222.17it/s]Running 10000 simulations.:  44%|████▍     | 4395/10000 [00:18<00:25, 223.62it/s]Running 10000 simulations.:  44%|████▍     | 4418/10000 [00:18<00:24, 224.12it/s]Running 10000 simulations.:  44%|████▍     | 4441/10000 [00:18<00:24, 224.81it/s]Running 10000 simulations.:  45%|████▍     | 4464/10000 [00:18<00:24, 226.04it/s]Running 10000 simulations.:  45%|████▍     | 4487/10000 [00:18<00:24, 224.69it/s]Running 10000 simulations.:  45%|████▌     | 4510/10000 [00:18<00:24, 224.93it/s]Running 10000 simulations.:  45%|████▌     | 4533/10000 [00:19<00:24, 224.28it/s]Running 10000 simulations.:  46%|████▌     | 4556/10000 [00:19<00:24, 224.27it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:19<00:24, 225.31it/s]Running 10000 simulations.:  46%|████▌     | 4602/10000 [00:19<00:23, 225.59it/s]Running 10000 simulations.:  46%|████▋     | 4625/10000 [00:19<00:24, 223.67it/s]Running 10000 simulations.:  46%|████▋     | 4648/10000 [00:19<00:24, 219.28it/s]Running 10000 simulations.:  47%|████▋     | 4670/10000 [00:19<00:24, 218.95it/s]Running 10000 simulations.:  47%|████▋     | 4693/10000 [00:19<00:24, 220.78it/s]Running 10000 simulations.:  47%|████▋     | 4716/10000 [00:19<00:23, 222.39it/s]Running 10000 simulations.:  47%|████▋     | 4739/10000 [00:20<00:23, 223.55it/s]Running 10000 simulations.:  48%|████▊     | 4762/10000 [00:20<00:23, 223.98it/s]Running 10000 simulations.:  48%|████▊     | 4785/10000 [00:20<00:23, 222.74it/s]Running 10000 simulations.:  48%|████▊     | 4808/10000 [00:20<00:23, 224.03it/s]Running 10000 simulations.:  48%|████▊     | 4831/10000 [00:20<00:22, 225.53it/s]Running 10000 simulations.:  49%|████▊     | 4854/10000 [00:20<00:22, 225.19it/s]Running 10000 simulations.:  49%|████▉     | 4877/10000 [00:20<00:22, 225.62it/s]Running 10000 simulations.:  49%|████▉     | 4900/10000 [00:20<00:22, 225.00it/s]Running 10000 simulations.:  49%|████▉     | 4923/10000 [00:20<00:22, 222.07it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:20<00:22, 224.27it/s]Running 10000 simulations.:  50%|████▉     | 4970/10000 [00:21<00:22, 226.20it/s]Running 10000 simulations.:  50%|████▉     | 4993/10000 [00:21<00:22, 227.23it/s]Running 10000 simulations.:  50%|█████     | 5017/10000 [00:21<00:21, 229.22it/s]Running 10000 simulations.:  50%|█████     | 5041/10000 [00:21<00:21, 230.16it/s]Running 10000 simulations.:  51%|█████     | 5065/10000 [00:21<00:21, 230.72it/s]Running 10000 simulations.:  51%|█████     | 5089/10000 [00:21<00:21, 230.67it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:21<00:21, 231.83it/s]Running 10000 simulations.:  51%|█████▏    | 5137/10000 [00:21<00:21, 231.17it/s]Running 10000 simulations.:  52%|█████▏    | 5161/10000 [00:21<00:21, 229.16it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:21<00:21, 228.07it/s]Running 10000 simulations.:  52%|█████▏    | 5207/10000 [00:22<00:21, 225.59it/s]Running 10000 simulations.:  52%|█████▏    | 5230/10000 [00:22<00:21, 225.47it/s]Running 10000 simulations.:  53%|█████▎    | 5253/10000 [00:22<00:21, 224.90it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:22<00:21, 217.33it/s]Running 10000 simulations.:  53%|█████▎    | 5299/10000 [00:22<00:21, 218.98it/s]Running 10000 simulations.:  53%|█████▎    | 5322/10000 [00:22<00:21, 220.21it/s]Running 10000 simulations.:  53%|█████▎    | 5345/10000 [00:22<00:20, 222.29it/s]Running 10000 simulations.:  54%|█████▎    | 5368/10000 [00:22<00:20, 222.73it/s]Running 10000 simulations.:  54%|█████▍    | 5391/10000 [00:22<00:20, 222.63it/s]Running 10000 simulations.:  54%|█████▍    | 5414/10000 [00:23<00:20, 222.94it/s]Running 10000 simulations.:  54%|█████▍    | 5437/10000 [00:23<00:20, 220.60it/s]Running 10000 simulations.:  55%|█████▍    | 5460/10000 [00:23<00:21, 213.42it/s]Running 10000 simulations.:  55%|█████▍    | 5482/10000 [00:23<00:21, 210.16it/s]Running 10000 simulations.:  55%|█████▌    | 5506/10000 [00:23<00:20, 217.13it/s]Running 10000 simulations.:  55%|█████▌    | 5530/10000 [00:23<00:20, 222.90it/s]Running 10000 simulations.:  56%|█████▌    | 5554/10000 [00:23<00:19, 226.48it/s]Running 10000 simulations.:  56%|█████▌    | 5578/10000 [00:23<00:19, 230.35it/s]Running 10000 simulations.:  56%|█████▌    | 5602/10000 [00:23<00:18, 233.05it/s]Running 10000 simulations.:  56%|█████▋    | 5627/10000 [00:23<00:18, 235.35it/s]Running 10000 simulations.:  57%|█████▋    | 5652/10000 [00:24<00:18, 236.73it/s]Running 10000 simulations.:  57%|█████▋    | 5676/10000 [00:24<00:18, 237.26it/s]Running 10000 simulations.:  57%|█████▋    | 5700/10000 [00:24<00:18, 237.75it/s]Running 10000 simulations.:  57%|█████▋    | 5724/10000 [00:24<00:17, 237.56it/s]Running 10000 simulations.:  57%|█████▋    | 5748/10000 [00:24<00:17, 238.07it/s]Running 10000 simulations.:  58%|█████▊    | 5772/10000 [00:24<00:17, 238.13it/s]Running 10000 simulations.:  58%|█████▊    | 5797/10000 [00:24<00:17, 239.36it/s]Running 10000 simulations.:  58%|█████▊    | 5822/10000 [00:24<00:17, 239.91it/s]Running 10000 simulations.:  58%|█████▊    | 5846/10000 [00:24<00:17, 239.71it/s]Running 10000 simulations.:  59%|█████▊    | 5871/10000 [00:24<00:17, 240.45it/s]Running 10000 simulations.:  59%|█████▉    | 5896/10000 [00:25<00:17, 240.18it/s]Running 10000 simulations.:  59%|█████▉    | 5921/10000 [00:25<00:16, 240.04it/s]Running 10000 simulations.:  59%|█████▉    | 5946/10000 [00:25<00:16, 239.85it/s]Running 10000 simulations.:  60%|█████▉    | 5970/10000 [00:25<00:16, 239.34it/s]Running 10000 simulations.:  60%|█████▉    | 5994/10000 [00:25<00:16, 238.68it/s]Running 10000 simulations.:  60%|██████    | 6018/10000 [00:25<00:16, 238.50it/s]Running 10000 simulations.:  60%|██████    | 6042/10000 [00:25<00:16, 238.61it/s]Running 10000 simulations.:  61%|██████    | 6067/10000 [00:25<00:16, 239.53it/s]Running 10000 simulations.:  61%|██████    | 6091/10000 [00:25<00:16, 239.20it/s]Running 10000 simulations.:  61%|██████    | 6115/10000 [00:25<00:16, 239.04it/s]Running 10000 simulations.:  61%|██████▏   | 6140/10000 [00:26<00:16, 240.07it/s]Running 10000 simulations.:  62%|██████▏   | 6165/10000 [00:26<00:15, 239.97it/s]Running 10000 simulations.:  62%|██████▏   | 6189/10000 [00:26<00:15, 239.86it/s]Running 10000 simulations.:  62%|██████▏   | 6214/10000 [00:26<00:15, 240.39it/s]Running 10000 simulations.:  62%|██████▏   | 6239/10000 [00:26<00:15, 241.29it/s]Running 10000 simulations.:  63%|██████▎   | 6264/10000 [00:26<00:15, 241.57it/s]Running 10000 simulations.:  63%|██████▎   | 6289/10000 [00:26<00:15, 240.61it/s]Running 10000 simulations.:  63%|██████▎   | 6314/10000 [00:26<00:15, 239.69it/s]Running 10000 simulations.:  63%|██████▎   | 6338/10000 [00:26<00:15, 239.12it/s]Running 10000 simulations.:  64%|██████▎   | 6362/10000 [00:27<00:15, 238.42it/s]Running 10000 simulations.:  64%|██████▍   | 6386/10000 [00:27<00:15, 237.38it/s]Running 10000 simulations.:  64%|██████▍   | 6410/10000 [00:27<00:15, 236.70it/s]Running 10000 simulations.:  64%|██████▍   | 6434/10000 [00:27<00:15, 237.50it/s]Running 10000 simulations.:  65%|██████▍   | 6458/10000 [00:27<00:14, 237.93it/s]Running 10000 simulations.:  65%|██████▍   | 6483/10000 [00:27<00:14, 238.58it/s]Running 10000 simulations.:  65%|██████▌   | 6507/10000 [00:27<00:14, 238.82it/s]Running 10000 simulations.:  65%|██████▌   | 6532/10000 [00:27<00:14, 239.32it/s]Running 10000 simulations.:  66%|██████▌   | 6557/10000 [00:27<00:14, 240.16it/s]Running 10000 simulations.:  66%|██████▌   | 6582/10000 [00:27<00:14, 239.82it/s]Running 10000 simulations.:  66%|██████▌   | 6606/10000 [00:28<00:14, 239.17it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:28<00:14, 238.45it/s]Running 10000 simulations.:  67%|██████▋   | 6654/10000 [00:28<00:14, 238.32it/s]Running 10000 simulations.:  67%|██████▋   | 6678/10000 [00:28<00:13, 237.97it/s]Running 10000 simulations.:  67%|██████▋   | 6702/10000 [00:28<00:13, 237.24it/s]Running 10000 simulations.:  67%|██████▋   | 6726/10000 [00:28<00:13, 237.30it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:28<00:13, 237.72it/s]Running 10000 simulations.:  68%|██████▊   | 6774/10000 [00:28<00:13, 238.26it/s]Running 10000 simulations.:  68%|██████▊   | 6799/10000 [00:28<00:13, 239.11it/s]Running 10000 simulations.:  68%|██████▊   | 6824/10000 [00:28<00:13, 239.78it/s]Running 10000 simulations.:  68%|██████▊   | 6848/10000 [00:29<00:13, 228.76it/s]Running 10000 simulations.:  69%|██████▊   | 6871/10000 [00:29<00:14, 219.25it/s]Running 10000 simulations.:  69%|██████▉   | 6894/10000 [00:29<00:14, 212.44it/s]Running 10000 simulations.:  69%|██████▉   | 6916/10000 [00:29<00:14, 214.56it/s]Running 10000 simulations.:  69%|██████▉   | 6939/10000 [00:29<00:14, 218.58it/s]Running 10000 simulations.:  70%|██████▉   | 6962/10000 [00:29<00:13, 221.71it/s]Running 10000 simulations.:  70%|██████▉   | 6985/10000 [00:29<00:13, 223.55it/s]Running 10000 simulations.:  70%|███████   | 7009/10000 [00:29<00:13, 225.68it/s]Running 10000 simulations.:  70%|███████   | 7032/10000 [00:29<00:13, 226.60it/s]Running 10000 simulations.:  71%|███████   | 7055/10000 [00:30<00:12, 227.09it/s]Running 10000 simulations.:  71%|███████   | 7078/10000 [00:30<00:12, 227.94it/s]Running 10000 simulations.:  71%|███████   | 7101/10000 [00:30<00:12, 228.01it/s]Running 10000 simulations.:  71%|███████   | 7124/10000 [00:30<00:12, 228.04it/s]Running 10000 simulations.:  71%|███████▏  | 7147/10000 [00:30<00:12, 227.68it/s]Running 10000 simulations.:  72%|███████▏  | 7170/10000 [00:30<00:12, 227.88it/s]Running 10000 simulations.:  72%|███████▏  | 7193/10000 [00:30<00:12, 226.15it/s]Running 10000 simulations.:  72%|███████▏  | 7216/10000 [00:30<00:12, 225.73it/s]Running 10000 simulations.:  72%|███████▏  | 7239/10000 [00:30<00:12, 226.22it/s]Running 10000 simulations.:  73%|███████▎  | 7262/10000 [00:30<00:12, 225.51it/s]Running 10000 simulations.:  73%|███████▎  | 7285/10000 [00:31<00:12, 226.21it/s]Running 10000 simulations.:  73%|███████▎  | 7308/10000 [00:31<00:11, 224.53it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:31<00:12, 218.29it/s]Running 10000 simulations.:  74%|███████▎  | 7353/10000 [00:31<00:12, 213.95it/s]Running 10000 simulations.:  74%|███████▍  | 7375/10000 [00:31<00:12, 211.01it/s]Running 10000 simulations.:  74%|███████▍  | 7397/10000 [00:31<00:12, 207.32it/s]Running 10000 simulations.:  74%|███████▍  | 7418/10000 [00:31<00:12, 204.88it/s]Running 10000 simulations.:  74%|███████▍  | 7439/10000 [00:31<00:12, 206.36it/s]Running 10000 simulations.:  75%|███████▍  | 7461/10000 [00:31<00:12, 207.84it/s]Running 10000 simulations.:  75%|███████▍  | 7482/10000 [00:31<00:12, 208.40it/s]Running 10000 simulations.:  75%|███████▌  | 7503/10000 [00:32<00:11, 208.45it/s]Running 10000 simulations.:  75%|███████▌  | 7525/10000 [00:32<00:11, 208.96it/s]Running 10000 simulations.:  75%|███████▌  | 7547/10000 [00:32<00:11, 209.87it/s]Running 10000 simulations.:  76%|███████▌  | 7569/10000 [00:32<00:11, 209.98it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:32<00:11, 210.59it/s]Running 10000 simulations.:  76%|███████▌  | 7613/10000 [00:32<00:11, 211.75it/s]Running 10000 simulations.:  76%|███████▋  | 7635/10000 [00:32<00:11, 212.28it/s]Running 10000 simulations.:  77%|███████▋  | 7657/10000 [00:32<00:11, 212.58it/s]Running 10000 simulations.:  77%|███████▋  | 7679/10000 [00:32<00:10, 212.75it/s]Running 10000 simulations.:  77%|███████▋  | 7701/10000 [00:33<00:10, 212.83it/s]Running 10000 simulations.:  77%|███████▋  | 7723/10000 [00:33<00:10, 212.96it/s]Running 10000 simulations.:  77%|███████▋  | 7745/10000 [00:33<00:10, 211.41it/s]Running 10000 simulations.:  78%|███████▊  | 7767/10000 [00:33<00:10, 208.43it/s]Running 10000 simulations.:  78%|███████▊  | 7788/10000 [00:33<00:10, 208.44it/s]Running 10000 simulations.:  78%|███████▊  | 7810/10000 [00:33<00:10, 209.38it/s]Running 10000 simulations.:  78%|███████▊  | 7832/10000 [00:33<00:10, 209.82it/s]Running 10000 simulations.:  79%|███████▊  | 7854/10000 [00:33<00:10, 210.33it/s]Running 10000 simulations.:  79%|███████▉  | 7876/10000 [00:33<00:10, 211.40it/s]Running 10000 simulations.:  79%|███████▉  | 7900/10000 [00:33<00:09, 217.18it/s]Running 10000 simulations.:  79%|███████▉  | 7927/10000 [00:34<00:09, 229.14it/s]Running 10000 simulations.:  80%|███████▉  | 7954/10000 [00:34<00:08, 237.63it/s]Running 10000 simulations.:  80%|███████▉  | 7980/10000 [00:34<00:08, 242.90it/s]Running 10000 simulations.:  80%|████████  | 8007/10000 [00:34<00:08, 248.49it/s]Running 10000 simulations.:  80%|████████  | 8034/10000 [00:34<00:07, 252.30it/s]Running 10000 simulations.:  81%|████████  | 8061/10000 [00:34<00:07, 254.56it/s]Running 10000 simulations.:  81%|████████  | 8087/10000 [00:34<00:07, 254.40it/s]Running 10000 simulations.:  81%|████████  | 8113/10000 [00:34<00:07, 250.81it/s]Running 10000 simulations.:  81%|████████▏ | 8139/10000 [00:34<00:07, 253.08it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:34<00:07, 254.16it/s]Running 10000 simulations.:  82%|████████▏ | 8192/10000 [00:35<00:07, 256.21it/s]Running 10000 simulations.:  82%|████████▏ | 8219/10000 [00:35<00:06, 257.40it/s]Running 10000 simulations.:  82%|████████▏ | 8246/10000 [00:35<00:06, 258.44it/s]Running 10000 simulations.:  83%|████████▎ | 8273/10000 [00:35<00:06, 260.09it/s]Running 10000 simulations.:  83%|████████▎ | 8300/10000 [00:35<00:06, 259.85it/s]Running 10000 simulations.:  83%|████████▎ | 8326/10000 [00:35<00:06, 259.35it/s]Running 10000 simulations.:  84%|████████▎ | 8352/10000 [00:35<00:06, 259.30it/s]Running 10000 simulations.:  84%|████████▍ | 8378/10000 [00:35<00:06, 259.05it/s]Running 10000 simulations.:  84%|████████▍ | 8405/10000 [00:35<00:06, 260.30it/s]Running 10000 simulations.:  84%|████████▍ | 8432/10000 [00:36<00:06, 260.08it/s]Running 10000 simulations.:  85%|████████▍ | 8459/10000 [00:36<00:05, 260.85it/s]Running 10000 simulations.:  85%|████████▍ | 8486/10000 [00:36<00:05, 262.23it/s]Running 10000 simulations.:  85%|████████▌ | 8513/10000 [00:36<00:05, 262.01it/s]Running 10000 simulations.:  85%|████████▌ | 8540/10000 [00:36<00:05, 262.44it/s]Running 10000 simulations.:  86%|████████▌ | 8567/10000 [00:36<00:05, 262.63it/s]Running 10000 simulations.:  86%|████████▌ | 8594/10000 [00:36<00:05, 261.73it/s]Running 10000 simulations.:  86%|████████▌ | 8621/10000 [00:36<00:05, 261.87it/s]Running 10000 simulations.:  86%|████████▋ | 8648/10000 [00:36<00:05, 260.50it/s]Running 10000 simulations.:  87%|████████▋ | 8675/10000 [00:36<00:05, 260.86it/s]Running 10000 simulations.:  87%|████████▋ | 8702/10000 [00:37<00:04, 261.19it/s]Running 10000 simulations.:  87%|████████▋ | 8729/10000 [00:37<00:04, 260.88it/s]Running 10000 simulations.:  88%|████████▊ | 8756/10000 [00:37<00:04, 261.92it/s]Running 10000 simulations.:  88%|████████▊ | 8783/10000 [00:37<00:04, 260.77it/s]Running 10000 simulations.:  88%|████████▊ | 8810/10000 [00:37<00:04, 260.11it/s]Running 10000 simulations.:  88%|████████▊ | 8837/10000 [00:37<00:04, 260.11it/s]Running 10000 simulations.:  89%|████████▊ | 8864/10000 [00:37<00:04, 259.98it/s]Running 10000 simulations.:  89%|████████▉ | 8891/10000 [00:37<00:04, 260.25it/s]Running 10000 simulations.:  89%|████████▉ | 8918/10000 [00:37<00:04, 260.61it/s]Running 10000 simulations.:  89%|████████▉ | 8945/10000 [00:37<00:04, 260.15it/s]Running 10000 simulations.:  90%|████████▉ | 8972/10000 [00:38<00:03, 259.20it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:38<00:03, 255.30it/s]Running 10000 simulations.:  90%|█████████ | 9024/10000 [00:38<00:03, 253.94it/s]Running 10000 simulations.:  90%|█████████ | 9050/10000 [00:38<00:03, 255.46it/s]Running 10000 simulations.:  91%|█████████ | 9076/10000 [00:38<00:03, 256.43it/s]Running 10000 simulations.:  91%|█████████ | 9102/10000 [00:38<00:03, 257.35it/s]Running 10000 simulations.:  91%|█████████▏| 9128/10000 [00:38<00:03, 258.12it/s]Running 10000 simulations.:  92%|█████████▏| 9155/10000 [00:38<00:03, 258.70it/s]Running 10000 simulations.:  92%|█████████▏| 9181/10000 [00:38<00:03, 258.77it/s]Running 10000 simulations.:  92%|█████████▏| 9208/10000 [00:38<00:03, 259.96it/s]Running 10000 simulations.:  92%|█████████▏| 9234/10000 [00:39<00:02, 259.89it/s]Running 10000 simulations.:  93%|█████████▎| 9261/10000 [00:39<00:02, 260.33it/s]Running 10000 simulations.:  93%|█████████▎| 9288/10000 [00:39<00:02, 260.43it/s]Running 10000 simulations.:  93%|█████████▎| 9315/10000 [00:39<00:02, 261.10it/s]Running 10000 simulations.:  93%|█████████▎| 9342/10000 [00:39<00:02, 259.71it/s]Running 10000 simulations.:  94%|█████████▎| 9368/10000 [00:39<00:02, 259.04it/s]Running 10000 simulations.:  94%|█████████▍| 9394/10000 [00:39<00:02, 258.77it/s]Running 10000 simulations.:  94%|█████████▍| 9420/10000 [00:39<00:02, 258.59it/s]Running 10000 simulations.:  94%|█████████▍| 9446/10000 [00:39<00:02, 258.47it/s]Running 10000 simulations.:  95%|█████████▍| 9472/10000 [00:40<00:02, 258.13it/s]Running 10000 simulations.:  95%|█████████▍| 9498/10000 [00:40<00:01, 258.35it/s]Running 10000 simulations.:  95%|█████████▌| 9525/10000 [00:40<00:01, 259.37it/s]Running 10000 simulations.:  96%|█████████▌| 9552/10000 [00:40<00:01, 260.17it/s]Running 10000 simulations.:  96%|█████████▌| 9579/10000 [00:40<00:01, 260.52it/s]Running 10000 simulations.:  96%|█████████▌| 9606/10000 [00:40<00:01, 259.52it/s]Running 10000 simulations.:  96%|█████████▋| 9632/10000 [00:40<00:01, 259.60it/s]Running 10000 simulations.:  97%|█████████▋| 9658/10000 [00:40<00:01, 259.61it/s]Running 10000 simulations.:  97%|█████████▋| 9684/10000 [00:40<00:01, 258.98it/s]Running 10000 simulations.:  97%|█████████▋| 9711/10000 [00:40<00:01, 259.80it/s]Running 10000 simulations.:  97%|█████████▋| 9737/10000 [00:41<00:01, 259.62it/s]Running 10000 simulations.:  98%|█████████▊| 9764/10000 [00:41<00:00, 260.33it/s]Running 10000 simulations.:  98%|█████████▊| 9791/10000 [00:41<00:00, 260.69it/s]Running 10000 simulations.:  98%|█████████▊| 9818/10000 [00:41<00:00, 260.72it/s]Running 10000 simulations.:  98%|█████████▊| 9845/10000 [00:41<00:00, 261.26it/s]Running 10000 simulations.:  99%|█████████▊| 9872/10000 [00:41<00:00, 262.36it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:41<00:00, 262.34it/s]Running 10000 simulations.:  99%|█████████▉| 9926/10000 [00:41<00:00, 262.23it/s]Running 10000 simulations.: 100%|█████████▉| 9953/10000 [00:41<00:00, 262.30it/s]Running 10000 simulations.: 100%|█████████▉| 9980/10000 [00:41<00:00, 261.53it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 237.89it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 24/10000 [00:00<00:42, 232.25it/s]Running 10000 simulations.:   0%|          | 47/10000 [00:00<00:43, 231.07it/s]Running 10000 simulations.:   1%|          | 70/10000 [00:00<00:43, 229.97it/s]Running 10000 simulations.:   1%|          | 93/10000 [00:00<00:43, 228.60it/s]Running 10000 simulations.:   1%|          | 116/10000 [00:00<00:43, 227.83it/s]Running 10000 simulations.:   1%|▏         | 138/10000 [00:00<00:43, 224.61it/s]Running 10000 simulations.:   2%|▏         | 161/10000 [00:00<00:43, 224.77it/s]Running 10000 simulations.:   2%|▏         | 184/10000 [00:00<00:43, 225.27it/s]Running 10000 simulations.:   2%|▏         | 207/10000 [00:00<00:43, 225.42it/s]Running 10000 simulations.:   2%|▏         | 230/10000 [00:01<00:43, 225.06it/s]Running 10000 simulations.:   3%|▎         | 253/10000 [00:01<00:43, 224.85it/s]Running 10000 simulations.:   3%|▎         | 276/10000 [00:01<00:43, 223.86it/s]Running 10000 simulations.:   3%|▎         | 299/10000 [00:01<00:43, 223.61it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:42, 226.47it/s]Running 10000 simulations.:   3%|▎         | 348/10000 [00:01<00:41, 232.91it/s]Running 10000 simulations.:   4%|▎         | 373/10000 [00:01<00:40, 237.63it/s]Running 10000 simulations.:   4%|▍         | 399/10000 [00:01<00:39, 242.27it/s]Running 10000 simulations.:   4%|▍         | 424/10000 [00:01<00:39, 243.53it/s]Running 10000 simulations.:   4%|▍         | 449/10000 [00:01<00:39, 244.73it/s]Running 10000 simulations.:   5%|▍         | 474/10000 [00:02<00:38, 245.93it/s]Running 10000 simulations.:   5%|▍         | 499/10000 [00:02<00:38, 247.12it/s]Running 10000 simulations.:   5%|▌         | 524/10000 [00:02<00:38, 247.14it/s]Running 10000 simulations.:   5%|▌         | 549/10000 [00:02<00:38, 246.77it/s]Running 10000 simulations.:   6%|▌         | 574/10000 [00:02<00:38, 247.06it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:02<00:37, 248.03it/s]Running 10000 simulations.:   6%|▋         | 625/10000 [00:02<00:37, 247.26it/s]Running 10000 simulations.:   6%|▋         | 650/10000 [00:02<00:37, 246.38it/s]Running 10000 simulations.:   7%|▋         | 675/10000 [00:02<00:37, 246.10it/s]Running 10000 simulations.:   7%|▋         | 700/10000 [00:02<00:37, 245.78it/s]Running 10000 simulations.:   7%|▋         | 725/10000 [00:03<00:37, 245.59it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:03<00:37, 245.08it/s]Running 10000 simulations.:   8%|▊         | 775/10000 [00:03<00:37, 245.10it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:03<00:37, 244.95it/s]Running 10000 simulations.:   8%|▊         | 825/10000 [00:03<00:37, 245.25it/s]Running 10000 simulations.:   8%|▊         | 850/10000 [00:03<00:37, 245.26it/s]Running 10000 simulations.:   9%|▉         | 875/10000 [00:03<00:37, 244.68it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:37, 244.33it/s]Running 10000 simulations.:   9%|▉         | 925/10000 [00:03<00:37, 243.98it/s]Running 10000 simulations.:  10%|▉         | 950/10000 [00:03<00:37, 243.61it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:04<00:36, 243.98it/s]Running 10000 simulations.:  10%|█         | 1000/10000 [00:04<00:36, 245.11it/s]Running 10000 simulations.:  10%|█         | 1025/10000 [00:04<00:36, 244.71it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:04<00:36, 242.66it/s]Running 10000 simulations.:  11%|█         | 1075/10000 [00:04<00:36, 243.96it/s]Running 10000 simulations.:  11%|█         | 1101/10000 [00:04<00:36, 245.88it/s]Running 10000 simulations.:  11%|█▏        | 1126/10000 [00:04<00:35, 246.87it/s]Running 10000 simulations.:  12%|█▏        | 1151/10000 [00:04<00:35, 247.35it/s]Running 10000 simulations.:  12%|█▏        | 1176/10000 [00:04<00:35, 247.71it/s]Running 10000 simulations.:  12%|█▏        | 1201/10000 [00:04<00:35, 247.74it/s]Running 10000 simulations.:  12%|█▏        | 1226/10000 [00:05<00:35, 246.07it/s]Running 10000 simulations.:  13%|█▎        | 1251/10000 [00:05<00:35, 245.54it/s]Running 10000 simulations.:  13%|█▎        | 1276/10000 [00:05<00:35, 245.10it/s]Running 10000 simulations.:  13%|█▎        | 1301/10000 [00:05<00:35, 244.78it/s]Running 10000 simulations.:  13%|█▎        | 1326/10000 [00:05<00:35, 244.44it/s]Running 10000 simulations.:  14%|█▎        | 1351/10000 [00:05<00:35, 245.17it/s]Running 10000 simulations.:  14%|█▍        | 1376/10000 [00:05<00:35, 246.18it/s]Running 10000 simulations.:  14%|█▍        | 1401/10000 [00:05<00:34, 246.60it/s]Running 10000 simulations.:  14%|█▍        | 1426/10000 [00:05<00:34, 245.77it/s]Running 10000 simulations.:  15%|█▍        | 1451/10000 [00:06<00:34, 245.03it/s]Running 10000 simulations.:  15%|█▍        | 1476/10000 [00:06<00:34, 244.50it/s]Running 10000 simulations.:  15%|█▌        | 1501/10000 [00:06<00:34, 244.37it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:06<00:34, 244.84it/s]Running 10000 simulations.:  16%|█▌        | 1551/10000 [00:06<00:34, 245.45it/s]Running 10000 simulations.:  16%|█▌        | 1576/10000 [00:06<00:34, 246.21it/s]Running 10000 simulations.:  16%|█▌        | 1601/10000 [00:06<00:34, 246.48it/s]Running 10000 simulations.:  16%|█▋        | 1626/10000 [00:06<00:34, 246.02it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:06<00:33, 245.66it/s]Running 10000 simulations.:  17%|█▋        | 1676/10000 [00:06<00:34, 244.43it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:07<00:34, 243.68it/s]Running 10000 simulations.:  17%|█▋        | 1726/10000 [00:07<00:34, 243.19it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:07<00:33, 242.74it/s]Running 10000 simulations.:  18%|█▊        | 1776/10000 [00:07<00:33, 242.47it/s]Running 10000 simulations.:  18%|█▊        | 1801/10000 [00:07<00:33, 243.42it/s]Running 10000 simulations.:  18%|█▊        | 1826/10000 [00:07<00:33, 244.52it/s]Running 10000 simulations.:  19%|█▊        | 1851/10000 [00:07<00:33, 245.42it/s]Running 10000 simulations.:  19%|█▉        | 1876/10000 [00:07<00:32, 246.26it/s]Running 10000 simulations.:  19%|█▉        | 1901/10000 [00:07<00:32, 246.27it/s]Running 10000 simulations.:  19%|█▉        | 1926/10000 [00:07<00:32, 246.40it/s]Running 10000 simulations.:  20%|█▉        | 1951/10000 [00:08<00:32, 245.94it/s]Running 10000 simulations.:  20%|█▉        | 1976/10000 [00:08<00:32, 246.18it/s]Running 10000 simulations.:  20%|██        | 2001/10000 [00:08<00:32, 246.42it/s]Running 10000 simulations.:  20%|██        | 2026/10000 [00:08<00:32, 245.77it/s]Running 10000 simulations.:  21%|██        | 2051/10000 [00:08<00:32, 245.43it/s]Running 10000 simulations.:  21%|██        | 2076/10000 [00:08<00:32, 244.84it/s]Running 10000 simulations.:  21%|██        | 2101/10000 [00:08<00:32, 245.72it/s]Running 10000 simulations.:  21%|██▏       | 2126/10000 [00:08<00:31, 246.60it/s]Running 10000 simulations.:  22%|██▏       | 2151/10000 [00:08<00:31, 246.24it/s]Running 10000 simulations.:  22%|██▏       | 2176/10000 [00:08<00:31, 245.62it/s]Running 10000 simulations.:  22%|██▏       | 2201/10000 [00:09<00:31, 244.81it/s]Running 10000 simulations.:  22%|██▏       | 2226/10000 [00:09<00:31, 245.09it/s]Running 10000 simulations.:  23%|██▎       | 2252/10000 [00:09<00:31, 248.62it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:09<00:30, 255.00it/s]Running 10000 simulations.:  23%|██▎       | 2306/10000 [00:09<00:30, 254.86it/s]Running 10000 simulations.:  23%|██▎       | 2332/10000 [00:09<00:30, 253.60it/s]Running 10000 simulations.:  24%|██▎       | 2360/10000 [00:09<00:29, 259.33it/s]Running 10000 simulations.:  24%|██▍       | 2388/10000 [00:09<00:28, 265.00it/s]Running 10000 simulations.:  24%|██▍       | 2416/10000 [00:09<00:28, 269.26it/s]Running 10000 simulations.:  24%|██▍       | 2444/10000 [00:09<00:27, 272.12it/s]Running 10000 simulations.:  25%|██▍       | 2472/10000 [00:10<00:28, 267.39it/s]Running 10000 simulations.:  25%|██▍       | 2499/10000 [00:10<00:28, 267.75it/s]Running 10000 simulations.:  25%|██▌       | 2526/10000 [00:10<00:28, 260.76it/s]Running 10000 simulations.:  26%|██▌       | 2553/10000 [00:10<00:29, 254.67it/s]Running 10000 simulations.:  26%|██▌       | 2579/10000 [00:10<00:29, 250.46it/s]Running 10000 simulations.:  26%|██▌       | 2605/10000 [00:10<00:29, 248.55it/s]Running 10000 simulations.:  26%|██▋       | 2630/10000 [00:10<00:29, 246.99it/s]Running 10000 simulations.:  27%|██▋       | 2655/10000 [00:10<00:29, 247.26it/s]Running 10000 simulations.:  27%|██▋       | 2680/10000 [00:10<00:29, 247.44it/s]Running 10000 simulations.:  27%|██▋       | 2705/10000 [00:11<00:29, 247.33it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:11<00:29, 246.29it/s]Running 10000 simulations.:  28%|██▊       | 2755/10000 [00:11<00:29, 245.54it/s]Running 10000 simulations.:  28%|██▊       | 2780/10000 [00:11<00:29, 244.41it/s]Running 10000 simulations.:  28%|██▊       | 2805/10000 [00:11<00:29, 244.69it/s]Running 10000 simulations.:  28%|██▊       | 2830/10000 [00:11<00:29, 239.59it/s]Running 10000 simulations.:  29%|██▊       | 2854/10000 [00:11<00:30, 232.96it/s]Running 10000 simulations.:  29%|██▉       | 2878/10000 [00:11<00:31, 227.15it/s]Running 10000 simulations.:  29%|██▉       | 2901/10000 [00:11<00:31, 223.95it/s]Running 10000 simulations.:  29%|██▉       | 2924/10000 [00:11<00:31, 223.41it/s]Running 10000 simulations.:  29%|██▉       | 2947/10000 [00:12<00:31, 223.65it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:12<00:31, 223.77it/s]Running 10000 simulations.:  30%|██▉       | 2993/10000 [00:12<00:31, 223.19it/s]Running 10000 simulations.:  30%|███       | 3016/10000 [00:12<00:31, 222.77it/s]Running 10000 simulations.:  30%|███       | 3039/10000 [00:12<00:31, 222.47it/s]Running 10000 simulations.:  31%|███       | 3062/10000 [00:12<00:31, 221.67it/s]Running 10000 simulations.:  31%|███       | 3085/10000 [00:12<00:31, 220.33it/s]Running 10000 simulations.:  31%|███       | 3108/10000 [00:12<00:31, 220.09it/s]Running 10000 simulations.:  31%|███▏      | 3131/10000 [00:12<00:31, 219.88it/s]Running 10000 simulations.:  32%|███▏      | 3154/10000 [00:13<00:31, 220.24it/s]Running 10000 simulations.:  32%|███▏      | 3177/10000 [00:13<00:31, 220.04it/s]Running 10000 simulations.:  32%|███▏      | 3200/10000 [00:13<00:30, 220.06it/s]Running 10000 simulations.:  32%|███▏      | 3223/10000 [00:13<00:30, 220.76it/s]Running 10000 simulations.:  32%|███▏      | 3246/10000 [00:13<00:30, 222.11it/s]Running 10000 simulations.:  33%|███▎      | 3269/10000 [00:13<00:30, 223.06it/s]Running 10000 simulations.:  33%|███▎      | 3292/10000 [00:13<00:29, 223.64it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:13<00:30, 220.64it/s]Running 10000 simulations.:  33%|███▎      | 3338/10000 [00:13<00:30, 218.67it/s]Running 10000 simulations.:  34%|███▎      | 3360/10000 [00:13<00:30, 218.91it/s]Running 10000 simulations.:  34%|███▍      | 3382/10000 [00:14<00:30, 218.25it/s]Running 10000 simulations.:  34%|███▍      | 3404/10000 [00:14<00:30, 217.58it/s]Running 10000 simulations.:  34%|███▍      | 3426/10000 [00:14<00:30, 218.06it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:14<00:30, 217.92it/s]Running 10000 simulations.:  35%|███▍      | 3470/10000 [00:14<00:29, 217.72it/s]Running 10000 simulations.:  35%|███▍      | 3492/10000 [00:14<00:29, 218.35it/s]Running 10000 simulations.:  35%|███▌      | 3515/10000 [00:14<00:29, 218.97it/s]Running 10000 simulations.:  35%|███▌      | 3537/10000 [00:14<00:29, 218.44it/s]Running 10000 simulations.:  36%|███▌      | 3560/10000 [00:14<00:29, 219.21it/s]Running 10000 simulations.:  36%|███▌      | 3583/10000 [00:14<00:28, 221.81it/s]Running 10000 simulations.:  36%|███▌      | 3606/10000 [00:15<00:28, 224.10it/s]Running 10000 simulations.:  36%|███▋      | 3629/10000 [00:15<00:28, 225.76it/s]Running 10000 simulations.:  37%|███▋      | 3652/10000 [00:15<00:28, 226.19it/s]Running 10000 simulations.:  37%|███▋      | 3675/10000 [00:15<00:27, 227.25it/s]Running 10000 simulations.:  37%|███▋      | 3699/10000 [00:15<00:27, 228.24it/s]Running 10000 simulations.:  37%|███▋      | 3723/10000 [00:15<00:27, 228.71it/s]Running 10000 simulations.:  37%|███▋      | 3746/10000 [00:15<00:27, 227.44it/s]Running 10000 simulations.:  38%|███▊      | 3769/10000 [00:15<00:27, 223.90it/s]Running 10000 simulations.:  38%|███▊      | 3794/10000 [00:15<00:26, 230.90it/s]Running 10000 simulations.:  38%|███▊      | 3820/10000 [00:16<00:26, 236.37it/s]Running 10000 simulations.:  38%|███▊      | 3845/10000 [00:16<00:25, 240.15it/s]Running 10000 simulations.:  39%|███▊      | 3871/10000 [00:16<00:25, 243.35it/s]Running 10000 simulations.:  39%|███▉      | 3896/10000 [00:16<00:25, 238.11it/s]Running 10000 simulations.:  39%|███▉      | 3922/10000 [00:16<00:25, 242.06it/s]Running 10000 simulations.:  39%|███▉      | 3948/10000 [00:16<00:24, 244.57it/s]Running 10000 simulations.:  40%|███▉      | 3974/10000 [00:16<00:24, 246.45it/s]Running 10000 simulations.:  40%|████      | 4000/10000 [00:16<00:24, 249.46it/s]Running 10000 simulations.:  40%|████      | 4026/10000 [00:16<00:23, 251.81it/s]Running 10000 simulations.:  41%|████      | 4052/10000 [00:16<00:23, 253.49it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:17<00:23, 254.64it/s]Running 10000 simulations.:  41%|████      | 4104/10000 [00:17<00:23, 253.78it/s]Running 10000 simulations.:  41%|████▏     | 4130/10000 [00:17<00:23, 253.02it/s]Running 10000 simulations.:  42%|████▏     | 4156/10000 [00:17<00:23, 252.83it/s]Running 10000 simulations.:  42%|████▏     | 4182/10000 [00:17<00:23, 252.56it/s]Running 10000 simulations.:  42%|████▏     | 4208/10000 [00:17<00:22, 253.26it/s]Running 10000 simulations.:  42%|████▏     | 4234/10000 [00:17<00:22, 252.74it/s]Running 10000 simulations.:  43%|████▎     | 4260/10000 [00:17<00:23, 247.04it/s]Running 10000 simulations.:  43%|████▎     | 4285/10000 [00:17<00:23, 246.43it/s]Running 10000 simulations.:  43%|████▎     | 4311/10000 [00:17<00:22, 248.61it/s]Running 10000 simulations.:  43%|████▎     | 4337/10000 [00:18<00:22, 250.93it/s]Running 10000 simulations.:  44%|████▎     | 4363/10000 [00:18<00:22, 251.70it/s]Running 10000 simulations.:  44%|████▍     | 4389/10000 [00:18<00:22, 252.80it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:18<00:22, 253.00it/s]Running 10000 simulations.:  44%|████▍     | 4441/10000 [00:18<00:21, 252.93it/s]Running 10000 simulations.:  45%|████▍     | 4467/10000 [00:18<00:21, 252.98it/s]Running 10000 simulations.:  45%|████▍     | 4493/10000 [00:18<00:21, 253.13it/s]Running 10000 simulations.:  45%|████▌     | 4519/10000 [00:18<00:21, 251.07it/s]Running 10000 simulations.:  45%|████▌     | 4545/10000 [00:18<00:21, 251.41it/s]Running 10000 simulations.:  46%|████▌     | 4571/10000 [00:18<00:21, 251.75it/s]Running 10000 simulations.:  46%|████▌     | 4597/10000 [00:19<00:21, 252.29it/s]Running 10000 simulations.:  46%|████▌     | 4623/10000 [00:19<00:21, 252.63it/s]Running 10000 simulations.:  46%|████▋     | 4649/10000 [00:19<00:21, 253.26it/s]Running 10000 simulations.:  47%|████▋     | 4675/10000 [00:19<00:21, 253.41it/s]Running 10000 simulations.:  47%|████▋     | 4701/10000 [00:19<00:20, 254.35it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:19<00:20, 254.30it/s]Running 10000 simulations.:  48%|████▊     | 4753/10000 [00:19<00:20, 253.37it/s]Running 10000 simulations.:  48%|████▊     | 4779/10000 [00:19<00:20, 253.04it/s]Running 10000 simulations.:  48%|████▊     | 4805/10000 [00:19<00:20, 252.56it/s]Running 10000 simulations.:  48%|████▊     | 4831/10000 [00:20<00:20, 251.87it/s]Running 10000 simulations.:  49%|████▊     | 4857/10000 [00:20<00:20, 251.23it/s]Running 10000 simulations.:  49%|████▉     | 4883/10000 [00:20<00:20, 251.33it/s]Running 10000 simulations.:  49%|████▉     | 4909/10000 [00:20<00:20, 251.31it/s]Running 10000 simulations.:  49%|████▉     | 4935/10000 [00:20<00:20, 251.63it/s]Running 10000 simulations.:  50%|████▉     | 4961/10000 [00:20<00:19, 252.19it/s]Running 10000 simulations.:  50%|████▉     | 4987/10000 [00:20<00:19, 252.14it/s]Running 10000 simulations.:  50%|█████     | 5013/10000 [00:20<00:19, 252.23it/s]Running 10000 simulations.:  50%|█████     | 5039/10000 [00:20<00:19, 251.97it/s]Running 10000 simulations.:  51%|█████     | 5065/10000 [00:20<00:19, 251.55it/s]Running 10000 simulations.:  51%|█████     | 5091/10000 [00:21<00:19, 252.19it/s]Running 10000 simulations.:  51%|█████     | 5117/10000 [00:21<00:19, 251.96it/s]Running 10000 simulations.:  51%|█████▏    | 5143/10000 [00:21<00:19, 251.32it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:21<00:19, 251.62it/s]Running 10000 simulations.:  52%|█████▏    | 5195/10000 [00:21<00:19, 252.03it/s]Running 10000 simulations.:  52%|█████▏    | 5221/10000 [00:21<00:18, 251.89it/s]Running 10000 simulations.:  52%|█████▏    | 5247/10000 [00:21<00:18, 251.83it/s]Running 10000 simulations.:  53%|█████▎    | 5273/10000 [00:21<00:18, 251.78it/s]Running 10000 simulations.:  53%|█████▎    | 5299/10000 [00:21<00:18, 251.99it/s]Running 10000 simulations.:  53%|█████▎    | 5325/10000 [00:21<00:18, 252.48it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:22<00:18, 252.67it/s]Running 10000 simulations.:  54%|█████▍    | 5377/10000 [00:22<00:18, 253.31it/s]Running 10000 simulations.:  54%|█████▍    | 5403/10000 [00:22<00:18, 253.76it/s]Running 10000 simulations.:  54%|█████▍    | 5429/10000 [00:22<00:17, 255.33it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:22<00:17, 255.51it/s]Running 10000 simulations.:  55%|█████▍    | 5481/10000 [00:22<00:17, 255.38it/s]Running 10000 simulations.:  55%|█████▌    | 5507/10000 [00:22<00:17, 255.15it/s]Running 10000 simulations.:  55%|█████▌    | 5533/10000 [00:22<00:17, 255.57it/s]Running 10000 simulations.:  56%|█████▌    | 5559/10000 [00:22<00:17, 255.71it/s]Running 10000 simulations.:  56%|█████▌    | 5585/10000 [00:23<00:17, 255.35it/s]Running 10000 simulations.:  56%|█████▌    | 5611/10000 [00:23<00:17, 254.75it/s]Running 10000 simulations.:  56%|█████▋    | 5637/10000 [00:23<00:17, 253.83it/s]Running 10000 simulations.:  57%|█████▋    | 5663/10000 [00:23<00:17, 253.00it/s]Running 10000 simulations.:  57%|█████▋    | 5689/10000 [00:23<00:16, 253.68it/s]Running 10000 simulations.:  57%|█████▋    | 5716/10000 [00:23<00:16, 255.65it/s]Running 10000 simulations.:  57%|█████▋    | 5742/10000 [00:23<00:16, 255.88it/s]Running 10000 simulations.:  58%|█████▊    | 5768/10000 [00:23<00:16, 255.20it/s]Running 10000 simulations.:  58%|█████▊    | 5794/10000 [00:23<00:16, 256.00it/s]Running 10000 simulations.:  58%|█████▊    | 5820/10000 [00:23<00:16, 256.85it/s]Running 10000 simulations.:  58%|█████▊    | 5846/10000 [00:24<00:16, 255.80it/s]Running 10000 simulations.:  59%|█████▊    | 5872/10000 [00:24<00:16, 255.99it/s]Running 10000 simulations.:  59%|█████▉    | 5898/10000 [00:24<00:16, 254.82it/s]Running 10000 simulations.:  59%|█████▉    | 5924/10000 [00:24<00:16, 253.69it/s]Running 10000 simulations.:  60%|█████▉    | 5950/10000 [00:24<00:16, 252.96it/s]Running 10000 simulations.:  60%|█████▉    | 5976/10000 [00:24<00:15, 253.64it/s]Running 10000 simulations.:  60%|██████    | 6002/10000 [00:24<00:15, 254.28it/s]Running 10000 simulations.:  60%|██████    | 6028/10000 [00:24<00:15, 253.04it/s]Running 10000 simulations.:  61%|██████    | 6054/10000 [00:24<00:15, 253.63it/s]Running 10000 simulations.:  61%|██████    | 6080/10000 [00:24<00:15, 254.84it/s]Running 10000 simulations.:  61%|██████    | 6106/10000 [00:25<00:15, 255.74it/s]Running 10000 simulations.:  61%|██████▏   | 6132/10000 [00:25<00:15, 256.64it/s]Running 10000 simulations.:  62%|██████▏   | 6158/10000 [00:25<00:15, 255.92it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:25<00:14, 255.05it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:25<00:14, 255.45it/s]Running 10000 simulations.:  62%|██████▏   | 6236/10000 [00:25<00:14, 254.30it/s]Running 10000 simulations.:  63%|██████▎   | 6262/10000 [00:25<00:14, 255.21it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:25<00:14, 256.29it/s]Running 10000 simulations.:  63%|██████▎   | 6314/10000 [00:25<00:15, 243.07it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:25<00:15, 234.11it/s]Running 10000 simulations.:  64%|██████▎   | 6363/10000 [00:26<00:15, 228.12it/s]Running 10000 simulations.:  64%|██████▍   | 6386/10000 [00:26<00:16, 223.19it/s]Running 10000 simulations.:  64%|██████▍   | 6409/10000 [00:26<00:16, 221.02it/s]Running 10000 simulations.:  64%|██████▍   | 6432/10000 [00:26<00:16, 219.35it/s]Running 10000 simulations.:  65%|██████▍   | 6455/10000 [00:26<00:16, 218.19it/s]Running 10000 simulations.:  65%|██████▍   | 6477/10000 [00:26<00:16, 217.12it/s]Running 10000 simulations.:  65%|██████▍   | 6499/10000 [00:26<00:16, 216.77it/s]Running 10000 simulations.:  65%|██████▌   | 6521/10000 [00:26<00:16, 216.25it/s]Running 10000 simulations.:  65%|██████▌   | 6543/10000 [00:26<00:16, 215.63it/s]Running 10000 simulations.:  66%|██████▌   | 6565/10000 [00:27<00:15, 214.80it/s]Running 10000 simulations.:  66%|██████▌   | 6587/10000 [00:27<00:15, 213.63it/s]Running 10000 simulations.:  66%|██████▌   | 6609/10000 [00:27<00:15, 214.41it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:27<00:15, 215.42it/s]Running 10000 simulations.:  67%|██████▋   | 6653/10000 [00:27<00:15, 216.11it/s]Running 10000 simulations.:  67%|██████▋   | 6675/10000 [00:27<00:15, 216.83it/s]Running 10000 simulations.:  67%|██████▋   | 6697/10000 [00:27<00:15, 216.75it/s]Running 10000 simulations.:  67%|██████▋   | 6719/10000 [00:27<00:15, 216.09it/s]Running 10000 simulations.:  67%|██████▋   | 6741/10000 [00:27<00:15, 214.58it/s]Running 10000 simulations.:  68%|██████▊   | 6763/10000 [00:27<00:15, 213.46it/s]Running 10000 simulations.:  68%|██████▊   | 6785/10000 [00:28<00:15, 212.90it/s]Running 10000 simulations.:  68%|██████▊   | 6807/10000 [00:28<00:15, 212.11it/s]Running 10000 simulations.:  68%|██████▊   | 6829/10000 [00:28<00:14, 212.16it/s]Running 10000 simulations.:  69%|██████▊   | 6851/10000 [00:28<00:14, 212.60it/s]Running 10000 simulations.:  69%|██████▊   | 6873/10000 [00:28<00:14, 212.51it/s]Running 10000 simulations.:  69%|██████▉   | 6895/10000 [00:28<00:14, 213.76it/s]Running 10000 simulations.:  69%|██████▉   | 6917/10000 [00:28<00:14, 214.57it/s]Running 10000 simulations.:  69%|██████▉   | 6939/10000 [00:28<00:14, 214.84it/s]Running 10000 simulations.:  70%|██████▉   | 6961/10000 [00:28<00:14, 214.76it/s]Running 10000 simulations.:  70%|██████▉   | 6983/10000 [00:28<00:14, 214.51it/s]Running 10000 simulations.:  70%|███████   | 7005/10000 [00:29<00:14, 213.78it/s]Running 10000 simulations.:  70%|███████   | 7027/10000 [00:29<00:13, 214.22it/s]Running 10000 simulations.:  70%|███████   | 7049/10000 [00:29<00:13, 214.34it/s]Running 10000 simulations.:  71%|███████   | 7071/10000 [00:29<00:13, 215.22it/s]Running 10000 simulations.:  71%|███████   | 7093/10000 [00:29<00:13, 215.25it/s]Running 10000 simulations.:  71%|███████   | 7115/10000 [00:29<00:13, 215.61it/s]Running 10000 simulations.:  71%|███████▏  | 7137/10000 [00:29<00:13, 215.54it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:29<00:13, 215.16it/s]Running 10000 simulations.:  72%|███████▏  | 7181/10000 [00:29<00:13, 213.52it/s]Running 10000 simulations.:  72%|███████▏  | 7203/10000 [00:30<00:13, 210.80it/s]Running 10000 simulations.:  72%|███████▏  | 7229/10000 [00:30<00:12, 223.44it/s]Running 10000 simulations.:  73%|███████▎  | 7256/10000 [00:30<00:11, 235.00it/s]Running 10000 simulations.:  73%|███████▎  | 7283/10000 [00:30<00:11, 242.61it/s]Running 10000 simulations.:  73%|███████▎  | 7310/10000 [00:30<00:10, 249.74it/s]Running 10000 simulations.:  73%|███████▎  | 7337/10000 [00:30<00:10, 254.51it/s]Running 10000 simulations.:  74%|███████▎  | 7364/10000 [00:30<00:10, 257.88it/s]Running 10000 simulations.:  74%|███████▍  | 7391/10000 [00:30<00:10, 258.91it/s]Running 10000 simulations.:  74%|███████▍  | 7418/10000 [00:30<00:09, 259.99it/s]Running 10000 simulations.:  74%|███████▍  | 7445/10000 [00:30<00:09, 259.61it/s]Running 10000 simulations.:  75%|███████▍  | 7472/10000 [00:31<00:09, 257.34it/s]Running 10000 simulations.:  75%|███████▍  | 7499/10000 [00:31<00:09, 259.42it/s]Running 10000 simulations.:  75%|███████▌  | 7526/10000 [00:31<00:09, 260.38it/s]Running 10000 simulations.:  76%|███████▌  | 7553/10000 [00:31<00:09, 253.98it/s]Running 10000 simulations.:  76%|███████▌  | 7579/10000 [00:31<00:10, 241.32it/s]Running 10000 simulations.:  76%|███████▌  | 7604/10000 [00:31<00:10, 233.25it/s]Running 10000 simulations.:  76%|███████▋  | 7628/10000 [00:31<00:10, 228.28it/s]Running 10000 simulations.:  77%|███████▋  | 7653/10000 [00:31<00:10, 232.73it/s]Running 10000 simulations.:  77%|███████▋  | 7678/10000 [00:31<00:09, 237.22it/s]Running 10000 simulations.:  77%|███████▋  | 7703/10000 [00:32<00:09, 240.89it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:32<00:09, 243.73it/s]Running 10000 simulations.:  78%|███████▊  | 7754/10000 [00:32<00:09, 244.98it/s]Running 10000 simulations.:  78%|███████▊  | 7779/10000 [00:32<00:09, 245.47it/s]Running 10000 simulations.:  78%|███████▊  | 7804/10000 [00:32<00:08, 246.23it/s]Running 10000 simulations.:  78%|███████▊  | 7829/10000 [00:32<00:08, 246.41it/s]Running 10000 simulations.:  79%|███████▊  | 7854/10000 [00:32<00:08, 246.80it/s]Running 10000 simulations.:  79%|███████▉  | 7879/10000 [00:32<00:08, 246.65it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:32<00:08, 247.85it/s]Running 10000 simulations.:  79%|███████▉  | 7930/10000 [00:32<00:08, 248.19it/s]Running 10000 simulations.:  80%|███████▉  | 7955/10000 [00:33<00:08, 247.85it/s]Running 10000 simulations.:  80%|███████▉  | 7980/10000 [00:33<00:08, 248.13it/s]Running 10000 simulations.:  80%|████████  | 8006/10000 [00:33<00:08, 248.79it/s]Running 10000 simulations.:  80%|████████  | 8031/10000 [00:33<00:07, 248.42it/s]Running 10000 simulations.:  81%|████████  | 8056/10000 [00:33<00:07, 247.99it/s]Running 10000 simulations.:  81%|████████  | 8081/10000 [00:33<00:07, 248.03it/s]Running 10000 simulations.:  81%|████████  | 8106/10000 [00:33<00:07, 247.66it/s]Running 10000 simulations.:  81%|████████▏ | 8131/10000 [00:33<00:07, 248.23it/s]Running 10000 simulations.:  82%|████████▏ | 8157/10000 [00:33<00:07, 248.98it/s]Running 10000 simulations.:  82%|████████▏ | 8182/10000 [00:33<00:07, 248.31it/s]Running 10000 simulations.:  82%|████████▏ | 8208/10000 [00:34<00:07, 249.72it/s]Running 10000 simulations.:  82%|████████▏ | 8234/10000 [00:34<00:07, 250.96it/s]Running 10000 simulations.:  83%|████████▎ | 8260/10000 [00:34<00:06, 250.92it/s]Running 10000 simulations.:  83%|████████▎ | 8286/10000 [00:34<00:06, 250.65it/s]Running 10000 simulations.:  83%|████████▎ | 8312/10000 [00:34<00:06, 241.37it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:34<00:07, 231.97it/s]Running 10000 simulations.:  84%|████████▎ | 8361/10000 [00:34<00:07, 225.17it/s]Running 10000 simulations.:  84%|████████▍ | 8384/10000 [00:34<00:07, 219.85it/s]Running 10000 simulations.:  84%|████████▍ | 8407/10000 [00:34<00:07, 217.14it/s]Running 10000 simulations.:  84%|████████▍ | 8429/10000 [00:35<00:07, 215.21it/s]Running 10000 simulations.:  85%|████████▍ | 8451/10000 [00:35<00:07, 213.52it/s]Running 10000 simulations.:  85%|████████▍ | 8473/10000 [00:35<00:07, 214.05it/s]Running 10000 simulations.:  85%|████████▍ | 8495/10000 [00:35<00:07, 213.64it/s]Running 10000 simulations.:  85%|████████▌ | 8517/10000 [00:35<00:06, 213.23it/s]Running 10000 simulations.:  85%|████████▌ | 8541/10000 [00:35<00:06, 220.38it/s]Running 10000 simulations.:  86%|████████▌ | 8568/10000 [00:35<00:06, 231.51it/s]Running 10000 simulations.:  86%|████████▌ | 8595/10000 [00:35<00:05, 239.58it/s]Running 10000 simulations.:  86%|████████▌ | 8621/10000 [00:35<00:05, 245.28it/s]Running 10000 simulations.:  86%|████████▋ | 8647/10000 [00:35<00:05, 248.65it/s]Running 10000 simulations.:  87%|████████▋ | 8674/10000 [00:36<00:05, 253.91it/s]Running 10000 simulations.:  87%|████████▋ | 8700/10000 [00:36<00:05, 253.69it/s]Running 10000 simulations.:  87%|████████▋ | 8726/10000 [00:36<00:05, 252.90it/s]Running 10000 simulations.:  88%|████████▊ | 8752/10000 [00:36<00:04, 253.52it/s]Running 10000 simulations.:  88%|████████▊ | 8778/10000 [00:36<00:04, 254.80it/s]Running 10000 simulations.:  88%|████████▊ | 8804/10000 [00:36<00:04, 255.80it/s]Running 10000 simulations.:  88%|████████▊ | 8831/10000 [00:36<00:04, 257.62it/s]Running 10000 simulations.:  89%|████████▊ | 8857/10000 [00:36<00:04, 258.30it/s]Running 10000 simulations.:  89%|████████▉ | 8883/10000 [00:36<00:04, 257.62it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [00:36<00:04, 259.18it/s]Running 10000 simulations.:  89%|████████▉ | 8937/10000 [00:37<00:04, 259.60it/s]Running 10000 simulations.:  90%|████████▉ | 8964/10000 [00:37<00:03, 260.42it/s]Running 10000 simulations.:  90%|████████▉ | 8991/10000 [00:37<00:03, 260.45it/s]Running 10000 simulations.:  90%|█████████ | 9018/10000 [00:37<00:03, 260.29it/s]Running 10000 simulations.:  90%|█████████ | 9045/10000 [00:37<00:03, 261.06it/s]Running 10000 simulations.:  91%|█████████ | 9072/10000 [00:37<00:03, 262.10it/s]Running 10000 simulations.:  91%|█████████ | 9099/10000 [00:37<00:03, 262.34it/s]Running 10000 simulations.:  91%|█████████▏| 9126/10000 [00:37<00:03, 259.39it/s]Running 10000 simulations.:  92%|█████████▏| 9154/10000 [00:37<00:03, 263.49it/s]Running 10000 simulations.:  92%|█████████▏| 9181/10000 [00:38<00:03, 265.37it/s]Running 10000 simulations.:  92%|█████████▏| 9209/10000 [00:38<00:02, 267.82it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [00:38<00:02, 261.06it/s]Running 10000 simulations.:  93%|█████████▎| 9263/10000 [00:38<00:02, 254.99it/s]Running 10000 simulations.:  93%|█████████▎| 9289/10000 [00:38<00:02, 251.08it/s]Running 10000 simulations.:  93%|█████████▎| 9315/10000 [00:38<00:02, 248.55it/s]Running 10000 simulations.:  93%|█████████▎| 9340/10000 [00:38<00:02, 247.66it/s]Running 10000 simulations.:  94%|█████████▎| 9365/10000 [00:38<00:02, 247.10it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:38<00:02, 246.04it/s]Running 10000 simulations.:  94%|█████████▍| 9415/10000 [00:38<00:02, 244.93it/s]Running 10000 simulations.:  94%|█████████▍| 9440/10000 [00:39<00:02, 243.50it/s]Running 10000 simulations.:  95%|█████████▍| 9465/10000 [00:39<00:02, 242.55it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [00:39<00:02, 241.77it/s]Running 10000 simulations.:  95%|█████████▌| 9515/10000 [00:39<00:02, 241.21it/s]Running 10000 simulations.:  95%|█████████▌| 9540/10000 [00:39<00:01, 241.74it/s]Running 10000 simulations.:  96%|█████████▌| 9565/10000 [00:39<00:01, 242.60it/s]Running 10000 simulations.:  96%|█████████▌| 9590/10000 [00:39<00:01, 243.18it/s]Running 10000 simulations.:  96%|█████████▌| 9615/10000 [00:39<00:01, 241.25it/s]Running 10000 simulations.:  96%|█████████▋| 9640/10000 [00:39<00:01, 237.67it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [00:39<00:01, 235.93it/s]Running 10000 simulations.:  97%|█████████▋| 9688/10000 [00:40<00:01, 234.78it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [00:40<00:01, 233.75it/s]Running 10000 simulations.:  97%|█████████▋| 9736/10000 [00:40<00:01, 232.38it/s]Running 10000 simulations.:  98%|█████████▊| 9760/10000 [00:40<00:01, 232.94it/s]Running 10000 simulations.:  98%|█████████▊| 9784/10000 [00:40<00:00, 233.60it/s]Running 10000 simulations.:  98%|█████████▊| 9808/10000 [00:40<00:00, 233.01it/s]Running 10000 simulations.:  98%|█████████▊| 9832/10000 [00:40<00:00, 232.55it/s]Running 10000 simulations.:  99%|█████████▊| 9856/10000 [00:40<00:00, 233.33it/s]Running 10000 simulations.:  99%|█████████▉| 9880/10000 [00:40<00:00, 233.31it/s]Running 10000 simulations.:  99%|█████████▉| 9904/10000 [00:41<00:00, 233.18it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [00:41<00:00, 233.86it/s]Running 10000 simulations.: 100%|█████████▉| 9952/10000 [00:41<00:00, 233.27it/s]Running 10000 simulations.: 100%|█████████▉| 9976/10000 [00:41<00:00, 233.65it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 234.37it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 241.33it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 275.96it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<00:36, 275.02it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<00:36, 274.05it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<00:36, 273.97it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:35, 274.23it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:35, 274.40it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:00<00:35, 274.11it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:00<00:35, 273.53it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:00<00:35, 273.39it/s]Running 10000 simulations.:   3%|▎         | 279/10000 [00:01<00:35, 271.85it/s]Running 10000 simulations.:   3%|▎         | 307/10000 [00:01<00:35, 271.83it/s]Running 10000 simulations.:   3%|▎         | 335/10000 [00:01<00:35, 272.26it/s]Running 10000 simulations.:   4%|▎         | 363/10000 [00:01<00:35, 272.87it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:01<00:35, 274.04it/s]Running 10000 simulations.:   4%|▍         | 419/10000 [00:01<00:35, 272.58it/s]Running 10000 simulations.:   4%|▍         | 447/10000 [00:01<00:35, 271.21it/s]Running 10000 simulations.:   5%|▍         | 475/10000 [00:01<00:35, 269.72it/s]Running 10000 simulations.:   5%|▌         | 502/10000 [00:01<00:35, 268.77it/s]Running 10000 simulations.:   5%|▌         | 529/10000 [00:01<00:35, 268.37it/s]Running 10000 simulations.:   6%|▌         | 557/10000 [00:02<00:34, 270.20it/s]Running 10000 simulations.:   6%|▌         | 585/10000 [00:02<00:34, 270.62it/s]Running 10000 simulations.:   6%|▌         | 613/10000 [00:02<00:34, 270.70it/s]Running 10000 simulations.:   6%|▋         | 641/10000 [00:02<00:34, 271.08it/s]Running 10000 simulations.:   7%|▋         | 669/10000 [00:02<00:34, 270.73it/s]Running 10000 simulations.:   7%|▋         | 697/10000 [00:02<00:34, 269.74it/s]Running 10000 simulations.:   7%|▋         | 724/10000 [00:02<00:34, 268.57it/s]Running 10000 simulations.:   8%|▊         | 751/10000 [00:02<00:34, 268.46it/s]Running 10000 simulations.:   8%|▊         | 779/10000 [00:02<00:34, 269.54it/s]Running 10000 simulations.:   8%|▊         | 806/10000 [00:02<00:34, 269.05it/s]Running 10000 simulations.:   8%|▊         | 833/10000 [00:03<00:34, 268.76it/s]Running 10000 simulations.:   9%|▊         | 860/10000 [00:03<00:34, 268.63it/s]Running 10000 simulations.:   9%|▉         | 888/10000 [00:03<00:33, 269.11it/s]Running 10000 simulations.:   9%|▉         | 915/10000 [00:03<00:33, 268.96it/s]Running 10000 simulations.:   9%|▉         | 942/10000 [00:03<00:33, 268.54it/s]Running 10000 simulations.:  10%|▉         | 969/10000 [00:03<00:33, 268.21it/s]Running 10000 simulations.:  10%|▉         | 996/10000 [00:03<00:33, 268.70it/s]Running 10000 simulations.:  10%|█         | 1023/10000 [00:03<00:33, 267.45it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:03<00:33, 267.61it/s]Running 10000 simulations.:  11%|█         | 1077/10000 [00:03<00:33, 267.86it/s]Running 10000 simulations.:  11%|█         | 1104/10000 [00:04<00:33, 267.04it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:04<00:33, 267.90it/s]Running 10000 simulations.:  12%|█▏        | 1158/10000 [00:04<00:32, 268.39it/s]Running 10000 simulations.:  12%|█▏        | 1185/10000 [00:04<00:32, 268.68it/s]Running 10000 simulations.:  12%|█▏        | 1212/10000 [00:04<00:32, 267.34it/s]Running 10000 simulations.:  12%|█▏        | 1239/10000 [00:04<00:32, 267.21it/s]Running 10000 simulations.:  13%|█▎        | 1266/10000 [00:04<00:32, 267.92it/s]Running 10000 simulations.:  13%|█▎        | 1293/10000 [00:04<00:32, 267.17it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:04<00:32, 268.01it/s]Running 10000 simulations.:  13%|█▎        | 1347/10000 [00:04<00:32, 268.05it/s]Running 10000 simulations.:  14%|█▎        | 1374/10000 [00:05<00:32, 267.79it/s]Running 10000 simulations.:  14%|█▍        | 1401/10000 [00:05<00:32, 267.48it/s]Running 10000 simulations.:  14%|█▍        | 1428/10000 [00:05<00:32, 267.31it/s]Running 10000 simulations.:  15%|█▍        | 1455/10000 [00:05<00:32, 262.69it/s]Running 10000 simulations.:  15%|█▍        | 1482/10000 [00:05<00:32, 261.58it/s]Running 10000 simulations.:  15%|█▌        | 1509/10000 [00:05<00:32, 262.93it/s]Running 10000 simulations.:  15%|█▌        | 1536/10000 [00:05<00:31, 264.57it/s]Running 10000 simulations.:  16%|█▌        | 1564/10000 [00:05<00:31, 267.13it/s]Running 10000 simulations.:  16%|█▌        | 1591/10000 [00:05<00:31, 265.65it/s]Running 10000 simulations.:  16%|█▌        | 1618/10000 [00:06<00:31, 266.07it/s]Running 10000 simulations.:  16%|█▋        | 1645/10000 [00:06<00:31, 265.43it/s]Running 10000 simulations.:  17%|█▋        | 1672/10000 [00:06<00:31, 265.87it/s]Running 10000 simulations.:  17%|█▋        | 1699/10000 [00:06<00:31, 266.72it/s]Running 10000 simulations.:  17%|█▋        | 1726/10000 [00:06<00:30, 267.11it/s]Running 10000 simulations.:  18%|█▊        | 1754/10000 [00:06<00:30, 268.15it/s]Running 10000 simulations.:  18%|█▊        | 1781/10000 [00:06<00:30, 267.66it/s]Running 10000 simulations.:  18%|█▊        | 1808/10000 [00:06<00:30, 267.85it/s]Running 10000 simulations.:  18%|█▊        | 1835/10000 [00:06<00:30, 266.23it/s]Running 10000 simulations.:  19%|█▊        | 1862/10000 [00:06<00:30, 265.83it/s]Running 10000 simulations.:  19%|█▉        | 1889/10000 [00:07<00:30, 266.51it/s]Running 10000 simulations.:  19%|█▉        | 1917/10000 [00:07<00:30, 267.58it/s]Running 10000 simulations.:  19%|█▉        | 1945/10000 [00:07<00:29, 269.16it/s]Running 10000 simulations.:  20%|█▉        | 1972/10000 [00:07<00:29, 268.24it/s]Running 10000 simulations.:  20%|█▉        | 1999/10000 [00:07<00:29, 268.42it/s]Running 10000 simulations.:  20%|██        | 2026/10000 [00:07<00:29, 267.44it/s]Running 10000 simulations.:  21%|██        | 2053/10000 [00:07<00:29, 267.92it/s]Running 10000 simulations.:  21%|██        | 2080/10000 [00:07<00:29, 267.55it/s]Running 10000 simulations.:  21%|██        | 2107/10000 [00:07<00:29, 266.28it/s]Running 10000 simulations.:  21%|██▏       | 2135/10000 [00:07<00:29, 267.75it/s]Running 10000 simulations.:  22%|██▏       | 2162/10000 [00:08<00:29, 267.32it/s]Running 10000 simulations.:  22%|██▏       | 2189/10000 [00:08<00:29, 267.91it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:08<00:29, 265.74it/s]Running 10000 simulations.:  22%|██▏       | 2243/10000 [00:08<00:29, 266.18it/s]Running 10000 simulations.:  23%|██▎       | 2270/10000 [00:08<00:29, 266.10it/s]Running 10000 simulations.:  23%|██▎       | 2297/10000 [00:08<00:28, 266.58it/s]Running 10000 simulations.:  23%|██▎       | 2324/10000 [00:08<00:28, 267.22it/s]Running 10000 simulations.:  24%|██▎       | 2351/10000 [00:08<00:28, 265.68it/s]Running 10000 simulations.:  24%|██▍       | 2378/10000 [00:08<00:28, 266.09it/s]Running 10000 simulations.:  24%|██▍       | 2405/10000 [00:08<00:28, 264.09it/s]Running 10000 simulations.:  24%|██▍       | 2432/10000 [00:09<00:28, 264.98it/s]Running 10000 simulations.:  25%|██▍       | 2459/10000 [00:09<00:28, 264.11it/s]Running 10000 simulations.:  25%|██▍       | 2487/10000 [00:09<00:28, 266.04it/s]Running 10000 simulations.:  25%|██▌       | 2515/10000 [00:09<00:28, 267.26it/s]Running 10000 simulations.:  25%|██▌       | 2542/10000 [00:09<00:27, 266.73it/s]Running 10000 simulations.:  26%|██▌       | 2569/10000 [00:09<00:27, 266.52it/s]Running 10000 simulations.:  26%|██▌       | 2596/10000 [00:09<00:27, 265.44it/s]Running 10000 simulations.:  26%|██▌       | 2623/10000 [00:09<00:27, 265.30it/s]Running 10000 simulations.:  26%|██▋       | 2650/10000 [00:09<00:27, 264.92it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:09<00:27, 265.84it/s]Running 10000 simulations.:  27%|██▋       | 2704/10000 [00:10<00:27, 266.23it/s]Running 10000 simulations.:  27%|██▋       | 2731/10000 [00:10<00:27, 266.31it/s]Running 10000 simulations.:  28%|██▊       | 2758/10000 [00:10<00:27, 264.77it/s]Running 10000 simulations.:  28%|██▊       | 2785/10000 [00:10<00:27, 264.30it/s]Running 10000 simulations.:  28%|██▊       | 2812/10000 [00:10<00:27, 264.10it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:10<00:27, 259.32it/s]Running 10000 simulations.:  29%|██▊       | 2865/10000 [00:10<00:27, 258.09it/s]Running 10000 simulations.:  29%|██▉       | 2892/10000 [00:10<00:27, 259.66it/s]Running 10000 simulations.:  29%|██▉       | 2919/10000 [00:10<00:27, 261.31it/s]Running 10000 simulations.:  29%|██▉       | 2946/10000 [00:11<00:26, 262.92it/s]Running 10000 simulations.:  30%|██▉       | 2973/10000 [00:11<00:26, 263.36it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:11<00:26, 262.98it/s]Running 10000 simulations.:  30%|███       | 3027/10000 [00:11<00:26, 263.89it/s]Running 10000 simulations.:  31%|███       | 3054/10000 [00:11<00:26, 264.41it/s]Running 10000 simulations.:  31%|███       | 3081/10000 [00:11<00:26, 265.86it/s]Running 10000 simulations.:  31%|███       | 3108/10000 [00:11<00:25, 266.21it/s]Running 10000 simulations.:  31%|███▏      | 3135/10000 [00:11<00:25, 266.17it/s]Running 10000 simulations.:  32%|███▏      | 3162/10000 [00:11<00:25, 265.97it/s]Running 10000 simulations.:  32%|███▏      | 3189/10000 [00:11<00:25, 264.64it/s]Running 10000 simulations.:  32%|███▏      | 3216/10000 [00:12<00:25, 264.49it/s]Running 10000 simulations.:  32%|███▏      | 3243/10000 [00:12<00:25, 263.97it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:12<00:25, 264.83it/s]Running 10000 simulations.:  33%|███▎      | 3297/10000 [00:12<00:25, 264.86it/s]Running 10000 simulations.:  33%|███▎      | 3324/10000 [00:12<00:25, 265.21it/s]Running 10000 simulations.:  34%|███▎      | 3351/10000 [00:12<00:25, 264.06it/s]Running 10000 simulations.:  34%|███▍      | 3378/10000 [00:12<00:25, 263.48it/s]Running 10000 simulations.:  34%|███▍      | 3405/10000 [00:12<00:25, 263.53it/s]Running 10000 simulations.:  34%|███▍      | 3432/10000 [00:12<00:24, 263.17it/s]Running 10000 simulations.:  35%|███▍      | 3459/10000 [00:12<00:24, 263.79it/s]Running 10000 simulations.:  35%|███▍      | 3486/10000 [00:13<00:24, 265.52it/s]Running 10000 simulations.:  35%|███▌      | 3513/10000 [00:13<00:24, 265.81it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:13<00:24, 264.43it/s]Running 10000 simulations.:  36%|███▌      | 3567/10000 [00:13<00:24, 263.61it/s]Running 10000 simulations.:  36%|███▌      | 3594/10000 [00:13<00:24, 264.10it/s]Running 10000 simulations.:  36%|███▌      | 3621/10000 [00:13<00:24, 265.41it/s]Running 10000 simulations.:  36%|███▋      | 3648/10000 [00:13<00:23, 265.54it/s]Running 10000 simulations.:  37%|███▋      | 3675/10000 [00:13<00:23, 265.63it/s]Running 10000 simulations.:  37%|███▋      | 3702/10000 [00:13<00:23, 265.25it/s]Running 10000 simulations.:  37%|███▋      | 3729/10000 [00:13<00:23, 264.27it/s]Running 10000 simulations.:  38%|███▊      | 3756/10000 [00:14<00:23, 263.90it/s]Running 10000 simulations.:  38%|███▊      | 3783/10000 [00:14<00:23, 263.18it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:14<00:23, 264.17it/s]Running 10000 simulations.:  38%|███▊      | 3837/10000 [00:14<00:23, 263.69it/s]Running 10000 simulations.:  39%|███▊      | 3864/10000 [00:14<00:23, 264.40it/s]Running 10000 simulations.:  39%|███▉      | 3891/10000 [00:14<00:22, 265.66it/s]Running 10000 simulations.:  39%|███▉      | 3918/10000 [00:14<00:22, 265.44it/s]Running 10000 simulations.:  39%|███▉      | 3945/10000 [00:14<00:22, 264.34it/s]Running 10000 simulations.:  40%|███▉      | 3972/10000 [00:14<00:22, 264.36it/s]Running 10000 simulations.:  40%|███▉      | 3999/10000 [00:14<00:22, 265.23it/s]Running 10000 simulations.:  40%|████      | 4026/10000 [00:15<00:22, 265.81it/s]Running 10000 simulations.:  41%|████      | 4053/10000 [00:15<00:22, 266.18it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:15<00:22, 265.52it/s]Running 10000 simulations.:  41%|████      | 4107/10000 [00:15<00:22, 266.17it/s]Running 10000 simulations.:  41%|████▏     | 4134/10000 [00:15<00:22, 265.10it/s]Running 10000 simulations.:  42%|████▏     | 4161/10000 [00:15<00:22, 265.38it/s]Running 10000 simulations.:  42%|████▏     | 4188/10000 [00:15<00:21, 265.77it/s]Running 10000 simulations.:  42%|████▏     | 4215/10000 [00:15<00:21, 265.22it/s]Running 10000 simulations.:  42%|████▏     | 4242/10000 [00:15<00:21, 266.58it/s]Running 10000 simulations.:  43%|████▎     | 4269/10000 [00:16<00:21, 265.30it/s]Running 10000 simulations.:  43%|████▎     | 4296/10000 [00:16<00:21, 263.32it/s]Running 10000 simulations.:  43%|████▎     | 4323/10000 [00:16<00:21, 263.36it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:16<00:21, 262.98it/s]Running 10000 simulations.:  44%|████▍     | 4377/10000 [00:16<00:21, 257.90it/s]Running 10000 simulations.:  44%|████▍     | 4403/10000 [00:16<00:21, 257.05it/s]Running 10000 simulations.:  44%|████▍     | 4430/10000 [00:16<00:21, 259.07it/s]Running 10000 simulations.:  45%|████▍     | 4457/10000 [00:16<00:21, 261.28it/s]Running 10000 simulations.:  45%|████▍     | 4484/10000 [00:16<00:21, 261.05it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:16<00:20, 262.35it/s]Running 10000 simulations.:  45%|████▌     | 4538/10000 [00:17<00:20, 262.01it/s]Running 10000 simulations.:  46%|████▌     | 4565/10000 [00:17<00:20, 263.44it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:17<00:20, 263.20it/s]Running 10000 simulations.:  46%|████▌     | 4619/10000 [00:17<00:20, 263.55it/s]Running 10000 simulations.:  46%|████▋     | 4646/10000 [00:17<00:20, 264.49it/s]Running 10000 simulations.:  47%|████▋     | 4673/10000 [00:17<00:20, 264.76it/s]Running 10000 simulations.:  47%|████▋     | 4700/10000 [00:17<00:20, 264.01it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:17<00:20, 263.38it/s]Running 10000 simulations.:  48%|████▊     | 4754/10000 [00:17<00:19, 263.53it/s]Running 10000 simulations.:  48%|████▊     | 4781/10000 [00:17<00:19, 264.20it/s]Running 10000 simulations.:  48%|████▊     | 4808/10000 [00:18<00:19, 264.68it/s]Running 10000 simulations.:  48%|████▊     | 4835/10000 [00:18<00:19, 264.42it/s]Running 10000 simulations.:  49%|████▊     | 4862/10000 [00:18<00:19, 263.17it/s]Running 10000 simulations.:  49%|████▉     | 4889/10000 [00:18<00:19, 263.45it/s]Running 10000 simulations.:  49%|████▉     | 4916/10000 [00:18<00:19, 264.14it/s]Running 10000 simulations.:  49%|████▉     | 4943/10000 [00:18<00:19, 263.73it/s]Running 10000 simulations.:  50%|████▉     | 4970/10000 [00:18<00:19, 262.28it/s]Running 10000 simulations.:  50%|████▉     | 4997/10000 [00:18<00:19, 261.99it/s]Running 10000 simulations.:  50%|█████     | 5024/10000 [00:18<00:18, 262.94it/s]Running 10000 simulations.:  51%|█████     | 5051/10000 [00:18<00:18, 262.53it/s]Running 10000 simulations.:  51%|█████     | 5078/10000 [00:19<00:18, 262.85it/s]Running 10000 simulations.:  51%|█████     | 5105/10000 [00:19<00:18, 263.54it/s]Running 10000 simulations.:  51%|█████▏    | 5132/10000 [00:19<00:18, 262.77it/s]Running 10000 simulations.:  52%|█████▏    | 5159/10000 [00:19<00:18, 261.88it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:19<00:18, 262.23it/s]Running 10000 simulations.:  52%|█████▏    | 5213/10000 [00:19<00:18, 260.81it/s]Running 10000 simulations.:  52%|█████▏    | 5240/10000 [00:19<00:18, 261.16it/s]Running 10000 simulations.:  53%|█████▎    | 5267/10000 [00:19<00:18, 261.43it/s]Running 10000 simulations.:  53%|█████▎    | 5294/10000 [00:19<00:17, 262.35it/s]Running 10000 simulations.:  53%|█████▎    | 5321/10000 [00:20<00:17, 262.28it/s]Running 10000 simulations.:  53%|█████▎    | 5348/10000 [00:20<00:17, 262.36it/s]Running 10000 simulations.:  54%|█████▍    | 5375/10000 [00:20<00:17, 261.45it/s]Running 10000 simulations.:  54%|█████▍    | 5402/10000 [00:20<00:17, 258.43it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:20<00:17, 255.50it/s]Running 10000 simulations.:  55%|█████▍    | 5454/10000 [00:20<00:17, 253.82it/s]Running 10000 simulations.:  55%|█████▍    | 5480/10000 [00:20<00:17, 253.40it/s]Running 10000 simulations.:  55%|█████▌    | 5506/10000 [00:20<00:17, 252.41it/s]Running 10000 simulations.:  55%|█████▌    | 5532/10000 [00:20<00:17, 249.45it/s]Running 10000 simulations.:  56%|█████▌    | 5557/10000 [00:20<00:17, 249.28it/s]Running 10000 simulations.:  56%|█████▌    | 5583/10000 [00:21<00:17, 250.09it/s]Running 10000 simulations.:  56%|█████▌    | 5609/10000 [00:21<00:17, 249.91it/s]Running 10000 simulations.:  56%|█████▋    | 5635/10000 [00:21<00:17, 250.10it/s]Running 10000 simulations.:  57%|█████▋    | 5661/10000 [00:21<00:17, 250.24it/s]Running 10000 simulations.:  57%|█████▋    | 5687/10000 [00:21<00:17, 249.29it/s]Running 10000 simulations.:  57%|█████▋    | 5712/10000 [00:21<00:17, 249.30it/s]Running 10000 simulations.:  57%|█████▋    | 5737/10000 [00:21<00:17, 247.23it/s]Running 10000 simulations.:  58%|█████▊    | 5762/10000 [00:21<00:17, 247.01it/s]Running 10000 simulations.:  58%|█████▊    | 5788/10000 [00:21<00:16, 248.19it/s]Running 10000 simulations.:  58%|█████▊    | 5814/10000 [00:21<00:16, 248.87it/s]Running 10000 simulations.:  58%|█████▊    | 5839/10000 [00:22<00:16, 249.17it/s]Running 10000 simulations.:  59%|█████▊    | 5864/10000 [00:22<00:16, 248.58it/s]Running 10000 simulations.:  59%|█████▉    | 5889/10000 [00:22<00:16, 248.48it/s]Running 10000 simulations.:  59%|█████▉    | 5914/10000 [00:22<00:16, 247.70it/s]Running 10000 simulations.:  59%|█████▉    | 5939/10000 [00:22<00:16, 248.25it/s]Running 10000 simulations.:  60%|█████▉    | 5964/10000 [00:22<00:16, 246.81it/s]Running 10000 simulations.:  60%|█████▉    | 5989/10000 [00:22<00:16, 245.54it/s]Running 10000 simulations.:  60%|██████    | 6014/10000 [00:22<00:16, 245.79it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:22<00:16, 246.80it/s]Running 10000 simulations.:  61%|██████    | 6065/10000 [00:23<00:15, 248.25it/s]Running 10000 simulations.:  61%|██████    | 6091/10000 [00:23<00:15, 249.04it/s]Running 10000 simulations.:  61%|██████    | 6116/10000 [00:23<00:15, 248.64it/s]Running 10000 simulations.:  61%|██████▏   | 6142/10000 [00:23<00:15, 249.44it/s]Running 10000 simulations.:  62%|██████▏   | 6168/10000 [00:23<00:15, 250.61it/s]Running 10000 simulations.:  62%|██████▏   | 6194/10000 [00:23<00:15, 250.07it/s]Running 10000 simulations.:  62%|██████▏   | 6220/10000 [00:23<00:15, 248.33it/s]Running 10000 simulations.:  62%|██████▏   | 6245/10000 [00:23<00:15, 247.42it/s]Running 10000 simulations.:  63%|██████▎   | 6271/10000 [00:23<00:14, 248.74it/s]Running 10000 simulations.:  63%|██████▎   | 6297/10000 [00:23<00:14, 249.15it/s]Running 10000 simulations.:  63%|██████▎   | 6323/10000 [00:24<00:14, 249.59it/s]Running 10000 simulations.:  63%|██████▎   | 6349/10000 [00:24<00:14, 249.94it/s]Running 10000 simulations.:  64%|██████▎   | 6374/10000 [00:24<00:14, 248.78it/s]Running 10000 simulations.:  64%|██████▍   | 6399/10000 [00:24<00:14, 248.02it/s]Running 10000 simulations.:  64%|██████▍   | 6424/10000 [00:24<00:14, 247.27it/s]Running 10000 simulations.:  64%|██████▍   | 6450/10000 [00:24<00:14, 248.52it/s]Running 10000 simulations.:  65%|██████▍   | 6476/10000 [00:24<00:14, 249.22it/s]Running 10000 simulations.:  65%|██████▌   | 6502/10000 [00:24<00:14, 249.85it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:24<00:13, 250.02it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:24<00:13, 249.52it/s]Running 10000 simulations.:  66%|██████▌   | 6579/10000 [00:25<00:13, 249.03it/s]Running 10000 simulations.:  66%|██████▌   | 6605/10000 [00:25<00:13, 249.50it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:25<00:13, 249.33it/s]Running 10000 simulations.:  67%|██████▋   | 6656/10000 [00:25<00:13, 249.57it/s]Running 10000 simulations.:  67%|██████▋   | 6682/10000 [00:25<00:13, 249.87it/s]Running 10000 simulations.:  67%|██████▋   | 6707/10000 [00:25<00:13, 249.43it/s]Running 10000 simulations.:  67%|██████▋   | 6732/10000 [00:25<00:13, 246.72it/s]Running 10000 simulations.:  68%|██████▊   | 6757/10000 [00:25<00:13, 247.46it/s]Running 10000 simulations.:  68%|██████▊   | 6783/10000 [00:25<00:12, 248.48it/s]Running 10000 simulations.:  68%|██████▊   | 6808/10000 [00:25<00:12, 248.77it/s]Running 10000 simulations.:  68%|██████▊   | 6834/10000 [00:26<00:12, 249.71it/s]Running 10000 simulations.:  69%|██████▊   | 6860/10000 [00:26<00:12, 251.12it/s]Running 10000 simulations.:  69%|██████▉   | 6886/10000 [00:26<00:12, 251.26it/s]Running 10000 simulations.:  69%|██████▉   | 6912/10000 [00:26<00:12, 251.52it/s]Running 10000 simulations.:  69%|██████▉   | 6938/10000 [00:26<00:12, 250.55it/s]Running 10000 simulations.:  70%|██████▉   | 6964/10000 [00:26<00:12, 249.49it/s]Running 10000 simulations.:  70%|██████▉   | 6989/10000 [00:26<00:12, 249.55it/s]Running 10000 simulations.:  70%|███████   | 7014/10000 [00:26<00:11, 249.50it/s]Running 10000 simulations.:  70%|███████   | 7039/10000 [00:26<00:11, 248.18it/s]Running 10000 simulations.:  71%|███████   | 7064/10000 [00:27<00:11, 248.49it/s]Running 10000 simulations.:  71%|███████   | 7089/10000 [00:27<00:11, 248.55it/s]Running 10000 simulations.:  71%|███████   | 7114/10000 [00:27<00:11, 248.92it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:27<00:11, 249.91it/s]Running 10000 simulations.:  72%|███████▏  | 7165/10000 [00:27<00:11, 246.59it/s]Running 10000 simulations.:  72%|███████▏  | 7190/10000 [00:27<00:11, 243.94it/s]Running 10000 simulations.:  72%|███████▏  | 7215/10000 [00:27<00:11, 241.57it/s]Running 10000 simulations.:  72%|███████▏  | 7240/10000 [00:27<00:11, 241.38it/s]Running 10000 simulations.:  73%|███████▎  | 7265/10000 [00:27<00:11, 241.27it/s]Running 10000 simulations.:  73%|███████▎  | 7290/10000 [00:27<00:11, 241.20it/s]Running 10000 simulations.:  73%|███████▎  | 7315/10000 [00:28<00:11, 242.07it/s]Running 10000 simulations.:  73%|███████▎  | 7340/10000 [00:28<00:11, 240.68it/s]Running 10000 simulations.:  74%|███████▎  | 7365/10000 [00:28<00:10, 240.08it/s]Running 10000 simulations.:  74%|███████▍  | 7390/10000 [00:28<00:10, 239.97it/s]Running 10000 simulations.:  74%|███████▍  | 7414/10000 [00:28<00:10, 238.18it/s]Running 10000 simulations.:  74%|███████▍  | 7439/10000 [00:28<00:10, 240.10it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:28<00:10, 242.26it/s]Running 10000 simulations.:  75%|███████▍  | 7490/10000 [00:28<00:10, 244.78it/s]Running 10000 simulations.:  75%|███████▌  | 7515/10000 [00:28<00:10, 246.22it/s]Running 10000 simulations.:  75%|███████▌  | 7540/10000 [00:28<00:10, 245.81it/s]Running 10000 simulations.:  76%|███████▌  | 7565/10000 [00:29<00:09, 243.91it/s]Running 10000 simulations.:  76%|███████▌  | 7590/10000 [00:29<00:10, 240.77it/s]Running 10000 simulations.:  76%|███████▌  | 7615/10000 [00:29<00:09, 239.81it/s]Running 10000 simulations.:  76%|███████▋  | 7640/10000 [00:29<00:09, 240.14it/s]Running 10000 simulations.:  77%|███████▋  | 7665/10000 [00:29<00:09, 240.02it/s]Running 10000 simulations.:  77%|███████▋  | 7690/10000 [00:29<00:09, 241.62it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:29<00:09, 241.36it/s]Running 10000 simulations.:  77%|███████▋  | 7740/10000 [00:29<00:09, 239.83it/s]Running 10000 simulations.:  78%|███████▊  | 7764/10000 [00:29<00:09, 232.83it/s]Running 10000 simulations.:  78%|███████▊  | 7789/10000 [00:30<00:09, 234.95it/s]Running 10000 simulations.:  78%|███████▊  | 7814/10000 [00:30<00:09, 236.51it/s]Running 10000 simulations.:  78%|███████▊  | 7838/10000 [00:30<00:09, 234.15it/s]Running 10000 simulations.:  79%|███████▊  | 7862/10000 [00:30<00:09, 233.77it/s]Running 10000 simulations.:  79%|███████▉  | 7886/10000 [00:30<00:08, 235.30it/s]Running 10000 simulations.:  79%|███████▉  | 7911/10000 [00:30<00:08, 237.21it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:30<00:08, 238.16it/s]Running 10000 simulations.:  80%|███████▉  | 7960/10000 [00:30<00:08, 236.67it/s]Running 10000 simulations.:  80%|███████▉  | 7984/10000 [00:30<00:08, 236.31it/s]Running 10000 simulations.:  80%|████████  | 8008/10000 [00:30<00:08, 235.89it/s]Running 10000 simulations.:  80%|████████  | 8033/10000 [00:31<00:08, 237.15it/s]Running 10000 simulations.:  81%|████████  | 8058/10000 [00:31<00:08, 238.33it/s]Running 10000 simulations.:  81%|████████  | 8083/10000 [00:31<00:07, 240.32it/s]Running 10000 simulations.:  81%|████████  | 8108/10000 [00:31<00:07, 241.79it/s]Running 10000 simulations.:  81%|████████▏ | 8133/10000 [00:31<00:07, 241.13it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:31<00:07, 240.43it/s]Running 10000 simulations.:  82%|████████▏ | 8183/10000 [00:31<00:07, 238.66it/s]Running 10000 simulations.:  82%|████████▏ | 8207/10000 [00:31<00:07, 238.42it/s]Running 10000 simulations.:  82%|████████▏ | 8232/10000 [00:31<00:07, 239.23it/s]Running 10000 simulations.:  83%|████████▎ | 8257/10000 [00:31<00:07, 239.88it/s]Running 10000 simulations.:  83%|████████▎ | 8282/10000 [00:32<00:07, 240.80it/s]Running 10000 simulations.:  83%|████████▎ | 8307/10000 [00:32<00:07, 240.63it/s]Running 10000 simulations.:  83%|████████▎ | 8332/10000 [00:32<00:06, 239.80it/s]Running 10000 simulations.:  84%|████████▎ | 8356/10000 [00:32<00:06, 238.58it/s]Running 10000 simulations.:  84%|████████▍ | 8381/10000 [00:32<00:06, 239.44it/s]Running 10000 simulations.:  84%|████████▍ | 8406/10000 [00:32<00:06, 239.95it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:32<00:06, 239.59it/s]Running 10000 simulations.:  85%|████████▍ | 8455/10000 [00:32<00:06, 240.62it/s]Running 10000 simulations.:  85%|████████▍ | 8480/10000 [00:32<00:06, 240.53it/s]Running 10000 simulations.:  85%|████████▌ | 8505/10000 [00:33<00:06, 239.87it/s]Running 10000 simulations.:  85%|████████▌ | 8529/10000 [00:33<00:06, 237.62it/s]Running 10000 simulations.:  86%|████████▌ | 8556/10000 [00:33<00:05, 244.35it/s]Running 10000 simulations.:  86%|████████▌ | 8583/10000 [00:33<00:05, 249.91it/s]Running 10000 simulations.:  86%|████████▌ | 8610/10000 [00:33<00:05, 253.70it/s]Running 10000 simulations.:  86%|████████▋ | 8637/10000 [00:33<00:05, 257.70it/s]Running 10000 simulations.:  87%|████████▋ | 8664/10000 [00:33<00:05, 259.49it/s]Running 10000 simulations.:  87%|████████▋ | 8691/10000 [00:33<00:05, 260.80it/s]Running 10000 simulations.:  87%|████████▋ | 8718/10000 [00:33<00:04, 260.53it/s]Running 10000 simulations.:  87%|████████▋ | 8745/10000 [00:33<00:04, 262.05it/s]Running 10000 simulations.:  88%|████████▊ | 8772/10000 [00:34<00:04, 263.04it/s]Running 10000 simulations.:  88%|████████▊ | 8799/10000 [00:34<00:04, 264.15it/s]Running 10000 simulations.:  88%|████████▊ | 8827/10000 [00:34<00:04, 266.32it/s]Running 10000 simulations.:  89%|████████▊ | 8854/10000 [00:34<00:04, 266.85it/s]Running 10000 simulations.:  89%|████████▉ | 8881/10000 [00:34<00:04, 243.12it/s]Running 10000 simulations.:  89%|████████▉ | 8906/10000 [00:34<00:04, 225.09it/s]Running 10000 simulations.:  89%|████████▉ | 8930/10000 [00:34<00:04, 215.71it/s]Running 10000 simulations.:  90%|████████▉ | 8953/10000 [00:34<00:04, 212.53it/s]Running 10000 simulations.:  90%|████████▉ | 8975/10000 [00:34<00:04, 212.27it/s]Running 10000 simulations.:  90%|████████▉ | 8997/10000 [00:35<00:04, 211.30it/s]Running 10000 simulations.:  90%|█████████ | 9019/10000 [00:35<00:04, 211.64it/s]Running 10000 simulations.:  90%|█████████ | 9041/10000 [00:35<00:04, 211.35it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [00:35<00:04, 212.42it/s]Running 10000 simulations.:  91%|█████████ | 9085/10000 [00:35<00:04, 210.39it/s]Running 10000 simulations.:  91%|█████████ | 9107/10000 [00:35<00:04, 207.81it/s]Running 10000 simulations.:  91%|█████████▏| 9128/10000 [00:35<00:04, 208.43it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [00:35<00:04, 209.80it/s]Running 10000 simulations.:  92%|█████████▏| 9172/10000 [00:35<00:03, 212.34it/s]Running 10000 simulations.:  92%|█████████▏| 9194/10000 [00:35<00:03, 210.38it/s]Running 10000 simulations.:  92%|█████████▏| 9216/10000 [00:36<00:03, 209.64it/s]Running 10000 simulations.:  92%|█████████▏| 9237/10000 [00:36<00:03, 208.78it/s]Running 10000 simulations.:  93%|█████████▎| 9259/10000 [00:36<00:03, 209.76it/s]Running 10000 simulations.:  93%|█████████▎| 9280/10000 [00:36<00:03, 208.12it/s]Running 10000 simulations.:  93%|█████████▎| 9301/10000 [00:36<00:03, 207.91it/s]Running 10000 simulations.:  93%|█████████▎| 9322/10000 [00:36<00:03, 207.35it/s]Running 10000 simulations.:  93%|█████████▎| 9344/10000 [00:36<00:03, 208.17it/s]Running 10000 simulations.:  94%|█████████▎| 9365/10000 [00:36<00:03, 204.72it/s]Running 10000 simulations.:  94%|█████████▍| 9386/10000 [00:36<00:03, 202.24it/s]Running 10000 simulations.:  94%|█████████▍| 9407/10000 [00:37<00:02, 202.18it/s]Running 10000 simulations.:  94%|█████████▍| 9428/10000 [00:37<00:02, 203.36it/s]Running 10000 simulations.:  95%|█████████▍| 9452/10000 [00:37<00:02, 211.22it/s]Running 10000 simulations.:  95%|█████████▍| 9476/10000 [00:37<00:02, 217.38it/s]Running 10000 simulations.:  95%|█████████▌| 9500/10000 [00:37<00:02, 222.34it/s]Running 10000 simulations.:  95%|█████████▌| 9524/10000 [00:37<00:02, 226.11it/s]Running 10000 simulations.:  95%|█████████▌| 9548/10000 [00:37<00:01, 228.21it/s]Running 10000 simulations.:  96%|█████████▌| 9572/10000 [00:37<00:01, 229.95it/s]Running 10000 simulations.:  96%|█████████▌| 9596/10000 [00:37<00:01, 231.11it/s]Running 10000 simulations.:  96%|█████████▌| 9620/10000 [00:37<00:01, 232.78it/s]Running 10000 simulations.:  96%|█████████▋| 9644/10000 [00:38<00:01, 233.70it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [00:38<00:01, 234.01it/s]Running 10000 simulations.:  97%|█████████▋| 9692/10000 [00:38<00:01, 233.66it/s]Running 10000 simulations.:  97%|█████████▋| 9716/10000 [00:38<00:01, 233.58it/s]Running 10000 simulations.:  97%|█████████▋| 9740/10000 [00:38<00:01, 233.82it/s]Running 10000 simulations.:  98%|█████████▊| 9764/10000 [00:38<00:01, 235.00it/s]Running 10000 simulations.:  98%|█████████▊| 9788/10000 [00:38<00:00, 235.37it/s]Running 10000 simulations.:  98%|█████████▊| 9812/10000 [00:38<00:00, 234.61it/s]Running 10000 simulations.:  98%|█████████▊| 9836/10000 [00:38<00:00, 233.78it/s]Running 10000 simulations.:  99%|█████████▊| 9860/10000 [00:38<00:00, 233.85it/s]Running 10000 simulations.:  99%|█████████▉| 9884/10000 [00:39<00:00, 233.99it/s]Running 10000 simulations.:  99%|█████████▉| 9908/10000 [00:39<00:00, 234.53it/s]Running 10000 simulations.:  99%|█████████▉| 9932/10000 [00:39<00:00, 235.47it/s]Running 10000 simulations.: 100%|█████████▉| 9956/10000 [00:39<00:00, 236.47it/s]Running 10000 simulations.: 100%|█████████▉| 9980/10000 [00:39<00:00, 236.29it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:39<00:00, 252.75it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 583569.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58431it [00:00, 565442.26it/s]           Drawing 50000 posterior samples: 58431it [00:00, 562755.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 585813.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627301.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26532/50000 [00:00<00:00, 256047.88it/s]Drawing 50000 posterior samples: 53253it [00:00, 256829.61it/s]                           Drawing 50000 posterior samples: 53253it [00:00, 256680.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52520it [00:00, 472657.46it/s]           Drawing 50000 posterior samples: 52520it [00:00, 470508.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 530214.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 533226.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 539135.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593651.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59989it [00:00, 596778.84it/s]           Drawing 50000 posterior samples: 59989it [00:00, 593784.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 590133.21it/s]           Drawing 50000 posterior samples: 59999it [00:00, 587333.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593052.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 586683.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 588847.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59229it [00:00, 582558.34it/s]           Drawing 50000 posterior samples: 59229it [00:00, 579760.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59893it [00:00, 589603.58it/s]           Drawing 50000 posterior samples: 59893it [00:00, 586385.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593924.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59477it [00:00, 586474.66it/s]           Drawing 50000 posterior samples: 59477it [00:00, 583541.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 583834.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590933.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587961.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 582209.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 580459.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 588284.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 586094.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59837it [00:00, 584573.99it/s]           Drawing 50000 posterior samples: 59837it [00:00, 581952.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 523268.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 530518.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57817it [00:00, 514071.83it/s]           Drawing 50000 posterior samples: 57817it [00:00, 512100.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54959it [00:00, 480844.13it/s]           Drawing 50000 posterior samples: 54959it [00:00, 478320.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52023it [00:00, 515460.92it/s]           Drawing 50000 posterior samples: 52023it [00:00, 512928.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54880it [00:00, 550284.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55038it [00:00, 531942.69it/s]           Drawing 50000 posterior samples: 55038it [00:00, 529497.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51702it [00:00, 506193.74it/s]           Drawing 50000 posterior samples: 51702it [00:00, 503702.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55050it [00:00, 547622.90it/s]           Drawing 50000 posterior samples: 55050it [00:00, 544880.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54920it [00:00, 548576.65it/s]           Drawing 50000 posterior samples: 54920it [00:00, 546004.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55042it [00:00, 568276.46it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55000it [00:00, 583662.38it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54931it [00:00, 586464.61it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54904it [00:00, 535824.71it/s]           Drawing 50000 posterior samples: 54904it [00:00, 533078.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54941it [00:00, 489428.85it/s]           Drawing 50000 posterior samples: 54941it [00:00, 486763.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54913it [00:00, 533658.83it/s]           Drawing 50000 posterior samples: 54913it [00:00, 530993.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54825it [00:00, 538207.02it/s]           Drawing 50000 posterior samples: 54825it [00:00, 535592.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54971it [00:00, 486776.48it/s]           Drawing 50000 posterior samples: 54971it [00:00, 484100.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55014it [00:00, 564197.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54793it [00:00, 568228.96it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54989it [00:00, 568765.29it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54898it [00:00, 556662.29it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54924it [00:00, 562578.34it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54917it [00:00, 543356.48it/s]           Drawing 50000 posterior samples: 54917it [00:00, 540617.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54941it [00:00, 532545.26it/s]           Drawing 50000 posterior samples: 54941it [00:00, 530065.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54963it [00:00, 534785.36it/s]           Drawing 50000 posterior samples: 54963it [00:00, 532105.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54891it [00:00, 542247.33it/s]           Drawing 50000 posterior samples: 54891it [00:00, 539602.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54898it [00:00, 568850.91it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54914it [00:00, 488367.87it/s]           Drawing 50000 posterior samples: 54914it [00:00, 485885.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54032it [00:00, 534781.83it/s]           Drawing 50000 posterior samples: 54032it [00:00, 532044.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54909it [00:00, 547430.34it/s]           Drawing 50000 posterior samples: 54909it [00:00, 544231.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54954it [00:00, 532205.13it/s]           Drawing 50000 posterior samples: 54954it [00:00, 529129.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54992it [00:00, 545689.59it/s]           Drawing 50000 posterior samples: 54992it [00:00, 542841.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55024it [00:00, 534531.97it/s]           Drawing 50000 posterior samples: 55024it [00:00, 531367.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52735it [00:00, 511551.36it/s]           Drawing 50000 posterior samples: 52735it [00:00, 509166.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54982it [00:00, 539249.72it/s]           Drawing 50000 posterior samples: 54982it [00:00, 535694.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54873it [00:00, 530855.61it/s]           Drawing 50000 posterior samples: 54873it [00:00, 528251.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54627it [00:00, 541980.47it/s]           Drawing 50000 posterior samples: 54627it [00:00, 539112.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55007it [00:00, 529617.20it/s]           Drawing 50000 posterior samples: 55007it [00:00, 527114.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54953it [00:00, 539368.89it/s]           Drawing 50000 posterior samples: 54953it [00:00, 536682.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54754it [00:00, 536506.72it/s]           Drawing 50000 posterior samples: 54754it [00:00, 534025.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54800it [00:00, 550351.88it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54832it [00:00, 542170.16it/s]           Drawing 50000 posterior samples: 54832it [00:00, 539265.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54881it [00:00, 538080.47it/s]           Drawing 50000 posterior samples: 54881it [00:00, 535683.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54983it [00:00, 529254.91it/s]           Drawing 50000 posterior samples: 54983it [00:00, 526400.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54860it [00:00, 534789.31it/s]           Drawing 50000 posterior samples: 54860it [00:00, 531852.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55040it [00:00, 540825.22it/s]           Drawing 50000 posterior samples: 55040it [00:00, 538330.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54873it [00:00, 552836.30it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54938it [00:00, 546574.87it/s]           Drawing 50000 posterior samples: 54938it [00:00, 543963.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54785it [00:00, 556068.99it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54997it [00:00, 558811.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54844it [00:00, 550476.12it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54937it [00:00, 550500.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54983it [00:00, 487920.06it/s]           Drawing 50000 posterior samples: 54983it [00:00, 485459.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54951it [00:00, 527992.04it/s]           Drawing 50000 posterior samples: 54951it [00:00, 525169.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54931it [00:00, 540809.56it/s]           Drawing 50000 posterior samples: 54931it [00:00, 538009.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54910it [00:00, 537859.37it/s]           Drawing 50000 posterior samples: 54910it [00:00, 535231.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54870it [00:00, 544118.53it/s]           Drawing 50000 posterior samples: 54870it [00:00, 541505.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54925it [00:00, 535699.35it/s]           Drawing 50000 posterior samples: 54925it [00:00, 533071.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54851it [00:00, 529920.42it/s]           Drawing 50000 posterior samples: 54851it [00:00, 527369.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54817it [00:00, 483699.21it/s]           Drawing 50000 posterior samples: 54817it [00:00, 480822.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54963it [00:00, 474313.48it/s]           Drawing 50000 posterior samples: 54963it [00:00, 471857.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54923it [00:00, 482268.52it/s]           Drawing 50000 posterior samples: 54923it [00:00, 479193.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54973it [00:00, 491104.31it/s]           Drawing 50000 posterior samples: 54973it [00:00, 487209.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54910it [00:00, 567266.91it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54971it [00:00, 554460.25it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54967it [00:00, 552334.55it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52359it [00:00, 525839.64it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54904it [00:00, 558752.04it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54917it [00:00, 557109.50it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54870it [00:00, 566390.52it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54875it [00:00, 558138.67it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54888it [00:00, 552915.70it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54997it [00:00, 557066.84it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54779it [00:00, 557789.86it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54765it [00:00, 552793.21it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54964it [00:00, 564099.76it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54912it [00:00, 547032.45it/s]           Drawing 50000 posterior samples: 54912it [00:00, 544344.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54941it [00:00, 565908.95it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54916it [00:00, 559746.09it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54887it [00:00, 569112.32it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54844it [00:00, 558486.98it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54981it [00:00, 562653.78it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54897it [00:00, 549506.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54903it [00:00, 534478.06it/s]           Drawing 50000 posterior samples: 54903it [00:00, 532088.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54956it [00:00, 551113.62it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54782it [00:00, 566998.97it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55044it [00:00, 568858.62it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54956it [00:00, 543832.15it/s]           Drawing 50000 posterior samples: 54956it [00:00, 541096.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54962it [00:00, 537891.38it/s]           Drawing 50000 posterior samples: 54962it [00:00, 535272.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54843it [00:00, 534879.68it/s]           Drawing 50000 posterior samples: 54843it [00:00, 532349.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54963it [00:00, 535231.11it/s]           Drawing 50000 posterior samples: 54963it [00:00, 532648.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54976it [00:00, 538542.34it/s]           Drawing 50000 posterior samples: 54976it [00:00, 535851.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 576435.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59915it [00:00, 585346.92it/s]           Drawing 50000 posterior samples: 59915it [00:00, 582557.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 579528.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 569013.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52510it [00:00, 502642.59it/s]           Drawing 50000 posterior samples: 52510it [00:00, 500230.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56910it [00:00, 509147.11it/s]           Drawing 50000 posterior samples: 56910it [00:00, 507114.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624276.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 579655.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589601.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587180.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58957it [00:00, 577607.48it/s]           Drawing 50000 posterior samples: 58957it [00:00, 574888.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 577611.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 529120.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 573296.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59992it [00:00, 572130.44it/s]           Drawing 50000 posterior samples: 59992it [00:00, 569558.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58973it [00:00, 555665.68it/s]           Drawing 50000 posterior samples: 58973it [00:00, 552924.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59601it [00:00, 568150.95it/s]           Drawing 50000 posterior samples: 59601it [00:00, 565307.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 573509.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59212it [00:00, 569870.83it/s]           Drawing 50000 posterior samples: 59212it [00:00, 567204.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 569434.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 577160.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 575066.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 577554.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 592330.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 586351.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 583143.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589196.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 619654.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 576150.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53288it [00:00, 524936.93it/s]           Drawing 50000 posterior samples: 53288it [00:00, 522559.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54919it [00:00, 513286.30it/s]           Drawing 50000 posterior samples: 54919it [00:00, 510501.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54966it [00:00, 496565.87it/s]           Drawing 50000 posterior samples: 54966it [00:00, 494267.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54874it [00:00, 574298.68it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54945it [00:00, 502330.20it/s]           Drawing 50000 posterior samples: 54945it [00:00, 500019.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51462it [00:00, 472928.21it/s]           Drawing 50000 posterior samples: 51462it [00:00, 470615.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54929it [00:00, 537771.70it/s]           Drawing 50000 posterior samples: 54929it [00:00, 535105.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54878it [00:00, 538078.73it/s]           Drawing 50000 posterior samples: 54878it [00:00, 535480.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54971it [00:00, 541147.48it/s]           Drawing 50000 posterior samples: 54971it [00:00, 538578.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54927it [00:00, 534013.89it/s]           Drawing 50000 posterior samples: 54927it [00:00, 531548.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54952it [00:00, 541142.07it/s]           Drawing 50000 posterior samples: 54952it [00:00, 538617.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54756it [00:00, 536230.68it/s]           Drawing 50000 posterior samples: 54756it [00:00, 533409.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54810it [00:00, 534260.92it/s]           Drawing 50000 posterior samples: 54810it [00:00, 531917.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54928it [00:00, 538706.25it/s]           Drawing 50000 posterior samples: 54928it [00:00, 536276.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54943it [00:00, 535082.31it/s]           Drawing 50000 posterior samples: 54943it [00:00, 532543.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54955it [00:00, 552075.09it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54890it [00:00, 494138.06it/s]           Drawing 50000 posterior samples: 54890it [00:00, 491939.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54812it [00:00, 496400.99it/s]           Drawing 50000 posterior samples: 54812it [00:00, 493830.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54981it [00:00, 498757.53it/s]           Drawing 50000 posterior samples: 54981it [00:00, 496425.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55034it [00:00, 491856.69it/s]           Drawing 50000 posterior samples: 55034it [00:00, 489601.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54888it [00:00, 546047.63it/s]           Drawing 50000 posterior samples: 54888it [00:00, 543550.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55050it [00:00, 546713.95it/s]           Drawing 50000 posterior samples: 55050it [00:00, 544037.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54876it [00:00, 531518.46it/s]           Drawing 50000 posterior samples: 54876it [00:00, 528977.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54933it [00:00, 545124.76it/s]           Drawing 50000 posterior samples: 54933it [00:00, 542127.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54875it [00:00, 545627.12it/s]           Drawing 50000 posterior samples: 54875it [00:00, 543010.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54689it [00:00, 533777.39it/s]           Drawing 50000 posterior samples: 54689it [00:00, 531525.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54871it [00:00, 546877.30it/s]           Drawing 50000 posterior samples: 54871it [00:00, 543903.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54861it [00:00, 541391.20it/s]           Drawing 50000 posterior samples: 54861it [00:00, 538482.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54894it [00:00, 542025.48it/s]           Drawing 50000 posterior samples: 54894it [00:00, 539429.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54740it [00:00, 543165.84it/s]           Drawing 50000 posterior samples: 54740it [00:00, 540286.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54903it [00:00, 543485.91it/s]           Drawing 50000 posterior samples: 54903it [00:00, 541091.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587882.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59840it [00:00, 589791.97it/s]           Drawing 50000 posterior samples: 59840it [00:00, 587149.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593840.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59885it [00:00, 586392.37it/s]           Drawing 50000 posterior samples: 59885it [00:00, 583348.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57945it [00:00, 579066.74it/s]           Drawing 50000 posterior samples: 57945it [00:00, 576003.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58913it [00:00, 580995.27it/s]           Drawing 50000 posterior samples: 58913it [00:00, 578328.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 594068.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 594191.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 583547.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 592161.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54428it [00:00, 538067.65it/s]           Drawing 50000 posterior samples: 54428it [00:00, 535384.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 585860.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617923.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 539083.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59859it [00:00, 592373.50it/s]           Drawing 50000 posterior samples: 59859it [00:00, 589757.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58156it [00:00, 578742.94it/s]           Drawing 50000 posterior samples: 58156it [00:00, 575623.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59997it [00:00, 594067.15it/s]           Drawing 50000 posterior samples: 59997it [00:00, 591404.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589268.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51979it [00:00, 508140.68it/s]           Drawing 50000 posterior samples: 51979it [00:00, 505765.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616548.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611010.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 631936.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587185.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 581041.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 536497.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 582880.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59870it [00:00, 577215.49it/s]           Drawing 50000 posterior samples: 59870it [00:00, 574447.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 526262.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 600608.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52422it [00:00, 532241.62it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 607986.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57036it [00:00, 576027.01it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598965.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59095it [00:00, 594397.08it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52462it [00:00, 506050.94it/s]           Drawing 50000 posterior samples: 52462it [00:00, 503708.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53261it [00:00, 520455.02it/s]           Drawing 50000 posterior samples: 53261it [00:00, 517949.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 570886.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 588150.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 573333.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 578369.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57171it [00:00, 550499.33it/s]           Drawing 50000 posterior samples: 57171it [00:00, 548038.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 580674.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595007.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 579946.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59334it [00:00, 568362.33it/s]           Drawing 50000 posterior samples: 59334it [00:00, 565702.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55095it [00:00, 533289.90it/s]           Drawing 50000 posterior samples: 55095it [00:00, 530856.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58947it [00:00, 573231.53it/s]           Drawing 50000 posterior samples: 58947it [00:00, 570533.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 580096.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  92%|█████████▏| 46127/50000 [00:00<00:00, 449983.05it/s]Drawing 50000 posterior samples: 53764it [00:00, 446406.24it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 583842.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 567158.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59998it [00:00, 574422.38it/s]           Drawing 50000 posterior samples: 59998it [00:00, 571636.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 544898.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 547765.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 544446.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 581940.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59866it [00:00, 582633.06it/s]           Drawing 50000 posterior samples: 59866it [00:00, 579916.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 572731.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 578098.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52175it [00:00, 504653.19it/s]           Drawing 50000 posterior samples: 52175it [00:00, 502355.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 585477.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57256it [00:00, 561402.89it/s]           Drawing 50000 posterior samples: 57256it [00:00, 558592.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 538161.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58584it [00:00, 563724.62it/s]           Drawing 50000 posterior samples: 58584it [00:00, 560960.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50697it [00:00, 492731.17it/s]           Drawing 50000 posterior samples: 50697it [00:00, 490552.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53965it [00:00, 517839.59it/s]           Drawing 50000 posterior samples: 53965it [00:00, 515457.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 573332.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 577602.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 572127.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 578636.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59059it [00:00, 572368.60it/s]           Drawing 50000 posterior samples: 59059it [00:00, 569490.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608189.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612507.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 606474.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59827it [00:00, 601366.08it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50725it [00:00, 435264.68it/s]           Drawing 50000 posterior samples: 50725it [00:00, 433332.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59866it [00:00, 603974.13it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603240.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56031it [00:00, 565502.70it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609750.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 599277.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 605315.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 600297.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 607547.44it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 604659.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 610850.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59761it [00:00, 600856.74it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587529.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 607866.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  87%|████████▋ | 43342/50000 [00:00<00:00, 431141.51it/s]Drawing 50000 posterior samples: 50687it [00:00, 430373.35it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602706.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57700it [00:00, 586540.59it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603234.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58710it [00:00, 596401.42it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56897it [00:00, 496605.58it/s]           Drawing 50000 posterior samples: 56897it [00:00, 494617.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52973it [00:00, 519326.15it/s]           Drawing 50000 posterior samples: 52973it [00:00, 516912.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 584339.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589195.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590216.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597412.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59355it [00:00, 592722.45it/s]           Drawing 50000 posterior samples: 59355it [00:00, 589952.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596101.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593732.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587967.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59537it [00:00, 593115.08it/s]           Drawing 50000 posterior samples: 59537it [00:00, 590391.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56810it [00:00, 557201.74it/s]           Drawing 50000 posterior samples: 56810it [00:00, 554760.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59049it [00:00, 586248.46it/s]           Drawing 50000 posterior samples: 59049it [00:00, 583307.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59996it [00:00, 601430.34it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58809it [00:00, 587838.29it/s]           Drawing 50000 posterior samples: 58809it [00:00, 585033.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 592255.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598678.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 605953.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618357.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 516394.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 538388.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 525382.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59576it [00:00, 577177.71it/s]           Drawing 50000 posterior samples: 59576it [00:00, 574318.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 570889.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 575934.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  94%|█████████▍| 46917/50000 [00:00<00:00, 448778.90it/s]Drawing 50000 posterior samples: 54680it [00:00, 446637.03it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
30
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Training neural network. Epochs trained:  372Neural network successfully converged after 372 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Neural network successfully converged after 301 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Neural network successfully converged after 241 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Neural network successfully converged after 195 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Training neural network. Epochs trained:  372Training neural network. Epochs trained:  373Training neural network. Epochs trained:  374Training neural network. Epochs trained:  375Training neural network. Epochs trained:  376Training neural network. Epochs trained:  377Training neural network. Epochs trained:  378Training neural network. Epochs trained:  379Training neural network. Epochs trained:  380Training neural network. Epochs trained:  381Training neural network. Epochs trained:  382Training neural network. Epochs trained:  383Training neural network. Epochs trained:  384Training neural network. Epochs trained:  385Training neural network. Epochs trained:  386Training neural network. Epochs trained:  387Training neural network. Epochs trained:  388Training neural network. Epochs trained:  389Training neural network. Epochs trained:  390Training neural network. Epochs trained:  391Training neural network. Epochs trained:  392Training neural network. Epochs trained:  393Training neural network. Epochs trained:  394Training neural network. Epochs trained:  395Training neural network. Epochs trained:  396Training neural network. Epochs trained:  397Training neural network. Epochs trained:  398Training neural network. Epochs trained:  399Training neural network. Epochs trained:  400Training neural network. Epochs trained:  401Training neural network. Epochs trained:  402Neural network successfully converged after 402 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Neural network successfully converged after 204 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Neural network successfully converged after 295 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Neural network successfully converged after 195 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Neural network successfully converged after 173 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Neural network successfully converged after 244 epochs.
log prob true 6.76157
log prob true 6.209161
log prob true 6.5737724
log prob true 6.413316
log prob true 6.5866485
log prob true 6.0879545
log prob true 5.8975983
log prob true 6.616726
log prob true 6.285284
log prob true 6.3844557
log prob true 6.2601533
log prob true 6.2310395
log prob true 6.922243
log prob true 6.452678
log prob true 6.1914897
log prob true 5.7485
log prob true 5.9809556
log prob true 6.340167
log prob true 6.083999
log prob true 6.533317
log prob true 6.7489624
log prob true 6.4041557
log prob true 6.6378045
log prob true 6.1940556
log prob true 6.589265
log prob true 6.2793345
log prob true 5.9081287
log prob true 6.170516
log prob true 6.4769974
log prob true 6.208636
log prob true 4.4120073
log prob true 3.8151317
log prob true 4.123791
log prob true 2.9816296
log prob true 3.1120067
log prob true 3.2208405
log prob true 3.5739856
log prob true 4.173583
log prob true 3.6591516
log prob true 3.9828281
log prob true 3.316405
log prob true 3.9758801
log prob true 4.327757
log prob true 4.114422
log prob true 3.3048718
log prob true 2.8970175
log prob true 3.639058
log prob true 4.1078086
log prob true 3.296447
log prob true 4.1755767
log prob true 3.8332562
log prob true 3.7331154
log prob true 4.293616
log prob true 3.6297233
log prob true 3.8628674
log prob true 3.9339159
log prob true 3.0379062
log prob true 3.5807545
log prob true 4.259604
log prob true 2.9898355
log prob true 4.2467027
log prob true 3.7121735
log prob true 4.304438
log prob true 3.4890645
log prob true 3.4261706
log prob true 3.238873
log prob true 3.7604642
log prob true 4.300541
log prob true 3.8714714
log prob true 3.8549702
log prob true 3.3515372
log prob true 4.0513268
log prob true 4.503093
log prob true 3.9035099
log prob true 3.5165813
log prob true 3.184126
log prob true 3.8949673
log prob true 4.1709437
log prob true 3.231545
log prob true 4.415549
log prob true 4.1573443
log prob true 3.9018261
log prob true 4.4665103
log prob true 3.8077927
log prob true 4.356133
log prob true 4.2504463
log prob true 3.0286624
log prob true 3.8275692
log prob true 4.321264
log prob true 2.7217927
log prob true 4.548117
log prob true 4.138378
log prob true 3.8750863
log prob true 3.2458386
log prob true 3.2857277
log prob true 2.9793134
log prob true 3.7255971
log prob true 4.276756
log prob true 3.7807882
log prob true 3.8965812
log prob true 3.2633777
log prob true 4.231295
log prob true 4.549582
log prob true 4.1948385
log prob true 3.0929008
log prob true 3.1439316
log prob true 3.7707837
log prob true 4.118043
log prob true 3.0206125
log prob true 4.3293834
log prob true 3.929039
log prob true 3.8528707
log prob true 4.0941095
log prob true 3.9327333
log prob true 4.3459396
log prob true 4.132984
log prob true 3.3466902
log prob true 3.6842427
log prob true 4.0406365
log prob true 3.103921
log prob true 6.970543
log prob true 6.539541
log prob true 6.7963004
log prob true 6.622433
log prob true 5.4322686
log prob true 6.5183287
log prob true 6.290653
log prob true 6.734091
log prob true 6.4753237
log prob true 6.677124
log prob true 6.473281
log prob true 6.741238
log prob true 7.1974134
log prob true 6.775374
log prob true 6.242665
log prob true 5.5590515
log prob true 5.49231
log prob true 6.239075
log prob true 6.335971
log prob true 6.8834653
log prob true 7.064906
log prob true 6.445772
log prob true 6.860187
log prob true 6.1289363
log prob true 6.6896653
log prob true 6.732338
log prob true 5.8701777
log prob true 6.2126856
log prob true 6.763061
log prob true 6.2790303
log prob true 4.339572
log prob true 3.921316
log prob true 4.1927824
log prob true 3.2251062
log prob true 2.9852252
log prob true 2.8695223
log prob true 3.6006536
log prob true 4.142525
log prob true 3.637548
log prob true 3.9910083
log prob true 3.3845537
log prob true 4.123535
log prob true 4.2197995
log prob true 4.0806212
log prob true 3.3586795
log prob true 2.7968187
log prob true 3.4081
log prob true 3.763126
log prob true 2.8760798
log prob true 4.2412853
log prob true 3.9831593
log prob true 3.6494005
log prob true 4.197941
log prob true 3.8353717
log prob true 3.9946594
log prob true 4.018743
log prob true 3.212582
log prob true 3.6081486
log prob true 3.9415283
log prob true 2.9301226
log prob true 6.703721
log prob true 6.19111
log prob true 6.41115
log prob true 6.169864
log prob true 5.518584
log prob true 4.8653216
log prob true 6.259898
log prob true 6.3858523
log prob true 6.195727
log prob true 6.1810374
log prob true 5.831037
log prob true 6.470009
log prob true 6.1845284
log prob true 6.470431
log prob true 6.0165496
log prob true 5.7702928
log prob true 6.0472426
log prob true 5.9742665
log prob true 5.8780346
log prob true 6.6090865
log prob true 6.23653
log prob true 5.5526037
log prob true 6.6035213
log prob true 5.937654
log prob true 6.397204
log prob true 6.487839
log prob true 5.5099115
log prob true 5.9563546
log prob true 6.4368625
log prob true 5.846194
log prob true 5.9662066
log prob true 5.730316
log prob true 6.0633626
log prob true 5.5727143
log prob true 4.8287125
log prob true 5.3764014
log prob true 5.4550323
log prob true 5.8020463
log prob true 5.5320816
log prob true 5.567552
log prob true 5.491494
log prob true 5.616159
log prob true 6.2334833
log prob true 5.9337187
log prob true 5.3204165
log prob true 5.1362605
log prob true 5.272851
log prob true 5.728348
log prob true 5.681549
log prob true 5.516671
log prob true 5.907149
log prob true 5.7306094
log prob true 6.048715
log prob true 5.474253
log prob true 5.9108734
log prob true 5.65108
log prob true 5.2135344
log prob true 5.407049
log prob true 5.975525
log prob true 5.087716
log prob true 6.154746
log prob true 5.6881456
log prob true 5.7279286
log prob true 5.582222
log prob true 5.0186214
log prob true 5.509844
log prob true 5.439928
log prob true 5.870008
log prob true 5.5633183
log prob true 5.826748
log prob true 5.5217757
log prob true 5.784699
log prob true 6.3706794
log prob true 5.856157
log prob true 5.3016295
log prob true 5.1416407
log prob true 5.158407
log prob true 5.7385273
log prob true 5.4107246
log prob true 6.0093036
log prob true 5.8160367
log prob true 5.8064904
log prob true 5.7230287
log prob true 5.5483737
log prob true 5.999147
log prob true 5.519969
log prob true 5.1755776
log prob true 5.521951
log prob true 5.896019
log prob true 5.59361
log prob true 6.3210654
log prob true 5.831518
log prob true 6.0611243
log prob true 5.528139
log prob true 5.2696896
log prob true 5.6949534
log prob true 5.462695
log prob true 6.084492
log prob true 5.5284963
log prob true 6.127705
log prob true 5.897839
log prob true 5.8338013
log prob true 6.299835
log prob true 5.9482636
log prob true 5.480462
log prob true 5.5432677
log prob true 5.8564043
log prob true 5.853095
log prob true 5.222714
log prob true 6.064781
log prob true 6.104079
log prob true 6.061001
log prob true 6.3743353
log prob true 5.7791324
log prob true 6.131817
log prob true 5.7509794
log prob true 5.407954
log prob true 5.8127255
log prob true 6.2376423
log prob true 5.610522
script complete
