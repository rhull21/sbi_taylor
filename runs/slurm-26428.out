Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 16/10000 [00:00<01:06, 150.81it/s]Running 10000 simulations.:   0%|          | 32/10000 [00:00<01:06, 150.72it/s]Running 10000 simulations.:   0%|          | 48/10000 [00:00<01:06, 150.71it/s]Running 10000 simulations.:   1%|          | 63/10000 [00:00<01:06, 150.29it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<01:06, 149.19it/s]Running 10000 simulations.:   1%|          | 93/10000 [00:00<01:06, 147.96it/s]Running 10000 simulations.:   1%|          | 108/10000 [00:00<01:07, 146.80it/s]Running 10000 simulations.:   1%|          | 123/10000 [00:00<01:07, 145.39it/s]Running 10000 simulations.:   1%|▏         | 138/10000 [00:00<01:08, 144.81it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:01<01:08, 144.20it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:01<01:08, 143.30it/s]Running 10000 simulations.:   2%|▏         | 183/10000 [00:01<01:08, 144.03it/s]Running 10000 simulations.:   2%|▏         | 198/10000 [00:01<01:08, 143.27it/s]Running 10000 simulations.:   2%|▏         | 213/10000 [00:01<01:08, 142.11it/s]Running 10000 simulations.:   2%|▏         | 228/10000 [00:01<01:09, 141.44it/s]Running 10000 simulations.:   2%|▏         | 243/10000 [00:01<01:09, 139.99it/s]Running 10000 simulations.:   3%|▎         | 257/10000 [00:01<01:10, 138.72it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<01:09, 140.29it/s]Running 10000 simulations.:   3%|▎         | 287/10000 [00:01<01:08, 141.58it/s]Running 10000 simulations.:   3%|▎         | 302/10000 [00:02<01:08, 142.57it/s]Running 10000 simulations.:   3%|▎         | 317/10000 [00:02<01:08, 142.33it/s]Running 10000 simulations.:   3%|▎         | 332/10000 [00:02<01:08, 141.80it/s]Running 10000 simulations.:   3%|▎         | 347/10000 [00:02<01:08, 141.82it/s]Running 10000 simulations.:   4%|▎         | 362/10000 [00:02<01:07, 142.10it/s]Running 10000 simulations.:   4%|▍         | 377/10000 [00:02<01:07, 142.40it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:02<01:07, 142.60it/s]Running 10000 simulations.:   4%|▍         | 407/10000 [00:02<01:07, 142.21it/s]Running 10000 simulations.:   4%|▍         | 422/10000 [00:02<01:07, 142.74it/s]Running 10000 simulations.:   4%|▍         | 437/10000 [00:03<01:07, 142.46it/s]Running 10000 simulations.:   5%|▍         | 452/10000 [00:03<01:07, 142.16it/s]Running 10000 simulations.:   5%|▍         | 467/10000 [00:03<01:07, 142.11it/s]Running 10000 simulations.:   5%|▍         | 482/10000 [00:03<01:07, 141.90it/s]Running 10000 simulations.:   5%|▍         | 497/10000 [00:03<01:07, 141.75it/s]Running 10000 simulations.:   5%|▌         | 512/10000 [00:03<01:06, 142.19it/s]Running 10000 simulations.:   5%|▌         | 527/10000 [00:03<01:06, 142.12it/s]Running 10000 simulations.:   5%|▌         | 542/10000 [00:03<01:07, 141.03it/s]Running 10000 simulations.:   6%|▌         | 557/10000 [00:03<01:06, 141.09it/s]Running 10000 simulations.:   6%|▌         | 572/10000 [00:04<01:06, 140.91it/s]Running 10000 simulations.:   6%|▌         | 587/10000 [00:04<01:06, 140.78it/s]Running 10000 simulations.:   6%|▌         | 602/10000 [00:04<01:06, 141.48it/s]Running 10000 simulations.:   6%|▌         | 617/10000 [00:04<01:06, 142.05it/s]Running 10000 simulations.:   6%|▋         | 632/10000 [00:04<01:05, 142.15it/s]Running 10000 simulations.:   6%|▋         | 647/10000 [00:04<01:06, 141.53it/s]Running 10000 simulations.:   7%|▋         | 662/10000 [00:04<01:06, 141.07it/s]Running 10000 simulations.:   7%|▋         | 677/10000 [00:04<01:06, 140.59it/s]Running 10000 simulations.:   7%|▋         | 692/10000 [00:04<01:06, 140.94it/s]Running 10000 simulations.:   7%|▋         | 707/10000 [00:04<01:05, 140.97it/s]Running 10000 simulations.:   7%|▋         | 722/10000 [00:05<01:05, 140.64it/s]Running 10000 simulations.:   7%|▋         | 737/10000 [00:05<01:05, 141.04it/s]Running 10000 simulations.:   8%|▊         | 752/10000 [00:05<01:05, 140.81it/s]Running 10000 simulations.:   8%|▊         | 767/10000 [00:05<01:05, 141.13it/s]Running 10000 simulations.:   8%|▊         | 782/10000 [00:05<01:05, 141.37it/s]Running 10000 simulations.:   8%|▊         | 797/10000 [00:05<01:05, 140.67it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:05<01:05, 140.66it/s]Running 10000 simulations.:   8%|▊         | 827/10000 [00:05<01:04, 141.46it/s]Running 10000 simulations.:   8%|▊         | 842/10000 [00:05<01:04, 141.60it/s]Running 10000 simulations.:   9%|▊         | 857/10000 [00:06<01:04, 141.19it/s]Running 10000 simulations.:   9%|▊         | 872/10000 [00:06<01:04, 141.12it/s]Running 10000 simulations.:   9%|▉         | 887/10000 [00:06<01:04, 140.97it/s]Running 10000 simulations.:   9%|▉         | 902/10000 [00:06<01:06, 136.66it/s]Running 10000 simulations.:   9%|▉         | 916/10000 [00:06<01:06, 137.16it/s]Running 10000 simulations.:   9%|▉         | 930/10000 [00:06<01:05, 137.82it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:06<01:05, 138.13it/s]Running 10000 simulations.:  10%|▉         | 958/10000 [00:06<01:05, 138.38it/s]Running 10000 simulations.:  10%|▉         | 972/10000 [00:06<01:05, 138.34it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:06<01:05, 138.25it/s]Running 10000 simulations.:  10%|█         | 1000/10000 [00:07<01:04, 138.73it/s]Running 10000 simulations.:  10%|█         | 1014/10000 [00:07<01:04, 139.02it/s]Running 10000 simulations.:  10%|█         | 1028/10000 [00:07<01:04, 138.25it/s]Running 10000 simulations.:  10%|█         | 1042/10000 [00:07<01:04, 138.30it/s]Running 10000 simulations.:  11%|█         | 1057/10000 [00:07<01:04, 139.48it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:07<01:03, 140.06it/s]Running 10000 simulations.:  11%|█         | 1087/10000 [00:07<01:03, 140.48it/s]Running 10000 simulations.:  11%|█         | 1102/10000 [00:07<01:03, 140.27it/s]Running 10000 simulations.:  11%|█         | 1117/10000 [00:07<01:03, 140.20it/s]Running 10000 simulations.:  11%|█▏        | 1132/10000 [00:08<01:03, 140.31it/s]Running 10000 simulations.:  11%|█▏        | 1147/10000 [00:08<01:03, 139.85it/s]Running 10000 simulations.:  12%|█▏        | 1161/10000 [00:08<01:03, 139.67it/s]Running 10000 simulations.:  12%|█▏        | 1175/10000 [00:08<01:03, 139.23it/s]Running 10000 simulations.:  12%|█▏        | 1190/10000 [00:08<01:03, 139.84it/s]Running 10000 simulations.:  12%|█▏        | 1205/10000 [00:08<01:02, 140.41it/s]Running 10000 simulations.:  12%|█▏        | 1220/10000 [00:08<01:02, 140.49it/s]Running 10000 simulations.:  12%|█▏        | 1235/10000 [00:08<01:02, 140.17it/s]Running 10000 simulations.:  12%|█▎        | 1250/10000 [00:08<01:02, 140.94it/s]Running 10000 simulations.:  13%|█▎        | 1265/10000 [00:08<01:01, 141.07it/s]Running 10000 simulations.:  13%|█▎        | 1280/10000 [00:09<01:01, 141.08it/s]Running 10000 simulations.:  13%|█▎        | 1295/10000 [00:09<01:01, 141.45it/s]Running 10000 simulations.:  13%|█▎        | 1310/10000 [00:09<01:01, 141.62it/s]Running 10000 simulations.:  13%|█▎        | 1325/10000 [00:09<01:01, 141.21it/s]Running 10000 simulations.:  13%|█▎        | 1340/10000 [00:09<01:01, 141.27it/s]Running 10000 simulations.:  14%|█▎        | 1355/10000 [00:09<01:00, 141.89it/s]Running 10000 simulations.:  14%|█▎        | 1370/10000 [00:09<01:00, 142.55it/s]Running 10000 simulations.:  14%|█▍        | 1385/10000 [00:09<01:00, 142.92it/s]Running 10000 simulations.:  14%|█▍        | 1400/10000 [00:09<01:00, 141.60it/s]Running 10000 simulations.:  14%|█▍        | 1415/10000 [00:10<01:00, 142.08it/s]Running 10000 simulations.:  14%|█▍        | 1430/10000 [00:10<01:00, 141.71it/s]Running 10000 simulations.:  14%|█▍        | 1445/10000 [00:10<01:00, 141.92it/s]Running 10000 simulations.:  15%|█▍        | 1460/10000 [00:10<01:00, 141.67it/s]Running 10000 simulations.:  15%|█▍        | 1475/10000 [00:10<00:59, 142.21it/s]Running 10000 simulations.:  15%|█▍        | 1490/10000 [00:10<00:59, 142.97it/s]Running 10000 simulations.:  15%|█▌        | 1505/10000 [00:10<00:59, 142.14it/s]Running 10000 simulations.:  15%|█▌        | 1520/10000 [00:10<00:59, 141.87it/s]Running 10000 simulations.:  15%|█▌        | 1535/10000 [00:10<00:59, 141.91it/s]Running 10000 simulations.:  16%|█▌        | 1550/10000 [00:10<00:59, 141.91it/s]Running 10000 simulations.:  16%|█▌        | 1565/10000 [00:11<00:59, 142.26it/s]Running 10000 simulations.:  16%|█▌        | 1580/10000 [00:11<00:59, 142.62it/s]Running 10000 simulations.:  16%|█▌        | 1595/10000 [00:11<00:58, 142.61it/s]Running 10000 simulations.:  16%|█▌        | 1610/10000 [00:11<00:58, 142.52it/s]Running 10000 simulations.:  16%|█▋        | 1625/10000 [00:11<00:58, 142.21it/s]Running 10000 simulations.:  16%|█▋        | 1640/10000 [00:11<00:58, 142.24it/s]Running 10000 simulations.:  17%|█▋        | 1655/10000 [00:11<00:58, 142.23it/s]Running 10000 simulations.:  17%|█▋        | 1670/10000 [00:11<00:58, 142.33it/s]Running 10000 simulations.:  17%|█▋        | 1685/10000 [00:11<00:58, 142.14it/s]Running 10000 simulations.:  17%|█▋        | 1700/10000 [00:12<00:58, 142.34it/s]Running 10000 simulations.:  17%|█▋        | 1715/10000 [00:12<00:58, 141.86it/s]Running 10000 simulations.:  17%|█▋        | 1730/10000 [00:12<00:58, 141.88it/s]Running 10000 simulations.:  17%|█▋        | 1746/10000 [00:12<00:56, 145.43it/s]Running 10000 simulations.:  18%|█▊        | 1762/10000 [00:12<00:55, 148.99it/s]Running 10000 simulations.:  18%|█▊        | 1777/10000 [00:12<00:55, 148.90it/s]Running 10000 simulations.:  18%|█▊        | 1792/10000 [00:12<00:56, 146.03it/s]Running 10000 simulations.:  18%|█▊        | 1807/10000 [00:12<00:56, 145.30it/s]Running 10000 simulations.:  18%|█▊        | 1822/10000 [00:12<00:56, 144.78it/s]Running 10000 simulations.:  18%|█▊        | 1837/10000 [00:12<00:56, 144.57it/s]Running 10000 simulations.:  19%|█▊        | 1852/10000 [00:13<00:56, 144.35it/s]Running 10000 simulations.:  19%|█▊        | 1867/10000 [00:13<00:56, 144.23it/s]Running 10000 simulations.:  19%|█▉        | 1882/10000 [00:13<00:56, 144.41it/s]Running 10000 simulations.:  19%|█▉        | 1897/10000 [00:13<00:56, 144.26it/s]Running 10000 simulations.:  19%|█▉        | 1912/10000 [00:13<00:56, 144.37it/s]Running 10000 simulations.:  19%|█▉        | 1927/10000 [00:13<00:56, 144.11it/s]Running 10000 simulations.:  19%|█▉        | 1942/10000 [00:13<00:55, 144.34it/s]Running 10000 simulations.:  20%|█▉        | 1957/10000 [00:13<00:55, 144.08it/s]Running 10000 simulations.:  20%|█▉        | 1972/10000 [00:13<00:55, 144.19it/s]Running 10000 simulations.:  20%|█▉        | 1987/10000 [00:13<00:55, 144.23it/s]Running 10000 simulations.:  20%|██        | 2002/10000 [00:14<00:55, 144.30it/s]Running 10000 simulations.:  20%|██        | 2017/10000 [00:14<00:55, 144.13it/s]Running 10000 simulations.:  20%|██        | 2032/10000 [00:14<00:55, 143.68it/s]Running 10000 simulations.:  20%|██        | 2047/10000 [00:14<00:55, 142.96it/s]Running 10000 simulations.:  21%|██        | 2062/10000 [00:14<00:55, 142.86it/s]Running 10000 simulations.:  21%|██        | 2077/10000 [00:14<00:55, 142.99it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:14<00:55, 142.78it/s]Running 10000 simulations.:  21%|██        | 2107/10000 [00:14<00:55, 142.91it/s]Running 10000 simulations.:  21%|██        | 2122/10000 [00:14<00:55, 142.75it/s]Running 10000 simulations.:  21%|██▏       | 2137/10000 [00:15<00:55, 142.64it/s]Running 10000 simulations.:  22%|██▏       | 2152/10000 [00:15<00:55, 142.36it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:15<00:54, 142.48it/s]Running 10000 simulations.:  22%|██▏       | 2182/10000 [00:15<00:54, 142.24it/s]Running 10000 simulations.:  22%|██▏       | 2197/10000 [00:15<00:55, 141.87it/s]Running 10000 simulations.:  22%|██▏       | 2212/10000 [00:15<00:54, 142.39it/s]Running 10000 simulations.:  22%|██▏       | 2227/10000 [00:15<00:54, 142.37it/s]Running 10000 simulations.:  22%|██▏       | 2242/10000 [00:15<00:54, 142.20it/s]Running 10000 simulations.:  23%|██▎       | 2257/10000 [00:15<00:54, 142.62it/s]Running 10000 simulations.:  23%|██▎       | 2272/10000 [00:15<00:54, 142.66it/s]Running 10000 simulations.:  23%|██▎       | 2287/10000 [00:16<00:54, 141.81it/s]Running 10000 simulations.:  23%|██▎       | 2302/10000 [00:16<00:54, 141.59it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:16<00:53, 142.33it/s]Running 10000 simulations.:  23%|██▎       | 2332/10000 [00:16<00:53, 142.24it/s]Running 10000 simulations.:  23%|██▎       | 2347/10000 [00:16<00:53, 142.64it/s]Running 10000 simulations.:  24%|██▎       | 2362/10000 [00:16<00:53, 142.47it/s]Running 10000 simulations.:  24%|██▍       | 2377/10000 [00:16<00:53, 142.63it/s]Running 10000 simulations.:  24%|██▍       | 2392/10000 [00:16<00:53, 143.02it/s]Running 10000 simulations.:  24%|██▍       | 2407/10000 [00:16<00:53, 142.97it/s]Running 10000 simulations.:  24%|██▍       | 2422/10000 [00:17<00:54, 139.56it/s]Running 10000 simulations.:  24%|██▍       | 2436/10000 [00:17<00:54, 137.73it/s]Running 10000 simulations.:  24%|██▍       | 2450/10000 [00:17<00:55, 135.11it/s]Running 10000 simulations.:  25%|██▍       | 2464/10000 [00:17<00:56, 133.35it/s]Running 10000 simulations.:  25%|██▍       | 2478/10000 [00:17<00:56, 132.35it/s]Running 10000 simulations.:  25%|██▍       | 2492/10000 [00:17<00:56, 131.98it/s]Running 10000 simulations.:  25%|██▌       | 2506/10000 [00:17<00:57, 130.86it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:17<00:57, 130.44it/s]Running 10000 simulations.:  25%|██▌       | 2534/10000 [00:17<00:57, 129.30it/s]Running 10000 simulations.:  25%|██▌       | 2547/10000 [00:18<00:57, 129.19it/s]Running 10000 simulations.:  26%|██▌       | 2560/10000 [00:18<00:57, 129.13it/s]Running 10000 simulations.:  26%|██▌       | 2573/10000 [00:18<00:57, 128.96it/s]Running 10000 simulations.:  26%|██▌       | 2586/10000 [00:18<00:57, 128.42it/s]Running 10000 simulations.:  26%|██▌       | 2599/10000 [00:18<00:57, 128.44it/s]Running 10000 simulations.:  26%|██▌       | 2612/10000 [00:18<00:57, 128.04it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:18<00:57, 127.96it/s]Running 10000 simulations.:  26%|██▋       | 2638/10000 [00:18<00:58, 126.38it/s]Running 10000 simulations.:  27%|██▋       | 2651/10000 [00:18<00:57, 126.73it/s]Running 10000 simulations.:  27%|██▋       | 2664/10000 [00:18<00:57, 127.21it/s]Running 10000 simulations.:  27%|██▋       | 2678/10000 [00:19<00:56, 128.88it/s]Running 10000 simulations.:  27%|██▋       | 2693/10000 [00:19<00:55, 132.29it/s]Running 10000 simulations.:  27%|██▋       | 2708/10000 [00:19<00:54, 134.77it/s]Running 10000 simulations.:  27%|██▋       | 2722/10000 [00:19<00:53, 136.18it/s]Running 10000 simulations.:  27%|██▋       | 2736/10000 [00:19<00:52, 137.12it/s]Running 10000 simulations.:  28%|██▊       | 2751/10000 [00:19<00:52, 138.18it/s]Running 10000 simulations.:  28%|██▊       | 2766/10000 [00:19<00:52, 138.99it/s]Running 10000 simulations.:  28%|██▊       | 2781/10000 [00:19<00:51, 139.39it/s]Running 10000 simulations.:  28%|██▊       | 2795/10000 [00:19<00:51, 139.57it/s]Running 10000 simulations.:  28%|██▊       | 2810/10000 [00:19<00:51, 139.61it/s]Running 10000 simulations.:  28%|██▊       | 2824/10000 [00:20<00:51, 138.78it/s]Running 10000 simulations.:  28%|██▊       | 2838/10000 [00:20<00:51, 137.92it/s]Running 10000 simulations.:  29%|██▊       | 2852/10000 [00:20<00:51, 137.95it/s]Running 10000 simulations.:  29%|██▊       | 2867/10000 [00:20<00:51, 138.65it/s]Running 10000 simulations.:  29%|██▉       | 2882/10000 [00:20<00:51, 139.27it/s]Running 10000 simulations.:  29%|██▉       | 2897/10000 [00:20<00:50, 139.96it/s]Running 10000 simulations.:  29%|██▉       | 2911/10000 [00:20<00:50, 139.96it/s]Running 10000 simulations.:  29%|██▉       | 2925/10000 [00:20<00:50, 139.77it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:20<00:50, 140.28it/s]Running 10000 simulations.:  30%|██▉       | 2955/10000 [00:21<00:50, 140.15it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:21<00:50, 140.16it/s]Running 10000 simulations.:  30%|██▉       | 2985/10000 [00:21<00:50, 139.55it/s]Running 10000 simulations.:  30%|██▉       | 2999/10000 [00:21<00:50, 139.57it/s]Running 10000 simulations.:  30%|███       | 3013/10000 [00:21<00:50, 139.38it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:21<00:49, 139.73it/s]Running 10000 simulations.:  30%|███       | 3042/10000 [00:21<00:49, 139.48it/s]Running 10000 simulations.:  31%|███       | 3056/10000 [00:21<00:49, 139.59it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:21<00:49, 140.07it/s]Running 10000 simulations.:  31%|███       | 3086/10000 [00:21<00:49, 140.24it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:22<00:49, 140.06it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:22<00:49, 140.17it/s]Running 10000 simulations.:  31%|███▏      | 3131/10000 [00:22<00:48, 140.29it/s]Running 10000 simulations.:  31%|███▏      | 3146/10000 [00:22<00:48, 140.77it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:22<00:48, 140.59it/s]Running 10000 simulations.:  32%|███▏      | 3176/10000 [00:22<00:48, 140.87it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:22<00:48, 141.33it/s]Running 10000 simulations.:  32%|███▏      | 3206/10000 [00:22<00:47, 141.65it/s]Running 10000 simulations.:  32%|███▏      | 3221/10000 [00:22<00:47, 141.43it/s]Running 10000 simulations.:  32%|███▏      | 3236/10000 [00:23<00:48, 140.78it/s]Running 10000 simulations.:  33%|███▎      | 3251/10000 [00:23<00:48, 140.42it/s]Running 10000 simulations.:  33%|███▎      | 3266/10000 [00:23<00:48, 139.77it/s]Running 10000 simulations.:  33%|███▎      | 3280/10000 [00:23<00:48, 139.07it/s]Running 10000 simulations.:  33%|███▎      | 3294/10000 [00:23<00:48, 139.01it/s]Running 10000 simulations.:  33%|███▎      | 3308/10000 [00:23<00:48, 139.05it/s]Running 10000 simulations.:  33%|███▎      | 3323/10000 [00:23<00:47, 139.93it/s]Running 10000 simulations.:  33%|███▎      | 3338/10000 [00:23<00:47, 140.14it/s]Running 10000 simulations.:  34%|███▎      | 3353/10000 [00:23<00:47, 139.86it/s]Running 10000 simulations.:  34%|███▎      | 3368/10000 [00:23<00:47, 139.95it/s]Running 10000 simulations.:  34%|███▍      | 3383/10000 [00:24<00:47, 140.11it/s]Running 10000 simulations.:  34%|███▍      | 3398/10000 [00:24<00:47, 139.79it/s]Running 10000 simulations.:  34%|███▍      | 3413/10000 [00:24<00:47, 140.01it/s]Running 10000 simulations.:  34%|███▍      | 3428/10000 [00:24<00:46, 139.86it/s]Running 10000 simulations.:  34%|███▍      | 3443/10000 [00:24<00:46, 140.33it/s]Running 10000 simulations.:  35%|███▍      | 3458/10000 [00:24<00:46, 140.47it/s]Running 10000 simulations.:  35%|███▍      | 3473/10000 [00:24<00:46, 140.37it/s]Running 10000 simulations.:  35%|███▍      | 3488/10000 [00:24<00:46, 140.25it/s]Running 10000 simulations.:  35%|███▌      | 3503/10000 [00:24<00:46, 140.21it/s]Running 10000 simulations.:  35%|███▌      | 3518/10000 [00:25<00:46, 140.44it/s]Running 10000 simulations.:  35%|███▌      | 3533/10000 [00:25<00:45, 140.75it/s]Running 10000 simulations.:  35%|███▌      | 3548/10000 [00:25<00:45, 140.79it/s]Running 10000 simulations.:  36%|███▌      | 3563/10000 [00:25<00:46, 139.92it/s]Running 10000 simulations.:  36%|███▌      | 3578/10000 [00:25<00:45, 140.10it/s]Running 10000 simulations.:  36%|███▌      | 3593/10000 [00:25<00:45, 140.07it/s]Running 10000 simulations.:  36%|███▌      | 3608/10000 [00:25<00:48, 132.50it/s]Running 10000 simulations.:  36%|███▌      | 3623/10000 [00:25<00:47, 134.91it/s]Running 10000 simulations.:  36%|███▋      | 3638/10000 [00:25<00:46, 136.70it/s]Running 10000 simulations.:  37%|███▋      | 3653/10000 [00:26<00:46, 137.80it/s]Running 10000 simulations.:  37%|███▋      | 3667/10000 [00:26<00:45, 138.05it/s]Running 10000 simulations.:  37%|███▋      | 3682/10000 [00:26<00:45, 138.79it/s]Running 10000 simulations.:  37%|███▋      | 3697/10000 [00:26<00:45, 139.35it/s]Running 10000 simulations.:  37%|███▋      | 3712/10000 [00:26<00:44, 139.91it/s]Running 10000 simulations.:  37%|███▋      | 3727/10000 [00:26<00:44, 140.58it/s]Running 10000 simulations.:  37%|███▋      | 3742/10000 [00:26<00:44, 140.75it/s]Running 10000 simulations.:  38%|███▊      | 3757/10000 [00:26<00:44, 140.79it/s]Running 10000 simulations.:  38%|███▊      | 3772/10000 [00:26<00:44, 140.59it/s]Running 10000 simulations.:  38%|███▊      | 3787/10000 [00:26<00:44, 140.25it/s]Running 10000 simulations.:  38%|███▊      | 3802/10000 [00:27<00:44, 140.44it/s]Running 10000 simulations.:  38%|███▊      | 3817/10000 [00:27<00:44, 140.35it/s]Running 10000 simulations.:  38%|███▊      | 3832/10000 [00:27<00:44, 140.01it/s]Running 10000 simulations.:  38%|███▊      | 3847/10000 [00:27<00:43, 140.93it/s]Running 10000 simulations.:  39%|███▊      | 3862/10000 [00:27<00:43, 141.21it/s]Running 10000 simulations.:  39%|███▉      | 3877/10000 [00:27<00:43, 141.60it/s]Running 10000 simulations.:  39%|███▉      | 3892/10000 [00:27<00:43, 141.96it/s]Running 10000 simulations.:  39%|███▉      | 3907/10000 [00:27<00:43, 141.20it/s]Running 10000 simulations.:  39%|███▉      | 3922/10000 [00:27<00:42, 141.42it/s]Running 10000 simulations.:  39%|███▉      | 3937/10000 [00:28<00:42, 141.60it/s]Running 10000 simulations.:  40%|███▉      | 3952/10000 [00:28<00:43, 140.58it/s]Running 10000 simulations.:  40%|███▉      | 3967/10000 [00:28<00:43, 139.91it/s]Running 10000 simulations.:  40%|███▉      | 3982/10000 [00:28<00:42, 140.43it/s]Running 10000 simulations.:  40%|███▉      | 3997/10000 [00:28<00:42, 140.71it/s]Running 10000 simulations.:  40%|████      | 4012/10000 [00:28<00:42, 140.50it/s]Running 10000 simulations.:  40%|████      | 4027/10000 [00:28<00:42, 140.37it/s]Running 10000 simulations.:  40%|████      | 4042/10000 [00:28<00:42, 140.32it/s]Running 10000 simulations.:  41%|████      | 4057/10000 [00:28<00:42, 140.24it/s]Running 10000 simulations.:  41%|████      | 4072/10000 [00:28<00:42, 140.30it/s]Running 10000 simulations.:  41%|████      | 4087/10000 [00:29<00:42, 140.27it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:29<00:41, 140.46it/s]Running 10000 simulations.:  41%|████      | 4117/10000 [00:29<00:41, 141.02it/s]Running 10000 simulations.:  41%|████▏     | 4132/10000 [00:29<00:41, 139.96it/s]Running 10000 simulations.:  41%|████▏     | 4146/10000 [00:29<00:43, 135.29it/s]Running 10000 simulations.:  42%|████▏     | 4160/10000 [00:29<00:43, 132.83it/s]Running 10000 simulations.:  42%|████▏     | 4174/10000 [00:29<00:44, 131.18it/s]Running 10000 simulations.:  42%|████▏     | 4188/10000 [00:29<00:44, 130.04it/s]Running 10000 simulations.:  42%|████▏     | 4202/10000 [00:29<00:44, 129.75it/s]Running 10000 simulations.:  42%|████▏     | 4215/10000 [00:30<00:44, 129.43it/s]Running 10000 simulations.:  42%|████▏     | 4228/10000 [00:30<00:44, 129.02it/s]Running 10000 simulations.:  42%|████▏     | 4241/10000 [00:30<00:44, 129.13it/s]Running 10000 simulations.:  43%|████▎     | 4254/10000 [00:30<00:44, 128.33it/s]Running 10000 simulations.:  43%|████▎     | 4267/10000 [00:30<00:44, 128.08it/s]Running 10000 simulations.:  43%|████▎     | 4280/10000 [00:30<00:44, 127.71it/s]Running 10000 simulations.:  43%|████▎     | 4293/10000 [00:30<00:44, 127.23it/s]Running 10000 simulations.:  43%|████▎     | 4306/10000 [00:30<00:44, 127.27it/s]Running 10000 simulations.:  43%|████▎     | 4319/10000 [00:30<00:44, 126.99it/s]Running 10000 simulations.:  43%|████▎     | 4332/10000 [00:30<00:44, 126.40it/s]Running 10000 simulations.:  43%|████▎     | 4345/10000 [00:31<00:44, 126.36it/s]Running 10000 simulations.:  44%|████▎     | 4358/10000 [00:31<00:44, 126.67it/s]Running 10000 simulations.:  44%|████▎     | 4371/10000 [00:31<00:44, 127.30it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:31<00:44, 127.08it/s]Running 10000 simulations.:  44%|████▍     | 4397/10000 [00:31<00:44, 126.93it/s]Running 10000 simulations.:  44%|████▍     | 4410/10000 [00:31<00:44, 126.86it/s]Running 10000 simulations.:  44%|████▍     | 4423/10000 [00:31<00:43, 127.29it/s]Running 10000 simulations.:  44%|████▍     | 4436/10000 [00:31<00:43, 127.67it/s]Running 10000 simulations.:  44%|████▍     | 4449/10000 [00:31<00:43, 128.02it/s]Running 10000 simulations.:  45%|████▍     | 4462/10000 [00:32<00:43, 127.68it/s]Running 10000 simulations.:  45%|████▍     | 4475/10000 [00:32<00:43, 127.62it/s]Running 10000 simulations.:  45%|████▍     | 4488/10000 [00:32<00:43, 127.39it/s]Running 10000 simulations.:  45%|████▌     | 4501/10000 [00:32<00:43, 126.75it/s]Running 10000 simulations.:  45%|████▌     | 4514/10000 [00:32<00:43, 126.66it/s]Running 10000 simulations.:  45%|████▌     | 4527/10000 [00:32<00:43, 126.70it/s]Running 10000 simulations.:  45%|████▌     | 4540/10000 [00:32<00:43, 126.66it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:32<00:43, 126.51it/s]Running 10000 simulations.:  46%|████▌     | 4566/10000 [00:32<00:42, 126.41it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:32<00:42, 126.18it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:33<00:42, 126.04it/s]Running 10000 simulations.:  46%|████▌     | 4605/10000 [00:33<00:42, 125.47it/s]Running 10000 simulations.:  46%|████▌     | 4618/10000 [00:33<00:42, 125.67it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:33<00:42, 125.44it/s]Running 10000 simulations.:  46%|████▋     | 4644/10000 [00:33<00:42, 125.88it/s]Running 10000 simulations.:  47%|████▋     | 4657/10000 [00:33<00:42, 125.65it/s]Running 10000 simulations.:  47%|████▋     | 4670/10000 [00:33<00:42, 125.17it/s]Running 10000 simulations.:  47%|████▋     | 4683/10000 [00:33<00:42, 125.18it/s]Running 10000 simulations.:  47%|████▋     | 4696/10000 [00:33<00:42, 125.25it/s]Running 10000 simulations.:  47%|████▋     | 4709/10000 [00:33<00:42, 125.15it/s]Running 10000 simulations.:  47%|████▋     | 4722/10000 [00:34<00:42, 125.38it/s]Running 10000 simulations.:  47%|████▋     | 4735/10000 [00:34<00:41, 125.65it/s]Running 10000 simulations.:  47%|████▋     | 4748/10000 [00:34<00:41, 125.42it/s]Running 10000 simulations.:  48%|████▊     | 4761/10000 [00:34<00:41, 125.24it/s]Running 10000 simulations.:  48%|████▊     | 4774/10000 [00:34<00:41, 125.06it/s]Running 10000 simulations.:  48%|████▊     | 4787/10000 [00:34<00:41, 126.12it/s]Running 10000 simulations.:  48%|████▊     | 4802/10000 [00:34<00:39, 130.27it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:34<00:38, 133.07it/s]Running 10000 simulations.:  48%|████▊     | 4831/10000 [00:34<00:38, 134.60it/s]Running 10000 simulations.:  48%|████▊     | 4845/10000 [00:35<00:38, 133.75it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:35<00:37, 135.38it/s]Running 10000 simulations.:  49%|████▊     | 4874/10000 [00:35<00:37, 137.00it/s]Running 10000 simulations.:  49%|████▉     | 4888/10000 [00:35<00:37, 137.56it/s]Running 10000 simulations.:  49%|████▉     | 4902/10000 [00:35<00:36, 138.18it/s]Running 10000 simulations.:  49%|████▉     | 4917/10000 [00:35<00:36, 138.86it/s]Running 10000 simulations.:  49%|████▉     | 4932/10000 [00:35<00:36, 139.28it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:35<00:36, 139.25it/s]Running 10000 simulations.:  50%|████▉     | 4960/10000 [00:35<00:36, 139.23it/s]Running 10000 simulations.:  50%|████▉     | 4974/10000 [00:35<00:36, 136.30it/s]Running 10000 simulations.:  50%|████▉     | 4988/10000 [00:36<00:37, 133.97it/s]Running 10000 simulations.:  50%|█████     | 5002/10000 [00:36<00:37, 132.01it/s]Running 10000 simulations.:  50%|█████     | 5016/10000 [00:36<00:38, 130.24it/s]Running 10000 simulations.:  50%|█████     | 5030/10000 [00:36<00:37, 130.81it/s]Running 10000 simulations.:  50%|█████     | 5044/10000 [00:36<00:37, 132.57it/s]Running 10000 simulations.:  51%|█████     | 5058/10000 [00:36<00:37, 133.55it/s]Running 10000 simulations.:  51%|█████     | 5072/10000 [00:36<00:36, 134.34it/s]Running 10000 simulations.:  51%|█████     | 5086/10000 [00:36<00:36, 134.14it/s]Running 10000 simulations.:  51%|█████     | 5100/10000 [00:36<00:36, 135.01it/s]Running 10000 simulations.:  51%|█████     | 5114/10000 [00:36<00:35, 135.88it/s]Running 10000 simulations.:  51%|█████▏    | 5128/10000 [00:37<00:35, 136.37it/s]Running 10000 simulations.:  51%|█████▏    | 5142/10000 [00:37<00:35, 136.68it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:37<00:35, 136.36it/s]Running 10000 simulations.:  52%|█████▏    | 5170/10000 [00:37<00:35, 136.02it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:37<00:35, 135.58it/s]Running 10000 simulations.:  52%|█████▏    | 5198/10000 [00:37<00:35, 135.40it/s]Running 10000 simulations.:  52%|█████▏    | 5212/10000 [00:37<00:35, 136.24it/s]Running 10000 simulations.:  52%|█████▏    | 5226/10000 [00:37<00:34, 136.51it/s]Running 10000 simulations.:  52%|█████▏    | 5240/10000 [00:37<00:34, 136.58it/s]Running 10000 simulations.:  53%|█████▎    | 5254/10000 [00:38<00:34, 136.06it/s]Running 10000 simulations.:  53%|█████▎    | 5268/10000 [00:38<00:35, 135.14it/s]Running 10000 simulations.:  53%|█████▎    | 5282/10000 [00:38<00:35, 134.67it/s]Running 10000 simulations.:  53%|█████▎    | 5296/10000 [00:38<00:34, 135.12it/s]Running 10000 simulations.:  53%|█████▎    | 5310/10000 [00:38<00:34, 135.82it/s]Running 10000 simulations.:  53%|█████▎    | 5324/10000 [00:38<00:34, 136.65it/s]Running 10000 simulations.:  53%|█████▎    | 5338/10000 [00:38<00:34, 136.98it/s]Running 10000 simulations.:  54%|█████▎    | 5352/10000 [00:38<00:33, 136.75it/s]Running 10000 simulations.:  54%|█████▎    | 5366/10000 [00:38<00:33, 136.42it/s]Running 10000 simulations.:  54%|█████▍    | 5380/10000 [00:38<00:33, 136.42it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:39<00:33, 135.92it/s]Running 10000 simulations.:  54%|█████▍    | 5408/10000 [00:39<00:34, 132.81it/s]Running 10000 simulations.:  54%|█████▍    | 5422/10000 [00:39<00:34, 131.02it/s]Running 10000 simulations.:  54%|█████▍    | 5436/10000 [00:39<00:35, 129.26it/s]Running 10000 simulations.:  54%|█████▍    | 5449/10000 [00:39<00:35, 127.89it/s]Running 10000 simulations.:  55%|█████▍    | 5462/10000 [00:39<00:35, 126.82it/s]Running 10000 simulations.:  55%|█████▍    | 5475/10000 [00:39<00:35, 126.55it/s]Running 10000 simulations.:  55%|█████▍    | 5488/10000 [00:39<00:35, 126.32it/s]Running 10000 simulations.:  55%|█████▌    | 5501/10000 [00:39<00:35, 125.97it/s]Running 10000 simulations.:  55%|█████▌    | 5514/10000 [00:40<00:35, 125.39it/s]Running 10000 simulations.:  55%|█████▌    | 5527/10000 [00:40<00:35, 125.43it/s]Running 10000 simulations.:  55%|█████▌    | 5540/10000 [00:40<00:35, 125.61it/s]Running 10000 simulations.:  56%|█████▌    | 5553/10000 [00:40<00:35, 125.49it/s]Running 10000 simulations.:  56%|█████▌    | 5567/10000 [00:40<00:34, 127.46it/s]Running 10000 simulations.:  56%|█████▌    | 5582/10000 [00:40<00:33, 131.07it/s]Running 10000 simulations.:  56%|█████▌    | 5597/10000 [00:40<00:32, 133.90it/s]Running 10000 simulations.:  56%|█████▌    | 5612/10000 [00:40<00:32, 135.74it/s]Running 10000 simulations.:  56%|█████▋    | 5627/10000 [00:40<00:31, 137.09it/s]Running 10000 simulations.:  56%|█████▋    | 5642/10000 [00:40<00:31, 138.28it/s]Running 10000 simulations.:  57%|█████▋    | 5656/10000 [00:41<00:31, 137.12it/s]Running 10000 simulations.:  57%|█████▋    | 5670/10000 [00:41<00:31, 137.14it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:41<00:31, 137.66it/s]Running 10000 simulations.:  57%|█████▋    | 5699/10000 [00:41<00:30, 138.88it/s]Running 10000 simulations.:  57%|█████▋    | 5714/10000 [00:41<00:30, 139.47it/s]Running 10000 simulations.:  57%|█████▋    | 5729/10000 [00:41<00:30, 139.88it/s]Running 10000 simulations.:  57%|█████▋    | 5744/10000 [00:41<00:30, 140.45it/s]Running 10000 simulations.:  58%|█████▊    | 5759/10000 [00:41<00:30, 140.34it/s]Running 10000 simulations.:  58%|█████▊    | 5774/10000 [00:41<00:30, 140.42it/s]Running 10000 simulations.:  58%|█████▊    | 5789/10000 [00:42<00:29, 141.21it/s]Running 10000 simulations.:  58%|█████▊    | 5804/10000 [00:42<00:29, 142.26it/s]Running 10000 simulations.:  58%|█████▊    | 5819/10000 [00:42<00:29, 141.83it/s]Running 10000 simulations.:  58%|█████▊    | 5834/10000 [00:42<00:29, 141.55it/s]Running 10000 simulations.:  58%|█████▊    | 5849/10000 [00:42<00:29, 141.50it/s]Running 10000 simulations.:  59%|█████▊    | 5864/10000 [00:42<00:29, 141.17it/s]Running 10000 simulations.:  59%|█████▉    | 5879/10000 [00:42<00:29, 140.04it/s]Running 10000 simulations.:  59%|█████▉    | 5894/10000 [00:42<00:29, 139.60it/s]Running 10000 simulations.:  59%|█████▉    | 5909/10000 [00:42<00:29, 139.86it/s]Running 10000 simulations.:  59%|█████▉    | 5924/10000 [00:42<00:29, 140.40it/s]Running 10000 simulations.:  59%|█████▉    | 5939/10000 [00:43<00:28, 140.27it/s]Running 10000 simulations.:  60%|█████▉    | 5954/10000 [00:43<00:29, 138.44it/s]Running 10000 simulations.:  60%|█████▉    | 5968/10000 [00:43<00:29, 137.29it/s]Running 10000 simulations.:  60%|█████▉    | 5982/10000 [00:43<00:29, 136.77it/s]Running 10000 simulations.:  60%|█████▉    | 5996/10000 [00:43<00:29, 136.43it/s]Running 10000 simulations.:  60%|██████    | 6010/10000 [00:43<00:29, 135.92it/s]Running 10000 simulations.:  60%|██████    | 6024/10000 [00:43<00:29, 135.72it/s]Running 10000 simulations.:  60%|██████    | 6038/10000 [00:43<00:29, 135.31it/s]Running 10000 simulations.:  61%|██████    | 6052/10000 [00:43<00:29, 135.99it/s]Running 10000 simulations.:  61%|██████    | 6066/10000 [00:44<00:28, 136.22it/s]Running 10000 simulations.:  61%|██████    | 6080/10000 [00:44<00:28, 136.46it/s]Running 10000 simulations.:  61%|██████    | 6094/10000 [00:44<00:28, 136.86it/s]Running 10000 simulations.:  61%|██████    | 6108/10000 [00:44<00:28, 136.73it/s]Running 10000 simulations.:  61%|██████    | 6122/10000 [00:44<00:28, 136.90it/s]Running 10000 simulations.:  61%|██████▏   | 6136/10000 [00:44<00:28, 136.24it/s]Running 10000 simulations.:  62%|██████▏   | 6150/10000 [00:44<00:28, 135.93it/s]Running 10000 simulations.:  62%|██████▏   | 6164/10000 [00:44<00:28, 136.30it/s]Running 10000 simulations.:  62%|██████▏   | 6178/10000 [00:44<00:28, 134.78it/s]Running 10000 simulations.:  62%|██████▏   | 6192/10000 [00:44<00:28, 133.03it/s]Running 10000 simulations.:  62%|██████▏   | 6206/10000 [00:45<00:28, 132.08it/s]Running 10000 simulations.:  62%|██████▏   | 6220/10000 [00:45<00:28, 131.31it/s]Running 10000 simulations.:  62%|██████▏   | 6234/10000 [00:45<00:28, 131.56it/s]Running 10000 simulations.:  62%|██████▏   | 6248/10000 [00:45<00:28, 131.90it/s]Running 10000 simulations.:  63%|██████▎   | 6262/10000 [00:45<00:28, 132.11it/s]Running 10000 simulations.:  63%|██████▎   | 6276/10000 [00:45<00:28, 132.40it/s]Running 10000 simulations.:  63%|██████▎   | 6290/10000 [00:45<00:28, 132.17it/s]Running 10000 simulations.:  63%|██████▎   | 6304/10000 [00:45<00:27, 132.36it/s]Running 10000 simulations.:  63%|██████▎   | 6318/10000 [00:45<00:27, 132.14it/s]Running 10000 simulations.:  63%|██████▎   | 6332/10000 [00:46<00:27, 132.42it/s]Running 10000 simulations.:  63%|██████▎   | 6346/10000 [00:46<00:27, 131.68it/s]Running 10000 simulations.:  64%|██████▎   | 6360/10000 [00:46<00:27, 131.24it/s]Running 10000 simulations.:  64%|██████▎   | 6374/10000 [00:46<00:27, 130.88it/s]Running 10000 simulations.:  64%|██████▍   | 6388/10000 [00:46<00:27, 130.99it/s]Running 10000 simulations.:  64%|██████▍   | 6402/10000 [00:46<00:27, 131.23it/s]Running 10000 simulations.:  64%|██████▍   | 6416/10000 [00:46<00:27, 131.42it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:46<00:27, 131.63it/s]Running 10000 simulations.:  64%|██████▍   | 6444/10000 [00:46<00:26, 132.84it/s]Running 10000 simulations.:  65%|██████▍   | 6458/10000 [00:46<00:26, 134.01it/s]Running 10000 simulations.:  65%|██████▍   | 6472/10000 [00:47<00:26, 134.77it/s]Running 10000 simulations.:  65%|██████▍   | 6487/10000 [00:47<00:25, 136.46it/s]Running 10000 simulations.:  65%|██████▌   | 6501/10000 [00:47<00:25, 136.00it/s]Running 10000 simulations.:  65%|██████▌   | 6515/10000 [00:47<00:25, 136.71it/s]Running 10000 simulations.:  65%|██████▌   | 6529/10000 [00:47<00:25, 135.95it/s]Running 10000 simulations.:  65%|██████▌   | 6543/10000 [00:47<00:25, 135.01it/s]Running 10000 simulations.:  66%|██████▌   | 6557/10000 [00:47<00:25, 134.84it/s]Running 10000 simulations.:  66%|██████▌   | 6571/10000 [00:47<00:25, 135.73it/s]Running 10000 simulations.:  66%|██████▌   | 6585/10000 [00:47<00:25, 136.59it/s]Running 10000 simulations.:  66%|██████▌   | 6599/10000 [00:47<00:24, 136.23it/s]Running 10000 simulations.:  66%|██████▌   | 6613/10000 [00:48<00:24, 135.75it/s]Running 10000 simulations.:  66%|██████▋   | 6627/10000 [00:48<00:24, 135.65it/s]Running 10000 simulations.:  66%|██████▋   | 6641/10000 [00:48<00:24, 135.86it/s]Running 10000 simulations.:  67%|██████▋   | 6656/10000 [00:48<00:24, 137.24it/s]Running 10000 simulations.:  67%|██████▋   | 6670/10000 [00:48<00:24, 137.27it/s]Running 10000 simulations.:  67%|██████▋   | 6684/10000 [00:48<00:24, 134.78it/s]Running 10000 simulations.:  67%|██████▋   | 6698/10000 [00:48<00:24, 132.52it/s]Running 10000 simulations.:  67%|██████▋   | 6712/10000 [00:48<00:25, 131.00it/s]Running 10000 simulations.:  67%|██████▋   | 6726/10000 [00:48<00:25, 129.89it/s]Running 10000 simulations.:  67%|██████▋   | 6740/10000 [00:49<00:25, 128.57it/s]Running 10000 simulations.:  68%|██████▊   | 6753/10000 [00:49<00:25, 128.04it/s]Running 10000 simulations.:  68%|██████▊   | 6766/10000 [00:49<00:25, 127.52it/s]Running 10000 simulations.:  68%|██████▊   | 6779/10000 [00:49<00:25, 126.90it/s]Running 10000 simulations.:  68%|██████▊   | 6792/10000 [00:49<00:25, 127.12it/s]Running 10000 simulations.:  68%|██████▊   | 6805/10000 [00:49<00:25, 127.10it/s]Running 10000 simulations.:  68%|██████▊   | 6818/10000 [00:49<00:25, 126.73it/s]Running 10000 simulations.:  68%|██████▊   | 6831/10000 [00:49<00:25, 126.55it/s]Running 10000 simulations.:  68%|██████▊   | 6845/10000 [00:49<00:24, 129.37it/s]Running 10000 simulations.:  69%|██████▊   | 6860/10000 [00:49<00:23, 132.60it/s]Running 10000 simulations.:  69%|██████▊   | 6874/10000 [00:50<00:23, 134.48it/s]Running 10000 simulations.:  69%|██████▉   | 6888/10000 [00:50<00:22, 135.85it/s]Running 10000 simulations.:  69%|██████▉   | 6903/10000 [00:50<00:22, 137.13it/s]Running 10000 simulations.:  69%|██████▉   | 6918/10000 [00:50<00:22, 138.13it/s]Running 10000 simulations.:  69%|██████▉   | 6933/10000 [00:50<00:22, 138.76it/s]Running 10000 simulations.:  69%|██████▉   | 6948/10000 [00:50<00:21, 140.43it/s]Running 10000 simulations.:  70%|██████▉   | 6963/10000 [00:50<00:21, 140.35it/s]Running 10000 simulations.:  70%|██████▉   | 6978/10000 [00:50<00:21, 140.78it/s]Running 10000 simulations.:  70%|██████▉   | 6993/10000 [00:50<00:21, 140.71it/s]Running 10000 simulations.:  70%|███████   | 7008/10000 [00:51<00:21, 141.01it/s]Running 10000 simulations.:  70%|███████   | 7023/10000 [00:51<00:21, 140.08it/s]Running 10000 simulations.:  70%|███████   | 7038/10000 [00:51<00:21, 139.43it/s]Running 10000 simulations.:  71%|███████   | 7052/10000 [00:51<00:21, 139.27it/s]Running 10000 simulations.:  71%|███████   | 7066/10000 [00:51<00:21, 139.24it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:51<00:20, 139.24it/s]Running 10000 simulations.:  71%|███████   | 7094/10000 [00:51<00:20, 139.08it/s]Running 10000 simulations.:  71%|███████   | 7109/10000 [00:51<00:20, 139.44it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:51<00:20, 139.31it/s]Running 10000 simulations.:  71%|███████▏  | 7137/10000 [00:51<00:20, 139.18it/s]Running 10000 simulations.:  72%|███████▏  | 7152/10000 [00:52<00:20, 139.57it/s]Running 10000 simulations.:  72%|███████▏  | 7166/10000 [00:52<00:20, 139.12it/s]Running 10000 simulations.:  72%|███████▏  | 7181/10000 [00:52<00:20, 139.58it/s]Running 10000 simulations.:  72%|███████▏  | 7196/10000 [00:52<00:19, 140.29it/s]Running 10000 simulations.:  72%|███████▏  | 7211/10000 [00:52<00:19, 140.17it/s]Running 10000 simulations.:  72%|███████▏  | 7226/10000 [00:52<00:19, 140.30it/s]Running 10000 simulations.:  72%|███████▏  | 7241/10000 [00:52<00:19, 140.88it/s]Running 10000 simulations.:  73%|███████▎  | 7256/10000 [00:52<00:19, 141.29it/s]Running 10000 simulations.:  73%|███████▎  | 7271/10000 [00:52<00:19, 141.01it/s]Running 10000 simulations.:  73%|███████▎  | 7286/10000 [00:53<00:19, 140.84it/s]Running 10000 simulations.:  73%|███████▎  | 7301/10000 [00:53<00:19, 140.59it/s]Running 10000 simulations.:  73%|███████▎  | 7316/10000 [00:53<00:19, 140.81it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:53<00:18, 140.71it/s]Running 10000 simulations.:  73%|███████▎  | 7346/10000 [00:53<00:18, 140.87it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:53<00:19, 137.41it/s]Running 10000 simulations.:  74%|███████▍  | 7375/10000 [00:53<00:18, 138.17it/s]Running 10000 simulations.:  74%|███████▍  | 7390/10000 [00:53<00:18, 138.95it/s]Running 10000 simulations.:  74%|███████▍  | 7405/10000 [00:53<00:18, 139.30it/s]Running 10000 simulations.:  74%|███████▍  | 7420/10000 [00:53<00:18, 139.56it/s]Running 10000 simulations.:  74%|███████▍  | 7434/10000 [00:54<00:18, 139.28it/s]Running 10000 simulations.:  74%|███████▍  | 7449/10000 [00:54<00:18, 139.82it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:54<00:18, 140.03it/s]Running 10000 simulations.:  75%|███████▍  | 7479/10000 [00:54<00:17, 140.46it/s]Running 10000 simulations.:  75%|███████▍  | 7494/10000 [00:54<00:17, 140.76it/s]Running 10000 simulations.:  75%|███████▌  | 7509/10000 [00:54<00:17, 140.86it/s]Running 10000 simulations.:  75%|███████▌  | 7524/10000 [00:54<00:17, 140.64it/s]Running 10000 simulations.:  75%|███████▌  | 7539/10000 [00:54<00:17, 140.58it/s]Running 10000 simulations.:  76%|███████▌  | 7554/10000 [00:54<00:17, 140.62it/s]Running 10000 simulations.:  76%|███████▌  | 7569/10000 [00:55<00:17, 140.79it/s]Running 10000 simulations.:  76%|███████▌  | 7584/10000 [00:55<00:17, 140.44it/s]Running 10000 simulations.:  76%|███████▌  | 7599/10000 [00:55<00:17, 140.62it/s]Running 10000 simulations.:  76%|███████▌  | 7614/10000 [00:55<00:16, 140.52it/s]Running 10000 simulations.:  76%|███████▋  | 7629/10000 [00:55<00:16, 140.34it/s]Running 10000 simulations.:  76%|███████▋  | 7644/10000 [00:55<00:17, 134.90it/s]Running 10000 simulations.:  77%|███████▋  | 7658/10000 [00:55<00:17, 134.66it/s]Running 10000 simulations.:  77%|███████▋  | 7673/10000 [00:55<00:17, 136.68it/s]Running 10000 simulations.:  77%|███████▋  | 7687/10000 [00:55<00:16, 137.64it/s]Running 10000 simulations.:  77%|███████▋  | 7702/10000 [00:56<00:16, 138.65it/s]Running 10000 simulations.:  77%|███████▋  | 7717/10000 [00:56<00:16, 139.24it/s]Running 10000 simulations.:  77%|███████▋  | 7732/10000 [00:56<00:16, 139.62it/s]Running 10000 simulations.:  77%|███████▋  | 7747/10000 [00:56<00:16, 140.59it/s]Running 10000 simulations.:  78%|███████▊  | 7762/10000 [00:56<00:15, 140.63it/s]Running 10000 simulations.:  78%|███████▊  | 7777/10000 [00:56<00:15, 139.61it/s]Running 10000 simulations.:  78%|███████▊  | 7791/10000 [00:56<00:15, 138.49it/s]Running 10000 simulations.:  78%|███████▊  | 7805/10000 [00:56<00:15, 137.83it/s]Running 10000 simulations.:  78%|███████▊  | 7819/10000 [00:56<00:15, 137.29it/s]Running 10000 simulations.:  78%|███████▊  | 7833/10000 [00:56<00:15, 136.66it/s]Running 10000 simulations.:  78%|███████▊  | 7847/10000 [00:57<00:15, 136.77it/s]Running 10000 simulations.:  79%|███████▊  | 7861/10000 [00:57<00:15, 135.79it/s]Running 10000 simulations.:  79%|███████▉  | 7875/10000 [00:57<00:15, 135.49it/s]Running 10000 simulations.:  79%|███████▉  | 7889/10000 [00:57<00:15, 135.23it/s]Running 10000 simulations.:  79%|███████▉  | 7903/10000 [00:57<00:15, 134.65it/s]Running 10000 simulations.:  79%|███████▉  | 7917/10000 [00:57<00:15, 135.14it/s]Running 10000 simulations.:  79%|███████▉  | 7931/10000 [00:57<00:15, 136.05it/s]Running 10000 simulations.:  79%|███████▉  | 7945/10000 [00:57<00:15, 135.56it/s]Running 10000 simulations.:  80%|███████▉  | 7959/10000 [00:57<00:14, 136.17it/s]Running 10000 simulations.:  80%|███████▉  | 7973/10000 [00:57<00:14, 136.39it/s]Running 10000 simulations.:  80%|███████▉  | 7987/10000 [00:58<00:14, 136.79it/s]Running 10000 simulations.:  80%|████████  | 8001/10000 [00:58<00:14, 137.59it/s]Running 10000 simulations.:  80%|████████  | 8015/10000 [00:58<00:14, 136.15it/s]Running 10000 simulations.:  80%|████████  | 8029/10000 [00:58<00:14, 136.36it/s]Running 10000 simulations.:  80%|████████  | 8043/10000 [00:58<00:25, 76.56it/s] Running 10000 simulations.:  81%|████████  | 8057/10000 [00:58<00:22, 88.11it/s]Running 10000 simulations.:  81%|████████  | 8071/10000 [00:58<00:19, 98.55it/s]Running 10000 simulations.:  81%|████████  | 8085/10000 [00:59<00:17, 107.57it/s]Running 10000 simulations.:  81%|████████  | 8099/10000 [00:59<00:16, 114.51it/s]Running 10000 simulations.:  81%|████████  | 8113/10000 [00:59<00:15, 120.72it/s]Running 10000 simulations.:  81%|████████▏ | 8127/10000 [00:59<00:14, 125.09it/s]Running 10000 simulations.:  81%|████████▏ | 8144/10000 [00:59<00:13, 134.52it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:59<00:13, 139.97it/s]Running 10000 simulations.:  82%|████████▏ | 8176/10000 [00:59<00:12, 144.79it/s]Running 10000 simulations.:  82%|████████▏ | 8191/10000 [00:59<00:12, 145.08it/s]Running 10000 simulations.:  82%|████████▏ | 8206/10000 [00:59<00:12, 144.64it/s]Running 10000 simulations.:  82%|████████▏ | 8221/10000 [01:00<00:12, 140.87it/s]Running 10000 simulations.:  82%|████████▏ | 8236/10000 [01:00<00:12, 136.13it/s]Running 10000 simulations.:  82%|████████▎ | 8250/10000 [01:00<00:13, 132.82it/s]Running 10000 simulations.:  83%|████████▎ | 8264/10000 [01:00<00:13, 130.52it/s]Running 10000 simulations.:  83%|████████▎ | 8278/10000 [01:00<00:13, 129.01it/s]Running 10000 simulations.:  83%|████████▎ | 8291/10000 [01:00<00:13, 127.95it/s]Running 10000 simulations.:  83%|████████▎ | 8304/10000 [01:00<00:13, 128.27it/s]Running 10000 simulations.:  83%|████████▎ | 8317/10000 [01:00<00:13, 128.11it/s]Running 10000 simulations.:  83%|████████▎ | 8330/10000 [01:00<00:12, 128.53it/s]Running 10000 simulations.:  83%|████████▎ | 8344/10000 [01:00<00:12, 129.80it/s]Running 10000 simulations.:  84%|████████▎ | 8358/10000 [01:01<00:12, 130.58it/s]Running 10000 simulations.:  84%|████████▎ | 8372/10000 [01:01<00:12, 131.13it/s]Running 10000 simulations.:  84%|████████▍ | 8386/10000 [01:01<00:12, 131.24it/s]Running 10000 simulations.:  84%|████████▍ | 8400/10000 [01:01<00:12, 131.52it/s]Running 10000 simulations.:  84%|████████▍ | 8414/10000 [01:01<00:12, 131.19it/s]Running 10000 simulations.:  84%|████████▍ | 8428/10000 [01:01<00:12, 130.81it/s]Running 10000 simulations.:  84%|████████▍ | 8442/10000 [01:01<00:11, 130.56it/s]Running 10000 simulations.:  85%|████████▍ | 8456/10000 [01:01<00:11, 130.41it/s]Running 10000 simulations.:  85%|████████▍ | 8470/10000 [01:01<00:11, 130.04it/s]Running 10000 simulations.:  85%|████████▍ | 8484/10000 [01:02<00:11, 130.26it/s]Running 10000 simulations.:  85%|████████▍ | 8498/10000 [01:02<00:11, 130.54it/s]Running 10000 simulations.:  85%|████████▌ | 8512/10000 [01:02<00:11, 130.21it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [01:02<00:11, 130.18it/s]Running 10000 simulations.:  85%|████████▌ | 8540/10000 [01:02<00:11, 130.19it/s]Running 10000 simulations.:  86%|████████▌ | 8554/10000 [01:02<00:11, 131.38it/s]Running 10000 simulations.:  86%|████████▌ | 8569/10000 [01:02<00:10, 134.38it/s]Running 10000 simulations.:  86%|████████▌ | 8584/10000 [01:02<00:10, 137.41it/s]Running 10000 simulations.:  86%|████████▌ | 8599/10000 [01:02<00:10, 139.14it/s]Running 10000 simulations.:  86%|████████▌ | 8613/10000 [01:03<00:09, 139.15it/s]Running 10000 simulations.:  86%|████████▋ | 8627/10000 [01:03<00:09, 139.09it/s]Running 10000 simulations.:  86%|████████▋ | 8642/10000 [01:03<00:09, 139.40it/s]Running 10000 simulations.:  87%|████████▋ | 8657/10000 [01:03<00:09, 139.66it/s]Running 10000 simulations.:  87%|████████▋ | 8672/10000 [01:03<00:09, 139.78it/s]Running 10000 simulations.:  87%|████████▋ | 8687/10000 [01:03<00:09, 139.97it/s]Running 10000 simulations.:  87%|████████▋ | 8702/10000 [01:03<00:09, 140.04it/s]Running 10000 simulations.:  87%|████████▋ | 8717/10000 [01:03<00:09, 140.09it/s]Running 10000 simulations.:  87%|████████▋ | 8732/10000 [01:03<00:09, 139.84it/s]Running 10000 simulations.:  87%|████████▋ | 8746/10000 [01:03<00:08, 139.69it/s]Running 10000 simulations.:  88%|████████▊ | 8760/10000 [01:04<00:08, 139.34it/s]Running 10000 simulations.:  88%|████████▊ | 8775/10000 [01:04<00:08, 140.28it/s]Running 10000 simulations.:  88%|████████▊ | 8790/10000 [01:04<00:08, 139.79it/s]Running 10000 simulations.:  88%|████████▊ | 8805/10000 [01:04<00:08, 139.90it/s]Running 10000 simulations.:  88%|████████▊ | 8819/10000 [01:04<00:08, 139.84it/s]Running 10000 simulations.:  88%|████████▊ | 8833/10000 [01:04<00:08, 139.40it/s]Running 10000 simulations.:  88%|████████▊ | 8848/10000 [01:04<00:08, 139.71it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [01:04<00:08, 139.69it/s]Running 10000 simulations.:  89%|████████▉ | 8876/10000 [01:04<00:08, 139.75it/s]Running 10000 simulations.:  89%|████████▉ | 8890/10000 [01:04<00:07, 139.73it/s]Running 10000 simulations.:  89%|████████▉ | 8905/10000 [01:05<00:07, 139.89it/s]Running 10000 simulations.:  89%|████████▉ | 8920/10000 [01:05<00:07, 140.10it/s]Running 10000 simulations.:  89%|████████▉ | 8935/10000 [01:05<00:07, 139.90it/s]Running 10000 simulations.:  89%|████████▉ | 8949/10000 [01:05<00:07, 135.18it/s]Running 10000 simulations.:  90%|████████▉ | 8963/10000 [01:05<00:07, 136.27it/s]Running 10000 simulations.:  90%|████████▉ | 8978/10000 [01:05<00:07, 137.65it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [01:05<00:07, 138.63it/s]Running 10000 simulations.:  90%|█████████ | 9007/10000 [01:05<00:07, 138.91it/s]Running 10000 simulations.:  90%|█████████ | 9022/10000 [01:05<00:07, 139.49it/s]Running 10000 simulations.:  90%|█████████ | 9036/10000 [01:06<00:06, 139.35it/s]Running 10000 simulations.:  90%|█████████ | 9050/10000 [01:06<00:06, 138.24it/s]Running 10000 simulations.:  91%|█████████ | 9064/10000 [01:06<00:06, 138.07it/s]Running 10000 simulations.:  91%|█████████ | 9078/10000 [01:06<00:06, 137.35it/s]Running 10000 simulations.:  91%|█████████ | 9092/10000 [01:06<00:06, 137.18it/s]Running 10000 simulations.:  91%|█████████ | 9106/10000 [01:06<00:06, 137.54it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [01:06<00:06, 137.48it/s]Running 10000 simulations.:  91%|█████████▏| 9134/10000 [01:06<00:06, 137.20it/s]Running 10000 simulations.:  91%|█████████▏| 9148/10000 [01:06<00:06, 137.21it/s]Running 10000 simulations.:  92%|█████████▏| 9162/10000 [01:06<00:06, 136.47it/s]Running 10000 simulations.:  92%|█████████▏| 9176/10000 [01:07<00:06, 135.86it/s]Running 10000 simulations.:  92%|█████████▏| 9190/10000 [01:07<00:05, 135.75it/s]Running 10000 simulations.:  92%|█████████▏| 9204/10000 [01:07<00:05, 135.67it/s]Running 10000 simulations.:  92%|█████████▏| 9218/10000 [01:07<00:05, 135.83it/s]Running 10000 simulations.:  92%|█████████▏| 9232/10000 [01:07<00:05, 134.53it/s]Running 10000 simulations.:  92%|█████████▏| 9246/10000 [01:07<00:05, 134.32it/s]Running 10000 simulations.:  93%|█████████▎| 9260/10000 [01:07<00:05, 134.68it/s]Running 10000 simulations.:  93%|█████████▎| 9274/10000 [01:07<00:05, 134.49it/s]Running 10000 simulations.:  93%|█████████▎| 9288/10000 [01:07<00:05, 134.59it/s]Running 10000 simulations.:  93%|█████████▎| 9302/10000 [01:08<00:05, 135.50it/s]Running 10000 simulations.:  93%|█████████▎| 9316/10000 [01:08<00:05, 134.99it/s]Running 10000 simulations.:  93%|█████████▎| 9330/10000 [01:08<00:04, 134.27it/s]Running 10000 simulations.:  93%|█████████▎| 9344/10000 [01:08<00:04, 134.45it/s]Running 10000 simulations.:  94%|█████████▎| 9358/10000 [01:08<00:04, 134.51it/s]Running 10000 simulations.:  94%|█████████▎| 9372/10000 [01:08<00:04, 135.21it/s]Running 10000 simulations.:  94%|█████████▍| 9386/10000 [01:08<00:04, 135.50it/s]Running 10000 simulations.:  94%|█████████▍| 9400/10000 [01:08<00:04, 134.85it/s]Running 10000 simulations.:  94%|█████████▍| 9414/10000 [01:08<00:04, 135.10it/s]Running 10000 simulations.:  94%|█████████▍| 9428/10000 [01:08<00:04, 135.51it/s]Running 10000 simulations.:  94%|█████████▍| 9442/10000 [01:09<00:04, 135.59it/s]Running 10000 simulations.:  95%|█████████▍| 9456/10000 [01:09<00:04, 135.80it/s]Running 10000 simulations.:  95%|█████████▍| 9470/10000 [01:09<00:03, 135.26it/s]Running 10000 simulations.:  95%|█████████▍| 9484/10000 [01:09<00:03, 135.01it/s]Running 10000 simulations.:  95%|█████████▍| 9498/10000 [01:09<00:03, 134.90it/s]Running 10000 simulations.:  95%|█████████▌| 9512/10000 [01:09<00:03, 134.35it/s]Running 10000 simulations.:  95%|█████████▌| 9526/10000 [01:09<00:03, 132.87it/s]Running 10000 simulations.:  95%|█████████▌| 9540/10000 [01:09<00:03, 131.96it/s]Running 10000 simulations.:  96%|█████████▌| 9554/10000 [01:09<00:03, 131.02it/s]Running 10000 simulations.:  96%|█████████▌| 9568/10000 [01:09<00:03, 131.10it/s]Running 10000 simulations.:  96%|█████████▌| 9582/10000 [01:10<00:03, 130.46it/s]Running 10000 simulations.:  96%|█████████▌| 9596/10000 [01:10<00:03, 130.23it/s]Running 10000 simulations.:  96%|█████████▌| 9610/10000 [01:10<00:03, 129.99it/s]Running 10000 simulations.:  96%|█████████▌| 9624/10000 [01:10<00:02, 130.26it/s]Running 10000 simulations.:  96%|█████████▋| 9638/10000 [01:10<00:02, 130.80it/s]Running 10000 simulations.:  97%|█████████▋| 9652/10000 [01:10<00:02, 130.66it/s]Running 10000 simulations.:  97%|█████████▋| 9666/10000 [01:10<00:02, 130.67it/s]Running 10000 simulations.:  97%|█████████▋| 9680/10000 [01:10<00:02, 131.14it/s]Running 10000 simulations.:  97%|█████████▋| 9694/10000 [01:10<00:02, 131.36it/s]Running 10000 simulations.:  97%|█████████▋| 9708/10000 [01:11<00:02, 131.49it/s]Running 10000 simulations.:  97%|█████████▋| 9722/10000 [01:11<00:02, 131.85it/s]Running 10000 simulations.:  97%|█████████▋| 9736/10000 [01:11<00:02, 131.74it/s]Running 10000 simulations.:  98%|█████████▊| 9750/10000 [01:11<00:01, 131.94it/s]Running 10000 simulations.:  98%|█████████▊| 9764/10000 [01:11<00:01, 131.32it/s]Running 10000 simulations.:  98%|█████████▊| 9778/10000 [01:11<00:01, 130.99it/s]Running 10000 simulations.:  98%|█████████▊| 9792/10000 [01:11<00:01, 130.58it/s]Running 10000 simulations.:  98%|█████████▊| 9806/10000 [01:11<00:01, 130.49it/s]Running 10000 simulations.:  98%|█████████▊| 9820/10000 [01:11<00:01, 130.31it/s]Running 10000 simulations.:  98%|█████████▊| 9834/10000 [01:12<00:01, 131.08it/s]Running 10000 simulations.:  98%|█████████▊| 9848/10000 [01:12<00:01, 130.66it/s]Running 10000 simulations.:  99%|█████████▊| 9862/10000 [01:12<00:01, 130.71it/s]Running 10000 simulations.:  99%|█████████▉| 9876/10000 [01:12<00:00, 130.67it/s]Running 10000 simulations.:  99%|█████████▉| 9890/10000 [01:12<00:00, 130.70it/s]Running 10000 simulations.:  99%|█████████▉| 9904/10000 [01:12<00:00, 130.71it/s]Running 10000 simulations.:  99%|█████████▉| 9918/10000 [01:12<00:00, 131.29it/s]Running 10000 simulations.:  99%|█████████▉| 9932/10000 [01:12<00:00, 131.14it/s]Running 10000 simulations.:  99%|█████████▉| 9946/10000 [01:12<00:00, 131.26it/s]Running 10000 simulations.: 100%|█████████▉| 9960/10000 [01:12<00:00, 131.27it/s]Running 10000 simulations.: 100%|█████████▉| 9974/10000 [01:13<00:00, 130.83it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [01:13<00:00, 131.15it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:13<00:00, 136.44it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 14/10000 [00:00<01:15, 133.09it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<01:15, 132.83it/s]Running 10000 simulations.:   0%|          | 42/10000 [00:00<01:15, 132.73it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<01:15, 132.28it/s]Running 10000 simulations.:   1%|          | 70/10000 [00:00<01:15, 131.99it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<01:14, 132.57it/s]Running 10000 simulations.:   1%|          | 98/10000 [00:00<01:14, 132.52it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<01:14, 132.50it/s]Running 10000 simulations.:   1%|▏         | 126/10000 [00:00<01:14, 132.28it/s]Running 10000 simulations.:   1%|▏         | 139/10000 [00:01<01:14, 131.54it/s]Running 10000 simulations.:   2%|▏         | 152/10000 [00:01<01:15, 130.95it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:01<01:15, 130.35it/s]Running 10000 simulations.:   2%|▏         | 179/10000 [00:01<01:15, 130.52it/s]Running 10000 simulations.:   2%|▏         | 192/10000 [00:01<01:15, 130.32it/s]Running 10000 simulations.:   2%|▏         | 205/10000 [00:01<01:15, 130.19it/s]Running 10000 simulations.:   2%|▏         | 219/10000 [00:01<01:14, 130.47it/s]Running 10000 simulations.:   2%|▏         | 234/10000 [00:01<01:12, 134.54it/s]Running 10000 simulations.:   2%|▏         | 249/10000 [00:01<01:10, 137.45it/s]Running 10000 simulations.:   3%|▎         | 264/10000 [00:01<01:09, 139.62it/s]Running 10000 simulations.:   3%|▎         | 279/10000 [00:02<01:08, 141.20it/s]Running 10000 simulations.:   3%|▎         | 294/10000 [00:02<01:08, 142.53it/s]Running 10000 simulations.:   3%|▎         | 309/10000 [00:02<01:07, 142.98it/s]Running 10000 simulations.:   3%|▎         | 324/10000 [00:02<01:07, 143.43it/s]Running 10000 simulations.:   3%|▎         | 339/10000 [00:02<01:07, 143.41it/s]Running 10000 simulations.:   4%|▎         | 354/10000 [00:02<01:07, 143.73it/s]Running 10000 simulations.:   4%|▎         | 369/10000 [00:02<01:06, 144.06it/s]Running 10000 simulations.:   4%|▍         | 384/10000 [00:02<01:06, 144.05it/s]Running 10000 simulations.:   4%|▍         | 399/10000 [00:02<01:06, 144.40it/s]Running 10000 simulations.:   4%|▍         | 414/10000 [00:03<01:06, 144.26it/s]Running 10000 simulations.:   4%|▍         | 429/10000 [00:03<01:06, 143.70it/s]Running 10000 simulations.:   4%|▍         | 444/10000 [00:03<01:06, 143.69it/s]Running 10000 simulations.:   5%|▍         | 459/10000 [00:03<01:06, 144.01it/s]Running 10000 simulations.:   5%|▍         | 474/10000 [00:03<01:06, 143.28it/s]Running 10000 simulations.:   5%|▍         | 489/10000 [00:03<01:06, 143.52it/s]Running 10000 simulations.:   5%|▌         | 504/10000 [00:03<01:06, 143.83it/s]Running 10000 simulations.:   5%|▌         | 519/10000 [00:03<01:05, 143.69it/s]Running 10000 simulations.:   5%|▌         | 534/10000 [00:03<01:05, 143.82it/s]Running 10000 simulations.:   5%|▌         | 549/10000 [00:03<01:05, 143.98it/s]Running 10000 simulations.:   6%|▌         | 564/10000 [00:04<01:05, 144.26it/s]Running 10000 simulations.:   6%|▌         | 579/10000 [00:04<01:05, 143.57it/s]Running 10000 simulations.:   6%|▌         | 594/10000 [00:04<01:05, 143.56it/s]Running 10000 simulations.:   6%|▌         | 609/10000 [00:04<01:05, 143.71it/s]Running 10000 simulations.:   6%|▌         | 624/10000 [00:04<01:05, 143.97it/s]Running 10000 simulations.:   6%|▋         | 639/10000 [00:04<01:05, 144.00it/s]Running 10000 simulations.:   7%|▋         | 654/10000 [00:04<01:04, 144.36it/s]Running 10000 simulations.:   7%|▋         | 669/10000 [00:04<01:04, 144.14it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:04<01:04, 144.15it/s]Running 10000 simulations.:   7%|▋         | 699/10000 [00:05<01:05, 142.95it/s]Running 10000 simulations.:   7%|▋         | 714/10000 [00:05<01:04, 143.12it/s]Running 10000 simulations.:   7%|▋         | 729/10000 [00:05<01:04, 143.22it/s]Running 10000 simulations.:   7%|▋         | 744/10000 [00:05<01:04, 143.72it/s]Running 10000 simulations.:   8%|▊         | 759/10000 [00:05<01:04, 143.36it/s]Running 10000 simulations.:   8%|▊         | 774/10000 [00:05<01:04, 143.61it/s]Running 10000 simulations.:   8%|▊         | 789/10000 [00:05<01:04, 142.69it/s]Running 10000 simulations.:   8%|▊         | 804/10000 [00:05<01:04, 142.56it/s]Running 10000 simulations.:   8%|▊         | 819/10000 [00:05<01:04, 143.11it/s]Running 10000 simulations.:   8%|▊         | 834/10000 [00:05<01:04, 143.01it/s]Running 10000 simulations.:   8%|▊         | 849/10000 [00:06<01:04, 142.93it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:06<01:03, 143.08it/s]Running 10000 simulations.:   9%|▉         | 879/10000 [00:06<01:03, 143.45it/s]Running 10000 simulations.:   9%|▉         | 894/10000 [00:06<01:03, 143.38it/s]Running 10000 simulations.:   9%|▉         | 909/10000 [00:06<01:03, 143.30it/s]Running 10000 simulations.:   9%|▉         | 924/10000 [00:06<01:03, 142.33it/s]Running 10000 simulations.:   9%|▉         | 939/10000 [00:06<01:03, 142.13it/s]Running 10000 simulations.:  10%|▉         | 954/10000 [00:06<01:03, 142.63it/s]Running 10000 simulations.:  10%|▉         | 969/10000 [00:06<01:03, 142.55it/s]Running 10000 simulations.:  10%|▉         | 984/10000 [00:06<01:03, 142.12it/s]Running 10000 simulations.:  10%|▉         | 999/10000 [00:07<01:03, 142.21it/s]Running 10000 simulations.:  10%|█         | 1014/10000 [00:07<01:03, 141.68it/s]Running 10000 simulations.:  10%|█         | 1029/10000 [00:07<01:03, 141.55it/s]Running 10000 simulations.:  10%|█         | 1044/10000 [00:07<01:03, 141.82it/s]Running 10000 simulations.:  11%|█         | 1059/10000 [00:07<01:03, 141.81it/s]Running 10000 simulations.:  11%|█         | 1074/10000 [00:07<01:03, 141.09it/s]Running 10000 simulations.:  11%|█         | 1089/10000 [00:07<01:02, 141.50it/s]Running 10000 simulations.:  11%|█         | 1104/10000 [00:07<01:02, 141.56it/s]Running 10000 simulations.:  11%|█         | 1119/10000 [00:07<01:02, 141.95it/s]Running 10000 simulations.:  11%|█▏        | 1134/10000 [00:08<01:02, 142.20it/s]Running 10000 simulations.:  11%|█▏        | 1149/10000 [00:08<01:02, 142.39it/s]Running 10000 simulations.:  12%|█▏        | 1164/10000 [00:08<01:02, 142.40it/s]Running 10000 simulations.:  12%|█▏        | 1179/10000 [00:08<01:02, 141.92it/s]Running 10000 simulations.:  12%|█▏        | 1194/10000 [00:08<01:02, 141.42it/s]Running 10000 simulations.:  12%|█▏        | 1209/10000 [00:08<01:02, 141.75it/s]Running 10000 simulations.:  12%|█▏        | 1224/10000 [00:08<01:02, 141.33it/s]Running 10000 simulations.:  12%|█▏        | 1239/10000 [00:08<01:02, 141.20it/s]Running 10000 simulations.:  13%|█▎        | 1254/10000 [00:08<01:01, 141.19it/s]Running 10000 simulations.:  13%|█▎        | 1269/10000 [00:09<01:01, 141.47it/s]Running 10000 simulations.:  13%|█▎        | 1284/10000 [00:09<01:01, 142.32it/s]Running 10000 simulations.:  13%|█▎        | 1299/10000 [00:09<01:01, 142.28it/s]Running 10000 simulations.:  13%|█▎        | 1314/10000 [00:09<01:00, 142.81it/s]Running 10000 simulations.:  13%|█▎        | 1329/10000 [00:09<01:00, 142.59it/s]Running 10000 simulations.:  13%|█▎        | 1344/10000 [00:09<01:00, 142.08it/s]Running 10000 simulations.:  14%|█▎        | 1359/10000 [00:09<01:01, 141.20it/s]Running 10000 simulations.:  14%|█▎        | 1374/10000 [00:09<01:01, 140.99it/s]Running 10000 simulations.:  14%|█▍        | 1389/10000 [00:09<01:00, 141.58it/s]Running 10000 simulations.:  14%|█▍        | 1404/10000 [00:09<01:00, 142.38it/s]Running 10000 simulations.:  14%|█▍        | 1419/10000 [00:10<01:00, 142.95it/s]Running 10000 simulations.:  14%|█▍        | 1434/10000 [00:10<01:00, 142.56it/s]Running 10000 simulations.:  14%|█▍        | 1449/10000 [00:10<01:00, 141.81it/s]Running 10000 simulations.:  15%|█▍        | 1464/10000 [00:10<01:00, 140.97it/s]Running 10000 simulations.:  15%|█▍        | 1479/10000 [00:10<01:00, 140.44it/s]Running 10000 simulations.:  15%|█▍        | 1494/10000 [00:10<01:00, 140.59it/s]Running 10000 simulations.:  15%|█▌        | 1509/10000 [00:10<01:00, 139.34it/s]Running 10000 simulations.:  15%|█▌        | 1524/10000 [00:10<01:00, 139.64it/s]Running 10000 simulations.:  15%|█▌        | 1538/10000 [00:10<01:00, 139.19it/s]Running 10000 simulations.:  16%|█▌        | 1552/10000 [00:11<01:01, 138.40it/s]Running 10000 simulations.:  16%|█▌        | 1566/10000 [00:11<01:00, 138.78it/s]Running 10000 simulations.:  16%|█▌        | 1580/10000 [00:11<01:00, 138.75it/s]Running 10000 simulations.:  16%|█▌        | 1595/10000 [00:11<01:00, 139.09it/s]Running 10000 simulations.:  16%|█▌        | 1609/10000 [00:11<01:00, 138.23it/s]Running 10000 simulations.:  16%|█▌        | 1624/10000 [00:11<01:00, 139.14it/s]Running 10000 simulations.:  16%|█▋        | 1639/10000 [00:11<00:59, 139.69it/s]Running 10000 simulations.:  17%|█▋        | 1654/10000 [00:11<00:59, 140.11it/s]Running 10000 simulations.:  17%|█▋        | 1669/10000 [00:11<00:59, 140.60it/s]Running 10000 simulations.:  17%|█▋        | 1684/10000 [00:11<00:59, 139.56it/s]Running 10000 simulations.:  17%|█▋        | 1698/10000 [00:12<00:59, 138.96it/s]Running 10000 simulations.:  17%|█▋        | 1712/10000 [00:12<00:59, 138.92it/s]Running 10000 simulations.:  17%|█▋        | 1726/10000 [00:12<00:59, 139.22it/s]Running 10000 simulations.:  17%|█▋        | 1741/10000 [00:12<00:59, 139.63it/s]Running 10000 simulations.:  18%|█▊        | 1756/10000 [00:12<00:58, 140.38it/s]Running 10000 simulations.:  18%|█▊        | 1771/10000 [00:12<00:58, 139.76it/s]Running 10000 simulations.:  18%|█▊        | 1786/10000 [00:12<00:58, 140.20it/s]Running 10000 simulations.:  18%|█▊        | 1801/10000 [00:12<00:58, 140.54it/s]Running 10000 simulations.:  18%|█▊        | 1816/10000 [00:12<00:58, 140.91it/s]Running 10000 simulations.:  18%|█▊        | 1831/10000 [00:13<00:57, 140.93it/s]Running 10000 simulations.:  18%|█▊        | 1846/10000 [00:13<00:57, 140.82it/s]Running 10000 simulations.:  19%|█▊        | 1861/10000 [00:13<00:58, 139.96it/s]Running 10000 simulations.:  19%|█▉        | 1875/10000 [00:13<00:58, 139.32it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:13<00:58, 139.62it/s]Running 10000 simulations.:  19%|█▉        | 1905/10000 [00:13<00:57, 139.91it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:13<00:57, 139.89it/s]Running 10000 simulations.:  19%|█▉        | 1934/10000 [00:13<00:57, 139.46it/s]Running 10000 simulations.:  19%|█▉        | 1949/10000 [00:13<00:57, 139.74it/s]Running 10000 simulations.:  20%|█▉        | 1963/10000 [00:13<00:57, 139.82it/s]Running 10000 simulations.:  20%|█▉        | 1977/10000 [00:14<00:57, 139.85it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:14<01:01, 130.60it/s]Running 10000 simulations.:  20%|██        | 2005/10000 [00:14<00:59, 133.28it/s]Running 10000 simulations.:  20%|██        | 2020/10000 [00:14<00:59, 135.21it/s]Running 10000 simulations.:  20%|██        | 2034/10000 [00:14<00:58, 135.70it/s]Running 10000 simulations.:  20%|██        | 2048/10000 [00:14<00:58, 135.58it/s]Running 10000 simulations.:  21%|██        | 2063/10000 [00:14<00:57, 137.15it/s]Running 10000 simulations.:  21%|██        | 2078/10000 [00:14<00:57, 138.59it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:14<00:56, 138.91it/s]Running 10000 simulations.:  21%|██        | 2106/10000 [00:15<00:56, 139.14it/s]Running 10000 simulations.:  21%|██        | 2120/10000 [00:15<00:56, 138.90it/s]Running 10000 simulations.:  21%|██▏       | 2134/10000 [00:15<00:56, 139.16it/s]Running 10000 simulations.:  21%|██▏       | 2148/10000 [00:15<00:56, 139.03it/s]Running 10000 simulations.:  22%|██▏       | 2162/10000 [00:15<00:56, 138.79it/s]Running 10000 simulations.:  22%|██▏       | 2176/10000 [00:15<00:56, 138.91it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:15<00:56, 139.31it/s]Running 10000 simulations.:  22%|██▏       | 2206/10000 [00:15<00:55, 139.63it/s]Running 10000 simulations.:  22%|██▏       | 2220/10000 [00:15<00:55, 138.94it/s]Running 10000 simulations.:  22%|██▏       | 2235/10000 [00:15<00:55, 139.64it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:16<00:55, 140.04it/s]Running 10000 simulations.:  23%|██▎       | 2265/10000 [00:16<00:55, 140.09it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:16<00:55, 139.90it/s]Running 10000 simulations.:  23%|██▎       | 2294/10000 [00:16<00:55, 139.76it/s]Running 10000 simulations.:  23%|██▎       | 2308/10000 [00:16<00:55, 139.82it/s]Running 10000 simulations.:  23%|██▎       | 2323/10000 [00:16<00:54, 140.21it/s]Running 10000 simulations.:  23%|██▎       | 2338/10000 [00:16<00:54, 140.52it/s]Running 10000 simulations.:  24%|██▎       | 2353/10000 [00:16<00:54, 140.55it/s]Running 10000 simulations.:  24%|██▎       | 2368/10000 [00:16<00:54, 140.48it/s]Running 10000 simulations.:  24%|██▍       | 2383/10000 [00:16<00:54, 140.91it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:17<00:53, 141.19it/s]Running 10000 simulations.:  24%|██▍       | 2413/10000 [00:17<00:53, 141.77it/s]Running 10000 simulations.:  24%|██▍       | 2428/10000 [00:17<00:53, 141.93it/s]Running 10000 simulations.:  24%|██▍       | 2443/10000 [00:17<00:53, 141.57it/s]Running 10000 simulations.:  25%|██▍       | 2458/10000 [00:17<00:53, 141.72it/s]Running 10000 simulations.:  25%|██▍       | 2473/10000 [00:17<00:52, 142.43it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:17<00:52, 142.56it/s]Running 10000 simulations.:  25%|██▌       | 2503/10000 [00:17<00:52, 142.45it/s]Running 10000 simulations.:  25%|██▌       | 2518/10000 [00:17<00:52, 141.75it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:18<00:52, 141.08it/s]Running 10000 simulations.:  25%|██▌       | 2548/10000 [00:18<00:52, 141.51it/s]Running 10000 simulations.:  26%|██▌       | 2563/10000 [00:18<00:52, 141.64it/s]Running 10000 simulations.:  26%|██▌       | 2578/10000 [00:18<00:52, 142.09it/s]Running 10000 simulations.:  26%|██▌       | 2593/10000 [00:18<00:52, 142.18it/s]Running 10000 simulations.:  26%|██▌       | 2608/10000 [00:18<00:52, 141.77it/s]Running 10000 simulations.:  26%|██▌       | 2623/10000 [00:18<00:52, 141.46it/s]Running 10000 simulations.:  26%|██▋       | 2638/10000 [00:18<00:52, 141.20it/s]Running 10000 simulations.:  27%|██▋       | 2653/10000 [00:18<00:52, 140.81it/s]Running 10000 simulations.:  27%|██▋       | 2668/10000 [00:18<00:52, 140.73it/s]Running 10000 simulations.:  27%|██▋       | 2683/10000 [00:19<00:51, 140.93it/s]Running 10000 simulations.:  27%|██▋       | 2698/10000 [00:19<00:51, 140.79it/s]Running 10000 simulations.:  27%|██▋       | 2713/10000 [00:19<00:51, 140.87it/s]Running 10000 simulations.:  27%|██▋       | 2728/10000 [00:19<00:51, 141.04it/s]Running 10000 simulations.:  27%|██▋       | 2743/10000 [00:19<00:51, 140.85it/s]Running 10000 simulations.:  28%|██▊       | 2758/10000 [00:19<00:51, 140.98it/s]Running 10000 simulations.:  28%|██▊       | 2773/10000 [00:19<00:51, 141.53it/s]Running 10000 simulations.:  28%|██▊       | 2788/10000 [00:19<00:51, 141.13it/s]Running 10000 simulations.:  28%|██▊       | 2803/10000 [00:19<00:52, 137.79it/s]Running 10000 simulations.:  28%|██▊       | 2818/10000 [00:20<00:51, 138.74it/s]Running 10000 simulations.:  28%|██▊       | 2833/10000 [00:20<00:51, 139.35it/s]Running 10000 simulations.:  28%|██▊       | 2848/10000 [00:20<00:50, 140.28it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:20<00:50, 140.40it/s]Running 10000 simulations.:  29%|██▉       | 2878/10000 [00:20<00:50, 140.62it/s]Running 10000 simulations.:  29%|██▉       | 2893/10000 [00:20<00:50, 141.25it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:20<00:50, 140.69it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:20<00:50, 140.86it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:20<00:50, 140.87it/s]Running 10000 simulations.:  30%|██▉       | 2953/10000 [00:21<00:50, 140.68it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:21<00:50, 139.78it/s]Running 10000 simulations.:  30%|██▉       | 2982/10000 [00:21<00:50, 139.80it/s]Running 10000 simulations.:  30%|██▉       | 2997/10000 [00:21<00:49, 140.26it/s]Running 10000 simulations.:  30%|███       | 3012/10000 [00:21<00:49, 141.05it/s]Running 10000 simulations.:  30%|███       | 3027/10000 [00:21<00:49, 141.21it/s]Running 10000 simulations.:  30%|███       | 3042/10000 [00:21<00:49, 140.97it/s]Running 10000 simulations.:  31%|███       | 3057/10000 [00:21<00:49, 140.50it/s]Running 10000 simulations.:  31%|███       | 3072/10000 [00:21<00:49, 140.64it/s]Running 10000 simulations.:  31%|███       | 3087/10000 [00:21<00:49, 141.01it/s]Running 10000 simulations.:  31%|███       | 3102/10000 [00:22<00:48, 140.92it/s]Running 10000 simulations.:  31%|███       | 3117/10000 [00:22<00:49, 140.27it/s]Running 10000 simulations.:  31%|███▏      | 3132/10000 [00:22<00:49, 139.92it/s]Running 10000 simulations.:  31%|███▏      | 3146/10000 [00:22<00:49, 139.43it/s]Running 10000 simulations.:  32%|███▏      | 3160/10000 [00:22<00:49, 139.57it/s]Running 10000 simulations.:  32%|███▏      | 3174/10000 [00:22<00:48, 139.46it/s]Running 10000 simulations.:  32%|███▏      | 3188/10000 [00:22<00:49, 138.12it/s]Running 10000 simulations.:  32%|███▏      | 3202/10000 [00:22<00:49, 137.64it/s]Running 10000 simulations.:  32%|███▏      | 3217/10000 [00:22<00:48, 139.11it/s]Running 10000 simulations.:  32%|███▏      | 3232/10000 [00:23<00:48, 139.93it/s]Running 10000 simulations.:  32%|███▏      | 3247/10000 [00:23<00:48, 140.12it/s]Running 10000 simulations.:  33%|███▎      | 3262/10000 [00:23<00:48, 140.20it/s]Running 10000 simulations.:  33%|███▎      | 3277/10000 [00:23<00:47, 140.18it/s]Running 10000 simulations.:  33%|███▎      | 3292/10000 [00:23<00:47, 140.39it/s]Running 10000 simulations.:  33%|███▎      | 3307/10000 [00:23<00:47, 140.56it/s]Running 10000 simulations.:  33%|███▎      | 3322/10000 [00:23<00:47, 140.75it/s]Running 10000 simulations.:  33%|███▎      | 3337/10000 [00:23<00:47, 141.12it/s]Running 10000 simulations.:  34%|███▎      | 3352/10000 [00:23<00:47, 141.07it/s]Running 10000 simulations.:  34%|███▎      | 3367/10000 [00:23<00:47, 140.00it/s]Running 10000 simulations.:  34%|███▍      | 3382/10000 [00:24<00:47, 140.55it/s]Running 10000 simulations.:  34%|███▍      | 3397/10000 [00:24<00:46, 140.82it/s]Running 10000 simulations.:  34%|███▍      | 3412/10000 [00:24<00:46, 141.15it/s]Running 10000 simulations.:  34%|███▍      | 3427/10000 [00:24<00:46, 141.23it/s]Running 10000 simulations.:  34%|███▍      | 3442/10000 [00:24<00:46, 140.83it/s]Running 10000 simulations.:  35%|███▍      | 3457/10000 [00:24<00:46, 141.59it/s]Running 10000 simulations.:  35%|███▍      | 3472/10000 [00:24<00:46, 141.34it/s]Running 10000 simulations.:  35%|███▍      | 3487/10000 [00:24<00:46, 141.35it/s]Running 10000 simulations.:  35%|███▌      | 3502/10000 [00:24<00:45, 141.70it/s]Running 10000 simulations.:  35%|███▌      | 3517/10000 [00:25<00:45, 141.54it/s]Running 10000 simulations.:  35%|███▌      | 3532/10000 [00:25<00:45, 141.10it/s]Running 10000 simulations.:  35%|███▌      | 3547/10000 [00:25<00:45, 141.03it/s]Running 10000 simulations.:  36%|███▌      | 3562/10000 [00:25<00:45, 141.41it/s]Running 10000 simulations.:  36%|███▌      | 3577/10000 [00:25<00:45, 141.54it/s]Running 10000 simulations.:  36%|███▌      | 3592/10000 [00:25<00:45, 141.95it/s]Running 10000 simulations.:  36%|███▌      | 3607/10000 [00:25<00:44, 142.14it/s]Running 10000 simulations.:  36%|███▌      | 3622/10000 [00:25<00:45, 140.97it/s]Running 10000 simulations.:  36%|███▋      | 3637/10000 [00:25<00:45, 140.77it/s]Running 10000 simulations.:  37%|███▋      | 3652/10000 [00:25<00:44, 141.15it/s]Running 10000 simulations.:  37%|███▋      | 3667/10000 [00:26<00:44, 141.19it/s]Running 10000 simulations.:  37%|███▋      | 3682/10000 [00:26<00:44, 140.89it/s]Running 10000 simulations.:  37%|███▋      | 3697/10000 [00:26<00:44, 140.67it/s]Running 10000 simulations.:  37%|███▋      | 3712/10000 [00:26<00:44, 140.92it/s]Running 10000 simulations.:  37%|███▋      | 3727/10000 [00:26<00:44, 141.59it/s]Running 10000 simulations.:  37%|███▋      | 3742/10000 [00:26<00:44, 141.78it/s]Running 10000 simulations.:  38%|███▊      | 3757/10000 [00:26<00:44, 141.80it/s]Running 10000 simulations.:  38%|███▊      | 3772/10000 [00:26<00:43, 142.12it/s]Running 10000 simulations.:  38%|███▊      | 3787/10000 [00:26<00:43, 142.18it/s]Running 10000 simulations.:  38%|███▊      | 3802/10000 [00:27<00:43, 142.37it/s]Running 10000 simulations.:  38%|███▊      | 3817/10000 [00:27<00:43, 142.58it/s]Running 10000 simulations.:  38%|███▊      | 3832/10000 [00:27<00:43, 141.69it/s]Running 10000 simulations.:  38%|███▊      | 3847/10000 [00:27<00:43, 141.78it/s]Running 10000 simulations.:  39%|███▊      | 3862/10000 [00:27<00:43, 141.74it/s]Running 10000 simulations.:  39%|███▉      | 3877/10000 [00:27<00:43, 141.42it/s]Running 10000 simulations.:  39%|███▉      | 3892/10000 [00:27<00:43, 141.33it/s]Running 10000 simulations.:  39%|███▉      | 3907/10000 [00:27<00:43, 141.28it/s]Running 10000 simulations.:  39%|███▉      | 3922/10000 [00:27<00:43, 141.13it/s]Running 10000 simulations.:  39%|███▉      | 3937/10000 [00:28<00:42, 141.05it/s]Running 10000 simulations.:  40%|███▉      | 3952/10000 [00:28<00:42, 140.94it/s]Running 10000 simulations.:  40%|███▉      | 3967/10000 [00:28<00:42, 140.86it/s]Running 10000 simulations.:  40%|███▉      | 3982/10000 [00:28<00:42, 140.69it/s]Running 10000 simulations.:  40%|███▉      | 3997/10000 [00:28<00:42, 139.99it/s]Running 10000 simulations.:  40%|████      | 4011/10000 [00:28<00:42, 139.85it/s]Running 10000 simulations.:  40%|████      | 4026/10000 [00:28<00:42, 140.18it/s]Running 10000 simulations.:  40%|████      | 4041/10000 [00:28<00:42, 140.50it/s]Running 10000 simulations.:  41%|████      | 4056/10000 [00:28<00:42, 140.52it/s]Running 10000 simulations.:  41%|████      | 4071/10000 [00:28<00:42, 140.88it/s]Running 10000 simulations.:  41%|████      | 4086/10000 [00:29<00:41, 140.81it/s]Running 10000 simulations.:  41%|████      | 4101/10000 [00:29<00:41, 140.97it/s]Running 10000 simulations.:  41%|████      | 4116/10000 [00:29<00:41, 141.15it/s]Running 10000 simulations.:  41%|████▏     | 4131/10000 [00:29<00:41, 141.02it/s]Running 10000 simulations.:  41%|████▏     | 4146/10000 [00:29<00:41, 140.84it/s]Running 10000 simulations.:  42%|████▏     | 4161/10000 [00:29<00:41, 141.38it/s]Running 10000 simulations.:  42%|████▏     | 4176/10000 [00:29<00:41, 141.73it/s]Running 10000 simulations.:  42%|████▏     | 4191/10000 [00:29<00:40, 142.00it/s]Running 10000 simulations.:  42%|████▏     | 4206/10000 [00:29<00:40, 142.39it/s]Running 10000 simulations.:  42%|████▏     | 4221/10000 [00:30<00:40, 142.46it/s]Running 10000 simulations.:  42%|████▏     | 4236/10000 [00:30<00:40, 141.74it/s]Running 10000 simulations.:  43%|████▎     | 4251/10000 [00:30<00:40, 141.26it/s]Running 10000 simulations.:  43%|████▎     | 4266/10000 [00:30<00:40, 140.46it/s]Running 10000 simulations.:  43%|████▎     | 4281/10000 [00:30<00:40, 140.87it/s]Running 10000 simulations.:  43%|████▎     | 4296/10000 [00:30<00:40, 141.53it/s]Running 10000 simulations.:  43%|████▎     | 4311/10000 [00:30<00:40, 141.79it/s]Running 10000 simulations.:  43%|████▎     | 4326/10000 [00:30<00:40, 141.56it/s]Running 10000 simulations.:  43%|████▎     | 4341/10000 [00:30<00:40, 140.91it/s]Running 10000 simulations.:  44%|████▎     | 4356/10000 [00:30<00:40, 140.10it/s]Running 10000 simulations.:  44%|████▎     | 4371/10000 [00:31<00:41, 136.86it/s]Running 10000 simulations.:  44%|████▍     | 4385/10000 [00:31<00:41, 134.59it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:31<00:41, 133.75it/s]Running 10000 simulations.:  44%|████▍     | 4413/10000 [00:31<00:41, 135.13it/s]Running 10000 simulations.:  44%|████▍     | 4427/10000 [00:31<00:40, 136.24it/s]Running 10000 simulations.:  44%|████▍     | 4441/10000 [00:31<00:40, 136.86it/s]Running 10000 simulations.:  45%|████▍     | 4455/10000 [00:31<00:40, 135.75it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:31<00:40, 135.80it/s]Running 10000 simulations.:  45%|████▍     | 4483/10000 [00:31<00:40, 135.94it/s]Running 10000 simulations.:  45%|████▍     | 4497/10000 [00:32<00:40, 135.37it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:32<00:40, 135.60it/s]Running 10000 simulations.:  45%|████▌     | 4525/10000 [00:32<00:40, 135.97it/s]Running 10000 simulations.:  45%|████▌     | 4539/10000 [00:32<00:39, 136.63it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:32<00:39, 136.38it/s]Running 10000 simulations.:  46%|████▌     | 4567/10000 [00:32<00:39, 136.55it/s]Running 10000 simulations.:  46%|████▌     | 4581/10000 [00:32<00:39, 135.87it/s]Running 10000 simulations.:  46%|████▌     | 4595/10000 [00:32<00:39, 136.72it/s]Running 10000 simulations.:  46%|████▌     | 4610/10000 [00:32<00:39, 137.85it/s]Running 10000 simulations.:  46%|████▌     | 4624/10000 [00:32<00:38, 138.42it/s]Running 10000 simulations.:  46%|████▋     | 4638/10000 [00:33<00:38, 138.25it/s]Running 10000 simulations.:  47%|████▋     | 4652/10000 [00:33<00:39, 137.02it/s]Running 10000 simulations.:  47%|████▋     | 4666/10000 [00:33<00:39, 136.01it/s]Running 10000 simulations.:  47%|████▋     | 4680/10000 [00:33<00:39, 135.11it/s]Running 10000 simulations.:  47%|████▋     | 4694/10000 [00:33<00:39, 135.92it/s]Running 10000 simulations.:  47%|████▋     | 4708/10000 [00:33<00:38, 136.77it/s]Running 10000 simulations.:  47%|████▋     | 4723/10000 [00:33<00:38, 137.83it/s]Running 10000 simulations.:  47%|████▋     | 4737/10000 [00:33<00:38, 137.29it/s]Running 10000 simulations.:  48%|████▊     | 4751/10000 [00:33<00:38, 136.95it/s]Running 10000 simulations.:  48%|████▊     | 4765/10000 [00:33<00:38, 136.07it/s]Running 10000 simulations.:  48%|████▊     | 4779/10000 [00:34<00:38, 135.26it/s]Running 10000 simulations.:  48%|████▊     | 4793/10000 [00:34<00:38, 135.35it/s]Running 10000 simulations.:  48%|████▊     | 4807/10000 [00:34<00:38, 136.29it/s]Running 10000 simulations.:  48%|████▊     | 4821/10000 [00:34<00:37, 137.14it/s]Running 10000 simulations.:  48%|████▊     | 4835/10000 [00:34<00:37, 136.54it/s]Running 10000 simulations.:  48%|████▊     | 4849/10000 [00:34<00:37, 136.61it/s]Running 10000 simulations.:  49%|████▊     | 4863/10000 [00:34<00:37, 136.33it/s]Running 10000 simulations.:  49%|████▉     | 4877/10000 [00:34<00:37, 136.38it/s]Running 10000 simulations.:  49%|████▉     | 4891/10000 [00:34<00:37, 136.51it/s]Running 10000 simulations.:  49%|████▉     | 4905/10000 [00:35<00:37, 137.47it/s]Running 10000 simulations.:  49%|████▉     | 4919/10000 [00:35<00:36, 137.47it/s]Running 10000 simulations.:  49%|████▉     | 4933/10000 [00:35<00:36, 137.65it/s]Running 10000 simulations.:  49%|████▉     | 4947/10000 [00:35<00:36, 136.83it/s]Running 10000 simulations.:  50%|████▉     | 4961/10000 [00:35<00:36, 136.97it/s]Running 10000 simulations.:  50%|████▉     | 4975/10000 [00:35<00:36, 137.80it/s]Running 10000 simulations.:  50%|████▉     | 4989/10000 [00:35<00:36, 137.99it/s]Running 10000 simulations.:  50%|█████     | 5003/10000 [00:35<00:36, 137.91it/s]Running 10000 simulations.:  50%|█████     | 5017/10000 [00:35<00:36, 136.69it/s]Running 10000 simulations.:  50%|█████     | 5031/10000 [00:35<00:36, 136.28it/s]Running 10000 simulations.:  50%|█████     | 5045/10000 [00:36<00:36, 137.23it/s]Running 10000 simulations.:  51%|█████     | 5059/10000 [00:36<00:35, 138.04it/s]Running 10000 simulations.:  51%|█████     | 5073/10000 [00:36<00:35, 137.17it/s]Running 10000 simulations.:  51%|█████     | 5087/10000 [00:36<00:36, 136.26it/s]Running 10000 simulations.:  51%|█████     | 5101/10000 [00:36<00:36, 135.78it/s]Running 10000 simulations.:  51%|█████     | 5115/10000 [00:36<00:36, 134.80it/s]Running 10000 simulations.:  51%|█████▏    | 5129/10000 [00:36<00:35, 135.53it/s]Running 10000 simulations.:  51%|█████▏    | 5143/10000 [00:36<00:35, 135.80it/s]Running 10000 simulations.:  52%|█████▏    | 5157/10000 [00:36<00:35, 135.78it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:36<00:35, 135.59it/s]Running 10000 simulations.:  52%|█████▏    | 5185/10000 [00:37<00:35, 136.41it/s]Running 10000 simulations.:  52%|█████▏    | 5200/10000 [00:37<00:34, 137.51it/s]Running 10000 simulations.:  52%|█████▏    | 5214/10000 [00:37<00:34, 137.95it/s]Running 10000 simulations.:  52%|█████▏    | 5229/10000 [00:37<00:34, 138.78it/s]Running 10000 simulations.:  52%|█████▏    | 5243/10000 [00:37<00:34, 138.99it/s]Running 10000 simulations.:  53%|█████▎    | 5257/10000 [00:37<00:34, 136.10it/s]Running 10000 simulations.:  53%|█████▎    | 5271/10000 [00:37<00:34, 135.77it/s]Running 10000 simulations.:  53%|█████▎    | 5285/10000 [00:37<00:34, 136.78it/s]Running 10000 simulations.:  53%|█████▎    | 5300/10000 [00:37<00:34, 137.75it/s]Running 10000 simulations.:  53%|█████▎    | 5314/10000 [00:37<00:33, 138.34it/s]Running 10000 simulations.:  53%|█████▎    | 5329/10000 [00:38<00:33, 138.85it/s]Running 10000 simulations.:  53%|█████▎    | 5343/10000 [00:38<00:33, 138.12it/s]Running 10000 simulations.:  54%|█████▎    | 5357/10000 [00:38<00:33, 137.93it/s]Running 10000 simulations.:  54%|█████▎    | 5371/10000 [00:38<00:33, 138.25it/s]Running 10000 simulations.:  54%|█████▍    | 5385/10000 [00:38<00:33, 138.45it/s]Running 10000 simulations.:  54%|█████▍    | 5399/10000 [00:38<00:33, 138.75it/s]Running 10000 simulations.:  54%|█████▍    | 5413/10000 [00:38<00:33, 138.42it/s]Running 10000 simulations.:  54%|█████▍    | 5427/10000 [00:38<00:33, 137.77it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:38<00:33, 136.63it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:39<00:33, 136.67it/s]Running 10000 simulations.:  55%|█████▍    | 5470/10000 [00:39<00:32, 138.75it/s]Running 10000 simulations.:  55%|█████▍    | 5485/10000 [00:39<00:32, 139.49it/s]Running 10000 simulations.:  55%|█████▌    | 5500/10000 [00:39<00:31, 140.68it/s]Running 10000 simulations.:  55%|█████▌    | 5516/10000 [00:39<00:30, 145.11it/s]Running 10000 simulations.:  55%|█████▌    | 5532/10000 [00:39<00:30, 148.26it/s]Running 10000 simulations.:  55%|█████▌    | 5548/10000 [00:39<00:29, 149.73it/s]Running 10000 simulations.:  56%|█████▌    | 5564/10000 [00:39<00:29, 148.35it/s]Running 10000 simulations.:  56%|█████▌    | 5579/10000 [00:39<00:30, 146.11it/s]Running 10000 simulations.:  56%|█████▌    | 5594/10000 [00:39<00:30, 145.00it/s]Running 10000 simulations.:  56%|█████▌    | 5609/10000 [00:40<00:30, 142.83it/s]Running 10000 simulations.:  56%|█████▌    | 5624/10000 [00:40<00:30, 141.41it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:40<00:31, 139.41it/s]Running 10000 simulations.:  57%|█████▋    | 5653/10000 [00:40<00:31, 139.27it/s]Running 10000 simulations.:  57%|█████▋    | 5668/10000 [00:40<00:30, 140.12it/s]Running 10000 simulations.:  57%|█████▋    | 5683/10000 [00:40<00:30, 140.85it/s]Running 10000 simulations.:  57%|█████▋    | 5698/10000 [00:40<00:30, 140.51it/s]Running 10000 simulations.:  57%|█████▋    | 5713/10000 [00:40<00:30, 139.81it/s]Running 10000 simulations.:  57%|█████▋    | 5728/10000 [00:40<00:30, 140.05it/s]Running 10000 simulations.:  57%|█████▋    | 5743/10000 [00:41<00:30, 140.16it/s]Running 10000 simulations.:  58%|█████▊    | 5758/10000 [00:41<00:30, 140.63it/s]Running 10000 simulations.:  58%|█████▊    | 5773/10000 [00:41<00:29, 140.93it/s]Running 10000 simulations.:  58%|█████▊    | 5788/10000 [00:41<00:29, 140.50it/s]Running 10000 simulations.:  58%|█████▊    | 5803/10000 [00:41<00:29, 140.50it/s]Running 10000 simulations.:  58%|█████▊    | 5818/10000 [00:41<00:29, 140.11it/s]Running 10000 simulations.:  58%|█████▊    | 5833/10000 [00:41<00:29, 139.69it/s]Running 10000 simulations.:  58%|█████▊    | 5848/10000 [00:41<00:29, 140.02it/s]Running 10000 simulations.:  59%|█████▊    | 5863/10000 [00:41<00:29, 140.47it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:41<00:29, 140.26it/s]Running 10000 simulations.:  59%|█████▉    | 5893/10000 [00:42<00:29, 138.92it/s]Running 10000 simulations.:  59%|█████▉    | 5907/10000 [00:42<00:29, 138.66it/s]Running 10000 simulations.:  59%|█████▉    | 5921/10000 [00:42<00:29, 138.76it/s]Running 10000 simulations.:  59%|█████▉    | 5936/10000 [00:42<00:29, 139.90it/s]Running 10000 simulations.:  60%|█████▉    | 5951/10000 [00:42<00:28, 140.84it/s]Running 10000 simulations.:  60%|█████▉    | 5966/10000 [00:42<00:28, 141.34it/s]Running 10000 simulations.:  60%|█████▉    | 5981/10000 [00:42<00:28, 141.75it/s]Running 10000 simulations.:  60%|█████▉    | 5996/10000 [00:42<00:28, 142.22it/s]Running 10000 simulations.:  60%|██████    | 6011/10000 [00:42<00:27, 143.00it/s]Running 10000 simulations.:  60%|██████    | 6026/10000 [00:43<00:27, 143.23it/s]Running 10000 simulations.:  60%|██████    | 6041/10000 [00:43<00:27, 143.80it/s]Running 10000 simulations.:  61%|██████    | 6056/10000 [00:43<00:27, 144.12it/s]Running 10000 simulations.:  61%|██████    | 6071/10000 [00:43<00:27, 143.68it/s]Running 10000 simulations.:  61%|██████    | 6086/10000 [00:43<00:27, 143.82it/s]Running 10000 simulations.:  61%|██████    | 6101/10000 [00:43<00:27, 139.85it/s]Running 10000 simulations.:  61%|██████    | 6116/10000 [00:43<00:28, 136.14it/s]Running 10000 simulations.:  61%|██████▏   | 6130/10000 [00:43<00:29, 132.73it/s]Running 10000 simulations.:  61%|██████▏   | 6144/10000 [00:43<00:29, 131.29it/s]Running 10000 simulations.:  62%|██████▏   | 6158/10000 [00:44<00:29, 131.57it/s]Running 10000 simulations.:  62%|██████▏   | 6172/10000 [00:44<00:31, 122.22it/s]Running 10000 simulations.:  62%|██████▏   | 6186/10000 [00:44<00:30, 124.72it/s]Running 10000 simulations.:  62%|██████▏   | 6200/10000 [00:44<00:30, 126.60it/s]Running 10000 simulations.:  62%|██████▏   | 6214/10000 [00:44<00:29, 128.57it/s]Running 10000 simulations.:  62%|██████▏   | 6228/10000 [00:44<00:29, 129.49it/s]Running 10000 simulations.:  62%|██████▏   | 6242/10000 [00:44<00:28, 129.78it/s]Running 10000 simulations.:  63%|██████▎   | 6256/10000 [00:44<00:28, 130.96it/s]Running 10000 simulations.:  63%|██████▎   | 6270/10000 [00:44<00:28, 131.10it/s]Running 10000 simulations.:  63%|██████▎   | 6284/10000 [00:45<00:28, 131.24it/s]Running 10000 simulations.:  63%|██████▎   | 6298/10000 [00:45<00:28, 131.59it/s]Running 10000 simulations.:  63%|██████▎   | 6312/10000 [00:45<00:27, 132.18it/s]Running 10000 simulations.:  63%|██████▎   | 6326/10000 [00:45<00:27, 132.29it/s]Running 10000 simulations.:  63%|██████▎   | 6340/10000 [00:45<00:27, 132.19it/s]Running 10000 simulations.:  64%|██████▎   | 6354/10000 [00:45<00:27, 132.20it/s]Running 10000 simulations.:  64%|██████▎   | 6368/10000 [00:45<00:27, 131.77it/s]Running 10000 simulations.:  64%|██████▍   | 6382/10000 [00:45<00:27, 132.15it/s]Running 10000 simulations.:  64%|██████▍   | 6396/10000 [00:45<00:27, 131.80it/s]Running 10000 simulations.:  64%|██████▍   | 6410/10000 [00:45<00:27, 131.82it/s]Running 10000 simulations.:  64%|██████▍   | 6424/10000 [00:46<00:27, 131.86it/s]Running 10000 simulations.:  64%|██████▍   | 6438/10000 [00:46<00:27, 131.64it/s]Running 10000 simulations.:  65%|██████▍   | 6452/10000 [00:46<00:26, 131.61it/s]Running 10000 simulations.:  65%|██████▍   | 6466/10000 [00:46<00:26, 131.55it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:46<00:26, 131.87it/s]Running 10000 simulations.:  65%|██████▍   | 6494/10000 [00:46<00:26, 131.93it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:46<00:26, 132.20it/s]Running 10000 simulations.:  65%|██████▌   | 6522/10000 [00:46<00:26, 132.27it/s]Running 10000 simulations.:  65%|██████▌   | 6536/10000 [00:46<00:25, 133.74it/s]Running 10000 simulations.:  66%|██████▌   | 6550/10000 [00:47<00:25, 134.62it/s]Running 10000 simulations.:  66%|██████▌   | 6564/10000 [00:47<00:25, 134.66it/s]Running 10000 simulations.:  66%|██████▌   | 6578/10000 [00:47<00:25, 134.91it/s]Running 10000 simulations.:  66%|██████▌   | 6592/10000 [00:47<00:25, 134.31it/s]Running 10000 simulations.:  66%|██████▌   | 6606/10000 [00:47<00:25, 134.40it/s]Running 10000 simulations.:  66%|██████▌   | 6620/10000 [00:47<00:25, 135.09it/s]Running 10000 simulations.:  66%|██████▋   | 6634/10000 [00:47<00:24, 135.33it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:47<00:24, 134.73it/s]Running 10000 simulations.:  67%|██████▋   | 6662/10000 [00:47<00:24, 134.82it/s]Running 10000 simulations.:  67%|██████▋   | 6676/10000 [00:47<00:24, 135.17it/s]Running 10000 simulations.:  67%|██████▋   | 6690/10000 [00:48<00:24, 135.35it/s]Running 10000 simulations.:  67%|██████▋   | 6704/10000 [00:48<00:24, 134.97it/s]Running 10000 simulations.:  67%|██████▋   | 6718/10000 [00:48<00:24, 135.52it/s]Running 10000 simulations.:  67%|██████▋   | 6732/10000 [00:48<00:24, 135.58it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:48<00:24, 134.94it/s]Running 10000 simulations.:  68%|██████▊   | 6760/10000 [00:48<00:24, 134.66it/s]Running 10000 simulations.:  68%|██████▊   | 6774/10000 [00:48<00:23, 135.03it/s]Running 10000 simulations.:  68%|██████▊   | 6788/10000 [00:48<00:23, 134.95it/s]Running 10000 simulations.:  68%|██████▊   | 6802/10000 [00:48<00:23, 135.61it/s]Running 10000 simulations.:  68%|██████▊   | 6816/10000 [00:48<00:23, 135.94it/s]Running 10000 simulations.:  68%|██████▊   | 6830/10000 [00:49<00:23, 135.62it/s]Running 10000 simulations.:  68%|██████▊   | 6844/10000 [00:49<00:23, 135.57it/s]Running 10000 simulations.:  69%|██████▊   | 6858/10000 [00:49<00:23, 134.96it/s]Running 10000 simulations.:  69%|██████▊   | 6872/10000 [00:49<00:23, 134.73it/s]Running 10000 simulations.:  69%|██████▉   | 6886/10000 [00:49<00:22, 135.61it/s]Running 10000 simulations.:  69%|██████▉   | 6900/10000 [00:49<00:22, 135.94it/s]Running 10000 simulations.:  69%|██████▉   | 6914/10000 [00:49<00:22, 136.49it/s]Running 10000 simulations.:  69%|██████▉   | 6928/10000 [00:49<00:22, 135.07it/s]Running 10000 simulations.:  69%|██████▉   | 6942/10000 [00:49<00:22, 134.73it/s]Running 10000 simulations.:  70%|██████▉   | 6956/10000 [00:50<00:22, 135.23it/s]Running 10000 simulations.:  70%|██████▉   | 6970/10000 [00:50<00:22, 135.36it/s]Running 10000 simulations.:  70%|██████▉   | 6984/10000 [00:50<00:22, 135.05it/s]Running 10000 simulations.:  70%|██████▉   | 6998/10000 [00:50<00:22, 135.12it/s]Running 10000 simulations.:  70%|███████   | 7012/10000 [00:50<00:22, 135.11it/s]Running 10000 simulations.:  70%|███████   | 7026/10000 [00:50<00:22, 134.97it/s]Running 10000 simulations.:  70%|███████   | 7040/10000 [00:50<00:21, 135.46it/s]Running 10000 simulations.:  71%|███████   | 7054/10000 [00:50<00:21, 134.88it/s]Running 10000 simulations.:  71%|███████   | 7068/10000 [00:50<00:21, 135.36it/s]Running 10000 simulations.:  71%|███████   | 7082/10000 [00:50<00:21, 135.39it/s]Running 10000 simulations.:  71%|███████   | 7096/10000 [00:51<00:21, 136.01it/s]Running 10000 simulations.:  71%|███████   | 7110/10000 [00:51<00:21, 135.71it/s]Running 10000 simulations.:  71%|███████   | 7124/10000 [00:51<00:21, 134.83it/s]Running 10000 simulations.:  71%|███████▏  | 7138/10000 [00:51<00:21, 135.31it/s]Running 10000 simulations.:  72%|███████▏  | 7152/10000 [00:51<00:21, 135.41it/s]Running 10000 simulations.:  72%|███████▏  | 7166/10000 [00:51<00:20, 136.15it/s]Running 10000 simulations.:  72%|███████▏  | 7180/10000 [00:51<00:20, 136.42it/s]Running 10000 simulations.:  72%|███████▏  | 7194/10000 [00:51<00:20, 136.65it/s]Running 10000 simulations.:  72%|███████▏  | 7208/10000 [00:51<00:20, 136.36it/s]Running 10000 simulations.:  72%|███████▏  | 7222/10000 [00:51<00:20, 136.55it/s]Running 10000 simulations.:  72%|███████▏  | 7236/10000 [00:52<00:20, 135.89it/s]Running 10000 simulations.:  72%|███████▎  | 7250/10000 [00:52<00:20, 135.77it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:52<00:20, 136.55it/s]Running 10000 simulations.:  73%|███████▎  | 7278/10000 [00:52<00:19, 136.10it/s]Running 10000 simulations.:  73%|███████▎  | 7292/10000 [00:52<00:19, 135.71it/s]Running 10000 simulations.:  73%|███████▎  | 7306/10000 [00:52<00:19, 135.47it/s]Running 10000 simulations.:  73%|███████▎  | 7320/10000 [00:52<00:20, 133.83it/s]Running 10000 simulations.:  73%|███████▎  | 7334/10000 [00:52<00:19, 133.66it/s]Running 10000 simulations.:  73%|███████▎  | 7348/10000 [00:52<00:19, 134.27it/s]Running 10000 simulations.:  74%|███████▎  | 7362/10000 [00:53<00:19, 134.57it/s]Running 10000 simulations.:  74%|███████▍  | 7376/10000 [00:53<00:19, 135.18it/s]Running 10000 simulations.:  74%|███████▍  | 7390/10000 [00:53<00:19, 134.86it/s]Running 10000 simulations.:  74%|███████▍  | 7404/10000 [00:53<00:19, 135.11it/s]Running 10000 simulations.:  74%|███████▍  | 7418/10000 [00:53<00:19, 134.88it/s]Running 10000 simulations.:  74%|███████▍  | 7432/10000 [00:53<00:18, 135.35it/s]Running 10000 simulations.:  74%|███████▍  | 7446/10000 [00:53<00:18, 134.90it/s]Running 10000 simulations.:  75%|███████▍  | 7460/10000 [00:53<00:18, 134.31it/s]Running 10000 simulations.:  75%|███████▍  | 7474/10000 [00:53<00:18, 133.92it/s]Running 10000 simulations.:  75%|███████▍  | 7488/10000 [00:53<00:18, 133.56it/s]Running 10000 simulations.:  75%|███████▌  | 7502/10000 [00:54<00:18, 134.01it/s]Running 10000 simulations.:  75%|███████▌  | 7516/10000 [00:54<00:18, 134.89it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:54<00:18, 135.14it/s]Running 10000 simulations.:  75%|███████▌  | 7544/10000 [00:54<00:18, 135.29it/s]Running 10000 simulations.:  76%|███████▌  | 7558/10000 [00:54<00:18, 135.21it/s]Running 10000 simulations.:  76%|███████▌  | 7572/10000 [00:54<00:17, 135.37it/s]Running 10000 simulations.:  76%|███████▌  | 7586/10000 [00:54<00:17, 135.51it/s]Running 10000 simulations.:  76%|███████▌  | 7600/10000 [00:54<00:17, 135.38it/s]Running 10000 simulations.:  76%|███████▌  | 7614/10000 [00:54<00:17, 135.47it/s]Running 10000 simulations.:  76%|███████▋  | 7628/10000 [00:54<00:17, 136.00it/s]Running 10000 simulations.:  76%|███████▋  | 7642/10000 [00:55<00:17, 135.36it/s]Running 10000 simulations.:  77%|███████▋  | 7656/10000 [00:55<00:17, 134.76it/s]Running 10000 simulations.:  77%|███████▋  | 7670/10000 [00:55<00:17, 135.14it/s]Running 10000 simulations.:  77%|███████▋  | 7684/10000 [00:55<00:17, 135.61it/s]Running 10000 simulations.:  77%|███████▋  | 7698/10000 [00:55<00:16, 135.81it/s]Running 10000 simulations.:  77%|███████▋  | 7712/10000 [00:55<00:16, 135.88it/s]Running 10000 simulations.:  77%|███████▋  | 7726/10000 [00:55<00:16, 135.47it/s]Running 10000 simulations.:  77%|███████▋  | 7740/10000 [00:55<00:16, 134.90it/s]Running 10000 simulations.:  78%|███████▊  | 7754/10000 [00:55<00:16, 135.18it/s]Running 10000 simulations.:  78%|███████▊  | 7768/10000 [00:56<00:16, 135.31it/s]Running 10000 simulations.:  78%|███████▊  | 7782/10000 [00:56<00:16, 135.85it/s]Running 10000 simulations.:  78%|███████▊  | 7796/10000 [00:56<00:16, 136.32it/s]Running 10000 simulations.:  78%|███████▊  | 7810/10000 [00:56<00:16, 136.17it/s]Running 10000 simulations.:  78%|███████▊  | 7824/10000 [00:56<00:16, 135.97it/s]Running 10000 simulations.:  78%|███████▊  | 7838/10000 [00:56<00:16, 135.04it/s]Running 10000 simulations.:  79%|███████▊  | 7852/10000 [00:56<00:15, 135.09it/s]Running 10000 simulations.:  79%|███████▊  | 7866/10000 [00:56<00:15, 134.66it/s]Running 10000 simulations.:  79%|███████▉  | 7880/10000 [00:56<00:15, 133.56it/s]Running 10000 simulations.:  79%|███████▉  | 7894/10000 [00:56<00:15, 135.25it/s]Running 10000 simulations.:  79%|███████▉  | 7908/10000 [00:57<00:15, 136.19it/s]Running 10000 simulations.:  79%|███████▉  | 7922/10000 [00:57<00:15, 136.56it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:57<00:15, 136.59it/s]Running 10000 simulations.:  80%|███████▉  | 7950/10000 [00:57<00:14, 136.68it/s]Running 10000 simulations.:  80%|███████▉  | 7964/10000 [00:57<00:14, 137.04it/s]Running 10000 simulations.:  80%|███████▉  | 7978/10000 [00:57<00:14, 137.63it/s]Running 10000 simulations.:  80%|███████▉  | 7992/10000 [00:57<00:14, 137.09it/s]Running 10000 simulations.:  80%|████████  | 8006/10000 [00:57<00:14, 136.67it/s]Running 10000 simulations.:  80%|████████  | 8020/10000 [00:57<00:14, 136.12it/s]Running 10000 simulations.:  80%|████████  | 8034/10000 [00:57<00:14, 136.49it/s]Running 10000 simulations.:  80%|████████  | 8048/10000 [00:58<00:14, 137.11it/s]Running 10000 simulations.:  81%|████████  | 8062/10000 [00:58<00:14, 136.95it/s]Running 10000 simulations.:  81%|████████  | 8076/10000 [00:58<00:13, 137.76it/s]Running 10000 simulations.:  81%|████████  | 8090/10000 [00:58<00:13, 137.95it/s]Running 10000 simulations.:  81%|████████  | 8104/10000 [00:58<00:13, 136.48it/s]Running 10000 simulations.:  81%|████████  | 8118/10000 [00:58<00:13, 137.12it/s]Running 10000 simulations.:  81%|████████▏ | 8132/10000 [00:58<00:13, 137.76it/s]Running 10000 simulations.:  81%|████████▏ | 8146/10000 [00:58<00:13, 137.37it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:58<00:13, 137.67it/s]Running 10000 simulations.:  82%|████████▏ | 8174/10000 [00:58<00:13, 137.95it/s]Running 10000 simulations.:  82%|████████▏ | 8188/10000 [00:59<00:13, 137.53it/s]Running 10000 simulations.:  82%|████████▏ | 8202/10000 [00:59<00:13, 136.95it/s]Running 10000 simulations.:  82%|████████▏ | 8216/10000 [00:59<00:13, 137.01it/s]Running 10000 simulations.:  82%|████████▏ | 8230/10000 [00:59<00:12, 136.92it/s]Running 10000 simulations.:  82%|████████▏ | 8244/10000 [00:59<00:12, 137.44it/s]Running 10000 simulations.:  83%|████████▎ | 8258/10000 [00:59<00:12, 137.32it/s]Running 10000 simulations.:  83%|████████▎ | 8272/10000 [00:59<00:12, 137.30it/s]Running 10000 simulations.:  83%|████████▎ | 8287/10000 [00:59<00:12, 138.17it/s]Running 10000 simulations.:  83%|████████▎ | 8302/10000 [00:59<00:12, 139.27it/s]Running 10000 simulations.:  83%|████████▎ | 8317/10000 [01:00<00:12, 140.20it/s]Running 10000 simulations.:  83%|████████▎ | 8332/10000 [01:00<00:11, 140.79it/s]Running 10000 simulations.:  83%|████████▎ | 8347/10000 [01:00<00:11, 141.11it/s]Running 10000 simulations.:  84%|████████▎ | 8362/10000 [01:00<00:11, 141.79it/s]Running 10000 simulations.:  84%|████████▍ | 8377/10000 [01:00<00:11, 142.55it/s]Running 10000 simulations.:  84%|████████▍ | 8392/10000 [01:00<00:11, 142.82it/s]Running 10000 simulations.:  84%|████████▍ | 8407/10000 [01:00<00:11, 143.25it/s]Running 10000 simulations.:  84%|████████▍ | 8422/10000 [01:00<00:11, 143.17it/s]Running 10000 simulations.:  84%|████████▍ | 8437/10000 [01:00<00:11, 142.07it/s]Running 10000 simulations.:  85%|████████▍ | 8452/10000 [01:00<00:10, 142.47it/s]Running 10000 simulations.:  85%|████████▍ | 8467/10000 [01:01<00:10, 142.01it/s]Running 10000 simulations.:  85%|████████▍ | 8482/10000 [01:01<00:10, 142.12it/s]Running 10000 simulations.:  85%|████████▍ | 8497/10000 [01:01<00:10, 142.19it/s]Running 10000 simulations.:  85%|████████▌ | 8512/10000 [01:01<00:10, 142.37it/s]Running 10000 simulations.:  85%|████████▌ | 8527/10000 [01:01<00:10, 142.21it/s]Running 10000 simulations.:  85%|████████▌ | 8542/10000 [01:01<00:10, 141.90it/s]Running 10000 simulations.:  86%|████████▌ | 8557/10000 [01:01<00:10, 142.34it/s]Running 10000 simulations.:  86%|████████▌ | 8572/10000 [01:01<00:10, 142.55it/s]Running 10000 simulations.:  86%|████████▌ | 8587/10000 [01:01<00:09, 142.10it/s]Running 10000 simulations.:  86%|████████▌ | 8602/10000 [01:02<00:09, 142.38it/s]Running 10000 simulations.:  86%|████████▌ | 8617/10000 [01:02<00:09, 142.29it/s]Running 10000 simulations.:  86%|████████▋ | 8632/10000 [01:02<00:09, 142.00it/s]Running 10000 simulations.:  86%|████████▋ | 8647/10000 [01:02<00:09, 141.84it/s]Running 10000 simulations.:  87%|████████▋ | 8662/10000 [01:02<00:09, 142.03it/s]Running 10000 simulations.:  87%|████████▋ | 8677/10000 [01:02<00:09, 141.47it/s]Running 10000 simulations.:  87%|████████▋ | 8692/10000 [01:02<00:09, 141.63it/s]Running 10000 simulations.:  87%|████████▋ | 8707/10000 [01:02<00:09, 141.75it/s]Running 10000 simulations.:  87%|████████▋ | 8722/10000 [01:02<00:09, 141.84it/s]Running 10000 simulations.:  87%|████████▋ | 8737/10000 [01:02<00:08, 141.75it/s]Running 10000 simulations.:  88%|████████▊ | 8752/10000 [01:03<00:08, 142.20it/s]Running 10000 simulations.:  88%|████████▊ | 8767/10000 [01:03<00:08, 141.81it/s]Running 10000 simulations.:  88%|████████▊ | 8782/10000 [01:03<00:08, 140.82it/s]Running 10000 simulations.:  88%|████████▊ | 8797/10000 [01:03<00:08, 140.80it/s]Running 10000 simulations.:  88%|████████▊ | 8812/10000 [01:03<00:08, 141.19it/s]Running 10000 simulations.:  88%|████████▊ | 8827/10000 [01:03<00:08, 141.57it/s]Running 10000 simulations.:  88%|████████▊ | 8842/10000 [01:03<00:08, 141.81it/s]Running 10000 simulations.:  89%|████████▊ | 8857/10000 [01:03<00:08, 141.37it/s]Running 10000 simulations.:  89%|████████▊ | 8872/10000 [01:03<00:08, 140.50it/s]Running 10000 simulations.:  89%|████████▉ | 8887/10000 [01:04<00:07, 140.12it/s]Running 10000 simulations.:  89%|████████▉ | 8902/10000 [01:04<00:07, 140.67it/s]Running 10000 simulations.:  89%|████████▉ | 8917/10000 [01:04<00:07, 139.98it/s]Running 10000 simulations.:  89%|████████▉ | 8932/10000 [01:04<00:07, 139.54it/s]Running 10000 simulations.:  89%|████████▉ | 8946/10000 [01:04<00:07, 139.42it/s]Running 10000 simulations.:  90%|████████▉ | 8961/10000 [01:04<00:07, 140.49it/s]Running 10000 simulations.:  90%|████████▉ | 8976/10000 [01:04<00:07, 141.15it/s]Running 10000 simulations.:  90%|████████▉ | 8991/10000 [01:04<00:07, 141.38it/s]Running 10000 simulations.:  90%|█████████ | 9006/10000 [01:04<00:07, 140.47it/s]Running 10000 simulations.:  90%|█████████ | 9021/10000 [01:04<00:06, 140.80it/s]Running 10000 simulations.:  90%|█████████ | 9036/10000 [01:05<00:06, 140.31it/s]Running 10000 simulations.:  91%|█████████ | 9051/10000 [01:05<00:06, 140.43it/s]Running 10000 simulations.:  91%|█████████ | 9066/10000 [01:05<00:06, 140.90it/s]Running 10000 simulations.:  91%|█████████ | 9081/10000 [01:05<00:06, 140.89it/s]Running 10000 simulations.:  91%|█████████ | 9096/10000 [01:05<00:06, 141.11it/s]Running 10000 simulations.:  91%|█████████ | 9111/10000 [01:05<00:06, 141.43it/s]Running 10000 simulations.:  91%|█████████▏| 9126/10000 [01:05<00:06, 140.66it/s]Running 10000 simulations.:  91%|█████████▏| 9141/10000 [01:05<00:06, 140.71it/s]Running 10000 simulations.:  92%|█████████▏| 9156/10000 [01:05<00:05, 140.72it/s]Running 10000 simulations.:  92%|█████████▏| 9171/10000 [01:06<00:05, 141.24it/s]Running 10000 simulations.:  92%|█████████▏| 9186/10000 [01:06<00:05, 141.07it/s]Running 10000 simulations.:  92%|█████████▏| 9201/10000 [01:06<00:05, 140.92it/s]Running 10000 simulations.:  92%|█████████▏| 9216/10000 [01:06<00:05, 140.14it/s]Running 10000 simulations.:  92%|█████████▏| 9231/10000 [01:06<00:05, 140.91it/s]Running 10000 simulations.:  92%|█████████▏| 9246/10000 [01:06<00:05, 141.01it/s]Running 10000 simulations.:  93%|█████████▎| 9261/10000 [01:06<00:05, 141.18it/s]Running 10000 simulations.:  93%|█████████▎| 9276/10000 [01:06<00:05, 139.75it/s]Running 10000 simulations.:  93%|█████████▎| 9290/10000 [01:06<00:05, 139.42it/s]Running 10000 simulations.:  93%|█████████▎| 9304/10000 [01:07<00:05, 139.12it/s]Running 10000 simulations.:  93%|█████████▎| 9319/10000 [01:07<00:04, 139.38it/s]Running 10000 simulations.:  93%|█████████▎| 9334/10000 [01:07<00:04, 139.97it/s]Running 10000 simulations.:  93%|█████████▎| 9348/10000 [01:07<00:04, 137.27it/s]Running 10000 simulations.:  94%|█████████▎| 9363/10000 [01:07<00:04, 138.88it/s]Running 10000 simulations.:  94%|█████████▍| 9378/10000 [01:07<00:04, 139.68it/s]Running 10000 simulations.:  94%|█████████▍| 9393/10000 [01:07<00:04, 140.18it/s]Running 10000 simulations.:  94%|█████████▍| 9408/10000 [01:07<00:04, 140.62it/s]Running 10000 simulations.:  94%|█████████▍| 9423/10000 [01:07<00:04, 141.28it/s]Running 10000 simulations.:  94%|█████████▍| 9438/10000 [01:07<00:03, 141.07it/s]Running 10000 simulations.:  95%|█████████▍| 9453/10000 [01:08<00:03, 140.73it/s]Running 10000 simulations.:  95%|█████████▍| 9468/10000 [01:08<00:03, 140.78it/s]Running 10000 simulations.:  95%|█████████▍| 9483/10000 [01:08<00:03, 140.50it/s]Running 10000 simulations.:  95%|█████████▍| 9498/10000 [01:08<00:03, 140.78it/s]Running 10000 simulations.:  95%|█████████▌| 9513/10000 [01:08<00:03, 141.37it/s]Running 10000 simulations.:  95%|█████████▌| 9528/10000 [01:08<00:03, 141.14it/s]Running 10000 simulations.:  95%|█████████▌| 9543/10000 [01:08<00:03, 140.08it/s]Running 10000 simulations.:  96%|█████████▌| 9558/10000 [01:08<00:03, 139.54it/s]Running 10000 simulations.:  96%|█████████▌| 9572/10000 [01:08<00:03, 139.40it/s]Running 10000 simulations.:  96%|█████████▌| 9587/10000 [01:09<00:02, 139.94it/s]Running 10000 simulations.:  96%|█████████▌| 9602/10000 [01:09<00:02, 141.02it/s]Running 10000 simulations.:  96%|█████████▌| 9617/10000 [01:09<00:02, 140.94it/s]Running 10000 simulations.:  96%|█████████▋| 9632/10000 [01:09<00:02, 141.39it/s]Running 10000 simulations.:  96%|█████████▋| 9647/10000 [01:09<00:02, 141.63it/s]Running 10000 simulations.:  97%|█████████▋| 9662/10000 [01:09<00:02, 141.63it/s]Running 10000 simulations.:  97%|█████████▋| 9677/10000 [01:09<00:02, 141.93it/s]Running 10000 simulations.:  97%|█████████▋| 9692/10000 [01:09<00:02, 141.62it/s]Running 10000 simulations.:  97%|█████████▋| 9707/10000 [01:09<00:02, 141.12it/s]Running 10000 simulations.:  97%|█████████▋| 9722/10000 [01:09<00:01, 141.28it/s]Running 10000 simulations.:  97%|█████████▋| 9737/10000 [01:10<00:01, 141.99it/s]Running 10000 simulations.:  98%|█████████▊| 9752/10000 [01:10<00:01, 141.58it/s]Running 10000 simulations.:  98%|█████████▊| 9767/10000 [01:10<00:01, 141.87it/s]Running 10000 simulations.:  98%|█████████▊| 9782/10000 [01:10<00:01, 142.13it/s]Running 10000 simulations.:  98%|█████████▊| 9797/10000 [01:10<00:01, 141.02it/s]Running 10000 simulations.:  98%|█████████▊| 9812/10000 [01:10<00:01, 141.21it/s]Running 10000 simulations.:  98%|█████████▊| 9827/10000 [01:10<00:01, 141.56it/s]Running 10000 simulations.:  98%|█████████▊| 9842/10000 [01:10<00:01, 141.18it/s]Running 10000 simulations.:  99%|█████████▊| 9857/10000 [01:10<00:01, 140.95it/s]Running 10000 simulations.:  99%|█████████▊| 9872/10000 [01:11<00:00, 140.58it/s]Running 10000 simulations.:  99%|█████████▉| 9887/10000 [01:11<00:00, 141.15it/s]Running 10000 simulations.:  99%|█████████▉| 9902/10000 [01:11<00:00, 141.80it/s]Running 10000 simulations.:  99%|█████████▉| 9917/10000 [01:11<00:00, 141.86it/s]Running 10000 simulations.:  99%|█████████▉| 9932/10000 [01:11<00:00, 140.24it/s]Running 10000 simulations.:  99%|█████████▉| 9947/10000 [01:11<00:00, 140.42it/s]Running 10000 simulations.: 100%|█████████▉| 9962/10000 [01:11<00:00, 139.59it/s]Running 10000 simulations.: 100%|█████████▉| 9977/10000 [01:11<00:00, 139.57it/s]Running 10000 simulations.: 100%|█████████▉| 9991/10000 [01:11<00:00, 137.00it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:11<00:00, 138.97it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:40, 244.36it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:40, 244.32it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:40, 243.03it/s]Running 10000 simulations.:   1%|          | 99/10000 [00:00<00:40, 241.86it/s]Running 10000 simulations.:   1%|          | 124/10000 [00:00<00:40, 241.41it/s]Running 10000 simulations.:   1%|▏         | 148/10000 [00:00<00:40, 240.88it/s]Running 10000 simulations.:   2%|▏         | 172/10000 [00:00<00:40, 240.21it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:00<00:40, 240.36it/s]Running 10000 simulations.:   2%|▏         | 221/10000 [00:00<00:40, 240.10it/s]Running 10000 simulations.:   2%|▏         | 245/10000 [00:01<00:40, 239.45it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:01<00:40, 238.94it/s]Running 10000 simulations.:   3%|▎         | 293/10000 [00:01<00:40, 238.74it/s]Running 10000 simulations.:   3%|▎         | 317/10000 [00:01<00:40, 238.50it/s]Running 10000 simulations.:   3%|▎         | 341/10000 [00:01<00:40, 237.97it/s]Running 10000 simulations.:   4%|▎         | 365/10000 [00:01<00:40, 237.48it/s]Running 10000 simulations.:   4%|▍         | 389/10000 [00:01<00:40, 237.56it/s]Running 10000 simulations.:   4%|▍         | 413/10000 [00:01<00:40, 236.76it/s]Running 10000 simulations.:   4%|▍         | 437/10000 [00:01<00:40, 236.69it/s]Running 10000 simulations.:   5%|▍         | 461/10000 [00:01<00:40, 237.13it/s]Running 10000 simulations.:   5%|▍         | 485/10000 [00:02<00:40, 237.13it/s]Running 10000 simulations.:   5%|▌         | 509/10000 [00:02<00:39, 237.30it/s]Running 10000 simulations.:   5%|▌         | 533/10000 [00:02<00:39, 236.77it/s]Running 10000 simulations.:   6%|▌         | 557/10000 [00:02<00:40, 235.75it/s]Running 10000 simulations.:   6%|▌         | 581/10000 [00:02<00:40, 235.05it/s]Running 10000 simulations.:   6%|▌         | 605/10000 [00:02<00:39, 235.02it/s]Running 10000 simulations.:   6%|▋         | 629/10000 [00:02<00:39, 235.12it/s]Running 10000 simulations.:   7%|▋         | 653/10000 [00:02<00:39, 236.00it/s]Running 10000 simulations.:   7%|▋         | 677/10000 [00:02<00:39, 235.93it/s]Running 10000 simulations.:   7%|▋         | 701/10000 [00:02<00:39, 235.68it/s]Running 10000 simulations.:   7%|▋         | 725/10000 [00:03<00:39, 235.43it/s]Running 10000 simulations.:   7%|▋         | 749/10000 [00:03<00:39, 234.80it/s]Running 10000 simulations.:   8%|▊         | 773/10000 [00:03<00:39, 234.16it/s]Running 10000 simulations.:   8%|▊         | 797/10000 [00:03<00:39, 234.11it/s]Running 10000 simulations.:   8%|▊         | 821/10000 [00:03<00:39, 234.06it/s]Running 10000 simulations.:   8%|▊         | 845/10000 [00:03<00:39, 234.05it/s]Running 10000 simulations.:   9%|▊         | 869/10000 [00:03<00:39, 233.85it/s]Running 10000 simulations.:   9%|▉         | 893/10000 [00:03<00:38, 234.15it/s]Running 10000 simulations.:   9%|▉         | 917/10000 [00:03<00:38, 233.98it/s]Running 10000 simulations.:   9%|▉         | 941/10000 [00:03<00:38, 233.73it/s]Running 10000 simulations.:  10%|▉         | 965/10000 [00:04<00:38, 234.20it/s]Running 10000 simulations.:  10%|▉         | 989/10000 [00:04<00:38, 233.77it/s]Running 10000 simulations.:  10%|█         | 1013/10000 [00:04<00:38, 232.46it/s]Running 10000 simulations.:  10%|█         | 1037/10000 [00:04<00:38, 231.58it/s]Running 10000 simulations.:  11%|█         | 1061/10000 [00:04<00:38, 230.67it/s]Running 10000 simulations.:  11%|█         | 1085/10000 [00:04<00:38, 229.39it/s]Running 10000 simulations.:  11%|█         | 1108/10000 [00:04<00:38, 229.11it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:04<00:38, 228.74it/s]Running 10000 simulations.:  12%|█▏        | 1154/10000 [00:04<00:38, 228.31it/s]Running 10000 simulations.:  12%|█▏        | 1177/10000 [00:05<00:38, 227.92it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:05<00:38, 228.30it/s]Running 10000 simulations.:  12%|█▏        | 1223/10000 [00:05<00:38, 228.38it/s]Running 10000 simulations.:  12%|█▏        | 1246/10000 [00:05<00:38, 228.63it/s]Running 10000 simulations.:  13%|█▎        | 1269/10000 [00:05<00:38, 228.95it/s]Running 10000 simulations.:  13%|█▎        | 1292/10000 [00:05<00:38, 228.72it/s]Running 10000 simulations.:  13%|█▎        | 1315/10000 [00:05<00:37, 228.67it/s]Running 10000 simulations.:  13%|█▎        | 1339/10000 [00:05<00:37, 229.08it/s]Running 10000 simulations.:  14%|█▎        | 1362/10000 [00:05<00:37, 228.18it/s]Running 10000 simulations.:  14%|█▍        | 1385/10000 [00:05<00:37, 227.75it/s]Running 10000 simulations.:  14%|█▍        | 1408/10000 [00:06<00:37, 228.17it/s]Running 10000 simulations.:  14%|█▍        | 1431/10000 [00:06<00:37, 228.14it/s]Running 10000 simulations.:  15%|█▍        | 1454/10000 [00:06<00:37, 228.43it/s]Running 10000 simulations.:  15%|█▍        | 1477/10000 [00:06<00:37, 228.68it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:06<00:37, 229.00it/s]Running 10000 simulations.:  15%|█▌        | 1523/10000 [00:06<00:37, 229.10it/s]Running 10000 simulations.:  15%|█▌        | 1546/10000 [00:06<00:36, 228.49it/s]Running 10000 simulations.:  16%|█▌        | 1569/10000 [00:06<00:36, 228.42it/s]Running 10000 simulations.:  16%|█▌        | 1592/10000 [00:06<00:36, 228.43it/s]Running 10000 simulations.:  16%|█▌        | 1615/10000 [00:06<00:36, 228.56it/s]Running 10000 simulations.:  16%|█▋        | 1638/10000 [00:07<00:36, 228.34it/s]Running 10000 simulations.:  17%|█▋        | 1661/10000 [00:07<00:36, 227.61it/s]Running 10000 simulations.:  17%|█▋        | 1684/10000 [00:07<00:36, 227.57it/s]Running 10000 simulations.:  17%|█▋        | 1707/10000 [00:07<00:36, 227.71it/s]Running 10000 simulations.:  17%|█▋        | 1730/10000 [00:07<00:36, 228.23it/s]Running 10000 simulations.:  18%|█▊        | 1753/10000 [00:07<00:36, 227.40it/s]Running 10000 simulations.:  18%|█▊        | 1776/10000 [00:07<00:36, 226.71it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:07<00:36, 226.21it/s]Running 10000 simulations.:  18%|█▊        | 1822/10000 [00:07<00:36, 226.39it/s]Running 10000 simulations.:  18%|█▊        | 1845/10000 [00:07<00:35, 226.98it/s]Running 10000 simulations.:  19%|█▊        | 1868/10000 [00:08<00:36, 225.87it/s]Running 10000 simulations.:  19%|█▉        | 1891/10000 [00:08<00:35, 226.01it/s]Running 10000 simulations.:  19%|█▉        | 1914/10000 [00:08<00:35, 226.55it/s]Running 10000 simulations.:  19%|█▉        | 1937/10000 [00:08<00:35, 226.79it/s]Running 10000 simulations.:  20%|█▉        | 1960/10000 [00:08<00:35, 226.96it/s]Running 10000 simulations.:  20%|█▉        | 1983/10000 [00:08<00:35, 226.69it/s]Running 10000 simulations.:  20%|██        | 2006/10000 [00:08<00:35, 226.73it/s]Running 10000 simulations.:  20%|██        | 2029/10000 [00:08<00:35, 227.16it/s]Running 10000 simulations.:  21%|██        | 2053/10000 [00:08<00:34, 230.04it/s]Running 10000 simulations.:  21%|██        | 2077/10000 [00:08<00:34, 232.13it/s]Running 10000 simulations.:  21%|██        | 2101/10000 [00:09<00:33, 232.86it/s]Running 10000 simulations.:  21%|██▏       | 2125/10000 [00:09<00:33, 232.85it/s]Running 10000 simulations.:  21%|██▏       | 2149/10000 [00:09<00:33, 232.15it/s]Running 10000 simulations.:  22%|██▏       | 2173/10000 [00:09<00:33, 232.32it/s]Running 10000 simulations.:  22%|██▏       | 2197/10000 [00:09<00:33, 232.73it/s]Running 10000 simulations.:  22%|██▏       | 2221/10000 [00:09<00:33, 233.90it/s]Running 10000 simulations.:  22%|██▏       | 2245/10000 [00:09<00:33, 234.01it/s]Running 10000 simulations.:  23%|██▎       | 2269/10000 [00:09<00:32, 235.07it/s]Running 10000 simulations.:  23%|██▎       | 2293/10000 [00:09<00:32, 234.45it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:09<00:32, 234.20it/s]Running 10000 simulations.:  23%|██▎       | 2341/10000 [00:10<00:32, 233.83it/s]Running 10000 simulations.:  24%|██▎       | 2365/10000 [00:10<00:32, 233.12it/s]Running 10000 simulations.:  24%|██▍       | 2389/10000 [00:10<00:32, 231.88it/s]Running 10000 simulations.:  24%|██▍       | 2413/10000 [00:10<00:32, 231.06it/s]Running 10000 simulations.:  24%|██▍       | 2437/10000 [00:10<00:32, 231.12it/s]Running 10000 simulations.:  25%|██▍       | 2461/10000 [00:10<00:32, 231.58it/s]Running 10000 simulations.:  25%|██▍       | 2485/10000 [00:10<00:32, 232.01it/s]Running 10000 simulations.:  25%|██▌       | 2509/10000 [00:10<00:32, 231.40it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:10<00:32, 231.00it/s]Running 10000 simulations.:  26%|██▌       | 2557/10000 [00:11<00:32, 231.15it/s]Running 10000 simulations.:  26%|██▌       | 2581/10000 [00:11<00:32, 231.37it/s]Running 10000 simulations.:  26%|██▌       | 2605/10000 [00:11<00:32, 230.43it/s]Running 10000 simulations.:  26%|██▋       | 2629/10000 [00:11<00:32, 229.41it/s]Running 10000 simulations.:  27%|██▋       | 2653/10000 [00:11<00:31, 229.85it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:11<00:31, 230.05it/s]Running 10000 simulations.:  27%|██▋       | 2701/10000 [00:11<00:31, 230.17it/s]Running 10000 simulations.:  27%|██▋       | 2725/10000 [00:11<00:31, 229.79it/s]Running 10000 simulations.:  27%|██▋       | 2748/10000 [00:11<00:31, 229.74it/s]Running 10000 simulations.:  28%|██▊       | 2771/10000 [00:11<00:31, 229.73it/s]Running 10000 simulations.:  28%|██▊       | 2795/10000 [00:12<00:31, 229.99it/s]Running 10000 simulations.:  28%|██▊       | 2818/10000 [00:12<00:31, 229.94it/s]Running 10000 simulations.:  28%|██▊       | 2842/10000 [00:12<00:31, 230.45it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:12<00:30, 230.37it/s]Running 10000 simulations.:  29%|██▉       | 2890/10000 [00:12<00:30, 230.23it/s]Running 10000 simulations.:  29%|██▉       | 2914/10000 [00:12<00:30, 230.18it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:12<00:30, 230.73it/s]Running 10000 simulations.:  30%|██▉       | 2962/10000 [00:12<00:30, 230.89it/s]Running 10000 simulations.:  30%|██▉       | 2986/10000 [00:12<00:30, 231.45it/s]Running 10000 simulations.:  30%|███       | 3010/10000 [00:12<00:30, 232.01it/s]Running 10000 simulations.:  30%|███       | 3034/10000 [00:13<00:29, 232.56it/s]Running 10000 simulations.:  31%|███       | 3058/10000 [00:13<00:29, 232.76it/s]Running 10000 simulations.:  31%|███       | 3082/10000 [00:13<00:29, 232.46it/s]Running 10000 simulations.:  31%|███       | 3106/10000 [00:13<00:29, 230.42it/s]Running 10000 simulations.:  31%|███▏      | 3130/10000 [00:13<00:30, 228.19it/s]Running 10000 simulations.:  32%|███▏      | 3153/10000 [00:13<00:30, 226.23it/s]Running 10000 simulations.:  32%|███▏      | 3176/10000 [00:13<00:30, 226.15it/s]Running 10000 simulations.:  32%|███▏      | 3199/10000 [00:13<00:29, 227.11it/s]Running 10000 simulations.:  32%|███▏      | 3223/10000 [00:13<00:29, 229.15it/s]Running 10000 simulations.:  32%|███▏      | 3247/10000 [00:14<00:29, 230.04it/s]Running 10000 simulations.:  33%|███▎      | 3271/10000 [00:14<00:29, 230.54it/s]Running 10000 simulations.:  33%|███▎      | 3295/10000 [00:14<00:29, 230.49it/s]Running 10000 simulations.:  33%|███▎      | 3319/10000 [00:14<00:28, 231.07it/s]Running 10000 simulations.:  33%|███▎      | 3343/10000 [00:14<00:28, 231.59it/s]Running 10000 simulations.:  34%|███▎      | 3367/10000 [00:14<00:28, 231.66it/s]Running 10000 simulations.:  34%|███▍      | 3391/10000 [00:14<00:28, 231.45it/s]Running 10000 simulations.:  34%|███▍      | 3415/10000 [00:14<00:28, 231.50it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:14<00:28, 231.70it/s]Running 10000 simulations.:  35%|███▍      | 3463/10000 [00:14<00:28, 231.84it/s]Running 10000 simulations.:  35%|███▍      | 3487/10000 [00:15<00:28, 231.80it/s]Running 10000 simulations.:  35%|███▌      | 3511/10000 [00:15<00:27, 231.81it/s]Running 10000 simulations.:  35%|███▌      | 3535/10000 [00:15<00:28, 229.35it/s]Running 10000 simulations.:  36%|███▌      | 3558/10000 [00:15<00:28, 229.30it/s]Running 10000 simulations.:  36%|███▌      | 3582/10000 [00:15<00:27, 229.60it/s]Running 10000 simulations.:  36%|███▌      | 3606/10000 [00:15<00:27, 229.94it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:15<00:27, 230.34it/s]Running 10000 simulations.:  37%|███▋      | 3654/10000 [00:15<00:27, 230.07it/s]Running 10000 simulations.:  37%|███▋      | 3678/10000 [00:15<00:27, 230.33it/s]Running 10000 simulations.:  37%|███▋      | 3702/10000 [00:15<00:27, 229.94it/s]Running 10000 simulations.:  37%|███▋      | 3726/10000 [00:16<00:27, 229.96it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:16<00:27, 229.81it/s]Running 10000 simulations.:  38%|███▊      | 3773/10000 [00:16<00:27, 230.04it/s]Running 10000 simulations.:  38%|███▊      | 3797/10000 [00:16<00:26, 230.20it/s]Running 10000 simulations.:  38%|███▊      | 3821/10000 [00:16<00:26, 229.85it/s]Running 10000 simulations.:  38%|███▊      | 3845/10000 [00:16<00:26, 230.18it/s]Running 10000 simulations.:  39%|███▊      | 3869/10000 [00:16<00:26, 231.21it/s]Running 10000 simulations.:  39%|███▉      | 3893/10000 [00:16<00:26, 231.43it/s]Running 10000 simulations.:  39%|███▉      | 3917/10000 [00:16<00:26, 232.11it/s]Running 10000 simulations.:  39%|███▉      | 3941/10000 [00:17<00:26, 232.55it/s]Running 10000 simulations.:  40%|███▉      | 3965/10000 [00:17<00:25, 232.87it/s]Running 10000 simulations.:  40%|███▉      | 3989/10000 [00:17<00:25, 231.69it/s]Running 10000 simulations.:  40%|████      | 4013/10000 [00:17<00:25, 230.91it/s]Running 10000 simulations.:  40%|████      | 4037/10000 [00:17<00:25, 230.55it/s]Running 10000 simulations.:  41%|████      | 4061/10000 [00:17<00:25, 230.93it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:17<00:25, 231.39it/s]Running 10000 simulations.:  41%|████      | 4109/10000 [00:17<00:25, 231.08it/s]Running 10000 simulations.:  41%|████▏     | 4133/10000 [00:17<00:25, 230.98it/s]Running 10000 simulations.:  42%|████▏     | 4157/10000 [00:17<00:25, 231.12it/s]Running 10000 simulations.:  42%|████▏     | 4181/10000 [00:18<00:25, 230.97it/s]Running 10000 simulations.:  42%|████▏     | 4205/10000 [00:18<00:25, 231.29it/s]Running 10000 simulations.:  42%|████▏     | 4229/10000 [00:18<00:24, 232.23it/s]Running 10000 simulations.:  43%|████▎     | 4253/10000 [00:18<00:24, 232.07it/s]Running 10000 simulations.:  43%|████▎     | 4277/10000 [00:18<00:24, 232.35it/s]Running 10000 simulations.:  43%|████▎     | 4301/10000 [00:18<00:24, 231.79it/s]Running 10000 simulations.:  43%|████▎     | 4325/10000 [00:18<00:24, 231.86it/s]Running 10000 simulations.:  43%|████▎     | 4349/10000 [00:18<00:24, 231.60it/s]Running 10000 simulations.:  44%|████▎     | 4373/10000 [00:18<00:24, 230.79it/s]Running 10000 simulations.:  44%|████▍     | 4397/10000 [00:18<00:24, 230.92it/s]Running 10000 simulations.:  44%|████▍     | 4421/10000 [00:19<00:24, 231.33it/s]Running 10000 simulations.:  44%|████▍     | 4445/10000 [00:19<00:24, 231.44it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:19<00:23, 231.00it/s]Running 10000 simulations.:  45%|████▍     | 4493/10000 [00:19<00:23, 231.29it/s]Running 10000 simulations.:  45%|████▌     | 4517/10000 [00:19<00:23, 229.80it/s]Running 10000 simulations.:  45%|████▌     | 4540/10000 [00:19<00:23, 229.67it/s]Running 10000 simulations.:  46%|████▌     | 4564/10000 [00:19<00:23, 230.08it/s]Running 10000 simulations.:  46%|████▌     | 4588/10000 [00:19<00:23, 230.19it/s]Running 10000 simulations.:  46%|████▌     | 4612/10000 [00:19<00:23, 229.20it/s]Running 10000 simulations.:  46%|████▋     | 4635/10000 [00:20<00:23, 226.94it/s]Running 10000 simulations.:  47%|████▋     | 4658/10000 [00:20<00:23, 225.54it/s]Running 10000 simulations.:  47%|████▋     | 4681/10000 [00:20<00:23, 224.73it/s]Running 10000 simulations.:  47%|████▋     | 4704/10000 [00:20<00:23, 222.52it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:20<00:23, 220.47it/s]Running 10000 simulations.:  48%|████▊     | 4750/10000 [00:20<00:24, 218.66it/s]Running 10000 simulations.:  48%|████▊     | 4772/10000 [00:20<00:24, 217.37it/s]Running 10000 simulations.:  48%|████▊     | 4794/10000 [00:20<00:23, 217.38it/s]Running 10000 simulations.:  48%|████▊     | 4816/10000 [00:20<00:23, 217.76it/s]Running 10000 simulations.:  48%|████▊     | 4838/10000 [00:20<00:23, 218.05it/s]Running 10000 simulations.:  49%|████▊     | 4861/10000 [00:21<00:23, 218.73it/s]Running 10000 simulations.:  49%|████▉     | 4884/10000 [00:21<00:23, 219.17it/s]Running 10000 simulations.:  49%|████▉     | 4907/10000 [00:21<00:23, 220.89it/s]Running 10000 simulations.:  49%|████▉     | 4930/10000 [00:21<00:22, 221.86it/s]Running 10000 simulations.:  50%|████▉     | 4953/10000 [00:21<00:22, 222.95it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:21<00:22, 224.09it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:21<00:22, 224.65it/s]Running 10000 simulations.:  50%|█████     | 5022/10000 [00:21<00:22, 224.53it/s]Running 10000 simulations.:  50%|█████     | 5045/10000 [00:21<00:22, 224.89it/s]Running 10000 simulations.:  51%|█████     | 5068/10000 [00:21<00:21, 225.49it/s]Running 10000 simulations.:  51%|█████     | 5091/10000 [00:22<00:21, 226.74it/s]Running 10000 simulations.:  51%|█████     | 5114/10000 [00:22<00:21, 227.43it/s]Running 10000 simulations.:  51%|█████▏    | 5137/10000 [00:22<00:21, 227.77it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:22<00:21, 228.00it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:22<00:21, 228.94it/s]Running 10000 simulations.:  52%|█████▏    | 5207/10000 [00:22<00:20, 228.71it/s]Running 10000 simulations.:  52%|█████▏    | 5230/10000 [00:22<00:20, 228.55it/s]Running 10000 simulations.:  53%|█████▎    | 5253/10000 [00:22<00:20, 228.72it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:22<00:20, 225.30it/s]Running 10000 simulations.:  53%|█████▎    | 5299/10000 [00:23<00:21, 222.41it/s]Running 10000 simulations.:  53%|█████▎    | 5322/10000 [00:23<00:21, 221.00it/s]Running 10000 simulations.:  53%|█████▎    | 5345/10000 [00:23<00:21, 219.02it/s]Running 10000 simulations.:  54%|█████▎    | 5367/10000 [00:23<00:22, 203.99it/s]Running 10000 simulations.:  54%|█████▍    | 5389/10000 [00:23<00:22, 206.98it/s]Running 10000 simulations.:  54%|█████▍    | 5411/10000 [00:23<00:21, 209.94it/s]Running 10000 simulations.:  54%|█████▍    | 5433/10000 [00:23<00:21, 212.55it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:23<00:21, 212.90it/s]Running 10000 simulations.:  55%|█████▍    | 5477/10000 [00:23<00:21, 211.95it/s]Running 10000 simulations.:  55%|█████▍    | 5499/10000 [00:23<00:21, 211.50it/s]Running 10000 simulations.:  55%|█████▌    | 5522/10000 [00:24<00:20, 215.08it/s]Running 10000 simulations.:  55%|█████▌    | 5545/10000 [00:24<00:20, 219.26it/s]Running 10000 simulations.:  56%|█████▌    | 5568/10000 [00:24<00:19, 222.16it/s]Running 10000 simulations.:  56%|█████▌    | 5592/10000 [00:24<00:19, 224.61it/s]Running 10000 simulations.:  56%|█████▌    | 5615/10000 [00:24<00:19, 225.56it/s]Running 10000 simulations.:  56%|█████▋    | 5638/10000 [00:24<00:19, 225.69it/s]Running 10000 simulations.:  57%|█████▋    | 5661/10000 [00:24<00:19, 225.91it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:24<00:19, 225.84it/s]Running 10000 simulations.:  57%|█████▋    | 5707/10000 [00:24<00:18, 226.05it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:24<00:18, 226.54it/s]Running 10000 simulations.:  58%|█████▊    | 5753/10000 [00:25<00:18, 226.68it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:25<00:18, 227.58it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:25<00:18, 227.06it/s]Running 10000 simulations.:  58%|█████▊    | 5822/10000 [00:25<00:18, 226.74it/s]Running 10000 simulations.:  58%|█████▊    | 5845/10000 [00:25<00:18, 227.46it/s]Running 10000 simulations.:  59%|█████▊    | 5868/10000 [00:25<00:18, 227.85it/s]Running 10000 simulations.:  59%|█████▉    | 5891/10000 [00:25<00:18, 228.03it/s]Running 10000 simulations.:  59%|█████▉    | 5915/10000 [00:25<00:17, 228.67it/s]Running 10000 simulations.:  59%|█████▉    | 5938/10000 [00:25<00:17, 227.83it/s]Running 10000 simulations.:  60%|█████▉    | 5961/10000 [00:25<00:17, 227.03it/s]Running 10000 simulations.:  60%|█████▉    | 5984/10000 [00:26<00:17, 226.72it/s]Running 10000 simulations.:  60%|██████    | 6007/10000 [00:26<00:17, 227.39it/s]Running 10000 simulations.:  60%|██████    | 6030/10000 [00:26<00:17, 228.00it/s]Running 10000 simulations.:  61%|██████    | 6053/10000 [00:26<00:17, 228.46it/s]Running 10000 simulations.:  61%|██████    | 6077/10000 [00:26<00:17, 229.14it/s]Running 10000 simulations.:  61%|██████    | 6100/10000 [00:26<00:17, 228.74it/s]Running 10000 simulations.:  61%|██████    | 6123/10000 [00:26<00:16, 228.14it/s]Running 10000 simulations.:  61%|██████▏   | 6146/10000 [00:26<00:16, 228.04it/s]Running 10000 simulations.:  62%|██████▏   | 6169/10000 [00:26<00:16, 227.79it/s]Running 10000 simulations.:  62%|██████▏   | 6192/10000 [00:27<00:16, 227.62it/s]Running 10000 simulations.:  62%|██████▏   | 6215/10000 [00:27<00:16, 227.06it/s]Running 10000 simulations.:  62%|██████▏   | 6238/10000 [00:27<00:16, 227.45it/s]Running 10000 simulations.:  63%|██████▎   | 6261/10000 [00:27<00:16, 227.41it/s]Running 10000 simulations.:  63%|██████▎   | 6284/10000 [00:27<00:16, 227.52it/s]Running 10000 simulations.:  63%|██████▎   | 6307/10000 [00:27<00:16, 227.44it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:27<00:16, 227.23it/s]Running 10000 simulations.:  64%|██████▎   | 6353/10000 [00:27<00:16, 227.23it/s]Running 10000 simulations.:  64%|██████▍   | 6376/10000 [00:27<00:15, 227.19it/s]Running 10000 simulations.:  64%|██████▍   | 6399/10000 [00:27<00:15, 226.77it/s]Running 10000 simulations.:  64%|██████▍   | 6422/10000 [00:28<00:15, 226.59it/s]Running 10000 simulations.:  64%|██████▍   | 6445/10000 [00:28<00:15, 226.76it/s]Running 10000 simulations.:  65%|██████▍   | 6468/10000 [00:28<00:15, 227.04it/s]Running 10000 simulations.:  65%|██████▍   | 6491/10000 [00:28<00:15, 227.44it/s]Running 10000 simulations.:  65%|██████▌   | 6514/10000 [00:28<00:15, 227.28it/s]Running 10000 simulations.:  65%|██████▌   | 6537/10000 [00:28<00:15, 227.26it/s]Running 10000 simulations.:  66%|██████▌   | 6560/10000 [00:28<00:15, 227.43it/s]Running 10000 simulations.:  66%|██████▌   | 6583/10000 [00:28<00:15, 227.34it/s]Running 10000 simulations.:  66%|██████▌   | 6606/10000 [00:28<00:14, 227.19it/s]Running 10000 simulations.:  66%|██████▋   | 6629/10000 [00:28<00:14, 227.56it/s]Running 10000 simulations.:  67%|██████▋   | 6652/10000 [00:29<00:14, 227.83it/s]Running 10000 simulations.:  67%|██████▋   | 6675/10000 [00:29<00:14, 227.99it/s]Running 10000 simulations.:  67%|██████▋   | 6698/10000 [00:29<00:14, 227.82it/s]Running 10000 simulations.:  67%|██████▋   | 6721/10000 [00:29<00:14, 227.15it/s]Running 10000 simulations.:  67%|██████▋   | 6744/10000 [00:29<00:14, 226.86it/s]Running 10000 simulations.:  68%|██████▊   | 6767/10000 [00:29<00:14, 226.91it/s]Running 10000 simulations.:  68%|██████▊   | 6790/10000 [00:29<00:14, 226.50it/s]Running 10000 simulations.:  68%|██████▊   | 6813/10000 [00:29<00:14, 226.32it/s]Running 10000 simulations.:  68%|██████▊   | 6836/10000 [00:29<00:13, 226.48it/s]Running 10000 simulations.:  69%|██████▊   | 6859/10000 [00:29<00:13, 226.86it/s]Running 10000 simulations.:  69%|██████▉   | 6882/10000 [00:30<00:13, 226.52it/s]Running 10000 simulations.:  69%|██████▉   | 6905/10000 [00:30<00:13, 226.03it/s]Running 10000 simulations.:  69%|██████▉   | 6928/10000 [00:30<00:13, 224.75it/s]Running 10000 simulations.:  70%|██████▉   | 6951/10000 [00:30<00:13, 224.67it/s]Running 10000 simulations.:  70%|██████▉   | 6974/10000 [00:30<00:13, 224.74it/s]Running 10000 simulations.:  70%|██████▉   | 6997/10000 [00:30<00:13, 225.05it/s]Running 10000 simulations.:  70%|███████   | 7020/10000 [00:30<00:13, 225.26it/s]Running 10000 simulations.:  70%|███████   | 7043/10000 [00:30<00:13, 224.97it/s]Running 10000 simulations.:  71%|███████   | 7066/10000 [00:30<00:13, 224.99it/s]Running 10000 simulations.:  71%|███████   | 7089/10000 [00:30<00:12, 224.91it/s]Running 10000 simulations.:  71%|███████   | 7112/10000 [00:31<00:12, 222.72it/s]Running 10000 simulations.:  71%|███████▏  | 7135/10000 [00:31<00:12, 221.76it/s]Running 10000 simulations.:  72%|███████▏  | 7158/10000 [00:31<00:12, 222.09it/s]Running 10000 simulations.:  72%|███████▏  | 7181/10000 [00:31<00:12, 222.61it/s]Running 10000 simulations.:  72%|███████▏  | 7204/10000 [00:31<00:12, 223.16it/s]Running 10000 simulations.:  72%|███████▏  | 7227/10000 [00:31<00:12, 223.79it/s]Running 10000 simulations.:  72%|███████▎  | 7250/10000 [00:31<00:12, 224.42it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:31<00:12, 225.47it/s]Running 10000 simulations.:  73%|███████▎  | 7296/10000 [00:31<00:11, 225.97it/s]Running 10000 simulations.:  73%|███████▎  | 7319/10000 [00:31<00:11, 226.21it/s]Running 10000 simulations.:  73%|███████▎  | 7342/10000 [00:32<00:11, 226.00it/s]Running 10000 simulations.:  74%|███████▎  | 7365/10000 [00:32<00:11, 225.32it/s]Running 10000 simulations.:  74%|███████▍  | 7388/10000 [00:32<00:11, 224.91it/s]Running 10000 simulations.:  74%|███████▍  | 7411/10000 [00:32<00:11, 224.07it/s]Running 10000 simulations.:  74%|███████▍  | 7434/10000 [00:32<00:11, 224.18it/s]Running 10000 simulations.:  75%|███████▍  | 7457/10000 [00:32<00:11, 223.73it/s]Running 10000 simulations.:  75%|███████▍  | 7480/10000 [00:32<00:11, 223.66it/s]Running 10000 simulations.:  75%|███████▌  | 7503/10000 [00:32<00:11, 223.94it/s]Running 10000 simulations.:  75%|███████▌  | 7526/10000 [00:32<00:11, 224.68it/s]Running 10000 simulations.:  75%|███████▌  | 7549/10000 [00:33<00:10, 225.50it/s]Running 10000 simulations.:  76%|███████▌  | 7572/10000 [00:33<00:10, 226.08it/s]Running 10000 simulations.:  76%|███████▌  | 7595/10000 [00:33<00:10, 226.56it/s]Running 10000 simulations.:  76%|███████▌  | 7618/10000 [00:33<00:10, 222.10it/s]Running 10000 simulations.:  76%|███████▋  | 7641/10000 [00:33<00:10, 218.50it/s]Running 10000 simulations.:  77%|███████▋  | 7663/10000 [00:33<00:10, 215.35it/s]Running 10000 simulations.:  77%|███████▋  | 7685/10000 [00:33<00:10, 212.86it/s]Running 10000 simulations.:  77%|███████▋  | 7707/10000 [00:33<00:10, 211.35it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:33<00:10, 210.96it/s]Running 10000 simulations.:  78%|███████▊  | 7751/10000 [00:33<00:10, 211.18it/s]Running 10000 simulations.:  78%|███████▊  | 7773/10000 [00:34<00:10, 211.84it/s]Running 10000 simulations.:  78%|███████▊  | 7795/10000 [00:34<00:10, 214.07it/s]Running 10000 simulations.:  78%|███████▊  | 7817/10000 [00:34<00:10, 215.37it/s]Running 10000 simulations.:  78%|███████▊  | 7839/10000 [00:34<00:09, 216.66it/s]Running 10000 simulations.:  79%|███████▊  | 7862/10000 [00:34<00:09, 218.42it/s]Running 10000 simulations.:  79%|███████▉  | 7884/10000 [00:34<00:09, 216.23it/s]Running 10000 simulations.:  79%|███████▉  | 7906/10000 [00:34<00:09, 216.34it/s]Running 10000 simulations.:  79%|███████▉  | 7928/10000 [00:34<00:09, 215.67it/s]Running 10000 simulations.:  80%|███████▉  | 7950/10000 [00:34<00:09, 215.29it/s]Running 10000 simulations.:  80%|███████▉  | 7972/10000 [00:34<00:09, 214.75it/s]Running 10000 simulations.:  80%|███████▉  | 7994/10000 [00:35<00:09, 214.53it/s]Running 10000 simulations.:  80%|████████  | 8016/10000 [00:35<00:09, 214.58it/s]Running 10000 simulations.:  80%|████████  | 8038/10000 [00:35<00:09, 214.83it/s]Running 10000 simulations.:  81%|████████  | 8060/10000 [00:35<00:09, 215.40it/s]Running 10000 simulations.:  81%|████████  | 8082/10000 [00:35<00:08, 216.10it/s]Running 10000 simulations.:  81%|████████  | 8105/10000 [00:35<00:08, 218.97it/s]Running 10000 simulations.:  81%|████████▏ | 8128/10000 [00:35<00:08, 221.23it/s]Running 10000 simulations.:  82%|████████▏ | 8151/10000 [00:35<00:08, 222.71it/s]Running 10000 simulations.:  82%|████████▏ | 8174/10000 [00:35<00:08, 224.25it/s]Running 10000 simulations.:  82%|████████▏ | 8197/10000 [00:35<00:08, 225.23it/s]Running 10000 simulations.:  82%|████████▏ | 8220/10000 [00:36<00:07, 225.93it/s]Running 10000 simulations.:  82%|████████▏ | 8243/10000 [00:36<00:07, 226.90it/s]Running 10000 simulations.:  83%|████████▎ | 8266/10000 [00:36<00:07, 227.13it/s]Running 10000 simulations.:  83%|████████▎ | 8289/10000 [00:36<00:07, 227.38it/s]Running 10000 simulations.:  83%|████████▎ | 8312/10000 [00:36<00:07, 227.16it/s]Running 10000 simulations.:  83%|████████▎ | 8335/10000 [00:36<00:07, 227.69it/s]Running 10000 simulations.:  84%|████████▎ | 8358/10000 [00:36<00:07, 228.15it/s]Running 10000 simulations.:  84%|████████▍ | 8381/10000 [00:36<00:07, 228.32it/s]Running 10000 simulations.:  84%|████████▍ | 8404/10000 [00:36<00:07, 227.93it/s]Running 10000 simulations.:  84%|████████▍ | 8427/10000 [00:37<00:06, 228.40it/s]Running 10000 simulations.:  84%|████████▍ | 8450/10000 [00:37<00:06, 228.37it/s]Running 10000 simulations.:  85%|████████▍ | 8473/10000 [00:37<00:06, 227.94it/s]Running 10000 simulations.:  85%|████████▍ | 8496/10000 [00:37<00:06, 227.91it/s]Running 10000 simulations.:  85%|████████▌ | 8519/10000 [00:37<00:06, 227.65it/s]Running 10000 simulations.:  85%|████████▌ | 8542/10000 [00:37<00:06, 227.45it/s]Running 10000 simulations.:  86%|████████▌ | 8565/10000 [00:37<00:06, 227.65it/s]Running 10000 simulations.:  86%|████████▌ | 8588/10000 [00:37<00:06, 227.75it/s]Running 10000 simulations.:  86%|████████▌ | 8611/10000 [00:37<00:06, 227.69it/s]Running 10000 simulations.:  86%|████████▋ | 8634/10000 [00:37<00:06, 227.13it/s]Running 10000 simulations.:  87%|████████▋ | 8657/10000 [00:38<00:05, 226.93it/s]Running 10000 simulations.:  87%|████████▋ | 8680/10000 [00:38<00:05, 226.85it/s]Running 10000 simulations.:  87%|████████▋ | 8703/10000 [00:38<00:05, 226.88it/s]Running 10000 simulations.:  87%|████████▋ | 8726/10000 [00:38<00:05, 227.27it/s]Running 10000 simulations.:  87%|████████▋ | 8749/10000 [00:38<00:05, 227.24it/s]Running 10000 simulations.:  88%|████████▊ | 8772/10000 [00:38<00:05, 227.95it/s]Running 10000 simulations.:  88%|████████▊ | 8795/10000 [00:38<00:05, 228.42it/s]Running 10000 simulations.:  88%|████████▊ | 8819/10000 [00:38<00:05, 229.17it/s]Running 10000 simulations.:  88%|████████▊ | 8842/10000 [00:38<00:05, 229.13it/s]Running 10000 simulations.:  89%|████████▊ | 8865/10000 [00:38<00:04, 228.57it/s]Running 10000 simulations.:  89%|████████▉ | 8888/10000 [00:39<00:04, 228.19it/s]Running 10000 simulations.:  89%|████████▉ | 8911/10000 [00:39<00:04, 228.27it/s]Running 10000 simulations.:  89%|████████▉ | 8934/10000 [00:39<00:04, 228.12it/s]Running 10000 simulations.:  90%|████████▉ | 8957/10000 [00:39<00:04, 228.50it/s]Running 10000 simulations.:  90%|████████▉ | 8980/10000 [00:39<00:04, 228.81it/s]Running 10000 simulations.:  90%|█████████ | 9004/10000 [00:39<00:04, 229.29it/s]Running 10000 simulations.:  90%|█████████ | 9027/10000 [00:39<00:04, 228.74it/s]Running 10000 simulations.:  90%|█████████ | 9050/10000 [00:39<00:04, 228.60it/s]Running 10000 simulations.:  91%|█████████ | 9073/10000 [00:39<00:04, 228.06it/s]Running 10000 simulations.:  91%|█████████ | 9096/10000 [00:39<00:03, 227.79it/s]Running 10000 simulations.:  91%|█████████ | 9119/10000 [00:40<00:03, 228.38it/s]Running 10000 simulations.:  91%|█████████▏| 9143/10000 [00:40<00:03, 229.51it/s]Running 10000 simulations.:  92%|█████████▏| 9167/10000 [00:40<00:03, 230.37it/s]Running 10000 simulations.:  92%|█████████▏| 9191/10000 [00:40<00:03, 231.35it/s]Running 10000 simulations.:  92%|█████████▏| 9215/10000 [00:40<00:03, 230.99it/s]Running 10000 simulations.:  92%|█████████▏| 9239/10000 [00:40<00:03, 230.52it/s]Running 10000 simulations.:  93%|█████████▎| 9263/10000 [00:40<00:03, 230.29it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [00:40<00:03, 229.73it/s]Running 10000 simulations.:  93%|█████████▎| 9310/10000 [00:40<00:03, 229.52it/s]Running 10000 simulations.:  93%|█████████▎| 9334/10000 [00:40<00:02, 230.10it/s]Running 10000 simulations.:  94%|█████████▎| 9358/10000 [00:41<00:02, 230.16it/s]Running 10000 simulations.:  94%|█████████▍| 9382/10000 [00:41<00:02, 230.65it/s]Running 10000 simulations.:  94%|█████████▍| 9406/10000 [00:41<00:02, 230.80it/s]Running 10000 simulations.:  94%|█████████▍| 9430/10000 [00:41<00:02, 230.20it/s]Running 10000 simulations.:  95%|█████████▍| 9454/10000 [00:41<00:02, 229.39it/s]Running 10000 simulations.:  95%|█████████▍| 9477/10000 [00:41<00:02, 228.85it/s]Running 10000 simulations.:  95%|█████████▌| 9501/10000 [00:41<00:02, 229.44it/s]Running 10000 simulations.:  95%|█████████▌| 9525/10000 [00:41<00:02, 230.04it/s]Running 10000 simulations.:  95%|█████████▌| 9549/10000 [00:41<00:01, 229.76it/s]Running 10000 simulations.:  96%|█████████▌| 9572/10000 [00:42<00:01, 229.35it/s]Running 10000 simulations.:  96%|█████████▌| 9595/10000 [00:42<00:01, 228.97it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [00:42<00:01, 228.14it/s]Running 10000 simulations.:  96%|█████████▋| 9641/10000 [00:42<00:01, 227.30it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [00:42<00:01, 226.93it/s]Running 10000 simulations.:  97%|█████████▋| 9687/10000 [00:42<00:01, 227.26it/s]Running 10000 simulations.:  97%|█████████▋| 9711/10000 [00:42<00:01, 228.06it/s]Running 10000 simulations.:  97%|█████████▋| 9734/10000 [00:42<00:01, 228.44it/s]Running 10000 simulations.:  98%|█████████▊| 9757/10000 [00:42<00:01, 228.90it/s]Running 10000 simulations.:  98%|█████████▊| 9781/10000 [00:42<00:00, 229.34it/s]Running 10000 simulations.:  98%|█████████▊| 9804/10000 [00:43<00:00, 229.45it/s]Running 10000 simulations.:  98%|█████████▊| 9828/10000 [00:43<00:00, 229.97it/s]Running 10000 simulations.:  99%|█████████▊| 9851/10000 [00:43<00:00, 229.90it/s]Running 10000 simulations.:  99%|█████████▊| 9874/10000 [00:43<00:00, 229.44it/s]Running 10000 simulations.:  99%|█████████▉| 9898/10000 [00:43<00:00, 229.93it/s]Running 10000 simulations.:  99%|█████████▉| 9922/10000 [00:43<00:00, 230.01it/s]Running 10000 simulations.:  99%|█████████▉| 9946/10000 [00:43<00:00, 230.68it/s]Running 10000 simulations.: 100%|█████████▉| 9970/10000 [00:43<00:00, 231.40it/s]Running 10000 simulations.: 100%|█████████▉| 9994/10000 [00:43<00:00, 231.96it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:43<00:00, 227.93it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:40, 244.69it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:40, 244.49it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:40, 244.20it/s]Running 10000 simulations.:   1%|          | 100/10000 [00:00<00:40, 243.32it/s]Running 10000 simulations.:   1%|          | 124/10000 [00:00<00:41, 240.70it/s]Running 10000 simulations.:   1%|▏         | 148/10000 [00:00<00:40, 240.38it/s]Running 10000 simulations.:   2%|▏         | 173/10000 [00:00<00:40, 240.95it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:00<00:40, 240.65it/s]Running 10000 simulations.:   2%|▏         | 222/10000 [00:00<00:40, 241.50it/s]Running 10000 simulations.:   2%|▏         | 246/10000 [00:01<00:40, 240.88it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:01<00:40, 239.71it/s]Running 10000 simulations.:   3%|▎         | 294/10000 [00:01<00:40, 239.63it/s]Running 10000 simulations.:   3%|▎         | 319/10000 [00:01<00:40, 240.05it/s]Running 10000 simulations.:   3%|▎         | 343/10000 [00:01<00:40, 239.85it/s]Running 10000 simulations.:   4%|▎         | 367/10000 [00:01<00:40, 239.22it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:01<00:40, 238.69it/s]Running 10000 simulations.:   4%|▍         | 415/10000 [00:01<00:40, 239.06it/s]Running 10000 simulations.:   4%|▍         | 439/10000 [00:01<00:40, 238.66it/s]Running 10000 simulations.:   5%|▍         | 463/10000 [00:01<00:40, 238.11it/s]Running 10000 simulations.:   5%|▍         | 487/10000 [00:02<00:40, 237.18it/s]Running 10000 simulations.:   5%|▌         | 511/10000 [00:02<00:39, 237.43it/s]Running 10000 simulations.:   5%|▌         | 535/10000 [00:02<00:39, 237.26it/s]Running 10000 simulations.:   6%|▌         | 559/10000 [00:02<00:39, 237.57it/s]Running 10000 simulations.:   6%|▌         | 583/10000 [00:02<00:39, 237.57it/s]Running 10000 simulations.:   6%|▌         | 607/10000 [00:02<00:39, 237.12it/s]Running 10000 simulations.:   6%|▋         | 631/10000 [00:02<00:39, 236.21it/s]Running 10000 simulations.:   7%|▋         | 655/10000 [00:02<00:39, 235.47it/s]Running 10000 simulations.:   7%|▋         | 679/10000 [00:02<00:39, 235.36it/s]Running 10000 simulations.:   7%|▋         | 703/10000 [00:02<00:39, 235.73it/s]Running 10000 simulations.:   7%|▋         | 727/10000 [00:03<00:39, 236.13it/s]Running 10000 simulations.:   8%|▊         | 751/10000 [00:03<00:39, 235.87it/s]Running 10000 simulations.:   8%|▊         | 775/10000 [00:03<00:39, 235.76it/s]Running 10000 simulations.:   8%|▊         | 799/10000 [00:03<00:38, 235.99it/s]Running 10000 simulations.:   8%|▊         | 823/10000 [00:03<00:38, 236.04it/s]Running 10000 simulations.:   8%|▊         | 847/10000 [00:03<00:38, 235.80it/s]Running 10000 simulations.:   9%|▊         | 871/10000 [00:03<00:38, 235.42it/s]Running 10000 simulations.:   9%|▉         | 895/10000 [00:03<00:38, 234.90it/s]Running 10000 simulations.:   9%|▉         | 919/10000 [00:03<00:38, 235.03it/s]Running 10000 simulations.:   9%|▉         | 943/10000 [00:03<00:38, 235.29it/s]Running 10000 simulations.:  10%|▉         | 967/10000 [00:04<00:38, 235.83it/s]Running 10000 simulations.:  10%|▉         | 991/10000 [00:04<00:38, 236.55it/s]Running 10000 simulations.:  10%|█         | 1015/10000 [00:04<00:37, 236.66it/s]Running 10000 simulations.:  10%|█         | 1039/10000 [00:04<00:37, 237.22it/s]Running 10000 simulations.:  11%|█         | 1063/10000 [00:04<00:37, 237.59it/s]Running 10000 simulations.:  11%|█         | 1087/10000 [00:04<00:37, 237.14it/s]Running 10000 simulations.:  11%|█         | 1111/10000 [00:04<00:37, 236.49it/s]Running 10000 simulations.:  11%|█▏        | 1135/10000 [00:04<00:37, 236.32it/s]Running 10000 simulations.:  12%|█▏        | 1159/10000 [00:04<00:37, 236.47it/s]Running 10000 simulations.:  12%|█▏        | 1183/10000 [00:04<00:37, 236.96it/s]Running 10000 simulations.:  12%|█▏        | 1207/10000 [00:05<00:37, 237.58it/s]Running 10000 simulations.:  12%|█▏        | 1231/10000 [00:05<00:37, 236.51it/s]Running 10000 simulations.:  13%|█▎        | 1255/10000 [00:05<00:37, 236.30it/s]Running 10000 simulations.:  13%|█▎        | 1279/10000 [00:05<00:36, 236.38it/s]Running 10000 simulations.:  13%|█▎        | 1303/10000 [00:05<00:36, 236.55it/s]Running 10000 simulations.:  13%|█▎        | 1327/10000 [00:05<00:36, 235.81it/s]Running 10000 simulations.:  14%|█▎        | 1351/10000 [00:05<00:36, 235.15it/s]Running 10000 simulations.:  14%|█▍        | 1375/10000 [00:05<00:36, 234.82it/s]Running 10000 simulations.:  14%|█▍        | 1399/10000 [00:05<00:36, 235.03it/s]Running 10000 simulations.:  14%|█▍        | 1423/10000 [00:05<00:36, 234.65it/s]Running 10000 simulations.:  14%|█▍        | 1447/10000 [00:06<00:36, 234.52it/s]Running 10000 simulations.:  15%|█▍        | 1471/10000 [00:06<00:36, 234.98it/s]Running 10000 simulations.:  15%|█▍        | 1495/10000 [00:06<00:36, 235.46it/s]Running 10000 simulations.:  15%|█▌        | 1519/10000 [00:06<00:35, 236.29it/s]Running 10000 simulations.:  15%|█▌        | 1543/10000 [00:06<00:35, 236.46it/s]Running 10000 simulations.:  16%|█▌        | 1567/10000 [00:06<00:35, 236.71it/s]Running 10000 simulations.:  16%|█▌        | 1591/10000 [00:06<00:35, 236.29it/s]Running 10000 simulations.:  16%|█▌        | 1615/10000 [00:06<00:35, 235.97it/s]Running 10000 simulations.:  16%|█▋        | 1639/10000 [00:06<00:35, 235.28it/s]Running 10000 simulations.:  17%|█▋        | 1663/10000 [00:07<00:35, 234.82it/s]Running 10000 simulations.:  17%|█▋        | 1687/10000 [00:07<00:35, 233.77it/s]Running 10000 simulations.:  17%|█▋        | 1711/10000 [00:07<00:35, 233.41it/s]Running 10000 simulations.:  17%|█▋        | 1735/10000 [00:07<00:35, 234.08it/s]Running 10000 simulations.:  18%|█▊        | 1759/10000 [00:07<00:35, 233.15it/s]Running 10000 simulations.:  18%|█▊        | 1783/10000 [00:07<00:35, 233.06it/s]Running 10000 simulations.:  18%|█▊        | 1807/10000 [00:07<00:35, 233.12it/s]Running 10000 simulations.:  18%|█▊        | 1831/10000 [00:07<00:35, 232.48it/s]Running 10000 simulations.:  19%|█▊        | 1855/10000 [00:07<00:35, 232.66it/s]Running 10000 simulations.:  19%|█▉        | 1879/10000 [00:07<00:34, 232.99it/s]Running 10000 simulations.:  19%|█▉        | 1903/10000 [00:08<00:34, 232.92it/s]Running 10000 simulations.:  19%|█▉        | 1927/10000 [00:08<00:34, 233.34it/s]Running 10000 simulations.:  20%|█▉        | 1951/10000 [00:08<00:34, 233.93it/s]Running 10000 simulations.:  20%|█▉        | 1975/10000 [00:08<00:34, 233.67it/s]Running 10000 simulations.:  20%|█▉        | 1999/10000 [00:08<00:34, 233.65it/s]Running 10000 simulations.:  20%|██        | 2023/10000 [00:08<00:34, 232.56it/s]Running 10000 simulations.:  20%|██        | 2047/10000 [00:08<00:34, 231.23it/s]Running 10000 simulations.:  21%|██        | 2071/10000 [00:08<00:34, 232.14it/s]Running 10000 simulations.:  21%|██        | 2095/10000 [00:08<00:33, 233.47it/s]Running 10000 simulations.:  21%|██        | 2119/10000 [00:08<00:33, 233.82it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:09<00:33, 234.26it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:09<00:33, 234.52it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:09<00:33, 234.58it/s]Running 10000 simulations.:  22%|██▏       | 2215/10000 [00:09<00:33, 234.04it/s]Running 10000 simulations.:  22%|██▏       | 2239/10000 [00:09<00:33, 233.95it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:09<00:33, 233.82it/s]Running 10000 simulations.:  23%|██▎       | 2287/10000 [00:09<00:32, 234.57it/s]Running 10000 simulations.:  23%|██▎       | 2311/10000 [00:09<00:32, 235.11it/s]Running 10000 simulations.:  23%|██▎       | 2335/10000 [00:09<00:32, 235.29it/s]Running 10000 simulations.:  24%|██▎       | 2359/10000 [00:09<00:32, 234.88it/s]Running 10000 simulations.:  24%|██▍       | 2383/10000 [00:10<00:32, 234.17it/s]Running 10000 simulations.:  24%|██▍       | 2407/10000 [00:10<00:32, 233.72it/s]Running 10000 simulations.:  24%|██▍       | 2431/10000 [00:10<00:32, 232.85it/s]Running 10000 simulations.:  25%|██▍       | 2455/10000 [00:10<00:48, 154.64it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:10<00:43, 172.10it/s]Running 10000 simulations.:  25%|██▌       | 2503/10000 [00:10<00:40, 187.28it/s]Running 10000 simulations.:  25%|██▌       | 2527/10000 [00:10<00:37, 199.18it/s]Running 10000 simulations.:  26%|██▌       | 2551/10000 [00:10<00:35, 208.02it/s]Running 10000 simulations.:  26%|██▌       | 2575/10000 [00:11<00:34, 214.38it/s]Running 10000 simulations.:  26%|██▌       | 2599/10000 [00:11<00:33, 219.91it/s]Running 10000 simulations.:  26%|██▌       | 2623/10000 [00:11<00:33, 223.26it/s]Running 10000 simulations.:  26%|██▋       | 2647/10000 [00:11<00:32, 225.62it/s]Running 10000 simulations.:  27%|██▋       | 2671/10000 [00:11<00:32, 227.39it/s]Running 10000 simulations.:  27%|██▋       | 2695/10000 [00:11<00:31, 229.69it/s]Running 10000 simulations.:  27%|██▋       | 2719/10000 [00:11<00:31, 231.15it/s]Running 10000 simulations.:  27%|██▋       | 2743/10000 [00:11<00:31, 231.84it/s]Running 10000 simulations.:  28%|██▊       | 2767/10000 [00:11<00:31, 232.56it/s]Running 10000 simulations.:  28%|██▊       | 2791/10000 [00:12<00:30, 232.56it/s]Running 10000 simulations.:  28%|██▊       | 2815/10000 [00:12<00:30, 232.04it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:12<00:30, 232.29it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:12<00:30, 231.88it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:12<00:30, 231.19it/s]Running 10000 simulations.:  29%|██▉       | 2911/10000 [00:12<00:30, 230.18it/s]Running 10000 simulations.:  29%|██▉       | 2935/10000 [00:12<00:30, 229.86it/s]Running 10000 simulations.:  30%|██▉       | 2959/10000 [00:12<00:30, 229.99it/s]Running 10000 simulations.:  30%|██▉       | 2983/10000 [00:12<00:30, 230.33it/s]Running 10000 simulations.:  30%|███       | 3007/10000 [00:12<00:30, 230.31it/s]Running 10000 simulations.:  30%|███       | 3031/10000 [00:13<00:30, 230.00it/s]Running 10000 simulations.:  31%|███       | 3055/10000 [00:13<00:30, 229.93it/s]Running 10000 simulations.:  31%|███       | 3078/10000 [00:13<00:30, 229.70it/s]Running 10000 simulations.:  31%|███       | 3102/10000 [00:13<00:29, 230.08it/s]Running 10000 simulations.:  31%|███▏      | 3126/10000 [00:13<00:29, 230.80it/s]Running 10000 simulations.:  32%|███▏      | 3150/10000 [00:13<00:29, 230.51it/s]Running 10000 simulations.:  32%|███▏      | 3174/10000 [00:13<00:29, 228.20it/s]Running 10000 simulations.:  32%|███▏      | 3197/10000 [00:13<00:29, 228.09it/s]Running 10000 simulations.:  32%|███▏      | 3221/10000 [00:13<00:29, 228.67it/s]Running 10000 simulations.:  32%|███▏      | 3245/10000 [00:13<00:29, 229.61it/s]Running 10000 simulations.:  33%|███▎      | 3269/10000 [00:14<00:29, 230.51it/s]Running 10000 simulations.:  33%|███▎      | 3293/10000 [00:14<00:29, 230.11it/s]Running 10000 simulations.:  33%|███▎      | 3317/10000 [00:14<00:28, 230.68it/s]Running 10000 simulations.:  33%|███▎      | 3341/10000 [00:14<00:28, 230.48it/s]Running 10000 simulations.:  34%|███▎      | 3365/10000 [00:14<00:28, 230.89it/s]Running 10000 simulations.:  34%|███▍      | 3389/10000 [00:14<00:28, 231.53it/s]Running 10000 simulations.:  34%|███▍      | 3413/10000 [00:14<00:28, 231.33it/s]Running 10000 simulations.:  34%|███▍      | 3437/10000 [00:14<00:28, 231.29it/s]Running 10000 simulations.:  35%|███▍      | 3461/10000 [00:14<00:28, 231.21it/s]Running 10000 simulations.:  35%|███▍      | 3485/10000 [00:15<00:28, 231.22it/s]Running 10000 simulations.:  35%|███▌      | 3509/10000 [00:15<00:28, 231.45it/s]Running 10000 simulations.:  35%|███▌      | 3533/10000 [00:15<00:27, 231.41it/s]Running 10000 simulations.:  36%|███▌      | 3557/10000 [00:15<00:27, 230.89it/s]Running 10000 simulations.:  36%|███▌      | 3581/10000 [00:15<00:27, 230.52it/s]Running 10000 simulations.:  36%|███▌      | 3605/10000 [00:15<00:27, 230.59it/s]Running 10000 simulations.:  36%|███▋      | 3629/10000 [00:15<00:27, 230.52it/s]Running 10000 simulations.:  37%|███▋      | 3653/10000 [00:15<00:27, 230.49it/s]Running 10000 simulations.:  37%|███▋      | 3677/10000 [00:15<00:27, 230.55it/s]Running 10000 simulations.:  37%|███▋      | 3701/10000 [00:15<00:27, 231.05it/s]Running 10000 simulations.:  37%|███▋      | 3725/10000 [00:16<00:27, 231.13it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:16<00:26, 231.53it/s]Running 10000 simulations.:  38%|███▊      | 3773/10000 [00:16<00:26, 231.77it/s]Running 10000 simulations.:  38%|███▊      | 3797/10000 [00:16<00:26, 232.60it/s]Running 10000 simulations.:  38%|███▊      | 3821/10000 [00:16<00:26, 231.80it/s]Running 10000 simulations.:  38%|███▊      | 3845/10000 [00:16<00:26, 231.73it/s]Running 10000 simulations.:  39%|███▊      | 3869/10000 [00:16<00:26, 230.76it/s]Running 10000 simulations.:  39%|███▉      | 3893/10000 [00:16<00:26, 230.05it/s]Running 10000 simulations.:  39%|███▉      | 3917/10000 [00:16<00:26, 229.96it/s]Running 10000 simulations.:  39%|███▉      | 3940/10000 [00:17<00:26, 229.78it/s]Running 10000 simulations.:  40%|███▉      | 3964/10000 [00:17<00:26, 230.11it/s]Running 10000 simulations.:  40%|███▉      | 3988/10000 [00:17<00:26, 230.00it/s]Running 10000 simulations.:  40%|████      | 4012/10000 [00:17<00:26, 229.75it/s]Running 10000 simulations.:  40%|████      | 4036/10000 [00:17<00:25, 230.15it/s]Running 10000 simulations.:  41%|████      | 4060/10000 [00:17<00:25, 230.65it/s]Running 10000 simulations.:  41%|████      | 4084/10000 [00:17<00:25, 230.95it/s]Running 10000 simulations.:  41%|████      | 4108/10000 [00:17<00:25, 231.26it/s]Running 10000 simulations.:  41%|████▏     | 4132/10000 [00:17<00:25, 230.70it/s]Running 10000 simulations.:  42%|████▏     | 4156/10000 [00:17<00:25, 230.71it/s]Running 10000 simulations.:  42%|████▏     | 4180/10000 [00:18<00:25, 229.71it/s]Running 10000 simulations.:  42%|████▏     | 4203/10000 [00:18<00:25, 229.51it/s]Running 10000 simulations.:  42%|████▏     | 4227/10000 [00:18<00:25, 230.51it/s]Running 10000 simulations.:  43%|████▎     | 4251/10000 [00:18<00:24, 230.80it/s]Running 10000 simulations.:  43%|████▎     | 4275/10000 [00:18<00:24, 230.79it/s]Running 10000 simulations.:  43%|████▎     | 4299/10000 [00:18<00:24, 231.21it/s]Running 10000 simulations.:  43%|████▎     | 4323/10000 [00:18<00:24, 230.99it/s]Running 10000 simulations.:  43%|████▎     | 4347/10000 [00:18<00:24, 230.75it/s]Running 10000 simulations.:  44%|████▎     | 4371/10000 [00:18<00:24, 230.78it/s]Running 10000 simulations.:  44%|████▍     | 4395/10000 [00:18<00:24, 230.97it/s]Running 10000 simulations.:  44%|████▍     | 4419/10000 [00:19<00:24, 230.50it/s]Running 10000 simulations.:  44%|████▍     | 4443/10000 [00:19<00:24, 230.97it/s]Running 10000 simulations.:  45%|████▍     | 4467/10000 [00:19<00:23, 231.68it/s]Running 10000 simulations.:  45%|████▍     | 4491/10000 [00:19<00:23, 231.85it/s]Running 10000 simulations.:  45%|████▌     | 4515/10000 [00:19<00:23, 231.73it/s]Running 10000 simulations.:  45%|████▌     | 4539/10000 [00:19<00:23, 230.92it/s]Running 10000 simulations.:  46%|████▌     | 4563/10000 [00:19<00:23, 230.61it/s]Running 10000 simulations.:  46%|████▌     | 4587/10000 [00:19<00:23, 230.10it/s]Running 10000 simulations.:  46%|████▌     | 4611/10000 [00:19<00:23, 229.70it/s]Running 10000 simulations.:  46%|████▋     | 4634/10000 [00:20<00:23, 229.58it/s]Running 10000 simulations.:  47%|████▋     | 4657/10000 [00:20<00:23, 229.46it/s]Running 10000 simulations.:  47%|████▋     | 4681/10000 [00:20<00:23, 229.86it/s]Running 10000 simulations.:  47%|████▋     | 4704/10000 [00:20<00:23, 228.97it/s]Running 10000 simulations.:  47%|████▋     | 4728/10000 [00:20<00:22, 229.90it/s]Running 10000 simulations.:  48%|████▊     | 4752/10000 [00:20<00:22, 230.84it/s]Running 10000 simulations.:  48%|████▊     | 4776/10000 [00:20<00:22, 231.84it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:20<00:22, 233.17it/s]Running 10000 simulations.:  48%|████▊     | 4824/10000 [00:20<00:22, 234.21it/s]Running 10000 simulations.:  48%|████▊     | 4848/10000 [00:20<00:21, 234.26it/s]Running 10000 simulations.:  49%|████▊     | 4872/10000 [00:21<00:21, 234.01it/s]Running 10000 simulations.:  49%|████▉     | 4896/10000 [00:21<00:21, 233.74it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:21<00:21, 233.99it/s]Running 10000 simulations.:  49%|████▉     | 4944/10000 [00:21<00:21, 233.64it/s]Running 10000 simulations.:  50%|████▉     | 4968/10000 [00:21<00:21, 233.78it/s]Running 10000 simulations.:  50%|████▉     | 4992/10000 [00:21<00:21, 232.63it/s]Running 10000 simulations.:  50%|█████     | 5016/10000 [00:21<00:21, 233.43it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:21<00:21, 233.47it/s]Running 10000 simulations.:  51%|█████     | 5064/10000 [00:21<00:21, 233.08it/s]Running 10000 simulations.:  51%|█████     | 5088/10000 [00:21<00:21, 232.86it/s]Running 10000 simulations.:  51%|█████     | 5112/10000 [00:22<00:21, 232.67it/s]Running 10000 simulations.:  51%|█████▏    | 5136/10000 [00:22<00:20, 232.99it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:22<00:20, 232.19it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:22<00:20, 232.44it/s]Running 10000 simulations.:  52%|█████▏    | 5208/10000 [00:22<00:20, 232.79it/s]Running 10000 simulations.:  52%|█████▏    | 5232/10000 [00:22<00:20, 232.36it/s]Running 10000 simulations.:  53%|█████▎    | 5256/10000 [00:22<00:20, 232.94it/s]Running 10000 simulations.:  53%|█████▎    | 5280/10000 [00:22<00:20, 233.46it/s]Running 10000 simulations.:  53%|█████▎    | 5304/10000 [00:22<00:20, 233.60it/s]Running 10000 simulations.:  53%|█████▎    | 5328/10000 [00:22<00:19, 233.98it/s]Running 10000 simulations.:  54%|█████▎    | 5352/10000 [00:23<00:19, 234.17it/s]Running 10000 simulations.:  54%|█████▍    | 5376/10000 [00:23<00:19, 234.60it/s]Running 10000 simulations.:  54%|█████▍    | 5400/10000 [00:23<00:19, 233.55it/s]Running 10000 simulations.:  54%|█████▍    | 5424/10000 [00:23<00:19, 231.91it/s]Running 10000 simulations.:  54%|█████▍    | 5448/10000 [00:23<00:19, 231.71it/s]Running 10000 simulations.:  55%|█████▍    | 5472/10000 [00:23<00:19, 231.57it/s]Running 10000 simulations.:  55%|█████▍    | 5496/10000 [00:23<00:19, 231.41it/s]Running 10000 simulations.:  55%|█████▌    | 5520/10000 [00:23<00:19, 231.03it/s]Running 10000 simulations.:  55%|█████▌    | 5544/10000 [00:23<00:19, 231.01it/s]Running 10000 simulations.:  56%|█████▌    | 5568/10000 [00:24<00:19, 231.37it/s]Running 10000 simulations.:  56%|█████▌    | 5592/10000 [00:24<00:19, 231.12it/s]Running 10000 simulations.:  56%|█████▌    | 5616/10000 [00:24<00:18, 232.20it/s]Running 10000 simulations.:  56%|█████▋    | 5640/10000 [00:24<00:18, 232.54it/s]Running 10000 simulations.:  57%|█████▋    | 5664/10000 [00:24<00:18, 232.25it/s]Running 10000 simulations.:  57%|█████▋    | 5688/10000 [00:24<00:18, 231.80it/s]Running 10000 simulations.:  57%|█████▋    | 5712/10000 [00:24<00:18, 231.66it/s]Running 10000 simulations.:  57%|█████▋    | 5736/10000 [00:24<00:18, 231.73it/s]Running 10000 simulations.:  58%|█████▊    | 5760/10000 [00:24<00:18, 230.07it/s]Running 10000 simulations.:  58%|█████▊    | 5784/10000 [00:24<00:18, 229.87it/s]Running 10000 simulations.:  58%|█████▊    | 5808/10000 [00:25<00:18, 230.04it/s]Running 10000 simulations.:  58%|█████▊    | 5832/10000 [00:25<00:18, 231.10it/s]Running 10000 simulations.:  59%|█████▊    | 5856/10000 [00:25<00:17, 231.53it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:25<00:17, 230.91it/s]Running 10000 simulations.:  59%|█████▉    | 5904/10000 [00:25<00:17, 231.09it/s]Running 10000 simulations.:  59%|█████▉    | 5928/10000 [00:25<00:17, 230.97it/s]Running 10000 simulations.:  60%|█████▉    | 5952/10000 [00:25<00:17, 230.78it/s]Running 10000 simulations.:  60%|█████▉    | 5976/10000 [00:25<00:17, 230.38it/s]Running 10000 simulations.:  60%|██████    | 6000/10000 [00:25<00:17, 230.38it/s]Running 10000 simulations.:  60%|██████    | 6024/10000 [00:26<00:17, 230.18it/s]Running 10000 simulations.:  60%|██████    | 6048/10000 [00:26<00:17, 230.36it/s]Running 10000 simulations.:  61%|██████    | 6072/10000 [00:26<00:17, 230.11it/s]Running 10000 simulations.:  61%|██████    | 6096/10000 [00:26<00:16, 230.97it/s]Running 10000 simulations.:  61%|██████    | 6120/10000 [00:26<00:16, 231.18it/s]Running 10000 simulations.:  61%|██████▏   | 6144/10000 [00:26<00:16, 232.28it/s]Running 10000 simulations.:  62%|██████▏   | 6168/10000 [00:26<00:16, 232.25it/s]Running 10000 simulations.:  62%|██████▏   | 6192/10000 [00:26<00:16, 232.52it/s]Running 10000 simulations.:  62%|██████▏   | 6216/10000 [00:26<00:16, 233.23it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:26<00:16, 233.42it/s]Running 10000 simulations.:  63%|██████▎   | 6264/10000 [00:27<00:16, 233.32it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:27<00:15, 233.68it/s]Running 10000 simulations.:  63%|██████▎   | 6312/10000 [00:27<00:15, 233.61it/s]Running 10000 simulations.:  63%|██████▎   | 6336/10000 [00:27<00:15, 232.45it/s]Running 10000 simulations.:  64%|██████▎   | 6360/10000 [00:27<00:15, 232.35it/s]Running 10000 simulations.:  64%|██████▍   | 6384/10000 [00:27<00:15, 231.75it/s]Running 10000 simulations.:  64%|██████▍   | 6408/10000 [00:27<00:15, 232.49it/s]Running 10000 simulations.:  64%|██████▍   | 6432/10000 [00:27<00:15, 232.75it/s]Running 10000 simulations.:  65%|██████▍   | 6456/10000 [00:27<00:15, 233.01it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:27<00:15, 232.91it/s]Running 10000 simulations.:  65%|██████▌   | 6504/10000 [00:28<00:15, 232.41it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:28<00:14, 232.36it/s]Running 10000 simulations.:  66%|██████▌   | 6552/10000 [00:28<00:14, 232.22it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:28<00:14, 231.75it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:28<00:14, 231.43it/s]Running 10000 simulations.:  66%|██████▌   | 6624/10000 [00:28<00:14, 231.27it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:28<00:14, 231.03it/s]Running 10000 simulations.:  67%|██████▋   | 6672/10000 [00:28<00:14, 230.86it/s]Running 10000 simulations.:  67%|██████▋   | 6696/10000 [00:28<00:14, 230.36it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:29<00:14, 230.44it/s]Running 10000 simulations.:  67%|██████▋   | 6744/10000 [00:29<00:14, 229.47it/s]Running 10000 simulations.:  68%|██████▊   | 6768/10000 [00:29<00:14, 229.70it/s]Running 10000 simulations.:  68%|██████▊   | 6791/10000 [00:29<00:13, 229.29it/s]Running 10000 simulations.:  68%|██████▊   | 6814/10000 [00:29<00:13, 228.78it/s]Running 10000 simulations.:  68%|██████▊   | 6837/10000 [00:29<00:13, 228.74it/s]Running 10000 simulations.:  69%|██████▊   | 6860/10000 [00:29<00:13, 228.79it/s]Running 10000 simulations.:  69%|██████▉   | 6883/10000 [00:29<00:13, 228.73it/s]Running 10000 simulations.:  69%|██████▉   | 6906/10000 [00:29<00:13, 228.06it/s]Running 10000 simulations.:  69%|██████▉   | 6929/10000 [00:29<00:13, 227.20it/s]Running 10000 simulations.:  70%|██████▉   | 6952/10000 [00:30<00:13, 227.22it/s]Running 10000 simulations.:  70%|██████▉   | 6975/10000 [00:30<00:13, 227.03it/s]Running 10000 simulations.:  70%|██████▉   | 6998/10000 [00:30<00:13, 227.71it/s]Running 10000 simulations.:  70%|███████   | 7021/10000 [00:30<00:13, 227.73it/s]Running 10000 simulations.:  70%|███████   | 7044/10000 [00:30<00:12, 227.57it/s]Running 10000 simulations.:  71%|███████   | 7067/10000 [00:30<00:12, 227.31it/s]Running 10000 simulations.:  71%|███████   | 7090/10000 [00:30<00:12, 227.87it/s]Running 10000 simulations.:  71%|███████   | 7113/10000 [00:30<00:12, 227.64it/s]Running 10000 simulations.:  71%|███████▏  | 7136/10000 [00:30<00:12, 227.09it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:30<00:12, 227.20it/s]Running 10000 simulations.:  72%|███████▏  | 7182/10000 [00:31<00:12, 226.81it/s]Running 10000 simulations.:  72%|███████▏  | 7205/10000 [00:31<00:12, 227.08it/s]Running 10000 simulations.:  72%|███████▏  | 7228/10000 [00:31<00:12, 227.10it/s]Running 10000 simulations.:  73%|███████▎  | 7251/10000 [00:31<00:12, 227.17it/s]Running 10000 simulations.:  73%|███████▎  | 7275/10000 [00:31<00:11, 228.53it/s]Running 10000 simulations.:  73%|███████▎  | 7299/10000 [00:31<00:11, 228.98it/s]Running 10000 simulations.:  73%|███████▎  | 7322/10000 [00:31<00:11, 228.55it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:31<00:11, 228.32it/s]Running 10000 simulations.:  74%|███████▎  | 7368/10000 [00:31<00:11, 227.65it/s]Running 10000 simulations.:  74%|███████▍  | 7391/10000 [00:31<00:11, 227.82it/s]Running 10000 simulations.:  74%|███████▍  | 7414/10000 [00:32<00:11, 227.66it/s]Running 10000 simulations.:  74%|███████▍  | 7437/10000 [00:32<00:11, 227.91it/s]Running 10000 simulations.:  75%|███████▍  | 7460/10000 [00:32<00:11, 227.03it/s]Running 10000 simulations.:  75%|███████▍  | 7483/10000 [00:32<00:11, 225.80it/s]Running 10000 simulations.:  75%|███████▌  | 7507/10000 [00:32<00:10, 227.09it/s]Running 10000 simulations.:  75%|███████▌  | 7531/10000 [00:32<00:10, 228.03it/s]Running 10000 simulations.:  76%|███████▌  | 7554/10000 [00:32<00:10, 227.96it/s]Running 10000 simulations.:  76%|███████▌  | 7577/10000 [00:32<00:10, 228.49it/s]Running 10000 simulations.:  76%|███████▌  | 7600/10000 [00:32<00:10, 228.45it/s]Running 10000 simulations.:  76%|███████▌  | 7623/10000 [00:32<00:10, 226.66it/s]Running 10000 simulations.:  76%|███████▋  | 7646/10000 [00:33<00:10, 226.27it/s]Running 10000 simulations.:  77%|███████▋  | 7669/10000 [00:33<00:10, 226.80it/s]Running 10000 simulations.:  77%|███████▋  | 7692/10000 [00:33<00:10, 227.53it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:33<00:10, 228.11it/s]Running 10000 simulations.:  77%|███████▋  | 7738/10000 [00:33<00:09, 227.70it/s]Running 10000 simulations.:  78%|███████▊  | 7761/10000 [00:33<00:09, 227.89it/s]Running 10000 simulations.:  78%|███████▊  | 7784/10000 [00:33<00:09, 228.48it/s]Running 10000 simulations.:  78%|███████▊  | 7808/10000 [00:33<00:09, 229.08it/s]Running 10000 simulations.:  78%|███████▊  | 7832/10000 [00:33<00:09, 229.89it/s]Running 10000 simulations.:  79%|███████▊  | 7855/10000 [00:33<00:09, 229.46it/s]Running 10000 simulations.:  79%|███████▉  | 7878/10000 [00:34<00:09, 228.72it/s]Running 10000 simulations.:  79%|███████▉  | 7901/10000 [00:34<00:09, 228.38it/s]Running 10000 simulations.:  79%|███████▉  | 7924/10000 [00:34<00:09, 228.29it/s]Running 10000 simulations.:  79%|███████▉  | 7947/10000 [00:34<00:09, 227.97it/s]Running 10000 simulations.:  80%|███████▉  | 7970/10000 [00:34<00:08, 227.82it/s]Running 10000 simulations.:  80%|███████▉  | 7993/10000 [00:34<00:08, 227.99it/s]Running 10000 simulations.:  80%|████████  | 8016/10000 [00:34<00:08, 228.35it/s]Running 10000 simulations.:  80%|████████  | 8039/10000 [00:34<00:08, 227.99it/s]Running 10000 simulations.:  81%|████████  | 8062/10000 [00:34<00:08, 228.29it/s]Running 10000 simulations.:  81%|████████  | 8085/10000 [00:34<00:08, 227.54it/s]Running 10000 simulations.:  81%|████████  | 8108/10000 [00:35<00:08, 226.27it/s]Running 10000 simulations.:  81%|████████▏ | 8131/10000 [00:35<00:08, 226.02it/s]Running 10000 simulations.:  82%|████████▏ | 8154/10000 [00:35<00:08, 226.35it/s]Running 10000 simulations.:  82%|████████▏ | 8177/10000 [00:35<00:08, 226.92it/s]Running 10000 simulations.:  82%|████████▏ | 8200/10000 [00:35<00:07, 227.10it/s]Running 10000 simulations.:  82%|████████▏ | 8223/10000 [00:35<00:07, 226.85it/s]Running 10000 simulations.:  82%|████████▏ | 8246/10000 [00:35<00:07, 227.02it/s]Running 10000 simulations.:  83%|████████▎ | 8269/10000 [00:35<00:07, 227.24it/s]Running 10000 simulations.:  83%|████████▎ | 8292/10000 [00:35<00:07, 227.21it/s]Running 10000 simulations.:  83%|████████▎ | 8316/10000 [00:36<00:07, 228.32it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:36<00:07, 228.83it/s]Running 10000 simulations.:  84%|████████▎ | 8363/10000 [00:36<00:07, 228.87it/s]Running 10000 simulations.:  84%|████████▍ | 8386/10000 [00:36<00:07, 229.07it/s]Running 10000 simulations.:  84%|████████▍ | 8409/10000 [00:36<00:06, 228.74it/s]Running 10000 simulations.:  84%|████████▍ | 8432/10000 [00:36<00:06, 228.72it/s]Running 10000 simulations.:  85%|████████▍ | 8455/10000 [00:36<00:06, 228.27it/s]Running 10000 simulations.:  85%|████████▍ | 8478/10000 [00:36<00:06, 228.00it/s]Running 10000 simulations.:  85%|████████▌ | 8502/10000 [00:36<00:06, 229.00it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [00:36<00:06, 230.16it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:37<00:06, 230.57it/s]Running 10000 simulations.:  86%|████████▌ | 8574/10000 [00:37<00:06, 230.52it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [00:37<00:06, 230.54it/s]Running 10000 simulations.:  86%|████████▌ | 8622/10000 [00:37<00:05, 230.03it/s]Running 10000 simulations.:  86%|████████▋ | 8646/10000 [00:37<00:05, 229.97it/s]Running 10000 simulations.:  87%|████████▋ | 8669/10000 [00:37<00:05, 229.91it/s]Running 10000 simulations.:  87%|████████▋ | 8692/10000 [00:37<00:05, 229.66it/s]Running 10000 simulations.:  87%|████████▋ | 8715/10000 [00:37<00:05, 229.27it/s]Running 10000 simulations.:  87%|████████▋ | 8739/10000 [00:37<00:05, 229.54it/s]Running 10000 simulations.:  88%|████████▊ | 8763/10000 [00:37<00:05, 230.39it/s]Running 10000 simulations.:  88%|████████▊ | 8787/10000 [00:38<00:05, 230.67it/s]Running 10000 simulations.:  88%|████████▊ | 8811/10000 [00:38<00:05, 230.64it/s]Running 10000 simulations.:  88%|████████▊ | 8835/10000 [00:38<00:05, 230.30it/s]Running 10000 simulations.:  89%|████████▊ | 8859/10000 [00:38<00:04, 230.09it/s]Running 10000 simulations.:  89%|████████▉ | 8883/10000 [00:38<00:04, 229.93it/s]Running 10000 simulations.:  89%|████████▉ | 8906/10000 [00:38<00:04, 229.51it/s]Running 10000 simulations.:  89%|████████▉ | 8929/10000 [00:38<00:04, 228.98it/s]Running 10000 simulations.:  90%|████████▉ | 8952/10000 [00:38<00:04, 228.48it/s]Running 10000 simulations.:  90%|████████▉ | 8975/10000 [00:38<00:04, 228.15it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:38<00:04, 228.14it/s]Running 10000 simulations.:  90%|█████████ | 9021/10000 [00:39<00:04, 227.81it/s]Running 10000 simulations.:  90%|█████████ | 9044/10000 [00:39<00:04, 227.28it/s]Running 10000 simulations.:  91%|█████████ | 9067/10000 [00:39<00:04, 227.57it/s]Running 10000 simulations.:  91%|█████████ | 9090/10000 [00:39<00:04, 227.43it/s]Running 10000 simulations.:  91%|█████████ | 9113/10000 [00:39<00:03, 226.86it/s]Running 10000 simulations.:  91%|█████████▏| 9136/10000 [00:39<00:03, 226.87it/s]Running 10000 simulations.:  92%|█████████▏| 9159/10000 [00:39<00:03, 227.05it/s]Running 10000 simulations.:  92%|█████████▏| 9182/10000 [00:39<00:03, 227.27it/s]Running 10000 simulations.:  92%|█████████▏| 9205/10000 [00:39<00:03, 226.88it/s]Running 10000 simulations.:  92%|█████████▏| 9228/10000 [00:39<00:03, 226.61it/s]Running 10000 simulations.:  93%|█████████▎| 9251/10000 [00:40<00:03, 226.27it/s]Running 10000 simulations.:  93%|█████████▎| 9274/10000 [00:40<00:03, 226.93it/s]Running 10000 simulations.:  93%|█████████▎| 9297/10000 [00:40<00:03, 226.56it/s]Running 10000 simulations.:  93%|█████████▎| 9320/10000 [00:40<00:03, 225.56it/s]Running 10000 simulations.:  93%|█████████▎| 9343/10000 [00:40<00:03, 213.23it/s]Running 10000 simulations.:  94%|█████████▎| 9366/10000 [00:40<00:02, 216.84it/s]Running 10000 simulations.:  94%|█████████▍| 9389/10000 [00:40<00:02, 219.19it/s]Running 10000 simulations.:  94%|█████████▍| 9412/10000 [00:40<00:02, 220.27it/s]Running 10000 simulations.:  94%|█████████▍| 9435/10000 [00:40<00:02, 221.89it/s]Running 10000 simulations.:  95%|█████████▍| 9458/10000 [00:41<00:02, 223.03it/s]Running 10000 simulations.:  95%|█████████▍| 9481/10000 [00:41<00:02, 224.23it/s]Running 10000 simulations.:  95%|█████████▌| 9504/10000 [00:41<00:02, 225.49it/s]Running 10000 simulations.:  95%|█████████▌| 9527/10000 [00:41<00:02, 225.79it/s]Running 10000 simulations.:  96%|█████████▌| 9550/10000 [00:41<00:01, 226.43it/s]Running 10000 simulations.:  96%|█████████▌| 9573/10000 [00:41<00:01, 226.03it/s]Running 10000 simulations.:  96%|█████████▌| 9596/10000 [00:41<00:01, 226.89it/s]Running 10000 simulations.:  96%|█████████▌| 9619/10000 [00:41<00:01, 227.27it/s]Running 10000 simulations.:  96%|█████████▋| 9643/10000 [00:41<00:01, 228.04it/s]Running 10000 simulations.:  97%|█████████▋| 9667/10000 [00:41<00:01, 228.95it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [00:42<00:01, 229.23it/s]Running 10000 simulations.:  97%|█████████▋| 9714/10000 [00:42<00:01, 229.76it/s]Running 10000 simulations.:  97%|█████████▋| 9737/10000 [00:42<00:01, 229.36it/s]Running 10000 simulations.:  98%|█████████▊| 9760/10000 [00:42<00:01, 228.70it/s]Running 10000 simulations.:  98%|█████████▊| 9783/10000 [00:42<00:00, 228.13it/s]Running 10000 simulations.:  98%|█████████▊| 9806/10000 [00:42<00:00, 228.15it/s]Running 10000 simulations.:  98%|█████████▊| 9830/10000 [00:42<00:00, 229.04it/s]Running 10000 simulations.:  99%|█████████▊| 9853/10000 [00:42<00:00, 229.18it/s]Running 10000 simulations.:  99%|█████████▉| 9876/10000 [00:42<00:00, 229.18it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:42<00:00, 229.05it/s]Running 10000 simulations.:  99%|█████████▉| 9922/10000 [00:43<00:00, 228.92it/s]Running 10000 simulations.:  99%|█████████▉| 9945/10000 [00:43<00:00, 228.90it/s]Running 10000 simulations.: 100%|█████████▉| 9968/10000 [00:43<00:00, 229.16it/s]Running 10000 simulations.: 100%|█████████▉| 9991/10000 [00:43<00:00, 229.10it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:43<00:00, 230.36it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:40, 244.00it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:40, 245.12it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:40, 245.23it/s]Running 10000 simulations.:   1%|          | 100/10000 [00:00<00:40, 244.75it/s]Running 10000 simulations.:   1%|▏         | 125/10000 [00:00<00:40, 243.92it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:40, 243.80it/s]Running 10000 simulations.:   2%|▏         | 175/10000 [00:00<00:40, 243.94it/s]Running 10000 simulations.:   2%|▏         | 200/10000 [00:00<00:40, 244.31it/s]Running 10000 simulations.:   2%|▏         | 225/10000 [00:00<00:40, 243.62it/s]Running 10000 simulations.:   2%|▎         | 250/10000 [00:01<00:40, 243.28it/s]Running 10000 simulations.:   3%|▎         | 275/10000 [00:01<00:39, 243.23it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:01<00:40, 242.21it/s]Running 10000 simulations.:   3%|▎         | 324/10000 [00:01<00:40, 240.92it/s]Running 10000 simulations.:   3%|▎         | 348/10000 [00:01<00:40, 240.48it/s]Running 10000 simulations.:   4%|▎         | 372/10000 [00:01<00:40, 237.73it/s]Running 10000 simulations.:   4%|▍         | 396/10000 [00:01<00:40, 237.00it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:40, 237.60it/s]Running 10000 simulations.:   4%|▍         | 444/10000 [00:01<00:40, 238.02it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:01<00:40, 237.70it/s]Running 10000 simulations.:   5%|▍         | 492/10000 [00:02<00:40, 237.53it/s]Running 10000 simulations.:   5%|▌         | 516/10000 [00:02<00:40, 236.49it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:02<00:40, 235.10it/s]Running 10000 simulations.:   6%|▌         | 564/10000 [00:02<00:40, 234.88it/s]Running 10000 simulations.:   6%|▌         | 588/10000 [00:02<00:40, 234.43it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:02<00:40, 233.23it/s]Running 10000 simulations.:   6%|▋         | 636/10000 [00:02<00:40, 232.78it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:02<00:40, 232.59it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:02<00:40, 232.65it/s]Running 10000 simulations.:   7%|▋         | 708/10000 [00:02<00:40, 232.24it/s]Running 10000 simulations.:   7%|▋         | 732/10000 [00:03<00:39, 232.10it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:03<00:39, 232.94it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:03<00:39, 232.61it/s]Running 10000 simulations.:   8%|▊         | 804/10000 [00:03<00:39, 232.29it/s]Running 10000 simulations.:   8%|▊         | 828/10000 [00:03<00:39, 232.15it/s]Running 10000 simulations.:   9%|▊         | 852/10000 [00:03<00:39, 232.64it/s]Running 10000 simulations.:   9%|▉         | 876/10000 [00:03<00:39, 232.60it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:39, 232.04it/s]Running 10000 simulations.:   9%|▉         | 924/10000 [00:03<00:39, 231.88it/s]Running 10000 simulations.:   9%|▉         | 948/10000 [00:04<00:38, 232.34it/s]Running 10000 simulations.:  10%|▉         | 972/10000 [00:04<00:38, 233.01it/s]Running 10000 simulations.:  10%|▉         | 996/10000 [00:04<00:38, 233.16it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:04<00:38, 232.89it/s]Running 10000 simulations.:  10%|█         | 1044/10000 [00:04<00:38, 232.51it/s]Running 10000 simulations.:  11%|█         | 1068/10000 [00:04<00:38, 229.67it/s]Running 10000 simulations.:  11%|█         | 1092/10000 [00:04<00:38, 230.54it/s]Running 10000 simulations.:  11%|█         | 1116/10000 [00:04<00:38, 231.56it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:04<00:38, 232.17it/s]Running 10000 simulations.:  12%|█▏        | 1164/10000 [00:04<00:37, 232.69it/s]Running 10000 simulations.:  12%|█▏        | 1188/10000 [00:05<00:37, 233.57it/s]Running 10000 simulations.:  12%|█▏        | 1212/10000 [00:05<00:37, 234.38it/s]Running 10000 simulations.:  12%|█▏        | 1236/10000 [00:05<00:37, 231.14it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:05<00:38, 225.57it/s]Running 10000 simulations.:  13%|█▎        | 1283/10000 [00:05<00:38, 223.67it/s]Running 10000 simulations.:  13%|█▎        | 1306/10000 [00:05<00:39, 221.93it/s]Running 10000 simulations.:  13%|█▎        | 1329/10000 [00:05<00:39, 221.24it/s]Running 10000 simulations.:  14%|█▎        | 1352/10000 [00:05<00:39, 220.32it/s]Running 10000 simulations.:  14%|█▍        | 1375/10000 [00:05<00:39, 219.05it/s]Running 10000 simulations.:  14%|█▍        | 1397/10000 [00:05<00:39, 217.84it/s]Running 10000 simulations.:  14%|█▍        | 1420/10000 [00:06<00:38, 220.05it/s]Running 10000 simulations.:  14%|█▍        | 1443/10000 [00:06<00:38, 221.39it/s]Running 10000 simulations.:  15%|█▍        | 1466/10000 [00:06<00:38, 220.40it/s]Running 10000 simulations.:  15%|█▍        | 1489/10000 [00:06<00:38, 221.37it/s]Running 10000 simulations.:  15%|█▌        | 1513/10000 [00:06<00:37, 224.85it/s]Running 10000 simulations.:  15%|█▌        | 1537/10000 [00:06<00:37, 227.85it/s]Running 10000 simulations.:  16%|█▌        | 1561/10000 [00:06<00:36, 229.44it/s]Running 10000 simulations.:  16%|█▌        | 1584/10000 [00:06<00:36, 229.43it/s]Running 10000 simulations.:  16%|█▌        | 1607/10000 [00:06<00:36, 227.63it/s]Running 10000 simulations.:  16%|█▋        | 1631/10000 [00:07<00:36, 228.73it/s]Running 10000 simulations.:  17%|█▋        | 1655/10000 [00:07<00:36, 229.40it/s]Running 10000 simulations.:  17%|█▋        | 1679/10000 [00:07<00:36, 230.77it/s]Running 10000 simulations.:  17%|█▋        | 1703/10000 [00:07<00:35, 231.77it/s]Running 10000 simulations.:  17%|█▋        | 1727/10000 [00:07<00:35, 231.86it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:07<00:35, 232.57it/s]Running 10000 simulations.:  18%|█▊        | 1775/10000 [00:07<00:35, 233.77it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:07<00:35, 234.06it/s]Running 10000 simulations.:  18%|█▊        | 1823/10000 [00:07<00:34, 234.41it/s]Running 10000 simulations.:  18%|█▊        | 1847/10000 [00:07<00:34, 235.19it/s]Running 10000 simulations.:  19%|█▊        | 1871/10000 [00:08<00:34, 234.00it/s]Running 10000 simulations.:  19%|█▉        | 1895/10000 [00:08<00:34, 233.07it/s]Running 10000 simulations.:  19%|█▉        | 1919/10000 [00:08<00:34, 234.34it/s]Running 10000 simulations.:  19%|█▉        | 1943/10000 [00:08<00:34, 235.23it/s]Running 10000 simulations.:  20%|█▉        | 1967/10000 [00:08<00:34, 235.67it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:08<00:33, 236.19it/s]Running 10000 simulations.:  20%|██        | 2015/10000 [00:08<00:33, 236.14it/s]Running 10000 simulations.:  20%|██        | 2039/10000 [00:08<00:33, 236.10it/s]Running 10000 simulations.:  21%|██        | 2063/10000 [00:08<00:33, 235.92it/s]Running 10000 simulations.:  21%|██        | 2087/10000 [00:08<00:33, 235.55it/s]Running 10000 simulations.:  21%|██        | 2111/10000 [00:09<00:33, 235.22it/s]Running 10000 simulations.:  21%|██▏       | 2135/10000 [00:09<00:33, 235.43it/s]Running 10000 simulations.:  22%|██▏       | 2159/10000 [00:09<00:33, 235.42it/s]Running 10000 simulations.:  22%|██▏       | 2183/10000 [00:09<00:33, 235.36it/s]Running 10000 simulations.:  22%|██▏       | 2207/10000 [00:09<00:33, 235.23it/s]Running 10000 simulations.:  22%|██▏       | 2231/10000 [00:09<00:33, 234.80it/s]Running 10000 simulations.:  23%|██▎       | 2255/10000 [00:09<00:33, 234.55it/s]Running 10000 simulations.:  23%|██▎       | 2279/10000 [00:09<00:32, 234.24it/s]Running 10000 simulations.:  23%|██▎       | 2303/10000 [00:09<00:32, 233.93it/s]Running 10000 simulations.:  23%|██▎       | 2327/10000 [00:09<00:32, 234.58it/s]Running 10000 simulations.:  24%|██▎       | 2351/10000 [00:10<00:32, 233.58it/s]Running 10000 simulations.:  24%|██▍       | 2375/10000 [00:10<00:32, 232.84it/s]Running 10000 simulations.:  24%|██▍       | 2399/10000 [00:10<00:32, 233.70it/s]Running 10000 simulations.:  24%|██▍       | 2423/10000 [00:10<00:32, 234.31it/s]Running 10000 simulations.:  24%|██▍       | 2447/10000 [00:10<00:32, 234.01it/s]Running 10000 simulations.:  25%|██▍       | 2471/10000 [00:10<00:32, 234.40it/s]Running 10000 simulations.:  25%|██▍       | 2495/10000 [00:10<00:32, 234.03it/s]Running 10000 simulations.:  25%|██▌       | 2519/10000 [00:10<00:31, 234.13it/s]Running 10000 simulations.:  25%|██▌       | 2543/10000 [00:10<00:31, 234.33it/s]Running 10000 simulations.:  26%|██▌       | 2567/10000 [00:11<00:31, 233.95it/s]Running 10000 simulations.:  26%|██▌       | 2591/10000 [00:11<00:31, 233.63it/s]Running 10000 simulations.:  26%|██▌       | 2615/10000 [00:11<00:31, 233.59it/s]Running 10000 simulations.:  26%|██▋       | 2639/10000 [00:11<00:31, 233.33it/s]Running 10000 simulations.:  27%|██▋       | 2663/10000 [00:11<00:31, 234.08it/s]Running 10000 simulations.:  27%|██▋       | 2687/10000 [00:11<00:31, 233.75it/s]Running 10000 simulations.:  27%|██▋       | 2711/10000 [00:11<00:31, 234.19it/s]Running 10000 simulations.:  27%|██▋       | 2735/10000 [00:11<00:31, 233.35it/s]Running 10000 simulations.:  28%|██▊       | 2759/10000 [00:11<00:31, 233.16it/s]Running 10000 simulations.:  28%|██▊       | 2783/10000 [00:11<00:30, 232.98it/s]Running 10000 simulations.:  28%|██▊       | 2807/10000 [00:12<00:30, 233.52it/s]Running 10000 simulations.:  28%|██▊       | 2831/10000 [00:12<00:30, 233.86it/s]Running 10000 simulations.:  29%|██▊       | 2855/10000 [00:12<00:30, 234.15it/s]Running 10000 simulations.:  29%|██▉       | 2879/10000 [00:12<00:30, 233.50it/s]Running 10000 simulations.:  29%|██▉       | 2903/10000 [00:12<00:30, 233.92it/s]Running 10000 simulations.:  29%|██▉       | 2927/10000 [00:12<00:30, 234.52it/s]Running 10000 simulations.:  30%|██▉       | 2951/10000 [00:12<00:29, 235.21it/s]Running 10000 simulations.:  30%|██▉       | 2975/10000 [00:12<00:29, 234.74it/s]Running 10000 simulations.:  30%|██▉       | 2999/10000 [00:12<00:29, 235.02it/s]Running 10000 simulations.:  30%|███       | 3023/10000 [00:12<00:29, 235.36it/s]Running 10000 simulations.:  30%|███       | 3047/10000 [00:13<00:29, 234.22it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:13<00:29, 233.75it/s]Running 10000 simulations.:  31%|███       | 3095/10000 [00:13<00:29, 233.29it/s]Running 10000 simulations.:  31%|███       | 3119/10000 [00:13<00:29, 233.38it/s]Running 10000 simulations.:  31%|███▏      | 3143/10000 [00:13<00:29, 232.32it/s]Running 10000 simulations.:  32%|███▏      | 3167/10000 [00:13<00:29, 232.59it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:13<00:29, 231.59it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:13<00:29, 232.32it/s]Running 10000 simulations.:  32%|███▏      | 3239/10000 [00:13<00:29, 232.91it/s]Running 10000 simulations.:  33%|███▎      | 3263/10000 [00:13<00:28, 232.57it/s]Running 10000 simulations.:  33%|███▎      | 3287/10000 [00:14<00:28, 232.42it/s]Running 10000 simulations.:  33%|███▎      | 3311/10000 [00:14<00:28, 232.07it/s]Running 10000 simulations.:  33%|███▎      | 3335/10000 [00:14<00:28, 232.28it/s]Running 10000 simulations.:  34%|███▎      | 3359/10000 [00:14<00:28, 232.99it/s]Running 10000 simulations.:  34%|███▍      | 3383/10000 [00:14<00:28, 232.20it/s]Running 10000 simulations.:  34%|███▍      | 3407/10000 [00:14<00:28, 232.30it/s]Running 10000 simulations.:  34%|███▍      | 3431/10000 [00:14<00:28, 232.23it/s]Running 10000 simulations.:  35%|███▍      | 3455/10000 [00:14<00:28, 233.03it/s]Running 10000 simulations.:  35%|███▍      | 3479/10000 [00:14<00:27, 233.83it/s]Running 10000 simulations.:  35%|███▌      | 3503/10000 [00:15<00:27, 234.49it/s]Running 10000 simulations.:  35%|███▌      | 3527/10000 [00:15<00:27, 234.10it/s]Running 10000 simulations.:  36%|███▌      | 3551/10000 [00:15<00:27, 232.97it/s]Running 10000 simulations.:  36%|███▌      | 3575/10000 [00:15<00:27, 232.73it/s]Running 10000 simulations.:  36%|███▌      | 3599/10000 [00:15<00:27, 233.09it/s]Running 10000 simulations.:  36%|███▌      | 3623/10000 [00:15<00:27, 233.77it/s]Running 10000 simulations.:  36%|███▋      | 3647/10000 [00:15<00:27, 233.59it/s]Running 10000 simulations.:  37%|███▋      | 3671/10000 [00:15<00:27, 233.04it/s]Running 10000 simulations.:  37%|███▋      | 3695/10000 [00:15<00:27, 233.40it/s]Running 10000 simulations.:  37%|███▋      | 3719/10000 [00:15<00:27, 230.77it/s]Running 10000 simulations.:  37%|███▋      | 3743/10000 [00:16<00:28, 218.92it/s]Running 10000 simulations.:  38%|███▊      | 3767/10000 [00:16<00:28, 222.46it/s]Running 10000 simulations.:  38%|███▊      | 3791/10000 [00:16<00:27, 225.95it/s]Running 10000 simulations.:  38%|███▊      | 3815/10000 [00:16<00:27, 228.70it/s]Running 10000 simulations.:  38%|███▊      | 3839/10000 [00:16<00:26, 230.23it/s]Running 10000 simulations.:  39%|███▊      | 3863/10000 [00:16<00:26, 230.77it/s]Running 10000 simulations.:  39%|███▉      | 3887/10000 [00:16<00:26, 232.20it/s]Running 10000 simulations.:  39%|███▉      | 3911/10000 [00:16<00:26, 232.84it/s]Running 10000 simulations.:  39%|███▉      | 3935/10000 [00:16<00:26, 231.36it/s]Running 10000 simulations.:  40%|███▉      | 3959/10000 [00:16<00:26, 230.94it/s]Running 10000 simulations.:  40%|███▉      | 3983/10000 [00:17<00:26, 230.68it/s]Running 10000 simulations.:  40%|████      | 4007/10000 [00:17<00:25, 231.57it/s]Running 10000 simulations.:  40%|████      | 4031/10000 [00:17<00:25, 231.96it/s]Running 10000 simulations.:  41%|████      | 4055/10000 [00:17<00:25, 232.98it/s]Running 10000 simulations.:  41%|████      | 4079/10000 [00:17<00:25, 233.09it/s]Running 10000 simulations.:  41%|████      | 4103/10000 [00:17<00:25, 233.72it/s]Running 10000 simulations.:  41%|████▏     | 4127/10000 [00:17<00:25, 234.14it/s]Running 10000 simulations.:  42%|████▏     | 4151/10000 [00:17<00:25, 233.36it/s]Running 10000 simulations.:  42%|████▏     | 4175/10000 [00:17<00:25, 232.65it/s]Running 10000 simulations.:  42%|████▏     | 4199/10000 [00:18<00:25, 231.57it/s]Running 10000 simulations.:  42%|████▏     | 4223/10000 [00:18<00:24, 231.17it/s]Running 10000 simulations.:  42%|████▏     | 4247/10000 [00:18<00:24, 231.32it/s]Running 10000 simulations.:  43%|████▎     | 4271/10000 [00:18<00:24, 231.51it/s]Running 10000 simulations.:  43%|████▎     | 4295/10000 [00:18<00:24, 231.70it/s]Running 10000 simulations.:  43%|████▎     | 4319/10000 [00:18<00:24, 231.81it/s]Running 10000 simulations.:  43%|████▎     | 4343/10000 [00:18<00:24, 231.64it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:18<00:24, 230.41it/s]Running 10000 simulations.:  44%|████▍     | 4391/10000 [00:18<00:24, 230.76it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:18<00:24, 231.71it/s]Running 10000 simulations.:  44%|████▍     | 4439/10000 [00:19<00:23, 232.44it/s]Running 10000 simulations.:  45%|████▍     | 4463/10000 [00:19<00:23, 231.90it/s]Running 10000 simulations.:  45%|████▍     | 4487/10000 [00:19<00:23, 232.38it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:19<00:23, 232.48it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:19<00:23, 231.60it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:19<00:23, 232.93it/s]Running 10000 simulations.:  46%|████▌     | 4583/10000 [00:19<00:23, 232.50it/s]Running 10000 simulations.:  46%|████▌     | 4607/10000 [00:19<00:23, 232.83it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:19<00:23, 233.02it/s]Running 10000 simulations.:  47%|████▋     | 4655/10000 [00:19<00:22, 233.12it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:20<00:22, 232.00it/s]Running 10000 simulations.:  47%|████▋     | 4703/10000 [00:20<00:22, 232.54it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:20<00:22, 232.59it/s]Running 10000 simulations.:  48%|████▊     | 4751/10000 [00:20<00:22, 231.13it/s]Running 10000 simulations.:  48%|████▊     | 4775/10000 [00:20<00:22, 230.62it/s]Running 10000 simulations.:  48%|████▊     | 4799/10000 [00:20<00:22, 231.54it/s]Running 10000 simulations.:  48%|████▊     | 4823/10000 [00:20<00:22, 232.37it/s]Running 10000 simulations.:  48%|████▊     | 4847/10000 [00:20<00:22, 232.54it/s]Running 10000 simulations.:  49%|████▊     | 4871/10000 [00:20<00:22, 231.73it/s]Running 10000 simulations.:  49%|████▉     | 4895/10000 [00:21<00:22, 231.30it/s]Running 10000 simulations.:  49%|████▉     | 4919/10000 [00:21<00:21, 232.26it/s]Running 10000 simulations.:  49%|████▉     | 4943/10000 [00:21<00:21, 232.79it/s]Running 10000 simulations.:  50%|████▉     | 4967/10000 [00:21<00:21, 232.40it/s]Running 10000 simulations.:  50%|████▉     | 4991/10000 [00:21<00:21, 232.09it/s]Running 10000 simulations.:  50%|█████     | 5015/10000 [00:21<00:21, 231.67it/s]Running 10000 simulations.:  50%|█████     | 5039/10000 [00:21<00:21, 231.44it/s]Running 10000 simulations.:  51%|█████     | 5063/10000 [00:21<00:21, 230.96it/s]Running 10000 simulations.:  51%|█████     | 5087/10000 [00:21<00:21, 229.66it/s]Running 10000 simulations.:  51%|█████     | 5110/10000 [00:21<00:21, 228.59it/s]Running 10000 simulations.:  51%|█████▏    | 5134/10000 [00:22<00:21, 229.58it/s]Running 10000 simulations.:  52%|█████▏    | 5158/10000 [00:22<00:20, 231.10it/s]Running 10000 simulations.:  52%|█████▏    | 5182/10000 [00:22<00:20, 231.82it/s]Running 10000 simulations.:  52%|█████▏    | 5206/10000 [00:22<00:20, 231.56it/s]Running 10000 simulations.:  52%|█████▏    | 5230/10000 [00:22<00:20, 231.99it/s]Running 10000 simulations.:  53%|█████▎    | 5254/10000 [00:22<00:20, 232.00it/s]Running 10000 simulations.:  53%|█████▎    | 5278/10000 [00:22<00:20, 231.97it/s]Running 10000 simulations.:  53%|█████▎    | 5302/10000 [00:22<00:20, 232.42it/s]Running 10000 simulations.:  53%|█████▎    | 5326/10000 [00:22<00:20, 232.94it/s]Running 10000 simulations.:  54%|█████▎    | 5350/10000 [00:22<00:19, 233.22it/s]Running 10000 simulations.:  54%|█████▎    | 5374/10000 [00:23<00:19, 232.60it/s]Running 10000 simulations.:  54%|█████▍    | 5398/10000 [00:23<00:19, 232.80it/s]Running 10000 simulations.:  54%|█████▍    | 5422/10000 [00:23<00:19, 232.54it/s]Running 10000 simulations.:  54%|█████▍    | 5446/10000 [00:23<00:19, 231.32it/s]Running 10000 simulations.:  55%|█████▍    | 5470/10000 [00:23<00:19, 231.25it/s]Running 10000 simulations.:  55%|█████▍    | 5494/10000 [00:23<00:19, 231.49it/s]Running 10000 simulations.:  55%|█████▌    | 5518/10000 [00:23<00:19, 231.21it/s]Running 10000 simulations.:  55%|█████▌    | 5542/10000 [00:23<00:19, 231.43it/s]Running 10000 simulations.:  56%|█████▌    | 5566/10000 [00:23<00:19, 229.69it/s]Running 10000 simulations.:  56%|█████▌    | 5590/10000 [00:24<00:19, 230.21it/s]Running 10000 simulations.:  56%|█████▌    | 5614/10000 [00:24<00:18, 230.98it/s]Running 10000 simulations.:  56%|█████▋    | 5638/10000 [00:24<00:18, 231.30it/s]Running 10000 simulations.:  57%|█████▋    | 5662/10000 [00:24<00:18, 230.09it/s]Running 10000 simulations.:  57%|█████▋    | 5686/10000 [00:24<00:18, 229.66it/s]Running 10000 simulations.:  57%|█████▋    | 5709/10000 [00:24<00:18, 229.68it/s]Running 10000 simulations.:  57%|█████▋    | 5733/10000 [00:24<00:18, 230.25it/s]Running 10000 simulations.:  58%|█████▊    | 5757/10000 [00:24<00:18, 230.10it/s]Running 10000 simulations.:  58%|█████▊    | 5781/10000 [00:24<00:18, 230.14it/s]Running 10000 simulations.:  58%|█████▊    | 5805/10000 [00:24<00:18, 230.11it/s]Running 10000 simulations.:  58%|█████▊    | 5829/10000 [00:25<00:18, 230.41it/s]Running 10000 simulations.:  59%|█████▊    | 5853/10000 [00:25<00:17, 230.55it/s]Running 10000 simulations.:  59%|█████▉    | 5877/10000 [00:25<00:17, 230.29it/s]Running 10000 simulations.:  59%|█████▉    | 5901/10000 [00:25<00:17, 230.04it/s]Running 10000 simulations.:  59%|█████▉    | 5925/10000 [00:25<00:17, 229.56it/s]Running 10000 simulations.:  59%|█████▉    | 5949/10000 [00:25<00:17, 229.98it/s]Running 10000 simulations.:  60%|█████▉    | 5973/10000 [00:25<00:17, 230.34it/s]Running 10000 simulations.:  60%|█████▉    | 5997/10000 [00:25<00:17, 229.63it/s]Running 10000 simulations.:  60%|██████    | 6020/10000 [00:25<00:17, 229.68it/s]Running 10000 simulations.:  60%|██████    | 6043/10000 [00:26<00:17, 229.02it/s]Running 10000 simulations.:  61%|██████    | 6066/10000 [00:26<00:17, 228.96it/s]Running 10000 simulations.:  61%|██████    | 6090/10000 [00:26<00:17, 229.71it/s]Running 10000 simulations.:  61%|██████    | 6113/10000 [00:26<00:16, 229.52it/s]Running 10000 simulations.:  61%|██████▏   | 6137/10000 [00:26<00:16, 230.29it/s]Running 10000 simulations.:  62%|██████▏   | 6161/10000 [00:26<00:16, 230.85it/s]Running 10000 simulations.:  62%|██████▏   | 6185/10000 [00:26<00:16, 231.17it/s]Running 10000 simulations.:  62%|██████▏   | 6209/10000 [00:26<00:16, 231.53it/s]Running 10000 simulations.:  62%|██████▏   | 6233/10000 [00:26<00:16, 231.46it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:26<00:16, 231.97it/s]Running 10000 simulations.:  63%|██████▎   | 6281/10000 [00:27<00:16, 231.96it/s]Running 10000 simulations.:  63%|██████▎   | 6305/10000 [00:27<00:15, 231.03it/s]Running 10000 simulations.:  63%|██████▎   | 6329/10000 [00:27<00:15, 229.80it/s]Running 10000 simulations.:  64%|██████▎   | 6352/10000 [00:27<00:15, 229.76it/s]Running 10000 simulations.:  64%|██████▍   | 6376/10000 [00:27<00:15, 230.27it/s]Running 10000 simulations.:  64%|██████▍   | 6400/10000 [00:27<00:15, 230.44it/s]Running 10000 simulations.:  64%|██████▍   | 6424/10000 [00:27<00:15, 227.05it/s]Running 10000 simulations.:  64%|██████▍   | 6447/10000 [00:27<00:15, 225.73it/s]Running 10000 simulations.:  65%|██████▍   | 6470/10000 [00:27<00:15, 225.62it/s]Running 10000 simulations.:  65%|██████▍   | 6493/10000 [00:27<00:15, 225.19it/s]Running 10000 simulations.:  65%|██████▌   | 6516/10000 [00:28<00:15, 225.27it/s]Running 10000 simulations.:  65%|██████▌   | 6539/10000 [00:28<00:15, 224.35it/s]Running 10000 simulations.:  66%|██████▌   | 6562/10000 [00:28<00:15, 224.81it/s]Running 10000 simulations.:  66%|██████▌   | 6585/10000 [00:28<00:15, 225.53it/s]Running 10000 simulations.:  66%|██████▌   | 6608/10000 [00:28<00:14, 226.19it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:28<00:14, 226.26it/s]Running 10000 simulations.:  67%|██████▋   | 6654/10000 [00:28<00:14, 225.45it/s]Running 10000 simulations.:  67%|██████▋   | 6677/10000 [00:28<00:14, 224.05it/s]Running 10000 simulations.:  67%|██████▋   | 6700/10000 [00:28<00:14, 224.47it/s]Running 10000 simulations.:  67%|██████▋   | 6723/10000 [00:28<00:14, 224.58it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:29<00:14, 224.36it/s]Running 10000 simulations.:  68%|██████▊   | 6769/10000 [00:29<00:14, 223.47it/s]Running 10000 simulations.:  68%|██████▊   | 6792/10000 [00:29<00:14, 223.01it/s]Running 10000 simulations.:  68%|██████▊   | 6815/10000 [00:29<00:14, 222.85it/s]Running 10000 simulations.:  68%|██████▊   | 6838/10000 [00:29<00:14, 223.21it/s]Running 10000 simulations.:  69%|██████▊   | 6861/10000 [00:29<00:14, 224.12it/s]Running 10000 simulations.:  69%|██████▉   | 6884/10000 [00:29<00:13, 224.29it/s]Running 10000 simulations.:  69%|██████▉   | 6907/10000 [00:29<00:13, 224.43it/s]Running 10000 simulations.:  69%|██████▉   | 6930/10000 [00:29<00:13, 224.94it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:30<00:13, 223.44it/s]Running 10000 simulations.:  70%|██████▉   | 6976/10000 [00:30<00:13, 223.19it/s]Running 10000 simulations.:  70%|██████▉   | 6999/10000 [00:30<00:13, 223.54it/s]Running 10000 simulations.:  70%|███████   | 7022/10000 [00:30<00:13, 224.46it/s]Running 10000 simulations.:  70%|███████   | 7045/10000 [00:30<00:13, 224.45it/s]Running 10000 simulations.:  71%|███████   | 7068/10000 [00:30<00:13, 224.15it/s]Running 10000 simulations.:  71%|███████   | 7091/10000 [00:30<00:13, 223.63it/s]Running 10000 simulations.:  71%|███████   | 7114/10000 [00:30<00:12, 224.59it/s]Running 10000 simulations.:  71%|███████▏  | 7137/10000 [00:30<00:12, 224.98it/s]Running 10000 simulations.:  72%|███████▏  | 7160/10000 [00:30<00:12, 224.67it/s]Running 10000 simulations.:  72%|███████▏  | 7183/10000 [00:31<00:12, 223.08it/s]Running 10000 simulations.:  72%|███████▏  | 7206/10000 [00:31<00:12, 224.29it/s]Running 10000 simulations.:  72%|███████▏  | 7229/10000 [00:31<00:12, 225.21it/s]Running 10000 simulations.:  73%|███████▎  | 7252/10000 [00:31<00:12, 226.17it/s]Running 10000 simulations.:  73%|███████▎  | 7275/10000 [00:31<00:12, 226.57it/s]Running 10000 simulations.:  73%|███████▎  | 7298/10000 [00:31<00:11, 225.89it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:31<00:11, 226.05it/s]Running 10000 simulations.:  73%|███████▎  | 7344/10000 [00:31<00:11, 226.32it/s]Running 10000 simulations.:  74%|███████▎  | 7367/10000 [00:31<00:11, 226.24it/s]Running 10000 simulations.:  74%|███████▍  | 7390/10000 [00:31<00:11, 226.01it/s]Running 10000 simulations.:  74%|███████▍  | 7413/10000 [00:32<00:11, 226.81it/s]Running 10000 simulations.:  74%|███████▍  | 7437/10000 [00:32<00:11, 228.17it/s]Running 10000 simulations.:  75%|███████▍  | 7461/10000 [00:32<00:11, 229.29it/s]Running 10000 simulations.:  75%|███████▍  | 7484/10000 [00:32<00:10, 229.23it/s]Running 10000 simulations.:  75%|███████▌  | 7507/10000 [00:32<00:10, 228.83it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:32<00:10, 228.95it/s]Running 10000 simulations.:  76%|███████▌  | 7553/10000 [00:32<00:10, 229.09it/s]Running 10000 simulations.:  76%|███████▌  | 7576/10000 [00:32<00:10, 229.13it/s]Running 10000 simulations.:  76%|███████▌  | 7599/10000 [00:32<00:10, 228.69it/s]Running 10000 simulations.:  76%|███████▌  | 7623/10000 [00:32<00:10, 229.64it/s]Running 10000 simulations.:  76%|███████▋  | 7647/10000 [00:33<00:10, 229.92it/s]Running 10000 simulations.:  77%|███████▋  | 7671/10000 [00:33<00:10, 230.08it/s]Running 10000 simulations.:  77%|███████▋  | 7695/10000 [00:33<00:10, 229.30it/s]Running 10000 simulations.:  77%|███████▋  | 7718/10000 [00:33<00:09, 229.49it/s]Running 10000 simulations.:  77%|███████▋  | 7741/10000 [00:33<00:09, 229.54it/s]Running 10000 simulations.:  78%|███████▊  | 7765/10000 [00:33<00:09, 230.08it/s]Running 10000 simulations.:  78%|███████▊  | 7789/10000 [00:33<00:09, 230.18it/s]Running 10000 simulations.:  78%|███████▊  | 7813/10000 [00:33<00:09, 229.37it/s]Running 10000 simulations.:  78%|███████▊  | 7836/10000 [00:33<00:09, 229.02it/s]Running 10000 simulations.:  79%|███████▊  | 7859/10000 [00:34<00:09, 228.87it/s]Running 10000 simulations.:  79%|███████▉  | 7882/10000 [00:34<00:09, 229.07it/s]Running 10000 simulations.:  79%|███████▉  | 7906/10000 [00:34<00:09, 229.98it/s]Running 10000 simulations.:  79%|███████▉  | 7929/10000 [00:34<00:09, 229.09it/s]Running 10000 simulations.:  80%|███████▉  | 7953/10000 [00:34<00:08, 229.66it/s]Running 10000 simulations.:  80%|███████▉  | 7977/10000 [00:34<00:08, 230.42it/s]Running 10000 simulations.:  80%|████████  | 8001/10000 [00:34<00:08, 230.93it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:34<00:08, 231.07it/s]Running 10000 simulations.:  80%|████████  | 8049/10000 [00:34<00:08, 231.60it/s]Running 10000 simulations.:  81%|████████  | 8073/10000 [00:34<00:08, 231.64it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:35<00:08, 231.51it/s]Running 10000 simulations.:  81%|████████  | 8121/10000 [00:35<00:08, 229.97it/s]Running 10000 simulations.:  81%|████████▏ | 8144/10000 [00:35<00:08, 229.20it/s]Running 10000 simulations.:  82%|████████▏ | 8168/10000 [00:35<00:07, 229.96it/s]Running 10000 simulations.:  82%|████████▏ | 8192/10000 [00:35<00:07, 230.81it/s]Running 10000 simulations.:  82%|████████▏ | 8216/10000 [00:35<00:07, 228.54it/s]Running 10000 simulations.:  82%|████████▏ | 8239/10000 [00:35<00:07, 228.30it/s]Running 10000 simulations.:  83%|████████▎ | 8263/10000 [00:35<00:07, 229.40it/s]Running 10000 simulations.:  83%|████████▎ | 8287/10000 [00:35<00:07, 230.15it/s]Running 10000 simulations.:  83%|████████▎ | 8311/10000 [00:35<00:07, 230.13it/s]Running 10000 simulations.:  83%|████████▎ | 8335/10000 [00:36<00:07, 229.80it/s]Running 10000 simulations.:  84%|████████▎ | 8358/10000 [00:36<00:07, 228.60it/s]Running 10000 simulations.:  84%|████████▍ | 8382/10000 [00:36<00:07, 229.04it/s]Running 10000 simulations.:  84%|████████▍ | 8405/10000 [00:36<00:06, 229.06it/s]Running 10000 simulations.:  84%|████████▍ | 8429/10000 [00:36<00:06, 229.39it/s]Running 10000 simulations.:  85%|████████▍ | 8453/10000 [00:36<00:06, 229.95it/s]Running 10000 simulations.:  85%|████████▍ | 8476/10000 [00:36<00:06, 229.87it/s]Running 10000 simulations.:  85%|████████▌ | 8500/10000 [00:36<00:06, 230.06it/s]Running 10000 simulations.:  85%|████████▌ | 8524/10000 [00:36<00:06, 230.66it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:36<00:06, 231.00it/s]Running 10000 simulations.:  86%|████████▌ | 8572/10000 [00:37<00:06, 230.15it/s]Running 10000 simulations.:  86%|████████▌ | 8596/10000 [00:37<00:06, 229.73it/s]Running 10000 simulations.:  86%|████████▌ | 8619/10000 [00:37<00:06, 229.55it/s]Running 10000 simulations.:  86%|████████▋ | 8642/10000 [00:37<00:05, 229.40it/s]Running 10000 simulations.:  87%|████████▋ | 8665/10000 [00:37<00:05, 229.56it/s]Running 10000 simulations.:  87%|████████▋ | 8688/10000 [00:37<00:05, 229.46it/s]Running 10000 simulations.:  87%|████████▋ | 8712/10000 [00:37<00:05, 229.86it/s]Running 10000 simulations.:  87%|████████▋ | 8735/10000 [00:37<00:05, 229.82it/s]Running 10000 simulations.:  88%|████████▊ | 8758/10000 [00:37<00:05, 229.39it/s]Running 10000 simulations.:  88%|████████▊ | 8781/10000 [00:38<00:05, 229.50it/s]Running 10000 simulations.:  88%|████████▊ | 8804/10000 [00:38<00:05, 229.10it/s]Running 10000 simulations.:  88%|████████▊ | 8827/10000 [00:38<00:05, 228.27it/s]Running 10000 simulations.:  88%|████████▊ | 8850/10000 [00:38<00:05, 227.00it/s]Running 10000 simulations.:  89%|████████▊ | 8873/10000 [00:38<00:04, 227.76it/s]Running 10000 simulations.:  89%|████████▉ | 8897/10000 [00:38<00:04, 228.56it/s]Running 10000 simulations.:  89%|████████▉ | 8920/10000 [00:38<00:04, 228.60it/s]Running 10000 simulations.:  89%|████████▉ | 8944/10000 [00:38<00:04, 229.12it/s]Running 10000 simulations.:  90%|████████▉ | 8968/10000 [00:38<00:04, 229.73it/s]Running 10000 simulations.:  90%|████████▉ | 8992/10000 [00:38<00:04, 230.24it/s]Running 10000 simulations.:  90%|█████████ | 9016/10000 [00:39<00:04, 230.58it/s]Running 10000 simulations.:  90%|█████████ | 9040/10000 [00:39<00:04, 229.86it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [00:39<00:04, 229.52it/s]Running 10000 simulations.:  91%|█████████ | 9087/10000 [00:39<00:03, 229.79it/s]Running 10000 simulations.:  91%|█████████ | 9110/10000 [00:39<00:03, 229.63it/s]Running 10000 simulations.:  91%|█████████▏| 9133/10000 [00:39<00:03, 229.28it/s]Running 10000 simulations.:  92%|█████████▏| 9156/10000 [00:39<00:03, 229.26it/s]Running 10000 simulations.:  92%|█████████▏| 9180/10000 [00:39<00:03, 229.71it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [00:39<00:03, 229.50it/s]Running 10000 simulations.:  92%|█████████▏| 9226/10000 [00:39<00:03, 228.93it/s]Running 10000 simulations.:  92%|█████████▏| 9249/10000 [00:40<00:03, 228.03it/s]Running 10000 simulations.:  93%|█████████▎| 9272/10000 [00:40<00:03, 228.36it/s]Running 10000 simulations.:  93%|█████████▎| 9295/10000 [00:40<00:03, 228.80it/s]Running 10000 simulations.:  93%|█████████▎| 9319/10000 [00:40<00:02, 229.50it/s]Running 10000 simulations.:  93%|█████████▎| 9343/10000 [00:40<00:02, 230.34it/s]Running 10000 simulations.:  94%|█████████▎| 9367/10000 [00:40<00:02, 229.88it/s]Running 10000 simulations.:  94%|█████████▍| 9391/10000 [00:40<00:02, 229.97it/s]Running 10000 simulations.:  94%|█████████▍| 9414/10000 [00:40<00:02, 229.88it/s]Running 10000 simulations.:  94%|█████████▍| 9437/10000 [00:40<00:02, 229.47it/s]Running 10000 simulations.:  95%|█████████▍| 9460/10000 [00:40<00:02, 229.40it/s]Running 10000 simulations.:  95%|█████████▍| 9484/10000 [00:41<00:02, 229.79it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [00:41<00:02, 230.31it/s]Running 10000 simulations.:  95%|█████████▌| 9532/10000 [00:41<00:02, 230.13it/s]Running 10000 simulations.:  96%|█████████▌| 9556/10000 [00:41<00:01, 229.24it/s]Running 10000 simulations.:  96%|█████████▌| 9579/10000 [00:41<00:01, 229.03it/s]Running 10000 simulations.:  96%|█████████▌| 9602/10000 [00:41<00:01, 229.08it/s]Running 10000 simulations.:  96%|█████████▋| 9625/10000 [00:41<00:01, 229.04it/s]Running 10000 simulations.:  96%|█████████▋| 9648/10000 [00:41<00:01, 228.85it/s]Running 10000 simulations.:  97%|█████████▋| 9672/10000 [00:41<00:01, 229.20it/s]Running 10000 simulations.:  97%|█████████▋| 9696/10000 [00:42<00:01, 229.71it/s]Running 10000 simulations.:  97%|█████████▋| 9719/10000 [00:42<00:01, 229.66it/s]Running 10000 simulations.:  97%|█████████▋| 9742/10000 [00:42<00:01, 229.47it/s]Running 10000 simulations.:  98%|█████████▊| 9766/10000 [00:42<00:01, 229.98it/s]Running 10000 simulations.:  98%|█████████▊| 9789/10000 [00:42<00:00, 229.97it/s]Running 10000 simulations.:  98%|█████████▊| 9813/10000 [00:42<00:00, 230.17it/s]Running 10000 simulations.:  98%|█████████▊| 9837/10000 [00:42<00:00, 229.99it/s]Running 10000 simulations.:  99%|█████████▊| 9860/10000 [00:42<00:00, 228.53it/s]Running 10000 simulations.:  99%|█████████▉| 9884/10000 [00:42<00:00, 229.42it/s]Running 10000 simulations.:  99%|█████████▉| 9907/10000 [00:42<00:00, 228.42it/s]Running 10000 simulations.:  99%|█████████▉| 9931/10000 [00:43<00:00, 229.14it/s]Running 10000 simulations.: 100%|█████████▉| 9955/10000 [00:43<00:00, 230.76it/s]Running 10000 simulations.: 100%|█████████▉| 9979/10000 [00:43<00:00, 232.03it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:43<00:00, 230.84it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 253.74it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<00:39, 252.31it/s]Running 10000 simulations.:   1%|          | 76/10000 [00:00<00:39, 250.68it/s]Running 10000 simulations.:   1%|          | 101/10000 [00:00<00:39, 249.78it/s]Running 10000 simulations.:   1%|▏         | 126/10000 [00:00<00:39, 248.31it/s]Running 10000 simulations.:   2%|▏         | 151/10000 [00:00<00:39, 246.62it/s]Running 10000 simulations.:   2%|▏         | 176/10000 [00:00<00:39, 245.90it/s]Running 10000 simulations.:   2%|▏         | 201/10000 [00:00<00:39, 245.49it/s]Running 10000 simulations.:   2%|▏         | 226/10000 [00:00<00:39, 245.44it/s]Running 10000 simulations.:   3%|▎         | 251/10000 [00:01<00:39, 244.98it/s]Running 10000 simulations.:   3%|▎         | 276/10000 [00:01<00:39, 244.64it/s]Running 10000 simulations.:   3%|▎         | 301/10000 [00:01<00:39, 245.22it/s]Running 10000 simulations.:   3%|▎         | 326/10000 [00:01<00:39, 245.40it/s]Running 10000 simulations.:   4%|▎         | 351/10000 [00:01<00:39, 245.89it/s]Running 10000 simulations.:   4%|▍         | 376/10000 [00:01<00:39, 246.48it/s]Running 10000 simulations.:   4%|▍         | 401/10000 [00:01<00:38, 246.49it/s]Running 10000 simulations.:   4%|▍         | 426/10000 [00:01<00:38, 246.59it/s]Running 10000 simulations.:   5%|▍         | 451/10000 [00:01<00:38, 246.30it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:01<00:38, 245.42it/s]Running 10000 simulations.:   5%|▌         | 501/10000 [00:02<00:38, 245.01it/s]Running 10000 simulations.:   5%|▌         | 526/10000 [00:02<00:38, 245.11it/s]Running 10000 simulations.:   6%|▌         | 551/10000 [00:02<00:38, 244.71it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:02<00:38, 245.20it/s]Running 10000 simulations.:   6%|▌         | 601/10000 [00:02<00:38, 244.86it/s]Running 10000 simulations.:   6%|▋         | 626/10000 [00:02<00:38, 244.97it/s]Running 10000 simulations.:   7%|▋         | 651/10000 [00:02<00:38, 244.52it/s]Running 10000 simulations.:   7%|▋         | 676/10000 [00:02<00:38, 244.33it/s]Running 10000 simulations.:   7%|▋         | 701/10000 [00:02<00:38, 243.16it/s]Running 10000 simulations.:   7%|▋         | 726/10000 [00:02<00:38, 243.17it/s]Running 10000 simulations.:   8%|▊         | 751/10000 [00:03<00:38, 243.20it/s]Running 10000 simulations.:   8%|▊         | 776/10000 [00:03<00:37, 243.44it/s]Running 10000 simulations.:   8%|▊         | 801/10000 [00:03<00:37, 243.15it/s]Running 10000 simulations.:   8%|▊         | 826/10000 [00:03<00:37, 243.14it/s]Running 10000 simulations.:   9%|▊         | 851/10000 [00:03<00:37, 243.62it/s]Running 10000 simulations.:   9%|▉         | 876/10000 [00:03<00:37, 243.87it/s]Running 10000 simulations.:   9%|▉         | 901/10000 [00:03<00:37, 243.26it/s]Running 10000 simulations.:   9%|▉         | 926/10000 [00:03<00:37, 243.55it/s]Running 10000 simulations.:  10%|▉         | 951/10000 [00:03<00:37, 243.64it/s]Running 10000 simulations.:  10%|▉         | 976/10000 [00:03<00:37, 243.52it/s]Running 10000 simulations.:  10%|█         | 1001/10000 [00:04<00:37, 243.12it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:04<00:36, 243.01it/s]Running 10000 simulations.:  11%|█         | 1051/10000 [00:04<00:36, 243.11it/s]Running 10000 simulations.:  11%|█         | 1076/10000 [00:04<00:36, 243.39it/s]Running 10000 simulations.:  11%|█         | 1101/10000 [00:04<00:36, 243.37it/s]Running 10000 simulations.:  11%|█▏        | 1126/10000 [00:04<00:36, 240.69it/s]Running 10000 simulations.:  12%|█▏        | 1151/10000 [00:04<00:36, 240.93it/s]Running 10000 simulations.:  12%|█▏        | 1176/10000 [00:04<00:36, 241.04it/s]Running 10000 simulations.:  12%|█▏        | 1201/10000 [00:04<00:36, 241.05it/s]Running 10000 simulations.:  12%|█▏        | 1226/10000 [00:05<00:36, 241.55it/s]Running 10000 simulations.:  13%|█▎        | 1251/10000 [00:05<00:36, 241.36it/s]Running 10000 simulations.:  13%|█▎        | 1276/10000 [00:05<00:36, 241.59it/s]Running 10000 simulations.:  13%|█▎        | 1301/10000 [00:05<00:35, 241.83it/s]Running 10000 simulations.:  13%|█▎        | 1326/10000 [00:05<00:35, 241.82it/s]Running 10000 simulations.:  14%|█▎        | 1351/10000 [00:05<00:35, 241.81it/s]Running 10000 simulations.:  14%|█▍        | 1376/10000 [00:05<00:35, 241.91it/s]Running 10000 simulations.:  14%|█▍        | 1401/10000 [00:05<00:35, 241.81it/s]Running 10000 simulations.:  14%|█▍        | 1426/10000 [00:05<00:35, 242.17it/s]Running 10000 simulations.:  15%|█▍        | 1451/10000 [00:05<00:35, 242.28it/s]Running 10000 simulations.:  15%|█▍        | 1476/10000 [00:06<00:35, 242.34it/s]Running 10000 simulations.:  15%|█▌        | 1501/10000 [00:06<00:35, 242.14it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:06<00:35, 241.99it/s]Running 10000 simulations.:  16%|█▌        | 1551/10000 [00:06<00:34, 242.09it/s]Running 10000 simulations.:  16%|█▌        | 1576/10000 [00:06<00:34, 241.85it/s]Running 10000 simulations.:  16%|█▌        | 1601/10000 [00:06<00:34, 241.64it/s]Running 10000 simulations.:  16%|█▋        | 1626/10000 [00:06<00:34, 241.66it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:06<00:34, 241.98it/s]Running 10000 simulations.:  17%|█▋        | 1676/10000 [00:06<00:34, 241.94it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:06<00:34, 241.60it/s]Running 10000 simulations.:  17%|█▋        | 1726/10000 [00:07<00:34, 241.44it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:07<00:34, 241.08it/s]Running 10000 simulations.:  18%|█▊        | 1776/10000 [00:07<00:34, 239.82it/s]Running 10000 simulations.:  18%|█▊        | 1801/10000 [00:07<00:34, 240.06it/s]Running 10000 simulations.:  18%|█▊        | 1826/10000 [00:07<00:34, 239.40it/s]Running 10000 simulations.:  18%|█▊        | 1850/10000 [00:07<00:34, 239.00it/s]Running 10000 simulations.:  19%|█▉        | 1875/10000 [00:07<00:33, 239.62it/s]Running 10000 simulations.:  19%|█▉        | 1899/10000 [00:07<00:33, 239.12it/s]Running 10000 simulations.:  19%|█▉        | 1923/10000 [00:07<00:33, 238.80it/s]Running 10000 simulations.:  19%|█▉        | 1947/10000 [00:08<00:33, 238.78it/s]Running 10000 simulations.:  20%|█▉        | 1971/10000 [00:08<00:33, 238.84it/s]Running 10000 simulations.:  20%|█▉        | 1995/10000 [00:08<00:33, 238.70it/s]Running 10000 simulations.:  20%|██        | 2019/10000 [00:08<00:33, 238.42it/s]Running 10000 simulations.:  20%|██        | 2043/10000 [00:08<00:33, 238.37it/s]Running 10000 simulations.:  21%|██        | 2067/10000 [00:08<00:33, 238.20it/s]Running 10000 simulations.:  21%|██        | 2091/10000 [00:08<00:33, 238.20it/s]Running 10000 simulations.:  21%|██        | 2115/10000 [00:08<00:33, 238.10it/s]Running 10000 simulations.:  21%|██▏       | 2139/10000 [00:08<00:33, 237.92it/s]Running 10000 simulations.:  22%|██▏       | 2163/10000 [00:08<00:32, 237.58it/s]Running 10000 simulations.:  22%|██▏       | 2187/10000 [00:09<00:32, 237.75it/s]Running 10000 simulations.:  22%|██▏       | 2211/10000 [00:09<00:32, 238.13it/s]Running 10000 simulations.:  22%|██▏       | 2235/10000 [00:09<00:32, 238.22it/s]Running 10000 simulations.:  23%|██▎       | 2259/10000 [00:09<00:32, 238.27it/s]Running 10000 simulations.:  23%|██▎       | 2283/10000 [00:09<00:32, 238.77it/s]Running 10000 simulations.:  23%|██▎       | 2307/10000 [00:09<00:32, 239.09it/s]Running 10000 simulations.:  23%|██▎       | 2331/10000 [00:09<00:32, 239.04it/s]Running 10000 simulations.:  24%|██▎       | 2356/10000 [00:09<00:31, 239.46it/s]Running 10000 simulations.:  24%|██▍       | 2380/10000 [00:09<00:31, 239.23it/s]Running 10000 simulations.:  24%|██▍       | 2405/10000 [00:09<00:31, 239.58it/s]Running 10000 simulations.:  24%|██▍       | 2429/10000 [00:10<00:31, 237.33it/s]Running 10000 simulations.:  25%|██▍       | 2453/10000 [00:10<00:44, 169.32it/s]Running 10000 simulations.:  25%|██▍       | 2477/10000 [00:10<00:40, 185.12it/s]Running 10000 simulations.:  25%|██▌       | 2501/10000 [00:10<00:37, 198.31it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:10<00:35, 208.42it/s]Running 10000 simulations.:  25%|██▌       | 2549/10000 [00:10<00:34, 216.33it/s]Running 10000 simulations.:  26%|██▌       | 2573/10000 [00:10<00:33, 222.20it/s]Running 10000 simulations.:  26%|██▌       | 2597/10000 [00:10<00:32, 226.48it/s]Running 10000 simulations.:  26%|██▌       | 2621/10000 [00:10<00:32, 229.49it/s]Running 10000 simulations.:  26%|██▋       | 2645/10000 [00:11<00:31, 232.27it/s]Running 10000 simulations.:  27%|██▋       | 2669/10000 [00:11<00:31, 234.23it/s]Running 10000 simulations.:  27%|██▋       | 2693/10000 [00:11<00:30, 235.80it/s]Running 10000 simulations.:  27%|██▋       | 2717/10000 [00:11<00:30, 236.99it/s]Running 10000 simulations.:  27%|██▋       | 2741/10000 [00:11<00:30, 236.85it/s]Running 10000 simulations.:  28%|██▊       | 2765/10000 [00:11<00:30, 236.04it/s]Running 10000 simulations.:  28%|██▊       | 2789/10000 [00:11<00:30, 235.42it/s]Running 10000 simulations.:  28%|██▊       | 2813/10000 [00:11<00:30, 235.31it/s]Running 10000 simulations.:  28%|██▊       | 2837/10000 [00:11<00:30, 235.59it/s]Running 10000 simulations.:  29%|██▊       | 2861/10000 [00:11<00:30, 235.37it/s]Running 10000 simulations.:  29%|██▉       | 2885/10000 [00:12<00:30, 235.44it/s]Running 10000 simulations.:  29%|██▉       | 2909/10000 [00:12<00:30, 235.94it/s]Running 10000 simulations.:  29%|██▉       | 2934/10000 [00:12<00:29, 238.00it/s]Running 10000 simulations.:  30%|██▉       | 2959/10000 [00:12<00:29, 239.42it/s]Running 10000 simulations.:  30%|██▉       | 2984/10000 [00:12<00:29, 240.47it/s]Running 10000 simulations.:  30%|███       | 3009/10000 [00:12<00:29, 240.91it/s]Running 10000 simulations.:  30%|███       | 3034/10000 [00:12<00:28, 241.25it/s]Running 10000 simulations.:  31%|███       | 3059/10000 [00:12<00:28, 241.53it/s]Running 10000 simulations.:  31%|███       | 3084/10000 [00:12<00:29, 233.84it/s]Running 10000 simulations.:  31%|███       | 3109/10000 [00:13<00:29, 236.28it/s]Running 10000 simulations.:  31%|███▏      | 3134/10000 [00:13<00:28, 238.26it/s]Running 10000 simulations.:  32%|███▏      | 3159/10000 [00:13<00:28, 239.17it/s]Running 10000 simulations.:  32%|███▏      | 3184/10000 [00:13<00:28, 239.89it/s]Running 10000 simulations.:  32%|███▏      | 3209/10000 [00:13<00:28, 240.78it/s]Running 10000 simulations.:  32%|███▏      | 3234/10000 [00:13<00:28, 241.53it/s]Running 10000 simulations.:  33%|███▎      | 3259/10000 [00:13<00:27, 241.85it/s]Running 10000 simulations.:  33%|███▎      | 3284/10000 [00:13<00:27, 242.21it/s]Running 10000 simulations.:  33%|███▎      | 3309/10000 [00:13<00:27, 242.28it/s]Running 10000 simulations.:  33%|███▎      | 3334/10000 [00:13<00:27, 242.20it/s]Running 10000 simulations.:  34%|███▎      | 3359/10000 [00:14<00:27, 243.02it/s]Running 10000 simulations.:  34%|███▍      | 3384/10000 [00:14<00:27, 243.22it/s]Running 10000 simulations.:  34%|███▍      | 3409/10000 [00:14<00:27, 242.24it/s]Running 10000 simulations.:  34%|███▍      | 3434/10000 [00:14<00:27, 241.67it/s]Running 10000 simulations.:  35%|███▍      | 3459/10000 [00:14<00:27, 241.18it/s]Running 10000 simulations.:  35%|███▍      | 3484/10000 [00:14<00:27, 241.10it/s]Running 10000 simulations.:  35%|███▌      | 3509/10000 [00:14<00:26, 240.63it/s]Running 10000 simulations.:  35%|███▌      | 3534/10000 [00:14<00:26, 240.49it/s]Running 10000 simulations.:  36%|███▌      | 3559/10000 [00:14<00:26, 238.61it/s]Running 10000 simulations.:  36%|███▌      | 3583/10000 [00:14<00:26, 238.10it/s]Running 10000 simulations.:  36%|███▌      | 3608/10000 [00:15<00:26, 238.74it/s]Running 10000 simulations.:  36%|███▋      | 3633/10000 [00:15<00:26, 239.24it/s]Running 10000 simulations.:  37%|███▋      | 3658/10000 [00:15<00:26, 239.63it/s]Running 10000 simulations.:  37%|███▋      | 3682/10000 [00:15<00:26, 239.71it/s]Running 10000 simulations.:  37%|███▋      | 3707/10000 [00:15<00:26, 240.55it/s]Running 10000 simulations.:  37%|███▋      | 3732/10000 [00:15<00:26, 240.35it/s]Running 10000 simulations.:  38%|███▊      | 3757/10000 [00:15<00:25, 240.77it/s]Running 10000 simulations.:  38%|███▊      | 3782/10000 [00:15<00:25, 241.04it/s]Running 10000 simulations.:  38%|███▊      | 3807/10000 [00:15<00:25, 240.72it/s]Running 10000 simulations.:  38%|███▊      | 3832/10000 [00:16<00:25, 240.73it/s]Running 10000 simulations.:  39%|███▊      | 3857/10000 [00:16<00:25, 240.52it/s]Running 10000 simulations.:  39%|███▉      | 3882/10000 [00:16<00:25, 239.26it/s]Running 10000 simulations.:  39%|███▉      | 3906/10000 [00:16<00:25, 237.77it/s]Running 10000 simulations.:  39%|███▉      | 3931/10000 [00:16<00:25, 238.96it/s]Running 10000 simulations.:  40%|███▉      | 3956/10000 [00:16<00:25, 239.64it/s]Running 10000 simulations.:  40%|███▉      | 3981/10000 [00:16<00:25, 239.94it/s]Running 10000 simulations.:  40%|████      | 4005/10000 [00:16<00:25, 239.56it/s]Running 10000 simulations.:  40%|████      | 4030/10000 [00:16<00:24, 239.93it/s]Running 10000 simulations.:  41%|████      | 4054/10000 [00:16<00:24, 239.58it/s]Running 10000 simulations.:  41%|████      | 4079/10000 [00:17<00:24, 239.84it/s]Running 10000 simulations.:  41%|████      | 4104/10000 [00:17<00:24, 240.37it/s]Running 10000 simulations.:  41%|████▏     | 4129/10000 [00:17<00:24, 240.37it/s]Running 10000 simulations.:  42%|████▏     | 4154/10000 [00:17<00:24, 239.97it/s]Running 10000 simulations.:  42%|████▏     | 4178/10000 [00:17<00:24, 239.49it/s]Running 10000 simulations.:  42%|████▏     | 4202/10000 [00:17<00:24, 239.43it/s]Running 10000 simulations.:  42%|████▏     | 4227/10000 [00:17<00:24, 239.83it/s]Running 10000 simulations.:  43%|████▎     | 4252/10000 [00:17<00:23, 239.95it/s]Running 10000 simulations.:  43%|████▎     | 4276/10000 [00:17<00:23, 239.85it/s]Running 10000 simulations.:  43%|████▎     | 4300/10000 [00:17<00:23, 239.58it/s]Running 10000 simulations.:  43%|████▎     | 4324/10000 [00:18<00:23, 239.54it/s]Running 10000 simulations.:  43%|████▎     | 4348/10000 [00:18<00:23, 239.31it/s]Running 10000 simulations.:  44%|████▎     | 4372/10000 [00:18<00:23, 239.40it/s]Running 10000 simulations.:  44%|████▍     | 4396/10000 [00:18<00:23, 239.15it/s]Running 10000 simulations.:  44%|████▍     | 4420/10000 [00:18<00:23, 239.06it/s]Running 10000 simulations.:  44%|████▍     | 4445/10000 [00:18<00:23, 239.69it/s]Running 10000 simulations.:  45%|████▍     | 4470/10000 [00:18<00:23, 240.28it/s]Running 10000 simulations.:  45%|████▍     | 4495/10000 [00:18<00:22, 240.69it/s]Running 10000 simulations.:  45%|████▌     | 4520/10000 [00:18<00:22, 240.28it/s]Running 10000 simulations.:  45%|████▌     | 4545/10000 [00:19<00:22, 240.52it/s]Running 10000 simulations.:  46%|████▌     | 4570/10000 [00:19<00:22, 240.38it/s]Running 10000 simulations.:  46%|████▌     | 4595/10000 [00:19<00:22, 240.49it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:19<00:22, 240.31it/s]Running 10000 simulations.:  46%|████▋     | 4645/10000 [00:19<00:22, 240.71it/s]Running 10000 simulations.:  47%|████▋     | 4670/10000 [00:19<00:22, 240.61it/s]Running 10000 simulations.:  47%|████▋     | 4695/10000 [00:19<00:22, 240.68it/s]Running 10000 simulations.:  47%|████▋     | 4720/10000 [00:19<00:21, 240.40it/s]Running 10000 simulations.:  47%|████▋     | 4745/10000 [00:19<00:21, 240.30it/s]Running 10000 simulations.:  48%|████▊     | 4770/10000 [00:19<00:21, 240.53it/s]Running 10000 simulations.:  48%|████▊     | 4795/10000 [00:20<00:21, 240.46it/s]Running 10000 simulations.:  48%|████▊     | 4820/10000 [00:20<00:21, 240.25it/s]Running 10000 simulations.:  48%|████▊     | 4845/10000 [00:20<00:21, 240.67it/s]Running 10000 simulations.:  49%|████▊     | 4870/10000 [00:20<00:21, 240.38it/s]Running 10000 simulations.:  49%|████▉     | 4895/10000 [00:20<00:21, 240.07it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:20<00:21, 239.99it/s]Running 10000 simulations.:  49%|████▉     | 4944/10000 [00:20<00:21, 237.82it/s]Running 10000 simulations.:  50%|████▉     | 4969/10000 [00:20<00:21, 238.66it/s]Running 10000 simulations.:  50%|████▉     | 4993/10000 [00:20<00:21, 238.34it/s]Running 10000 simulations.:  50%|█████     | 5017/10000 [00:20<00:20, 238.49it/s]Running 10000 simulations.:  50%|█████     | 5041/10000 [00:21<00:20, 238.24it/s]Running 10000 simulations.:  51%|█████     | 5065/10000 [00:21<00:20, 238.03it/s]Running 10000 simulations.:  51%|█████     | 5090/10000 [00:21<00:20, 238.68it/s]Running 10000 simulations.:  51%|█████     | 5114/10000 [00:21<00:20, 238.86it/s]Running 10000 simulations.:  51%|█████▏    | 5138/10000 [00:21<00:20, 238.71it/s]Running 10000 simulations.:  52%|█████▏    | 5162/10000 [00:21<00:20, 239.01it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:21<00:20, 238.65it/s]Running 10000 simulations.:  52%|█████▏    | 5210/10000 [00:21<00:20, 237.99it/s]Running 10000 simulations.:  52%|█████▏    | 5234/10000 [00:21<00:20, 238.23it/s]Running 10000 simulations.:  53%|█████▎    | 5259/10000 [00:21<00:19, 238.91it/s]Running 10000 simulations.:  53%|█████▎    | 5283/10000 [00:22<00:19, 239.03it/s]Running 10000 simulations.:  53%|█████▎    | 5307/10000 [00:22<00:19, 239.27it/s]Running 10000 simulations.:  53%|█████▎    | 5331/10000 [00:22<00:19, 239.02it/s]Running 10000 simulations.:  54%|█████▎    | 5355/10000 [00:22<00:19, 239.14it/s]Running 10000 simulations.:  54%|█████▍    | 5379/10000 [00:22<00:19, 239.28it/s]Running 10000 simulations.:  54%|█████▍    | 5403/10000 [00:22<00:19, 239.18it/s]Running 10000 simulations.:  54%|█████▍    | 5427/10000 [00:22<00:19, 239.03it/s]Running 10000 simulations.:  55%|█████▍    | 5451/10000 [00:22<00:19, 238.58it/s]Running 10000 simulations.:  55%|█████▍    | 5475/10000 [00:22<00:18, 238.71it/s]Running 10000 simulations.:  55%|█████▍    | 5499/10000 [00:22<00:18, 238.78it/s]Running 10000 simulations.:  55%|█████▌    | 5523/10000 [00:23<00:18, 238.35it/s]Running 10000 simulations.:  55%|█████▌    | 5547/10000 [00:23<00:18, 238.79it/s]Running 10000 simulations.:  56%|█████▌    | 5571/10000 [00:23<00:18, 238.00it/s]Running 10000 simulations.:  56%|█████▌    | 5595/10000 [00:23<00:18, 238.37it/s]Running 10000 simulations.:  56%|█████▌    | 5619/10000 [00:23<00:18, 238.42it/s]Running 10000 simulations.:  56%|█████▋    | 5643/10000 [00:23<00:18, 238.41it/s]Running 10000 simulations.:  57%|█████▋    | 5667/10000 [00:23<00:18, 238.64it/s]Running 10000 simulations.:  57%|█████▋    | 5691/10000 [00:23<00:18, 237.97it/s]Running 10000 simulations.:  57%|█████▋    | 5715/10000 [00:23<00:17, 238.14it/s]Running 10000 simulations.:  57%|█████▋    | 5739/10000 [00:24<00:17, 237.25it/s]Running 10000 simulations.:  58%|█████▊    | 5763/10000 [00:24<00:18, 234.33it/s]Running 10000 simulations.:  58%|█████▊    | 5787/10000 [00:24<00:18, 233.25it/s]Running 10000 simulations.:  58%|█████▊    | 5811/10000 [00:24<00:17, 234.02it/s]Running 10000 simulations.:  58%|█████▊    | 5835/10000 [00:24<00:17, 234.72it/s]Running 10000 simulations.:  59%|█████▊    | 5859/10000 [00:24<00:17, 234.74it/s]Running 10000 simulations.:  59%|█████▉    | 5883/10000 [00:24<00:17, 235.46it/s]Running 10000 simulations.:  59%|█████▉    | 5907/10000 [00:24<00:17, 235.53it/s]Running 10000 simulations.:  59%|█████▉    | 5932/10000 [00:24<00:17, 237.11it/s]Running 10000 simulations.:  60%|█████▉    | 5956/10000 [00:24<00:17, 237.61it/s]Running 10000 simulations.:  60%|█████▉    | 5980/10000 [00:25<00:16, 237.65it/s]Running 10000 simulations.:  60%|██████    | 6004/10000 [00:25<00:16, 237.44it/s]Running 10000 simulations.:  60%|██████    | 6028/10000 [00:25<00:16, 237.73it/s]Running 10000 simulations.:  61%|██████    | 6053/10000 [00:25<00:16, 238.63it/s]Running 10000 simulations.:  61%|██████    | 6077/10000 [00:25<00:16, 238.92it/s]Running 10000 simulations.:  61%|██████    | 6101/10000 [00:25<00:16, 238.87it/s]Running 10000 simulations.:  61%|██████▏   | 6126/10000 [00:25<00:16, 239.21it/s]Running 10000 simulations.:  62%|██████▏   | 6150/10000 [00:25<00:16, 239.41it/s]Running 10000 simulations.:  62%|██████▏   | 6175/10000 [00:25<00:15, 239.67it/s]Running 10000 simulations.:  62%|██████▏   | 6199/10000 [00:25<00:15, 239.43it/s]Running 10000 simulations.:  62%|██████▏   | 6223/10000 [00:26<00:15, 239.09it/s]Running 10000 simulations.:  62%|██████▏   | 6248/10000 [00:26<00:15, 239.49it/s]Running 10000 simulations.:  63%|██████▎   | 6272/10000 [00:26<00:15, 239.58it/s]Running 10000 simulations.:  63%|██████▎   | 6297/10000 [00:26<00:15, 239.76it/s]Running 10000 simulations.:  63%|██████▎   | 6322/10000 [00:26<00:15, 240.04it/s]Running 10000 simulations.:  63%|██████▎   | 6347/10000 [00:26<00:15, 239.80it/s]Running 10000 simulations.:  64%|██████▎   | 6372/10000 [00:26<00:15, 239.99it/s]Running 10000 simulations.:  64%|██████▍   | 6396/10000 [00:26<00:15, 239.94it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:26<00:14, 239.63it/s]Running 10000 simulations.:  64%|██████▍   | 6445/10000 [00:26<00:14, 240.06it/s]Running 10000 simulations.:  65%|██████▍   | 6470/10000 [00:27<00:14, 239.99it/s]Running 10000 simulations.:  65%|██████▍   | 6495/10000 [00:27<00:14, 240.35it/s]Running 10000 simulations.:  65%|██████▌   | 6520/10000 [00:27<00:14, 240.07it/s]Running 10000 simulations.:  65%|██████▌   | 6545/10000 [00:27<00:14, 239.94it/s]Running 10000 simulations.:  66%|██████▌   | 6570/10000 [00:27<00:14, 240.00it/s]Running 10000 simulations.:  66%|██████▌   | 6595/10000 [00:27<00:14, 239.84it/s]Running 10000 simulations.:  66%|██████▌   | 6620/10000 [00:27<00:14, 240.04it/s]Running 10000 simulations.:  66%|██████▋   | 6645/10000 [00:27<00:13, 240.25it/s]Running 10000 simulations.:  67%|██████▋   | 6670/10000 [00:27<00:13, 240.64it/s]Running 10000 simulations.:  67%|██████▋   | 6695/10000 [00:28<00:13, 240.50it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:28<00:13, 240.11it/s]Running 10000 simulations.:  67%|██████▋   | 6745/10000 [00:28<00:13, 239.90it/s]Running 10000 simulations.:  68%|██████▊   | 6769/10000 [00:28<00:13, 239.80it/s]Running 10000 simulations.:  68%|██████▊   | 6793/10000 [00:28<00:13, 239.76it/s]Running 10000 simulations.:  68%|██████▊   | 6817/10000 [00:28<00:13, 239.66it/s]Running 10000 simulations.:  68%|██████▊   | 6841/10000 [00:28<00:13, 239.45it/s]Running 10000 simulations.:  69%|██████▊   | 6865/10000 [00:28<00:13, 239.61it/s]Running 10000 simulations.:  69%|██████▉   | 6890/10000 [00:28<00:12, 240.19it/s]Running 10000 simulations.:  69%|██████▉   | 6915/10000 [00:28<00:12, 240.09it/s]Running 10000 simulations.:  69%|██████▉   | 6940/10000 [00:29<00:12, 240.10it/s]Running 10000 simulations.:  70%|██████▉   | 6965/10000 [00:29<00:12, 239.68it/s]Running 10000 simulations.:  70%|██████▉   | 6989/10000 [00:29<00:12, 239.64it/s]Running 10000 simulations.:  70%|███████   | 7013/10000 [00:29<00:12, 239.58it/s]Running 10000 simulations.:  70%|███████   | 7038/10000 [00:29<00:12, 239.69it/s]Running 10000 simulations.:  71%|███████   | 7062/10000 [00:29<00:12, 237.61it/s]Running 10000 simulations.:  71%|███████   | 7086/10000 [00:29<00:12, 237.53it/s]Running 10000 simulations.:  71%|███████   | 7110/10000 [00:29<00:12, 238.19it/s]Running 10000 simulations.:  71%|███████▏  | 7135/10000 [00:29<00:11, 239.06it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:29<00:11, 239.25it/s]Running 10000 simulations.:  72%|███████▏  | 7183/10000 [00:30<00:11, 239.11it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:30<00:11, 239.24it/s]Running 10000 simulations.:  72%|███████▏  | 7231/10000 [00:30<00:11, 238.99it/s]Running 10000 simulations.:  73%|███████▎  | 7255/10000 [00:30<00:11, 239.03it/s]Running 10000 simulations.:  73%|███████▎  | 7279/10000 [00:30<00:11, 239.30it/s]Running 10000 simulations.:  73%|███████▎  | 7303/10000 [00:30<00:11, 239.38it/s]Running 10000 simulations.:  73%|███████▎  | 7328/10000 [00:30<00:11, 239.72it/s]Running 10000 simulations.:  74%|███████▎  | 7352/10000 [00:30<00:11, 239.64it/s]Running 10000 simulations.:  74%|███████▍  | 7376/10000 [00:30<00:10, 239.67it/s]Running 10000 simulations.:  74%|███████▍  | 7400/10000 [00:30<00:10, 239.60it/s]Running 10000 simulations.:  74%|███████▍  | 7425/10000 [00:31<00:10, 239.88it/s]Running 10000 simulations.:  74%|███████▍  | 7450/10000 [00:31<00:10, 240.31it/s]Running 10000 simulations.:  75%|███████▍  | 7475/10000 [00:31<00:10, 240.11it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:31<00:10, 240.26it/s]Running 10000 simulations.:  75%|███████▌  | 7525/10000 [00:31<00:10, 240.68it/s]Running 10000 simulations.:  76%|███████▌  | 7550/10000 [00:31<00:10, 240.97it/s]Running 10000 simulations.:  76%|███████▌  | 7575/10000 [00:31<00:10, 240.89it/s]Running 10000 simulations.:  76%|███████▌  | 7600/10000 [00:31<00:09, 241.59it/s]Running 10000 simulations.:  76%|███████▋  | 7625/10000 [00:31<00:09, 239.87it/s]Running 10000 simulations.:  76%|███████▋  | 7649/10000 [00:31<00:09, 239.38it/s]Running 10000 simulations.:  77%|███████▋  | 7674/10000 [00:32<00:09, 239.66it/s]Running 10000 simulations.:  77%|███████▋  | 7699/10000 [00:32<00:09, 240.14it/s]Running 10000 simulations.:  77%|███████▋  | 7724/10000 [00:32<00:09, 238.06it/s]Running 10000 simulations.:  77%|███████▋  | 7748/10000 [00:32<00:09, 238.52it/s]Running 10000 simulations.:  78%|███████▊  | 7773/10000 [00:32<00:09, 239.50it/s]Running 10000 simulations.:  78%|███████▊  | 7798/10000 [00:32<00:09, 240.24it/s]Running 10000 simulations.:  78%|███████▊  | 7823/10000 [00:32<00:09, 240.72it/s]Running 10000 simulations.:  78%|███████▊  | 7848/10000 [00:32<00:08, 241.08it/s]Running 10000 simulations.:  79%|███████▊  | 7873/10000 [00:32<00:08, 240.86it/s]Running 10000 simulations.:  79%|███████▉  | 7898/10000 [00:33<00:08, 240.88it/s]Running 10000 simulations.:  79%|███████▉  | 7923/10000 [00:33<00:08, 241.04it/s]Running 10000 simulations.:  79%|███████▉  | 7948/10000 [00:33<00:08, 241.13it/s]Running 10000 simulations.:  80%|███████▉  | 7973/10000 [00:33<00:08, 241.27it/s]Running 10000 simulations.:  80%|███████▉  | 7998/10000 [00:33<00:08, 241.18it/s]Running 10000 simulations.:  80%|████████  | 8023/10000 [00:33<00:08, 240.95it/s]Running 10000 simulations.:  80%|████████  | 8048/10000 [00:33<00:08, 241.24it/s]Running 10000 simulations.:  81%|████████  | 8073/10000 [00:33<00:07, 241.42it/s]Running 10000 simulations.:  81%|████████  | 8098/10000 [00:33<00:07, 241.66it/s]Running 10000 simulations.:  81%|████████  | 8123/10000 [00:33<00:07, 241.77it/s]Running 10000 simulations.:  81%|████████▏ | 8148/10000 [00:34<00:07, 241.71it/s]Running 10000 simulations.:  82%|████████▏ | 8173/10000 [00:34<00:07, 241.16it/s]Running 10000 simulations.:  82%|████████▏ | 8198/10000 [00:34<00:07, 241.82it/s]Running 10000 simulations.:  82%|████████▏ | 8223/10000 [00:34<00:07, 241.36it/s]Running 10000 simulations.:  82%|████████▏ | 8248/10000 [00:34<00:07, 241.65it/s]Running 10000 simulations.:  83%|████████▎ | 8273/10000 [00:34<00:07, 241.46it/s]Running 10000 simulations.:  83%|████████▎ | 8298/10000 [00:34<00:07, 241.51it/s]Running 10000 simulations.:  83%|████████▎ | 8323/10000 [00:34<00:06, 241.31it/s]Running 10000 simulations.:  83%|████████▎ | 8348/10000 [00:34<00:06, 240.65it/s]Running 10000 simulations.:  84%|████████▎ | 8373/10000 [00:34<00:06, 240.83it/s]Running 10000 simulations.:  84%|████████▍ | 8398/10000 [00:35<00:06, 240.78it/s]Running 10000 simulations.:  84%|████████▍ | 8423/10000 [00:35<00:06, 240.51it/s]Running 10000 simulations.:  84%|████████▍ | 8448/10000 [00:35<00:06, 240.89it/s]Running 10000 simulations.:  85%|████████▍ | 8473/10000 [00:35<00:06, 240.93it/s]Running 10000 simulations.:  85%|████████▍ | 8498/10000 [00:35<00:06, 240.48it/s]Running 10000 simulations.:  85%|████████▌ | 8523/10000 [00:35<00:06, 240.62it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:35<00:06, 241.06it/s]Running 10000 simulations.:  86%|████████▌ | 8573/10000 [00:35<00:05, 241.46it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [00:35<00:05, 241.45it/s]Running 10000 simulations.:  86%|████████▌ | 8623/10000 [00:36<00:05, 241.54it/s]Running 10000 simulations.:  86%|████████▋ | 8648/10000 [00:36<00:05, 241.58it/s]Running 10000 simulations.:  87%|████████▋ | 8673/10000 [00:36<00:05, 241.67it/s]Running 10000 simulations.:  87%|████████▋ | 8698/10000 [00:36<00:05, 241.39it/s]Running 10000 simulations.:  87%|████████▋ | 8723/10000 [00:36<00:05, 241.36it/s]Running 10000 simulations.:  87%|████████▋ | 8748/10000 [00:36<00:05, 241.62it/s]Running 10000 simulations.:  88%|████████▊ | 8773/10000 [00:36<00:05, 241.87it/s]Running 10000 simulations.:  88%|████████▊ | 8798/10000 [00:36<00:04, 242.06it/s]Running 10000 simulations.:  88%|████████▊ | 8823/10000 [00:36<00:04, 241.89it/s]Running 10000 simulations.:  88%|████████▊ | 8848/10000 [00:36<00:04, 241.81it/s]Running 10000 simulations.:  89%|████████▊ | 8873/10000 [00:37<00:04, 241.42it/s]Running 10000 simulations.:  89%|████████▉ | 8898/10000 [00:37<00:04, 241.31it/s]Running 10000 simulations.:  89%|████████▉ | 8923/10000 [00:37<00:04, 241.53it/s]Running 10000 simulations.:  89%|████████▉ | 8948/10000 [00:37<00:04, 241.63it/s]Running 10000 simulations.:  90%|████████▉ | 8973/10000 [00:37<00:04, 241.95it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:37<00:04, 242.22it/s]Running 10000 simulations.:  90%|█████████ | 9023/10000 [00:37<00:04, 241.97it/s]Running 10000 simulations.:  90%|█████████ | 9048/10000 [00:37<00:03, 241.61it/s]Running 10000 simulations.:  91%|█████████ | 9073/10000 [00:37<00:03, 241.99it/s]Running 10000 simulations.:  91%|█████████ | 9098/10000 [00:37<00:03, 241.64it/s]Running 10000 simulations.:  91%|█████████ | 9123/10000 [00:38<00:03, 241.55it/s]Running 10000 simulations.:  91%|█████████▏| 9148/10000 [00:38<00:03, 241.54it/s]Running 10000 simulations.:  92%|█████████▏| 9173/10000 [00:38<00:03, 241.33it/s]Running 10000 simulations.:  92%|█████████▏| 9198/10000 [00:38<00:03, 241.20it/s]Running 10000 simulations.:  92%|█████████▏| 9223/10000 [00:38<00:03, 241.07it/s]Running 10000 simulations.:  92%|█████████▏| 9248/10000 [00:38<00:03, 241.00it/s]Running 10000 simulations.:  93%|█████████▎| 9273/10000 [00:38<00:03, 241.10it/s]Running 10000 simulations.:  93%|█████████▎| 9298/10000 [00:38<00:02, 240.84it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [00:38<00:02, 241.18it/s]Running 10000 simulations.:  93%|█████████▎| 9348/10000 [00:39<00:02, 241.86it/s]Running 10000 simulations.:  94%|█████████▎| 9373/10000 [00:39<00:02, 241.07it/s]Running 10000 simulations.:  94%|█████████▍| 9398/10000 [00:39<00:02, 241.10it/s]Running 10000 simulations.:  94%|█████████▍| 9423/10000 [00:39<00:02, 241.03it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [00:39<00:02, 241.27it/s]Running 10000 simulations.:  95%|█████████▍| 9473/10000 [00:39<00:02, 241.15it/s]Running 10000 simulations.:  95%|█████████▍| 9498/10000 [00:39<00:02, 241.02it/s]Running 10000 simulations.:  95%|█████████▌| 9523/10000 [00:39<00:01, 240.85it/s]Running 10000 simulations.:  95%|█████████▌| 9548/10000 [00:39<00:01, 241.64it/s]Running 10000 simulations.:  96%|█████████▌| 9573/10000 [00:39<00:01, 241.72it/s]Running 10000 simulations.:  96%|█████████▌| 9598/10000 [00:40<00:01, 241.57it/s]Running 10000 simulations.:  96%|█████████▌| 9623/10000 [00:40<00:01, 241.83it/s]Running 10000 simulations.:  96%|█████████▋| 9648/10000 [00:40<00:01, 241.85it/s]Running 10000 simulations.:  97%|█████████▋| 9673/10000 [00:40<00:01, 241.57it/s]Running 10000 simulations.:  97%|█████████▋| 9698/10000 [00:40<00:01, 241.75it/s]Running 10000 simulations.:  97%|█████████▋| 9723/10000 [00:40<00:01, 242.19it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [00:40<00:01, 242.66it/s]Running 10000 simulations.:  98%|█████████▊| 9773/10000 [00:40<00:00, 242.83it/s]Running 10000 simulations.:  98%|█████████▊| 9798/10000 [00:40<00:00, 242.86it/s]Running 10000 simulations.:  98%|█████████▊| 9823/10000 [00:40<00:00, 242.97it/s]Running 10000 simulations.:  98%|█████████▊| 9848/10000 [00:41<00:00, 243.64it/s]Running 10000 simulations.:  99%|█████████▊| 9873/10000 [00:41<00:00, 243.46it/s]Running 10000 simulations.:  99%|█████████▉| 9898/10000 [00:41<00:00, 243.90it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [00:41<00:00, 243.52it/s]Running 10000 simulations.:  99%|█████████▉| 9948/10000 [00:41<00:00, 243.55it/s]Running 10000 simulations.: 100%|█████████▉| 9973/10000 [00:41<00:00, 243.50it/s]Running 10000 simulations.: 100%|█████████▉| 9998/10000 [00:41<00:00, 243.70it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 239.68it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 253.49it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 252.65it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:39, 252.92it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:39, 252.07it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:39, 252.66it/s]Running 10000 simulations.:   2%|▏         | 155/10000 [00:00<00:39, 251.86it/s]Running 10000 simulations.:   2%|▏         | 181/10000 [00:00<00:38, 252.35it/s]Running 10000 simulations.:   2%|▏         | 207/10000 [00:00<00:38, 252.38it/s]Running 10000 simulations.:   2%|▏         | 233/10000 [00:00<00:38, 252.12it/s]Running 10000 simulations.:   3%|▎         | 259/10000 [00:01<00:38, 251.90it/s]Running 10000 simulations.:   3%|▎         | 285/10000 [00:01<00:38, 252.55it/s]Running 10000 simulations.:   3%|▎         | 310/10000 [00:01<00:38, 251.35it/s]Running 10000 simulations.:   3%|▎         | 335/10000 [00:01<00:38, 250.04it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:01<00:38, 248.77it/s]Running 10000 simulations.:   4%|▍         | 385/10000 [00:01<00:38, 248.89it/s]Running 10000 simulations.:   4%|▍         | 410/10000 [00:01<00:38, 248.52it/s]Running 10000 simulations.:   4%|▍         | 435/10000 [00:01<00:38, 248.60it/s]Running 10000 simulations.:   5%|▍         | 460/10000 [00:01<00:38, 248.51it/s]Running 10000 simulations.:   5%|▍         | 485/10000 [00:01<00:38, 248.74it/s]Running 10000 simulations.:   5%|▌         | 511/10000 [00:02<00:37, 249.75it/s]Running 10000 simulations.:   5%|▌         | 536/10000 [00:02<00:37, 249.75it/s]Running 10000 simulations.:   6%|▌         | 561/10000 [00:02<00:37, 248.61it/s]Running 10000 simulations.:   6%|▌         | 586/10000 [00:02<00:38, 247.71it/s]Running 10000 simulations.:   6%|▌         | 611/10000 [00:02<00:38, 246.80it/s]Running 10000 simulations.:   6%|▋         | 636/10000 [00:02<00:38, 242.98it/s]Running 10000 simulations.:   7%|▋         | 661/10000 [00:02<00:38, 243.49it/s]Running 10000 simulations.:   7%|▋         | 686/10000 [00:02<00:38, 244.27it/s]Running 10000 simulations.:   7%|▋         | 711/10000 [00:02<00:37, 245.07it/s]Running 10000 simulations.:   7%|▋         | 736/10000 [00:02<00:37, 245.84it/s]Running 10000 simulations.:   8%|▊         | 761/10000 [00:03<00:37, 246.18it/s]Running 10000 simulations.:   8%|▊         | 786/10000 [00:03<00:37, 246.31it/s]Running 10000 simulations.:   8%|▊         | 811/10000 [00:03<00:37, 247.14it/s]Running 10000 simulations.:   8%|▊         | 836/10000 [00:03<00:37, 246.90it/s]Running 10000 simulations.:   9%|▊         | 861/10000 [00:03<00:37, 246.57it/s]Running 10000 simulations.:   9%|▉         | 886/10000 [00:03<00:37, 246.29it/s]Running 10000 simulations.:   9%|▉         | 911/10000 [00:03<00:36, 245.72it/s]Running 10000 simulations.:   9%|▉         | 936/10000 [00:03<00:36, 245.82it/s]Running 10000 simulations.:  10%|▉         | 961/10000 [00:03<00:36, 245.54it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:03<00:36, 245.25it/s]Running 10000 simulations.:  10%|█         | 1011/10000 [00:04<00:36, 246.03it/s]Running 10000 simulations.:  10%|█         | 1037/10000 [00:04<00:36, 247.47it/s]Running 10000 simulations.:  11%|█         | 1062/10000 [00:04<00:36, 247.15it/s]Running 10000 simulations.:  11%|█         | 1087/10000 [00:04<00:36, 246.19it/s]Running 10000 simulations.:  11%|█         | 1112/10000 [00:04<00:36, 246.36it/s]Running 10000 simulations.:  11%|█▏        | 1137/10000 [00:04<00:36, 246.17it/s]Running 10000 simulations.:  12%|█▏        | 1162/10000 [00:04<00:35, 247.00it/s]Running 10000 simulations.:  12%|█▏        | 1187/10000 [00:04<00:35, 247.40it/s]Running 10000 simulations.:  12%|█▏        | 1212/10000 [00:04<00:35, 246.15it/s]Running 10000 simulations.:  12%|█▏        | 1237/10000 [00:04<00:35, 245.19it/s]Running 10000 simulations.:  13%|█▎        | 1262/10000 [00:05<00:35, 245.06it/s]Running 10000 simulations.:  13%|█▎        | 1287/10000 [00:05<00:35, 246.21it/s]Running 10000 simulations.:  13%|█▎        | 1312/10000 [00:05<00:35, 246.88it/s]Running 10000 simulations.:  13%|█▎        | 1337/10000 [00:05<00:35, 246.69it/s]Running 10000 simulations.:  14%|█▎        | 1362/10000 [00:05<00:34, 247.01it/s]Running 10000 simulations.:  14%|█▍        | 1387/10000 [00:05<00:34, 246.52it/s]Running 10000 simulations.:  14%|█▍        | 1412/10000 [00:05<00:34, 247.07it/s]Running 10000 simulations.:  14%|█▍        | 1437/10000 [00:05<00:34, 247.78it/s]Running 10000 simulations.:  15%|█▍        | 1462/10000 [00:05<00:34, 247.56it/s]Running 10000 simulations.:  15%|█▍        | 1487/10000 [00:06<00:34, 246.69it/s]Running 10000 simulations.:  15%|█▌        | 1512/10000 [00:06<00:34, 245.86it/s]Running 10000 simulations.:  15%|█▌        | 1537/10000 [00:06<00:34, 244.87it/s]Running 10000 simulations.:  16%|█▌        | 1562/10000 [00:06<00:34, 244.48it/s]Running 10000 simulations.:  16%|█▌        | 1587/10000 [00:06<00:34, 244.09it/s]Running 10000 simulations.:  16%|█▌        | 1612/10000 [00:06<00:34, 243.89it/s]Running 10000 simulations.:  16%|█▋        | 1637/10000 [00:06<00:34, 244.60it/s]Running 10000 simulations.:  17%|█▋        | 1662/10000 [00:06<00:33, 245.62it/s]Running 10000 simulations.:  17%|█▋        | 1687/10000 [00:06<00:33, 246.71it/s]Running 10000 simulations.:  17%|█▋        | 1712/10000 [00:06<00:33, 245.95it/s]Running 10000 simulations.:  17%|█▋        | 1737/10000 [00:07<00:33, 245.50it/s]Running 10000 simulations.:  18%|█▊        | 1762/10000 [00:07<00:33, 245.16it/s]Running 10000 simulations.:  18%|█▊        | 1787/10000 [00:07<00:33, 245.55it/s]Running 10000 simulations.:  18%|█▊        | 1812/10000 [00:07<00:33, 244.92it/s]Running 10000 simulations.:  18%|█▊        | 1837/10000 [00:07<00:33, 244.23it/s]Running 10000 simulations.:  19%|█▊        | 1862/10000 [00:07<00:33, 244.85it/s]Running 10000 simulations.:  19%|█▉        | 1887/10000 [00:07<00:33, 244.64it/s]Running 10000 simulations.:  19%|█▉        | 1912/10000 [00:07<00:33, 244.29it/s]Running 10000 simulations.:  19%|█▉        | 1937/10000 [00:07<00:32, 244.42it/s]Running 10000 simulations.:  20%|█▉        | 1962/10000 [00:07<00:32, 244.68it/s]Running 10000 simulations.:  20%|█▉        | 1987/10000 [00:08<00:32, 245.64it/s]Running 10000 simulations.:  20%|██        | 2012/10000 [00:08<00:32, 245.47it/s]Running 10000 simulations.:  20%|██        | 2037/10000 [00:08<00:32, 245.05it/s]Running 10000 simulations.:  21%|██        | 2062/10000 [00:08<00:32, 245.23it/s]Running 10000 simulations.:  21%|██        | 2087/10000 [00:08<00:32, 245.51it/s]Running 10000 simulations.:  21%|██        | 2112/10000 [00:08<00:32, 245.96it/s]Running 10000 simulations.:  21%|██▏       | 2137/10000 [00:08<00:32, 245.00it/s]Running 10000 simulations.:  22%|██▏       | 2162/10000 [00:08<00:32, 243.68it/s]Running 10000 simulations.:  22%|██▏       | 2187/10000 [00:08<00:32, 243.42it/s]Running 10000 simulations.:  22%|██▏       | 2212/10000 [00:08<00:31, 244.22it/s]Running 10000 simulations.:  22%|██▏       | 2237/10000 [00:09<00:31, 244.65it/s]Running 10000 simulations.:  23%|██▎       | 2262/10000 [00:09<00:31, 244.54it/s]Running 10000 simulations.:  23%|██▎       | 2287/10000 [00:09<00:31, 244.52it/s]Running 10000 simulations.:  23%|██▎       | 2312/10000 [00:09<00:31, 244.55it/s]Running 10000 simulations.:  23%|██▎       | 2337/10000 [00:09<00:31, 242.65it/s]Running 10000 simulations.:  24%|██▎       | 2362/10000 [00:09<00:31, 241.53it/s]Running 10000 simulations.:  24%|██▍       | 2387/10000 [00:09<00:31, 241.42it/s]Running 10000 simulations.:  24%|██▍       | 2412/10000 [00:09<00:31, 240.65it/s]Running 10000 simulations.:  24%|██▍       | 2437/10000 [00:09<00:31, 240.93it/s]Running 10000 simulations.:  25%|██▍       | 2462/10000 [00:09<00:31, 240.66it/s]Running 10000 simulations.:  25%|██▍       | 2487/10000 [00:10<00:31, 241.93it/s]Running 10000 simulations.:  25%|██▌       | 2512/10000 [00:10<00:30, 242.40it/s]Running 10000 simulations.:  25%|██▌       | 2537/10000 [00:10<00:30, 242.13it/s]Running 10000 simulations.:  26%|██▌       | 2562/10000 [00:10<00:30, 242.32it/s]Running 10000 simulations.:  26%|██▌       | 2587/10000 [00:10<00:30, 242.57it/s]Running 10000 simulations.:  26%|██▌       | 2612/10000 [00:10<00:30, 242.75it/s]Running 10000 simulations.:  26%|██▋       | 2637/10000 [00:10<00:30, 243.36it/s]Running 10000 simulations.:  27%|██▋       | 2662/10000 [00:10<00:30, 243.97it/s]Running 10000 simulations.:  27%|██▋       | 2687/10000 [00:10<00:30, 243.47it/s]Running 10000 simulations.:  27%|██▋       | 2712/10000 [00:11<00:29, 243.11it/s]Running 10000 simulations.:  27%|██▋       | 2737/10000 [00:11<00:29, 243.88it/s]Running 10000 simulations.:  28%|██▊       | 2762/10000 [00:11<00:29, 243.68it/s]Running 10000 simulations.:  28%|██▊       | 2787/10000 [00:11<00:29, 244.09it/s]Running 10000 simulations.:  28%|██▊       | 2812/10000 [00:11<00:29, 243.79it/s]Running 10000 simulations.:  28%|██▊       | 2837/10000 [00:11<00:29, 243.63it/s]Running 10000 simulations.:  29%|██▊       | 2862/10000 [00:11<00:29, 243.40it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:11<00:29, 243.29it/s]Running 10000 simulations.:  29%|██▉       | 2912/10000 [00:11<00:29, 243.46it/s]Running 10000 simulations.:  29%|██▉       | 2937/10000 [00:11<00:29, 242.96it/s]Running 10000 simulations.:  30%|██▉       | 2962/10000 [00:12<00:29, 242.55it/s]Running 10000 simulations.:  30%|██▉       | 2987/10000 [00:12<00:28, 242.22it/s]Running 10000 simulations.:  30%|███       | 3012/10000 [00:12<00:28, 242.31it/s]Running 10000 simulations.:  30%|███       | 3037/10000 [00:12<00:28, 241.70it/s]Running 10000 simulations.:  31%|███       | 3062/10000 [00:12<00:28, 241.95it/s]Running 10000 simulations.:  31%|███       | 3087/10000 [00:12<00:28, 242.54it/s]Running 10000 simulations.:  31%|███       | 3112/10000 [00:12<00:28, 243.93it/s]Running 10000 simulations.:  31%|███▏      | 3137/10000 [00:12<00:28, 244.62it/s]Running 10000 simulations.:  32%|███▏      | 3162/10000 [00:12<00:27, 244.46it/s]Running 10000 simulations.:  32%|███▏      | 3187/10000 [00:12<00:27, 244.23it/s]Running 10000 simulations.:  32%|███▏      | 3212/10000 [00:13<00:27, 243.83it/s]Running 10000 simulations.:  32%|███▏      | 3237/10000 [00:13<00:27, 243.02it/s]Running 10000 simulations.:  33%|███▎      | 3262/10000 [00:13<00:27, 243.76it/s]Running 10000 simulations.:  33%|███▎      | 3287/10000 [00:13<00:27, 243.28it/s]Running 10000 simulations.:  33%|███▎      | 3312/10000 [00:13<00:27, 243.49it/s]Running 10000 simulations.:  33%|███▎      | 3337/10000 [00:13<00:27, 243.91it/s]Running 10000 simulations.:  34%|███▎      | 3362/10000 [00:13<00:27, 243.45it/s]Running 10000 simulations.:  34%|███▍      | 3387/10000 [00:13<00:27, 243.30it/s]Running 10000 simulations.:  34%|███▍      | 3412/10000 [00:13<00:27, 240.36it/s]Running 10000 simulations.:  34%|███▍      | 3437/10000 [00:14<00:27, 240.38it/s]Running 10000 simulations.:  35%|███▍      | 3462/10000 [00:14<00:27, 241.75it/s]Running 10000 simulations.:  35%|███▍      | 3487/10000 [00:14<00:26, 242.71it/s]Running 10000 simulations.:  35%|███▌      | 3512/10000 [00:14<00:26, 243.43it/s]Running 10000 simulations.:  35%|███▌      | 3537/10000 [00:14<00:26, 243.70it/s]Running 10000 simulations.:  36%|███▌      | 3562/10000 [00:14<00:26, 242.99it/s]Running 10000 simulations.:  36%|███▌      | 3587/10000 [00:14<00:26, 242.05it/s]Running 10000 simulations.:  36%|███▌      | 3612/10000 [00:14<00:26, 241.58it/s]Running 10000 simulations.:  36%|███▋      | 3637/10000 [00:14<00:26, 241.34it/s]Running 10000 simulations.:  37%|███▋      | 3662/10000 [00:14<00:26, 241.72it/s]Running 10000 simulations.:  37%|███▋      | 3687/10000 [00:15<00:26, 242.32it/s]Running 10000 simulations.:  37%|███▋      | 3712/10000 [00:15<00:25, 243.61it/s]Running 10000 simulations.:  37%|███▋      | 3737/10000 [00:15<00:25, 243.57it/s]Running 10000 simulations.:  38%|███▊      | 3762/10000 [00:15<00:25, 243.14it/s]Running 10000 simulations.:  38%|███▊      | 3787/10000 [00:15<00:25, 242.72it/s]Running 10000 simulations.:  38%|███▊      | 3812/10000 [00:15<00:25, 242.09it/s]Running 10000 simulations.:  38%|███▊      | 3837/10000 [00:15<00:25, 241.99it/s]Running 10000 simulations.:  39%|███▊      | 3862/10000 [00:15<00:25, 241.56it/s]Running 10000 simulations.:  39%|███▉      | 3887/10000 [00:15<00:25, 242.65it/s]Running 10000 simulations.:  39%|███▉      | 3912/10000 [00:15<00:25, 243.44it/s]Running 10000 simulations.:  39%|███▉      | 3937/10000 [00:16<00:24, 243.07it/s]Running 10000 simulations.:  40%|███▉      | 3962/10000 [00:16<00:24, 242.84it/s]Running 10000 simulations.:  40%|███▉      | 3987/10000 [00:16<00:24, 242.63it/s]Running 10000 simulations.:  40%|████      | 4012/10000 [00:16<00:25, 235.54it/s]Running 10000 simulations.:  40%|████      | 4037/10000 [00:16<00:25, 238.25it/s]Running 10000 simulations.:  41%|████      | 4062/10000 [00:16<00:24, 240.31it/s]Running 10000 simulations.:  41%|████      | 4087/10000 [00:16<00:24, 240.12it/s]Running 10000 simulations.:  41%|████      | 4112/10000 [00:16<00:24, 240.00it/s]Running 10000 simulations.:  41%|████▏     | 4137/10000 [00:16<00:24, 240.01it/s]Running 10000 simulations.:  42%|████▏     | 4162/10000 [00:17<00:24, 239.60it/s]Running 10000 simulations.:  42%|████▏     | 4186/10000 [00:17<00:24, 239.13it/s]Running 10000 simulations.:  42%|████▏     | 4210/10000 [00:17<00:24, 239.11it/s]Running 10000 simulations.:  42%|████▏     | 4234/10000 [00:17<00:24, 239.02it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:17<00:23, 240.04it/s]Running 10000 simulations.:  43%|████▎     | 4284/10000 [00:17<00:23, 241.39it/s]Running 10000 simulations.:  43%|████▎     | 4309/10000 [00:17<00:23, 241.91it/s]Running 10000 simulations.:  43%|████▎     | 4334/10000 [00:17<00:23, 242.34it/s]Running 10000 simulations.:  44%|████▎     | 4359/10000 [00:17<00:23, 242.98it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:17<00:23, 242.67it/s]Running 10000 simulations.:  44%|████▍     | 4409/10000 [00:18<00:23, 242.61it/s]Running 10000 simulations.:  44%|████▍     | 4434/10000 [00:18<00:23, 241.85it/s]Running 10000 simulations.:  45%|████▍     | 4459/10000 [00:18<00:22, 241.08it/s]Running 10000 simulations.:  45%|████▍     | 4484/10000 [00:18<00:22, 240.72it/s]Running 10000 simulations.:  45%|████▌     | 4509/10000 [00:18<00:22, 240.73it/s]Running 10000 simulations.:  45%|████▌     | 4534/10000 [00:18<00:22, 240.63it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:18<00:22, 241.06it/s]Running 10000 simulations.:  46%|████▌     | 4584/10000 [00:18<00:22, 241.74it/s]Running 10000 simulations.:  46%|████▌     | 4609/10000 [00:18<00:22, 242.09it/s]Running 10000 simulations.:  46%|████▋     | 4634/10000 [00:18<00:22, 243.06it/s]Running 10000 simulations.:  47%|████▋     | 4659/10000 [00:19<00:22, 242.29it/s]Running 10000 simulations.:  47%|████▋     | 4684/10000 [00:19<00:22, 241.32it/s]Running 10000 simulations.:  47%|████▋     | 4709/10000 [00:19<00:21, 240.92it/s]Running 10000 simulations.:  47%|████▋     | 4734/10000 [00:19<00:21, 240.49it/s]Running 10000 simulations.:  48%|████▊     | 4759/10000 [00:19<00:21, 240.44it/s]Running 10000 simulations.:  48%|████▊     | 4784/10000 [00:19<00:21, 240.63it/s]Running 10000 simulations.:  48%|████▊     | 4809/10000 [00:19<00:21, 242.07it/s]Running 10000 simulations.:  48%|████▊     | 4834/10000 [00:19<00:21, 243.27it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:19<00:21, 243.80it/s]Running 10000 simulations.:  49%|████▉     | 4884/10000 [00:19<00:20, 244.02it/s]Running 10000 simulations.:  49%|████▉     | 4909/10000 [00:20<00:20, 243.71it/s]Running 10000 simulations.:  49%|████▉     | 4934/10000 [00:20<00:20, 242.90it/s]Running 10000 simulations.:  50%|████▉     | 4959/10000 [00:20<00:20, 242.06it/s]Running 10000 simulations.:  50%|████▉     | 4984/10000 [00:20<00:20, 240.74it/s]Running 10000 simulations.:  50%|█████     | 5009/10000 [00:20<00:20, 241.23it/s]Running 10000 simulations.:  50%|█████     | 5034/10000 [00:20<00:20, 241.90it/s]Running 10000 simulations.:  51%|█████     | 5059/10000 [00:20<00:20, 242.45it/s]Running 10000 simulations.:  51%|█████     | 5084/10000 [00:20<00:20, 242.10it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:20<00:20, 241.54it/s]Running 10000 simulations.:  51%|█████▏    | 5134/10000 [00:21<00:20, 241.25it/s]Running 10000 simulations.:  52%|█████▏    | 5159/10000 [00:21<00:20, 240.11it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:21<00:20, 239.76it/s]Running 10000 simulations.:  52%|█████▏    | 5209/10000 [00:21<00:19, 240.18it/s]Running 10000 simulations.:  52%|█████▏    | 5234/10000 [00:21<00:19, 239.54it/s]Running 10000 simulations.:  53%|█████▎    | 5258/10000 [00:21<00:19, 239.28it/s]Running 10000 simulations.:  53%|█████▎    | 5283/10000 [00:21<00:19, 240.13it/s]Running 10000 simulations.:  53%|█████▎    | 5308/10000 [00:21<00:19, 241.31it/s]Running 10000 simulations.:  53%|█████▎    | 5333/10000 [00:21<00:19, 242.50it/s]Running 10000 simulations.:  54%|█████▎    | 5358/10000 [00:21<00:19, 242.59it/s]Running 10000 simulations.:  54%|█████▍    | 5383/10000 [00:22<00:18, 243.03it/s]Running 10000 simulations.:  54%|█████▍    | 5408/10000 [00:22<00:18, 243.41it/s]Running 10000 simulations.:  54%|█████▍    | 5433/10000 [00:22<00:18, 242.01it/s]Running 10000 simulations.:  55%|█████▍    | 5458/10000 [00:22<00:18, 241.06it/s]Running 10000 simulations.:  55%|█████▍    | 5483/10000 [00:22<00:18, 241.47it/s]Running 10000 simulations.:  55%|█████▌    | 5508/10000 [00:22<00:18, 241.37it/s]Running 10000 simulations.:  55%|█████▌    | 5533/10000 [00:22<00:18, 241.77it/s]Running 10000 simulations.:  56%|█████▌    | 5558/10000 [00:22<00:18, 241.54it/s]Running 10000 simulations.:  56%|█████▌    | 5583/10000 [00:22<00:18, 241.17it/s]Running 10000 simulations.:  56%|█████▌    | 5608/10000 [00:22<00:18, 241.71it/s]Running 10000 simulations.:  56%|█████▋    | 5633/10000 [00:23<00:18, 241.40it/s]Running 10000 simulations.:  57%|█████▋    | 5658/10000 [00:23<00:18, 240.97it/s]Running 10000 simulations.:  57%|█████▋    | 5683/10000 [00:23<00:17, 240.42it/s]Running 10000 simulations.:  57%|█████▋    | 5708/10000 [00:23<00:17, 239.67it/s]Running 10000 simulations.:  57%|█████▋    | 5732/10000 [00:23<00:17, 239.26it/s]Running 10000 simulations.:  58%|█████▊    | 5756/10000 [00:23<00:17, 239.14it/s]Running 10000 simulations.:  58%|█████▊    | 5781/10000 [00:23<00:17, 239.75it/s]Running 10000 simulations.:  58%|█████▊    | 5805/10000 [00:23<00:17, 239.80it/s]Running 10000 simulations.:  58%|█████▊    | 5829/10000 [00:23<00:17, 239.25it/s]Running 10000 simulations.:  59%|█████▊    | 5853/10000 [00:24<00:17, 239.27it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:24<00:17, 239.61it/s]Running 10000 simulations.:  59%|█████▉    | 5903/10000 [00:24<00:17, 240.64it/s]Running 10000 simulations.:  59%|█████▉    | 5928/10000 [00:24<00:16, 241.23it/s]Running 10000 simulations.:  60%|█████▉    | 5953/10000 [00:24<00:16, 238.46it/s]Running 10000 simulations.:  60%|█████▉    | 5977/10000 [00:24<00:16, 238.03it/s]Running 10000 simulations.:  60%|██████    | 6001/10000 [00:24<00:16, 237.62it/s]Running 10000 simulations.:  60%|██████    | 6025/10000 [00:24<00:16, 237.47it/s]Running 10000 simulations.:  60%|██████    | 6049/10000 [00:24<00:16, 237.52it/s]Running 10000 simulations.:  61%|██████    | 6073/10000 [00:24<00:16, 237.65it/s]Running 10000 simulations.:  61%|██████    | 6097/10000 [00:25<00:16, 238.35it/s]Running 10000 simulations.:  61%|██████    | 6122/10000 [00:25<00:16, 239.07it/s]Running 10000 simulations.:  61%|██████▏   | 6147/10000 [00:25<00:16, 240.35it/s]Running 10000 simulations.:  62%|██████▏   | 6172/10000 [00:25<00:15, 240.77it/s]Running 10000 simulations.:  62%|██████▏   | 6197/10000 [00:25<00:15, 239.70it/s]Running 10000 simulations.:  62%|██████▏   | 6221/10000 [00:25<00:15, 239.72it/s]Running 10000 simulations.:  62%|██████▏   | 6245/10000 [00:25<00:15, 238.94it/s]Running 10000 simulations.:  63%|██████▎   | 6269/10000 [00:25<00:15, 237.51it/s]Running 10000 simulations.:  63%|██████▎   | 6293/10000 [00:25<00:15, 236.24it/s]Running 10000 simulations.:  63%|██████▎   | 6317/10000 [00:25<00:15, 235.52it/s]Running 10000 simulations.:  63%|██████▎   | 6341/10000 [00:26<00:15, 235.26it/s]Running 10000 simulations.:  64%|██████▎   | 6365/10000 [00:26<00:15, 234.76it/s]Running 10000 simulations.:  64%|██████▍   | 6389/10000 [00:26<00:15, 235.02it/s]Running 10000 simulations.:  64%|██████▍   | 6413/10000 [00:26<00:15, 235.21it/s]Running 10000 simulations.:  64%|██████▍   | 6438/10000 [00:26<00:15, 237.11it/s]Running 10000 simulations.:  65%|██████▍   | 6462/10000 [00:26<00:14, 237.93it/s]Running 10000 simulations.:  65%|██████▍   | 6486/10000 [00:26<00:14, 237.92it/s]Running 10000 simulations.:  65%|██████▌   | 6511/10000 [00:26<00:14, 238.99it/s]Running 10000 simulations.:  65%|██████▌   | 6536/10000 [00:26<00:14, 239.42it/s]Running 10000 simulations.:  66%|██████▌   | 6561/10000 [00:26<00:14, 239.97it/s]Running 10000 simulations.:  66%|██████▌   | 6586/10000 [00:27<00:14, 240.08it/s]Running 10000 simulations.:  66%|██████▌   | 6611/10000 [00:27<00:14, 239.68it/s]Running 10000 simulations.:  66%|██████▋   | 6635/10000 [00:27<00:14, 238.89it/s]Running 10000 simulations.:  67%|██████▋   | 6659/10000 [00:27<00:14, 238.15it/s]Running 10000 simulations.:  67%|██████▋   | 6683/10000 [00:27<00:13, 238.38it/s]Running 10000 simulations.:  67%|██████▋   | 6708/10000 [00:27<00:13, 240.14it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:27<00:13, 241.48it/s]Running 10000 simulations.:  68%|██████▊   | 6758/10000 [00:27<00:13, 242.42it/s]Running 10000 simulations.:  68%|██████▊   | 6783/10000 [00:27<00:13, 243.08it/s]Running 10000 simulations.:  68%|██████▊   | 6808/10000 [00:28<00:13, 242.01it/s]Running 10000 simulations.:  68%|██████▊   | 6833/10000 [00:28<00:13, 239.30it/s]Running 10000 simulations.:  69%|██████▊   | 6857/10000 [00:28<00:13, 238.68it/s]Running 10000 simulations.:  69%|██████▉   | 6881/10000 [00:28<00:13, 238.17it/s]Running 10000 simulations.:  69%|██████▉   | 6905/10000 [00:28<00:12, 238.33it/s]Running 10000 simulations.:  69%|██████▉   | 6929/10000 [00:28<00:12, 238.60it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:28<00:12, 238.49it/s]Running 10000 simulations.:  70%|██████▉   | 6977/10000 [00:28<00:12, 238.36it/s]Running 10000 simulations.:  70%|███████   | 7002/10000 [00:28<00:12, 239.02it/s]Running 10000 simulations.:  70%|███████   | 7026/10000 [00:28<00:12, 239.21it/s]Running 10000 simulations.:  71%|███████   | 7051/10000 [00:29<00:12, 239.47it/s]Running 10000 simulations.:  71%|███████   | 7076/10000 [00:29<00:12, 240.44it/s]Running 10000 simulations.:  71%|███████   | 7101/10000 [00:29<00:12, 240.75it/s]Running 10000 simulations.:  71%|███████▏  | 7126/10000 [00:29<00:12, 239.26it/s]Running 10000 simulations.:  72%|███████▏  | 7150/10000 [00:29<00:11, 238.19it/s]Running 10000 simulations.:  72%|███████▏  | 7174/10000 [00:29<00:11, 237.92it/s]Running 10000 simulations.:  72%|███████▏  | 7198/10000 [00:29<00:11, 237.72it/s]Running 10000 simulations.:  72%|███████▏  | 7222/10000 [00:29<00:11, 237.53it/s]Running 10000 simulations.:  72%|███████▏  | 7246/10000 [00:29<00:11, 237.34it/s]Running 10000 simulations.:  73%|███████▎  | 7270/10000 [00:29<00:11, 237.14it/s]Running 10000 simulations.:  73%|███████▎  | 7294/10000 [00:30<00:11, 237.48it/s]Running 10000 simulations.:  73%|███████▎  | 7318/10000 [00:30<00:11, 237.96it/s]Running 10000 simulations.:  73%|███████▎  | 7342/10000 [00:30<00:11, 238.49it/s]Running 10000 simulations.:  74%|███████▎  | 7367/10000 [00:30<00:11, 239.29it/s]Running 10000 simulations.:  74%|███████▍  | 7392/10000 [00:30<00:10, 239.73it/s]Running 10000 simulations.:  74%|███████▍  | 7416/10000 [00:30<00:10, 239.67it/s]Running 10000 simulations.:  74%|███████▍  | 7441/10000 [00:30<00:10, 240.46it/s]Running 10000 simulations.:  75%|███████▍  | 7466/10000 [00:30<00:10, 240.26it/s]Running 10000 simulations.:  75%|███████▍  | 7491/10000 [00:30<00:10, 240.03it/s]Running 10000 simulations.:  75%|███████▌  | 7516/10000 [00:30<00:10, 239.78it/s]Running 10000 simulations.:  75%|███████▌  | 7541/10000 [00:31<00:10, 240.09it/s]Running 10000 simulations.:  76%|███████▌  | 7566/10000 [00:31<00:10, 240.76it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:31<00:09, 241.54it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:31<00:09, 242.05it/s]Running 10000 simulations.:  76%|███████▋  | 7641/10000 [00:31<00:09, 242.16it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:31<00:09, 240.63it/s]Running 10000 simulations.:  77%|███████▋  | 7691/10000 [00:31<00:09, 239.31it/s]Running 10000 simulations.:  77%|███████▋  | 7716/10000 [00:31<00:09, 239.68it/s]Running 10000 simulations.:  77%|███████▋  | 7740/10000 [00:31<00:09, 239.69it/s]Running 10000 simulations.:  78%|███████▊  | 7765/10000 [00:32<00:09, 240.17it/s]Running 10000 simulations.:  78%|███████▊  | 7790/10000 [00:32<00:09, 239.77it/s]Running 10000 simulations.:  78%|███████▊  | 7814/10000 [00:32<00:09, 239.74it/s]Running 10000 simulations.:  78%|███████▊  | 7838/10000 [00:32<00:09, 239.47it/s]Running 10000 simulations.:  79%|███████▊  | 7863/10000 [00:32<00:08, 240.53it/s]Running 10000 simulations.:  79%|███████▉  | 7888/10000 [00:32<00:08, 240.71it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:32<00:08, 239.88it/s]Running 10000 simulations.:  79%|███████▉  | 7937/10000 [00:32<00:08, 239.38it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:32<00:08, 239.39it/s]Running 10000 simulations.:  80%|███████▉  | 7986/10000 [00:32<00:08, 239.78it/s]Running 10000 simulations.:  80%|████████  | 8011/10000 [00:33<00:08, 240.58it/s]Running 10000 simulations.:  80%|████████  | 8036/10000 [00:33<00:08, 240.72it/s]Running 10000 simulations.:  81%|████████  | 8061/10000 [00:33<00:08, 240.49it/s]Running 10000 simulations.:  81%|████████  | 8086/10000 [00:33<00:07, 240.48it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:33<00:07, 240.63it/s]Running 10000 simulations.:  81%|████████▏ | 8136/10000 [00:33<00:07, 242.02it/s]Running 10000 simulations.:  82%|████████▏ | 8161/10000 [00:33<00:07, 242.67it/s]Running 10000 simulations.:  82%|████████▏ | 8186/10000 [00:33<00:07, 241.61it/s]Running 10000 simulations.:  82%|████████▏ | 8211/10000 [00:33<00:07, 240.48it/s]Running 10000 simulations.:  82%|████████▏ | 8236/10000 [00:33<00:07, 239.67it/s]Running 10000 simulations.:  83%|████████▎ | 8261/10000 [00:34<00:07, 240.31it/s]Running 10000 simulations.:  83%|████████▎ | 8286/10000 [00:34<00:07, 240.58it/s]Running 10000 simulations.:  83%|████████▎ | 8311/10000 [00:34<00:07, 239.84it/s]Running 10000 simulations.:  83%|████████▎ | 8335/10000 [00:34<00:06, 239.51it/s]Running 10000 simulations.:  84%|████████▎ | 8359/10000 [00:34<00:06, 239.49it/s]Running 10000 simulations.:  84%|████████▍ | 8384/10000 [00:34<00:06, 239.84it/s]Running 10000 simulations.:  84%|████████▍ | 8409/10000 [00:34<00:06, 240.09it/s]Running 10000 simulations.:  84%|████████▍ | 8434/10000 [00:34<00:06, 241.48it/s]Running 10000 simulations.:  85%|████████▍ | 8459/10000 [00:34<00:06, 242.26it/s]Running 10000 simulations.:  85%|████████▍ | 8484/10000 [00:35<00:06, 241.10it/s]Running 10000 simulations.:  85%|████████▌ | 8509/10000 [00:35<00:06, 240.38it/s]Running 10000 simulations.:  85%|████████▌ | 8534/10000 [00:35<00:06, 239.65it/s]Running 10000 simulations.:  86%|████████▌ | 8559/10000 [00:35<00:06, 239.88it/s]Running 10000 simulations.:  86%|████████▌ | 8583/10000 [00:35<00:05, 239.92it/s]Running 10000 simulations.:  86%|████████▌ | 8607/10000 [00:35<00:05, 239.51it/s]Running 10000 simulations.:  86%|████████▋ | 8631/10000 [00:35<00:05, 238.97it/s]Running 10000 simulations.:  87%|████████▋ | 8655/10000 [00:35<00:05, 238.84it/s]Running 10000 simulations.:  87%|████████▋ | 8679/10000 [00:35<00:05, 238.70it/s]Running 10000 simulations.:  87%|████████▋ | 8704/10000 [00:35<00:05, 239.91it/s]Running 10000 simulations.:  87%|████████▋ | 8728/10000 [00:36<00:05, 238.38it/s]Running 10000 simulations.:  88%|████████▊ | 8752/10000 [00:36<00:05, 238.66it/s]Running 10000 simulations.:  88%|████████▊ | 8776/10000 [00:36<00:05, 238.58it/s]Running 10000 simulations.:  88%|████████▊ | 8800/10000 [00:36<00:05, 238.90it/s]Running 10000 simulations.:  88%|████████▊ | 8824/10000 [00:36<00:04, 238.20it/s]Running 10000 simulations.:  88%|████████▊ | 8848/10000 [00:36<00:04, 238.35it/s]Running 10000 simulations.:  89%|████████▊ | 8872/10000 [00:36<00:04, 238.65it/s]Running 10000 simulations.:  89%|████████▉ | 8896/10000 [00:36<00:04, 238.96it/s]Running 10000 simulations.:  89%|████████▉ | 8921/10000 [00:36<00:04, 239.57it/s]Running 10000 simulations.:  89%|████████▉ | 8946/10000 [00:36<00:04, 241.20it/s]Running 10000 simulations.:  90%|████████▉ | 8971/10000 [00:37<00:04, 242.11it/s]Running 10000 simulations.:  90%|████████▉ | 8996/10000 [00:37<00:04, 241.28it/s]Running 10000 simulations.:  90%|█████████ | 9021/10000 [00:37<00:04, 234.91it/s]Running 10000 simulations.:  90%|█████████ | 9045/10000 [00:37<00:04, 231.42it/s]Running 10000 simulations.:  91%|█████████ | 9069/10000 [00:37<00:04, 229.49it/s]Running 10000 simulations.:  91%|█████████ | 9092/10000 [00:37<00:04, 226.84it/s]Running 10000 simulations.:  91%|█████████ | 9115/10000 [00:37<00:03, 227.06it/s]Running 10000 simulations.:  91%|█████████▏| 9139/10000 [00:37<00:03, 228.99it/s]Running 10000 simulations.:  92%|█████████▏| 9163/10000 [00:37<00:03, 231.40it/s]Running 10000 simulations.:  92%|█████████▏| 9187/10000 [00:37<00:03, 232.64it/s]Running 10000 simulations.:  92%|█████████▏| 9211/10000 [00:38<00:03, 233.31it/s]Running 10000 simulations.:  92%|█████████▏| 9235/10000 [00:38<00:03, 233.31it/s]Running 10000 simulations.:  93%|█████████▎| 9259/10000 [00:38<00:03, 233.76it/s]Running 10000 simulations.:  93%|█████████▎| 9283/10000 [00:38<00:03, 233.01it/s]Running 10000 simulations.:  93%|█████████▎| 9307/10000 [00:38<00:02, 232.99it/s]Running 10000 simulations.:  93%|█████████▎| 9331/10000 [00:38<00:02, 231.63it/s]Running 10000 simulations.:  94%|█████████▎| 9355/10000 [00:38<00:02, 231.91it/s]Running 10000 simulations.:  94%|█████████▍| 9379/10000 [00:38<00:02, 233.83it/s]Running 10000 simulations.:  94%|█████████▍| 9403/10000 [00:38<00:02, 234.69it/s]Running 10000 simulations.:  94%|█████████▍| 9427/10000 [00:39<00:02, 234.54it/s]Running 10000 simulations.:  95%|█████████▍| 9451/10000 [00:39<00:02, 233.96it/s]Running 10000 simulations.:  95%|█████████▍| 9475/10000 [00:39<00:02, 234.08it/s]Running 10000 simulations.:  95%|█████████▍| 9499/10000 [00:39<00:02, 233.82it/s]Running 10000 simulations.:  95%|█████████▌| 9523/10000 [00:39<00:02, 234.08it/s]Running 10000 simulations.:  95%|█████████▌| 9547/10000 [00:39<00:01, 233.68it/s]Running 10000 simulations.:  96%|█████████▌| 9571/10000 [00:39<00:01, 233.99it/s]Running 10000 simulations.:  96%|█████████▌| 9595/10000 [00:39<00:01, 235.57it/s]Running 10000 simulations.:  96%|█████████▌| 9619/10000 [00:39<00:01, 235.81it/s]Running 10000 simulations.:  96%|█████████▋| 9643/10000 [00:39<00:01, 236.02it/s]Running 10000 simulations.:  97%|█████████▋| 9667/10000 [00:40<00:01, 236.43it/s]Running 10000 simulations.:  97%|█████████▋| 9692/10000 [00:40<00:01, 238.56it/s]Running 10000 simulations.:  97%|█████████▋| 9717/10000 [00:40<00:01, 239.99it/s]Running 10000 simulations.:  97%|█████████▋| 9742/10000 [00:40<00:01, 240.97it/s]Running 10000 simulations.:  98%|█████████▊| 9767/10000 [00:40<00:00, 242.44it/s]Running 10000 simulations.:  98%|█████████▊| 9792/10000 [00:40<00:00, 242.99it/s]Running 10000 simulations.:  98%|█████████▊| 9817/10000 [00:40<00:00, 243.02it/s]Running 10000 simulations.:  98%|█████████▊| 9842/10000 [00:40<00:00, 243.34it/s]Running 10000 simulations.:  99%|█████████▊| 9867/10000 [00:40<00:00, 244.93it/s]Running 10000 simulations.:  99%|█████████▉| 9892/10000 [00:40<00:00, 244.90it/s]Running 10000 simulations.:  99%|█████████▉| 9917/10000 [00:41<00:00, 244.39it/s]Running 10000 simulations.:  99%|█████████▉| 9942/10000 [00:41<00:00, 244.02it/s]Running 10000 simulations.: 100%|█████████▉| 9967/10000 [00:41<00:00, 244.70it/s]Running 10000 simulations.: 100%|█████████▉| 9992/10000 [00:41<00:00, 245.11it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 241.59it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 27/10000 [00:00<00:38, 260.36it/s]Running 10000 simulations.:   1%|          | 53/10000 [00:00<00:38, 258.68it/s]Running 10000 simulations.:   1%|          | 79/10000 [00:00<00:38, 258.42it/s]Running 10000 simulations.:   1%|          | 105/10000 [00:00<00:38, 257.54it/s]Running 10000 simulations.:   1%|▏         | 131/10000 [00:00<00:38, 256.78it/s]Running 10000 simulations.:   2%|▏         | 157/10000 [00:00<00:38, 256.31it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:00<00:39, 245.68it/s]Running 10000 simulations.:   2%|▏         | 205/10000 [00:00<00:39, 246.19it/s]Running 10000 simulations.:   2%|▏         | 231/10000 [00:00<00:39, 248.86it/s]Running 10000 simulations.:   3%|▎         | 257/10000 [00:01<00:38, 251.00it/s]Running 10000 simulations.:   3%|▎         | 283/10000 [00:01<00:38, 252.61it/s]Running 10000 simulations.:   3%|▎         | 309/10000 [00:01<00:38, 252.43it/s]Running 10000 simulations.:   3%|▎         | 334/10000 [00:01<00:38, 251.00it/s]Running 10000 simulations.:   4%|▎         | 359/10000 [00:01<00:38, 249.72it/s]Running 10000 simulations.:   4%|▍         | 384/10000 [00:01<00:38, 248.43it/s]Running 10000 simulations.:   4%|▍         | 409/10000 [00:01<00:38, 248.66it/s]Running 10000 simulations.:   4%|▍         | 434/10000 [00:01<00:38, 248.92it/s]Running 10000 simulations.:   5%|▍         | 460/10000 [00:01<00:38, 249.63it/s]Running 10000 simulations.:   5%|▍         | 485/10000 [00:01<00:38, 248.17it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:02<00:38, 248.06it/s]Running 10000 simulations.:   5%|▌         | 536/10000 [00:02<00:38, 248.81it/s]Running 10000 simulations.:   6%|▌         | 562/10000 [00:02<00:37, 249.58it/s]Running 10000 simulations.:   6%|▌         | 587/10000 [00:02<00:37, 249.09it/s]Running 10000 simulations.:   6%|▌         | 613/10000 [00:02<00:37, 249.75it/s]Running 10000 simulations.:   6%|▋         | 638/10000 [00:02<00:37, 249.74it/s]Running 10000 simulations.:   7%|▋         | 664/10000 [00:02<00:37, 250.49it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:02<00:36, 251.70it/s]Running 10000 simulations.:   7%|▋         | 716/10000 [00:02<00:37, 250.26it/s]Running 10000 simulations.:   7%|▋         | 742/10000 [00:02<00:37, 247.01it/s]Running 10000 simulations.:   8%|▊         | 767/10000 [00:03<00:37, 247.51it/s]Running 10000 simulations.:   8%|▊         | 792/10000 [00:03<00:37, 247.15it/s]Running 10000 simulations.:   8%|▊         | 817/10000 [00:03<00:37, 247.51it/s]Running 10000 simulations.:   8%|▊         | 842/10000 [00:03<00:36, 247.59it/s]Running 10000 simulations.:   9%|▊         | 867/10000 [00:03<00:36, 247.44it/s]Running 10000 simulations.:   9%|▉         | 892/10000 [00:03<00:36, 247.33it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:03<00:36, 248.18it/s]Running 10000 simulations.:   9%|▉         | 943/10000 [00:03<00:36, 248.48it/s]Running 10000 simulations.:  10%|▉         | 968/10000 [00:03<00:36, 246.92it/s]Running 10000 simulations.:  10%|▉         | 993/10000 [00:03<00:36, 247.52it/s]Running 10000 simulations.:  10%|█         | 1018/10000 [00:04<00:36, 246.91it/s]Running 10000 simulations.:  10%|█         | 1043/10000 [00:04<00:36, 246.84it/s]Running 10000 simulations.:  11%|█         | 1068/10000 [00:04<00:36, 246.66it/s]Running 10000 simulations.:  11%|█         | 1093/10000 [00:04<00:36, 246.38it/s]Running 10000 simulations.:  11%|█         | 1118/10000 [00:04<00:36, 246.49it/s]Running 10000 simulations.:  11%|█▏        | 1143/10000 [00:04<00:35, 247.09it/s]Running 10000 simulations.:  12%|█▏        | 1168/10000 [00:04<00:35, 247.93it/s]Running 10000 simulations.:  12%|█▏        | 1193/10000 [00:04<00:35, 245.74it/s]Running 10000 simulations.:  12%|█▏        | 1218/10000 [00:04<00:36, 243.89it/s]Running 10000 simulations.:  12%|█▏        | 1243/10000 [00:04<00:35, 244.72it/s]Running 10000 simulations.:  13%|█▎        | 1268/10000 [00:05<00:35, 245.03it/s]Running 10000 simulations.:  13%|█▎        | 1293/10000 [00:05<00:35, 246.10it/s]Running 10000 simulations.:  13%|█▎        | 1318/10000 [00:05<00:35, 246.11it/s]Running 10000 simulations.:  13%|█▎        | 1343/10000 [00:05<00:35, 245.74it/s]Running 10000 simulations.:  14%|█▎        | 1368/10000 [00:05<00:35, 244.96it/s]Running 10000 simulations.:  14%|█▍        | 1393/10000 [00:05<00:35, 243.01it/s]Running 10000 simulations.:  14%|█▍        | 1418/10000 [00:05<00:35, 244.23it/s]Running 10000 simulations.:  14%|█▍        | 1443/10000 [00:05<00:35, 243.43it/s]Running 10000 simulations.:  15%|█▍        | 1468/10000 [00:05<00:35, 243.52it/s]Running 10000 simulations.:  15%|█▍        | 1493/10000 [00:06<00:34, 244.13it/s]Running 10000 simulations.:  15%|█▌        | 1518/10000 [00:06<00:34, 244.71it/s]Running 10000 simulations.:  15%|█▌        | 1543/10000 [00:06<00:34, 244.56it/s]Running 10000 simulations.:  16%|█▌        | 1568/10000 [00:06<00:34, 244.80it/s]Running 10000 simulations.:  16%|█▌        | 1593/10000 [00:06<00:34, 245.03it/s]Running 10000 simulations.:  16%|█▌        | 1618/10000 [00:06<00:34, 246.36it/s]Running 10000 simulations.:  16%|█▋        | 1643/10000 [00:06<00:33, 246.82it/s]Running 10000 simulations.:  17%|█▋        | 1668/10000 [00:06<00:33, 246.31it/s]Running 10000 simulations.:  17%|█▋        | 1693/10000 [00:06<00:33, 244.52it/s]Running 10000 simulations.:  17%|█▋        | 1718/10000 [00:06<00:33, 245.58it/s]Running 10000 simulations.:  17%|█▋        | 1743/10000 [00:07<00:33, 245.21it/s]Running 10000 simulations.:  18%|█▊        | 1768/10000 [00:07<00:33, 245.91it/s]Running 10000 simulations.:  18%|█▊        | 1793/10000 [00:07<00:33, 246.96it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:07<00:33, 246.23it/s]Running 10000 simulations.:  18%|█▊        | 1843/10000 [00:07<00:33, 245.11it/s]Running 10000 simulations.:  19%|█▊        | 1868/10000 [00:07<00:33, 243.26it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:07<00:33, 243.48it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:07<00:33, 242.22it/s]Running 10000 simulations.:  19%|█▉        | 1943/10000 [00:07<00:33, 243.85it/s]Running 10000 simulations.:  20%|█▉        | 1968/10000 [00:07<00:32, 243.79it/s]Running 10000 simulations.:  20%|█▉        | 1993/10000 [00:08<00:32, 244.14it/s]Running 10000 simulations.:  20%|██        | 2018/10000 [00:08<00:32, 244.65it/s]Running 10000 simulations.:  20%|██        | 2043/10000 [00:08<00:32, 245.10it/s]Running 10000 simulations.:  21%|██        | 2068/10000 [00:08<00:32, 245.65it/s]Running 10000 simulations.:  21%|██        | 2094/10000 [00:08<00:32, 246.99it/s]Running 10000 simulations.:  21%|██        | 2119/10000 [00:08<00:31, 246.79it/s]Running 10000 simulations.:  21%|██▏       | 2144/10000 [00:08<00:32, 245.41it/s]Running 10000 simulations.:  22%|██▏       | 2169/10000 [00:08<00:32, 242.98it/s]Running 10000 simulations.:  22%|██▏       | 2194/10000 [00:08<00:32, 243.56it/s]Running 10000 simulations.:  22%|██▏       | 2219/10000 [00:08<00:31, 244.71it/s]Running 10000 simulations.:  22%|██▏       | 2244/10000 [00:09<00:31, 245.30it/s]Running 10000 simulations.:  23%|██▎       | 2269/10000 [00:09<00:31, 245.25it/s]Running 10000 simulations.:  23%|██▎       | 2294/10000 [00:09<00:31, 243.34it/s]Running 10000 simulations.:  23%|██▎       | 2319/10000 [00:09<00:31, 244.09it/s]Running 10000 simulations.:  23%|██▎       | 2344/10000 [00:09<00:31, 244.13it/s]Running 10000 simulations.:  24%|██▎       | 2369/10000 [00:09<00:31, 245.05it/s]Running 10000 simulations.:  24%|██▍       | 2394/10000 [00:09<00:30, 245.91it/s]Running 10000 simulations.:  24%|██▍       | 2419/10000 [00:09<00:30, 246.14it/s]Running 10000 simulations.:  24%|██▍       | 2444/10000 [00:09<00:30, 245.65it/s]Running 10000 simulations.:  25%|██▍       | 2469/10000 [00:10<00:30, 245.08it/s]Running 10000 simulations.:  25%|██▍       | 2494/10000 [00:10<00:30, 246.34it/s]Running 10000 simulations.:  25%|██▌       | 2519/10000 [00:10<00:30, 246.74it/s]Running 10000 simulations.:  25%|██▌       | 2544/10000 [00:10<00:30, 246.26it/s]Running 10000 simulations.:  26%|██▌       | 2569/10000 [00:10<00:30, 246.82it/s]Running 10000 simulations.:  26%|██▌       | 2594/10000 [00:10<00:29, 247.45it/s]Running 10000 simulations.:  26%|██▌       | 2619/10000 [00:10<00:29, 247.19it/s]Running 10000 simulations.:  26%|██▋       | 2644/10000 [00:10<00:29, 246.19it/s]Running 10000 simulations.:  27%|██▋       | 2669/10000 [00:10<00:29, 245.32it/s]Running 10000 simulations.:  27%|██▋       | 2694/10000 [00:10<00:29, 243.59it/s]Running 10000 simulations.:  27%|██▋       | 2719/10000 [00:11<00:29, 243.76it/s]Running 10000 simulations.:  27%|██▋       | 2744/10000 [00:11<00:29, 243.59it/s]Running 10000 simulations.:  28%|██▊       | 2769/10000 [00:11<00:29, 243.54it/s]Running 10000 simulations.:  28%|██▊       | 2794/10000 [00:11<00:29, 243.84it/s]Running 10000 simulations.:  28%|██▊       | 2819/10000 [00:11<00:29, 243.82it/s]Running 10000 simulations.:  28%|██▊       | 2844/10000 [00:11<00:29, 243.84it/s]Running 10000 simulations.:  29%|██▊       | 2869/10000 [00:11<00:29, 244.09it/s]Running 10000 simulations.:  29%|██▉       | 2894/10000 [00:11<00:29, 244.66it/s]Running 10000 simulations.:  29%|██▉       | 2919/10000 [00:11<00:29, 243.46it/s]Running 10000 simulations.:  29%|██▉       | 2944/10000 [00:11<00:29, 241.78it/s]Running 10000 simulations.:  30%|██▉       | 2969/10000 [00:12<00:29, 242.08it/s]Running 10000 simulations.:  30%|██▉       | 2994/10000 [00:12<00:28, 242.44it/s]Running 10000 simulations.:  30%|███       | 3019/10000 [00:12<00:28, 242.59it/s]Running 10000 simulations.:  30%|███       | 3044/10000 [00:12<00:28, 241.35it/s]Running 10000 simulations.:  31%|███       | 3069/10000 [00:12<00:28, 241.30it/s]Running 10000 simulations.:  31%|███       | 3094/10000 [00:12<00:28, 242.83it/s]Running 10000 simulations.:  31%|███       | 3119/10000 [00:12<00:28, 244.90it/s]Running 10000 simulations.:  31%|███▏      | 3144/10000 [00:12<00:28, 244.23it/s]Running 10000 simulations.:  32%|███▏      | 3169/10000 [00:12<00:28, 243.21it/s]Running 10000 simulations.:  32%|███▏      | 3194/10000 [00:12<00:27, 243.22it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:13<00:27, 243.77it/s]Running 10000 simulations.:  32%|███▏      | 3244/10000 [00:13<00:27, 243.79it/s]Running 10000 simulations.:  33%|███▎      | 3269/10000 [00:13<00:27, 243.90it/s]Running 10000 simulations.:  33%|███▎      | 3294/10000 [00:13<00:27, 244.84it/s]Running 10000 simulations.:  33%|███▎      | 3319/10000 [00:13<00:27, 246.30it/s]Running 10000 simulations.:  33%|███▎      | 3344/10000 [00:13<00:26, 246.86it/s]Running 10000 simulations.:  34%|███▎      | 3369/10000 [00:13<00:26, 246.94it/s]Running 10000 simulations.:  34%|███▍      | 3394/10000 [00:13<00:27, 243.95it/s]Running 10000 simulations.:  34%|███▍      | 3419/10000 [00:13<00:27, 243.65it/s]Running 10000 simulations.:  34%|███▍      | 3444/10000 [00:13<00:26, 243.73it/s]Running 10000 simulations.:  35%|███▍      | 3469/10000 [00:14<00:26, 243.91it/s]Running 10000 simulations.:  35%|███▍      | 3494/10000 [00:14<00:26, 244.27it/s]Running 10000 simulations.:  35%|███▌      | 3519/10000 [00:14<00:26, 245.39it/s]Running 10000 simulations.:  35%|███▌      | 3544/10000 [00:14<00:26, 245.91it/s]Running 10000 simulations.:  36%|███▌      | 3569/10000 [00:14<00:26, 247.02it/s]Running 10000 simulations.:  36%|███▌      | 3594/10000 [00:14<00:25, 247.66it/s]Running 10000 simulations.:  36%|███▌      | 3619/10000 [00:14<00:26, 245.11it/s]Running 10000 simulations.:  36%|███▋      | 3644/10000 [00:14<00:26, 242.34it/s]Running 10000 simulations.:  37%|███▋      | 3669/10000 [00:14<00:26, 242.81it/s]Running 10000 simulations.:  37%|███▋      | 3694/10000 [00:15<00:25, 242.60it/s]Running 10000 simulations.:  37%|███▋      | 3719/10000 [00:15<00:25, 242.91it/s]Running 10000 simulations.:  37%|███▋      | 3744/10000 [00:15<00:25, 242.87it/s]Running 10000 simulations.:  38%|███▊      | 3769/10000 [00:15<00:25, 242.67it/s]Running 10000 simulations.:  38%|███▊      | 3794/10000 [00:15<00:25, 242.74it/s]Running 10000 simulations.:  38%|███▊      | 3819/10000 [00:15<00:25, 243.22it/s]Running 10000 simulations.:  38%|███▊      | 3844/10000 [00:15<00:25, 242.34it/s]Running 10000 simulations.:  39%|███▊      | 3869/10000 [00:15<00:25, 241.81it/s]Running 10000 simulations.:  39%|███▉      | 3894/10000 [00:15<00:25, 243.03it/s]Running 10000 simulations.:  39%|███▉      | 3919/10000 [00:15<00:25, 242.35it/s]Running 10000 simulations.:  39%|███▉      | 3944/10000 [00:16<00:25, 240.25it/s]Running 10000 simulations.:  40%|███▉      | 3969/10000 [00:16<00:24, 241.49it/s]Running 10000 simulations.:  40%|███▉      | 3994/10000 [00:16<00:24, 243.49it/s]Running 10000 simulations.:  40%|████      | 4019/10000 [00:16<00:24, 243.62it/s]Running 10000 simulations.:  40%|████      | 4044/10000 [00:16<00:24, 241.69it/s]Running 10000 simulations.:  41%|████      | 4069/10000 [00:16<00:24, 242.82it/s]Running 10000 simulations.:  41%|████      | 4094/10000 [00:16<00:24, 243.49it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:16<00:24, 244.19it/s]Running 10000 simulations.:  41%|████▏     | 4144/10000 [00:16<00:24, 243.88it/s]Running 10000 simulations.:  42%|████▏     | 4169/10000 [00:16<00:23, 243.15it/s]Running 10000 simulations.:  42%|████▏     | 4194/10000 [00:17<00:23, 244.32it/s]Running 10000 simulations.:  42%|████▏     | 4219/10000 [00:17<00:23, 244.92it/s]Running 10000 simulations.:  42%|████▏     | 4244/10000 [00:17<00:23, 244.27it/s]Running 10000 simulations.:  43%|████▎     | 4269/10000 [00:17<00:23, 244.53it/s]Running 10000 simulations.:  43%|████▎     | 4294/10000 [00:17<00:23, 244.43it/s]Running 10000 simulations.:  43%|████▎     | 4319/10000 [00:17<00:23, 245.78it/s]Running 10000 simulations.:  43%|████▎     | 4344/10000 [00:17<00:22, 247.02it/s]Running 10000 simulations.:  44%|████▎     | 4369/10000 [00:17<00:22, 245.94it/s]Running 10000 simulations.:  44%|████▍     | 4394/10000 [00:17<00:22, 245.09it/s]Running 10000 simulations.:  44%|████▍     | 4419/10000 [00:17<00:23, 241.07it/s]Running 10000 simulations.:  44%|████▍     | 4444/10000 [00:18<00:23, 241.42it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:18<00:22, 240.85it/s]Running 10000 simulations.:  45%|████▍     | 4494/10000 [00:18<00:22, 239.49it/s]Running 10000 simulations.:  45%|████▌     | 4519/10000 [00:18<00:22, 241.50it/s]Running 10000 simulations.:  45%|████▌     | 4544/10000 [00:18<00:22, 243.72it/s]Running 10000 simulations.:  46%|████▌     | 4570/10000 [00:18<00:22, 245.66it/s]Running 10000 simulations.:  46%|████▌     | 4595/10000 [00:18<00:22, 245.66it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:18<00:21, 245.10it/s]Running 10000 simulations.:  46%|████▋     | 4645/10000 [00:18<00:22, 241.31it/s]Running 10000 simulations.:  47%|████▋     | 4670/10000 [00:19<00:22, 237.96it/s]Running 10000 simulations.:  47%|████▋     | 4694/10000 [00:19<00:22, 237.56it/s]Running 10000 simulations.:  47%|████▋     | 4719/10000 [00:19<00:22, 238.58it/s]Running 10000 simulations.:  47%|████▋     | 4744/10000 [00:19<00:21, 239.63it/s]Running 10000 simulations.:  48%|████▊     | 4769/10000 [00:19<00:21, 240.38it/s]Running 10000 simulations.:  48%|████▊     | 4794/10000 [00:19<00:21, 240.58it/s]Running 10000 simulations.:  48%|████▊     | 4819/10000 [00:19<00:21, 240.61it/s]Running 10000 simulations.:  48%|████▊     | 4844/10000 [00:19<00:21, 240.76it/s]Running 10000 simulations.:  49%|████▊     | 4869/10000 [00:19<00:21, 240.68it/s]Running 10000 simulations.:  49%|████▉     | 4894/10000 [00:19<00:21, 239.35it/s]Running 10000 simulations.:  49%|████▉     | 4919/10000 [00:20<00:21, 240.10it/s]Running 10000 simulations.:  49%|████▉     | 4944/10000 [00:20<00:20, 241.24it/s]Running 10000 simulations.:  50%|████▉     | 4969/10000 [00:20<00:20, 241.57it/s]Running 10000 simulations.:  50%|████▉     | 4994/10000 [00:20<00:20, 242.00it/s]Running 10000 simulations.:  50%|█████     | 5019/10000 [00:20<00:20, 241.91it/s]Running 10000 simulations.:  50%|█████     | 5044/10000 [00:20<00:20, 241.59it/s]Running 10000 simulations.:  51%|█████     | 5069/10000 [00:20<00:20, 242.42it/s]Running 10000 simulations.:  51%|█████     | 5094/10000 [00:20<00:20, 241.34it/s]Running 10000 simulations.:  51%|█████     | 5119/10000 [00:20<00:20, 239.92it/s]Running 10000 simulations.:  51%|█████▏    | 5144/10000 [00:21<00:20, 240.84it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:21<00:19, 241.93it/s]Running 10000 simulations.:  52%|█████▏    | 5194/10000 [00:21<00:19, 242.30it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:21<00:19, 241.81it/s]Running 10000 simulations.:  52%|█████▏    | 5244/10000 [00:21<00:19, 241.66it/s]Running 10000 simulations.:  53%|█████▎    | 5269/10000 [00:21<00:19, 241.81it/s]Running 10000 simulations.:  53%|█████▎    | 5294/10000 [00:21<00:19, 242.17it/s]Running 10000 simulations.:  53%|█████▎    | 5319/10000 [00:21<00:19, 242.56it/s]Running 10000 simulations.:  53%|█████▎    | 5344/10000 [00:21<00:19, 241.37it/s]Running 10000 simulations.:  54%|█████▎    | 5369/10000 [00:21<00:19, 242.47it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:22<00:18, 242.47it/s]Running 10000 simulations.:  54%|█████▍    | 5419/10000 [00:22<00:18, 242.01it/s]Running 10000 simulations.:  54%|█████▍    | 5444/10000 [00:22<00:18, 241.79it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:22<00:18, 241.88it/s]Running 10000 simulations.:  55%|█████▍    | 5494/10000 [00:22<00:18, 241.48it/s]Running 10000 simulations.:  55%|█████▌    | 5519/10000 [00:22<00:18, 241.75it/s]Running 10000 simulations.:  55%|█████▌    | 5544/10000 [00:22<00:18, 242.10it/s]Running 10000 simulations.:  56%|█████▌    | 5569/10000 [00:22<00:18, 241.33it/s]Running 10000 simulations.:  56%|█████▌    | 5594/10000 [00:22<00:18, 239.55it/s]Running 10000 simulations.:  56%|█████▌    | 5619/10000 [00:22<00:18, 239.83it/s]Running 10000 simulations.:  56%|█████▋    | 5644/10000 [00:23<00:18, 240.65it/s]Running 10000 simulations.:  57%|█████▋    | 5669/10000 [00:23<00:18, 240.44it/s]Running 10000 simulations.:  57%|█████▋    | 5694/10000 [00:23<00:17, 240.80it/s]Running 10000 simulations.:  57%|█████▋    | 5719/10000 [00:23<00:17, 240.50it/s]Running 10000 simulations.:  57%|█████▋    | 5744/10000 [00:23<00:17, 240.92it/s]Running 10000 simulations.:  58%|█████▊    | 5769/10000 [00:23<00:17, 241.68it/s]Running 10000 simulations.:  58%|█████▊    | 5794/10000 [00:23<00:17, 242.01it/s]Running 10000 simulations.:  58%|█████▊    | 5819/10000 [00:23<00:17, 240.01it/s]Running 10000 simulations.:  58%|█████▊    | 5844/10000 [00:23<00:17, 239.87it/s]Running 10000 simulations.:  59%|█████▊    | 5869/10000 [00:24<00:17, 240.00it/s]Running 10000 simulations.:  59%|█████▉    | 5894/10000 [00:24<00:17, 239.65it/s]Running 10000 simulations.:  59%|█████▉    | 5919/10000 [00:24<00:16, 240.31it/s]Running 10000 simulations.:  59%|█████▉    | 5944/10000 [00:24<00:16, 240.61it/s]Running 10000 simulations.:  60%|█████▉    | 5969/10000 [00:24<00:16, 239.31it/s]Running 10000 simulations.:  60%|█████▉    | 5993/10000 [00:24<00:16, 238.78it/s]Running 10000 simulations.:  60%|██████    | 6018/10000 [00:24<00:16, 239.38it/s]Running 10000 simulations.:  60%|██████    | 6043/10000 [00:24<00:16, 240.50it/s]Running 10000 simulations.:  61%|██████    | 6068/10000 [00:24<00:16, 241.30it/s]Running 10000 simulations.:  61%|██████    | 6093/10000 [00:24<00:16, 240.45it/s]Running 10000 simulations.:  61%|██████    | 6118/10000 [00:25<00:16, 239.85it/s]Running 10000 simulations.:  61%|██████▏   | 6143/10000 [00:25<00:16, 240.37it/s]Running 10000 simulations.:  62%|██████▏   | 6168/10000 [00:25<00:15, 240.93it/s]Running 10000 simulations.:  62%|██████▏   | 6193/10000 [00:25<00:15, 241.15it/s]Running 10000 simulations.:  62%|██████▏   | 6218/10000 [00:25<00:15, 241.04it/s]Running 10000 simulations.:  62%|██████▏   | 6243/10000 [00:25<00:15, 241.06it/s]Running 10000 simulations.:  63%|██████▎   | 6268/10000 [00:25<00:15, 241.88it/s]Running 10000 simulations.:  63%|██████▎   | 6293/10000 [00:25<00:15, 242.67it/s]Running 10000 simulations.:  63%|██████▎   | 6318/10000 [00:25<00:15, 243.12it/s]Running 10000 simulations.:  63%|██████▎   | 6343/10000 [00:25<00:15, 242.79it/s]Running 10000 simulations.:  64%|██████▎   | 6368/10000 [00:26<00:15, 241.30it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:26<00:14, 241.43it/s]Running 10000 simulations.:  64%|██████▍   | 6418/10000 [00:26<00:14, 240.98it/s]Running 10000 simulations.:  64%|██████▍   | 6443/10000 [00:26<00:14, 240.85it/s]Running 10000 simulations.:  65%|██████▍   | 6468/10000 [00:26<00:14, 240.95it/s]Running 10000 simulations.:  65%|██████▍   | 6493/10000 [00:26<00:14, 240.54it/s]Running 10000 simulations.:  65%|██████▌   | 6518/10000 [00:26<00:14, 240.72it/s]Running 10000 simulations.:  65%|██████▌   | 6543/10000 [00:26<00:14, 241.63it/s]Running 10000 simulations.:  66%|██████▌   | 6568/10000 [00:26<00:14, 241.12it/s]Running 10000 simulations.:  66%|██████▌   | 6593/10000 [00:27<00:14, 240.59it/s]Running 10000 simulations.:  66%|██████▌   | 6618/10000 [00:27<00:13, 241.78it/s]Running 10000 simulations.:  66%|██████▋   | 6643/10000 [00:27<00:13, 241.47it/s]Running 10000 simulations.:  67%|██████▋   | 6668/10000 [00:27<00:13, 241.29it/s]Running 10000 simulations.:  67%|██████▋   | 6693/10000 [00:27<00:13, 241.50it/s]Running 10000 simulations.:  67%|██████▋   | 6718/10000 [00:27<00:13, 241.42it/s]Running 10000 simulations.:  67%|██████▋   | 6743/10000 [00:27<00:13, 239.82it/s]Running 10000 simulations.:  68%|██████▊   | 6768/10000 [00:27<00:13, 240.87it/s]Running 10000 simulations.:  68%|██████▊   | 6793/10000 [00:27<00:13, 241.48it/s]Running 10000 simulations.:  68%|██████▊   | 6818/10000 [00:27<00:13, 241.01it/s]Running 10000 simulations.:  68%|██████▊   | 6843/10000 [00:28<00:13, 241.26it/s]Running 10000 simulations.:  69%|██████▊   | 6868/10000 [00:28<00:12, 241.68it/s]Running 10000 simulations.:  69%|██████▉   | 6893/10000 [00:28<00:12, 242.07it/s]Running 10000 simulations.:  69%|██████▉   | 6918/10000 [00:28<00:12, 242.32it/s]Running 10000 simulations.:  69%|██████▉   | 6943/10000 [00:28<00:12, 241.96it/s]Running 10000 simulations.:  70%|██████▉   | 6968/10000 [00:28<00:12, 241.61it/s]Running 10000 simulations.:  70%|██████▉   | 6993/10000 [00:28<00:12, 242.84it/s]Running 10000 simulations.:  70%|███████   | 7018/10000 [00:28<00:12, 243.52it/s]Running 10000 simulations.:  70%|███████   | 7043/10000 [00:28<00:12, 241.48it/s]Running 10000 simulations.:  71%|███████   | 7068/10000 [00:28<00:12, 237.76it/s]Running 10000 simulations.:  71%|███████   | 7092/10000 [00:29<00:12, 236.24it/s]Running 10000 simulations.:  71%|███████   | 7116/10000 [00:29<00:12, 235.83it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:29<00:12, 236.70it/s]Running 10000 simulations.:  72%|███████▏  | 7164/10000 [00:29<00:11, 236.94it/s]Running 10000 simulations.:  72%|███████▏  | 7189/10000 [00:29<00:11, 240.06it/s]Running 10000 simulations.:  72%|███████▏  | 7214/10000 [00:29<00:11, 240.34it/s]Running 10000 simulations.:  72%|███████▏  | 7239/10000 [00:29<00:11, 238.46it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:29<00:11, 241.55it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:29<00:11, 239.42it/s]Running 10000 simulations.:  73%|███████▎  | 7313/10000 [00:30<00:11, 234.04it/s]Running 10000 simulations.:  73%|███████▎  | 7337/10000 [00:30<00:11, 234.84it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:30<00:11, 235.39it/s]Running 10000 simulations.:  74%|███████▍  | 7385/10000 [00:30<00:11, 235.81it/s]Running 10000 simulations.:  74%|███████▍  | 7410/10000 [00:30<00:10, 237.52it/s]Running 10000 simulations.:  74%|███████▍  | 7435/10000 [00:30<00:10, 240.78it/s]Running 10000 simulations.:  75%|███████▍  | 7460/10000 [00:30<00:10, 243.02it/s]Running 10000 simulations.:  75%|███████▍  | 7485/10000 [00:30<00:10, 235.57it/s]Running 10000 simulations.:  75%|███████▌  | 7509/10000 [00:30<00:10, 235.98it/s]Running 10000 simulations.:  75%|███████▌  | 7533/10000 [00:30<00:10, 234.89it/s]Running 10000 simulations.:  76%|███████▌  | 7557/10000 [00:31<00:10, 233.99it/s]Running 10000 simulations.:  76%|███████▌  | 7581/10000 [00:31<00:10, 235.50it/s]Running 10000 simulations.:  76%|███████▌  | 7605/10000 [00:31<00:10, 235.70it/s]Running 10000 simulations.:  76%|███████▋  | 7629/10000 [00:31<00:10, 236.09it/s]Running 10000 simulations.:  77%|███████▋  | 7654/10000 [00:31<00:09, 237.84it/s]Running 10000 simulations.:  77%|███████▋  | 7679/10000 [00:31<00:09, 239.53it/s]Running 10000 simulations.:  77%|███████▋  | 7704/10000 [00:31<00:09, 240.17it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:31<00:09, 240.69it/s]Running 10000 simulations.:  78%|███████▊  | 7754/10000 [00:31<00:09, 237.51it/s]Running 10000 simulations.:  78%|███████▊  | 7778/10000 [00:31<00:09, 233.34it/s]Running 10000 simulations.:  78%|███████▊  | 7802/10000 [00:32<00:09, 234.29it/s]Running 10000 simulations.:  78%|███████▊  | 7826/10000 [00:32<00:09, 234.91it/s]Running 10000 simulations.:  78%|███████▊  | 7850/10000 [00:32<00:09, 235.66it/s]Running 10000 simulations.:  79%|███████▊  | 7874/10000 [00:32<00:09, 236.18it/s]Running 10000 simulations.:  79%|███████▉  | 7899/10000 [00:32<00:08, 239.42it/s]Running 10000 simulations.:  79%|███████▉  | 7924/10000 [00:32<00:08, 240.69it/s]Running 10000 simulations.:  79%|███████▉  | 7949/10000 [00:32<00:08, 239.99it/s]Running 10000 simulations.:  80%|███████▉  | 7974/10000 [00:32<00:08, 239.92it/s]Running 10000 simulations.:  80%|███████▉  | 7999/10000 [00:32<00:08, 240.32it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:33<00:08, 242.20it/s]Running 10000 simulations.:  80%|████████  | 8049/10000 [00:33<00:07, 244.29it/s]Running 10000 simulations.:  81%|████████  | 8074/10000 [00:33<00:07, 245.09it/s]Running 10000 simulations.:  81%|████████  | 8099/10000 [00:33<00:07, 243.60it/s]Running 10000 simulations.:  81%|████████  | 8124/10000 [00:33<00:07, 242.13it/s]Running 10000 simulations.:  81%|████████▏ | 8149/10000 [00:33<00:07, 243.10it/s]Running 10000 simulations.:  82%|████████▏ | 8174/10000 [00:33<00:07, 243.98it/s]Running 10000 simulations.:  82%|████████▏ | 8199/10000 [00:33<00:07, 244.41it/s]Running 10000 simulations.:  82%|████████▏ | 8224/10000 [00:33<00:07, 244.89it/s]Running 10000 simulations.:  82%|████████▏ | 8249/10000 [00:33<00:07, 244.20it/s]Running 10000 simulations.:  83%|████████▎ | 8274/10000 [00:34<00:07, 244.81it/s]Running 10000 simulations.:  83%|████████▎ | 8299/10000 [00:34<00:06, 245.24it/s]Running 10000 simulations.:  83%|████████▎ | 8324/10000 [00:34<00:06, 244.13it/s]Running 10000 simulations.:  83%|████████▎ | 8349/10000 [00:34<00:06, 242.92it/s]Running 10000 simulations.:  84%|████████▎ | 8374/10000 [00:34<00:06, 243.86it/s]Running 10000 simulations.:  84%|████████▍ | 8399/10000 [00:34<00:06, 243.49it/s]Running 10000 simulations.:  84%|████████▍ | 8424/10000 [00:34<00:06, 242.56it/s]Running 10000 simulations.:  84%|████████▍ | 8449/10000 [00:34<00:06, 242.64it/s]Running 10000 simulations.:  85%|████████▍ | 8474/10000 [00:34<00:06, 243.09it/s]Running 10000 simulations.:  85%|████████▍ | 8499/10000 [00:34<00:06, 242.48it/s]Running 10000 simulations.:  85%|████████▌ | 8524/10000 [00:35<00:06, 242.96it/s]Running 10000 simulations.:  85%|████████▌ | 8549/10000 [00:35<00:05, 242.79it/s]Running 10000 simulations.:  86%|████████▌ | 8574/10000 [00:35<00:05, 242.09it/s]Running 10000 simulations.:  86%|████████▌ | 8599/10000 [00:35<00:05, 239.71it/s]Running 10000 simulations.:  86%|████████▌ | 8624/10000 [00:35<00:05, 240.46it/s]Running 10000 simulations.:  86%|████████▋ | 8649/10000 [00:35<00:05, 241.25it/s]Running 10000 simulations.:  87%|████████▋ | 8674/10000 [00:35<00:05, 241.91it/s]Running 10000 simulations.:  87%|████████▋ | 8699/10000 [00:35<00:05, 243.22it/s]Running 10000 simulations.:  87%|████████▋ | 8724/10000 [00:35<00:05, 242.66it/s]Running 10000 simulations.:  87%|████████▋ | 8749/10000 [00:35<00:05, 242.60it/s]Running 10000 simulations.:  88%|████████▊ | 8774/10000 [00:36<00:05, 242.67it/s]Running 10000 simulations.:  88%|████████▊ | 8799/10000 [00:36<00:04, 241.73it/s]Running 10000 simulations.:  88%|████████▊ | 8824/10000 [00:36<00:04, 240.49it/s]Running 10000 simulations.:  88%|████████▊ | 8849/10000 [00:36<00:04, 241.13it/s]Running 10000 simulations.:  89%|████████▊ | 8874/10000 [00:36<00:04, 241.52it/s]Running 10000 simulations.:  89%|████████▉ | 8899/10000 [00:36<00:04, 241.35it/s]Running 10000 simulations.:  89%|████████▉ | 8924/10000 [00:36<00:04, 241.26it/s]Running 10000 simulations.:  89%|████████▉ | 8949/10000 [00:36<00:04, 241.24it/s]Running 10000 simulations.:  90%|████████▉ | 8974/10000 [00:36<00:04, 240.94it/s]Running 10000 simulations.:  90%|████████▉ | 8999/10000 [00:37<00:04, 240.30it/s]Running 10000 simulations.:  90%|█████████ | 9024/10000 [00:37<00:04, 239.26it/s]Running 10000 simulations.:  90%|█████████ | 9048/10000 [00:37<00:04, 236.44it/s]Running 10000 simulations.:  91%|█████████ | 9072/10000 [00:37<00:03, 237.00it/s]Running 10000 simulations.:  91%|█████████ | 9096/10000 [00:37<00:03, 237.20it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:37<00:03, 237.64it/s]Running 10000 simulations.:  91%|█████████▏| 9144/10000 [00:37<00:03, 238.08it/s]Running 10000 simulations.:  92%|█████████▏| 9169/10000 [00:37<00:03, 239.71it/s]Running 10000 simulations.:  92%|█████████▏| 9194/10000 [00:37<00:03, 241.19it/s]Running 10000 simulations.:  92%|█████████▏| 9219/10000 [00:37<00:03, 242.69it/s]Running 10000 simulations.:  92%|█████████▏| 9244/10000 [00:38<00:03, 242.62it/s]Running 10000 simulations.:  93%|█████████▎| 9269/10000 [00:38<00:03, 238.32it/s]Running 10000 simulations.:  93%|█████████▎| 9293/10000 [00:38<00:02, 235.68it/s]Running 10000 simulations.:  93%|█████████▎| 9318/10000 [00:38<00:02, 238.23it/s]Running 10000 simulations.:  93%|█████████▎| 9343/10000 [00:38<00:02, 239.42it/s]Running 10000 simulations.:  94%|█████████▎| 9368/10000 [00:38<00:02, 240.92it/s]Running 10000 simulations.:  94%|█████████▍| 9393/10000 [00:38<00:02, 241.82it/s]Running 10000 simulations.:  94%|█████████▍| 9418/10000 [00:38<00:02, 242.31it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [00:38<00:02, 241.99it/s]Running 10000 simulations.:  95%|█████████▍| 9468/10000 [00:38<00:02, 242.58it/s]Running 10000 simulations.:  95%|█████████▍| 9493/10000 [00:39<00:02, 243.25it/s]Running 10000 simulations.:  95%|█████████▌| 9518/10000 [00:39<00:01, 242.86it/s]Running 10000 simulations.:  95%|█████████▌| 9543/10000 [00:39<00:01, 241.39it/s]Running 10000 simulations.:  96%|█████████▌| 9568/10000 [00:39<00:01, 242.54it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:39<00:01, 243.07it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [00:39<00:01, 244.29it/s]Running 10000 simulations.:  96%|█████████▋| 9643/10000 [00:39<00:01, 245.23it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [00:39<00:01, 245.58it/s]Running 10000 simulations.:  97%|█████████▋| 9693/10000 [00:39<00:01, 246.47it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [00:39<00:01, 247.46it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [00:40<00:01, 246.89it/s]Running 10000 simulations.:  98%|█████████▊| 9768/10000 [00:40<00:00, 245.93it/s]Running 10000 simulations.:  98%|█████████▊| 9793/10000 [00:40<00:00, 245.88it/s]Running 10000 simulations.:  98%|█████████▊| 9818/10000 [00:40<00:00, 244.66it/s]Running 10000 simulations.:  98%|█████████▊| 9843/10000 [00:40<00:00, 245.89it/s]Running 10000 simulations.:  99%|█████████▊| 9868/10000 [00:40<00:00, 246.27it/s]Running 10000 simulations.:  99%|█████████▉| 9894/10000 [00:40<00:00, 248.03it/s]Running 10000 simulations.:  99%|█████████▉| 9919/10000 [00:40<00:00, 247.96it/s]Running 10000 simulations.:  99%|█████████▉| 9944/10000 [00:40<00:00, 248.05it/s]Running 10000 simulations.: 100%|█████████▉| 9970/10000 [00:41<00:00, 248.79it/s]Running 10000 simulations.: 100%|█████████▉| 9996/10000 [00:41<00:00, 249.41it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 243.09it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 27/10000 [00:00<00:37, 267.11it/s]Running 10000 simulations.:   1%|          | 54/10000 [00:00<00:37, 266.49it/s]Running 10000 simulations.:   1%|          | 81/10000 [00:00<00:37, 266.79it/s]Running 10000 simulations.:   1%|          | 108/10000 [00:00<00:37, 264.99it/s]Running 10000 simulations.:   1%|▏         | 134/10000 [00:00<00:37, 260.58it/s]Running 10000 simulations.:   2%|▏         | 161/10000 [00:00<00:37, 260.61it/s]Running 10000 simulations.:   2%|▏         | 188/10000 [00:00<00:37, 261.63it/s]Running 10000 simulations.:   2%|▏         | 215/10000 [00:00<00:37, 261.31it/s]Running 10000 simulations.:   2%|▏         | 242/10000 [00:00<00:37, 261.76it/s]Running 10000 simulations.:   3%|▎         | 268/10000 [00:01<00:37, 260.84it/s]Running 10000 simulations.:   3%|▎         | 294/10000 [00:01<00:37, 256.29it/s]Running 10000 simulations.:   3%|▎         | 321/10000 [00:01<00:37, 258.00it/s]Running 10000 simulations.:   3%|▎         | 347/10000 [00:01<00:37, 258.17it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:01<00:37, 258.76it/s]Running 10000 simulations.:   4%|▍         | 401/10000 [00:01<00:37, 259.21it/s]Running 10000 simulations.:   4%|▍         | 427/10000 [00:01<00:37, 258.56it/s]Running 10000 simulations.:   5%|▍         | 453/10000 [00:01<00:37, 256.00it/s]Running 10000 simulations.:   5%|▍         | 479/10000 [00:01<00:37, 256.62it/s]Running 10000 simulations.:   5%|▌         | 505/10000 [00:01<00:36, 257.27it/s]Running 10000 simulations.:   5%|▌         | 531/10000 [00:02<00:36, 257.06it/s]Running 10000 simulations.:   6%|▌         | 557/10000 [00:02<00:37, 254.89it/s]Running 10000 simulations.:   6%|▌         | 583/10000 [00:02<00:36, 255.46it/s]Running 10000 simulations.:   6%|▌         | 610/10000 [00:02<00:36, 257.12it/s]Running 10000 simulations.:   6%|▋         | 636/10000 [00:02<00:36, 255.31it/s]Running 10000 simulations.:   7%|▋         | 662/10000 [00:02<00:36, 252.67it/s]Running 10000 simulations.:   7%|▋         | 688/10000 [00:02<00:36, 253.06it/s]Running 10000 simulations.:   7%|▋         | 714/10000 [00:02<00:36, 254.21it/s]Running 10000 simulations.:   7%|▋         | 741/10000 [00:02<00:36, 256.14it/s]Running 10000 simulations.:   8%|▊         | 767/10000 [00:02<00:35, 257.25it/s]Running 10000 simulations.:   8%|▊         | 793/10000 [00:03<00:36, 255.11it/s]Running 10000 simulations.:   8%|▊         | 819/10000 [00:03<00:36, 254.48it/s]Running 10000 simulations.:   8%|▊         | 845/10000 [00:03<00:35, 255.32it/s]Running 10000 simulations.:   9%|▊         | 871/10000 [00:03<00:35, 255.51it/s]Running 10000 simulations.:   9%|▉         | 897/10000 [00:03<00:35, 256.82it/s]Running 10000 simulations.:   9%|▉         | 923/10000 [00:03<00:35, 257.57it/s]Running 10000 simulations.:   9%|▉         | 949/10000 [00:03<00:35, 253.34it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:03<00:35, 253.42it/s]Running 10000 simulations.:  10%|█         | 1001/10000 [00:03<00:35, 253.30it/s]Running 10000 simulations.:  10%|█         | 1027/10000 [00:03<00:35, 254.06it/s]Running 10000 simulations.:  11%|█         | 1053/10000 [00:04<00:35, 254.61it/s]Running 10000 simulations.:  11%|█         | 1079/10000 [00:04<00:34, 254.92it/s]Running 10000 simulations.:  11%|█         | 1105/10000 [00:04<00:35, 251.44it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:04<00:35, 252.19it/s]Running 10000 simulations.:  12%|█▏        | 1157/10000 [00:04<00:34, 253.37it/s]Running 10000 simulations.:  12%|█▏        | 1183/10000 [00:04<00:34, 254.36it/s]Running 10000 simulations.:  12%|█▏        | 1209/10000 [00:04<00:34, 255.13it/s]Running 10000 simulations.:  12%|█▏        | 1235/10000 [00:04<00:34, 255.11it/s]Running 10000 simulations.:  13%|█▎        | 1261/10000 [00:04<00:34, 252.09it/s]Running 10000 simulations.:  13%|█▎        | 1287/10000 [00:05<00:34, 252.78it/s]Running 10000 simulations.:  13%|█▎        | 1313/10000 [00:05<00:34, 253.90it/s]Running 10000 simulations.:  13%|█▎        | 1339/10000 [00:05<00:34, 254.31it/s]Running 10000 simulations.:  14%|█▎        | 1365/10000 [00:05<00:33, 254.96it/s]Running 10000 simulations.:  14%|█▍        | 1391/10000 [00:05<00:33, 254.46it/s]Running 10000 simulations.:  14%|█▍        | 1417/10000 [00:05<00:33, 252.64it/s]Running 10000 simulations.:  14%|█▍        | 1443/10000 [00:05<00:33, 253.14it/s]Running 10000 simulations.:  15%|█▍        | 1469/10000 [00:05<00:33, 252.19it/s]Running 10000 simulations.:  15%|█▍        | 1495/10000 [00:05<00:34, 249.87it/s]Running 10000 simulations.:  15%|█▌        | 1521/10000 [00:05<00:33, 252.67it/s]Running 10000 simulations.:  15%|█▌        | 1547/10000 [00:06<00:33, 249.46it/s]Running 10000 simulations.:  16%|█▌        | 1573/10000 [00:06<00:33, 250.57it/s]Running 10000 simulations.:  16%|█▌        | 1599/10000 [00:06<00:33, 251.08it/s]Running 10000 simulations.:  16%|█▋        | 1625/10000 [00:06<00:33, 251.99it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:06<00:32, 253.00it/s]Running 10000 simulations.:  17%|█▋        | 1677/10000 [00:06<00:32, 253.41it/s]Running 10000 simulations.:  17%|█▋        | 1703/10000 [00:06<00:33, 249.71it/s]Running 10000 simulations.:  17%|█▋        | 1728/10000 [00:06<00:33, 249.53it/s]Running 10000 simulations.:  18%|█▊        | 1754/10000 [00:06<00:32, 250.89it/s]Running 10000 simulations.:  18%|█▊        | 1780/10000 [00:06<00:32, 251.76it/s]Running 10000 simulations.:  18%|█▊        | 1806/10000 [00:07<00:32, 249.84it/s]Running 10000 simulations.:  18%|█▊        | 1832/10000 [00:07<00:32, 250.70it/s]Running 10000 simulations.:  19%|█▊        | 1858/10000 [00:07<00:32, 252.26it/s]Running 10000 simulations.:  19%|█▉        | 1884/10000 [00:07<00:32, 249.22it/s]Running 10000 simulations.:  19%|█▉        | 1910/10000 [00:07<00:32, 250.93it/s]Running 10000 simulations.:  19%|█▉        | 1936/10000 [00:07<00:31, 252.58it/s]Running 10000 simulations.:  20%|█▉        | 1962/10000 [00:07<00:31, 253.95it/s]Running 10000 simulations.:  20%|█▉        | 1988/10000 [00:07<00:31, 254.75it/s]Running 10000 simulations.:  20%|██        | 2014/10000 [00:07<00:31, 255.44it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:08<00:31, 251.97it/s]Running 10000 simulations.:  21%|██        | 2066/10000 [00:08<00:31, 252.41it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:08<00:31, 252.52it/s]Running 10000 simulations.:  21%|██        | 2118/10000 [00:08<00:31, 252.53it/s]Running 10000 simulations.:  21%|██▏       | 2144/10000 [00:08<00:31, 252.94it/s]Running 10000 simulations.:  22%|██▏       | 2170/10000 [00:08<00:30, 253.72it/s]Running 10000 simulations.:  22%|██▏       | 2196/10000 [00:08<00:31, 250.77it/s]Running 10000 simulations.:  22%|██▏       | 2222/10000 [00:08<00:30, 250.94it/s]Running 10000 simulations.:  22%|██▏       | 2248/10000 [00:08<00:30, 251.86it/s]Running 10000 simulations.:  23%|██▎       | 2274/10000 [00:08<00:30, 252.69it/s]Running 10000 simulations.:  23%|██▎       | 2300/10000 [00:09<00:30, 254.10it/s]Running 10000 simulations.:  23%|██▎       | 2326/10000 [00:09<00:30, 253.26it/s]Running 10000 simulations.:  24%|██▎       | 2352/10000 [00:09<00:30, 249.43it/s]Running 10000 simulations.:  24%|██▍       | 2378/10000 [00:09<00:30, 250.27it/s]Running 10000 simulations.:  24%|██▍       | 2404/10000 [00:09<00:30, 251.68it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:09<00:29, 252.80it/s]Running 10000 simulations.:  25%|██▍       | 2456/10000 [00:09<00:29, 254.08it/s]Running 10000 simulations.:  25%|██▍       | 2482/10000 [00:09<00:30, 248.03it/s]Running 10000 simulations.:  25%|██▌       | 2507/10000 [00:09<00:30, 245.78it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:09<00:30, 247.48it/s]Running 10000 simulations.:  26%|██▌       | 2559/10000 [00:10<00:29, 249.24it/s]Running 10000 simulations.:  26%|██▌       | 2585/10000 [00:10<00:29, 250.75it/s]Running 10000 simulations.:  26%|██▌       | 2611/10000 [00:10<00:29, 253.11it/s]Running 10000 simulations.:  26%|██▋       | 2637/10000 [00:10<00:29, 250.22it/s]Running 10000 simulations.:  27%|██▋       | 2663/10000 [00:10<00:29, 250.18it/s]Running 10000 simulations.:  27%|██▋       | 2689/10000 [00:10<00:29, 251.35it/s]Running 10000 simulations.:  27%|██▋       | 2715/10000 [00:10<00:28, 252.33it/s]Running 10000 simulations.:  27%|██▋       | 2741/10000 [00:10<00:28, 253.19it/s]Running 10000 simulations.:  28%|██▊       | 2767/10000 [00:10<00:28, 252.85it/s]Running 10000 simulations.:  28%|██▊       | 2793/10000 [00:11<00:28, 250.70it/s]Running 10000 simulations.:  28%|██▊       | 2819/10000 [00:11<00:28, 252.14it/s]Running 10000 simulations.:  28%|██▊       | 2845/10000 [00:11<00:28, 252.77it/s]Running 10000 simulations.:  29%|██▊       | 2871/10000 [00:11<00:28, 252.97it/s]Running 10000 simulations.:  29%|██▉       | 2897/10000 [00:11<00:28, 253.30it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:11<00:27, 253.84it/s]Running 10000 simulations.:  29%|██▉       | 2949/10000 [00:11<00:27, 251.92it/s]Running 10000 simulations.:  30%|██▉       | 2975/10000 [00:11<00:27, 252.99it/s]Running 10000 simulations.:  30%|███       | 3001/10000 [00:11<00:27, 253.40it/s]Running 10000 simulations.:  30%|███       | 3027/10000 [00:11<00:27, 253.65it/s]Running 10000 simulations.:  31%|███       | 3053/10000 [00:12<00:27, 251.42it/s]Running 10000 simulations.:  31%|███       | 3079/10000 [00:12<00:27, 251.17it/s]Running 10000 simulations.:  31%|███       | 3105/10000 [00:12<00:27, 252.49it/s]Running 10000 simulations.:  31%|███▏      | 3131/10000 [00:12<00:28, 242.97it/s]Running 10000 simulations.:  32%|███▏      | 3157/10000 [00:12<00:27, 245.32it/s]Running 10000 simulations.:  32%|███▏      | 3183/10000 [00:12<00:27, 247.30it/s]Running 10000 simulations.:  32%|███▏      | 3209/10000 [00:12<00:27, 249.80it/s]Running 10000 simulations.:  32%|███▏      | 3235/10000 [00:12<00:26, 251.54it/s]Running 10000 simulations.:  33%|███▎      | 3261/10000 [00:12<00:26, 253.63it/s]Running 10000 simulations.:  33%|███▎      | 3287/10000 [00:12<00:26, 250.99it/s]Running 10000 simulations.:  33%|███▎      | 3313/10000 [00:13<00:26, 251.58it/s]Running 10000 simulations.:  33%|███▎      | 3339/10000 [00:13<00:26, 251.81it/s]Running 10000 simulations.:  34%|███▎      | 3365/10000 [00:13<00:26, 251.44it/s]Running 10000 simulations.:  34%|███▍      | 3391/10000 [00:13<00:26, 252.13it/s]Running 10000 simulations.:  34%|███▍      | 3417/10000 [00:13<00:25, 253.39it/s]Running 10000 simulations.:  34%|███▍      | 3443/10000 [00:13<00:26, 251.27it/s]Running 10000 simulations.:  35%|███▍      | 3469/10000 [00:13<00:25, 251.68it/s]Running 10000 simulations.:  35%|███▍      | 3495/10000 [00:13<00:25, 251.80it/s]Running 10000 simulations.:  35%|███▌      | 3521/10000 [00:13<00:25, 251.67it/s]Running 10000 simulations.:  35%|███▌      | 3547/10000 [00:14<00:25, 252.10it/s]Running 10000 simulations.:  36%|███▌      | 3573/10000 [00:14<00:25, 252.54it/s]Running 10000 simulations.:  36%|███▌      | 3599/10000 [00:14<00:25, 250.17it/s]Running 10000 simulations.:  36%|███▋      | 3625/10000 [00:14<00:25, 251.29it/s]Running 10000 simulations.:  37%|███▋      | 3651/10000 [00:14<00:25, 250.87it/s]Running 10000 simulations.:  37%|███▋      | 3677/10000 [00:14<00:25, 251.41it/s]Running 10000 simulations.:  37%|███▋      | 3703/10000 [00:14<00:24, 252.40it/s]Running 10000 simulations.:  37%|███▋      | 3729/10000 [00:14<00:24, 252.40it/s]Running 10000 simulations.:  38%|███▊      | 3755/10000 [00:14<00:25, 249.41it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:14<00:24, 248.98it/s]Running 10000 simulations.:  38%|███▊      | 3806/10000 [00:15<00:24, 249.76it/s]Running 10000 simulations.:  38%|███▊      | 3831/10000 [00:15<00:24, 249.75it/s]Running 10000 simulations.:  39%|███▊      | 3857/10000 [00:15<00:24, 250.71it/s]Running 10000 simulations.:  39%|███▉      | 3883/10000 [00:15<00:24, 246.04it/s]Running 10000 simulations.:  39%|███▉      | 3908/10000 [00:15<00:24, 246.22it/s]Running 10000 simulations.:  39%|███▉      | 3934/10000 [00:15<00:24, 248.10it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:15<00:24, 249.73it/s]Running 10000 simulations.:  40%|███▉      | 3986/10000 [00:15<00:23, 251.17it/s]Running 10000 simulations.:  40%|████      | 4012/10000 [00:15<00:23, 249.66it/s]Running 10000 simulations.:  40%|████      | 4037/10000 [00:15<00:24, 245.95it/s]Running 10000 simulations.:  41%|████      | 4063/10000 [00:16<00:23, 247.55it/s]Running 10000 simulations.:  41%|████      | 4088/10000 [00:16<00:23, 247.81it/s]Running 10000 simulations.:  41%|████      | 4114/10000 [00:16<00:23, 248.91it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:16<00:23, 250.78it/s]Running 10000 simulations.:  42%|████▏     | 4166/10000 [00:16<00:23, 250.87it/s]Running 10000 simulations.:  42%|████▏     | 4192/10000 [00:16<00:23, 248.44it/s]Running 10000 simulations.:  42%|████▏     | 4218/10000 [00:16<00:23, 249.04it/s]Running 10000 simulations.:  42%|████▏     | 4244/10000 [00:16<00:22, 250.53it/s]Running 10000 simulations.:  43%|████▎     | 4270/10000 [00:16<00:22, 250.88it/s]Running 10000 simulations.:  43%|████▎     | 4296/10000 [00:17<00:22, 248.71it/s]Running 10000 simulations.:  43%|████▎     | 4321/10000 [00:17<00:22, 248.63it/s]Running 10000 simulations.:  43%|████▎     | 4347/10000 [00:17<00:22, 249.18it/s]Running 10000 simulations.:  44%|████▎     | 4373/10000 [00:17<00:22, 249.61it/s]Running 10000 simulations.:  44%|████▍     | 4398/10000 [00:17<00:22, 247.68it/s]Running 10000 simulations.:  44%|████▍     | 4424/10000 [00:17<00:22, 248.92it/s]Running 10000 simulations.:  44%|████▍     | 4450/10000 [00:17<00:22, 249.42it/s]Running 10000 simulations.:  45%|████▍     | 4476/10000 [00:17<00:22, 250.26it/s]Running 10000 simulations.:  45%|████▌     | 4502/10000 [00:17<00:21, 251.53it/s]Running 10000 simulations.:  45%|████▌     | 4528/10000 [00:18<00:30, 178.88it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:18<00:27, 195.44it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:18<00:25, 209.51it/s]Running 10000 simulations.:  46%|████▌     | 4605/10000 [00:18<00:24, 220.51it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:18<00:23, 228.75it/s]Running 10000 simulations.:  47%|████▋     | 4656/10000 [00:18<00:22, 232.40it/s]Running 10000 simulations.:  47%|████▋     | 4682/10000 [00:18<00:22, 237.48it/s]Running 10000 simulations.:  47%|████▋     | 4707/10000 [00:18<00:21, 241.02it/s]Running 10000 simulations.:  47%|████▋     | 4732/10000 [00:18<00:21, 243.60it/s]Running 10000 simulations.:  48%|████▊     | 4758/10000 [00:18<00:21, 245.96it/s]Running 10000 simulations.:  48%|████▊     | 4783/10000 [00:19<00:21, 246.89it/s]Running 10000 simulations.:  48%|████▊     | 4808/10000 [00:19<00:21, 245.33it/s]Running 10000 simulations.:  48%|████▊     | 4833/10000 [00:19<00:20, 246.54it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:19<00:20, 248.06it/s]Running 10000 simulations.:  49%|████▉     | 4885/10000 [00:19<00:20, 249.70it/s]Running 10000 simulations.:  49%|████▉     | 4911/10000 [00:19<00:20, 251.24it/s]Running 10000 simulations.:  49%|████▉     | 4937/10000 [00:19<00:20, 243.42it/s]Running 10000 simulations.:  50%|████▉     | 4962/10000 [00:19<00:20, 240.57it/s]Running 10000 simulations.:  50%|████▉     | 4987/10000 [00:19<00:21, 238.46it/s]Running 10000 simulations.:  50%|█████     | 5011/10000 [00:20<00:21, 236.80it/s]Running 10000 simulations.:  50%|█████     | 5037/10000 [00:20<00:20, 240.94it/s]Running 10000 simulations.:  51%|█████     | 5063/10000 [00:20<00:20, 243.66it/s]Running 10000 simulations.:  51%|█████     | 5088/10000 [00:20<00:20, 240.08it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:20<00:21, 232.44it/s]Running 10000 simulations.:  51%|█████▏    | 5137/10000 [00:20<00:20, 233.00it/s]Running 10000 simulations.:  52%|█████▏    | 5161/10000 [00:20<00:20, 234.00it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:20<00:20, 237.80it/s]Running 10000 simulations.:  52%|█████▏    | 5212/10000 [00:20<00:19, 241.67it/s]Running 10000 simulations.:  52%|█████▏    | 5237/10000 [00:20<00:19, 241.46it/s]Running 10000 simulations.:  53%|█████▎    | 5262/10000 [00:21<00:19, 237.34it/s]Running 10000 simulations.:  53%|█████▎    | 5286/10000 [00:21<00:20, 235.21it/s]Running 10000 simulations.:  53%|█████▎    | 5310/10000 [00:21<00:19, 236.08it/s]Running 10000 simulations.:  53%|█████▎    | 5335/10000 [00:21<00:19, 238.88it/s]Running 10000 simulations.:  54%|█████▎    | 5361/10000 [00:21<00:19, 242.09it/s]Running 10000 simulations.:  54%|█████▍    | 5386/10000 [00:21<00:19, 241.25it/s]Running 10000 simulations.:  54%|█████▍    | 5411/10000 [00:21<00:19, 236.33it/s]Running 10000 simulations.:  54%|█████▍    | 5436/10000 [00:21<00:19, 237.58it/s]Running 10000 simulations.:  55%|█████▍    | 5460/10000 [00:21<00:19, 237.80it/s]Running 10000 simulations.:  55%|█████▍    | 5485/10000 [00:22<00:18, 240.84it/s]Running 10000 simulations.:  55%|█████▌    | 5510/10000 [00:22<00:18, 242.47it/s]Running 10000 simulations.:  55%|█████▌    | 5535/10000 [00:22<00:18, 240.32it/s]Running 10000 simulations.:  56%|█████▌    | 5560/10000 [00:22<00:18, 242.84it/s]Running 10000 simulations.:  56%|█████▌    | 5585/10000 [00:22<00:18, 243.91it/s]Running 10000 simulations.:  56%|█████▌    | 5610/10000 [00:22<00:17, 244.81it/s]Running 10000 simulations.:  56%|█████▋    | 5635/10000 [00:22<00:18, 238.71it/s]Running 10000 simulations.:  57%|█████▋    | 5659/10000 [00:22<00:18, 238.45it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:22<00:18, 239.12it/s]Running 10000 simulations.:  57%|█████▋    | 5709/10000 [00:22<00:17, 240.53it/s]Running 10000 simulations.:  57%|█████▋    | 5734/10000 [00:23<00:17, 242.31it/s]Running 10000 simulations.:  58%|█████▊    | 5759/10000 [00:23<00:17, 243.26it/s]Running 10000 simulations.:  58%|█████▊    | 5784/10000 [00:23<00:17, 240.70it/s]Running 10000 simulations.:  58%|█████▊    | 5809/10000 [00:23<00:17, 238.70it/s]Running 10000 simulations.:  58%|█████▊    | 5834/10000 [00:23<00:17, 240.33it/s]Running 10000 simulations.:  59%|█████▊    | 5860/10000 [00:23<00:16, 243.96it/s]Running 10000 simulations.:  59%|█████▉    | 5886/10000 [00:23<00:16, 246.71it/s]Running 10000 simulations.:  59%|█████▉    | 5912/10000 [00:23<00:16, 249.13it/s]Running 10000 simulations.:  59%|█████▉    | 5937/10000 [00:23<00:16, 247.07it/s]Running 10000 simulations.:  60%|█████▉    | 5962/10000 [00:23<00:16, 247.53it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:24<00:16, 247.53it/s]Running 10000 simulations.:  60%|██████    | 6012/10000 [00:24<00:16, 247.76it/s]Running 10000 simulations.:  60%|██████    | 6037/10000 [00:24<00:15, 248.13it/s]Running 10000 simulations.:  61%|██████    | 6063/10000 [00:24<00:15, 248.97it/s]Running 10000 simulations.:  61%|██████    | 6088/10000 [00:24<00:15, 247.84it/s]Running 10000 simulations.:  61%|██████    | 6113/10000 [00:24<00:15, 248.47it/s]Running 10000 simulations.:  61%|██████▏   | 6138/10000 [00:24<00:15, 247.50it/s]Running 10000 simulations.:  62%|██████▏   | 6163/10000 [00:24<00:15, 247.58it/s]Running 10000 simulations.:  62%|██████▏   | 6188/10000 [00:24<00:15, 248.07it/s]Running 10000 simulations.:  62%|██████▏   | 6214/10000 [00:24<00:15, 248.84it/s]Running 10000 simulations.:  62%|██████▏   | 6239/10000 [00:25<00:15, 247.67it/s]Running 10000 simulations.:  63%|██████▎   | 6265/10000 [00:25<00:15, 248.95it/s]Running 10000 simulations.:  63%|██████▎   | 6291/10000 [00:25<00:14, 250.01it/s]Running 10000 simulations.:  63%|██████▎   | 6317/10000 [00:25<00:14, 250.14it/s]Running 10000 simulations.:  63%|██████▎   | 6343/10000 [00:25<00:14, 250.91it/s]Running 10000 simulations.:  64%|██████▎   | 6369/10000 [00:25<00:14, 248.99it/s]Running 10000 simulations.:  64%|██████▍   | 6394/10000 [00:25<00:14, 248.46it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:25<00:14, 249.01it/s]Running 10000 simulations.:  64%|██████▍   | 6446/10000 [00:25<00:14, 249.36it/s]Running 10000 simulations.:  65%|██████▍   | 6472/10000 [00:26<00:14, 250.13it/s]Running 10000 simulations.:  65%|██████▍   | 6498/10000 [00:26<00:14, 250.01it/s]Running 10000 simulations.:  65%|██████▌   | 6524/10000 [00:26<00:14, 248.07it/s]Running 10000 simulations.:  65%|██████▌   | 6549/10000 [00:26<00:13, 248.25it/s]Running 10000 simulations.:  66%|██████▌   | 6574/10000 [00:26<00:13, 248.74it/s]Running 10000 simulations.:  66%|██████▌   | 6599/10000 [00:26<00:13, 249.00it/s]Running 10000 simulations.:  66%|██████▋   | 6625/10000 [00:26<00:13, 249.84it/s]Running 10000 simulations.:  66%|██████▋   | 6650/10000 [00:26<00:13, 249.14it/s]Running 10000 simulations.:  67%|██████▋   | 6675/10000 [00:26<00:13, 247.17it/s]Running 10000 simulations.:  67%|██████▋   | 6700/10000 [00:26<00:13, 247.64it/s]Running 10000 simulations.:  67%|██████▋   | 6725/10000 [00:27<00:13, 248.26it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:27<00:13, 246.47it/s]Running 10000 simulations.:  68%|██████▊   | 6775/10000 [00:27<00:13, 244.42it/s]Running 10000 simulations.:  68%|██████▊   | 6800/10000 [00:27<00:13, 245.98it/s]Running 10000 simulations.:  68%|██████▊   | 6826/10000 [00:27<00:12, 248.39it/s]Running 10000 simulations.:  69%|██████▊   | 6852/10000 [00:27<00:12, 249.18it/s]Running 10000 simulations.:  69%|██████▉   | 6877/10000 [00:27<00:12, 247.32it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:27<00:12, 247.76it/s]Running 10000 simulations.:  69%|██████▉   | 6928/10000 [00:27<00:12, 248.50it/s]Running 10000 simulations.:  70%|██████▉   | 6954/10000 [00:27<00:12, 249.65it/s]Running 10000 simulations.:  70%|██████▉   | 6980/10000 [00:28<00:12, 250.71it/s]Running 10000 simulations.:  70%|███████   | 7006/10000 [00:28<00:12, 248.63it/s]Running 10000 simulations.:  70%|███████   | 7032/10000 [00:28<00:11, 249.24it/s]Running 10000 simulations.:  71%|███████   | 7058/10000 [00:28<00:11, 250.63it/s]Running 10000 simulations.:  71%|███████   | 7084/10000 [00:28<00:11, 251.24it/s]Running 10000 simulations.:  71%|███████   | 7110/10000 [00:28<00:11, 250.53it/s]Running 10000 simulations.:  71%|███████▏  | 7136/10000 [00:28<00:11, 249.36it/s]Running 10000 simulations.:  72%|███████▏  | 7161/10000 [00:28<00:11, 247.51it/s]Running 10000 simulations.:  72%|███████▏  | 7186/10000 [00:28<00:11, 247.64it/s]Running 10000 simulations.:  72%|███████▏  | 7212/10000 [00:29<00:11, 248.59it/s]Running 10000 simulations.:  72%|███████▏  | 7238/10000 [00:29<00:11, 250.19it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:29<00:10, 249.80it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:29<00:10, 248.25it/s]Running 10000 simulations.:  73%|███████▎  | 7314/10000 [00:29<00:10, 246.45it/s]Running 10000 simulations.:  73%|███████▎  | 7340/10000 [00:29<00:10, 247.86it/s]Running 10000 simulations.:  74%|███████▎  | 7366/10000 [00:29<00:10, 248.65it/s]Running 10000 simulations.:  74%|███████▍  | 7391/10000 [00:29<00:10, 248.88it/s]Running 10000 simulations.:  74%|███████▍  | 7417/10000 [00:29<00:10, 249.67it/s]Running 10000 simulations.:  74%|███████▍  | 7442/10000 [00:29<00:10, 249.56it/s]Running 10000 simulations.:  75%|███████▍  | 7467/10000 [00:30<00:10, 247.58it/s]Running 10000 simulations.:  75%|███████▍  | 7493/10000 [00:30<00:10, 248.50it/s]Running 10000 simulations.:  75%|███████▌  | 7518/10000 [00:30<00:09, 248.46it/s]Running 10000 simulations.:  75%|███████▌  | 7544/10000 [00:30<00:09, 249.09it/s]Running 10000 simulations.:  76%|███████▌  | 7570/10000 [00:30<00:09, 250.38it/s]Running 10000 simulations.:  76%|███████▌  | 7596/10000 [00:30<00:09, 249.14it/s]Running 10000 simulations.:  76%|███████▌  | 7621/10000 [00:30<00:09, 247.47it/s]Running 10000 simulations.:  76%|███████▋  | 7646/10000 [00:30<00:09, 247.52it/s]Running 10000 simulations.:  77%|███████▋  | 7671/10000 [00:30<00:09, 247.75it/s]Running 10000 simulations.:  77%|███████▋  | 7697/10000 [00:30<00:09, 248.50it/s]Running 10000 simulations.:  77%|███████▋  | 7723/10000 [00:31<00:09, 249.75it/s]Running 10000 simulations.:  77%|███████▋  | 7748/10000 [00:31<00:09, 246.45it/s]Running 10000 simulations.:  78%|███████▊  | 7773/10000 [00:31<00:09, 244.88it/s]Running 10000 simulations.:  78%|███████▊  | 7798/10000 [00:31<00:08, 245.47it/s]Running 10000 simulations.:  78%|███████▊  | 7823/10000 [00:31<00:08, 246.75it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:31<00:08, 247.98it/s]Running 10000 simulations.:  79%|███████▊  | 7874/10000 [00:31<00:08, 248.46it/s]Running 10000 simulations.:  79%|███████▉  | 7899/10000 [00:31<00:08, 244.80it/s]Running 10000 simulations.:  79%|███████▉  | 7924/10000 [00:31<00:08, 246.22it/s]Running 10000 simulations.:  79%|███████▉  | 7949/10000 [00:31<00:08, 247.32it/s]Running 10000 simulations.:  80%|███████▉  | 7974/10000 [00:32<00:08, 247.77it/s]Running 10000 simulations.:  80%|███████▉  | 7999/10000 [00:32<00:08, 246.33it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:32<00:08, 246.09it/s]Running 10000 simulations.:  80%|████████  | 8049/10000 [00:32<00:07, 247.05it/s]Running 10000 simulations.:  81%|████████  | 8074/10000 [00:32<00:07, 247.36it/s]Running 10000 simulations.:  81%|████████  | 8099/10000 [00:32<00:07, 245.61it/s]Running 10000 simulations.:  81%|████████  | 8124/10000 [00:32<00:07, 246.37it/s]Running 10000 simulations.:  82%|████████▏ | 8150/10000 [00:32<00:07, 248.16it/s]Running 10000 simulations.:  82%|████████▏ | 8176/10000 [00:32<00:07, 249.89it/s]Running 10000 simulations.:  82%|████████▏ | 8202/10000 [00:32<00:07, 250.47it/s]Running 10000 simulations.:  82%|████████▏ | 8228/10000 [00:33<00:07, 250.78it/s]Running 10000 simulations.:  83%|████████▎ | 8254/10000 [00:33<00:07, 246.73it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:33<00:06, 247.90it/s]Running 10000 simulations.:  83%|████████▎ | 8306/10000 [00:33<00:06, 248.99it/s]Running 10000 simulations.:  83%|████████▎ | 8331/10000 [00:33<00:06, 249.22it/s]Running 10000 simulations.:  84%|████████▎ | 8357/10000 [00:33<00:06, 250.43it/s]Running 10000 simulations.:  84%|████████▍ | 8383/10000 [00:33<00:06, 250.33it/s]Running 10000 simulations.:  84%|████████▍ | 8409/10000 [00:33<00:06, 247.69it/s]Running 10000 simulations.:  84%|████████▍ | 8435/10000 [00:33<00:06, 248.52it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:34<00:06, 248.77it/s]Running 10000 simulations.:  85%|████████▍ | 8485/10000 [00:34<00:06, 248.70it/s]Running 10000 simulations.:  85%|████████▌ | 8511/10000 [00:34<00:05, 249.65it/s]Running 10000 simulations.:  85%|████████▌ | 8536/10000 [00:34<00:05, 246.37it/s]Running 10000 simulations.:  86%|████████▌ | 8562/10000 [00:34<00:05, 247.57it/s]Running 10000 simulations.:  86%|████████▌ | 8588/10000 [00:34<00:05, 248.60it/s]Running 10000 simulations.:  86%|████████▌ | 8614/10000 [00:34<00:05, 249.54it/s]Running 10000 simulations.:  86%|████████▋ | 8639/10000 [00:34<00:05, 249.03it/s]Running 10000 simulations.:  87%|████████▋ | 8664/10000 [00:34<00:05, 249.20it/s]Running 10000 simulations.:  87%|████████▋ | 8689/10000 [00:34<00:05, 247.70it/s]Running 10000 simulations.:  87%|████████▋ | 8715/10000 [00:35<00:05, 248.81it/s]Running 10000 simulations.:  87%|████████▋ | 8741/10000 [00:35<00:05, 250.06it/s]Running 10000 simulations.:  88%|████████▊ | 8767/10000 [00:35<00:04, 250.63it/s]Running 10000 simulations.:  88%|████████▊ | 8793/10000 [00:35<00:04, 250.29it/s]Running 10000 simulations.:  88%|████████▊ | 8819/10000 [00:35<00:04, 249.68it/s]Running 10000 simulations.:  88%|████████▊ | 8844/10000 [00:35<00:04, 246.41it/s]Running 10000 simulations.:  89%|████████▊ | 8869/10000 [00:35<00:04, 247.19it/s]Running 10000 simulations.:  89%|████████▉ | 8895/10000 [00:35<00:04, 248.87it/s]Running 10000 simulations.:  89%|████████▉ | 8921/10000 [00:35<00:04, 250.10it/s]Running 10000 simulations.:  89%|████████▉ | 8947/10000 [00:35<00:04, 251.91it/s]Running 10000 simulations.:  90%|████████▉ | 8973/10000 [00:36<00:04, 246.67it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:36<00:04, 246.51it/s]Running 10000 simulations.:  90%|█████████ | 9023/10000 [00:36<00:03, 246.76it/s]Running 10000 simulations.:  90%|█████████ | 9048/10000 [00:36<00:03, 247.35it/s]Running 10000 simulations.:  91%|█████████ | 9073/10000 [00:36<00:03, 248.10it/s]Running 10000 simulations.:  91%|█████████ | 9099/10000 [00:36<00:03, 249.23it/s]Running 10000 simulations.:  91%|█████████ | 9124/10000 [00:36<00:03, 248.64it/s]Running 10000 simulations.:  91%|█████████▏| 9149/10000 [00:36<00:03, 248.38it/s]Running 10000 simulations.:  92%|█████████▏| 9174/10000 [00:36<00:03, 248.53it/s]Running 10000 simulations.:  92%|█████████▏| 9199/10000 [00:37<00:03, 248.94it/s]Running 10000 simulations.:  92%|█████████▏| 9224/10000 [00:37<00:03, 246.64it/s]Running 10000 simulations.:  92%|█████████▏| 9249/10000 [00:37<00:03, 246.75it/s]Running 10000 simulations.:  93%|█████████▎| 9274/10000 [00:37<00:02, 245.32it/s]Running 10000 simulations.:  93%|█████████▎| 9299/10000 [00:37<00:02, 246.10it/s]Running 10000 simulations.:  93%|█████████▎| 9324/10000 [00:37<00:02, 245.13it/s]Running 10000 simulations.:  94%|█████████▎| 9350/10000 [00:37<00:02, 246.98it/s]Running 10000 simulations.:  94%|█████████▍| 9376/10000 [00:37<00:02, 248.51it/s]Running 10000 simulations.:  94%|█████████▍| 9402/10000 [00:37<00:02, 249.25it/s]Running 10000 simulations.:  94%|█████████▍| 9428/10000 [00:37<00:02, 250.14it/s]Running 10000 simulations.:  95%|█████████▍| 9454/10000 [00:38<00:02, 248.00it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [00:38<00:02, 248.53it/s]Running 10000 simulations.:  95%|█████████▌| 9505/10000 [00:38<00:01, 249.46it/s]Running 10000 simulations.:  95%|█████████▌| 9531/10000 [00:38<00:01, 250.10it/s]Running 10000 simulations.:  96%|█████████▌| 9557/10000 [00:38<00:01, 251.12it/s]Running 10000 simulations.:  96%|█████████▌| 9583/10000 [00:38<00:01, 251.47it/s]Running 10000 simulations.:  96%|█████████▌| 9609/10000 [00:38<00:01, 249.19it/s]Running 10000 simulations.:  96%|█████████▋| 9635/10000 [00:38<00:01, 249.70it/s]Running 10000 simulations.:  97%|█████████▋| 9661/10000 [00:38<00:01, 250.82it/s]Running 10000 simulations.:  97%|█████████▋| 9687/10000 [00:38<00:01, 251.66it/s]Running 10000 simulations.:  97%|█████████▋| 9713/10000 [00:39<00:01, 252.30it/s]Running 10000 simulations.:  97%|█████████▋| 9739/10000 [00:39<00:01, 251.60it/s]Running 10000 simulations.:  98%|█████████▊| 9765/10000 [00:39<00:00, 251.10it/s]Running 10000 simulations.:  98%|█████████▊| 9791/10000 [00:39<00:00, 252.23it/s]Running 10000 simulations.:  98%|█████████▊| 9817/10000 [00:39<00:00, 252.90it/s]Running 10000 simulations.:  98%|█████████▊| 9843/10000 [00:39<00:00, 253.74it/s]Running 10000 simulations.:  99%|█████████▊| 9869/10000 [00:39<00:00, 253.87it/s]Running 10000 simulations.:  99%|█████████▉| 9895/10000 [00:39<00:00, 254.61it/s]Running 10000 simulations.:  99%|█████████▉| 9921/10000 [00:39<00:00, 252.69it/s]Running 10000 simulations.:  99%|█████████▉| 9947/10000 [00:39<00:00, 252.44it/s]Running 10000 simulations.: 100%|█████████▉| 9973/10000 [00:40<00:00, 252.22it/s]Running 10000 simulations.: 100%|█████████▉| 9999/10000 [00:40<00:00, 252.97it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:40<00:00, 248.71it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:35, 278.31it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<00:35, 278.07it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<00:35, 277.40it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<00:35, 277.01it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:35, 276.00it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:35, 275.59it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:00<00:35, 275.84it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:00<00:35, 276.33it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:00<00:35, 276.19it/s]Running 10000 simulations.:   3%|▎         | 280/10000 [00:01<00:35, 276.25it/s]Running 10000 simulations.:   3%|▎         | 308/10000 [00:01<00:35, 275.63it/s]Running 10000 simulations.:   3%|▎         | 336/10000 [00:01<00:35, 274.03it/s]Running 10000 simulations.:   4%|▎         | 364/10000 [00:01<00:35, 273.58it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:01<00:35, 272.30it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:35, 272.61it/s]Running 10000 simulations.:   4%|▍         | 448/10000 [00:01<00:35, 272.49it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:01<00:35, 271.89it/s]Running 10000 simulations.:   5%|▌         | 504/10000 [00:01<00:35, 270.57it/s]Running 10000 simulations.:   5%|▌         | 532/10000 [00:01<00:34, 271.09it/s]Running 10000 simulations.:   6%|▌         | 560/10000 [00:02<00:34, 271.55it/s]Running 10000 simulations.:   6%|▌         | 588/10000 [00:02<00:34, 270.93it/s]Running 10000 simulations.:   6%|▌         | 616/10000 [00:02<00:34, 270.38it/s]Running 10000 simulations.:   6%|▋         | 644/10000 [00:02<00:34, 270.38it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:02<00:34, 270.38it/s]Running 10000 simulations.:   7%|▋         | 700/10000 [00:02<00:34, 271.15it/s]Running 10000 simulations.:   7%|▋         | 728/10000 [00:02<00:34, 271.14it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:02<00:34, 270.97it/s]Running 10000 simulations.:   8%|▊         | 784/10000 [00:02<00:34, 271.06it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:02<00:33, 271.82it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:03<00:33, 271.37it/s]Running 10000 simulations.:   9%|▊         | 868/10000 [00:03<00:33, 271.86it/s]Running 10000 simulations.:   9%|▉         | 896/10000 [00:03<00:33, 271.59it/s]Running 10000 simulations.:   9%|▉         | 924/10000 [00:03<00:33, 271.60it/s]Running 10000 simulations.:  10%|▉         | 952/10000 [00:03<00:33, 271.50it/s]Running 10000 simulations.:  10%|▉         | 980/10000 [00:03<00:33, 270.97it/s]Running 10000 simulations.:  10%|█         | 1008/10000 [00:03<00:33, 269.85it/s]Running 10000 simulations.:  10%|█         | 1035/10000 [00:03<00:33, 266.50it/s]Running 10000 simulations.:  11%|█         | 1062/10000 [00:03<00:33, 267.28it/s]Running 10000 simulations.:  11%|█         | 1089/10000 [00:04<00:33, 267.20it/s]Running 10000 simulations.:  11%|█         | 1117/10000 [00:04<00:33, 268.32it/s]Running 10000 simulations.:  11%|█▏        | 1144/10000 [00:04<00:32, 268.78it/s]Running 10000 simulations.:  12%|█▏        | 1172/10000 [00:04<00:32, 269.58it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:32, 270.41it/s]Running 10000 simulations.:  12%|█▏        | 1228/10000 [00:04<00:32, 270.59it/s]Running 10000 simulations.:  13%|█▎        | 1256/10000 [00:04<00:32, 270.09it/s]Running 10000 simulations.:  13%|█▎        | 1284/10000 [00:04<00:32, 269.42it/s]Running 10000 simulations.:  13%|█▎        | 1311/10000 [00:04<00:32, 269.35it/s]Running 10000 simulations.:  13%|█▎        | 1338/10000 [00:04<00:32, 268.74it/s]Running 10000 simulations.:  14%|█▎        | 1366/10000 [00:05<00:32, 269.39it/s]Running 10000 simulations.:  14%|█▍        | 1393/10000 [00:05<00:31, 269.32it/s]Running 10000 simulations.:  14%|█▍        | 1420/10000 [00:05<00:31, 269.39it/s]Running 10000 simulations.:  14%|█▍        | 1448/10000 [00:05<00:31, 269.72it/s]Running 10000 simulations.:  15%|█▍        | 1476/10000 [00:05<00:31, 270.40it/s]Running 10000 simulations.:  15%|█▌        | 1504/10000 [00:05<00:31, 270.30it/s]Running 10000 simulations.:  15%|█▌        | 1532/10000 [00:05<00:31, 270.30it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:05<00:31, 270.36it/s]Running 10000 simulations.:  16%|█▌        | 1588/10000 [00:05<00:31, 269.47it/s]Running 10000 simulations.:  16%|█▌        | 1615/10000 [00:05<00:31, 269.04it/s]Running 10000 simulations.:  16%|█▋        | 1642/10000 [00:06<00:31, 268.36it/s]Running 10000 simulations.:  17%|█▋        | 1669/10000 [00:06<00:30, 268.75it/s]Running 10000 simulations.:  17%|█▋        | 1696/10000 [00:06<00:30, 268.84it/s]Running 10000 simulations.:  17%|█▋        | 1723/10000 [00:06<00:30, 268.76it/s]Running 10000 simulations.:  18%|█▊        | 1750/10000 [00:06<00:30, 268.04it/s]Running 10000 simulations.:  18%|█▊        | 1777/10000 [00:06<00:30, 266.32it/s]Running 10000 simulations.:  18%|█▊        | 1804/10000 [00:06<00:30, 266.95it/s]Running 10000 simulations.:  18%|█▊        | 1831/10000 [00:06<00:30, 266.72it/s]Running 10000 simulations.:  19%|█▊        | 1858/10000 [00:06<00:30, 266.53it/s]Running 10000 simulations.:  19%|█▉        | 1885/10000 [00:06<00:30, 266.78it/s]Running 10000 simulations.:  19%|█▉        | 1912/10000 [00:07<00:30, 266.60it/s]Running 10000 simulations.:  19%|█▉        | 1939/10000 [00:07<00:30, 266.81it/s]Running 10000 simulations.:  20%|█▉        | 1966/10000 [00:07<00:30, 266.95it/s]Running 10000 simulations.:  20%|█▉        | 1993/10000 [00:07<00:29, 267.07it/s]Running 10000 simulations.:  20%|██        | 2020/10000 [00:07<00:29, 267.05it/s]Running 10000 simulations.:  20%|██        | 2047/10000 [00:07<00:29, 266.87it/s]Running 10000 simulations.:  21%|██        | 2074/10000 [00:07<00:29, 266.29it/s]Running 10000 simulations.:  21%|██        | 2101/10000 [00:07<00:29, 267.01it/s]Running 10000 simulations.:  21%|██▏       | 2128/10000 [00:07<00:29, 266.50it/s]Running 10000 simulations.:  22%|██▏       | 2155/10000 [00:07<00:29, 266.18it/s]Running 10000 simulations.:  22%|██▏       | 2182/10000 [00:08<00:29, 266.57it/s]Running 10000 simulations.:  22%|██▏       | 2209/10000 [00:08<00:29, 266.89it/s]Running 10000 simulations.:  22%|██▏       | 2236/10000 [00:08<00:29, 265.95it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:08<00:29, 266.54it/s]Running 10000 simulations.:  23%|██▎       | 2290/10000 [00:08<00:28, 266.09it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:08<00:28, 265.76it/s]Running 10000 simulations.:  23%|██▎       | 2344/10000 [00:08<00:28, 266.08it/s]Running 10000 simulations.:  24%|██▎       | 2371/10000 [00:08<00:28, 266.21it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:08<00:28, 266.58it/s]Running 10000 simulations.:  24%|██▍       | 2425/10000 [00:08<00:28, 266.70it/s]Running 10000 simulations.:  25%|██▍       | 2452/10000 [00:09<00:37, 199.51it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:09<00:34, 215.57it/s]Running 10000 simulations.:  25%|██▌       | 2506/10000 [00:09<00:32, 228.24it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:09<00:31, 237.61it/s]Running 10000 simulations.:  26%|██▌       | 2559/10000 [00:09<00:30, 241.25it/s]Running 10000 simulations.:  26%|██▌       | 2586/10000 [00:09<00:29, 247.60it/s]Running 10000 simulations.:  26%|██▌       | 2613/10000 [00:09<00:29, 253.08it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:09<00:28, 256.37it/s]Running 10000 simulations.:  27%|██▋       | 2667/10000 [00:10<00:28, 259.07it/s]Running 10000 simulations.:  27%|██▋       | 2694/10000 [00:10<00:27, 260.99it/s]Running 10000 simulations.:  27%|██▋       | 2721/10000 [00:10<00:27, 262.14it/s]Running 10000 simulations.:  27%|██▋       | 2748/10000 [00:10<00:27, 263.02it/s]Running 10000 simulations.:  28%|██▊       | 2775/10000 [00:10<00:27, 263.54it/s]Running 10000 simulations.:  28%|██▊       | 2802/10000 [00:10<00:27, 264.08it/s]Running 10000 simulations.:  28%|██▊       | 2829/10000 [00:10<00:27, 264.75it/s]Running 10000 simulations.:  29%|██▊       | 2856/10000 [00:10<00:26, 265.04it/s]Running 10000 simulations.:  29%|██▉       | 2883/10000 [00:10<00:26, 265.75it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:10<00:26, 265.90it/s]Running 10000 simulations.:  29%|██▉       | 2937/10000 [00:11<00:26, 265.70it/s]Running 10000 simulations.:  30%|██▉       | 2964/10000 [00:11<00:26, 265.62it/s]Running 10000 simulations.:  30%|██▉       | 2991/10000 [00:11<00:26, 264.95it/s]Running 10000 simulations.:  30%|███       | 3018/10000 [00:11<00:26, 264.24it/s]Running 10000 simulations.:  30%|███       | 3045/10000 [00:11<00:26, 263.70it/s]Running 10000 simulations.:  31%|███       | 3072/10000 [00:11<00:26, 263.40it/s]Running 10000 simulations.:  31%|███       | 3099/10000 [00:11<00:26, 263.58it/s]Running 10000 simulations.:  31%|███▏      | 3126/10000 [00:11<00:26, 263.83it/s]Running 10000 simulations.:  32%|███▏      | 3153/10000 [00:11<00:25, 263.74it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:11<00:25, 264.07it/s]Running 10000 simulations.:  32%|███▏      | 3207/10000 [00:12<00:25, 264.71it/s]Running 10000 simulations.:  32%|███▏      | 3234/10000 [00:12<00:25, 264.58it/s]Running 10000 simulations.:  33%|███▎      | 3261/10000 [00:12<00:25, 264.13it/s]Running 10000 simulations.:  33%|███▎      | 3288/10000 [00:12<00:25, 264.47it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:12<00:25, 264.39it/s]Running 10000 simulations.:  33%|███▎      | 3342/10000 [00:12<00:25, 264.44it/s]Running 10000 simulations.:  34%|███▎      | 3369/10000 [00:12<00:25, 264.86it/s]Running 10000 simulations.:  34%|███▍      | 3396/10000 [00:12<00:24, 264.69it/s]Running 10000 simulations.:  34%|███▍      | 3423/10000 [00:12<00:24, 264.28it/s]Running 10000 simulations.:  34%|███▍      | 3450/10000 [00:12<00:24, 264.45it/s]Running 10000 simulations.:  35%|███▍      | 3477/10000 [00:13<00:24, 264.73it/s]Running 10000 simulations.:  35%|███▌      | 3504/10000 [00:13<00:24, 264.69it/s]Running 10000 simulations.:  35%|███▌      | 3531/10000 [00:13<00:24, 264.56it/s]Running 10000 simulations.:  36%|███▌      | 3558/10000 [00:13<00:24, 264.15it/s]Running 10000 simulations.:  36%|███▌      | 3585/10000 [00:13<00:24, 264.28it/s]Running 10000 simulations.:  36%|███▌      | 3612/10000 [00:13<00:24, 264.55it/s]Running 10000 simulations.:  36%|███▋      | 3639/10000 [00:13<00:24, 264.57it/s]Running 10000 simulations.:  37%|███▋      | 3666/10000 [00:13<00:23, 265.08it/s]Running 10000 simulations.:  37%|███▋      | 3693/10000 [00:13<00:23, 265.58it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:14<00:23, 265.65it/s]Running 10000 simulations.:  37%|███▋      | 3747/10000 [00:14<00:23, 265.70it/s]Running 10000 simulations.:  38%|███▊      | 3774/10000 [00:14<00:23, 260.55it/s]Running 10000 simulations.:  38%|███▊      | 3801/10000 [00:14<00:23, 261.02it/s]Running 10000 simulations.:  38%|███▊      | 3828/10000 [00:14<00:23, 263.08it/s]Running 10000 simulations.:  39%|███▊      | 3855/10000 [00:14<00:23, 264.86it/s]Running 10000 simulations.:  39%|███▉      | 3882/10000 [00:14<00:23, 265.70it/s]Running 10000 simulations.:  39%|███▉      | 3909/10000 [00:14<00:22, 266.22it/s]Running 10000 simulations.:  39%|███▉      | 3936/10000 [00:14<00:22, 266.66it/s]Running 10000 simulations.:  40%|███▉      | 3963/10000 [00:14<00:22, 266.91it/s]Running 10000 simulations.:  40%|███▉      | 3990/10000 [00:15<00:22, 267.03it/s]Running 10000 simulations.:  40%|████      | 4017/10000 [00:15<00:22, 267.65it/s]Running 10000 simulations.:  40%|████      | 4044/10000 [00:15<00:22, 266.67it/s]Running 10000 simulations.:  41%|████      | 4071/10000 [00:15<00:22, 266.59it/s]Running 10000 simulations.:  41%|████      | 4098/10000 [00:15<00:22, 266.83it/s]Running 10000 simulations.:  41%|████▏     | 4125/10000 [00:15<00:21, 267.36it/s]Running 10000 simulations.:  42%|████▏     | 4152/10000 [00:15<00:21, 266.88it/s]Running 10000 simulations.:  42%|████▏     | 4179/10000 [00:15<00:21, 267.56it/s]Running 10000 simulations.:  42%|████▏     | 4206/10000 [00:15<00:21, 267.79it/s]Running 10000 simulations.:  42%|████▏     | 4233/10000 [00:15<00:21, 267.69it/s]Running 10000 simulations.:  43%|████▎     | 4260/10000 [00:16<00:21, 267.73it/s]Running 10000 simulations.:  43%|████▎     | 4287/10000 [00:16<00:21, 266.43it/s]Running 10000 simulations.:  43%|████▎     | 4314/10000 [00:16<00:21, 265.99it/s]Running 10000 simulations.:  43%|████▎     | 4341/10000 [00:16<00:21, 266.10it/s]Running 10000 simulations.:  44%|████▎     | 4368/10000 [00:16<00:21, 265.67it/s]Running 10000 simulations.:  44%|████▍     | 4395/10000 [00:16<00:21, 266.06it/s]Running 10000 simulations.:  44%|████▍     | 4422/10000 [00:16<00:20, 266.41it/s]Running 10000 simulations.:  44%|████▍     | 4449/10000 [00:16<00:20, 267.11it/s]Running 10000 simulations.:  45%|████▍     | 4476/10000 [00:16<00:20, 267.00it/s]Running 10000 simulations.:  45%|████▌     | 4503/10000 [00:16<00:20, 267.40it/s]Running 10000 simulations.:  45%|████▌     | 4530/10000 [00:17<00:20, 266.64it/s]Running 10000 simulations.:  46%|████▌     | 4557/10000 [00:17<00:20, 266.75it/s]Running 10000 simulations.:  46%|████▌     | 4584/10000 [00:17<00:20, 266.79it/s]Running 10000 simulations.:  46%|████▌     | 4611/10000 [00:17<00:20, 267.17it/s]Running 10000 simulations.:  46%|████▋     | 4638/10000 [00:17<00:20, 266.92it/s]Running 10000 simulations.:  47%|████▋     | 4665/10000 [00:17<00:20, 266.05it/s]Running 10000 simulations.:  47%|████▋     | 4692/10000 [00:17<00:20, 265.07it/s]Running 10000 simulations.:  47%|████▋     | 4719/10000 [00:17<00:19, 264.99it/s]Running 10000 simulations.:  47%|████▋     | 4746/10000 [00:17<00:19, 264.60it/s]Running 10000 simulations.:  48%|████▊     | 4773/10000 [00:17<00:19, 263.49it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:18<00:19, 264.34it/s]Running 10000 simulations.:  48%|████▊     | 4827/10000 [00:18<00:19, 264.94it/s]Running 10000 simulations.:  49%|████▊     | 4854/10000 [00:18<00:19, 265.07it/s]Running 10000 simulations.:  49%|████▉     | 4881/10000 [00:18<00:19, 265.27it/s]Running 10000 simulations.:  49%|████▉     | 4908/10000 [00:18<00:19, 265.79it/s]Running 10000 simulations.:  49%|████▉     | 4935/10000 [00:18<00:19, 265.65it/s]Running 10000 simulations.:  50%|████▉     | 4962/10000 [00:18<00:18, 265.34it/s]Running 10000 simulations.:  50%|████▉     | 4989/10000 [00:18<00:18, 265.04it/s]Running 10000 simulations.:  50%|█████     | 5016/10000 [00:18<00:19, 262.24it/s]Running 10000 simulations.:  50%|█████     | 5043/10000 [00:18<00:19, 258.98it/s]Running 10000 simulations.:  51%|█████     | 5070/10000 [00:19<00:18, 260.83it/s]Running 10000 simulations.:  51%|█████     | 5097/10000 [00:19<00:18, 261.93it/s]Running 10000 simulations.:  51%|█████     | 5124/10000 [00:19<00:18, 262.40it/s]Running 10000 simulations.:  52%|█████▏    | 5151/10000 [00:19<00:18, 262.53it/s]Running 10000 simulations.:  52%|█████▏    | 5178/10000 [00:19<00:18, 263.14it/s]Running 10000 simulations.:  52%|█████▏    | 5205/10000 [00:19<00:18, 263.67it/s]Running 10000 simulations.:  52%|█████▏    | 5232/10000 [00:19<00:18, 263.64it/s]Running 10000 simulations.:  53%|█████▎    | 5259/10000 [00:19<00:18, 263.22it/s]Running 10000 simulations.:  53%|█████▎    | 5286/10000 [00:19<00:17, 262.53it/s]Running 10000 simulations.:  53%|█████▎    | 5313/10000 [00:20<00:17, 262.77it/s]Running 10000 simulations.:  53%|█████▎    | 5340/10000 [00:20<00:17, 263.33it/s]Running 10000 simulations.:  54%|█████▎    | 5367/10000 [00:20<00:17, 262.77it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:20<00:17, 263.18it/s]Running 10000 simulations.:  54%|█████▍    | 5421/10000 [00:20<00:17, 263.04it/s]Running 10000 simulations.:  54%|█████▍    | 5448/10000 [00:20<00:17, 263.22it/s]Running 10000 simulations.:  55%|█████▍    | 5475/10000 [00:20<00:17, 263.58it/s]Running 10000 simulations.:  55%|█████▌    | 5502/10000 [00:20<00:17, 263.71it/s]Running 10000 simulations.:  55%|█████▌    | 5529/10000 [00:20<00:16, 263.31it/s]Running 10000 simulations.:  56%|█████▌    | 5556/10000 [00:20<00:16, 263.83it/s]Running 10000 simulations.:  56%|█████▌    | 5583/10000 [00:21<00:16, 264.47it/s]Running 10000 simulations.:  56%|█████▌    | 5610/10000 [00:21<00:16, 264.22it/s]Running 10000 simulations.:  56%|█████▋    | 5637/10000 [00:21<00:16, 264.41it/s]Running 10000 simulations.:  57%|█████▋    | 5664/10000 [00:21<00:16, 264.97it/s]Running 10000 simulations.:  57%|█████▋    | 5691/10000 [00:21<00:16, 265.05it/s]Running 10000 simulations.:  57%|█████▋    | 5718/10000 [00:21<00:16, 265.41it/s]Running 10000 simulations.:  57%|█████▋    | 5745/10000 [00:21<00:16, 264.93it/s]Running 10000 simulations.:  58%|█████▊    | 5772/10000 [00:21<00:15, 264.57it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:21<00:15, 264.83it/s]Running 10000 simulations.:  58%|█████▊    | 5826/10000 [00:21<00:15, 264.73it/s]Running 10000 simulations.:  59%|█████▊    | 5853/10000 [00:22<00:15, 264.08it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:22<00:15, 264.45it/s]Running 10000 simulations.:  59%|█████▉    | 5907/10000 [00:22<00:15, 264.24it/s]Running 10000 simulations.:  59%|█████▉    | 5934/10000 [00:22<00:15, 264.34it/s]Running 10000 simulations.:  60%|█████▉    | 5961/10000 [00:22<00:15, 264.03it/s]Running 10000 simulations.:  60%|█████▉    | 5988/10000 [00:22<00:15, 264.37it/s]Running 10000 simulations.:  60%|██████    | 6015/10000 [00:22<00:15, 263.93it/s]Running 10000 simulations.:  60%|██████    | 6042/10000 [00:22<00:14, 264.19it/s]Running 10000 simulations.:  61%|██████    | 6069/10000 [00:22<00:14, 264.93it/s]Running 10000 simulations.:  61%|██████    | 6096/10000 [00:22<00:14, 264.88it/s]Running 10000 simulations.:  61%|██████    | 6123/10000 [00:23<00:14, 264.90it/s]Running 10000 simulations.:  62%|██████▏   | 6150/10000 [00:23<00:14, 264.65it/s]Running 10000 simulations.:  62%|██████▏   | 6177/10000 [00:23<00:14, 264.48it/s]Running 10000 simulations.:  62%|██████▏   | 6204/10000 [00:23<00:14, 263.95it/s]Running 10000 simulations.:  62%|██████▏   | 6231/10000 [00:23<00:14, 264.07it/s]Running 10000 simulations.:  63%|██████▎   | 6258/10000 [00:23<00:14, 262.17it/s]Running 10000 simulations.:  63%|██████▎   | 6285/10000 [00:23<00:14, 259.42it/s]Running 10000 simulations.:  63%|██████▎   | 6312/10000 [00:23<00:14, 259.82it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:23<00:14, 260.53it/s]Running 10000 simulations.:  64%|██████▎   | 6366/10000 [00:24<00:13, 260.89it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:24<00:13, 261.07it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:24<00:13, 261.40it/s]Running 10000 simulations.:  64%|██████▍   | 6447/10000 [00:24<00:13, 262.20it/s]Running 10000 simulations.:  65%|██████▍   | 6474/10000 [00:24<00:13, 262.84it/s]Running 10000 simulations.:  65%|██████▌   | 6501/10000 [00:24<00:13, 262.42it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:24<00:13, 262.26it/s]Running 10000 simulations.:  66%|██████▌   | 6555/10000 [00:24<00:13, 262.39it/s]Running 10000 simulations.:  66%|██████▌   | 6582/10000 [00:24<00:13, 262.69it/s]Running 10000 simulations.:  66%|██████▌   | 6609/10000 [00:24<00:12, 263.09it/s]Running 10000 simulations.:  66%|██████▋   | 6636/10000 [00:25<00:12, 262.35it/s]Running 10000 simulations.:  67%|██████▋   | 6663/10000 [00:25<00:12, 262.46it/s]Running 10000 simulations.:  67%|██████▋   | 6690/10000 [00:25<00:12, 262.94it/s]Running 10000 simulations.:  67%|██████▋   | 6717/10000 [00:25<00:12, 263.60it/s]Running 10000 simulations.:  67%|██████▋   | 6744/10000 [00:25<00:12, 263.30it/s]Running 10000 simulations.:  68%|██████▊   | 6771/10000 [00:25<00:12, 263.15it/s]Running 10000 simulations.:  68%|██████▊   | 6798/10000 [00:25<00:12, 263.32it/s]Running 10000 simulations.:  68%|██████▊   | 6825/10000 [00:25<00:12, 263.18it/s]Running 10000 simulations.:  69%|██████▊   | 6852/10000 [00:25<00:11, 263.49it/s]Running 10000 simulations.:  69%|██████▉   | 6879/10000 [00:25<00:11, 263.79it/s]Running 10000 simulations.:  69%|██████▉   | 6906/10000 [00:26<00:11, 264.67it/s]Running 10000 simulations.:  69%|██████▉   | 6933/10000 [00:26<00:11, 264.52it/s]Running 10000 simulations.:  70%|██████▉   | 6960/10000 [00:26<00:11, 264.35it/s]Running 10000 simulations.:  70%|██████▉   | 6987/10000 [00:26<00:11, 263.31it/s]Running 10000 simulations.:  70%|███████   | 7014/10000 [00:26<00:11, 263.17it/s]Running 10000 simulations.:  70%|███████   | 7041/10000 [00:26<00:11, 262.93it/s]Running 10000 simulations.:  71%|███████   | 7068/10000 [00:26<00:11, 263.13it/s]Running 10000 simulations.:  71%|███████   | 7095/10000 [00:26<00:11, 263.21it/s]Running 10000 simulations.:  71%|███████   | 7122/10000 [00:26<00:10, 263.73it/s]Running 10000 simulations.:  71%|███████▏  | 7149/10000 [00:26<00:10, 264.40it/s]Running 10000 simulations.:  72%|███████▏  | 7176/10000 [00:27<00:10, 264.73it/s]Running 10000 simulations.:  72%|███████▏  | 7203/10000 [00:27<00:10, 265.41it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:27<00:10, 265.51it/s]Running 10000 simulations.:  73%|███████▎  | 7257/10000 [00:27<00:10, 264.69it/s]Running 10000 simulations.:  73%|███████▎  | 7284/10000 [00:27<00:10, 264.50it/s]Running 10000 simulations.:  73%|███████▎  | 7311/10000 [00:27<00:10, 264.92it/s]Running 10000 simulations.:  73%|███████▎  | 7338/10000 [00:27<00:10, 265.26it/s]Running 10000 simulations.:  74%|███████▎  | 7365/10000 [00:27<00:09, 264.80it/s]Running 10000 simulations.:  74%|███████▍  | 7392/10000 [00:27<00:09, 265.02it/s]Running 10000 simulations.:  74%|███████▍  | 7419/10000 [00:27<00:09, 264.60it/s]Running 10000 simulations.:  74%|███████▍  | 7446/10000 [00:28<00:09, 265.14it/s]Running 10000 simulations.:  75%|███████▍  | 7473/10000 [00:28<00:09, 264.13it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:28<00:09, 255.65it/s]Running 10000 simulations.:  75%|███████▌  | 7527/10000 [00:28<00:09, 257.60it/s]Running 10000 simulations.:  76%|███████▌  | 7554/10000 [00:28<00:09, 260.08it/s]Running 10000 simulations.:  76%|███████▌  | 7581/10000 [00:28<00:09, 261.45it/s]Running 10000 simulations.:  76%|███████▌  | 7608/10000 [00:28<00:09, 262.65it/s]Running 10000 simulations.:  76%|███████▋  | 7635/10000 [00:28<00:08, 263.10it/s]Running 10000 simulations.:  77%|███████▋  | 7662/10000 [00:28<00:08, 263.60it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:29<00:08, 263.87it/s]Running 10000 simulations.:  77%|███████▋  | 7716/10000 [00:29<00:08, 264.38it/s]Running 10000 simulations.:  77%|███████▋  | 7743/10000 [00:29<00:08, 260.00it/s]Running 10000 simulations.:  78%|███████▊  | 7770/10000 [00:29<00:08, 260.84it/s]Running 10000 simulations.:  78%|███████▊  | 7797/10000 [00:29<00:08, 263.10it/s]Running 10000 simulations.:  78%|███████▊  | 7824/10000 [00:29<00:08, 264.33it/s]Running 10000 simulations.:  79%|███████▊  | 7851/10000 [00:29<00:08, 265.12it/s]Running 10000 simulations.:  79%|███████▉  | 7878/10000 [00:29<00:07, 265.56it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:29<00:07, 265.93it/s]Running 10000 simulations.:  79%|███████▉  | 7932/10000 [00:29<00:07, 266.85it/s]Running 10000 simulations.:  80%|███████▉  | 7959/10000 [00:30<00:07, 265.62it/s]Running 10000 simulations.:  80%|███████▉  | 7986/10000 [00:30<00:07, 264.64it/s]Running 10000 simulations.:  80%|████████  | 8013/10000 [00:30<00:07, 263.74it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:30<00:07, 263.82it/s]Running 10000 simulations.:  81%|████████  | 8067/10000 [00:30<00:07, 263.99it/s]Running 10000 simulations.:  81%|████████  | 8094/10000 [00:30<00:07, 264.51it/s]Running 10000 simulations.:  81%|████████  | 8121/10000 [00:30<00:07, 264.22it/s]Running 10000 simulations.:  81%|████████▏ | 8148/10000 [00:30<00:07, 264.25it/s]Running 10000 simulations.:  82%|████████▏ | 8175/10000 [00:30<00:06, 264.69it/s]Running 10000 simulations.:  82%|████████▏ | 8202/10000 [00:30<00:06, 265.16it/s]Running 10000 simulations.:  82%|████████▏ | 8229/10000 [00:31<00:06, 265.50it/s]Running 10000 simulations.:  83%|████████▎ | 8256/10000 [00:31<00:06, 264.68it/s]Running 10000 simulations.:  83%|████████▎ | 8283/10000 [00:31<00:06, 264.29it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:31<00:06, 264.44it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:31<00:06, 264.67it/s]Running 10000 simulations.:  84%|████████▎ | 8364/10000 [00:31<00:06, 264.74it/s]Running 10000 simulations.:  84%|████████▍ | 8391/10000 [00:31<00:06, 264.56it/s]Running 10000 simulations.:  84%|████████▍ | 8418/10000 [00:31<00:05, 264.93it/s]Running 10000 simulations.:  84%|████████▍ | 8445/10000 [00:31<00:05, 265.26it/s]Running 10000 simulations.:  85%|████████▍ | 8472/10000 [00:31<00:05, 264.64it/s]Running 10000 simulations.:  85%|████████▍ | 8499/10000 [00:32<00:05, 264.33it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [00:32<00:05, 264.37it/s]Running 10000 simulations.:  86%|████████▌ | 8553/10000 [00:32<00:05, 264.26it/s]Running 10000 simulations.:  86%|████████▌ | 8580/10000 [00:32<00:05, 264.06it/s]Running 10000 simulations.:  86%|████████▌ | 8607/10000 [00:32<00:05, 264.30it/s]Running 10000 simulations.:  86%|████████▋ | 8634/10000 [00:32<00:05, 264.25it/s]Running 10000 simulations.:  87%|████████▋ | 8661/10000 [00:32<00:05, 264.23it/s]Running 10000 simulations.:  87%|████████▋ | 8688/10000 [00:32<00:04, 264.61it/s]Running 10000 simulations.:  87%|████████▋ | 8715/10000 [00:32<00:04, 265.22it/s]Running 10000 simulations.:  87%|████████▋ | 8742/10000 [00:33<00:04, 264.72it/s]Running 10000 simulations.:  88%|████████▊ | 8769/10000 [00:33<00:04, 264.86it/s]Running 10000 simulations.:  88%|████████▊ | 8796/10000 [00:33<00:04, 264.32it/s]Running 10000 simulations.:  88%|████████▊ | 8823/10000 [00:33<00:04, 264.30it/s]Running 10000 simulations.:  88%|████████▊ | 8850/10000 [00:33<00:04, 264.67it/s]Running 10000 simulations.:  89%|████████▉ | 8877/10000 [00:33<00:04, 264.80it/s]Running 10000 simulations.:  89%|████████▉ | 8904/10000 [00:33<00:04, 265.22it/s]Running 10000 simulations.:  89%|████████▉ | 8931/10000 [00:33<00:04, 265.15it/s]Running 10000 simulations.:  90%|████████▉ | 8958/10000 [00:33<00:03, 265.45it/s]Running 10000 simulations.:  90%|████████▉ | 8985/10000 [00:33<00:03, 265.26it/s]Running 10000 simulations.:  90%|█████████ | 9012/10000 [00:34<00:03, 259.40it/s]Running 10000 simulations.:  90%|█████████ | 9039/10000 [00:34<00:03, 260.99it/s]Running 10000 simulations.:  91%|█████████ | 9066/10000 [00:34<00:03, 261.49it/s]Running 10000 simulations.:  91%|█████████ | 9093/10000 [00:34<00:03, 261.86it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:34<00:03, 262.69it/s]Running 10000 simulations.:  91%|█████████▏| 9147/10000 [00:34<00:03, 262.41it/s]Running 10000 simulations.:  92%|█████████▏| 9174/10000 [00:34<00:03, 262.31it/s]Running 10000 simulations.:  92%|█████████▏| 9201/10000 [00:34<00:03, 263.07it/s]Running 10000 simulations.:  92%|█████████▏| 9228/10000 [00:34<00:02, 263.69it/s]Running 10000 simulations.:  93%|█████████▎| 9255/10000 [00:34<00:02, 262.81it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [00:35<00:02, 263.25it/s]Running 10000 simulations.:  93%|█████████▎| 9309/10000 [00:35<00:02, 263.05it/s]Running 10000 simulations.:  93%|█████████▎| 9336/10000 [00:35<00:02, 263.42it/s]Running 10000 simulations.:  94%|█████████▎| 9363/10000 [00:35<00:02, 263.93it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:35<00:02, 263.61it/s]Running 10000 simulations.:  94%|█████████▍| 9417/10000 [00:35<00:02, 264.12it/s]Running 10000 simulations.:  94%|█████████▍| 9444/10000 [00:35<00:02, 264.19it/s]Running 10000 simulations.:  95%|█████████▍| 9471/10000 [00:35<00:02, 263.77it/s]Running 10000 simulations.:  95%|█████████▍| 9498/10000 [00:35<00:01, 263.98it/s]Running 10000 simulations.:  95%|█████████▌| 9525/10000 [00:35<00:01, 264.11it/s]Running 10000 simulations.:  96%|█████████▌| 9552/10000 [00:36<00:01, 264.16it/s]Running 10000 simulations.:  96%|█████████▌| 9579/10000 [00:36<00:01, 264.90it/s]Running 10000 simulations.:  96%|█████████▌| 9606/10000 [00:36<00:01, 265.28it/s]Running 10000 simulations.:  96%|█████████▋| 9633/10000 [00:36<00:01, 265.77it/s]Running 10000 simulations.:  97%|█████████▋| 9660/10000 [00:36<00:01, 266.07it/s]Running 10000 simulations.:  97%|█████████▋| 9687/10000 [00:36<00:01, 266.87it/s]Running 10000 simulations.:  97%|█████████▋| 9714/10000 [00:36<00:01, 267.27it/s]Running 10000 simulations.:  97%|█████████▋| 9741/10000 [00:36<00:00, 267.71it/s]Running 10000 simulations.:  98%|█████████▊| 9768/10000 [00:36<00:00, 267.74it/s]Running 10000 simulations.:  98%|█████████▊| 9795/10000 [00:36<00:00, 267.77it/s]Running 10000 simulations.:  98%|█████████▊| 9822/10000 [00:37<00:00, 267.94it/s]Running 10000 simulations.:  98%|█████████▊| 9849/10000 [00:37<00:00, 267.25it/s]Running 10000 simulations.:  99%|█████████▉| 9876/10000 [00:37<00:00, 266.75it/s]Running 10000 simulations.:  99%|█████████▉| 9903/10000 [00:37<00:00, 267.09it/s]Running 10000 simulations.:  99%|█████████▉| 9930/10000 [00:37<00:00, 267.32it/s]Running 10000 simulations.: 100%|█████████▉| 9958/10000 [00:37<00:00, 268.47it/s]Running 10000 simulations.: 100%|█████████▉| 9986/10000 [00:37<00:00, 269.43it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:37<00:00, 264.85it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593757.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53500it [00:00, 540216.82it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601446.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59991it [00:00, 599568.93it/s]           Drawing 50000 posterior samples: 59991it [00:00, 596936.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52656it [00:00, 526414.91it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54366it [00:00, 536611.12it/s]           Drawing 50000 posterior samples: 54366it [00:00, 534008.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 576219.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593750.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596787.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598229.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59035it [00:00, 574425.57it/s]           Drawing 50000 posterior samples: 59035it [00:00, 571875.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59988it [00:00, 598241.73it/s]           Drawing 50000 posterior samples: 59988it [00:00, 595824.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589168.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595304.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 597291.99it/s]           Drawing 50000 posterior samples: 59999it [00:00, 594138.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55028it [00:00, 546159.23it/s]           Drawing 50000 posterior samples: 55028it [00:00, 543810.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55850it [00:00, 561534.26it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 504104.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58366it [00:00, 583585.42it/s]           Drawing 50000 posterior samples: 58366it [00:00, 581159.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 584788.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596247.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602389.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587615.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59988it [00:00, 605774.68it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595636.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602839.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58989it [00:00, 568834.09it/s]           Drawing 50000 posterior samples: 58989it [00:00, 566401.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596741.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596267.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57001it [00:00, 489705.32it/s]           Drawing 50000 posterior samples: 57001it [00:00, 487859.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 588112.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58690it [00:00, 594723.29it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 576211.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608254.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55437it [00:00, 558901.11it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57962it [00:00, 563270.23it/s]           Drawing 50000 posterior samples: 57962it [00:00, 560563.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 588464.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 599684.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596068.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 599664.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 572262.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590442.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602986.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602154.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611462.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59987it [00:00, 575669.21it/s]           Drawing 50000 posterior samples: 59987it [00:00, 572878.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59933it [00:00, 598779.52it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591333.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59976it [00:00, 602063.00it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597703.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 592027.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598017.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589432.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598334.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 592573.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 585719.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59988it [00:00, 604235.54it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593866.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589864.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54797it [00:00, 547110.91it/s]           Drawing 50000 posterior samples: 54797it [00:00, 544731.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55134it [00:00, 521775.37it/s]           Drawing 50000 posterior samples: 55134it [00:00, 519550.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54940it [00:00, 552020.92it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55137it [00:00, 549095.23it/s]           Drawing 50000 posterior samples: 55137it [00:00, 546797.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55183it [00:00, 522220.24it/s]           Drawing 50000 posterior samples: 55183it [00:00, 519813.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53410it [00:00, 530460.65it/s]           Drawing 50000 posterior samples: 53410it [00:00, 528144.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55173it [00:00, 539044.48it/s]           Drawing 50000 posterior samples: 55173it [00:00, 536620.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55243it [00:00, 557320.35it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55263it [00:00, 551716.33it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55189it [00:00, 550437.76it/s]           Drawing 50000 posterior samples: 55189it [00:00, 547841.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55013it [00:00, 544418.05it/s]           Drawing 50000 posterior samples: 55013it [00:00, 542109.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55119it [00:00, 550790.00it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55148it [00:00, 560843.29it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55138it [00:00, 539435.09it/s]           Drawing 50000 posterior samples: 55138it [00:00, 536995.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55049it [00:00, 535750.15it/s]           Drawing 50000 posterior samples: 55049it [00:00, 533195.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55240it [00:00, 555220.11it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55193it [00:00, 566495.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55306it [00:00, 553068.44it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55129it [00:00, 556707.22it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55225it [00:00, 564970.20it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55115it [00:00, 554333.02it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55201it [00:00, 526193.27it/s]           Drawing 50000 posterior samples: 55201it [00:00, 523920.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55190it [00:00, 479637.56it/s]           Drawing 50000 posterior samples: 55190it [00:00, 477831.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55164it [00:00, 556989.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55206it [00:00, 553906.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55253it [00:00, 514668.19it/s]           Drawing 50000 posterior samples: 55253it [00:00, 512091.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55207it [00:00, 542945.70it/s]           Drawing 50000 posterior samples: 55207it [00:00, 540594.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55216it [00:00, 553190.60it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55191it [00:00, 543114.36it/s]           Drawing 50000 posterior samples: 55191it [00:00, 540457.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55212it [00:00, 532176.13it/s]           Drawing 50000 posterior samples: 55212it [00:00, 529620.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55208it [00:00, 544897.59it/s]           Drawing 50000 posterior samples: 55208it [00:00, 542387.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 581152.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51345it [00:00, 441818.63it/s]           Drawing 50000 posterior samples: 51345it [00:00, 440119.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 559550.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59937it [00:00, 580648.29it/s]           Drawing 50000 posterior samples: 59937it [00:00, 578115.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53216it [00:00, 526331.62it/s]           Drawing 50000 posterior samples: 53216it [00:00, 524125.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53288it [00:00, 538352.21it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 570768.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 559943.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 581924.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 605292.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57108it [00:00, 561520.39it/s]           Drawing 50000 posterior samples: 57108it [00:00, 558084.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59765it [00:00, 589754.00it/s]           Drawing 50000 posterior samples: 59765it [00:00, 586747.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596228.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 571322.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59995it [00:00, 595338.94it/s]           Drawing 50000 posterior samples: 59995it [00:00, 592913.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51963it [00:00, 529745.97it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  76%|███████▋  | 38232/50000 [00:00<00:00, 374073.32it/s]Drawing 50000 posterior samples: 51079it [00:00, 372791.83it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59875it [00:00, 594834.93it/s]           Drawing 50000 posterior samples: 59875it [00:00, 591844.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57498it [00:00, 588665.98it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 567846.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608775.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 579570.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596125.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59987it [00:00, 603040.84it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 568047.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 588129.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58266it [00:00, 581169.63it/s]           Drawing 50000 posterior samples: 58266it [00:00, 578467.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59973it [00:00, 595893.20it/s]           Drawing 50000 posterior samples: 59973it [00:00, 593051.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596670.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52325it [00:00, 516913.40it/s]           Drawing 50000 posterior samples: 52325it [00:00, 513812.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54838it [00:00, 540426.74it/s]           Drawing 50000 posterior samples: 54838it [00:00, 537101.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54622it [00:00, 547231.67it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54864it [00:00, 502843.55it/s]           Drawing 50000 posterior samples: 54864it [00:00, 500438.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54735it [00:00, 533583.18it/s]           Drawing 50000 posterior samples: 54735it [00:00, 530933.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51999it [00:00, 518667.33it/s]           Drawing 50000 posterior samples: 51999it [00:00, 516355.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54754it [00:00, 543927.57it/s]           Drawing 50000 posterior samples: 54754it [00:00, 541591.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54906it [00:00, 551466.61it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54751it [00:00, 534322.84it/s]           Drawing 50000 posterior samples: 54751it [00:00, 531974.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54924it [00:00, 559233.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54730it [00:00, 525486.98it/s]           Drawing 50000 posterior samples: 54730it [00:00, 523241.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54730it [00:00, 529683.55it/s]           Drawing 50000 posterior samples: 54730it [00:00, 527415.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54740it [00:00, 574113.94it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54799it [00:00, 562703.76it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54675it [00:00, 567040.30it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54724it [00:00, 568525.49it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54794it [00:00, 573334.10it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54807it [00:00, 570960.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54778it [00:00, 563392.94it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54723it [00:00, 543052.40it/s]           Drawing 50000 posterior samples: 54723it [00:00, 540522.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54872it [00:00, 543522.83it/s]           Drawing 50000 posterior samples: 54872it [00:00, 540526.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54781it [00:00, 522509.14it/s]           Drawing 50000 posterior samples: 54781it [00:00, 520201.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54763it [00:00, 527636.13it/s]           Drawing 50000 posterior samples: 54763it [00:00, 525351.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54845it [00:00, 549074.96it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54848it [00:00, 559213.34it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54830it [00:00, 554436.70it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54591it [00:00, 559115.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54742it [00:00, 548530.84it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54833it [00:00, 556801.42it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54756it [00:00, 555242.55it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54686it [00:00, 563707.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615150.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57927it [00:00, 583163.59it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593483.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59943it [00:00, 602319.89it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57012it [00:00, 495762.65it/s]           Drawing 50000 posterior samples: 57012it [00:00, 493466.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55936it [00:00, 569242.16it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603914.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609346.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608023.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 607350.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59814it [00:00, 615375.43it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597064.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614368.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 619420.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59978it [00:00, 609960.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59531it [00:00, 607324.42it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59902it [00:00, 618841.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615336.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56333it [00:00, 582866.42it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598179.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609754.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 606262.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614200.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601962.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 606725.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612190.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59990it [00:00, 612374.96it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603827.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 613448.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55312it [00:00, 555605.61it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54849it [00:00, 569932.81it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54809it [00:00, 566025.53it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54969it [00:00, 554015.07it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54924it [00:00, 556791.32it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51774it [00:00, 517345.79it/s]           Drawing 50000 posterior samples: 51774it [00:00, 514567.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54944it [00:00, 561636.57it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54796it [00:00, 565455.49it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54800it [00:00, 564216.90it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54930it [00:00, 561915.25it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55008it [00:00, 559096.88it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54896it [00:00, 566866.77it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55002it [00:00, 574915.29it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54994it [00:00, 564232.31it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54865it [00:00, 564121.74it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54868it [00:00, 550462.77it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54826it [00:00, 554940.77it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51750it [00:00, 453546.76it/s]           Drawing 50000 posterior samples: 51750it [00:00, 451796.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55017it [00:00, 578204.69it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54890it [00:00, 554357.79it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54934it [00:00, 583066.73it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54943it [00:00, 571648.82it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55037it [00:00, 544659.41it/s]           Drawing 50000 posterior samples: 55037it [00:00, 541893.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54946it [00:00, 529831.38it/s]           Drawing 50000 posterior samples: 54946it [00:00, 527431.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54892it [00:00, 541577.34it/s]           Drawing 50000 posterior samples: 54892it [00:00, 539199.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55082it [00:00, 542216.01it/s]           Drawing 50000 posterior samples: 55082it [00:00, 539767.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54972it [00:00, 560662.96it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54822it [00:00, 565650.04it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54963it [00:00, 532768.35it/s]           Drawing 50000 posterior samples: 54963it [00:00, 530024.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54848it [00:00, 546507.82it/s]           Drawing 50000 posterior samples: 54848it [00:00, 543991.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54922it [00:00, 561310.45it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597227.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59854it [00:00, 598235.34it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596639.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59987it [00:00, 601180.63it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51646it [00:00, 524924.51it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57504it [00:00, 581791.57it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615377.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615352.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 606528.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 606690.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59901it [00:00, 597807.63it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615798.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608473.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603820.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 604148.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58826it [00:00, 599870.97it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59977it [00:00, 604585.00it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 613661.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59245it [00:00, 597967.90it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602730.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612106.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609102.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 607016.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616042.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 613374.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608284.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59997it [00:00, 616319.35it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 607197.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597574.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54217it [00:00, 544168.51it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55038it [00:00, 557921.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54519it [00:00, 550221.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54939it [00:00, 556907.04it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54927it [00:00, 566035.81it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|█████████▉| 49889/50000 [00:00<00:00, 433899.22it/s]Drawing 50000 posterior samples: 57027it [00:00, 432227.37it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54931it [00:00, 561992.64it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55098it [00:00, 561590.26it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54972it [00:00, 565086.16it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54913it [00:00, 573342.03it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55051it [00:00, 563477.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54873it [00:00, 560716.76it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55084it [00:00, 560853.33it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54869it [00:00, 556341.33it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54980it [00:00, 554936.70it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55065it [00:00, 564649.99it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54973it [00:00, 556358.87it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55037it [00:00, 556197.32it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55077it [00:00, 554811.60it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54900it [00:00, 561961.97it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55068it [00:00, 557203.35it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54996it [00:00, 564747.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54980it [00:00, 568398.87it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55018it [00:00, 568210.50it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54964it [00:00, 548555.00it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54975it [00:00, 558217.68it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54946it [00:00, 562561.89it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54948it [00:00, 552457.31it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54927it [00:00, 563917.34it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54793it [00:00, 554502.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54941it [00:00, 564084.55it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616164.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54663it [00:00, 558513.74it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609079.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59894it [00:00, 620205.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56373it [00:00, 495607.67it/s]           Drawing 50000 posterior samples: 56373it [00:00, 493349.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55465it [00:00, 485530.47it/s]           Drawing 50000 posterior samples: 55465it [00:00, 483492.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596653.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611366.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618588.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611156.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59373it [00:00, 611160.66it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 613096.51it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617461.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611286.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59939it [00:00, 613383.01it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54240it [00:00, 547263.43it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58512it [00:00, 589246.68it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 607197.08it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57266it [00:00, 593606.54it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609495.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618043.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611466.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616691.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596636.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593450.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 606248.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59688it [00:00, 609820.52it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612582.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612303.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55621it [00:00, 568694.06it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
30
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Neural network successfully converged after 255 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Training neural network. Epochs trained:  372Training neural network. Epochs trained:  373Training neural network. Epochs trained:  374Training neural network. Epochs trained:  375Training neural network. Epochs trained:  376Training neural network. Epochs trained:  377Training neural network. Epochs trained:  378Training neural network. Epochs trained:  379Training neural network. Epochs trained:  380Training neural network. Epochs trained:  381Training neural network. Epochs trained:  382Training neural network. Epochs trained:  383Training neural network. Epochs trained:  384Training neural network. Epochs trained:  385Training neural network. Epochs trained:  386Training neural network. Epochs trained:  387Training neural network. Epochs trained:  388Training neural network. Epochs trained:  389Training neural network. Epochs trained:  390Training neural network. Epochs trained:  391Training neural network. Epochs trained:  392Training neural network. Epochs trained:  393Training neural network. Epochs trained:  394Training neural network. Epochs trained:  395Training neural network. Epochs trained:  396Training neural network. Epochs trained:  397Training neural network. Epochs trained:  398Training neural network. Epochs trained:  399Training neural network. Epochs trained:  400Training neural network. Epochs trained:  401Training neural network. Epochs trained:  402Training neural network. Epochs trained:  403Training neural network. Epochs trained:  404Training neural network. Epochs trained:  405Training neural network. Epochs trained:  406Training neural network. Epochs trained:  407Training neural network. Epochs trained:  408Training neural network. Epochs trained:  409Training neural network. Epochs trained:  410Training neural network. Epochs trained:  411Training neural network. Epochs trained:  412Training neural network. Epochs trained:  413Training neural network. Epochs trained:  414Training neural network. Epochs trained:  415Training neural network. Epochs trained:  416Training neural network. Epochs trained:  417Training neural network. Epochs trained:  418Training neural network. Epochs trained:  419Training neural network. Epochs trained:  420Training neural network. Epochs trained:  421Training neural network. Epochs trained:  422Training neural network. Epochs trained:  423Training neural network. Epochs trained:  424Training neural network. Epochs trained:  425Training neural network. Epochs trained:  426Training neural network. Epochs trained:  427Training neural network. Epochs trained:  428Training neural network. Epochs trained:  429Training neural network. Epochs trained:  430Training neural network. Epochs trained:  431Training neural network. Epochs trained:  432Training neural network. Epochs trained:  433Training neural network. Epochs trained:  434Training neural network. Epochs trained:  435Training neural network. Epochs trained:  436Training neural network. Epochs trained:  437Training neural network. Epochs trained:  438Training neural network. Epochs trained:  439Training neural network. Epochs trained:  440Training neural network. Epochs trained:  441Training neural network. Epochs trained:  442Training neural network. Epochs trained:  443Training neural network. Epochs trained:  444Training neural network. Epochs trained:  445Training neural network. Epochs trained:  446Training neural network. Epochs trained:  447Training neural network. Epochs trained:  448Training neural network. Epochs trained:  449Training neural network. Epochs trained:  450Training neural network. Epochs trained:  451Training neural network. Epochs trained:  452Training neural network. Epochs trained:  453Training neural network. Epochs trained:  454Training neural network. Epochs trained:  455Training neural network. Epochs trained:  456Training neural network. Epochs trained:  457Training neural network. Epochs trained:  458Training neural network. Epochs trained:  459Training neural network. Epochs trained:  460Training neural network. Epochs trained:  461Training neural network. Epochs trained:  462Training neural network. Epochs trained:  463Training neural network. Epochs trained:  464Training neural network. Epochs trained:  465Training neural network. Epochs trained:  466Training neural network. Epochs trained:  467Training neural network. Epochs trained:  468Training neural network. Epochs trained:  469Training neural network. Epochs trained:  470Training neural network. Epochs trained:  471Training neural network. Epochs trained:  472Training neural network. Epochs trained:  473Training neural network. Epochs trained:  474Training neural network. Epochs trained:  475Training neural network. Epochs trained:  476Training neural network. Epochs trained:  477Training neural network. Epochs trained:  478Training neural network. Epochs trained:  479Training neural network. Epochs trained:  480Training neural network. Epochs trained:  481Training neural network. Epochs trained:  482Training neural network. Epochs trained:  483Training neural network. Epochs trained:  484Training neural network. Epochs trained:  485Training neural network. Epochs trained:  486Training neural network. Epochs trained:  487Training neural network. Epochs trained:  488Training neural network. Epochs trained:  489Training neural network. Epochs trained:  490Training neural network. Epochs trained:  491Training neural network. Epochs trained:  492Training neural network. Epochs trained:  493Training neural network. Epochs trained:  494Training neural network. Epochs trained:  495Training neural network. Epochs trained:  496Training neural network. Epochs trained:  497Training neural network. Epochs trained:  498Training neural network. Epochs trained:  499Training neural network. Epochs trained:  500Training neural network. Epochs trained:  501Training neural network. Epochs trained:  502Training neural network. Epochs trained:  503Training neural network. Epochs trained:  504Training neural network. Epochs trained:  505Training neural network. Epochs trained:  506Training neural network. Epochs trained:  507Training neural network. Epochs trained:  508Training neural network. Epochs trained:  509Training neural network. Epochs trained:  510Training neural network. Epochs trained:  511Training neural network. Epochs trained:  512Training neural network. Epochs trained:  513Training neural network. Epochs trained:  514Neural network successfully converged after 514 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Neural network successfully converged after 191 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Neural network successfully converged after 148 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Neural network successfully converged after 351 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Neural network successfully converged after 267 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Neural network successfully converged after 294 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Training neural network. Epochs trained:  372Training neural network. Epochs trained:  373Training neural network. Epochs trained:  374Training neural network. Epochs trained:  375Training neural network. Epochs trained:  376Training neural network. Epochs trained:  377Training neural network. Epochs trained:  378Training neural network. Epochs trained:  379Training neural network. Epochs trained:  380Training neural network. Epochs trained:  381Training neural network. Epochs trained:  382Training neural network. Epochs trained:  383Training neural network. Epochs trained:  384Training neural network. Epochs trained:  385Training neural network. Epochs trained:  386Training neural network. Epochs trained:  387Training neural network. Epochs trained:  388Training neural network. Epochs trained:  389Training neural network. Epochs trained:  390Training neural network. Epochs trained:  391Neural network successfully converged after 391 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Neural network successfully converged after 164 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Neural network successfully converged after 256 epochs.
log prob true 6.190191
log prob true 5.8593664
log prob true 6.0376344
log prob true 5.855543
log prob true 5.320314
log prob true 5.5749335
log prob true 5.560245
log prob true 6.083549
log prob true 5.6637964
log prob true 5.883204
log prob true 5.6898694
log prob true 5.797476
log prob true 6.4522796
log prob true 5.92761
log prob true 5.528531
log prob true 4.930362
log prob true 5.6474996
log prob true 5.681811
log prob true 5.429215
log prob true 6.015236
log prob true 6.1321964
log prob true 5.8017526
log prob true 6.176511
log prob true 5.6759953
log prob true 5.9540315
log prob true 5.833326
log prob true 5.4057846
log prob true 5.758716
log prob true 6.0619745
log prob true 5.6774807
log prob true 7.4960365
log prob true 6.9826255
log prob true 7.1536374
log prob true 6.7480955
log prob true 6.496835
log prob true 6.7652187
log prob true 6.9146676
log prob true 7.361975
log prob true 6.8738203
log prob true 7.1609025
log prob true 6.946793
log prob true 7.167117
log prob true 7.5430107
log prob true 7.2114863
log prob true 6.7859936
log prob true 6.597344
log prob true 6.8612614
log prob true 7.1211033
log prob true 6.7863684
log prob true 7.398237
log prob true 7.25709
log prob true 7.0801992
log prob true 7.3325577
log prob true 6.9157
log prob true 7.198739
log prob true 7.1882863
log prob true 6.417196
log prob true 6.950327
log prob true 7.270977
log prob true 6.7894588
log prob true 4.3272953
log prob true 3.7430785
log prob true 4.202144
log prob true 3.490238
log prob true 3.4782827
log prob true 3.0434947
log prob true 3.6446328
log prob true 4.1655574
log prob true 3.8625836
log prob true 3.989106
log prob true 3.4442854
log prob true 4.1042776
log prob true 4.259323
log prob true 4.041971
log prob true 3.415711
log prob true 2.9976816
log prob true 3.778472
log prob true 4.1116304
log prob true 3.2303698
log prob true 4.262287
log prob true 3.9122508
log prob true 3.6877415
log prob true 4.3737526
log prob true 3.7878954
log prob true 4.303039
log prob true 4.041829
log prob true 3.0676746
log prob true 3.5793788
log prob true 4.258374
log prob true 2.8546784
log prob true 5.8926105
log prob true 5.011143
log prob true 5.59263
log prob true 5.48082
log prob true 4.4650254
log prob true 4.9498134
log prob true 5.2328815
log prob true 5.299608
log prob true 5.1519656
log prob true 5.329801
log prob true 4.968441
log prob true 5.430361
log prob true 5.9565835
log prob true 5.67872
log prob true 4.9663405
log prob true 4.736116
log prob true 5.0779257
log prob true 5.156572
log prob true 5.116831
log prob true 5.753905
log prob true 5.895166
log prob true 5.0754423
log prob true 5.340706
log prob true 4.8439918
log prob true 5.4852357
log prob true 5.5472465
log prob true 4.204069
log prob true 4.76936
log prob true 5.4511614
log prob true 4.94072
log prob true 4.3429427
log prob true 3.8562357
log prob true 4.114831
log prob true 3.3007243
log prob true 3.3489552
log prob true 2.6842268
log prob true 3.5371733
log prob true 4.168514
log prob true 3.7830598
log prob true 3.6677005
log prob true 3.1644053
log prob true 4.1398687
log prob true 4.265265
log prob true 3.9748824
log prob true 3.34759
log prob true 2.499095
log prob true 3.7966557
log prob true 4.1112056
log prob true 3.1682472
log prob true 4.141444
log prob true 3.9895535
log prob true 3.6133385
log prob true 4.207002
log prob true 3.812846
log prob true 4.2210836
log prob true 3.9077897
log prob true 3.1607835
log prob true 3.5923674
log prob true 3.9140236
log prob true 2.978146
log prob true 6.777647
log prob true 6.0491524
log prob true 6.522239
log prob true 6.0657463
log prob true 5.875719
log prob true 5.8462176
log prob true 5.8906655
log prob true 6.450002
log prob true 6.003739
log prob true 6.4051943
log prob true 6.1915956
log prob true 6.2308035
log prob true 6.7394676
log prob true 6.4395957
log prob true 5.898281
log prob true 5.5701737
log prob true 5.7263856
log prob true 6.2807755
log prob true 6.022618
log prob true 6.5273876
log prob true 6.4629574
log prob true 6.258507
log prob true 6.445102
log prob true 5.8687067
log prob true 6.223853
log prob true 6.304293
log prob true 5.508696
log prob true 6.0447407
log prob true 6.3441634
log prob true 5.6352315
log prob true 4.283023
log prob true 3.9001987
log prob true 3.967677
log prob true 3.2436738
log prob true 3.2653966
log prob true 2.867103
log prob true 3.505374
log prob true 3.7868953
log prob true 3.645948
log prob true 3.8137946
log prob true 3.2498312
log prob true 4.039314
log prob true 4.158446
log prob true 3.9857745
log prob true 3.1267881
log prob true 2.801644
log prob true 3.723602
log prob true 3.9367766
log prob true 2.9854617
log prob true 4.10081
log prob true 3.811495
log prob true 3.5835218
log prob true 4.114064
log prob true 3.7085469
log prob true 4.108835
log prob true 3.8815103
log prob true 3.175222
log prob true 3.3022027
log prob true 3.8917453
log prob true 2.8587506
log prob true 6.9688506
log prob true 6.3519716
log prob true 6.722304
log prob true 6.461295
log prob true 6.5020394
log prob true 6.108715
log prob true 6.391511
log prob true 6.779878
log prob true 6.552726
log prob true 6.6018763
log prob true 6.408787
log prob true 6.696259
log prob true 6.8470874
log prob true 6.71766
log prob true 6.3777175
log prob true 6.1359377
log prob true 6.370368
log prob true 6.6500998
log prob true 6.38186
log prob true 6.7368464
log prob true 6.860211
log prob true 6.5032926
log prob true 6.513063
log prob true 6.387656
log prob true 6.6868653
log prob true 6.5665126
log prob true 5.9562593
log prob true 6.3641744
log prob true 6.828133
log prob true 6.152661
log prob true 3.9981067
log prob true 3.7360098
log prob true 3.4956427
log prob true 3.0486066
log prob true 3.2368853
log prob true 2.611207
log prob true 3.4978142
log prob true 4.171987
log prob true 3.2951248
log prob true 3.3746984
log prob true 2.851389
log prob true 3.9661596
log prob true 4.0609827
log prob true 3.6070828
log prob true 2.8674939
log prob true 2.1067293
log prob true 3.3924475
log prob true 3.675159
log prob true 2.3981895
log prob true 4.190037
log prob true 3.9721792
log prob true 3.5413334
log prob true 3.6016452
log prob true 3.7020981
log prob true 3.7649834
log prob true 3.9335697
log prob true 3.0384212
log prob true 3.5549564
log prob true 3.6725638
log prob true 2.7368293
log prob true 6.420337
log prob true 5.9377594
log prob true 6.129289
log prob true 5.67535
log prob true 5.5976486
log prob true 5.359216
log prob true 5.7192883
log prob true 6.0620704
log prob true 5.823696
log prob true 6.0531287
log prob true 5.981726
log prob true 5.9873853
log prob true 6.373872
log prob true 6.2739887
log prob true 5.555272
log prob true 5.0045857
log prob true 5.23441
log prob true 5.947418
log prob true 5.7961755
log prob true 6.2492085
log prob true 6.0870633
log prob true 5.840747
log prob true 6.297134
log prob true 5.756257
log prob true 6.1505165
log prob true 6.02983
log prob true 5.281664
log prob true 5.7403417
log prob true 6.2433887
log prob true 5.247383
script complete
