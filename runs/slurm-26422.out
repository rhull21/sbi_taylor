Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 17/10000 [00:00<00:58, 169.41it/s]Running 10000 simulations.:   0%|          | 35/10000 [00:00<00:58, 169.91it/s]Running 10000 simulations.:   1%|          | 53/10000 [00:00<00:58, 170.65it/s]Running 10000 simulations.:   1%|          | 71/10000 [00:00<00:58, 170.56it/s]Running 10000 simulations.:   1%|          | 89/10000 [00:00<00:58, 170.48it/s]Running 10000 simulations.:   1%|          | 107/10000 [00:00<00:57, 170.59it/s]Running 10000 simulations.:   1%|▏         | 125/10000 [00:00<00:57, 170.92it/s]Running 10000 simulations.:   1%|▏         | 143/10000 [00:00<00:57, 170.97it/s]Running 10000 simulations.:   2%|▏         | 161/10000 [00:00<00:57, 170.89it/s]Running 10000 simulations.:   2%|▏         | 179/10000 [00:01<00:57, 170.68it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:01<00:57, 170.57it/s]Running 10000 simulations.:   2%|▏         | 214/10000 [00:01<00:57, 170.07it/s]Running 10000 simulations.:   2%|▏         | 232/10000 [00:01<00:57, 170.55it/s]Running 10000 simulations.:   2%|▎         | 250/10000 [00:01<00:57, 170.81it/s]Running 10000 simulations.:   3%|▎         | 268/10000 [00:01<00:57, 170.61it/s]Running 10000 simulations.:   3%|▎         | 285/10000 [00:01<00:57, 170.32it/s]Running 10000 simulations.:   3%|▎         | 302/10000 [00:01<00:57, 169.95it/s]Running 10000 simulations.:   3%|▎         | 320/10000 [00:01<00:56, 170.07it/s]Running 10000 simulations.:   3%|▎         | 338/10000 [00:01<00:56, 170.13it/s]Running 10000 simulations.:   4%|▎         | 356/10000 [00:02<00:56, 170.27it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:02<00:56, 169.92it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:02<00:56, 170.02it/s]Running 10000 simulations.:   4%|▍         | 410/10000 [00:02<00:56, 170.20it/s]Running 10000 simulations.:   4%|▍         | 428/10000 [00:02<00:56, 170.13it/s]Running 10000 simulations.:   4%|▍         | 446/10000 [00:02<00:56, 169.90it/s]Running 10000 simulations.:   5%|▍         | 463/10000 [00:02<00:56, 169.60it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:02<00:56, 169.67it/s]Running 10000 simulations.:   5%|▍         | 497/10000 [00:02<00:55, 169.76it/s]Running 10000 simulations.:   5%|▌         | 514/10000 [00:03<00:56, 169.11it/s]Running 10000 simulations.:   5%|▌         | 532/10000 [00:03<00:55, 170.17it/s]Running 10000 simulations.:   6%|▌         | 550/10000 [00:03<00:55, 170.54it/s]Running 10000 simulations.:   6%|▌         | 568/10000 [00:03<00:55, 170.48it/s]Running 10000 simulations.:   6%|▌         | 586/10000 [00:03<00:55, 169.83it/s]Running 10000 simulations.:   6%|▌         | 603/10000 [00:03<00:55, 169.73it/s]Running 10000 simulations.:   6%|▌         | 620/10000 [00:03<00:55, 169.28it/s]Running 10000 simulations.:   6%|▋         | 637/10000 [00:03<00:55, 169.17it/s]Running 10000 simulations.:   7%|▋         | 654/10000 [00:03<00:55, 169.01it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:03<00:54, 169.83it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:04<00:54, 170.29it/s]Running 10000 simulations.:   7%|▋         | 708/10000 [00:04<00:54, 169.99it/s]Running 10000 simulations.:   7%|▋         | 726/10000 [00:04<00:54, 170.31it/s]Running 10000 simulations.:   7%|▋         | 744/10000 [00:04<00:54, 170.04it/s]Running 10000 simulations.:   8%|▊         | 762/10000 [00:04<00:54, 170.24it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:04<00:54, 170.00it/s]Running 10000 simulations.:   8%|▊         | 798/10000 [00:04<00:54, 169.85it/s]Running 10000 simulations.:   8%|▊         | 815/10000 [00:04<00:54, 169.86it/s]Running 10000 simulations.:   8%|▊         | 832/10000 [00:04<00:53, 169.87it/s]Running 10000 simulations.:   8%|▊         | 850/10000 [00:04<00:53, 170.01it/s]Running 10000 simulations.:   9%|▊         | 868/10000 [00:05<00:53, 170.24it/s]Running 10000 simulations.:   9%|▉         | 886/10000 [00:05<00:53, 170.38it/s]Running 10000 simulations.:   9%|▉         | 904/10000 [00:05<00:53, 170.24it/s]Running 10000 simulations.:   9%|▉         | 922/10000 [00:05<00:53, 170.12it/s]Running 10000 simulations.:   9%|▉         | 940/10000 [00:05<00:53, 169.73it/s]Running 10000 simulations.:  10%|▉         | 957/10000 [00:05<00:53, 169.80it/s]Running 10000 simulations.:  10%|▉         | 974/10000 [00:05<00:53, 169.27it/s]Running 10000 simulations.:  10%|▉         | 991/10000 [00:05<00:53, 168.93it/s]Running 10000 simulations.:  10%|█         | 1008/10000 [00:05<00:53, 168.95it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:06<00:53, 169.29it/s]Running 10000 simulations.:  10%|█         | 1043/10000 [00:06<00:52, 169.39it/s]Running 10000 simulations.:  11%|█         | 1061/10000 [00:06<00:52, 169.66it/s]Running 10000 simulations.:  11%|█         | 1079/10000 [00:06<00:52, 169.87it/s]Running 10000 simulations.:  11%|█         | 1097/10000 [00:06<00:52, 170.22it/s]Running 10000 simulations.:  11%|█         | 1115/10000 [00:06<00:52, 170.01it/s]Running 10000 simulations.:  11%|█▏        | 1133/10000 [00:06<00:52, 169.92it/s]Running 10000 simulations.:  12%|█▏        | 1150/10000 [00:06<00:52, 169.47it/s]Running 10000 simulations.:  12%|█▏        | 1167/10000 [00:06<00:52, 169.51it/s]Running 10000 simulations.:  12%|█▏        | 1184/10000 [00:06<00:52, 169.22it/s]Running 10000 simulations.:  12%|█▏        | 1201/10000 [00:07<00:52, 169.03it/s]Running 10000 simulations.:  12%|█▏        | 1218/10000 [00:07<00:53, 163.51it/s]Running 10000 simulations.:  12%|█▏        | 1235/10000 [00:07<00:53, 164.58it/s]Running 10000 simulations.:  13%|█▎        | 1252/10000 [00:07<00:52, 165.21it/s]Running 10000 simulations.:  13%|█▎        | 1269/10000 [00:07<00:52, 165.67it/s]Running 10000 simulations.:  13%|█▎        | 1286/10000 [00:07<00:52, 166.19it/s]Running 10000 simulations.:  13%|█▎        | 1303/10000 [00:07<00:52, 166.40it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:07<00:52, 166.71it/s]Running 10000 simulations.:  13%|█▎        | 1337/10000 [00:07<00:51, 166.61it/s]Running 10000 simulations.:  14%|█▎        | 1354/10000 [00:07<00:51, 167.07it/s]Running 10000 simulations.:  14%|█▎        | 1372/10000 [00:08<00:51, 167.94it/s]Running 10000 simulations.:  14%|█▍        | 1390/10000 [00:08<00:51, 168.56it/s]Running 10000 simulations.:  14%|█▍        | 1407/10000 [00:08<00:50, 168.68it/s]Running 10000 simulations.:  14%|█▍        | 1424/10000 [00:08<00:51, 167.33it/s]Running 10000 simulations.:  14%|█▍        | 1441/10000 [00:08<00:51, 165.50it/s]Running 10000 simulations.:  15%|█▍        | 1458/10000 [00:08<00:51, 164.84it/s]Running 10000 simulations.:  15%|█▍        | 1475/10000 [00:08<00:51, 164.57it/s]Running 10000 simulations.:  15%|█▍        | 1494/10000 [00:08<00:49, 170.25it/s]Running 10000 simulations.:  15%|█▌        | 1513/10000 [00:08<00:49, 173.01it/s]Running 10000 simulations.:  15%|█▌        | 1531/10000 [00:09<00:49, 170.56it/s]Running 10000 simulations.:  15%|█▌        | 1549/10000 [00:09<00:50, 168.44it/s]Running 10000 simulations.:  16%|█▌        | 1566/10000 [00:09<00:50, 167.10it/s]Running 10000 simulations.:  16%|█▌        | 1583/10000 [00:09<00:50, 165.91it/s]Running 10000 simulations.:  16%|█▌        | 1600/10000 [00:09<00:50, 165.56it/s]Running 10000 simulations.:  16%|█▌        | 1617/10000 [00:09<00:50, 165.38it/s]Running 10000 simulations.:  16%|█▋        | 1634/10000 [00:09<00:50, 164.71it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:09<00:50, 164.07it/s]Running 10000 simulations.:  17%|█▋        | 1668/10000 [00:09<00:50, 163.87it/s]Running 10000 simulations.:  17%|█▋        | 1685/10000 [00:09<00:50, 163.13it/s]Running 10000 simulations.:  17%|█▋        | 1702/10000 [00:10<00:50, 162.89it/s]Running 10000 simulations.:  17%|█▋        | 1719/10000 [00:10<00:50, 162.99it/s]Running 10000 simulations.:  17%|█▋        | 1736/10000 [00:10<00:50, 163.17it/s]Running 10000 simulations.:  18%|█▊        | 1753/10000 [00:10<00:50, 163.38it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:10<00:50, 163.21it/s]Running 10000 simulations.:  18%|█▊        | 1787/10000 [00:10<00:50, 163.47it/s]Running 10000 simulations.:  18%|█▊        | 1804/10000 [00:10<00:50, 163.21it/s]Running 10000 simulations.:  18%|█▊        | 1821/10000 [00:10<00:50, 163.31it/s]Running 10000 simulations.:  18%|█▊        | 1838/10000 [00:10<00:50, 163.17it/s]Running 10000 simulations.:  19%|█▊        | 1855/10000 [00:11<00:49, 163.11it/s]Running 10000 simulations.:  19%|█▊        | 1872/10000 [00:11<00:49, 163.22it/s]Running 10000 simulations.:  19%|█▉        | 1889/10000 [00:11<00:49, 163.19it/s]Running 10000 simulations.:  19%|█▉        | 1906/10000 [00:11<00:49, 163.34it/s]Running 10000 simulations.:  19%|█▉        | 1923/10000 [00:11<00:49, 162.86it/s]Running 10000 simulations.:  19%|█▉        | 1940/10000 [00:11<00:49, 162.99it/s]Running 10000 simulations.:  20%|█▉        | 1957/10000 [00:11<00:49, 163.21it/s]Running 10000 simulations.:  20%|█▉        | 1974/10000 [00:11<00:49, 163.32it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:11<00:49, 163.23it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:11<00:48, 163.19it/s]Running 10000 simulations.:  20%|██        | 2025/10000 [00:12<00:48, 163.17it/s]Running 10000 simulations.:  20%|██        | 2042/10000 [00:12<00:49, 162.32it/s]Running 10000 simulations.:  21%|██        | 2059/10000 [00:12<00:49, 161.90it/s]Running 10000 simulations.:  21%|██        | 2076/10000 [00:12<00:49, 161.48it/s]Running 10000 simulations.:  21%|██        | 2093/10000 [00:12<00:48, 161.47it/s]Running 10000 simulations.:  21%|██        | 2110/10000 [00:12<00:49, 160.82it/s]Running 10000 simulations.:  21%|██▏       | 2127/10000 [00:12<00:49, 160.30it/s]Running 10000 simulations.:  21%|██▏       | 2144/10000 [00:12<00:49, 160.28it/s]Running 10000 simulations.:  22%|██▏       | 2161/10000 [00:12<00:48, 160.88it/s]Running 10000 simulations.:  22%|██▏       | 2178/10000 [00:13<00:48, 160.98it/s]Running 10000 simulations.:  22%|██▏       | 2195/10000 [00:13<00:48, 161.15it/s]Running 10000 simulations.:  22%|██▏       | 2212/10000 [00:13<00:48, 161.40it/s]Running 10000 simulations.:  22%|██▏       | 2229/10000 [00:13<00:48, 161.55it/s]Running 10000 simulations.:  22%|██▏       | 2246/10000 [00:13<00:47, 162.44it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:13<00:47, 162.36it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:13<00:47, 162.17it/s]Running 10000 simulations.:  23%|██▎       | 2297/10000 [00:13<00:47, 162.08it/s]Running 10000 simulations.:  23%|██▎       | 2314/10000 [00:13<00:47, 161.60it/s]Running 10000 simulations.:  23%|██▎       | 2331/10000 [00:13<00:47, 161.54it/s]Running 10000 simulations.:  23%|██▎       | 2348/10000 [00:14<00:47, 161.20it/s]Running 10000 simulations.:  24%|██▎       | 2365/10000 [00:14<00:47, 160.94it/s]Running 10000 simulations.:  24%|██▍       | 2382/10000 [00:14<00:47, 160.39it/s]Running 10000 simulations.:  24%|██▍       | 2399/10000 [00:14<00:47, 160.59it/s]Running 10000 simulations.:  24%|██▍       | 2416/10000 [00:14<00:46, 161.51it/s]Running 10000 simulations.:  24%|██▍       | 2433/10000 [00:14<00:46, 161.27it/s]Running 10000 simulations.:  24%|██▍       | 2450/10000 [00:14<00:46, 161.05it/s]Running 10000 simulations.:  25%|██▍       | 2467/10000 [00:14<00:46, 160.90it/s]Running 10000 simulations.:  25%|██▍       | 2484/10000 [00:14<00:46, 160.77it/s]Running 10000 simulations.:  25%|██▌       | 2501/10000 [00:15<00:46, 160.94it/s]Running 10000 simulations.:  25%|██▌       | 2518/10000 [00:15<00:46, 160.73it/s]Running 10000 simulations.:  25%|██▌       | 2535/10000 [00:15<00:46, 161.43it/s]Running 10000 simulations.:  26%|██▌       | 2552/10000 [00:15<00:46, 160.91it/s]Running 10000 simulations.:  26%|██▌       | 2569/10000 [00:15<00:46, 161.09it/s]Running 10000 simulations.:  26%|██▌       | 2586/10000 [00:15<00:46, 160.98it/s]Running 10000 simulations.:  26%|██▌       | 2603/10000 [00:15<00:45, 161.11it/s]Running 10000 simulations.:  26%|██▌       | 2620/10000 [00:15<00:45, 160.96it/s]Running 10000 simulations.:  26%|██▋       | 2637/10000 [00:15<00:45, 160.52it/s]Running 10000 simulations.:  27%|██▋       | 2654/10000 [00:15<00:45, 161.24it/s]Running 10000 simulations.:  27%|██▋       | 2671/10000 [00:16<00:45, 161.97it/s]Running 10000 simulations.:  27%|██▋       | 2688/10000 [00:16<00:45, 162.34it/s]Running 10000 simulations.:  27%|██▋       | 2705/10000 [00:16<00:44, 162.53it/s]Running 10000 simulations.:  27%|██▋       | 2722/10000 [00:16<00:44, 162.34it/s]Running 10000 simulations.:  27%|██▋       | 2739/10000 [00:16<00:44, 162.36it/s]Running 10000 simulations.:  28%|██▊       | 2756/10000 [00:16<00:44, 162.33it/s]Running 10000 simulations.:  28%|██▊       | 2773/10000 [00:16<00:44, 162.12it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:16<00:44, 162.13it/s]Running 10000 simulations.:  28%|██▊       | 2807/10000 [00:16<00:44, 162.34it/s]Running 10000 simulations.:  28%|██▊       | 2824/10000 [00:17<00:44, 162.50it/s]Running 10000 simulations.:  28%|██▊       | 2841/10000 [00:17<00:44, 162.62it/s]Running 10000 simulations.:  29%|██▊       | 2858/10000 [00:17<00:43, 162.58it/s]Running 10000 simulations.:  29%|██▉       | 2875/10000 [00:17<00:43, 162.22it/s]Running 10000 simulations.:  29%|██▉       | 2892/10000 [00:17<00:43, 162.53it/s]Running 10000 simulations.:  29%|██▉       | 2909/10000 [00:17<00:43, 162.92it/s]Running 10000 simulations.:  29%|██▉       | 2926/10000 [00:17<00:43, 162.33it/s]Running 10000 simulations.:  29%|██▉       | 2943/10000 [00:17<00:43, 162.21it/s]Running 10000 simulations.:  30%|██▉       | 2960/10000 [00:17<00:43, 162.13it/s]Running 10000 simulations.:  30%|██▉       | 2977/10000 [00:17<00:43, 161.83it/s]Running 10000 simulations.:  30%|██▉       | 2994/10000 [00:18<00:43, 161.72it/s]Running 10000 simulations.:  30%|███       | 3011/10000 [00:18<00:43, 161.95it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:18<00:43, 161.75it/s]Running 10000 simulations.:  30%|███       | 3045/10000 [00:18<00:42, 161.85it/s]Running 10000 simulations.:  31%|███       | 3062/10000 [00:18<00:42, 162.00it/s]Running 10000 simulations.:  31%|███       | 3079/10000 [00:18<00:42, 162.04it/s]Running 10000 simulations.:  31%|███       | 3096/10000 [00:18<00:42, 162.18it/s]Running 10000 simulations.:  31%|███       | 3113/10000 [00:18<00:42, 162.31it/s]Running 10000 simulations.:  31%|███▏      | 3130/10000 [00:18<00:42, 162.11it/s]Running 10000 simulations.:  31%|███▏      | 3147/10000 [00:19<00:42, 162.27it/s]Running 10000 simulations.:  32%|███▏      | 3164/10000 [00:19<00:42, 162.24it/s]Running 10000 simulations.:  32%|███▏      | 3181/10000 [00:19<00:41, 162.40it/s]Running 10000 simulations.:  32%|███▏      | 3198/10000 [00:19<00:41, 162.31it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:19<00:41, 162.34it/s]Running 10000 simulations.:  32%|███▏      | 3232/10000 [00:19<00:41, 162.15it/s]Running 10000 simulations.:  32%|███▏      | 3249/10000 [00:19<00:41, 162.21it/s]Running 10000 simulations.:  33%|███▎      | 3266/10000 [00:19<00:41, 162.19it/s]Running 10000 simulations.:  33%|███▎      | 3283/10000 [00:19<00:41, 162.34it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:19<00:41, 162.33it/s]Running 10000 simulations.:  33%|███▎      | 3317/10000 [00:20<00:41, 162.33it/s]Running 10000 simulations.:  33%|███▎      | 3334/10000 [00:20<00:41, 162.20it/s]Running 10000 simulations.:  34%|███▎      | 3351/10000 [00:20<00:41, 162.15it/s]Running 10000 simulations.:  34%|███▎      | 3368/10000 [00:20<00:40, 162.02it/s]Running 10000 simulations.:  34%|███▍      | 3385/10000 [00:20<00:40, 161.92it/s]Running 10000 simulations.:  34%|███▍      | 3402/10000 [00:20<00:40, 161.80it/s]Running 10000 simulations.:  34%|███▍      | 3419/10000 [00:20<00:40, 161.76it/s]Running 10000 simulations.:  34%|███▍      | 3436/10000 [00:20<00:40, 161.95it/s]Running 10000 simulations.:  35%|███▍      | 3453/10000 [00:20<00:40, 161.86it/s]Running 10000 simulations.:  35%|███▍      | 3470/10000 [00:20<00:40, 161.89it/s]Running 10000 simulations.:  35%|███▍      | 3487/10000 [00:21<00:40, 161.86it/s]Running 10000 simulations.:  35%|███▌      | 3504/10000 [00:21<00:40, 161.90it/s]Running 10000 simulations.:  35%|███▌      | 3521/10000 [00:21<00:40, 161.84it/s]Running 10000 simulations.:  35%|███▌      | 3538/10000 [00:21<00:39, 161.80it/s]Running 10000 simulations.:  36%|███▌      | 3555/10000 [00:21<00:39, 161.89it/s]Running 10000 simulations.:  36%|███▌      | 3572/10000 [00:21<00:39, 162.27it/s]Running 10000 simulations.:  36%|███▌      | 3589/10000 [00:21<00:39, 162.61it/s]Running 10000 simulations.:  36%|███▌      | 3606/10000 [00:21<00:39, 162.48it/s]Running 10000 simulations.:  36%|███▌      | 3623/10000 [00:21<00:39, 162.27it/s]Running 10000 simulations.:  36%|███▋      | 3640/10000 [00:22<00:39, 162.06it/s]Running 10000 simulations.:  37%|███▋      | 3657/10000 [00:22<00:39, 161.75it/s]Running 10000 simulations.:  37%|███▋      | 3674/10000 [00:22<00:39, 162.16it/s]Running 10000 simulations.:  37%|███▋      | 3691/10000 [00:22<00:38, 162.44it/s]Running 10000 simulations.:  37%|███▋      | 3708/10000 [00:22<00:38, 162.40it/s]Running 10000 simulations.:  37%|███▋      | 3725/10000 [00:22<00:38, 162.42it/s]Running 10000 simulations.:  37%|███▋      | 3742/10000 [00:22<00:38, 162.09it/s]Running 10000 simulations.:  38%|███▊      | 3759/10000 [00:22<00:38, 162.17it/s]Running 10000 simulations.:  38%|███▊      | 3776/10000 [00:22<00:38, 162.15it/s]Running 10000 simulations.:  38%|███▊      | 3793/10000 [00:22<00:38, 162.05it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:23<00:38, 161.86it/s]Running 10000 simulations.:  38%|███▊      | 3827/10000 [00:23<00:38, 161.83it/s]Running 10000 simulations.:  38%|███▊      | 3844/10000 [00:23<00:38, 161.76it/s]Running 10000 simulations.:  39%|███▊      | 3861/10000 [00:23<00:37, 162.01it/s]Running 10000 simulations.:  39%|███▉      | 3878/10000 [00:23<00:37, 161.88it/s]Running 10000 simulations.:  39%|███▉      | 3895/10000 [00:23<00:37, 161.82it/s]Running 10000 simulations.:  39%|███▉      | 3912/10000 [00:23<00:37, 161.73it/s]Running 10000 simulations.:  39%|███▉      | 3929/10000 [00:23<00:37, 161.90it/s]Running 10000 simulations.:  39%|███▉      | 3946/10000 [00:23<00:37, 162.03it/s]Running 10000 simulations.:  40%|███▉      | 3963/10000 [00:24<00:37, 161.95it/s]Running 10000 simulations.:  40%|███▉      | 3980/10000 [00:24<00:37, 161.88it/s]Running 10000 simulations.:  40%|███▉      | 3997/10000 [00:24<00:37, 161.96it/s]Running 10000 simulations.:  40%|████      | 4014/10000 [00:24<00:36, 162.15it/s]Running 10000 simulations.:  40%|████      | 4031/10000 [00:24<00:36, 162.23it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:24<00:36, 162.47it/s]Running 10000 simulations.:  41%|████      | 4065/10000 [00:24<00:36, 162.05it/s]Running 10000 simulations.:  41%|████      | 4082/10000 [00:24<00:36, 162.12it/s]Running 10000 simulations.:  41%|████      | 4099/10000 [00:24<00:36, 162.21it/s]Running 10000 simulations.:  41%|████      | 4116/10000 [00:24<00:36, 162.25it/s]Running 10000 simulations.:  41%|████▏     | 4133/10000 [00:25<00:36, 161.95it/s]Running 10000 simulations.:  42%|████▏     | 4150/10000 [00:25<00:36, 161.68it/s]Running 10000 simulations.:  42%|████▏     | 4167/10000 [00:25<00:36, 160.68it/s]Running 10000 simulations.:  42%|████▏     | 4184/10000 [00:25<00:36, 159.80it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:25<00:36, 159.42it/s]Running 10000 simulations.:  42%|████▏     | 4216/10000 [00:25<00:36, 159.01it/s]Running 10000 simulations.:  42%|████▏     | 4232/10000 [00:25<00:36, 158.96it/s]Running 10000 simulations.:  42%|████▏     | 4248/10000 [00:25<00:36, 159.11it/s]Running 10000 simulations.:  43%|████▎     | 4265/10000 [00:25<00:35, 159.51it/s]Running 10000 simulations.:  43%|████▎     | 4282/10000 [00:26<00:35, 160.00it/s]Running 10000 simulations.:  43%|████▎     | 4299/10000 [00:26<00:35, 159.92it/s]Running 10000 simulations.:  43%|████▎     | 4316/10000 [00:26<00:35, 160.87it/s]Running 10000 simulations.:  43%|████▎     | 4333/10000 [00:26<00:35, 161.14it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:26<00:37, 152.23it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:26<00:36, 155.12it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:26<00:35, 157.10it/s]Running 10000 simulations.:  44%|████▍     | 4401/10000 [00:26<00:35, 158.41it/s]Running 10000 simulations.:  44%|████▍     | 4418/10000 [00:26<00:35, 159.38it/s]Running 10000 simulations.:  44%|████▍     | 4435/10000 [00:26<00:34, 160.02it/s]Running 10000 simulations.:  45%|████▍     | 4452/10000 [00:27<00:34, 160.74it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:27<00:34, 160.91it/s]Running 10000 simulations.:  45%|████▍     | 4486/10000 [00:27<00:34, 161.21it/s]Running 10000 simulations.:  45%|████▌     | 4503/10000 [00:27<00:34, 161.30it/s]Running 10000 simulations.:  45%|████▌     | 4520/10000 [00:27<00:33, 161.29it/s]Running 10000 simulations.:  45%|████▌     | 4537/10000 [00:27<00:34, 158.80it/s]Running 10000 simulations.:  46%|████▌     | 4554/10000 [00:27<00:34, 159.79it/s]Running 10000 simulations.:  46%|████▌     | 4571/10000 [00:27<00:33, 160.39it/s]Running 10000 simulations.:  46%|████▌     | 4588/10000 [00:27<00:33, 160.82it/s]Running 10000 simulations.:  46%|████▌     | 4605/10000 [00:28<00:33, 161.10it/s]Running 10000 simulations.:  46%|████▌     | 4622/10000 [00:28<00:33, 161.26it/s]Running 10000 simulations.:  46%|████▋     | 4639/10000 [00:28<00:33, 161.47it/s]Running 10000 simulations.:  47%|████▋     | 4656/10000 [00:28<00:33, 161.61it/s]Running 10000 simulations.:  47%|████▋     | 4673/10000 [00:28<00:32, 161.66it/s]Running 10000 simulations.:  47%|████▋     | 4690/10000 [00:28<00:32, 161.79it/s]Running 10000 simulations.:  47%|████▋     | 4707/10000 [00:28<00:32, 161.79it/s]Running 10000 simulations.:  47%|████▋     | 4724/10000 [00:28<00:32, 161.85it/s]Running 10000 simulations.:  47%|████▋     | 4741/10000 [00:28<00:32, 161.97it/s]Running 10000 simulations.:  48%|████▊     | 4758/10000 [00:28<00:32, 161.71it/s]Running 10000 simulations.:  48%|████▊     | 4775/10000 [00:29<00:32, 161.35it/s]Running 10000 simulations.:  48%|████▊     | 4792/10000 [00:29<00:32, 161.40it/s]Running 10000 simulations.:  48%|████▊     | 4809/10000 [00:29<00:32, 161.43it/s]Running 10000 simulations.:  48%|████▊     | 4826/10000 [00:29<00:32, 161.54it/s]Running 10000 simulations.:  48%|████▊     | 4843/10000 [00:29<00:31, 161.65it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:29<00:31, 161.20it/s]Running 10000 simulations.:  49%|████▉     | 4877/10000 [00:29<00:31, 161.36it/s]Running 10000 simulations.:  49%|████▉     | 4894/10000 [00:29<00:31, 161.46it/s]Running 10000 simulations.:  49%|████▉     | 4911/10000 [00:29<00:31, 161.48it/s]Running 10000 simulations.:  49%|████▉     | 4928/10000 [00:30<00:31, 160.99it/s]Running 10000 simulations.:  49%|████▉     | 4945/10000 [00:30<00:31, 160.55it/s]Running 10000 simulations.:  50%|████▉     | 4962/10000 [00:30<00:31, 160.36it/s]Running 10000 simulations.:  50%|████▉     | 4979/10000 [00:30<00:31, 160.72it/s]Running 10000 simulations.:  50%|████▉     | 4996/10000 [00:30<00:31, 161.02it/s]Running 10000 simulations.:  50%|█████     | 5013/10000 [00:30<00:31, 160.67it/s]Running 10000 simulations.:  50%|█████     | 5030/10000 [00:30<00:30, 161.15it/s]Running 10000 simulations.:  50%|█████     | 5047/10000 [00:30<00:30, 161.47it/s]Running 10000 simulations.:  51%|█████     | 5064/10000 [00:30<00:30, 161.81it/s]Running 10000 simulations.:  51%|█████     | 5081/10000 [00:30<00:30, 161.74it/s]Running 10000 simulations.:  51%|█████     | 5098/10000 [00:31<00:30, 161.84it/s]Running 10000 simulations.:  51%|█████     | 5115/10000 [00:31<00:30, 161.90it/s]Running 10000 simulations.:  51%|█████▏    | 5132/10000 [00:31<00:30, 161.99it/s]Running 10000 simulations.:  51%|█████▏    | 5149/10000 [00:31<00:29, 161.71it/s]Running 10000 simulations.:  52%|█████▏    | 5166/10000 [00:31<00:29, 161.65it/s]Running 10000 simulations.:  52%|█████▏    | 5183/10000 [00:31<00:29, 161.80it/s]Running 10000 simulations.:  52%|█████▏    | 5200/10000 [00:31<00:29, 161.83it/s]Running 10000 simulations.:  52%|█████▏    | 5217/10000 [00:31<00:29, 161.75it/s]Running 10000 simulations.:  52%|█████▏    | 5234/10000 [00:31<00:29, 161.87it/s]Running 10000 simulations.:  53%|█████▎    | 5251/10000 [00:32<00:29, 162.05it/s]Running 10000 simulations.:  53%|█████▎    | 5268/10000 [00:32<00:29, 162.25it/s]Running 10000 simulations.:  53%|█████▎    | 5285/10000 [00:32<00:29, 162.42it/s]Running 10000 simulations.:  53%|█████▎    | 5302/10000 [00:32<00:28, 162.22it/s]Running 10000 simulations.:  53%|█████▎    | 5319/10000 [00:32<00:28, 162.66it/s]Running 10000 simulations.:  53%|█████▎    | 5336/10000 [00:32<00:28, 163.35it/s]Running 10000 simulations.:  54%|█████▎    | 5353/10000 [00:32<00:28, 163.48it/s]Running 10000 simulations.:  54%|█████▎    | 5370/10000 [00:32<00:28, 163.58it/s]Running 10000 simulations.:  54%|█████▍    | 5387/10000 [00:32<00:28, 163.56it/s]Running 10000 simulations.:  54%|█████▍    | 5404/10000 [00:32<00:28, 163.60it/s]Running 10000 simulations.:  54%|█████▍    | 5421/10000 [00:33<00:28, 163.24it/s]Running 10000 simulations.:  54%|█████▍    | 5438/10000 [00:33<00:28, 162.57it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:33<00:28, 161.87it/s]Running 10000 simulations.:  55%|█████▍    | 5472/10000 [00:33<00:28, 161.02it/s]Running 10000 simulations.:  55%|█████▍    | 5489/10000 [00:33<00:28, 160.93it/s]Running 10000 simulations.:  55%|█████▌    | 5506/10000 [00:33<00:27, 161.34it/s]Running 10000 simulations.:  55%|█████▌    | 5523/10000 [00:33<00:27, 161.67it/s]Running 10000 simulations.:  55%|█████▌    | 5540/10000 [00:33<00:27, 161.89it/s]Running 10000 simulations.:  56%|█████▌    | 5557/10000 [00:33<00:27, 162.11it/s]Running 10000 simulations.:  56%|█████▌    | 5574/10000 [00:34<00:27, 162.12it/s]Running 10000 simulations.:  56%|█████▌    | 5591/10000 [00:34<00:27, 162.40it/s]Running 10000 simulations.:  56%|█████▌    | 5608/10000 [00:34<00:27, 162.49it/s]Running 10000 simulations.:  56%|█████▋    | 5625/10000 [00:34<00:26, 162.60it/s]Running 10000 simulations.:  56%|█████▋    | 5642/10000 [00:34<00:26, 162.40it/s]Running 10000 simulations.:  57%|█████▋    | 5659/10000 [00:34<00:26, 162.53it/s]Running 10000 simulations.:  57%|█████▋    | 5676/10000 [00:34<00:26, 162.50it/s]Running 10000 simulations.:  57%|█████▋    | 5693/10000 [00:34<00:26, 162.62it/s]Running 10000 simulations.:  57%|█████▋    | 5712/10000 [00:34<00:25, 167.94it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:34<00:25, 169.71it/s]Running 10000 simulations.:  57%|█████▋    | 5748/10000 [00:35<00:25, 167.35it/s]Running 10000 simulations.:  58%|█████▊    | 5765/10000 [00:35<00:25, 165.76it/s]Running 10000 simulations.:  58%|█████▊    | 5782/10000 [00:35<00:25, 164.75it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:35<00:25, 163.99it/s]Running 10000 simulations.:  58%|█████▊    | 5816/10000 [00:35<00:25, 163.55it/s]Running 10000 simulations.:  58%|█████▊    | 5833/10000 [00:35<00:25, 163.11it/s]Running 10000 simulations.:  58%|█████▊    | 5850/10000 [00:35<00:25, 162.97it/s]Running 10000 simulations.:  59%|█████▊    | 5867/10000 [00:35<00:25, 162.76it/s]Running 10000 simulations.:  59%|█████▉    | 5884/10000 [00:35<00:25, 162.55it/s]Running 10000 simulations.:  59%|█████▉    | 5901/10000 [00:36<00:25, 162.49it/s]Running 10000 simulations.:  59%|█████▉    | 5918/10000 [00:36<00:25, 162.14it/s]Running 10000 simulations.:  59%|█████▉    | 5935/10000 [00:36<00:25, 161.37it/s]Running 10000 simulations.:  60%|█████▉    | 5952/10000 [00:36<00:25, 160.63it/s]Running 10000 simulations.:  60%|█████▉    | 5969/10000 [00:36<00:25, 160.01it/s]Running 10000 simulations.:  60%|█████▉    | 5986/10000 [00:36<00:25, 159.71it/s]Running 10000 simulations.:  60%|██████    | 6002/10000 [00:36<00:25, 159.75it/s]Running 10000 simulations.:  60%|██████    | 6018/10000 [00:36<00:24, 159.69it/s]Running 10000 simulations.:  60%|██████    | 6035/10000 [00:36<00:24, 159.90it/s]Running 10000 simulations.:  61%|██████    | 6051/10000 [00:36<00:24, 159.59it/s]Running 10000 simulations.:  61%|██████    | 6067/10000 [00:37<00:24, 159.57it/s]Running 10000 simulations.:  61%|██████    | 6084/10000 [00:37<00:24, 159.87it/s]Running 10000 simulations.:  61%|██████    | 6101/10000 [00:37<00:24, 160.81it/s]Running 10000 simulations.:  61%|██████    | 6118/10000 [00:37<00:24, 161.47it/s]Running 10000 simulations.:  61%|██████▏   | 6135/10000 [00:37<00:23, 161.90it/s]Running 10000 simulations.:  62%|██████▏   | 6152/10000 [00:37<00:23, 162.12it/s]Running 10000 simulations.:  62%|██████▏   | 6169/10000 [00:37<00:23, 162.75it/s]Running 10000 simulations.:  62%|██████▏   | 6186/10000 [00:37<00:23, 162.28it/s]Running 10000 simulations.:  62%|██████▏   | 6203/10000 [00:37<00:23, 162.43it/s]Running 10000 simulations.:  62%|██████▏   | 6220/10000 [00:38<00:23, 162.79it/s]Running 10000 simulations.:  62%|██████▏   | 6237/10000 [00:38<00:23, 162.87it/s]Running 10000 simulations.:  63%|██████▎   | 6254/10000 [00:38<00:23, 162.67it/s]Running 10000 simulations.:  63%|██████▎   | 6271/10000 [00:38<00:22, 163.24it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:38<00:22, 163.33it/s]Running 10000 simulations.:  63%|██████▎   | 6305/10000 [00:38<00:22, 163.14it/s]Running 10000 simulations.:  63%|██████▎   | 6322/10000 [00:38<00:22, 163.07it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:38<00:22, 163.13it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:38<00:22, 163.03it/s]Running 10000 simulations.:  64%|██████▎   | 6373/10000 [00:38<00:22, 162.80it/s]Running 10000 simulations.:  64%|██████▍   | 6390/10000 [00:39<00:22, 162.76it/s]Running 10000 simulations.:  64%|██████▍   | 6407/10000 [00:39<00:22, 162.80it/s]Running 10000 simulations.:  64%|██████▍   | 6424/10000 [00:39<00:21, 163.14it/s]Running 10000 simulations.:  64%|██████▍   | 6441/10000 [00:39<00:21, 163.32it/s]Running 10000 simulations.:  65%|██████▍   | 6458/10000 [00:39<00:21, 163.34it/s]Running 10000 simulations.:  65%|██████▍   | 6475/10000 [00:39<00:21, 163.93it/s]Running 10000 simulations.:  65%|██████▍   | 6492/10000 [00:39<00:21, 163.92it/s]Running 10000 simulations.:  65%|██████▌   | 6509/10000 [00:39<00:21, 163.63it/s]Running 10000 simulations.:  65%|██████▌   | 6526/10000 [00:39<00:21, 163.40it/s]Running 10000 simulations.:  65%|██████▌   | 6543/10000 [00:39<00:21, 163.49it/s]Running 10000 simulations.:  66%|██████▌   | 6560/10000 [00:40<00:21, 163.43it/s]Running 10000 simulations.:  66%|██████▌   | 6577/10000 [00:40<00:20, 163.39it/s]Running 10000 simulations.:  66%|██████▌   | 6594/10000 [00:40<00:20, 163.27it/s]Running 10000 simulations.:  66%|██████▌   | 6611/10000 [00:40<00:20, 162.90it/s]Running 10000 simulations.:  66%|██████▋   | 6628/10000 [00:40<00:20, 163.02it/s]Running 10000 simulations.:  66%|██████▋   | 6645/10000 [00:40<00:20, 162.93it/s]Running 10000 simulations.:  67%|██████▋   | 6662/10000 [00:40<00:20, 162.68it/s]Running 10000 simulations.:  67%|██████▋   | 6679/10000 [00:40<00:20, 162.51it/s]Running 10000 simulations.:  67%|██████▋   | 6696/10000 [00:40<00:20, 162.55it/s]Running 10000 simulations.:  67%|██████▋   | 6713/10000 [00:41<00:20, 162.15it/s]Running 10000 simulations.:  67%|██████▋   | 6730/10000 [00:41<00:20, 161.93it/s]Running 10000 simulations.:  67%|██████▋   | 6747/10000 [00:41<00:20, 161.82it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:41<00:19, 162.00it/s]Running 10000 simulations.:  68%|██████▊   | 6781/10000 [00:41<00:19, 162.45it/s]Running 10000 simulations.:  68%|██████▊   | 6798/10000 [00:41<00:19, 162.35it/s]Running 10000 simulations.:  68%|██████▊   | 6815/10000 [00:41<00:19, 162.11it/s]Running 10000 simulations.:  68%|██████▊   | 6832/10000 [00:41<00:19, 162.08it/s]Running 10000 simulations.:  68%|██████▊   | 6849/10000 [00:41<00:19, 162.04it/s]Running 10000 simulations.:  69%|██████▊   | 6866/10000 [00:41<00:19, 161.79it/s]Running 10000 simulations.:  69%|██████▉   | 6883/10000 [00:42<00:19, 160.89it/s]Running 10000 simulations.:  69%|██████▉   | 6900/10000 [00:42<00:19, 160.49it/s]Running 10000 simulations.:  69%|██████▉   | 6917/10000 [00:42<00:19, 159.96it/s]Running 10000 simulations.:  69%|██████▉   | 6933/10000 [00:42<00:19, 159.60it/s]Running 10000 simulations.:  69%|██████▉   | 6949/10000 [00:42<00:19, 159.47it/s]Running 10000 simulations.:  70%|██████▉   | 6965/10000 [00:42<00:19, 159.32it/s]Running 10000 simulations.:  70%|██████▉   | 6981/10000 [00:42<00:19, 158.88it/s]Running 10000 simulations.:  70%|██████▉   | 6997/10000 [00:42<00:18, 158.80it/s]Running 10000 simulations.:  70%|███████   | 7013/10000 [00:42<00:18, 158.89it/s]Running 10000 simulations.:  70%|███████   | 7029/10000 [00:43<00:18, 159.14it/s]Running 10000 simulations.:  70%|███████   | 7046/10000 [00:43<00:18, 159.79it/s]Running 10000 simulations.:  71%|███████   | 7063/10000 [00:43<00:18, 160.87it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:43<00:18, 161.12it/s]Running 10000 simulations.:  71%|███████   | 7097/10000 [00:43<00:17, 162.24it/s]Running 10000 simulations.:  71%|███████   | 7114/10000 [00:43<00:17, 162.23it/s]Running 10000 simulations.:  71%|███████▏  | 7131/10000 [00:43<00:17, 162.40it/s]Running 10000 simulations.:  71%|███████▏  | 7148/10000 [00:43<00:17, 159.58it/s]Running 10000 simulations.:  72%|███████▏  | 7165/10000 [00:43<00:17, 160.70it/s]Running 10000 simulations.:  72%|███████▏  | 7182/10000 [00:43<00:17, 161.13it/s]Running 10000 simulations.:  72%|███████▏  | 7199/10000 [00:44<00:17, 161.52it/s]Running 10000 simulations.:  72%|███████▏  | 7216/10000 [00:44<00:17, 161.75it/s]Running 10000 simulations.:  72%|███████▏  | 7233/10000 [00:44<00:17, 161.97it/s]Running 10000 simulations.:  72%|███████▎  | 7250/10000 [00:44<00:16, 161.82it/s]Running 10000 simulations.:  73%|███████▎  | 7267/10000 [00:44<00:16, 162.15it/s]Running 10000 simulations.:  73%|███████▎  | 7284/10000 [00:44<00:16, 161.88it/s]Running 10000 simulations.:  73%|███████▎  | 7301/10000 [00:44<00:16, 161.49it/s]Running 10000 simulations.:  73%|███████▎  | 7318/10000 [00:44<00:16, 160.55it/s]Running 10000 simulations.:  73%|███████▎  | 7335/10000 [00:44<00:16, 159.86it/s]Running 10000 simulations.:  74%|███████▎  | 7351/10000 [00:45<00:16, 159.44it/s]Running 10000 simulations.:  74%|███████▎  | 7367/10000 [00:45<00:16, 156.68it/s]Running 10000 simulations.:  74%|███████▍  | 7383/10000 [00:45<00:16, 157.33it/s]Running 10000 simulations.:  74%|███████▍  | 7399/10000 [00:45<00:16, 157.63it/s]Running 10000 simulations.:  74%|███████▍  | 7415/10000 [00:45<00:16, 157.95it/s]Running 10000 simulations.:  74%|███████▍  | 7431/10000 [00:45<00:16, 158.15it/s]Running 10000 simulations.:  74%|███████▍  | 7447/10000 [00:45<00:16, 158.32it/s]Running 10000 simulations.:  75%|███████▍  | 7463/10000 [00:45<00:15, 158.66it/s]Running 10000 simulations.:  75%|███████▍  | 7480/10000 [00:45<00:15, 159.61it/s]Running 10000 simulations.:  75%|███████▍  | 7497/10000 [00:45<00:15, 160.13it/s]Running 10000 simulations.:  75%|███████▌  | 7514/10000 [00:46<00:15, 160.46it/s]Running 10000 simulations.:  75%|███████▌  | 7531/10000 [00:46<00:15, 161.13it/s]Running 10000 simulations.:  75%|███████▌  | 7548/10000 [00:46<00:15, 161.70it/s]Running 10000 simulations.:  76%|███████▌  | 7565/10000 [00:46<00:15, 161.91it/s]Running 10000 simulations.:  76%|███████▌  | 7582/10000 [00:46<00:14, 162.46it/s]Running 10000 simulations.:  76%|███████▌  | 7599/10000 [00:46<00:14, 162.28it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:46<00:14, 162.35it/s]Running 10000 simulations.:  76%|███████▋  | 7633/10000 [00:46<00:14, 162.50it/s]Running 10000 simulations.:  76%|███████▋  | 7650/10000 [00:46<00:14, 162.57it/s]Running 10000 simulations.:  77%|███████▋  | 7667/10000 [00:46<00:14, 162.57it/s]Running 10000 simulations.:  77%|███████▋  | 7684/10000 [00:47<00:14, 162.61it/s]Running 10000 simulations.:  77%|███████▋  | 7701/10000 [00:47<00:14, 162.53it/s]Running 10000 simulations.:  77%|███████▋  | 7718/10000 [00:47<00:14, 162.40it/s]Running 10000 simulations.:  77%|███████▋  | 7735/10000 [00:47<00:13, 162.84it/s]Running 10000 simulations.:  78%|███████▊  | 7752/10000 [00:47<00:13, 163.22it/s]Running 10000 simulations.:  78%|███████▊  | 7769/10000 [00:47<00:13, 163.12it/s]Running 10000 simulations.:  78%|███████▊  | 7786/10000 [00:47<00:13, 163.21it/s]Running 10000 simulations.:  78%|███████▊  | 7803/10000 [00:47<00:13, 163.58it/s]Running 10000 simulations.:  78%|███████▊  | 7820/10000 [00:47<00:13, 163.32it/s]Running 10000 simulations.:  78%|███████▊  | 7837/10000 [00:48<00:13, 163.39it/s]Running 10000 simulations.:  79%|███████▊  | 7854/10000 [00:48<00:13, 163.83it/s]Running 10000 simulations.:  79%|███████▊  | 7871/10000 [00:48<00:12, 164.01it/s]Running 10000 simulations.:  79%|███████▉  | 7888/10000 [00:48<00:12, 164.08it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:48<00:12, 163.54it/s]Running 10000 simulations.:  79%|███████▉  | 7922/10000 [00:48<00:12, 163.21it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:48<00:12, 162.77it/s]Running 10000 simulations.:  80%|███████▉  | 7956/10000 [00:48<00:12, 162.98it/s]Running 10000 simulations.:  80%|███████▉  | 7973/10000 [00:48<00:12, 162.95it/s]Running 10000 simulations.:  80%|███████▉  | 7990/10000 [00:48<00:12, 162.96it/s]Running 10000 simulations.:  80%|████████  | 8007/10000 [00:49<00:12, 162.54it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:49<00:12, 162.30it/s]Running 10000 simulations.:  80%|████████  | 8041/10000 [00:49<00:12, 162.49it/s]Running 10000 simulations.:  81%|████████  | 8058/10000 [00:49<00:17, 108.93it/s]Running 10000 simulations.:  81%|████████  | 8075/10000 [00:49<00:15, 120.87it/s]Running 10000 simulations.:  81%|████████  | 8092/10000 [00:49<00:14, 130.96it/s]Running 10000 simulations.:  81%|████████  | 8109/10000 [00:49<00:13, 139.42it/s]Running 10000 simulations.:  81%|████████▏ | 8126/10000 [00:49<00:12, 146.00it/s]Running 10000 simulations.:  81%|████████▏ | 8143/10000 [00:50<00:12, 150.90it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:50<00:11, 154.20it/s]Running 10000 simulations.:  82%|████████▏ | 8177/10000 [00:50<00:11, 156.96it/s]Running 10000 simulations.:  82%|████████▏ | 8194/10000 [00:50<00:11, 158.90it/s]Running 10000 simulations.:  82%|████████▏ | 8211/10000 [00:50<00:11, 160.15it/s]Running 10000 simulations.:  82%|████████▏ | 8228/10000 [00:50<00:11, 161.01it/s]Running 10000 simulations.:  82%|████████▏ | 8245/10000 [00:50<00:10, 162.10it/s]Running 10000 simulations.:  83%|████████▎ | 8262/10000 [00:50<00:10, 162.31it/s]Running 10000 simulations.:  83%|████████▎ | 8279/10000 [00:50<00:10, 162.85it/s]Running 10000 simulations.:  83%|████████▎ | 8296/10000 [00:50<00:10, 162.72it/s]Running 10000 simulations.:  83%|████████▎ | 8313/10000 [00:51<00:10, 162.65it/s]Running 10000 simulations.:  83%|████████▎ | 8330/10000 [00:51<00:10, 162.78it/s]Running 10000 simulations.:  83%|████████▎ | 8347/10000 [00:51<00:10, 163.17it/s]Running 10000 simulations.:  84%|████████▎ | 8364/10000 [00:51<00:10, 162.91it/s]Running 10000 simulations.:  84%|████████▍ | 8381/10000 [00:51<00:09, 163.09it/s]Running 10000 simulations.:  84%|████████▍ | 8398/10000 [00:51<00:09, 163.24it/s]Running 10000 simulations.:  84%|████████▍ | 8415/10000 [00:51<00:09, 163.13it/s]Running 10000 simulations.:  84%|████████▍ | 8432/10000 [00:51<00:09, 163.06it/s]Running 10000 simulations.:  84%|████████▍ | 8449/10000 [00:51<00:09, 162.77it/s]Running 10000 simulations.:  85%|████████▍ | 8466/10000 [00:52<00:09, 162.66it/s]Running 10000 simulations.:  85%|████████▍ | 8483/10000 [00:52<00:09, 162.37it/s]Running 10000 simulations.:  85%|████████▌ | 8500/10000 [00:52<00:09, 162.52it/s]Running 10000 simulations.:  85%|████████▌ | 8517/10000 [00:52<00:09, 162.71it/s]Running 10000 simulations.:  85%|████████▌ | 8534/10000 [00:52<00:09, 162.57it/s]Running 10000 simulations.:  86%|████████▌ | 8551/10000 [00:52<00:08, 163.10it/s]Running 10000 simulations.:  86%|████████▌ | 8568/10000 [00:52<00:08, 163.43it/s]Running 10000 simulations.:  86%|████████▌ | 8585/10000 [00:52<00:08, 163.47it/s]Running 10000 simulations.:  86%|████████▌ | 8602/10000 [00:52<00:08, 163.40it/s]Running 10000 simulations.:  86%|████████▌ | 8619/10000 [00:52<00:08, 163.28it/s]Running 10000 simulations.:  86%|████████▋ | 8636/10000 [00:53<00:08, 163.83it/s]Running 10000 simulations.:  87%|████████▋ | 8653/10000 [00:53<00:08, 163.64it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [00:53<00:08, 163.57it/s]Running 10000 simulations.:  87%|████████▋ | 8687/10000 [00:53<00:08, 163.79it/s]Running 10000 simulations.:  87%|████████▋ | 8704/10000 [00:53<00:07, 163.20it/s]Running 10000 simulations.:  87%|████████▋ | 8721/10000 [00:53<00:07, 162.93it/s]Running 10000 simulations.:  87%|████████▋ | 8738/10000 [00:53<00:07, 162.92it/s]Running 10000 simulations.:  88%|████████▊ | 8755/10000 [00:53<00:07, 162.70it/s]Running 10000 simulations.:  88%|████████▊ | 8772/10000 [00:53<00:07, 162.93it/s]Running 10000 simulations.:  88%|████████▊ | 8789/10000 [00:54<00:07, 162.78it/s]Running 10000 simulations.:  88%|████████▊ | 8806/10000 [00:54<00:07, 162.37it/s]Running 10000 simulations.:  88%|████████▊ | 8823/10000 [00:54<00:07, 162.29it/s]Running 10000 simulations.:  88%|████████▊ | 8840/10000 [00:54<00:07, 162.45it/s]Running 10000 simulations.:  89%|████████▊ | 8857/10000 [00:54<00:07, 162.53it/s]Running 10000 simulations.:  89%|████████▊ | 8874/10000 [00:54<00:06, 162.78it/s]Running 10000 simulations.:  89%|████████▉ | 8891/10000 [00:54<00:06, 163.19it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:54<00:06, 162.88it/s]Running 10000 simulations.:  89%|████████▉ | 8925/10000 [00:54<00:06, 162.66it/s]Running 10000 simulations.:  89%|████████▉ | 8942/10000 [00:54<00:06, 162.84it/s]Running 10000 simulations.:  90%|████████▉ | 8959/10000 [00:55<00:06, 162.49it/s]Running 10000 simulations.:  90%|████████▉ | 8976/10000 [00:55<00:06, 162.25it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [00:55<00:06, 161.74it/s]Running 10000 simulations.:  90%|█████████ | 9010/10000 [00:55<00:06, 161.76it/s]Running 10000 simulations.:  90%|█████████ | 9027/10000 [00:55<00:06, 160.77it/s]Running 10000 simulations.:  90%|█████████ | 9044/10000 [00:55<00:05, 160.58it/s]Running 10000 simulations.:  91%|█████████ | 9061/10000 [00:55<00:05, 160.52it/s]Running 10000 simulations.:  91%|█████████ | 9078/10000 [00:55<00:05, 160.55it/s]Running 10000 simulations.:  91%|█████████ | 9095/10000 [00:55<00:05, 160.74it/s]Running 10000 simulations.:  91%|█████████ | 9112/10000 [00:56<00:05, 161.37it/s]Running 10000 simulations.:  91%|█████████▏| 9129/10000 [00:56<00:05, 161.45it/s]Running 10000 simulations.:  91%|█████████▏| 9146/10000 [00:56<00:05, 161.64it/s]Running 10000 simulations.:  92%|█████████▏| 9163/10000 [00:56<00:05, 162.00it/s]Running 10000 simulations.:  92%|█████████▏| 9180/10000 [00:56<00:05, 152.78it/s]Running 10000 simulations.:  92%|█████████▏| 9197/10000 [00:56<00:05, 155.89it/s]Running 10000 simulations.:  92%|█████████▏| 9214/10000 [00:56<00:04, 157.55it/s]Running 10000 simulations.:  92%|█████████▏| 9231/10000 [00:56<00:04, 159.40it/s]Running 10000 simulations.:  92%|█████████▏| 9248/10000 [00:56<00:04, 160.62it/s]Running 10000 simulations.:  93%|█████████▎| 9265/10000 [00:56<00:04, 161.51it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [00:57<00:04, 161.97it/s]Running 10000 simulations.:  93%|█████████▎| 9299/10000 [00:57<00:04, 162.58it/s]Running 10000 simulations.:  93%|█████████▎| 9316/10000 [00:57<00:04, 162.54it/s]Running 10000 simulations.:  93%|█████████▎| 9333/10000 [00:57<00:04, 162.35it/s]Running 10000 simulations.:  94%|█████████▎| 9350/10000 [00:57<00:04, 161.49it/s]Running 10000 simulations.:  94%|█████████▎| 9367/10000 [00:57<00:03, 161.33it/s]Running 10000 simulations.:  94%|█████████▍| 9384/10000 [00:57<00:03, 161.35it/s]Running 10000 simulations.:  94%|█████████▍| 9401/10000 [00:57<00:03, 161.17it/s]Running 10000 simulations.:  94%|█████████▍| 9418/10000 [00:57<00:03, 161.99it/s]Running 10000 simulations.:  94%|█████████▍| 9435/10000 [00:58<00:03, 162.44it/s]Running 10000 simulations.:  95%|█████████▍| 9452/10000 [00:58<00:03, 163.03it/s]Running 10000 simulations.:  95%|█████████▍| 9469/10000 [00:58<00:03, 163.39it/s]Running 10000 simulations.:  95%|█████████▍| 9486/10000 [00:58<00:03, 163.19it/s]Running 10000 simulations.:  95%|█████████▌| 9503/10000 [00:58<00:03, 163.26it/s]Running 10000 simulations.:  95%|█████████▌| 9520/10000 [00:58<00:02, 163.25it/s]Running 10000 simulations.:  95%|█████████▌| 9537/10000 [00:58<00:02, 162.94it/s]Running 10000 simulations.:  96%|█████████▌| 9554/10000 [00:58<00:02, 162.95it/s]Running 10000 simulations.:  96%|█████████▌| 9571/10000 [00:58<00:02, 163.39it/s]Running 10000 simulations.:  96%|█████████▌| 9588/10000 [00:58<00:02, 163.22it/s]Running 10000 simulations.:  96%|█████████▌| 9605/10000 [00:59<00:02, 163.34it/s]Running 10000 simulations.:  96%|█████████▌| 9622/10000 [00:59<00:02, 163.65it/s]Running 10000 simulations.:  96%|█████████▋| 9639/10000 [00:59<00:02, 163.85it/s]Running 10000 simulations.:  97%|█████████▋| 9656/10000 [00:59<00:02, 163.96it/s]Running 10000 simulations.:  97%|█████████▋| 9673/10000 [00:59<00:01, 163.91it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [00:59<00:01, 163.80it/s]Running 10000 simulations.:  97%|█████████▋| 9707/10000 [00:59<00:01, 163.53it/s]Running 10000 simulations.:  97%|█████████▋| 9724/10000 [00:59<00:01, 163.92it/s]Running 10000 simulations.:  97%|█████████▋| 9741/10000 [00:59<00:01, 163.72it/s]Running 10000 simulations.:  98%|█████████▊| 9758/10000 [00:59<00:01, 163.97it/s]Running 10000 simulations.:  98%|█████████▊| 9775/10000 [01:00<00:01, 164.00it/s]Running 10000 simulations.:  98%|█████████▊| 9792/10000 [01:00<00:01, 163.94it/s]Running 10000 simulations.:  98%|█████████▊| 9809/10000 [01:00<00:01, 163.75it/s]Running 10000 simulations.:  98%|█████████▊| 9826/10000 [01:00<00:01, 163.80it/s]Running 10000 simulations.:  98%|█████████▊| 9843/10000 [01:00<00:00, 164.16it/s]Running 10000 simulations.:  99%|█████████▊| 9860/10000 [01:00<00:00, 164.24it/s]Running 10000 simulations.:  99%|█████████▉| 9877/10000 [01:00<00:00, 164.11it/s]Running 10000 simulations.:  99%|█████████▉| 9894/10000 [01:00<00:00, 164.22it/s]Running 10000 simulations.:  99%|█████████▉| 9911/10000 [01:00<00:00, 164.26it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [01:01<00:00, 164.21it/s]Running 10000 simulations.:  99%|█████████▉| 9945/10000 [01:01<00:00, 163.87it/s]Running 10000 simulations.: 100%|█████████▉| 9962/10000 [01:01<00:00, 163.83it/s]Running 10000 simulations.: 100%|█████████▉| 9979/10000 [01:01<00:00, 163.62it/s]Running 10000 simulations.: 100%|█████████▉| 9996/10000 [01:01<00:00, 163.78it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:01<00:00, 162.67it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 14/10000 [00:00<01:13, 135.23it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<01:13, 135.10it/s]Running 10000 simulations.:   0%|          | 42/10000 [00:00<01:13, 134.87it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<01:13, 134.95it/s]Running 10000 simulations.:   1%|          | 70/10000 [00:00<01:13, 134.75it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<01:13, 134.26it/s]Running 10000 simulations.:   1%|          | 98/10000 [00:00<01:14, 133.37it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<01:14, 133.11it/s]Running 10000 simulations.:   1%|▏         | 126/10000 [00:00<01:14, 132.99it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:01<01:14, 132.75it/s]Running 10000 simulations.:   2%|▏         | 154/10000 [00:01<01:14, 132.49it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:01<01:14, 131.84it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:01<01:14, 131.77it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:01<01:14, 131.70it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:01<01:14, 131.89it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:01<01:14, 132.01it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:01<01:14, 131.75it/s]Running 10000 simulations.:   3%|▎         | 253/10000 [00:01<01:12, 134.88it/s]Running 10000 simulations.:   3%|▎         | 268/10000 [00:02<01:10, 137.32it/s]Running 10000 simulations.:   3%|▎         | 283/10000 [00:02<01:10, 138.32it/s]Running 10000 simulations.:   3%|▎         | 298/10000 [00:02<01:09, 139.31it/s]Running 10000 simulations.:   3%|▎         | 313/10000 [00:02<01:09, 140.22it/s]Running 10000 simulations.:   3%|▎         | 328/10000 [00:02<01:08, 140.82it/s]Running 10000 simulations.:   3%|▎         | 343/10000 [00:02<01:08, 140.94it/s]Running 10000 simulations.:   4%|▎         | 358/10000 [00:02<01:08, 141.51it/s]Running 10000 simulations.:   4%|▎         | 373/10000 [00:02<01:08, 141.46it/s]Running 10000 simulations.:   4%|▍         | 388/10000 [00:02<01:08, 140.34it/s]Running 10000 simulations.:   4%|▍         | 403/10000 [00:02<01:08, 139.54it/s]Running 10000 simulations.:   4%|▍         | 417/10000 [00:03<01:08, 139.62it/s]Running 10000 simulations.:   4%|▍         | 432/10000 [00:03<01:08, 140.15it/s]Running 10000 simulations.:   4%|▍         | 447/10000 [00:03<01:07, 140.49it/s]Running 10000 simulations.:   5%|▍         | 462/10000 [00:03<01:07, 140.62it/s]Running 10000 simulations.:   5%|▍         | 477/10000 [00:03<01:07, 140.40it/s]Running 10000 simulations.:   5%|▍         | 492/10000 [00:03<01:07, 140.90it/s]Running 10000 simulations.:   5%|▌         | 507/10000 [00:03<01:07, 141.21it/s]Running 10000 simulations.:   5%|▌         | 522/10000 [00:03<01:07, 141.33it/s]Running 10000 simulations.:   5%|▌         | 537/10000 [00:03<01:07, 140.91it/s]Running 10000 simulations.:   6%|▌         | 552/10000 [00:04<01:07, 140.41it/s]Running 10000 simulations.:   6%|▌         | 567/10000 [00:04<01:07, 140.40it/s]Running 10000 simulations.:   6%|▌         | 582/10000 [00:04<01:07, 139.96it/s]Running 10000 simulations.:   6%|▌         | 597/10000 [00:04<01:07, 140.07it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:04<01:07, 139.91it/s]Running 10000 simulations.:   6%|▋         | 627/10000 [00:04<01:06, 140.22it/s]Running 10000 simulations.:   6%|▋         | 642/10000 [00:04<01:06, 140.44it/s]Running 10000 simulations.:   7%|▋         | 657/10000 [00:04<01:06, 140.64it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:04<01:06, 140.63it/s]Running 10000 simulations.:   7%|▋         | 687/10000 [00:04<01:06, 140.33it/s]Running 10000 simulations.:   7%|▋         | 702/10000 [00:05<01:06, 140.72it/s]Running 10000 simulations.:   7%|▋         | 717/10000 [00:05<01:05, 140.90it/s]Running 10000 simulations.:   7%|▋         | 732/10000 [00:05<01:05, 140.85it/s]Running 10000 simulations.:   7%|▋         | 747/10000 [00:05<01:05, 141.01it/s]Running 10000 simulations.:   8%|▊         | 762/10000 [00:05<01:05, 141.34it/s]Running 10000 simulations.:   8%|▊         | 777/10000 [00:05<01:05, 141.86it/s]Running 10000 simulations.:   8%|▊         | 792/10000 [00:05<01:05, 141.20it/s]Running 10000 simulations.:   8%|▊         | 807/10000 [00:05<01:05, 140.79it/s]Running 10000 simulations.:   8%|▊         | 822/10000 [00:05<01:05, 139.90it/s]Running 10000 simulations.:   8%|▊         | 836/10000 [00:06<01:05, 139.13it/s]Running 10000 simulations.:   8%|▊         | 850/10000 [00:06<01:05, 138.71it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:06<01:05, 138.87it/s]Running 10000 simulations.:   9%|▉         | 878/10000 [00:06<01:05, 138.95it/s]Running 10000 simulations.:   9%|▉         | 893/10000 [00:06<01:05, 139.90it/s]Running 10000 simulations.:   9%|▉         | 908/10000 [00:06<01:04, 139.93it/s]Running 10000 simulations.:   9%|▉         | 922/10000 [00:06<01:04, 139.82it/s]Running 10000 simulations.:   9%|▉         | 936/10000 [00:06<01:04, 139.68it/s]Running 10000 simulations.:  10%|▉         | 950/10000 [00:06<01:04, 139.61it/s]Running 10000 simulations.:  10%|▉         | 965/10000 [00:06<01:04, 139.81it/s]Running 10000 simulations.:  10%|▉         | 980/10000 [00:07<01:04, 139.90it/s]Running 10000 simulations.:  10%|▉         | 995/10000 [00:07<01:03, 141.03it/s]Running 10000 simulations.:  10%|█         | 1010/10000 [00:07<01:03, 141.07it/s]Running 10000 simulations.:  10%|█         | 1025/10000 [00:07<01:03, 140.55it/s]Running 10000 simulations.:  10%|█         | 1040/10000 [00:07<01:03, 140.55it/s]Running 10000 simulations.:  11%|█         | 1055/10000 [00:07<01:03, 140.67it/s]Running 10000 simulations.:  11%|█         | 1070/10000 [00:07<01:03, 140.36it/s]Running 10000 simulations.:  11%|█         | 1085/10000 [00:07<01:03, 140.57it/s]Running 10000 simulations.:  11%|█         | 1100/10000 [00:07<01:03, 140.71it/s]Running 10000 simulations.:  11%|█         | 1115/10000 [00:08<01:03, 140.41it/s]Running 10000 simulations.:  11%|█▏        | 1130/10000 [00:08<01:03, 139.86it/s]Running 10000 simulations.:  11%|█▏        | 1145/10000 [00:08<01:03, 139.96it/s]Running 10000 simulations.:  12%|█▏        | 1160/10000 [00:08<01:03, 140.13it/s]Running 10000 simulations.:  12%|█▏        | 1175/10000 [00:08<01:02, 140.46it/s]Running 10000 simulations.:  12%|█▏        | 1190/10000 [00:08<01:02, 140.35it/s]Running 10000 simulations.:  12%|█▏        | 1205/10000 [00:08<01:02, 140.39it/s]Running 10000 simulations.:  12%|█▏        | 1220/10000 [00:08<01:02, 140.15it/s]Running 10000 simulations.:  12%|█▏        | 1235/10000 [00:08<01:02, 139.70it/s]Running 10000 simulations.:  12%|█▏        | 1249/10000 [00:08<01:02, 139.36it/s]Running 10000 simulations.:  13%|█▎        | 1263/10000 [00:09<01:02, 139.20it/s]Running 10000 simulations.:  13%|█▎        | 1278/10000 [00:09<01:02, 139.61it/s]Running 10000 simulations.:  13%|█▎        | 1293/10000 [00:09<01:02, 140.43it/s]Running 10000 simulations.:  13%|█▎        | 1308/10000 [00:09<01:01, 140.65it/s]Running 10000 simulations.:  13%|█▎        | 1323/10000 [00:09<01:01, 140.35it/s]Running 10000 simulations.:  13%|█▎        | 1338/10000 [00:09<01:01, 140.52it/s]Running 10000 simulations.:  14%|█▎        | 1353/10000 [00:09<01:01, 140.19it/s]Running 10000 simulations.:  14%|█▎        | 1368/10000 [00:09<01:01, 140.16it/s]Running 10000 simulations.:  14%|█▍        | 1383/10000 [00:09<01:01, 140.24it/s]Running 10000 simulations.:  14%|█▍        | 1398/10000 [00:10<01:01, 140.16it/s]Running 10000 simulations.:  14%|█▍        | 1413/10000 [00:10<01:01, 140.52it/s]Running 10000 simulations.:  14%|█▍        | 1428/10000 [00:10<01:00, 141.10it/s]Running 10000 simulations.:  14%|█▍        | 1443/10000 [00:10<01:00, 140.84it/s]Running 10000 simulations.:  15%|█▍        | 1458/10000 [00:10<01:00, 140.78it/s]Running 10000 simulations.:  15%|█▍        | 1473/10000 [00:10<01:00, 140.48it/s]Running 10000 simulations.:  15%|█▍        | 1488/10000 [00:10<01:00, 140.55it/s]Running 10000 simulations.:  15%|█▌        | 1503/10000 [00:10<01:00, 140.92it/s]Running 10000 simulations.:  15%|█▌        | 1518/10000 [00:10<01:00, 140.62it/s]Running 10000 simulations.:  15%|█▌        | 1533/10000 [00:11<01:00, 139.91it/s]Running 10000 simulations.:  15%|█▌        | 1547/10000 [00:11<01:00, 139.75it/s]Running 10000 simulations.:  16%|█▌        | 1562/10000 [00:11<01:00, 140.02it/s]Running 10000 simulations.:  16%|█▌        | 1577/10000 [00:11<01:00, 140.04it/s]Running 10000 simulations.:  16%|█▌        | 1592/10000 [00:11<01:00, 139.91it/s]Running 10000 simulations.:  16%|█▌        | 1606/10000 [00:11<01:00, 139.69it/s]Running 10000 simulations.:  16%|█▌        | 1621/10000 [00:11<00:59, 139.88it/s]Running 10000 simulations.:  16%|█▋        | 1635/10000 [00:11<00:59, 139.84it/s]Running 10000 simulations.:  16%|█▋        | 1649/10000 [00:11<00:59, 139.73it/s]Running 10000 simulations.:  17%|█▋        | 1663/10000 [00:11<00:59, 139.78it/s]Running 10000 simulations.:  17%|█▋        | 1678/10000 [00:12<00:59, 140.05it/s]Running 10000 simulations.:  17%|█▋        | 1693/10000 [00:12<00:59, 139.78it/s]Running 10000 simulations.:  17%|█▋        | 1707/10000 [00:12<01:00, 136.86it/s]Running 10000 simulations.:  17%|█▋        | 1721/10000 [00:12<01:01, 133.66it/s]Running 10000 simulations.:  17%|█▋        | 1735/10000 [00:12<01:02, 131.31it/s]Running 10000 simulations.:  17%|█▋        | 1749/10000 [00:12<01:03, 130.10it/s]Running 10000 simulations.:  18%|█▊        | 1763/10000 [00:12<01:03, 129.12it/s]Running 10000 simulations.:  18%|█▊        | 1776/10000 [00:12<01:03, 128.92it/s]Running 10000 simulations.:  18%|█▊        | 1789/10000 [00:12<01:03, 128.42it/s]Running 10000 simulations.:  18%|█▊        | 1802/10000 [00:13<01:04, 127.59it/s]Running 10000 simulations.:  18%|█▊        | 1815/10000 [00:13<01:04, 127.11it/s]Running 10000 simulations.:  18%|█▊        | 1828/10000 [00:13<01:04, 126.37it/s]Running 10000 simulations.:  18%|█▊        | 1841/10000 [00:13<01:04, 126.31it/s]Running 10000 simulations.:  19%|█▊        | 1854/10000 [00:13<01:04, 125.84it/s]Running 10000 simulations.:  19%|█▊        | 1867/10000 [00:13<01:04, 125.90it/s]Running 10000 simulations.:  19%|█▉        | 1880/10000 [00:13<01:04, 125.86it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:13<01:04, 125.78it/s]Running 10000 simulations.:  19%|█▉        | 1906/10000 [00:13<01:04, 125.76it/s]Running 10000 simulations.:  19%|█▉        | 1919/10000 [00:13<01:04, 125.83it/s]Running 10000 simulations.:  19%|█▉        | 1932/10000 [00:14<01:03, 126.49it/s]Running 10000 simulations.:  19%|█▉        | 1945/10000 [00:14<01:03, 126.96it/s]Running 10000 simulations.:  20%|█▉        | 1958/10000 [00:14<01:03, 126.81it/s]Running 10000 simulations.:  20%|█▉        | 1971/10000 [00:14<01:03, 126.65it/s]Running 10000 simulations.:  20%|█▉        | 1984/10000 [00:14<01:03, 126.67it/s]Running 10000 simulations.:  20%|█▉        | 1997/10000 [00:14<01:02, 127.23it/s]Running 10000 simulations.:  20%|██        | 2010/10000 [00:14<01:02, 127.57it/s]Running 10000 simulations.:  20%|██        | 2023/10000 [00:14<01:02, 127.60it/s]Running 10000 simulations.:  20%|██        | 2036/10000 [00:14<01:02, 127.42it/s]Running 10000 simulations.:  20%|██        | 2049/10000 [00:14<01:02, 128.11it/s]Running 10000 simulations.:  21%|██        | 2062/10000 [00:15<01:02, 127.20it/s]Running 10000 simulations.:  21%|██        | 2075/10000 [00:15<01:03, 125.28it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:15<01:03, 125.28it/s]Running 10000 simulations.:  21%|██        | 2101/10000 [00:15<01:03, 125.21it/s]Running 10000 simulations.:  21%|██        | 2114/10000 [00:15<01:03, 124.99it/s]Running 10000 simulations.:  21%|██▏       | 2127/10000 [00:15<01:02, 125.36it/s]Running 10000 simulations.:  21%|██▏       | 2140/10000 [00:15<01:02, 125.35it/s]Running 10000 simulations.:  22%|██▏       | 2153/10000 [00:15<01:02, 124.87it/s]Running 10000 simulations.:  22%|██▏       | 2166/10000 [00:15<01:02, 124.85it/s]Running 10000 simulations.:  22%|██▏       | 2179/10000 [00:16<01:02, 125.14it/s]Running 10000 simulations.:  22%|██▏       | 2192/10000 [00:16<01:02, 125.29it/s]Running 10000 simulations.:  22%|██▏       | 2205/10000 [00:16<01:02, 125.56it/s]Running 10000 simulations.:  22%|██▏       | 2218/10000 [00:16<01:01, 125.66it/s]Running 10000 simulations.:  22%|██▏       | 2231/10000 [00:16<01:01, 125.33it/s]Running 10000 simulations.:  22%|██▏       | 2244/10000 [00:16<01:01, 125.49it/s]Running 10000 simulations.:  23%|██▎       | 2257/10000 [00:16<01:01, 125.62it/s]Running 10000 simulations.:  23%|██▎       | 2270/10000 [00:16<01:01, 125.10it/s]Running 10000 simulations.:  23%|██▎       | 2283/10000 [00:16<01:02, 124.36it/s]Running 10000 simulations.:  23%|██▎       | 2296/10000 [00:16<01:01, 124.39it/s]Running 10000 simulations.:  23%|██▎       | 2309/10000 [00:17<01:01, 124.53it/s]Running 10000 simulations.:  23%|██▎       | 2322/10000 [00:17<01:01, 124.66it/s]Running 10000 simulations.:  23%|██▎       | 2335/10000 [00:17<01:01, 124.72it/s]Running 10000 simulations.:  23%|██▎       | 2348/10000 [00:17<01:01, 124.85it/s]Running 10000 simulations.:  24%|██▎       | 2362/10000 [00:17<00:59, 128.79it/s]Running 10000 simulations.:  24%|██▍       | 2376/10000 [00:17<00:57, 131.76it/s]Running 10000 simulations.:  24%|██▍       | 2391/10000 [00:17<00:56, 134.28it/s]Running 10000 simulations.:  24%|██▍       | 2405/10000 [00:17<00:56, 135.60it/s]Running 10000 simulations.:  24%|██▍       | 2420/10000 [00:17<00:55, 137.06it/s]Running 10000 simulations.:  24%|██▍       | 2434/10000 [00:17<00:54, 137.84it/s]Running 10000 simulations.:  24%|██▍       | 2448/10000 [00:18<00:54, 138.08it/s]Running 10000 simulations.:  25%|██▍       | 2462/10000 [00:18<00:54, 138.52it/s]Running 10000 simulations.:  25%|██▍       | 2477/10000 [00:18<00:54, 139.12it/s]Running 10000 simulations.:  25%|██▍       | 2492/10000 [00:18<00:53, 139.47it/s]Running 10000 simulations.:  25%|██▌       | 2506/10000 [00:18<00:53, 139.42it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:18<00:53, 138.89it/s]Running 10000 simulations.:  25%|██▌       | 2534/10000 [00:18<00:54, 137.06it/s]Running 10000 simulations.:  25%|██▌       | 2548/10000 [00:18<00:55, 135.30it/s]Running 10000 simulations.:  26%|██▌       | 2562/10000 [00:18<00:56, 132.57it/s]Running 10000 simulations.:  26%|██▌       | 2576/10000 [00:19<00:56, 131.02it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:19<00:56, 130.20it/s]Running 10000 simulations.:  26%|██▌       | 2604/10000 [00:19<00:55, 132.54it/s]Running 10000 simulations.:  26%|██▌       | 2618/10000 [00:19<00:55, 132.90it/s]Running 10000 simulations.:  26%|██▋       | 2632/10000 [00:19<00:55, 133.87it/s]Running 10000 simulations.:  26%|██▋       | 2646/10000 [00:19<00:54, 134.51it/s]Running 10000 simulations.:  27%|██▋       | 2660/10000 [00:19<00:54, 135.03it/s]Running 10000 simulations.:  27%|██▋       | 2674/10000 [00:19<00:53, 135.67it/s]Running 10000 simulations.:  27%|██▋       | 2688/10000 [00:19<00:53, 136.32it/s]Running 10000 simulations.:  27%|██▋       | 2702/10000 [00:19<00:53, 136.90it/s]Running 10000 simulations.:  27%|██▋       | 2716/10000 [00:20<00:53, 136.40it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:20<00:57, 125.70it/s]Running 10000 simulations.:  27%|██▋       | 2744/10000 [00:20<00:56, 127.99it/s]Running 10000 simulations.:  28%|██▊       | 2758/10000 [00:20<00:55, 129.68it/s]Running 10000 simulations.:  28%|██▊       | 2772/10000 [00:20<00:54, 131.68it/s]Running 10000 simulations.:  28%|██▊       | 2786/10000 [00:20<00:54, 132.98it/s]Running 10000 simulations.:  28%|██▊       | 2800/10000 [00:20<00:53, 133.69it/s]Running 10000 simulations.:  28%|██▊       | 2814/10000 [00:20<00:53, 133.85it/s]Running 10000 simulations.:  28%|██▊       | 2828/10000 [00:20<00:53, 133.58it/s]Running 10000 simulations.:  28%|██▊       | 2842/10000 [00:21<00:53, 133.81it/s]Running 10000 simulations.:  29%|██▊       | 2856/10000 [00:21<00:53, 134.16it/s]Running 10000 simulations.:  29%|██▊       | 2870/10000 [00:21<00:52, 134.98it/s]Running 10000 simulations.:  29%|██▉       | 2884/10000 [00:21<00:52, 135.58it/s]Running 10000 simulations.:  29%|██▉       | 2898/10000 [00:21<00:52, 136.52it/s]Running 10000 simulations.:  29%|██▉       | 2912/10000 [00:21<00:51, 136.60it/s]Running 10000 simulations.:  29%|██▉       | 2926/10000 [00:21<00:51, 136.52it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:21<00:51, 136.07it/s]Running 10000 simulations.:  30%|██▉       | 2954/10000 [00:21<00:52, 135.33it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:21<00:53, 132.40it/s]Running 10000 simulations.:  30%|██▉       | 2982/10000 [00:22<00:53, 130.48it/s]Running 10000 simulations.:  30%|██▉       | 2996/10000 [00:22<00:54, 128.88it/s]Running 10000 simulations.:  30%|███       | 3009/10000 [00:22<00:54, 127.50it/s]Running 10000 simulations.:  30%|███       | 3022/10000 [00:22<00:55, 126.58it/s]Running 10000 simulations.:  30%|███       | 3035/10000 [00:22<00:55, 126.32it/s]Running 10000 simulations.:  30%|███       | 3048/10000 [00:22<00:55, 126.17it/s]Running 10000 simulations.:  31%|███       | 3061/10000 [00:22<00:55, 125.65it/s]Running 10000 simulations.:  31%|███       | 3074/10000 [00:22<00:55, 125.45it/s]Running 10000 simulations.:  31%|███       | 3087/10000 [00:22<00:55, 125.36it/s]Running 10000 simulations.:  31%|███       | 3100/10000 [00:23<00:55, 125.41it/s]Running 10000 simulations.:  31%|███       | 3113/10000 [00:23<00:55, 125.13it/s]Running 10000 simulations.:  31%|███▏      | 3127/10000 [00:23<00:54, 126.97it/s]Running 10000 simulations.:  31%|███▏      | 3141/10000 [00:23<00:52, 130.16it/s]Running 10000 simulations.:  32%|███▏      | 3155/10000 [00:23<00:51, 132.96it/s]Running 10000 simulations.:  32%|███▏      | 3170/10000 [00:23<00:50, 135.25it/s]Running 10000 simulations.:  32%|███▏      | 3184/10000 [00:23<00:49, 136.36it/s]Running 10000 simulations.:  32%|███▏      | 3198/10000 [00:23<00:49, 137.35it/s]Running 10000 simulations.:  32%|███▏      | 3212/10000 [00:23<00:49, 137.41it/s]Running 10000 simulations.:  32%|███▏      | 3226/10000 [00:23<00:49, 137.37it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:24<00:49, 137.67it/s]Running 10000 simulations.:  33%|███▎      | 3254/10000 [00:24<00:48, 138.35it/s]Running 10000 simulations.:  33%|███▎      | 3269/10000 [00:24<00:48, 138.93it/s]Running 10000 simulations.:  33%|███▎      | 3283/10000 [00:24<00:48, 139.16it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:24<00:47, 139.82it/s]Running 10000 simulations.:  33%|███▎      | 3313/10000 [00:24<00:47, 139.92it/s]Running 10000 simulations.:  33%|███▎      | 3328/10000 [00:24<00:47, 140.03it/s]Running 10000 simulations.:  33%|███▎      | 3343/10000 [00:24<00:47, 140.71it/s]Running 10000 simulations.:  34%|███▎      | 3358/10000 [00:24<00:47, 141.25it/s]Running 10000 simulations.:  34%|███▎      | 3373/10000 [00:24<00:47, 140.89it/s]Running 10000 simulations.:  34%|███▍      | 3388/10000 [00:25<00:46, 140.99it/s]Running 10000 simulations.:  34%|███▍      | 3403/10000 [00:25<00:46, 141.00it/s]Running 10000 simulations.:  34%|███▍      | 3418/10000 [00:25<00:46, 140.72it/s]Running 10000 simulations.:  34%|███▍      | 3433/10000 [00:25<00:46, 140.00it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:25<00:47, 138.90it/s]Running 10000 simulations.:  35%|███▍      | 3462/10000 [00:25<00:46, 139.20it/s]Running 10000 simulations.:  35%|███▍      | 3477/10000 [00:25<00:46, 139.52it/s]Running 10000 simulations.:  35%|███▍      | 3492/10000 [00:25<00:46, 140.13it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:25<00:47, 137.66it/s]Running 10000 simulations.:  35%|███▌      | 3521/10000 [00:26<00:47, 136.50it/s]Running 10000 simulations.:  35%|███▌      | 3535/10000 [00:26<00:47, 136.20it/s]Running 10000 simulations.:  35%|███▌      | 3549/10000 [00:26<00:47, 136.10it/s]Running 10000 simulations.:  36%|███▌      | 3563/10000 [00:26<00:47, 135.28it/s]Running 10000 simulations.:  36%|███▌      | 3577/10000 [00:26<00:47, 134.50it/s]Running 10000 simulations.:  36%|███▌      | 3591/10000 [00:26<00:47, 134.51it/s]Running 10000 simulations.:  36%|███▌      | 3605/10000 [00:26<00:47, 134.32it/s]Running 10000 simulations.:  36%|███▌      | 3619/10000 [00:26<00:47, 134.67it/s]Running 10000 simulations.:  36%|███▋      | 3633/10000 [00:26<00:46, 135.50it/s]Running 10000 simulations.:  36%|███▋      | 3647/10000 [00:26<00:46, 136.02it/s]Running 10000 simulations.:  37%|███▋      | 3661/10000 [00:27<00:46, 136.01it/s]Running 10000 simulations.:  37%|███▋      | 3675/10000 [00:27<00:46, 136.04it/s]Running 10000 simulations.:  37%|███▋      | 3689/10000 [00:27<00:46, 135.34it/s]Running 10000 simulations.:  37%|███▋      | 3703/10000 [00:27<00:46, 135.26it/s]Running 10000 simulations.:  37%|███▋      | 3717/10000 [00:27<00:46, 135.17it/s]Running 10000 simulations.:  37%|███▋      | 3731/10000 [00:27<00:46, 134.31it/s]Running 10000 simulations.:  37%|███▋      | 3745/10000 [00:27<00:47, 132.76it/s]Running 10000 simulations.:  38%|███▊      | 3759/10000 [00:27<00:47, 131.83it/s]Running 10000 simulations.:  38%|███▊      | 3773/10000 [00:27<00:47, 130.81it/s]Running 10000 simulations.:  38%|███▊      | 3787/10000 [00:28<00:47, 130.85it/s]Running 10000 simulations.:  38%|███▊      | 3801/10000 [00:28<00:47, 131.30it/s]Running 10000 simulations.:  38%|███▊      | 3815/10000 [00:28<00:47, 131.54it/s]Running 10000 simulations.:  38%|███▊      | 3829/10000 [00:28<00:46, 131.36it/s]Running 10000 simulations.:  38%|███▊      | 3843/10000 [00:28<00:46, 131.49it/s]Running 10000 simulations.:  39%|███▊      | 3857/10000 [00:28<00:46, 131.86it/s]Running 10000 simulations.:  39%|███▊      | 3871/10000 [00:28<00:46, 131.71it/s]Running 10000 simulations.:  39%|███▉      | 3885/10000 [00:28<00:46, 131.57it/s]Running 10000 simulations.:  39%|███▉      | 3899/10000 [00:28<00:46, 131.22it/s]Running 10000 simulations.:  39%|███▉      | 3913/10000 [00:28<00:46, 130.45it/s]Running 10000 simulations.:  39%|███▉      | 3927/10000 [00:29<00:46, 130.40it/s]Running 10000 simulations.:  39%|███▉      | 3941/10000 [00:29<00:46, 129.70it/s]Running 10000 simulations.:  40%|███▉      | 3955/10000 [00:29<00:46, 130.21it/s]Running 10000 simulations.:  40%|███▉      | 3969/10000 [00:29<00:46, 130.47it/s]Running 10000 simulations.:  40%|███▉      | 3983/10000 [00:29<00:46, 130.34it/s]Running 10000 simulations.:  40%|███▉      | 3997/10000 [00:29<00:45, 131.57it/s]Running 10000 simulations.:  40%|████      | 4011/10000 [00:29<00:44, 133.25it/s]Running 10000 simulations.:  40%|████      | 4025/10000 [00:29<00:44, 134.13it/s]Running 10000 simulations.:  40%|████      | 4039/10000 [00:29<00:43, 135.56it/s]Running 10000 simulations.:  41%|████      | 4053/10000 [00:30<00:44, 134.91it/s]Running 10000 simulations.:  41%|████      | 4067/10000 [00:30<00:43, 135.03it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:30<00:43, 136.15it/s]Running 10000 simulations.:  41%|████      | 4097/10000 [00:30<00:41, 141.11it/s]Running 10000 simulations.:  41%|████      | 4113/10000 [00:30<00:40, 144.72it/s]Running 10000 simulations.:  41%|████▏     | 4128/10000 [00:30<00:41, 142.26it/s]Running 10000 simulations.:  41%|████▏     | 4143/10000 [00:30<00:41, 140.69it/s]Running 10000 simulations.:  42%|████▏     | 4158/10000 [00:30<00:42, 138.50it/s]Running 10000 simulations.:  42%|████▏     | 4172/10000 [00:30<00:42, 136.97it/s]Running 10000 simulations.:  42%|████▏     | 4186/10000 [00:30<00:42, 135.71it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:31<00:42, 135.99it/s]Running 10000 simulations.:  42%|████▏     | 4215/10000 [00:31<00:42, 137.37it/s]Running 10000 simulations.:  42%|████▏     | 4229/10000 [00:31<00:41, 137.77it/s]Running 10000 simulations.:  42%|████▏     | 4243/10000 [00:31<00:42, 134.50it/s]Running 10000 simulations.:  43%|████▎     | 4257/10000 [00:31<00:43, 132.31it/s]Running 10000 simulations.:  43%|████▎     | 4271/10000 [00:31<00:43, 130.31it/s]Running 10000 simulations.:  43%|████▎     | 4285/10000 [00:31<00:44, 129.43it/s]Running 10000 simulations.:  43%|████▎     | 4298/10000 [00:31<00:44, 128.22it/s]Running 10000 simulations.:  43%|████▎     | 4311/10000 [00:31<00:44, 127.58it/s]Running 10000 simulations.:  43%|████▎     | 4324/10000 [00:32<00:44, 127.11it/s]Running 10000 simulations.:  43%|████▎     | 4337/10000 [00:32<00:44, 126.86it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:32<00:44, 126.44it/s]Running 10000 simulations.:  44%|████▎     | 4363/10000 [00:32<00:44, 126.25it/s]Running 10000 simulations.:  44%|████▍     | 4376/10000 [00:32<00:44, 126.00it/s]Running 10000 simulations.:  44%|████▍     | 4389/10000 [00:32<00:44, 126.05it/s]Running 10000 simulations.:  44%|████▍     | 4403/10000 [00:32<00:43, 129.06it/s]Running 10000 simulations.:  44%|████▍     | 4418/10000 [00:32<00:42, 132.47it/s]Running 10000 simulations.:  44%|████▍     | 4432/10000 [00:32<00:41, 134.35it/s]Running 10000 simulations.:  44%|████▍     | 4446/10000 [00:32<00:40, 135.69it/s]Running 10000 simulations.:  45%|████▍     | 4460/10000 [00:33<00:40, 136.78it/s]Running 10000 simulations.:  45%|████▍     | 4474/10000 [00:33<00:40, 137.23it/s]Running 10000 simulations.:  45%|████▍     | 4489/10000 [00:33<00:39, 138.14it/s]Running 10000 simulations.:  45%|████▌     | 4504/10000 [00:33<00:39, 138.78it/s]Running 10000 simulations.:  45%|████▌     | 4518/10000 [00:33<00:39, 138.92it/s]Running 10000 simulations.:  45%|████▌     | 4533/10000 [00:33<00:39, 139.85it/s]Running 10000 simulations.:  45%|████▌     | 4548/10000 [00:33<00:38, 139.98it/s]Running 10000 simulations.:  46%|████▌     | 4563/10000 [00:33<00:38, 140.13it/s]Running 10000 simulations.:  46%|████▌     | 4578/10000 [00:33<00:38, 139.38it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:34<00:38, 138.68it/s]Running 10000 simulations.:  46%|████▌     | 4606/10000 [00:34<00:38, 138.88it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:34<00:38, 138.91it/s]Running 10000 simulations.:  46%|████▋     | 4634/10000 [00:34<00:38, 139.01it/s]Running 10000 simulations.:  46%|████▋     | 4648/10000 [00:34<00:38, 139.14it/s]Running 10000 simulations.:  47%|████▋     | 4663/10000 [00:34<00:38, 139.55it/s]Running 10000 simulations.:  47%|████▋     | 4677/10000 [00:34<00:38, 139.49it/s]Running 10000 simulations.:  47%|████▋     | 4691/10000 [00:34<00:38, 139.14it/s]Running 10000 simulations.:  47%|████▋     | 4705/10000 [00:34<00:38, 139.28it/s]Running 10000 simulations.:  47%|████▋     | 4719/10000 [00:34<00:38, 138.94it/s]Running 10000 simulations.:  47%|████▋     | 4734/10000 [00:35<00:37, 139.29it/s]Running 10000 simulations.:  47%|████▋     | 4749/10000 [00:35<00:37, 139.67it/s]Running 10000 simulations.:  48%|████▊     | 4764/10000 [00:35<00:37, 140.08it/s]Running 10000 simulations.:  48%|████▊     | 4779/10000 [00:35<00:37, 140.09it/s]Running 10000 simulations.:  48%|████▊     | 4794/10000 [00:35<00:37, 140.09it/s]Running 10000 simulations.:  48%|████▊     | 4809/10000 [00:35<00:36, 140.69it/s]Running 10000 simulations.:  48%|████▊     | 4824/10000 [00:35<00:36, 140.41it/s]Running 10000 simulations.:  48%|████▊     | 4839/10000 [00:35<00:36, 140.03it/s]Running 10000 simulations.:  49%|████▊     | 4854/10000 [00:35<00:36, 139.88it/s]Running 10000 simulations.:  49%|████▊     | 4868/10000 [00:36<00:36, 139.74it/s]Running 10000 simulations.:  49%|████▉     | 4883/10000 [00:36<00:36, 140.22it/s]Running 10000 simulations.:  49%|████▉     | 4898/10000 [00:36<00:36, 140.18it/s]Running 10000 simulations.:  49%|████▉     | 4913/10000 [00:36<00:36, 139.98it/s]Running 10000 simulations.:  49%|████▉     | 4927/10000 [00:36<00:36, 139.92it/s]Running 10000 simulations.:  49%|████▉     | 4941/10000 [00:36<00:36, 139.86it/s]Running 10000 simulations.:  50%|████▉     | 4955/10000 [00:36<00:36, 139.72it/s]Running 10000 simulations.:  50%|████▉     | 4970/10000 [00:36<00:35, 139.94it/s]Running 10000 simulations.:  50%|████▉     | 4984/10000 [00:36<00:35, 139.66it/s]Running 10000 simulations.:  50%|████▉     | 4998/10000 [00:36<00:35, 139.56it/s]Running 10000 simulations.:  50%|█████     | 5012/10000 [00:37<00:35, 139.42it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:37<00:35, 140.08it/s]Running 10000 simulations.:  50%|█████     | 5042/10000 [00:37<00:35, 140.60it/s]Running 10000 simulations.:  51%|█████     | 5057/10000 [00:37<00:35, 140.66it/s]Running 10000 simulations.:  51%|█████     | 5072/10000 [00:37<00:35, 139.89it/s]Running 10000 simulations.:  51%|█████     | 5086/10000 [00:37<00:35, 139.78it/s]Running 10000 simulations.:  51%|█████     | 5101/10000 [00:37<00:34, 140.40it/s]Running 10000 simulations.:  51%|█████     | 5116/10000 [00:37<00:34, 140.35it/s]Running 10000 simulations.:  51%|█████▏    | 5131/10000 [00:37<00:34, 139.83it/s]Running 10000 simulations.:  51%|█████▏    | 5145/10000 [00:37<00:34, 139.48it/s]Running 10000 simulations.:  52%|█████▏    | 5159/10000 [00:38<00:34, 139.49it/s]Running 10000 simulations.:  52%|█████▏    | 5173/10000 [00:38<00:34, 139.21it/s]Running 10000 simulations.:  52%|█████▏    | 5187/10000 [00:38<00:34, 139.23it/s]Running 10000 simulations.:  52%|█████▏    | 5201/10000 [00:38<00:34, 139.45it/s]Running 10000 simulations.:  52%|█████▏    | 5216/10000 [00:38<00:34, 139.77it/s]Running 10000 simulations.:  52%|█████▏    | 5230/10000 [00:38<00:34, 139.77it/s]Running 10000 simulations.:  52%|█████▏    | 5244/10000 [00:38<00:34, 139.59it/s]Running 10000 simulations.:  53%|█████▎    | 5258/10000 [00:38<00:34, 139.37it/s]Running 10000 simulations.:  53%|█████▎    | 5273/10000 [00:38<00:33, 139.59it/s]Running 10000 simulations.:  53%|█████▎    | 5287/10000 [00:39<00:33, 139.65it/s]Running 10000 simulations.:  53%|█████▎    | 5301/10000 [00:39<00:33, 139.64it/s]Running 10000 simulations.:  53%|█████▎    | 5315/10000 [00:39<00:33, 139.59it/s]Running 10000 simulations.:  53%|█████▎    | 5329/10000 [00:39<00:33, 139.47it/s]Running 10000 simulations.:  53%|█████▎    | 5343/10000 [00:39<00:33, 137.64it/s]Running 10000 simulations.:  54%|█████▎    | 5357/10000 [00:39<00:33, 137.37it/s]Running 10000 simulations.:  54%|█████▎    | 5371/10000 [00:39<00:33, 136.20it/s]Running 10000 simulations.:  54%|█████▍    | 5385/10000 [00:39<00:33, 135.87it/s]Running 10000 simulations.:  54%|█████▍    | 5399/10000 [00:39<00:33, 136.13it/s]Running 10000 simulations.:  54%|█████▍    | 5413/10000 [00:39<00:33, 135.14it/s]Running 10000 simulations.:  54%|█████▍    | 5427/10000 [00:40<00:33, 135.21it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:40<00:33, 135.01it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:40<00:33, 134.12it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:40<00:33, 134.32it/s]Running 10000 simulations.:  55%|█████▍    | 5483/10000 [00:40<00:33, 134.55it/s]Running 10000 simulations.:  55%|█████▍    | 5497/10000 [00:40<00:33, 134.88it/s]Running 10000 simulations.:  55%|█████▌    | 5511/10000 [00:40<00:33, 135.53it/s]Running 10000 simulations.:  55%|█████▌    | 5525/10000 [00:40<00:32, 135.81it/s]Running 10000 simulations.:  55%|█████▌    | 5539/10000 [00:40<00:32, 136.16it/s]Running 10000 simulations.:  56%|█████▌    | 5553/10000 [00:40<00:32, 136.64it/s]Running 10000 simulations.:  56%|█████▌    | 5567/10000 [00:41<00:32, 135.28it/s]Running 10000 simulations.:  56%|█████▌    | 5581/10000 [00:41<00:32, 135.21it/s]Running 10000 simulations.:  56%|█████▌    | 5595/10000 [00:41<00:32, 135.21it/s]Running 10000 simulations.:  56%|█████▌    | 5609/10000 [00:41<00:33, 130.90it/s]Running 10000 simulations.:  56%|█████▌    | 5623/10000 [00:41<00:33, 131.29it/s]Running 10000 simulations.:  56%|█████▋    | 5637/10000 [00:41<00:32, 132.88it/s]Running 10000 simulations.:  57%|█████▋    | 5651/10000 [00:41<00:32, 133.69it/s]Running 10000 simulations.:  57%|█████▋    | 5665/10000 [00:41<00:32, 134.33it/s]Running 10000 simulations.:  57%|█████▋    | 5679/10000 [00:41<00:32, 134.00it/s]Running 10000 simulations.:  57%|█████▋    | 5693/10000 [00:42<00:32, 134.15it/s]Running 10000 simulations.:  57%|█████▋    | 5707/10000 [00:42<00:31, 135.02it/s]Running 10000 simulations.:  57%|█████▋    | 5721/10000 [00:42<00:31, 135.13it/s]Running 10000 simulations.:  57%|█████▋    | 5735/10000 [00:42<00:31, 135.56it/s]Running 10000 simulations.:  57%|█████▊    | 5750/10000 [00:42<00:30, 137.10it/s]Running 10000 simulations.:  58%|█████▊    | 5765/10000 [00:42<00:30, 138.03it/s]Running 10000 simulations.:  58%|█████▊    | 5779/10000 [00:42<00:30, 138.13it/s]Running 10000 simulations.:  58%|█████▊    | 5793/10000 [00:42<00:30, 138.51it/s]Running 10000 simulations.:  58%|█████▊    | 5807/10000 [00:42<00:31, 133.17it/s]Running 10000 simulations.:  58%|█████▊    | 5821/10000 [00:42<00:32, 128.16it/s]Running 10000 simulations.:  58%|█████▊    | 5834/10000 [00:43<00:33, 125.17it/s]Running 10000 simulations.:  58%|█████▊    | 5847/10000 [00:43<00:33, 123.36it/s]Running 10000 simulations.:  59%|█████▊    | 5860/10000 [00:43<00:33, 122.57it/s]Running 10000 simulations.:  59%|█████▊    | 5873/10000 [00:43<00:33, 122.05it/s]Running 10000 simulations.:  59%|█████▉    | 5886/10000 [00:43<00:33, 121.66it/s]Running 10000 simulations.:  59%|█████▉    | 5899/10000 [00:43<00:33, 120.89it/s]Running 10000 simulations.:  59%|█████▉    | 5912/10000 [00:43<00:33, 122.12it/s]Running 10000 simulations.:  59%|█████▉    | 5925/10000 [00:43<00:33, 123.26it/s]Running 10000 simulations.:  59%|█████▉    | 5938/10000 [00:43<00:32, 124.21it/s]Running 10000 simulations.:  60%|█████▉    | 5951/10000 [00:44<00:32, 124.30it/s]Running 10000 simulations.:  60%|█████▉    | 5964/10000 [00:44<00:32, 124.78it/s]Running 10000 simulations.:  60%|█████▉    | 5977/10000 [00:44<00:32, 125.15it/s]Running 10000 simulations.:  60%|█████▉    | 5990/10000 [00:44<00:32, 124.71it/s]Running 10000 simulations.:  60%|██████    | 6003/10000 [00:44<00:32, 124.06it/s]Running 10000 simulations.:  60%|██████    | 6016/10000 [00:44<00:32, 123.81it/s]Running 10000 simulations.:  60%|██████    | 6029/10000 [00:44<00:31, 124.12it/s]Running 10000 simulations.:  60%|██████    | 6042/10000 [00:44<00:31, 124.05it/s]Running 10000 simulations.:  61%|██████    | 6055/10000 [00:44<00:31, 123.88it/s]Running 10000 simulations.:  61%|██████    | 6068/10000 [00:44<00:31, 124.05it/s]Running 10000 simulations.:  61%|██████    | 6081/10000 [00:45<00:31, 123.75it/s]Running 10000 simulations.:  61%|██████    | 6094/10000 [00:45<00:31, 123.62it/s]Running 10000 simulations.:  61%|██████    | 6107/10000 [00:45<00:31, 123.62it/s]Running 10000 simulations.:  61%|██████    | 6120/10000 [00:45<00:31, 125.05it/s]Running 10000 simulations.:  61%|██████▏   | 6134/10000 [00:45<00:30, 128.84it/s]Running 10000 simulations.:  61%|██████▏   | 6148/10000 [00:45<00:29, 131.97it/s]Running 10000 simulations.:  62%|██████▏   | 6162/10000 [00:45<00:28, 134.05it/s]Running 10000 simulations.:  62%|██████▏   | 6176/10000 [00:45<00:28, 134.41it/s]Running 10000 simulations.:  62%|██████▏   | 6190/10000 [00:45<00:28, 134.37it/s]Running 10000 simulations.:  62%|██████▏   | 6204/10000 [00:46<00:28, 134.56it/s]Running 10000 simulations.:  62%|██████▏   | 6218/10000 [00:46<00:28, 134.67it/s]Running 10000 simulations.:  62%|██████▏   | 6232/10000 [00:46<00:28, 134.34it/s]Running 10000 simulations.:  62%|██████▏   | 6246/10000 [00:46<00:27, 134.55it/s]Running 10000 simulations.:  63%|██████▎   | 6260/10000 [00:46<00:27, 134.93it/s]Running 10000 simulations.:  63%|██████▎   | 6274/10000 [00:46<00:27, 135.02it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:46<00:27, 135.27it/s]Running 10000 simulations.:  63%|██████▎   | 6302/10000 [00:46<00:27, 135.84it/s]Running 10000 simulations.:  63%|██████▎   | 6316/10000 [00:46<00:27, 135.13it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:46<00:27, 135.39it/s]Running 10000 simulations.:  63%|██████▎   | 6344/10000 [00:47<00:27, 135.14it/s]Running 10000 simulations.:  64%|██████▎   | 6358/10000 [00:47<00:26, 135.10it/s]Running 10000 simulations.:  64%|██████▎   | 6372/10000 [00:47<00:26, 135.22it/s]Running 10000 simulations.:  64%|██████▍   | 6386/10000 [00:47<00:26, 135.03it/s]Running 10000 simulations.:  64%|██████▍   | 6400/10000 [00:47<00:26, 135.07it/s]Running 10000 simulations.:  64%|██████▍   | 6414/10000 [00:47<00:26, 135.15it/s]Running 10000 simulations.:  64%|██████▍   | 6428/10000 [00:47<00:26, 135.03it/s]Running 10000 simulations.:  64%|██████▍   | 6442/10000 [00:47<00:26, 134.54it/s]Running 10000 simulations.:  65%|██████▍   | 6456/10000 [00:47<00:26, 134.51it/s]Running 10000 simulations.:  65%|██████▍   | 6470/10000 [00:47<00:26, 134.03it/s]Running 10000 simulations.:  65%|██████▍   | 6484/10000 [00:48<00:26, 133.84it/s]Running 10000 simulations.:  65%|██████▍   | 6498/10000 [00:48<00:26, 134.32it/s]Running 10000 simulations.:  65%|██████▌   | 6512/10000 [00:48<00:25, 135.39it/s]Running 10000 simulations.:  65%|██████▌   | 6526/10000 [00:48<00:25, 135.63it/s]Running 10000 simulations.:  65%|██████▌   | 6540/10000 [00:48<00:25, 136.04it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:48<00:25, 135.65it/s]Running 10000 simulations.:  66%|██████▌   | 6568/10000 [00:48<00:25, 135.70it/s]Running 10000 simulations.:  66%|██████▌   | 6582/10000 [00:48<00:25, 135.09it/s]Running 10000 simulations.:  66%|██████▌   | 6596/10000 [00:48<00:25, 134.02it/s]Running 10000 simulations.:  66%|██████▌   | 6610/10000 [00:49<00:25, 132.96it/s]Running 10000 simulations.:  66%|██████▌   | 6624/10000 [00:49<00:25, 132.28it/s]Running 10000 simulations.:  66%|██████▋   | 6638/10000 [00:49<00:25, 132.03it/s]Running 10000 simulations.:  67%|██████▋   | 6652/10000 [00:49<00:25, 131.99it/s]Running 10000 simulations.:  67%|██████▋   | 6666/10000 [00:49<00:25, 131.68it/s]Running 10000 simulations.:  67%|██████▋   | 6680/10000 [00:49<00:25, 131.42it/s]Running 10000 simulations.:  67%|██████▋   | 6694/10000 [00:49<00:25, 131.45it/s]Running 10000 simulations.:  67%|██████▋   | 6708/10000 [00:49<00:24, 131.83it/s]Running 10000 simulations.:  67%|██████▋   | 6722/10000 [00:49<00:24, 132.06it/s]Running 10000 simulations.:  67%|██████▋   | 6736/10000 [00:49<00:24, 132.26it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:50<00:24, 132.83it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:50<00:26, 123.53it/s]Running 10000 simulations.:  68%|██████▊   | 6777/10000 [00:50<00:25, 125.09it/s]Running 10000 simulations.:  68%|██████▊   | 6791/10000 [00:50<00:25, 127.18it/s]Running 10000 simulations.:  68%|██████▊   | 6805/10000 [00:50<00:24, 129.30it/s]Running 10000 simulations.:  68%|██████▊   | 6819/10000 [00:50<00:24, 130.79it/s]Running 10000 simulations.:  68%|██████▊   | 6833/10000 [00:50<00:24, 131.85it/s]Running 10000 simulations.:  68%|██████▊   | 6847/10000 [00:50<00:23, 132.69it/s]Running 10000 simulations.:  69%|██████▊   | 6861/10000 [00:50<00:23, 132.02it/s]Running 10000 simulations.:  69%|██████▉   | 6875/10000 [00:51<00:23, 132.21it/s]Running 10000 simulations.:  69%|██████▉   | 6889/10000 [00:51<00:23, 132.47it/s]Running 10000 simulations.:  69%|██████▉   | 6903/10000 [00:51<00:23, 132.89it/s]Running 10000 simulations.:  69%|██████▉   | 6917/10000 [00:51<00:23, 133.94it/s]Running 10000 simulations.:  69%|██████▉   | 6931/10000 [00:51<00:22, 134.14it/s]Running 10000 simulations.:  69%|██████▉   | 6945/10000 [00:51<00:22, 133.63it/s]Running 10000 simulations.:  70%|██████▉   | 6959/10000 [00:51<00:22, 134.26it/s]Running 10000 simulations.:  70%|██████▉   | 6973/10000 [00:51<00:22, 134.14it/s]Running 10000 simulations.:  70%|██████▉   | 6987/10000 [00:51<00:22, 134.45it/s]Running 10000 simulations.:  70%|███████   | 7001/10000 [00:51<00:22, 134.82it/s]Running 10000 simulations.:  70%|███████   | 7015/10000 [00:52<00:22, 134.24it/s]Running 10000 simulations.:  70%|███████   | 7029/10000 [00:52<00:22, 133.46it/s]Running 10000 simulations.:  70%|███████   | 7043/10000 [00:52<00:22, 133.47it/s]Running 10000 simulations.:  71%|███████   | 7057/10000 [00:52<00:22, 132.79it/s]Running 10000 simulations.:  71%|███████   | 7071/10000 [00:52<00:22, 131.51it/s]Running 10000 simulations.:  71%|███████   | 7085/10000 [00:52<00:22, 130.86it/s]Running 10000 simulations.:  71%|███████   | 7099/10000 [00:52<00:22, 130.19it/s]Running 10000 simulations.:  71%|███████   | 7113/10000 [00:52<00:22, 130.05it/s]Running 10000 simulations.:  71%|███████▏  | 7127/10000 [00:52<00:22, 129.53it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:53<00:22, 129.58it/s]Running 10000 simulations.:  72%|███████▏  | 7153/10000 [00:53<00:22, 129.33it/s]Running 10000 simulations.:  72%|███████▏  | 7167/10000 [00:53<00:21, 130.29it/s]Running 10000 simulations.:  72%|███████▏  | 7181/10000 [00:53<00:21, 129.68it/s]Running 10000 simulations.:  72%|███████▏  | 7194/10000 [00:53<00:21, 129.59it/s]Running 10000 simulations.:  72%|███████▏  | 7208/10000 [00:53<00:21, 130.05it/s]Running 10000 simulations.:  72%|███████▏  | 7222/10000 [00:53<00:21, 130.22it/s]Running 10000 simulations.:  72%|███████▏  | 7236/10000 [00:53<00:21, 130.81it/s]Running 10000 simulations.:  72%|███████▎  | 7250/10000 [00:53<00:21, 130.82it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:53<00:20, 131.14it/s]Running 10000 simulations.:  73%|███████▎  | 7278/10000 [00:54<00:21, 128.21it/s]Running 10000 simulations.:  73%|███████▎  | 7292/10000 [00:54<00:20, 129.01it/s]Running 10000 simulations.:  73%|███████▎  | 7305/10000 [00:54<00:20, 129.14it/s]Running 10000 simulations.:  73%|███████▎  | 7318/10000 [00:54<00:20, 129.39it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:54<00:20, 129.18it/s]Running 10000 simulations.:  73%|███████▎  | 7344/10000 [00:54<00:20, 129.32it/s]Running 10000 simulations.:  74%|███████▎  | 7358/10000 [00:54<00:20, 129.93it/s]Running 10000 simulations.:  74%|███████▎  | 7372/10000 [00:54<00:20, 130.68it/s]Running 10000 simulations.:  74%|███████▍  | 7386/10000 [00:54<00:19, 130.97it/s]Running 10000 simulations.:  74%|███████▍  | 7400/10000 [00:55<00:19, 130.54it/s]Running 10000 simulations.:  74%|███████▍  | 7414/10000 [00:55<00:19, 130.19it/s]Running 10000 simulations.:  74%|███████▍  | 7428/10000 [00:55<00:19, 129.91it/s]Running 10000 simulations.:  74%|███████▍  | 7442/10000 [00:55<00:19, 130.10it/s]Running 10000 simulations.:  75%|███████▍  | 7456/10000 [00:55<00:19, 130.19it/s]Running 10000 simulations.:  75%|███████▍  | 7470/10000 [00:55<00:19, 130.35it/s]Running 10000 simulations.:  75%|███████▍  | 7484/10000 [00:55<00:19, 131.10it/s]Running 10000 simulations.:  75%|███████▍  | 7498/10000 [00:55<00:19, 131.19it/s]Running 10000 simulations.:  75%|███████▌  | 7512/10000 [00:55<00:19, 130.86it/s]Running 10000 simulations.:  75%|███████▌  | 7526/10000 [00:56<00:18, 130.82it/s]Running 10000 simulations.:  75%|███████▌  | 7540/10000 [00:56<00:18, 130.59it/s]Running 10000 simulations.:  76%|███████▌  | 7554/10000 [00:56<00:18, 130.52it/s]Running 10000 simulations.:  76%|███████▌  | 7568/10000 [00:56<00:18, 130.65it/s]Running 10000 simulations.:  76%|███████▌  | 7582/10000 [00:56<00:18, 131.78it/s]Running 10000 simulations.:  76%|███████▌  | 7596/10000 [00:56<00:18, 129.87it/s]Running 10000 simulations.:  76%|███████▌  | 7610/10000 [00:56<00:18, 131.33it/s]Running 10000 simulations.:  76%|███████▌  | 7624/10000 [00:56<00:17, 132.60it/s]Running 10000 simulations.:  76%|███████▋  | 7638/10000 [00:56<00:17, 133.46it/s]Running 10000 simulations.:  77%|███████▋  | 7652/10000 [00:56<00:17, 134.27it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:57<00:17, 135.03it/s]Running 10000 simulations.:  77%|███████▋  | 7680/10000 [00:57<00:17, 135.35it/s]Running 10000 simulations.:  77%|███████▋  | 7694/10000 [00:57<00:17, 135.50it/s]Running 10000 simulations.:  77%|███████▋  | 7708/10000 [00:57<00:16, 135.43it/s]Running 10000 simulations.:  77%|███████▋  | 7722/10000 [00:57<00:16, 135.78it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:57<00:16, 135.84it/s]Running 10000 simulations.:  78%|███████▊  | 7750/10000 [00:57<00:16, 135.96it/s]Running 10000 simulations.:  78%|███████▊  | 7764/10000 [00:57<00:16, 136.22it/s]Running 10000 simulations.:  78%|███████▊  | 7778/10000 [00:57<00:16, 135.53it/s]Running 10000 simulations.:  78%|███████▊  | 7792/10000 [00:57<00:16, 135.52it/s]Running 10000 simulations.:  78%|███████▊  | 7806/10000 [00:58<00:16, 135.77it/s]Running 10000 simulations.:  78%|███████▊  | 7820/10000 [00:58<00:16, 135.86it/s]Running 10000 simulations.:  78%|███████▊  | 7834/10000 [00:58<00:15, 135.87it/s]Running 10000 simulations.:  78%|███████▊  | 7848/10000 [00:58<00:15, 135.88it/s]Running 10000 simulations.:  79%|███████▊  | 7862/10000 [00:58<00:15, 135.73it/s]Running 10000 simulations.:  79%|███████▉  | 7876/10000 [00:58<00:15, 134.75it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:58<00:15, 134.26it/s]Running 10000 simulations.:  79%|███████▉  | 7904/10000 [00:58<00:15, 134.44it/s]Running 10000 simulations.:  79%|███████▉  | 7918/10000 [00:58<00:15, 134.74it/s]Running 10000 simulations.:  79%|███████▉  | 7932/10000 [00:59<00:15, 134.68it/s]Running 10000 simulations.:  79%|███████▉  | 7946/10000 [00:59<00:15, 135.23it/s]Running 10000 simulations.:  80%|███████▉  | 7960/10000 [00:59<00:15, 135.37it/s]Running 10000 simulations.:  80%|███████▉  | 7974/10000 [00:59<00:14, 135.14it/s]Running 10000 simulations.:  80%|███████▉  | 7988/10000 [00:59<00:14, 135.44it/s]Running 10000 simulations.:  80%|████████  | 8002/10000 [00:59<00:14, 135.21it/s]Running 10000 simulations.:  80%|████████  | 8016/10000 [00:59<00:14, 134.66it/s]Running 10000 simulations.:  80%|████████  | 8030/10000 [00:59<00:14, 135.16it/s]Running 10000 simulations.:  80%|████████  | 8044/10000 [00:59<00:14, 135.15it/s]Running 10000 simulations.:  81%|████████  | 8058/10000 [00:59<00:14, 134.09it/s]Running 10000 simulations.:  81%|████████  | 8072/10000 [01:00<00:14, 132.85it/s]Running 10000 simulations.:  81%|████████  | 8086/10000 [01:00<00:14, 132.99it/s]Running 10000 simulations.:  81%|████████  | 8101/10000 [01:00<00:14, 135.21it/s]Running 10000 simulations.:  81%|████████  | 8115/10000 [01:00<00:13, 136.51it/s]Running 10000 simulations.:  81%|████████▏ | 8130/10000 [01:00<00:13, 138.25it/s]Running 10000 simulations.:  81%|████████▏ | 8145/10000 [01:00<00:13, 139.19it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [01:00<00:13, 139.58it/s]Running 10000 simulations.:  82%|████████▏ | 8175/10000 [01:00<00:13, 139.90it/s]Running 10000 simulations.:  82%|████████▏ | 8189/10000 [01:00<00:12, 139.63it/s]Running 10000 simulations.:  82%|████████▏ | 8203/10000 [01:01<00:12, 139.50it/s]Running 10000 simulations.:  82%|████████▏ | 8217/10000 [01:01<00:12, 139.33it/s]Running 10000 simulations.:  82%|████████▏ | 8231/10000 [01:01<00:12, 139.53it/s]Running 10000 simulations.:  82%|████████▏ | 8246/10000 [01:01<00:12, 139.94it/s]Running 10000 simulations.:  83%|████████▎ | 8261/10000 [01:01<00:12, 140.12it/s]Running 10000 simulations.:  83%|████████▎ | 8276/10000 [01:01<00:12, 140.12it/s]Running 10000 simulations.:  83%|████████▎ | 8291/10000 [01:01<00:12, 140.10it/s]Running 10000 simulations.:  83%|████████▎ | 8306/10000 [01:01<00:12, 140.26it/s]Running 10000 simulations.:  83%|████████▎ | 8321/10000 [01:01<00:11, 140.41it/s]Running 10000 simulations.:  83%|████████▎ | 8336/10000 [01:01<00:11, 140.90it/s]Running 10000 simulations.:  84%|████████▎ | 8351/10000 [01:02<00:11, 141.18it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [01:02<00:11, 141.15it/s]Running 10000 simulations.:  84%|████████▍ | 8381/10000 [01:02<00:11, 141.18it/s]Running 10000 simulations.:  84%|████████▍ | 8396/10000 [01:02<00:11, 141.46it/s]Running 10000 simulations.:  84%|████████▍ | 8411/10000 [01:02<00:11, 141.14it/s]Running 10000 simulations.:  84%|████████▍ | 8426/10000 [01:02<00:11, 140.65it/s]Running 10000 simulations.:  84%|████████▍ | 8441/10000 [01:02<00:11, 140.27it/s]Running 10000 simulations.:  85%|████████▍ | 8456/10000 [01:02<00:11, 139.40it/s]Running 10000 simulations.:  85%|████████▍ | 8470/10000 [01:02<00:10, 139.28it/s]Running 10000 simulations.:  85%|████████▍ | 8484/10000 [01:03<00:10, 139.42it/s]Running 10000 simulations.:  85%|████████▍ | 8498/10000 [01:03<00:10, 139.45it/s]Running 10000 simulations.:  85%|████████▌ | 8513/10000 [01:03<00:10, 139.79it/s]Running 10000 simulations.:  85%|████████▌ | 8528/10000 [01:03<00:10, 140.19it/s]Running 10000 simulations.:  85%|████████▌ | 8543/10000 [01:03<00:10, 139.68it/s]Running 10000 simulations.:  86%|████████▌ | 8558/10000 [01:03<00:10, 139.78it/s]Running 10000 simulations.:  86%|████████▌ | 8573/10000 [01:03<00:10, 140.30it/s]Running 10000 simulations.:  86%|████████▌ | 8589/10000 [01:03<00:09, 145.49it/s]Running 10000 simulations.:  86%|████████▌ | 8605/10000 [01:03<00:09, 148.10it/s]Running 10000 simulations.:  86%|████████▌ | 8620/10000 [01:03<00:09, 145.63it/s]Running 10000 simulations.:  86%|████████▋ | 8635/10000 [01:04<00:09, 144.08it/s]Running 10000 simulations.:  86%|████████▋ | 8650/10000 [01:04<00:09, 142.78it/s]Running 10000 simulations.:  87%|████████▋ | 8665/10000 [01:04<00:09, 142.20it/s]Running 10000 simulations.:  87%|████████▋ | 8680/10000 [01:04<00:09, 142.08it/s]Running 10000 simulations.:  87%|████████▋ | 8695/10000 [01:04<00:09, 141.77it/s]Running 10000 simulations.:  87%|████████▋ | 8710/10000 [01:04<00:09, 141.38it/s]Running 10000 simulations.:  87%|████████▋ | 8725/10000 [01:04<00:09, 140.61it/s]Running 10000 simulations.:  87%|████████▋ | 8740/10000 [01:04<00:08, 140.33it/s]Running 10000 simulations.:  88%|████████▊ | 8755/10000 [01:04<00:08, 140.47it/s]Running 10000 simulations.:  88%|████████▊ | 8770/10000 [01:05<00:08, 140.93it/s]Running 10000 simulations.:  88%|████████▊ | 8785/10000 [01:05<00:08, 140.87it/s]Running 10000 simulations.:  88%|████████▊ | 8800/10000 [01:05<00:08, 141.22it/s]Running 10000 simulations.:  88%|████████▊ | 8815/10000 [01:05<00:08, 141.56it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [01:05<00:08, 141.85it/s]Running 10000 simulations.:  88%|████████▊ | 8845/10000 [01:05<00:08, 141.37it/s]Running 10000 simulations.:  89%|████████▊ | 8860/10000 [01:05<00:08, 141.25it/s]Running 10000 simulations.:  89%|████████▉ | 8875/10000 [01:05<00:07, 140.81it/s]Running 10000 simulations.:  89%|████████▉ | 8890/10000 [01:05<00:07, 140.35it/s]Running 10000 simulations.:  89%|████████▉ | 8905/10000 [01:05<00:07, 140.26it/s]Running 10000 simulations.:  89%|████████▉ | 8920/10000 [01:06<00:07, 140.07it/s]Running 10000 simulations.:  89%|████████▉ | 8935/10000 [01:06<00:07, 140.57it/s]Running 10000 simulations.:  90%|████████▉ | 8950/10000 [01:06<00:07, 140.54it/s]Running 10000 simulations.:  90%|████████▉ | 8965/10000 [01:06<00:07, 137.97it/s]Running 10000 simulations.:  90%|████████▉ | 8979/10000 [01:06<00:07, 134.85it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [01:06<00:07, 132.64it/s]Running 10000 simulations.:  90%|█████████ | 9007/10000 [01:06<00:07, 131.31it/s]Running 10000 simulations.:  90%|█████████ | 9021/10000 [01:06<00:07, 131.74it/s]Running 10000 simulations.:  90%|█████████ | 9035/10000 [01:06<00:07, 133.43it/s]Running 10000 simulations.:  90%|█████████ | 9049/10000 [01:07<00:07, 134.82it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [01:07<00:06, 135.77it/s]Running 10000 simulations.:  91%|█████████ | 9077/10000 [01:07<00:06, 136.16it/s]Running 10000 simulations.:  91%|█████████ | 9091/10000 [01:07<00:06, 136.57it/s]Running 10000 simulations.:  91%|█████████ | 9105/10000 [01:07<00:06, 136.30it/s]Running 10000 simulations.:  91%|█████████ | 9119/10000 [01:07<00:06, 135.82it/s]Running 10000 simulations.:  91%|█████████▏| 9133/10000 [01:07<00:06, 135.81it/s]Running 10000 simulations.:  91%|█████████▏| 9147/10000 [01:07<00:06, 135.65it/s]Running 10000 simulations.:  92%|█████████▏| 9161/10000 [01:07<00:06, 135.46it/s]Running 10000 simulations.:  92%|█████████▏| 9175/10000 [01:07<00:06, 135.22it/s]Running 10000 simulations.:  92%|█████████▏| 9189/10000 [01:08<00:05, 135.21it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [01:08<00:05, 135.62it/s]Running 10000 simulations.:  92%|█████████▏| 9217/10000 [01:08<00:05, 135.38it/s]Running 10000 simulations.:  92%|█████████▏| 9231/10000 [01:08<00:05, 135.46it/s]Running 10000 simulations.:  92%|█████████▏| 9245/10000 [01:08<00:05, 135.44it/s]Running 10000 simulations.:  93%|█████████▎| 9259/10000 [01:08<00:05, 135.64it/s]Running 10000 simulations.:  93%|█████████▎| 9273/10000 [01:08<00:05, 135.66it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [01:08<00:05, 135.99it/s]Running 10000 simulations.:  93%|█████████▎| 9301/10000 [01:08<00:05, 135.60it/s]Running 10000 simulations.:  93%|█████████▎| 9315/10000 [01:09<00:05, 135.28it/s]Running 10000 simulations.:  93%|█████████▎| 9329/10000 [01:09<00:04, 135.23it/s]Running 10000 simulations.:  93%|█████████▎| 9343/10000 [01:09<00:04, 135.36it/s]Running 10000 simulations.:  94%|█████████▎| 9357/10000 [01:09<00:04, 135.39it/s]Running 10000 simulations.:  94%|█████████▎| 9371/10000 [01:09<00:04, 135.77it/s]Running 10000 simulations.:  94%|█████████▍| 9385/10000 [01:09<00:04, 136.23it/s]Running 10000 simulations.:  94%|█████████▍| 9399/10000 [01:09<00:04, 136.12it/s]Running 10000 simulations.:  94%|█████████▍| 9413/10000 [01:09<00:04, 135.84it/s]Running 10000 simulations.:  94%|█████████▍| 9427/10000 [01:09<00:04, 135.61it/s]Running 10000 simulations.:  94%|█████████▍| 9441/10000 [01:09<00:04, 134.51it/s]Running 10000 simulations.:  95%|█████████▍| 9455/10000 [01:10<00:04, 133.89it/s]Running 10000 simulations.:  95%|█████████▍| 9469/10000 [01:10<00:03, 133.63it/s]Running 10000 simulations.:  95%|█████████▍| 9483/10000 [01:10<00:03, 134.24it/s]Running 10000 simulations.:  95%|█████████▍| 9497/10000 [01:10<00:03, 134.95it/s]Running 10000 simulations.:  95%|█████████▌| 9511/10000 [01:10<00:03, 134.99it/s]Running 10000 simulations.:  95%|█████████▌| 9525/10000 [01:10<00:03, 134.77it/s]Running 10000 simulations.:  95%|█████████▌| 9539/10000 [01:10<00:03, 135.18it/s]Running 10000 simulations.:  96%|█████████▌| 9553/10000 [01:10<00:03, 135.26it/s]Running 10000 simulations.:  96%|█████████▌| 9567/10000 [01:10<00:03, 135.70it/s]Running 10000 simulations.:  96%|█████████▌| 9581/10000 [01:10<00:03, 135.69it/s]Running 10000 simulations.:  96%|█████████▌| 9595/10000 [01:11<00:03, 133.65it/s]Running 10000 simulations.:  96%|█████████▌| 9609/10000 [01:11<00:02, 132.11it/s]Running 10000 simulations.:  96%|█████████▌| 9623/10000 [01:11<00:02, 131.10it/s]Running 10000 simulations.:  96%|█████████▋| 9637/10000 [01:11<00:02, 130.77it/s]Running 10000 simulations.:  97%|█████████▋| 9651/10000 [01:11<00:02, 130.13it/s]Running 10000 simulations.:  97%|█████████▋| 9665/10000 [01:11<00:02, 129.77it/s]Running 10000 simulations.:  97%|█████████▋| 9678/10000 [01:11<00:02, 129.58it/s]Running 10000 simulations.:  97%|█████████▋| 9691/10000 [01:11<00:02, 128.88it/s]Running 10000 simulations.:  97%|█████████▋| 9704/10000 [01:11<00:02, 128.65it/s]Running 10000 simulations.:  97%|█████████▋| 9717/10000 [01:12<00:02, 128.74it/s]Running 10000 simulations.:  97%|█████████▋| 9730/10000 [01:12<00:02, 128.46it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [01:12<00:02, 128.08it/s]Running 10000 simulations.:  98%|█████████▊| 9756/10000 [01:12<00:01, 127.63it/s]Running 10000 simulations.:  98%|█████████▊| 9769/10000 [01:12<00:01, 127.79it/s]Running 10000 simulations.:  98%|█████████▊| 9782/10000 [01:12<00:01, 127.88it/s]Running 10000 simulations.:  98%|█████████▊| 9795/10000 [01:12<00:01, 128.38it/s]Running 10000 simulations.:  98%|█████████▊| 9809/10000 [01:12<00:01, 131.59it/s]Running 10000 simulations.:  98%|█████████▊| 9824/10000 [01:12<00:01, 134.05it/s]Running 10000 simulations.:  98%|█████████▊| 9839/10000 [01:12<00:01, 136.14it/s]Running 10000 simulations.:  99%|█████████▊| 9854/10000 [01:13<00:01, 138.15it/s]Running 10000 simulations.:  99%|█████████▊| 9869/10000 [01:13<00:00, 139.30it/s]Running 10000 simulations.:  99%|█████████▉| 9884/10000 [01:13<00:00, 140.39it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [01:13<00:00, 141.33it/s]Running 10000 simulations.:  99%|█████████▉| 9914/10000 [01:13<00:00, 141.58it/s]Running 10000 simulations.:  99%|█████████▉| 9929/10000 [01:13<00:00, 141.42it/s]Running 10000 simulations.:  99%|█████████▉| 9944/10000 [01:13<00:00, 141.82it/s]Running 10000 simulations.: 100%|█████████▉| 9959/10000 [01:13<00:00, 141.75it/s]Running 10000 simulations.: 100%|█████████▉| 9974/10000 [01:13<00:00, 141.76it/s]Running 10000 simulations.: 100%|█████████▉| 9989/10000 [01:14<00:00, 141.85it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:14<00:00, 134.96it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 14/10000 [00:00<01:14, 133.22it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<01:14, 133.12it/s]Running 10000 simulations.:   0%|          | 42/10000 [00:00<01:14, 133.31it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<01:14, 133.90it/s]Running 10000 simulations.:   1%|          | 70/10000 [00:00<01:14, 133.46it/s]Running 10000 simulations.:   1%|          | 83/10000 [00:00<01:14, 132.40it/s]Running 10000 simulations.:   1%|          | 97/10000 [00:00<01:14, 132.28it/s]Running 10000 simulations.:   1%|          | 111/10000 [00:00<01:14, 132.30it/s]Running 10000 simulations.:   1%|▏         | 125/10000 [00:00<01:14, 131.75it/s]Running 10000 simulations.:   1%|▏         | 139/10000 [00:01<01:15, 131.24it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:01<01:14, 131.68it/s]Running 10000 simulations.:   2%|▏         | 167/10000 [00:01<01:14, 131.70it/s]Running 10000 simulations.:   2%|▏         | 181/10000 [00:01<01:14, 131.39it/s]Running 10000 simulations.:   2%|▏         | 195/10000 [00:01<01:14, 131.08it/s]Running 10000 simulations.:   2%|▏         | 209/10000 [00:01<01:14, 131.34it/s]Running 10000 simulations.:   2%|▏         | 223/10000 [00:01<01:14, 131.29it/s]Running 10000 simulations.:   2%|▏         | 237/10000 [00:01<01:14, 130.65it/s]Running 10000 simulations.:   3%|▎         | 251/10000 [00:01<01:14, 130.40it/s]Running 10000 simulations.:   3%|▎         | 265/10000 [00:02<01:14, 130.95it/s]Running 10000 simulations.:   3%|▎         | 279/10000 [00:02<01:14, 131.08it/s]Running 10000 simulations.:   3%|▎         | 293/10000 [00:02<01:14, 131.03it/s]Running 10000 simulations.:   3%|▎         | 307/10000 [00:02<01:14, 130.95it/s]Running 10000 simulations.:   3%|▎         | 321/10000 [00:02<01:14, 130.78it/s]Running 10000 simulations.:   3%|▎         | 335/10000 [00:02<01:13, 131.43it/s]Running 10000 simulations.:   3%|▎         | 349/10000 [00:02<01:13, 131.19it/s]Running 10000 simulations.:   4%|▎         | 363/10000 [00:02<01:13, 130.57it/s]Running 10000 simulations.:   4%|▍         | 377/10000 [00:02<01:13, 130.06it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:03<01:19, 121.18it/s]Running 10000 simulations.:   4%|▍         | 404/10000 [00:03<01:17, 123.64it/s]Running 10000 simulations.:   4%|▍         | 418/10000 [00:03<01:16, 125.79it/s]Running 10000 simulations.:   4%|▍         | 432/10000 [00:03<01:15, 127.25it/s]Running 10000 simulations.:   4%|▍         | 446/10000 [00:03<01:14, 128.14it/s]Running 10000 simulations.:   5%|▍         | 460/10000 [00:03<01:13, 129.26it/s]Running 10000 simulations.:   5%|▍         | 474/10000 [00:03<01:13, 130.09it/s]Running 10000 simulations.:   5%|▍         | 488/10000 [00:03<01:13, 130.18it/s]Running 10000 simulations.:   5%|▌         | 502/10000 [00:03<01:13, 130.06it/s]Running 10000 simulations.:   5%|▌         | 516/10000 [00:03<01:12, 130.27it/s]Running 10000 simulations.:   5%|▌         | 530/10000 [00:04<01:12, 130.88it/s]Running 10000 simulations.:   5%|▌         | 544/10000 [00:04<01:12, 131.00it/s]Running 10000 simulations.:   6%|▌         | 558/10000 [00:04<01:11, 131.27it/s]Running 10000 simulations.:   6%|▌         | 572/10000 [00:04<01:12, 130.90it/s]Running 10000 simulations.:   6%|▌         | 587/10000 [00:04<01:10, 133.77it/s]Running 10000 simulations.:   6%|▌         | 603/10000 [00:04<01:07, 139.79it/s]Running 10000 simulations.:   6%|▌         | 619/10000 [00:04<01:05, 143.82it/s]Running 10000 simulations.:   6%|▋         | 634/10000 [00:04<01:05, 142.74it/s]Running 10000 simulations.:   6%|▋         | 649/10000 [00:04<01:05, 142.10it/s]Running 10000 simulations.:   7%|▋         | 664/10000 [00:05<01:06, 140.98it/s]Running 10000 simulations.:   7%|▋         | 679/10000 [00:05<01:06, 140.52it/s]Running 10000 simulations.:   7%|▋         | 694/10000 [00:05<01:06, 140.12it/s]Running 10000 simulations.:   7%|▋         | 709/10000 [00:05<01:06, 139.61it/s]Running 10000 simulations.:   7%|▋         | 724/10000 [00:05<01:06, 139.96it/s]Running 10000 simulations.:   7%|▋         | 739/10000 [00:05<01:06, 140.22it/s]Running 10000 simulations.:   8%|▊         | 754/10000 [00:05<01:06, 139.72it/s]Running 10000 simulations.:   8%|▊         | 768/10000 [00:05<01:06, 139.22it/s]Running 10000 simulations.:   8%|▊         | 782/10000 [00:05<01:06, 139.35it/s]Running 10000 simulations.:   8%|▊         | 797/10000 [00:05<01:05, 140.13it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:06<01:05, 140.20it/s]Running 10000 simulations.:   8%|▊         | 827/10000 [00:06<01:05, 140.47it/s]Running 10000 simulations.:   8%|▊         | 842/10000 [00:06<01:05, 139.60it/s]Running 10000 simulations.:   9%|▊         | 856/10000 [00:06<01:05, 138.85it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:06<01:05, 139.17it/s]Running 10000 simulations.:   9%|▉         | 884/10000 [00:06<01:05, 139.19it/s]Running 10000 simulations.:   9%|▉         | 899/10000 [00:06<01:05, 139.71it/s]Running 10000 simulations.:   9%|▉         | 914/10000 [00:06<01:04, 140.07it/s]Running 10000 simulations.:   9%|▉         | 929/10000 [00:06<01:04, 139.72it/s]Running 10000 simulations.:   9%|▉         | 943/10000 [00:07<01:04, 139.65it/s]Running 10000 simulations.:  10%|▉         | 957/10000 [00:07<01:05, 138.73it/s]Running 10000 simulations.:  10%|▉         | 971/10000 [00:07<01:04, 139.08it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:07<01:04, 139.50it/s]Running 10000 simulations.:  10%|█         | 1000/10000 [00:07<01:04, 139.51it/s]Running 10000 simulations.:  10%|█         | 1014/10000 [00:07<01:04, 138.76it/s]Running 10000 simulations.:  10%|█         | 1028/10000 [00:07<01:04, 138.76it/s]Running 10000 simulations.:  10%|█         | 1042/10000 [00:07<01:04, 139.03it/s]Running 10000 simulations.:  11%|█         | 1057/10000 [00:07<01:03, 140.00it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:07<01:03, 140.14it/s]Running 10000 simulations.:  11%|█         | 1087/10000 [00:08<01:03, 139.75it/s]Running 10000 simulations.:  11%|█         | 1101/10000 [00:08<01:04, 138.52it/s]Running 10000 simulations.:  11%|█         | 1115/10000 [00:08<01:05, 136.23it/s]Running 10000 simulations.:  11%|█▏        | 1129/10000 [00:08<01:05, 135.70it/s]Running 10000 simulations.:  11%|█▏        | 1143/10000 [00:08<01:05, 135.94it/s]Running 10000 simulations.:  12%|█▏        | 1157/10000 [00:08<01:05, 135.57it/s]Running 10000 simulations.:  12%|█▏        | 1171/10000 [00:08<01:04, 136.60it/s]Running 10000 simulations.:  12%|█▏        | 1185/10000 [00:08<01:04, 137.54it/s]Running 10000 simulations.:  12%|█▏        | 1199/10000 [00:08<01:04, 137.48it/s]Running 10000 simulations.:  12%|█▏        | 1213/10000 [00:08<01:03, 137.77it/s]Running 10000 simulations.:  12%|█▏        | 1227/10000 [00:09<01:04, 136.79it/s]Running 10000 simulations.:  12%|█▏        | 1241/10000 [00:09<01:04, 136.66it/s]Running 10000 simulations.:  13%|█▎        | 1255/10000 [00:09<01:03, 137.13it/s]Running 10000 simulations.:  13%|█▎        | 1269/10000 [00:09<01:03, 137.93it/s]Running 10000 simulations.:  13%|█▎        | 1283/10000 [00:09<01:02, 138.49it/s]Running 10000 simulations.:  13%|█▎        | 1297/10000 [00:09<01:02, 138.25it/s]Running 10000 simulations.:  13%|█▎        | 1312/10000 [00:09<01:02, 138.84it/s]Running 10000 simulations.:  13%|█▎        | 1326/10000 [00:09<01:03, 137.13it/s]Running 10000 simulations.:  13%|█▎        | 1340/10000 [00:09<01:03, 137.36it/s]Running 10000 simulations.:  14%|█▎        | 1354/10000 [00:10<01:02, 137.98it/s]Running 10000 simulations.:  14%|█▎        | 1368/10000 [00:10<01:02, 138.33it/s]Running 10000 simulations.:  14%|█▍        | 1383/10000 [00:10<01:02, 138.81it/s]Running 10000 simulations.:  14%|█▍        | 1397/10000 [00:10<01:01, 138.85it/s]Running 10000 simulations.:  14%|█▍        | 1411/10000 [00:10<01:02, 138.14it/s]Running 10000 simulations.:  14%|█▍        | 1426/10000 [00:10<01:01, 139.28it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:10<01:01, 139.36it/s]Running 10000 simulations.:  15%|█▍        | 1454/10000 [00:10<01:01, 139.14it/s]Running 10000 simulations.:  15%|█▍        | 1468/10000 [00:10<01:01, 139.11it/s]Running 10000 simulations.:  15%|█▍        | 1482/10000 [00:10<01:01, 138.99it/s]Running 10000 simulations.:  15%|█▍        | 1496/10000 [00:11<01:01, 137.35it/s]Running 10000 simulations.:  15%|█▌        | 1510/10000 [00:11<01:01, 137.80it/s]Running 10000 simulations.:  15%|█▌        | 1524/10000 [00:11<01:01, 138.14it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:11<01:00, 138.76it/s]Running 10000 simulations.:  16%|█▌        | 1554/10000 [00:11<01:00, 139.30it/s]Running 10000 simulations.:  16%|█▌        | 1568/10000 [00:11<01:00, 139.24it/s]Running 10000 simulations.:  16%|█▌        | 1582/10000 [00:11<01:01, 137.41it/s]Running 10000 simulations.:  16%|█▌        | 1596/10000 [00:11<01:01, 137.35it/s]Running 10000 simulations.:  16%|█▌        | 1610/10000 [00:11<01:00, 138.02it/s]Running 10000 simulations.:  16%|█▌        | 1624/10000 [00:11<01:00, 138.12it/s]Running 10000 simulations.:  16%|█▋        | 1638/10000 [00:12<01:00, 138.45it/s]Running 10000 simulations.:  17%|█▋        | 1652/10000 [00:12<01:00, 138.24it/s]Running 10000 simulations.:  17%|█▋        | 1666/10000 [00:12<01:00, 138.50it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:12<01:00, 138.04it/s]Running 10000 simulations.:  17%|█▋        | 1694/10000 [00:12<01:00, 137.77it/s]Running 10000 simulations.:  17%|█▋        | 1708/10000 [00:12<01:00, 137.77it/s]Running 10000 simulations.:  17%|█▋        | 1723/10000 [00:12<00:59, 138.50it/s]Running 10000 simulations.:  17%|█▋        | 1737/10000 [00:12<00:59, 138.86it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:12<00:59, 139.01it/s]Running 10000 simulations.:  18%|█▊        | 1765/10000 [00:12<00:59, 138.26it/s]Running 10000 simulations.:  18%|█▊        | 1779/10000 [00:13<00:59, 138.42it/s]Running 10000 simulations.:  18%|█▊        | 1793/10000 [00:13<00:59, 138.17it/s]Running 10000 simulations.:  18%|█▊        | 1807/10000 [00:13<00:59, 137.74it/s]Running 10000 simulations.:  18%|█▊        | 1821/10000 [00:13<00:59, 138.02it/s]Running 10000 simulations.:  18%|█▊        | 1835/10000 [00:13<00:59, 138.04it/s]Running 10000 simulations.:  18%|█▊        | 1849/10000 [00:13<00:59, 137.94it/s]Running 10000 simulations.:  19%|█▊        | 1863/10000 [00:13<00:58, 138.51it/s]Running 10000 simulations.:  19%|█▉        | 1877/10000 [00:13<00:58, 138.78it/s]Running 10000 simulations.:  19%|█▉        | 1891/10000 [00:13<00:59, 137.07it/s]Running 10000 simulations.:  19%|█▉        | 1905/10000 [00:13<01:00, 133.85it/s]Running 10000 simulations.:  19%|█▉        | 1919/10000 [00:14<01:01, 132.23it/s]Running 10000 simulations.:  19%|█▉        | 1933/10000 [00:14<01:01, 130.59it/s]Running 10000 simulations.:  19%|█▉        | 1947/10000 [00:14<01:01, 130.10it/s]Running 10000 simulations.:  20%|█▉        | 1961/10000 [00:14<01:01, 129.72it/s]Running 10000 simulations.:  20%|█▉        | 1974/10000 [00:14<01:02, 128.99it/s]Running 10000 simulations.:  20%|█▉        | 1987/10000 [00:14<01:02, 128.46it/s]Running 10000 simulations.:  20%|██        | 2000/10000 [00:14<01:02, 128.80it/s]Running 10000 simulations.:  20%|██        | 2013/10000 [00:14<01:02, 128.21it/s]Running 10000 simulations.:  20%|██        | 2026/10000 [00:14<01:02, 128.32it/s]Running 10000 simulations.:  20%|██        | 2039/10000 [00:15<01:01, 128.67it/s]Running 10000 simulations.:  21%|██        | 2052/10000 [00:15<01:01, 128.71it/s]Running 10000 simulations.:  21%|██        | 2065/10000 [00:15<01:01, 128.91it/s]Running 10000 simulations.:  21%|██        | 2078/10000 [00:15<01:01, 128.39it/s]Running 10000 simulations.:  21%|██        | 2091/10000 [00:15<01:01, 128.29it/s]Running 10000 simulations.:  21%|██        | 2104/10000 [00:15<01:01, 127.90it/s]Running 10000 simulations.:  21%|██        | 2117/10000 [00:15<01:01, 127.80it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:15<01:01, 127.80it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:15<01:01, 127.92it/s]Running 10000 simulations.:  22%|██▏       | 2156/10000 [00:15<01:01, 127.90it/s]Running 10000 simulations.:  22%|██▏       | 2169/10000 [00:16<01:01, 127.73it/s]Running 10000 simulations.:  22%|██▏       | 2182/10000 [00:16<01:01, 127.69it/s]Running 10000 simulations.:  22%|██▏       | 2195/10000 [00:16<01:01, 127.81it/s]Running 10000 simulations.:  22%|██▏       | 2208/10000 [00:16<01:01, 127.37it/s]Running 10000 simulations.:  22%|██▏       | 2221/10000 [00:16<01:00, 127.54it/s]Running 10000 simulations.:  22%|██▏       | 2234/10000 [00:16<01:00, 127.73it/s]Running 10000 simulations.:  22%|██▏       | 2247/10000 [00:16<01:00, 128.21it/s]Running 10000 simulations.:  23%|██▎       | 2260/10000 [00:16<01:00, 128.28it/s]Running 10000 simulations.:  23%|██▎       | 2273/10000 [00:16<01:00, 127.99it/s]Running 10000 simulations.:  23%|██▎       | 2286/10000 [00:16<01:00, 127.72it/s]Running 10000 simulations.:  23%|██▎       | 2299/10000 [00:17<01:00, 127.73it/s]Running 10000 simulations.:  23%|██▎       | 2312/10000 [00:17<01:00, 127.67it/s]Running 10000 simulations.:  23%|██▎       | 2325/10000 [00:17<01:00, 127.56it/s]Running 10000 simulations.:  23%|██▎       | 2339/10000 [00:17<00:59, 128.59it/s]Running 10000 simulations.:  24%|██▎       | 2353/10000 [00:17<00:58, 131.18it/s]Running 10000 simulations.:  24%|██▎       | 2367/10000 [00:17<00:57, 132.47it/s]Running 10000 simulations.:  24%|██▍       | 2381/10000 [00:17<00:57, 132.70it/s]Running 10000 simulations.:  24%|██▍       | 2395/10000 [00:17<00:57, 133.25it/s]Running 10000 simulations.:  24%|██▍       | 2409/10000 [00:17<00:56, 133.28it/s]Running 10000 simulations.:  24%|██▍       | 2423/10000 [00:18<00:56, 133.42it/s]Running 10000 simulations.:  24%|██▍       | 2437/10000 [00:18<00:56, 133.79it/s]Running 10000 simulations.:  25%|██▍       | 2451/10000 [00:18<00:56, 134.53it/s]Running 10000 simulations.:  25%|██▍       | 2465/10000 [00:18<00:55, 134.80it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:18<00:55, 134.93it/s]Running 10000 simulations.:  25%|██▍       | 2493/10000 [00:18<00:55, 135.87it/s]Running 10000 simulations.:  25%|██▌       | 2507/10000 [00:18<00:55, 134.00it/s]Running 10000 simulations.:  25%|██▌       | 2521/10000 [00:18<00:56, 132.18it/s]Running 10000 simulations.:  25%|██▌       | 2535/10000 [00:18<00:56, 131.74it/s]Running 10000 simulations.:  25%|██▌       | 2549/10000 [00:18<00:57, 130.56it/s]Running 10000 simulations.:  26%|██▌       | 2563/10000 [00:19<00:57, 129.97it/s]Running 10000 simulations.:  26%|██▌       | 2577/10000 [00:19<00:57, 129.67it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:19<00:57, 129.38it/s]Running 10000 simulations.:  26%|██▌       | 2603/10000 [00:19<00:57, 129.15it/s]Running 10000 simulations.:  26%|██▌       | 2616/10000 [00:19<00:57, 128.33it/s]Running 10000 simulations.:  26%|██▋       | 2630/10000 [00:19<00:56, 131.46it/s]Running 10000 simulations.:  26%|██▋       | 2645/10000 [00:19<00:54, 134.60it/s]Running 10000 simulations.:  27%|██▋       | 2660/10000 [00:19<00:53, 137.18it/s]Running 10000 simulations.:  27%|██▋       | 2675/10000 [00:19<00:52, 139.35it/s]Running 10000 simulations.:  27%|██▋       | 2690/10000 [00:19<00:52, 140.32it/s]Running 10000 simulations.:  27%|██▋       | 2705/10000 [00:20<00:51, 141.00it/s]Running 10000 simulations.:  27%|██▋       | 2720/10000 [00:20<00:51, 141.34it/s]Running 10000 simulations.:  27%|██▋       | 2735/10000 [00:20<00:51, 141.32it/s]Running 10000 simulations.:  28%|██▊       | 2750/10000 [00:20<00:51, 141.66it/s]Running 10000 simulations.:  28%|██▊       | 2765/10000 [00:20<00:50, 142.07it/s]Running 10000 simulations.:  28%|██▊       | 2780/10000 [00:20<00:50, 141.88it/s]Running 10000 simulations.:  28%|██▊       | 2795/10000 [00:20<00:51, 140.90it/s]Running 10000 simulations.:  28%|██▊       | 2810/10000 [00:20<00:51, 138.97it/s]Running 10000 simulations.:  28%|██▊       | 2824/10000 [00:20<00:52, 136.08it/s]Running 10000 simulations.:  28%|██▊       | 2838/10000 [00:21<00:53, 134.11it/s]Running 10000 simulations.:  29%|██▊       | 2852/10000 [00:21<00:53, 134.40it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:21<00:52, 135.48it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:21<00:52, 136.62it/s]Running 10000 simulations.:  29%|██▉       | 2895/10000 [00:21<00:51, 137.92it/s]Running 10000 simulations.:  29%|██▉       | 2909/10000 [00:21<00:51, 137.87it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:21<00:51, 138.26it/s]Running 10000 simulations.:  29%|██▉       | 2937/10000 [00:21<00:51, 138.43it/s]Running 10000 simulations.:  30%|██▉       | 2951/10000 [00:21<00:50, 138.82it/s]Running 10000 simulations.:  30%|██▉       | 2966/10000 [00:21<00:50, 139.26it/s]Running 10000 simulations.:  30%|██▉       | 2981/10000 [00:22<00:50, 140.01it/s]Running 10000 simulations.:  30%|██▉       | 2996/10000 [00:22<00:49, 140.08it/s]Running 10000 simulations.:  30%|███       | 3011/10000 [00:22<00:49, 140.51it/s]Running 10000 simulations.:  30%|███       | 3026/10000 [00:22<00:49, 140.62it/s]Running 10000 simulations.:  30%|███       | 3041/10000 [00:22<00:49, 140.32it/s]Running 10000 simulations.:  31%|███       | 3056/10000 [00:22<00:49, 140.31it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:22<00:49, 140.32it/s]Running 10000 simulations.:  31%|███       | 3086/10000 [00:22<00:49, 139.90it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:22<00:49, 140.10it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:23<00:49, 139.58it/s]Running 10000 simulations.:  31%|███▏      | 3130/10000 [00:23<00:49, 139.51it/s]Running 10000 simulations.:  31%|███▏      | 3144/10000 [00:23<00:49, 138.48it/s]Running 10000 simulations.:  32%|███▏      | 3158/10000 [00:23<00:49, 138.86it/s]Running 10000 simulations.:  32%|███▏      | 3172/10000 [00:23<00:49, 139.11it/s]Running 10000 simulations.:  32%|███▏      | 3186/10000 [00:23<00:48, 139.10it/s]Running 10000 simulations.:  32%|███▏      | 3200/10000 [00:23<00:49, 138.33it/s]Running 10000 simulations.:  32%|███▏      | 3214/10000 [00:23<00:48, 138.54it/s]Running 10000 simulations.:  32%|███▏      | 3228/10000 [00:23<00:49, 137.33it/s]Running 10000 simulations.:  32%|███▏      | 3242/10000 [00:23<00:49, 136.24it/s]Running 10000 simulations.:  33%|███▎      | 3256/10000 [00:24<00:49, 135.62it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:24<00:49, 135.16it/s]Running 10000 simulations.:  33%|███▎      | 3284/10000 [00:24<00:50, 134.04it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:24<00:49, 134.06it/s]Running 10000 simulations.:  33%|███▎      | 3312/10000 [00:24<00:49, 134.74it/s]Running 10000 simulations.:  33%|███▎      | 3326/10000 [00:24<00:49, 134.68it/s]Running 10000 simulations.:  33%|███▎      | 3340/10000 [00:24<00:49, 134.03it/s]Running 10000 simulations.:  34%|███▎      | 3354/10000 [00:24<00:49, 133.89it/s]Running 10000 simulations.:  34%|███▎      | 3368/10000 [00:24<00:49, 133.39it/s]Running 10000 simulations.:  34%|███▍      | 3382/10000 [00:25<00:49, 134.15it/s]Running 10000 simulations.:  34%|███▍      | 3396/10000 [00:25<00:49, 134.54it/s]Running 10000 simulations.:  34%|███▍      | 3410/10000 [00:25<00:48, 135.14it/s]Running 10000 simulations.:  34%|███▍      | 3424/10000 [00:25<00:48, 134.71it/s]Running 10000 simulations.:  34%|███▍      | 3438/10000 [00:25<00:48, 134.52it/s]Running 10000 simulations.:  35%|███▍      | 3452/10000 [00:25<00:48, 135.41it/s]Running 10000 simulations.:  35%|███▍      | 3466/10000 [00:25<00:48, 135.85it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:25<00:47, 135.92it/s]Running 10000 simulations.:  35%|███▍      | 3494/10000 [00:25<00:47, 135.76it/s]Running 10000 simulations.:  35%|███▌      | 3509/10000 [00:25<00:47, 137.06it/s]Running 10000 simulations.:  35%|███▌      | 3524/10000 [00:26<00:46, 138.25it/s]Running 10000 simulations.:  35%|███▌      | 3539/10000 [00:26<00:46, 139.80it/s]Running 10000 simulations.:  36%|███▌      | 3554/10000 [00:26<00:45, 140.76it/s]Running 10000 simulations.:  36%|███▌      | 3569/10000 [00:26<00:45, 141.96it/s]Running 10000 simulations.:  36%|███▌      | 3584/10000 [00:26<00:45, 141.54it/s]Running 10000 simulations.:  36%|███▌      | 3599/10000 [00:26<00:45, 140.91it/s]Running 10000 simulations.:  36%|███▌      | 3614/10000 [00:26<00:45, 141.71it/s]Running 10000 simulations.:  36%|███▋      | 3629/10000 [00:26<00:44, 142.10it/s]Running 10000 simulations.:  36%|███▋      | 3644/10000 [00:26<00:44, 142.63it/s]Running 10000 simulations.:  37%|███▋      | 3659/10000 [00:27<00:44, 142.74it/s]Running 10000 simulations.:  37%|███▋      | 3674/10000 [00:27<00:44, 142.57it/s]Running 10000 simulations.:  37%|███▋      | 3689/10000 [00:27<00:44, 142.73it/s]Running 10000 simulations.:  37%|███▋      | 3704/10000 [00:27<00:43, 143.16it/s]Running 10000 simulations.:  37%|███▋      | 3719/10000 [00:27<00:43, 143.45it/s]Running 10000 simulations.:  37%|███▋      | 3734/10000 [00:27<00:43, 143.66it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:27<00:43, 143.77it/s]Running 10000 simulations.:  38%|███▊      | 3764/10000 [00:27<00:43, 143.38it/s]Running 10000 simulations.:  38%|███▊      | 3779/10000 [00:27<00:43, 143.33it/s]Running 10000 simulations.:  38%|███▊      | 3794/10000 [00:27<00:43, 142.59it/s]Running 10000 simulations.:  38%|███▊      | 3809/10000 [00:28<00:43, 142.60it/s]Running 10000 simulations.:  38%|███▊      | 3824/10000 [00:28<00:43, 142.51it/s]Running 10000 simulations.:  38%|███▊      | 3839/10000 [00:28<00:43, 142.93it/s]Running 10000 simulations.:  39%|███▊      | 3854/10000 [00:28<00:43, 142.67it/s]Running 10000 simulations.:  39%|███▊      | 3869/10000 [00:28<00:43, 141.91it/s]Running 10000 simulations.:  39%|███▉      | 3884/10000 [00:28<00:43, 141.88it/s]Running 10000 simulations.:  39%|███▉      | 3899/10000 [00:28<00:42, 141.94it/s]Running 10000 simulations.:  39%|███▉      | 3914/10000 [00:28<00:42, 142.05it/s]Running 10000 simulations.:  39%|███▉      | 3929/10000 [00:28<00:43, 140.80it/s]Running 10000 simulations.:  39%|███▉      | 3944/10000 [00:29<00:43, 140.78it/s]Running 10000 simulations.:  40%|███▉      | 3959/10000 [00:29<00:42, 140.60it/s]Running 10000 simulations.:  40%|███▉      | 3974/10000 [00:29<00:42, 141.38it/s]Running 10000 simulations.:  40%|███▉      | 3989/10000 [00:29<00:42, 141.51it/s]Running 10000 simulations.:  40%|████      | 4004/10000 [00:29<00:42, 141.81it/s]Running 10000 simulations.:  40%|████      | 4019/10000 [00:29<00:42, 141.47it/s]Running 10000 simulations.:  40%|████      | 4034/10000 [00:29<00:42, 140.89it/s]Running 10000 simulations.:  40%|████      | 4049/10000 [00:29<00:42, 140.51it/s]Running 10000 simulations.:  41%|████      | 4064/10000 [00:29<00:42, 139.41it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:29<00:42, 138.89it/s]Running 10000 simulations.:  41%|████      | 4093/10000 [00:30<00:42, 139.15it/s]Running 10000 simulations.:  41%|████      | 4107/10000 [00:30<00:43, 136.32it/s]Running 10000 simulations.:  41%|████      | 4121/10000 [00:30<00:43, 134.04it/s]Running 10000 simulations.:  41%|████▏     | 4135/10000 [00:30<00:44, 132.64it/s]Running 10000 simulations.:  41%|████▏     | 4149/10000 [00:30<00:44, 131.64it/s]Running 10000 simulations.:  42%|████▏     | 4163/10000 [00:30<00:44, 130.74it/s]Running 10000 simulations.:  42%|████▏     | 4177/10000 [00:30<00:44, 129.82it/s]Running 10000 simulations.:  42%|████▏     | 4191/10000 [00:30<00:44, 129.88it/s]Running 10000 simulations.:  42%|████▏     | 4204/10000 [00:30<00:44, 129.23it/s]Running 10000 simulations.:  42%|████▏     | 4218/10000 [00:31<00:44, 129.49it/s]Running 10000 simulations.:  42%|████▏     | 4231/10000 [00:31<00:44, 129.47it/s]Running 10000 simulations.:  42%|████▏     | 4244/10000 [00:31<00:44, 129.45it/s]Running 10000 simulations.:  43%|████▎     | 4258/10000 [00:31<00:44, 130.42it/s]Running 10000 simulations.:  43%|████▎     | 4272/10000 [00:31<00:43, 132.66it/s]Running 10000 simulations.:  43%|████▎     | 4287/10000 [00:31<00:42, 135.33it/s]Running 10000 simulations.:  43%|████▎     | 4302/10000 [00:31<00:41, 137.55it/s]Running 10000 simulations.:  43%|████▎     | 4317/10000 [00:31<00:40, 138.85it/s]Running 10000 simulations.:  43%|████▎     | 4332/10000 [00:31<00:40, 139.91it/s]Running 10000 simulations.:  43%|████▎     | 4347/10000 [00:31<00:40, 140.14it/s]Running 10000 simulations.:  44%|████▎     | 4362/10000 [00:32<00:40, 140.01it/s]Running 10000 simulations.:  44%|████▍     | 4377/10000 [00:32<00:40, 139.94it/s]Running 10000 simulations.:  44%|████▍     | 4392/10000 [00:32<00:39, 140.32it/s]Running 10000 simulations.:  44%|████▍     | 4407/10000 [00:32<00:39, 140.07it/s]Running 10000 simulations.:  44%|████▍     | 4422/10000 [00:32<00:39, 139.93it/s]Running 10000 simulations.:  44%|████▍     | 4437/10000 [00:32<00:39, 140.14it/s]Running 10000 simulations.:  45%|████▍     | 4452/10000 [00:32<00:39, 139.82it/s]Running 10000 simulations.:  45%|████▍     | 4467/10000 [00:32<00:39, 140.49it/s]Running 10000 simulations.:  45%|████▍     | 4482/10000 [00:32<00:42, 130.17it/s]Running 10000 simulations.:  45%|████▍     | 4496/10000 [00:33<00:42, 129.68it/s]Running 10000 simulations.:  45%|████▌     | 4510/10000 [00:33<00:42, 129.43it/s]Running 10000 simulations.:  45%|████▌     | 4524/10000 [00:33<00:42, 129.13it/s]Running 10000 simulations.:  45%|████▌     | 4537/10000 [00:33<00:42, 128.75it/s]Running 10000 simulations.:  46%|████▌     | 4550/10000 [00:33<00:42, 128.63it/s]Running 10000 simulations.:  46%|████▌     | 4563/10000 [00:33<00:42, 128.33it/s]Running 10000 simulations.:  46%|████▌     | 4576/10000 [00:33<00:42, 128.00it/s]Running 10000 simulations.:  46%|████▌     | 4589/10000 [00:33<00:42, 128.05it/s]Running 10000 simulations.:  46%|████▌     | 4602/10000 [00:33<00:42, 127.87it/s]Running 10000 simulations.:  46%|████▌     | 4615/10000 [00:34<00:42, 128.10it/s]Running 10000 simulations.:  46%|████▋     | 4628/10000 [00:34<00:41, 128.11it/s]Running 10000 simulations.:  46%|████▋     | 4642/10000 [00:34<00:41, 130.22it/s]Running 10000 simulations.:  47%|████▋     | 4657/10000 [00:34<00:40, 133.39it/s]Running 10000 simulations.:  47%|████▋     | 4672/10000 [00:34<00:39, 136.06it/s]Running 10000 simulations.:  47%|████▋     | 4687/10000 [00:34<00:38, 137.61it/s]Running 10000 simulations.:  47%|████▋     | 4702/10000 [00:34<00:38, 139.04it/s]Running 10000 simulations.:  47%|████▋     | 4717/10000 [00:34<00:37, 139.61it/s]Running 10000 simulations.:  47%|████▋     | 4732/10000 [00:34<00:37, 139.96it/s]Running 10000 simulations.:  47%|████▋     | 4747/10000 [00:34<00:37, 140.29it/s]Running 10000 simulations.:  48%|████▊     | 4762/10000 [00:35<00:37, 140.70it/s]Running 10000 simulations.:  48%|████▊     | 4777/10000 [00:35<00:37, 140.74it/s]Running 10000 simulations.:  48%|████▊     | 4792/10000 [00:35<00:36, 140.82it/s]Running 10000 simulations.:  48%|████▊     | 4807/10000 [00:35<00:36, 141.07it/s]Running 10000 simulations.:  48%|████▊     | 4822/10000 [00:35<00:36, 141.23it/s]Running 10000 simulations.:  48%|████▊     | 4837/10000 [00:35<00:36, 141.42it/s]Running 10000 simulations.:  49%|████▊     | 4852/10000 [00:35<00:36, 141.11it/s]Running 10000 simulations.:  49%|████▊     | 4867/10000 [00:35<00:36, 140.59it/s]Running 10000 simulations.:  49%|████▉     | 4882/10000 [00:35<00:36, 140.33it/s]Running 10000 simulations.:  49%|████▉     | 4897/10000 [00:36<00:36, 140.72it/s]Running 10000 simulations.:  49%|████▉     | 4912/10000 [00:36<00:36, 141.29it/s]Running 10000 simulations.:  49%|████▉     | 4927/10000 [00:36<00:35, 141.33it/s]Running 10000 simulations.:  49%|████▉     | 4942/10000 [00:36<00:35, 141.08it/s]Running 10000 simulations.:  50%|████▉     | 4958/10000 [00:36<00:34, 145.31it/s]Running 10000 simulations.:  50%|████▉     | 4974/10000 [00:36<00:33, 148.82it/s]Running 10000 simulations.:  50%|████▉     | 4989/10000 [00:36<00:34, 146.46it/s]Running 10000 simulations.:  50%|█████     | 5004/10000 [00:36<00:34, 144.87it/s]Running 10000 simulations.:  50%|█████     | 5019/10000 [00:36<00:34, 143.78it/s]Running 10000 simulations.:  50%|█████     | 5034/10000 [00:36<00:34, 142.64it/s]Running 10000 simulations.:  50%|█████     | 5049/10000 [00:37<00:35, 141.43it/s]Running 10000 simulations.:  51%|█████     | 5064/10000 [00:37<00:35, 140.92it/s]Running 10000 simulations.:  51%|█████     | 5079/10000 [00:37<00:34, 141.18it/s]Running 10000 simulations.:  51%|█████     | 5094/10000 [00:37<00:34, 140.96it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:37<00:34, 141.19it/s]Running 10000 simulations.:  51%|█████     | 5124/10000 [00:37<00:34, 141.19it/s]Running 10000 simulations.:  51%|█████▏    | 5139/10000 [00:37<00:34, 140.53it/s]Running 10000 simulations.:  52%|█████▏    | 5154/10000 [00:37<00:34, 141.06it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:37<00:34, 141.15it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:38<00:34, 141.19it/s]Running 10000 simulations.:  52%|█████▏    | 5199/10000 [00:38<00:33, 141.58it/s]Running 10000 simulations.:  52%|█████▏    | 5214/10000 [00:38<00:34, 140.60it/s]Running 10000 simulations.:  52%|█████▏    | 5229/10000 [00:38<00:33, 140.80it/s]Running 10000 simulations.:  52%|█████▏    | 5244/10000 [00:38<00:33, 141.32it/s]Running 10000 simulations.:  53%|█████▎    | 5259/10000 [00:38<00:33, 141.35it/s]Running 10000 simulations.:  53%|█████▎    | 5274/10000 [00:38<00:33, 141.59it/s]Running 10000 simulations.:  53%|█████▎    | 5289/10000 [00:38<00:33, 141.17it/s]Running 10000 simulations.:  53%|█████▎    | 5304/10000 [00:38<00:33, 140.83it/s]Running 10000 simulations.:  53%|█████▎    | 5319/10000 [00:38<00:33, 140.69it/s]Running 10000 simulations.:  53%|█████▎    | 5334/10000 [00:39<00:33, 140.68it/s]Running 10000 simulations.:  53%|█████▎    | 5349/10000 [00:39<00:32, 141.02it/s]Running 10000 simulations.:  54%|█████▎    | 5364/10000 [00:39<00:32, 141.19it/s]Running 10000 simulations.:  54%|█████▍    | 5379/10000 [00:39<00:32, 140.64it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:39<00:32, 140.34it/s]Running 10000 simulations.:  54%|█████▍    | 5409/10000 [00:39<00:32, 140.36it/s]Running 10000 simulations.:  54%|█████▍    | 5424/10000 [00:39<00:32, 140.73it/s]Running 10000 simulations.:  54%|█████▍    | 5439/10000 [00:39<00:32, 141.07it/s]Running 10000 simulations.:  55%|█████▍    | 5454/10000 [00:39<00:32, 141.23it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:40<00:32, 140.53it/s]Running 10000 simulations.:  55%|█████▍    | 5484/10000 [00:40<00:32, 140.23it/s]Running 10000 simulations.:  55%|█████▍    | 5499/10000 [00:40<00:32, 139.97it/s]Running 10000 simulations.:  55%|█████▌    | 5513/10000 [00:40<00:32, 139.73it/s]Running 10000 simulations.:  55%|█████▌    | 5527/10000 [00:40<00:32, 139.40it/s]Running 10000 simulations.:  55%|█████▌    | 5541/10000 [00:40<00:32, 138.85it/s]Running 10000 simulations.:  56%|█████▌    | 5555/10000 [00:40<00:32, 138.65it/s]Running 10000 simulations.:  56%|█████▌    | 5569/10000 [00:40<00:32, 138.38it/s]Running 10000 simulations.:  56%|█████▌    | 5583/10000 [00:40<00:31, 138.42it/s]Running 10000 simulations.:  56%|█████▌    | 5597/10000 [00:40<00:31, 138.87it/s]Running 10000 simulations.:  56%|█████▌    | 5611/10000 [00:41<00:31, 138.27it/s]Running 10000 simulations.:  56%|█████▋    | 5625/10000 [00:41<00:31, 136.97it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:41<00:31, 137.49it/s]Running 10000 simulations.:  57%|█████▋    | 5654/10000 [00:41<00:31, 138.48it/s]Running 10000 simulations.:  57%|█████▋    | 5669/10000 [00:41<00:31, 139.42it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:41<00:30, 140.09it/s]Running 10000 simulations.:  57%|█████▋    | 5699/10000 [00:41<00:30, 139.49it/s]Running 10000 simulations.:  57%|█████▋    | 5713/10000 [00:41<00:30, 139.16it/s]Running 10000 simulations.:  57%|█████▋    | 5727/10000 [00:41<00:30, 139.41it/s]Running 10000 simulations.:  57%|█████▋    | 5741/10000 [00:42<00:30, 139.49it/s]Running 10000 simulations.:  58%|█████▊    | 5756/10000 [00:42<00:30, 140.02it/s]Running 10000 simulations.:  58%|█████▊    | 5771/10000 [00:42<00:30, 140.10it/s]Running 10000 simulations.:  58%|█████▊    | 5786/10000 [00:42<00:30, 139.47it/s]Running 10000 simulations.:  58%|█████▊    | 5800/10000 [00:42<00:30, 138.95it/s]Running 10000 simulations.:  58%|█████▊    | 5814/10000 [00:42<00:30, 138.91it/s]Running 10000 simulations.:  58%|█████▊    | 5828/10000 [00:42<00:30, 139.02it/s]Running 10000 simulations.:  58%|█████▊    | 5842/10000 [00:42<00:29, 138.94it/s]Running 10000 simulations.:  59%|█████▊    | 5857/10000 [00:42<00:29, 139.71it/s]Running 10000 simulations.:  59%|█████▊    | 5871/10000 [00:42<00:29, 139.52it/s]Running 10000 simulations.:  59%|█████▉    | 5886/10000 [00:43<00:29, 140.02it/s]Running 10000 simulations.:  59%|█████▉    | 5901/10000 [00:43<00:29, 138.71it/s]Running 10000 simulations.:  59%|█████▉    | 5916/10000 [00:43<00:29, 139.19it/s]Running 10000 simulations.:  59%|█████▉    | 5931/10000 [00:43<00:29, 140.13it/s]Running 10000 simulations.:  59%|█████▉    | 5946/10000 [00:43<00:28, 140.63it/s]Running 10000 simulations.:  60%|█████▉    | 5961/10000 [00:43<00:28, 140.99it/s]Running 10000 simulations.:  60%|█████▉    | 5976/10000 [00:43<00:29, 137.21it/s]Running 10000 simulations.:  60%|█████▉    | 5990/10000 [00:43<00:30, 132.76it/s]Running 10000 simulations.:  60%|██████    | 6004/10000 [00:43<00:30, 129.61it/s]Running 10000 simulations.:  60%|██████    | 6018/10000 [00:44<00:30, 128.85it/s]Running 10000 simulations.:  60%|██████    | 6031/10000 [00:44<00:31, 126.89it/s]Running 10000 simulations.:  60%|██████    | 6044/10000 [00:44<00:31, 126.01it/s]Running 10000 simulations.:  61%|██████    | 6057/10000 [00:44<00:31, 125.22it/s]Running 10000 simulations.:  61%|██████    | 6070/10000 [00:44<00:31, 125.71it/s]Running 10000 simulations.:  61%|██████    | 6083/10000 [00:44<00:30, 126.74it/s]Running 10000 simulations.:  61%|██████    | 6096/10000 [00:44<00:30, 127.16it/s]Running 10000 simulations.:  61%|██████    | 6110/10000 [00:44<00:30, 128.30it/s]Running 10000 simulations.:  61%|██████    | 6124/10000 [00:44<00:29, 129.96it/s]Running 10000 simulations.:  61%|██████▏   | 6138/10000 [00:44<00:29, 130.57it/s]Running 10000 simulations.:  62%|██████▏   | 6152/10000 [00:45<00:29, 129.73it/s]Running 10000 simulations.:  62%|██████▏   | 6165/10000 [00:45<00:29, 129.20it/s]Running 10000 simulations.:  62%|██████▏   | 6179/10000 [00:45<00:29, 129.45it/s]Running 10000 simulations.:  62%|██████▏   | 6192/10000 [00:45<00:29, 128.53it/s]Running 10000 simulations.:  62%|██████▏   | 6205/10000 [00:45<00:29, 127.87it/s]Running 10000 simulations.:  62%|██████▏   | 6218/10000 [00:45<00:29, 127.66it/s]Running 10000 simulations.:  62%|██████▏   | 6231/10000 [00:45<00:29, 127.69it/s]Running 10000 simulations.:  62%|██████▏   | 6244/10000 [00:45<00:29, 127.29it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:45<00:29, 127.03it/s]Running 10000 simulations.:  63%|██████▎   | 6270/10000 [00:46<00:29, 127.47it/s]Running 10000 simulations.:  63%|██████▎   | 6285/10000 [00:46<00:28, 131.61it/s]Running 10000 simulations.:  63%|██████▎   | 6300/10000 [00:46<00:27, 134.31it/s]Running 10000 simulations.:  63%|██████▎   | 6315/10000 [00:46<00:27, 136.09it/s]Running 10000 simulations.:  63%|██████▎   | 6329/10000 [00:46<00:26, 137.17it/s]Running 10000 simulations.:  63%|██████▎   | 6344/10000 [00:46<00:26, 138.76it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:46<00:26, 139.54it/s]Running 10000 simulations.:  64%|██████▎   | 6374/10000 [00:46<00:25, 140.15it/s]Running 10000 simulations.:  64%|██████▍   | 6389/10000 [00:46<00:25, 140.87it/s]Running 10000 simulations.:  64%|██████▍   | 6404/10000 [00:46<00:25, 140.99it/s]Running 10000 simulations.:  64%|██████▍   | 6419/10000 [00:47<00:25, 141.30it/s]Running 10000 simulations.:  64%|██████▍   | 6434/10000 [00:47<00:25, 141.40it/s]Running 10000 simulations.:  64%|██████▍   | 6449/10000 [00:47<00:25, 141.06it/s]Running 10000 simulations.:  65%|██████▍   | 6464/10000 [00:47<00:25, 140.60it/s]Running 10000 simulations.:  65%|██████▍   | 6479/10000 [00:47<00:24, 141.49it/s]Running 10000 simulations.:  65%|██████▍   | 6494/10000 [00:47<00:24, 141.56it/s]Running 10000 simulations.:  65%|██████▌   | 6509/10000 [00:47<00:24, 141.42it/s]Running 10000 simulations.:  65%|██████▌   | 6524/10000 [00:47<00:24, 141.28it/s]Running 10000 simulations.:  65%|██████▌   | 6539/10000 [00:47<00:24, 140.36it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:48<00:24, 140.97it/s]Running 10000 simulations.:  66%|██████▌   | 6569/10000 [00:48<00:24, 141.72it/s]Running 10000 simulations.:  66%|██████▌   | 6584/10000 [00:48<00:24, 142.09it/s]Running 10000 simulations.:  66%|██████▌   | 6599/10000 [00:48<00:24, 141.65it/s]Running 10000 simulations.:  66%|██████▌   | 6614/10000 [00:48<00:23, 141.77it/s]Running 10000 simulations.:  66%|██████▋   | 6629/10000 [00:48<00:23, 141.11it/s]Running 10000 simulations.:  66%|██████▋   | 6644/10000 [00:48<00:23, 141.07it/s]Running 10000 simulations.:  67%|██████▋   | 6659/10000 [00:48<00:23, 141.49it/s]Running 10000 simulations.:  67%|██████▋   | 6674/10000 [00:48<00:23, 141.09it/s]Running 10000 simulations.:  67%|██████▋   | 6689/10000 [00:48<00:23, 140.52it/s]Running 10000 simulations.:  67%|██████▋   | 6704/10000 [00:49<00:23, 140.77it/s]Running 10000 simulations.:  67%|██████▋   | 6719/10000 [00:49<00:23, 140.62it/s]Running 10000 simulations.:  67%|██████▋   | 6734/10000 [00:49<00:23, 140.88it/s]Running 10000 simulations.:  67%|██████▋   | 6749/10000 [00:49<00:23, 141.16it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:49<00:22, 141.38it/s]Running 10000 simulations.:  68%|██████▊   | 6779/10000 [00:49<00:22, 140.91it/s]Running 10000 simulations.:  68%|██████▊   | 6794/10000 [00:49<00:22, 140.90it/s]Running 10000 simulations.:  68%|██████▊   | 6809/10000 [00:49<00:22, 140.90it/s]Running 10000 simulations.:  68%|██████▊   | 6824/10000 [00:49<00:22, 141.86it/s]Running 10000 simulations.:  68%|██████▊   | 6839/10000 [00:50<00:22, 141.84it/s]Running 10000 simulations.:  69%|██████▊   | 6854/10000 [00:50<00:22, 141.81it/s]Running 10000 simulations.:  69%|██████▊   | 6869/10000 [00:50<00:22, 141.49it/s]Running 10000 simulations.:  69%|██████▉   | 6884/10000 [00:50<00:22, 141.55it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:50<00:21, 141.27it/s]Running 10000 simulations.:  69%|██████▉   | 6914/10000 [00:50<00:21, 141.13it/s]Running 10000 simulations.:  69%|██████▉   | 6929/10000 [00:50<00:21, 141.51it/s]Running 10000 simulations.:  69%|██████▉   | 6944/10000 [00:50<00:21, 141.88it/s]Running 10000 simulations.:  70%|██████▉   | 6959/10000 [00:50<00:21, 141.02it/s]Running 10000 simulations.:  70%|██████▉   | 6974/10000 [00:50<00:21, 141.18it/s]Running 10000 simulations.:  70%|██████▉   | 6989/10000 [00:51<00:21, 141.45it/s]Running 10000 simulations.:  70%|███████   | 7004/10000 [00:51<00:21, 140.82it/s]Running 10000 simulations.:  70%|███████   | 7019/10000 [00:51<00:21, 140.69it/s]Running 10000 simulations.:  70%|███████   | 7034/10000 [00:51<00:21, 141.02it/s]Running 10000 simulations.:  70%|███████   | 7049/10000 [00:51<00:20, 141.10it/s]Running 10000 simulations.:  71%|███████   | 7064/10000 [00:51<00:20, 141.27it/s]Running 10000 simulations.:  71%|███████   | 7079/10000 [00:51<00:20, 141.19it/s]Running 10000 simulations.:  71%|███████   | 7094/10000 [00:51<00:20, 141.35it/s]Running 10000 simulations.:  71%|███████   | 7109/10000 [00:51<00:20, 140.83it/s]Running 10000 simulations.:  71%|███████   | 7124/10000 [00:52<00:20, 140.90it/s]Running 10000 simulations.:  71%|███████▏  | 7139/10000 [00:52<00:20, 140.72it/s]Running 10000 simulations.:  72%|███████▏  | 7154/10000 [00:52<00:20, 140.94it/s]Running 10000 simulations.:  72%|███████▏  | 7169/10000 [00:52<00:20, 141.00it/s]Running 10000 simulations.:  72%|███████▏  | 7184/10000 [00:52<00:19, 141.31it/s]Running 10000 simulations.:  72%|███████▏  | 7199/10000 [00:52<00:19, 140.98it/s]Running 10000 simulations.:  72%|███████▏  | 7214/10000 [00:52<00:19, 141.10it/s]Running 10000 simulations.:  72%|███████▏  | 7229/10000 [00:52<00:19, 140.54it/s]Running 10000 simulations.:  72%|███████▏  | 7244/10000 [00:52<00:19, 140.72it/s]Running 10000 simulations.:  73%|███████▎  | 7259/10000 [00:53<00:19, 141.18it/s]Running 10000 simulations.:  73%|███████▎  | 7274/10000 [00:53<00:19, 140.76it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:53<00:19, 138.62it/s]Running 10000 simulations.:  73%|███████▎  | 7303/10000 [00:53<00:19, 137.76it/s]Running 10000 simulations.:  73%|███████▎  | 7317/10000 [00:53<00:19, 137.02it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:53<00:19, 135.71it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:53<00:19, 135.59it/s]Running 10000 simulations.:  74%|███████▎  | 7359/10000 [00:53<00:19, 136.21it/s]Running 10000 simulations.:  74%|███████▎  | 7373/10000 [00:53<00:19, 136.28it/s]Running 10000 simulations.:  74%|███████▍  | 7387/10000 [00:53<00:19, 136.17it/s]Running 10000 simulations.:  74%|███████▍  | 7401/10000 [00:54<00:19, 135.52it/s]Running 10000 simulations.:  74%|███████▍  | 7415/10000 [00:54<00:19, 135.80it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:54<00:18, 135.45it/s]Running 10000 simulations.:  74%|███████▍  | 7443/10000 [00:54<00:18, 135.95it/s]Running 10000 simulations.:  75%|███████▍  | 7457/10000 [00:54<00:18, 135.82it/s]Running 10000 simulations.:  75%|███████▍  | 7471/10000 [00:54<00:18, 135.06it/s]Running 10000 simulations.:  75%|███████▍  | 7485/10000 [00:54<00:18, 135.64it/s]Running 10000 simulations.:  75%|███████▍  | 7499/10000 [00:54<00:18, 135.76it/s]Running 10000 simulations.:  75%|███████▌  | 7513/10000 [00:54<00:18, 135.44it/s]Running 10000 simulations.:  75%|███████▌  | 7527/10000 [00:54<00:18, 135.13it/s]Running 10000 simulations.:  75%|███████▌  | 7541/10000 [00:55<00:18, 135.46it/s]Running 10000 simulations.:  76%|███████▌  | 7555/10000 [00:55<00:18, 135.01it/s]Running 10000 simulations.:  76%|███████▌  | 7569/10000 [00:55<00:18, 134.89it/s]Running 10000 simulations.:  76%|███████▌  | 7583/10000 [00:55<00:17, 134.82it/s]Running 10000 simulations.:  76%|███████▌  | 7597/10000 [00:55<00:17, 135.07it/s]Running 10000 simulations.:  76%|███████▌  | 7611/10000 [00:55<00:17, 134.15it/s]Running 10000 simulations.:  76%|███████▋  | 7625/10000 [00:55<00:17, 134.38it/s]Running 10000 simulations.:  76%|███████▋  | 7639/10000 [00:55<00:17, 134.82it/s]Running 10000 simulations.:  77%|███████▋  | 7653/10000 [00:55<00:17, 134.97it/s]Running 10000 simulations.:  77%|███████▋  | 7667/10000 [00:56<00:17, 134.88it/s]Running 10000 simulations.:  77%|███████▋  | 7681/10000 [00:56<00:17, 135.01it/s]Running 10000 simulations.:  77%|███████▋  | 7695/10000 [00:56<00:17, 135.38it/s]Running 10000 simulations.:  77%|███████▋  | 7709/10000 [00:56<00:16, 134.82it/s]Running 10000 simulations.:  77%|███████▋  | 7723/10000 [00:56<00:16, 134.79it/s]Running 10000 simulations.:  77%|███████▋  | 7737/10000 [00:56<00:16, 135.20it/s]Running 10000 simulations.:  78%|███████▊  | 7751/10000 [00:56<00:16, 135.71it/s]Running 10000 simulations.:  78%|███████▊  | 7765/10000 [00:56<00:16, 135.89it/s]Running 10000 simulations.:  78%|███████▊  | 7779/10000 [00:56<00:16, 135.79it/s]Running 10000 simulations.:  78%|███████▊  | 7793/10000 [00:56<00:16, 134.89it/s]Running 10000 simulations.:  78%|███████▊  | 7807/10000 [00:57<00:16, 135.14it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:57<00:16, 134.87it/s]Running 10000 simulations.:  78%|███████▊  | 7835/10000 [00:57<00:15, 135.46it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:57<00:15, 136.31it/s]Running 10000 simulations.:  79%|███████▊  | 7863/10000 [00:57<00:15, 136.62it/s]Running 10000 simulations.:  79%|███████▉  | 7877/10000 [00:57<00:15, 136.71it/s]Running 10000 simulations.:  79%|███████▉  | 7891/10000 [00:57<00:15, 136.47it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:57<00:15, 135.85it/s]Running 10000 simulations.:  79%|███████▉  | 7919/10000 [00:57<00:15, 135.48it/s]Running 10000 simulations.:  79%|███████▉  | 7933/10000 [00:57<00:15, 135.47it/s]Running 10000 simulations.:  79%|███████▉  | 7947/10000 [00:58<00:15, 135.00it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:58<00:15, 135.43it/s]Running 10000 simulations.:  80%|███████▉  | 7975/10000 [00:58<00:14, 135.84it/s]Running 10000 simulations.:  80%|███████▉  | 7989/10000 [00:58<00:14, 135.91it/s]Running 10000 simulations.:  80%|████████  | 8003/10000 [00:58<00:14, 135.35it/s]Running 10000 simulations.:  80%|████████  | 8017/10000 [00:58<00:14, 135.58it/s]Running 10000 simulations.:  80%|████████  | 8031/10000 [00:58<00:14, 135.59it/s]Running 10000 simulations.:  80%|████████  | 8045/10000 [00:58<00:14, 135.23it/s]Running 10000 simulations.:  81%|████████  | 8059/10000 [00:58<00:14, 135.55it/s]Running 10000 simulations.:  81%|████████  | 8073/10000 [00:59<00:14, 135.52it/s]Running 10000 simulations.:  81%|████████  | 8087/10000 [00:59<00:14, 135.16it/s]Running 10000 simulations.:  81%|████████  | 8101/10000 [00:59<00:14, 135.29it/s]Running 10000 simulations.:  81%|████████  | 8115/10000 [00:59<00:13, 135.98it/s]Running 10000 simulations.:  81%|████████▏ | 8129/10000 [00:59<00:13, 135.70it/s]Running 10000 simulations.:  81%|████████▏ | 8143/10000 [00:59<00:13, 135.52it/s]Running 10000 simulations.:  82%|████████▏ | 8157/10000 [00:59<00:13, 135.43it/s]Running 10000 simulations.:  82%|████████▏ | 8171/10000 [00:59<00:13, 135.23it/s]Running 10000 simulations.:  82%|████████▏ | 8185/10000 [00:59<00:13, 134.44it/s]Running 10000 simulations.:  82%|████████▏ | 8199/10000 [00:59<00:13, 134.23it/s]Running 10000 simulations.:  82%|████████▏ | 8213/10000 [01:00<00:13, 135.22it/s]Running 10000 simulations.:  82%|████████▏ | 8227/10000 [01:00<00:13, 134.71it/s]Running 10000 simulations.:  82%|████████▏ | 8241/10000 [01:00<00:13, 135.08it/s]Running 10000 simulations.:  83%|████████▎ | 8255/10000 [01:00<00:12, 135.51it/s]Running 10000 simulations.:  83%|████████▎ | 8269/10000 [01:00<00:12, 134.99it/s]Running 10000 simulations.:  83%|████████▎ | 8283/10000 [01:00<00:12, 132.86it/s]Running 10000 simulations.:  83%|████████▎ | 8297/10000 [01:00<00:12, 132.11it/s]Running 10000 simulations.:  83%|████████▎ | 8311/10000 [01:00<00:12, 134.28it/s]Running 10000 simulations.:  83%|████████▎ | 8326/10000 [01:00<00:12, 136.03it/s]Running 10000 simulations.:  83%|████████▎ | 8341/10000 [01:01<00:12, 137.66it/s]Running 10000 simulations.:  84%|████████▎ | 8356/10000 [01:01<00:11, 138.67it/s]Running 10000 simulations.:  84%|████████▎ | 8370/10000 [01:01<00:11, 138.68it/s]Running 10000 simulations.:  84%|████████▍ | 8385/10000 [01:01<00:11, 139.11it/s]Running 10000 simulations.:  84%|████████▍ | 8399/10000 [01:01<00:11, 134.68it/s]Running 10000 simulations.:  84%|████████▍ | 8414/10000 [01:01<00:11, 136.39it/s]Running 10000 simulations.:  84%|████████▍ | 8429/10000 [01:01<00:11, 138.05it/s]Running 10000 simulations.:  84%|████████▍ | 8444/10000 [01:01<00:11, 139.47it/s]Running 10000 simulations.:  85%|████████▍ | 8458/10000 [01:01<00:11, 139.25it/s]Running 10000 simulations.:  85%|████████▍ | 8472/10000 [01:01<00:10, 139.15it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [01:02<00:10, 139.74it/s]Running 10000 simulations.:  85%|████████▌ | 8501/10000 [01:02<00:10, 139.17it/s]Running 10000 simulations.:  85%|████████▌ | 8515/10000 [01:02<00:10, 138.93it/s]Running 10000 simulations.:  85%|████████▌ | 8530/10000 [01:02<00:10, 139.53it/s]Running 10000 simulations.:  85%|████████▌ | 8544/10000 [01:02<00:10, 139.13it/s]Running 10000 simulations.:  86%|████████▌ | 8558/10000 [01:02<00:10, 138.62it/s]Running 10000 simulations.:  86%|████████▌ | 8573/10000 [01:02<00:10, 139.51it/s]Running 10000 simulations.:  86%|████████▌ | 8588/10000 [01:02<00:10, 140.19it/s]Running 10000 simulations.:  86%|████████▌ | 8603/10000 [01:02<00:10, 133.88it/s]Running 10000 simulations.:  86%|████████▌ | 8617/10000 [01:03<00:10, 131.75it/s]Running 10000 simulations.:  86%|████████▋ | 8632/10000 [01:03<00:10, 134.55it/s]Running 10000 simulations.:  86%|████████▋ | 8647/10000 [01:03<00:09, 136.40it/s]Running 10000 simulations.:  87%|████████▋ | 8662/10000 [01:03<00:09, 138.02it/s]Running 10000 simulations.:  87%|████████▋ | 8677/10000 [01:03<00:09, 138.88it/s]Running 10000 simulations.:  87%|████████▋ | 8691/10000 [01:03<00:09, 139.09it/s]Running 10000 simulations.:  87%|████████▋ | 8706/10000 [01:03<00:09, 139.67it/s]Running 10000 simulations.:  87%|████████▋ | 8721/10000 [01:03<00:09, 140.19it/s]Running 10000 simulations.:  87%|████████▋ | 8736/10000 [01:03<00:09, 139.94it/s]Running 10000 simulations.:  88%|████████▊ | 8751/10000 [01:03<00:08, 140.16it/s]Running 10000 simulations.:  88%|████████▊ | 8766/10000 [01:04<00:08, 140.48it/s]Running 10000 simulations.:  88%|████████▊ | 8781/10000 [01:04<00:08, 140.08it/s]Running 10000 simulations.:  88%|████████▊ | 8796/10000 [01:04<00:08, 140.60it/s]Running 10000 simulations.:  88%|████████▊ | 8811/10000 [01:04<00:08, 140.70it/s]Running 10000 simulations.:  88%|████████▊ | 8826/10000 [01:04<00:08, 140.44it/s]Running 10000 simulations.:  88%|████████▊ | 8841/10000 [01:04<00:08, 140.48it/s]Running 10000 simulations.:  89%|████████▊ | 8856/10000 [01:04<00:08, 140.57it/s]Running 10000 simulations.:  89%|████████▊ | 8871/10000 [01:04<00:08, 140.61it/s]Running 10000 simulations.:  89%|████████▉ | 8886/10000 [01:04<00:07, 140.83it/s]Running 10000 simulations.:  89%|████████▉ | 8901/10000 [01:05<00:07, 141.34it/s]Running 10000 simulations.:  89%|████████▉ | 8916/10000 [01:05<00:07, 140.91it/s]Running 10000 simulations.:  89%|████████▉ | 8931/10000 [01:05<00:07, 141.06it/s]Running 10000 simulations.:  89%|████████▉ | 8946/10000 [01:05<00:07, 141.24it/s]Running 10000 simulations.:  90%|████████▉ | 8961/10000 [01:05<00:07, 140.73it/s]Running 10000 simulations.:  90%|████████▉ | 8976/10000 [01:05<00:07, 139.57it/s]Running 10000 simulations.:  90%|████████▉ | 8990/10000 [01:05<00:07, 139.22it/s]Running 10000 simulations.:  90%|█████████ | 9004/10000 [01:05<00:07, 139.09it/s]Running 10000 simulations.:  90%|█████████ | 9018/10000 [01:05<00:07, 139.29it/s]Running 10000 simulations.:  90%|█████████ | 9033/10000 [01:05<00:06, 139.68it/s]Running 10000 simulations.:  90%|█████████ | 9048/10000 [01:06<00:06, 140.11it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [01:06<00:06, 139.96it/s]Running 10000 simulations.:  91%|█████████ | 9078/10000 [01:06<00:06, 140.46it/s]Running 10000 simulations.:  91%|█████████ | 9093/10000 [01:06<00:06, 140.58it/s]Running 10000 simulations.:  91%|█████████ | 9108/10000 [01:06<00:06, 138.70it/s]Running 10000 simulations.:  91%|█████████ | 9122/10000 [01:06<00:06, 134.64it/s]Running 10000 simulations.:  91%|█████████▏| 9136/10000 [01:06<00:06, 132.89it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [01:06<00:06, 131.22it/s]Running 10000 simulations.:  92%|█████████▏| 9164/10000 [01:06<00:06, 130.26it/s]Running 10000 simulations.:  92%|█████████▏| 9178/10000 [01:07<00:06, 130.04it/s]Running 10000 simulations.:  92%|█████████▏| 9192/10000 [01:07<00:06, 129.75it/s]Running 10000 simulations.:  92%|█████████▏| 9205/10000 [01:07<00:06, 128.99it/s]Running 10000 simulations.:  92%|█████████▏| 9218/10000 [01:07<00:06, 128.44it/s]Running 10000 simulations.:  92%|█████████▏| 9231/10000 [01:07<00:05, 128.52it/s]Running 10000 simulations.:  92%|█████████▏| 9244/10000 [01:07<00:05, 128.01it/s]Running 10000 simulations.:  93%|█████████▎| 9257/10000 [01:07<00:05, 127.85it/s]Running 10000 simulations.:  93%|█████████▎| 9270/10000 [01:07<00:05, 127.95it/s]Running 10000 simulations.:  93%|█████████▎| 9283/10000 [01:07<00:05, 128.01it/s]Running 10000 simulations.:  93%|█████████▎| 9296/10000 [01:07<00:05, 128.26it/s]Running 10000 simulations.:  93%|█████████▎| 9309/10000 [01:08<00:05, 128.61it/s]Running 10000 simulations.:  93%|█████████▎| 9322/10000 [01:08<00:05, 128.75it/s]Running 10000 simulations.:  93%|█████████▎| 9335/10000 [01:08<00:05, 128.70it/s]Running 10000 simulations.:  93%|█████████▎| 9348/10000 [01:08<00:05, 128.90it/s]Running 10000 simulations.:  94%|█████████▎| 9361/10000 [01:08<00:04, 128.82it/s]Running 10000 simulations.:  94%|█████████▎| 9374/10000 [01:08<00:04, 129.09it/s]Running 10000 simulations.:  94%|█████████▍| 9387/10000 [01:08<00:04, 129.30it/s]Running 10000 simulations.:  94%|█████████▍| 9400/10000 [01:08<00:04, 129.44it/s]Running 10000 simulations.:  94%|█████████▍| 9413/10000 [01:08<00:04, 129.59it/s]Running 10000 simulations.:  94%|█████████▍| 9426/10000 [01:08<00:04, 128.75it/s]Running 10000 simulations.:  94%|█████████▍| 9439/10000 [01:09<00:04, 128.66it/s]Running 10000 simulations.:  95%|█████████▍| 9452/10000 [01:09<00:04, 128.40it/s]Running 10000 simulations.:  95%|█████████▍| 9465/10000 [01:09<00:04, 128.70it/s]Running 10000 simulations.:  95%|█████████▍| 9478/10000 [01:09<00:04, 128.76it/s]Running 10000 simulations.:  95%|█████████▍| 9491/10000 [01:09<00:03, 128.70it/s]Running 10000 simulations.:  95%|█████████▌| 9504/10000 [01:09<00:03, 128.68it/s]Running 10000 simulations.:  95%|█████████▌| 9518/10000 [01:09<00:03, 129.85it/s]Running 10000 simulations.:  95%|█████████▌| 9533/10000 [01:09<00:03, 135.00it/s]Running 10000 simulations.:  95%|█████████▌| 9548/10000 [01:09<00:03, 138.73it/s]Running 10000 simulations.:  96%|█████████▌| 9563/10000 [01:10<00:03, 140.06it/s]Running 10000 simulations.:  96%|█████████▌| 9578/10000 [01:10<00:03, 136.36it/s]Running 10000 simulations.:  96%|█████████▌| 9592/10000 [01:10<00:03, 133.76it/s]Running 10000 simulations.:  96%|█████████▌| 9606/10000 [01:10<00:02, 132.12it/s]Running 10000 simulations.:  96%|█████████▌| 9620/10000 [01:10<00:02, 131.10it/s]Running 10000 simulations.:  96%|█████████▋| 9634/10000 [01:10<00:02, 130.08it/s]Running 10000 simulations.:  96%|█████████▋| 9648/10000 [01:10<00:02, 129.78it/s]Running 10000 simulations.:  97%|█████████▋| 9662/10000 [01:10<00:02, 129.92it/s]Running 10000 simulations.:  97%|█████████▋| 9676/10000 [01:10<00:02, 130.00it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [01:10<00:02, 129.52it/s]Running 10000 simulations.:  97%|█████████▋| 9703/10000 [01:11<00:02, 129.66it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [01:11<00:02, 133.56it/s]Running 10000 simulations.:  97%|█████████▋| 9733/10000 [01:11<00:01, 136.06it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [01:11<00:01, 137.98it/s]Running 10000 simulations.:  98%|█████████▊| 9763/10000 [01:11<00:01, 139.38it/s]Running 10000 simulations.:  98%|█████████▊| 9778/10000 [01:11<00:01, 140.15it/s]Running 10000 simulations.:  98%|█████████▊| 9793/10000 [01:11<00:01, 141.25it/s]Running 10000 simulations.:  98%|█████████▊| 9808/10000 [01:11<00:01, 141.96it/s]Running 10000 simulations.:  98%|█████████▊| 9823/10000 [01:11<00:01, 142.21it/s]Running 10000 simulations.:  98%|█████████▊| 9838/10000 [01:12<00:01, 142.15it/s]Running 10000 simulations.:  99%|█████████▊| 9853/10000 [01:12<00:01, 142.72it/s]Running 10000 simulations.:  99%|█████████▊| 9868/10000 [01:12<00:00, 142.81it/s]Running 10000 simulations.:  99%|█████████▉| 9883/10000 [01:12<00:00, 142.83it/s]Running 10000 simulations.:  99%|█████████▉| 9898/10000 [01:12<00:00, 142.60it/s]Running 10000 simulations.:  99%|█████████▉| 9913/10000 [01:12<00:00, 142.86it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [01:12<00:00, 142.75it/s]Running 10000 simulations.:  99%|█████████▉| 9943/10000 [01:12<00:00, 143.24it/s]Running 10000 simulations.: 100%|█████████▉| 9958/10000 [01:12<00:00, 143.29it/s]Running 10000 simulations.: 100%|█████████▉| 9973/10000 [01:12<00:00, 143.40it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [01:13<00:00, 143.09it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:13<00:00, 136.68it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:07, 146.96it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<01:07, 147.09it/s]Running 10000 simulations.:   0%|          | 45/10000 [00:00<01:07, 146.81it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<01:07, 146.28it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<01:07, 146.04it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<01:07, 145.86it/s]Running 10000 simulations.:   1%|          | 105/10000 [00:00<01:07, 145.74it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<01:07, 145.81it/s]Running 10000 simulations.:   1%|▏         | 135/10000 [00:00<01:07, 145.98it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:01<01:07, 146.13it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:01<01:07, 146.09it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:01<01:07, 145.97it/s]Running 10000 simulations.:   2%|▏         | 195/10000 [00:01<01:07, 146.00it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:01<01:07, 145.03it/s]Running 10000 simulations.:   2%|▏         | 225/10000 [00:01<01:07, 144.60it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:01<01:07, 144.06it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<01:07, 144.20it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:01<01:07, 144.22it/s]Running 10000 simulations.:   3%|▎         | 285/10000 [00:01<01:07, 144.17it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:02<01:07, 143.65it/s]Running 10000 simulations.:   3%|▎         | 315/10000 [00:02<01:07, 143.20it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:02<01:07, 142.96it/s]Running 10000 simulations.:   3%|▎         | 345/10000 [00:02<01:07, 142.62it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:02<01:07, 142.76it/s]Running 10000 simulations.:   4%|▍         | 375/10000 [00:02<01:07, 142.67it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:02<01:07, 141.81it/s]Running 10000 simulations.:   4%|▍         | 405/10000 [00:02<01:07, 142.27it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:02<01:06, 143.05it/s]Running 10000 simulations.:   4%|▍         | 435/10000 [00:03<01:07, 142.74it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:03<01:06, 143.00it/s]Running 10000 simulations.:   5%|▍         | 465/10000 [00:03<01:07, 142.22it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:03<01:07, 142.04it/s]Running 10000 simulations.:   5%|▍         | 495/10000 [00:03<01:06, 141.92it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:03<01:07, 140.53it/s]Running 10000 simulations.:   5%|▌         | 525/10000 [00:03<01:07, 139.57it/s]Running 10000 simulations.:   5%|▌         | 539/10000 [00:03<01:07, 139.51it/s]Running 10000 simulations.:   6%|▌         | 553/10000 [00:03<01:07, 139.32it/s]Running 10000 simulations.:   6%|▌         | 567/10000 [00:03<01:07, 139.08it/s]Running 10000 simulations.:   6%|▌         | 582/10000 [00:04<01:07, 139.84it/s]Running 10000 simulations.:   6%|▌         | 597/10000 [00:04<01:07, 140.30it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:04<01:06, 140.37it/s]Running 10000 simulations.:   6%|▋         | 627/10000 [00:04<01:06, 141.03it/s]Running 10000 simulations.:   6%|▋         | 642/10000 [00:04<01:07, 139.36it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:04<01:08, 136.69it/s]Running 10000 simulations.:   7%|▋         | 670/10000 [00:04<01:08, 136.90it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:04<01:07, 137.54it/s]Running 10000 simulations.:   7%|▋         | 698/10000 [00:04<01:07, 138.19it/s]Running 10000 simulations.:   7%|▋         | 713/10000 [00:05<01:06, 139.23it/s]Running 10000 simulations.:   7%|▋         | 728/10000 [00:05<01:06, 139.78it/s]Running 10000 simulations.:   7%|▋         | 743/10000 [00:05<01:05, 140.28it/s]Running 10000 simulations.:   8%|▊         | 758/10000 [00:05<01:05, 141.27it/s]Running 10000 simulations.:   8%|▊         | 773/10000 [00:05<01:05, 140.61it/s]Running 10000 simulations.:   8%|▊         | 788/10000 [00:05<01:05, 140.07it/s]Running 10000 simulations.:   8%|▊         | 803/10000 [00:05<01:06, 139.14it/s]Running 10000 simulations.:   8%|▊         | 817/10000 [00:05<01:06, 138.38it/s]Running 10000 simulations.:   8%|▊         | 832/10000 [00:05<01:05, 139.02it/s]Running 10000 simulations.:   8%|▊         | 847/10000 [00:05<01:05, 139.93it/s]Running 10000 simulations.:   9%|▊         | 862/10000 [00:06<01:04, 140.86it/s]Running 10000 simulations.:   9%|▉         | 877/10000 [00:06<01:04, 141.56it/s]Running 10000 simulations.:   9%|▉         | 892/10000 [00:06<01:05, 138.25it/s]Running 10000 simulations.:   9%|▉         | 906/10000 [00:06<01:08, 133.36it/s]Running 10000 simulations.:   9%|▉         | 920/10000 [00:06<01:10, 129.29it/s]Running 10000 simulations.:   9%|▉         | 933/10000 [00:06<01:11, 127.57it/s]Running 10000 simulations.:   9%|▉         | 946/10000 [00:06<01:11, 126.12it/s]Running 10000 simulations.:  10%|▉         | 959/10000 [00:06<01:12, 124.22it/s]Running 10000 simulations.:  10%|▉         | 972/10000 [00:06<01:12, 124.31it/s]Running 10000 simulations.:  10%|▉         | 985/10000 [00:07<01:12, 124.17it/s]Running 10000 simulations.:  10%|▉         | 998/10000 [00:07<01:13, 123.20it/s]Running 10000 simulations.:  10%|█         | 1011/10000 [00:07<01:11, 124.86it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:07<01:09, 129.32it/s]Running 10000 simulations.:  10%|█         | 1040/10000 [00:07<01:07, 132.17it/s]Running 10000 simulations.:  11%|█         | 1055/10000 [00:07<01:06, 135.03it/s]Running 10000 simulations.:  11%|█         | 1069/10000 [00:07<01:05, 136.38it/s]Running 10000 simulations.:  11%|█         | 1084/10000 [00:07<01:04, 137.86it/s]Running 10000 simulations.:  11%|█         | 1099/10000 [00:07<01:04, 138.82it/s]Running 10000 simulations.:  11%|█         | 1114/10000 [00:07<01:03, 139.71it/s]Running 10000 simulations.:  11%|█▏        | 1129/10000 [00:08<01:03, 140.69it/s]Running 10000 simulations.:  11%|█▏        | 1144/10000 [00:08<01:02, 140.63it/s]Running 10000 simulations.:  12%|█▏        | 1159/10000 [00:08<01:03, 139.98it/s]Running 10000 simulations.:  12%|█▏        | 1174/10000 [00:08<01:03, 139.26it/s]Running 10000 simulations.:  12%|█▏        | 1188/10000 [00:08<01:03, 139.13it/s]Running 10000 simulations.:  12%|█▏        | 1203/10000 [00:08<01:03, 139.50it/s]Running 10000 simulations.:  12%|█▏        | 1217/10000 [00:08<01:02, 139.45it/s]Running 10000 simulations.:  12%|█▏        | 1232/10000 [00:08<01:02, 140.21it/s]Running 10000 simulations.:  12%|█▏        | 1247/10000 [00:08<01:02, 140.75it/s]Running 10000 simulations.:  13%|█▎        | 1262/10000 [00:09<01:01, 141.50it/s]Running 10000 simulations.:  13%|█▎        | 1277/10000 [00:09<01:01, 141.74it/s]Running 10000 simulations.:  13%|█▎        | 1292/10000 [00:09<01:01, 140.73it/s]Running 10000 simulations.:  13%|█▎        | 1307/10000 [00:09<01:02, 138.93it/s]Running 10000 simulations.:  13%|█▎        | 1321/10000 [00:09<01:03, 137.51it/s]Running 10000 simulations.:  13%|█▎        | 1335/10000 [00:09<01:02, 137.65it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:09<01:02, 138.57it/s]Running 10000 simulations.:  14%|█▎        | 1365/10000 [00:09<01:01, 139.45it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:09<01:01, 140.14it/s]Running 10000 simulations.:  14%|█▍        | 1395/10000 [00:09<01:01, 140.35it/s]Running 10000 simulations.:  14%|█▍        | 1410/10000 [00:10<01:01, 139.97it/s]Running 10000 simulations.:  14%|█▍        | 1425/10000 [00:10<01:00, 141.02it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:10<01:00, 141.33it/s]Running 10000 simulations.:  15%|█▍        | 1455/10000 [00:10<01:00, 141.55it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:10<01:00, 141.54it/s]Running 10000 simulations.:  15%|█▍        | 1485/10000 [00:10<01:00, 140.12it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:10<01:01, 139.20it/s]Running 10000 simulations.:  15%|█▌        | 1514/10000 [00:10<01:00, 139.38it/s]Running 10000 simulations.:  15%|█▌        | 1529/10000 [00:10<01:00, 139.75it/s]Running 10000 simulations.:  15%|█▌        | 1543/10000 [00:11<01:00, 139.77it/s]Running 10000 simulations.:  16%|█▌        | 1558/10000 [00:11<01:00, 140.07it/s]Running 10000 simulations.:  16%|█▌        | 1573/10000 [00:11<00:59, 140.58it/s]Running 10000 simulations.:  16%|█▌        | 1588/10000 [00:11<00:59, 141.01it/s]Running 10000 simulations.:  16%|█▌        | 1603/10000 [00:11<00:59, 141.26it/s]Running 10000 simulations.:  16%|█▌        | 1618/10000 [00:11<00:59, 140.59it/s]Running 10000 simulations.:  16%|█▋        | 1633/10000 [00:11<00:59, 139.62it/s]Running 10000 simulations.:  16%|█▋        | 1648/10000 [00:11<00:59, 139.84it/s]Running 10000 simulations.:  17%|█▋        | 1663/10000 [00:11<00:59, 139.97it/s]Running 10000 simulations.:  17%|█▋        | 1678/10000 [00:12<00:59, 140.10it/s]Running 10000 simulations.:  17%|█▋        | 1693/10000 [00:12<00:59, 140.65it/s]Running 10000 simulations.:  17%|█▋        | 1708/10000 [00:12<00:58, 140.84it/s]Running 10000 simulations.:  17%|█▋        | 1723/10000 [00:12<00:58, 141.30it/s]Running 10000 simulations.:  17%|█▋        | 1738/10000 [00:12<00:58, 141.60it/s]Running 10000 simulations.:  18%|█▊        | 1753/10000 [00:12<00:58, 141.25it/s]Running 10000 simulations.:  18%|█▊        | 1768/10000 [00:12<00:58, 140.41it/s]Running 10000 simulations.:  18%|█▊        | 1783/10000 [00:12<00:58, 140.23it/s]Running 10000 simulations.:  18%|█▊        | 1798/10000 [00:12<00:58, 140.64it/s]Running 10000 simulations.:  18%|█▊        | 1813/10000 [00:12<00:58, 140.17it/s]Running 10000 simulations.:  18%|█▊        | 1828/10000 [00:13<00:58, 140.04it/s]Running 10000 simulations.:  18%|█▊        | 1843/10000 [00:13<00:57, 140.85it/s]Running 10000 simulations.:  19%|█▊        | 1858/10000 [00:13<00:57, 141.15it/s]Running 10000 simulations.:  19%|█▊        | 1873/10000 [00:13<00:57, 141.52it/s]Running 10000 simulations.:  19%|█▉        | 1888/10000 [00:13<00:57, 141.53it/s]Running 10000 simulations.:  19%|█▉        | 1903/10000 [00:13<00:57, 140.47it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:13<00:57, 140.20it/s]Running 10000 simulations.:  19%|█▉        | 1933/10000 [00:13<00:57, 140.30it/s]Running 10000 simulations.:  19%|█▉        | 1948/10000 [00:13<00:57, 140.53it/s]Running 10000 simulations.:  20%|█▉        | 1963/10000 [00:14<00:57, 140.08it/s]Running 10000 simulations.:  20%|█▉        | 1978/10000 [00:14<00:57, 140.69it/s]Running 10000 simulations.:  20%|█▉        | 1993/10000 [00:14<00:56, 140.82it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:14<00:56, 141.03it/s]Running 10000 simulations.:  20%|██        | 2023/10000 [00:14<00:56, 141.33it/s]Running 10000 simulations.:  20%|██        | 2038/10000 [00:14<00:56, 140.51it/s]Running 10000 simulations.:  21%|██        | 2053/10000 [00:14<00:56, 139.58it/s]Running 10000 simulations.:  21%|██        | 2068/10000 [00:14<00:56, 139.90it/s]Running 10000 simulations.:  21%|██        | 2083/10000 [00:14<00:56, 140.54it/s]Running 10000 simulations.:  21%|██        | 2098/10000 [00:14<00:56, 140.96it/s]Running 10000 simulations.:  21%|██        | 2113/10000 [00:15<00:55, 141.77it/s]Running 10000 simulations.:  21%|██▏       | 2128/10000 [00:15<00:55, 142.09it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:15<00:55, 142.10it/s]Running 10000 simulations.:  22%|██▏       | 2158/10000 [00:15<00:55, 142.02it/s]Running 10000 simulations.:  22%|██▏       | 2173/10000 [00:15<00:55, 140.02it/s]Running 10000 simulations.:  22%|██▏       | 2188/10000 [00:15<00:55, 139.98it/s]Running 10000 simulations.:  22%|██▏       | 2203/10000 [00:15<00:55, 140.16it/s]Running 10000 simulations.:  22%|██▏       | 2218/10000 [00:15<00:55, 140.11it/s]Running 10000 simulations.:  22%|██▏       | 2233/10000 [00:15<00:55, 140.55it/s]Running 10000 simulations.:  22%|██▏       | 2248/10000 [00:16<00:54, 140.96it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:16<00:54, 141.07it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:16<00:54, 140.98it/s]Running 10000 simulations.:  23%|██▎       | 2293/10000 [00:16<00:54, 140.15it/s]Running 10000 simulations.:  23%|██▎       | 2308/10000 [00:16<00:55, 139.41it/s]Running 10000 simulations.:  23%|██▎       | 2322/10000 [00:16<00:55, 139.28it/s]Running 10000 simulations.:  23%|██▎       | 2336/10000 [00:16<00:55, 139.23it/s]Running 10000 simulations.:  24%|██▎       | 2350/10000 [00:16<00:54, 139.31it/s]Running 10000 simulations.:  24%|██▎       | 2365/10000 [00:16<00:54, 139.57it/s]Running 10000 simulations.:  24%|██▍       | 2379/10000 [00:16<00:54, 139.66it/s]Running 10000 simulations.:  24%|██▍       | 2393/10000 [00:17<00:54, 139.72it/s]Running 10000 simulations.:  24%|██▍       | 2407/10000 [00:17<00:54, 139.54it/s]Running 10000 simulations.:  24%|██▍       | 2421/10000 [00:17<00:54, 138.92it/s]Running 10000 simulations.:  24%|██▍       | 2436/10000 [00:17<00:53, 140.93it/s]Running 10000 simulations.:  25%|██▍       | 2452/10000 [00:17<00:52, 145.09it/s]Running 10000 simulations.:  25%|██▍       | 2467/10000 [00:17<00:51, 146.37it/s]Running 10000 simulations.:  25%|██▍       | 2482/10000 [00:17<00:53, 141.79it/s]Running 10000 simulations.:  25%|██▍       | 2497/10000 [00:17<00:53, 140.22it/s]Running 10000 simulations.:  25%|██▌       | 2512/10000 [00:17<00:53, 140.05it/s]Running 10000 simulations.:  25%|██▌       | 2527/10000 [00:18<00:53, 139.56it/s]Running 10000 simulations.:  25%|██▌       | 2541/10000 [00:18<00:53, 138.22it/s]Running 10000 simulations.:  26%|██▌       | 2555/10000 [00:18<00:54, 137.65it/s]Running 10000 simulations.:  26%|██▌       | 2569/10000 [00:18<00:53, 138.00it/s]Running 10000 simulations.:  26%|██▌       | 2583/10000 [00:18<00:53, 138.35it/s]Running 10000 simulations.:  26%|██▌       | 2598/10000 [00:18<00:53, 138.94it/s]Running 10000 simulations.:  26%|██▌       | 2612/10000 [00:18<00:53, 137.95it/s]Running 10000 simulations.:  26%|██▋       | 2626/10000 [00:18<00:53, 136.68it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:18<00:53, 136.51it/s]Running 10000 simulations.:  27%|██▋       | 2654/10000 [00:18<00:54, 135.66it/s]Running 10000 simulations.:  27%|██▋       | 2668/10000 [00:19<00:54, 134.75it/s]Running 10000 simulations.:  27%|██▋       | 2682/10000 [00:19<00:54, 133.41it/s]Running 10000 simulations.:  27%|██▋       | 2696/10000 [00:19<00:54, 135.25it/s]Running 10000 simulations.:  27%|██▋       | 2711/10000 [00:19<00:53, 137.19it/s]Running 10000 simulations.:  27%|██▋       | 2726/10000 [00:19<00:52, 138.18it/s]Running 10000 simulations.:  27%|██▋       | 2741/10000 [00:19<00:52, 138.80it/s]Running 10000 simulations.:  28%|██▊       | 2755/10000 [00:19<00:53, 136.00it/s]Running 10000 simulations.:  28%|██▊       | 2769/10000 [00:19<00:53, 136.32it/s]Running 10000 simulations.:  28%|██▊       | 2783/10000 [00:19<00:53, 136.05it/s]Running 10000 simulations.:  28%|██▊       | 2797/10000 [00:20<00:52, 136.25it/s]Running 10000 simulations.:  28%|██▊       | 2811/10000 [00:20<00:52, 136.43it/s]Running 10000 simulations.:  28%|██▊       | 2825/10000 [00:20<00:52, 136.77it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:20<00:52, 136.98it/s]Running 10000 simulations.:  29%|██▊       | 2853/10000 [00:20<00:52, 137.20it/s]Running 10000 simulations.:  29%|██▊       | 2867/10000 [00:20<00:51, 137.99it/s]Running 10000 simulations.:  29%|██▉       | 2881/10000 [00:20<00:51, 137.29it/s]Running 10000 simulations.:  29%|██▉       | 2895/10000 [00:20<00:52, 136.21it/s]Running 10000 simulations.:  29%|██▉       | 2909/10000 [00:20<00:52, 135.86it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:20<00:52, 135.86it/s]Running 10000 simulations.:  29%|██▉       | 2937/10000 [00:21<00:52, 134.79it/s]Running 10000 simulations.:  30%|██▉       | 2951/10000 [00:21<00:51, 135.97it/s]Running 10000 simulations.:  30%|██▉       | 2965/10000 [00:21<00:51, 136.86it/s]Running 10000 simulations.:  30%|██▉       | 2979/10000 [00:21<00:51, 137.14it/s]Running 10000 simulations.:  30%|██▉       | 2993/10000 [00:21<00:50, 137.45it/s]Running 10000 simulations.:  30%|███       | 3007/10000 [00:21<00:51, 136.70it/s]Running 10000 simulations.:  30%|███       | 3021/10000 [00:21<00:51, 136.83it/s]Running 10000 simulations.:  30%|███       | 3035/10000 [00:21<00:50, 137.62it/s]Running 10000 simulations.:  30%|███       | 3049/10000 [00:21<00:50, 138.02it/s]Running 10000 simulations.:  31%|███       | 3063/10000 [00:21<00:50, 138.50it/s]Running 10000 simulations.:  31%|███       | 3077/10000 [00:22<00:50, 137.48it/s]Running 10000 simulations.:  31%|███       | 3091/10000 [00:22<00:50, 138.17it/s]Running 10000 simulations.:  31%|███       | 3106/10000 [00:22<00:49, 139.03it/s]Running 10000 simulations.:  31%|███       | 3121/10000 [00:22<00:49, 139.52it/s]Running 10000 simulations.:  31%|███▏      | 3135/10000 [00:22<00:49, 139.47it/s]Running 10000 simulations.:  31%|███▏      | 3149/10000 [00:22<00:49, 137.16it/s]Running 10000 simulations.:  32%|███▏      | 3163/10000 [00:22<00:50, 135.84it/s]Running 10000 simulations.:  32%|███▏      | 3177/10000 [00:22<00:50, 135.66it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:22<00:50, 135.32it/s]Running 10000 simulations.:  32%|███▏      | 3205/10000 [00:23<00:50, 135.45it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:23<00:49, 135.76it/s]Running 10000 simulations.:  32%|███▏      | 3233/10000 [00:23<00:49, 136.58it/s]Running 10000 simulations.:  32%|███▏      | 3247/10000 [00:23<00:49, 136.55it/s]Running 10000 simulations.:  33%|███▎      | 3261/10000 [00:23<00:50, 134.68it/s]Running 10000 simulations.:  33%|███▎      | 3275/10000 [00:23<00:50, 132.90it/s]Running 10000 simulations.:  33%|███▎      | 3289/10000 [00:23<00:51, 130.56it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:23<00:51, 129.40it/s]Running 10000 simulations.:  33%|███▎      | 3316/10000 [00:23<00:51, 128.64it/s]Running 10000 simulations.:  33%|███▎      | 3329/10000 [00:23<00:52, 128.03it/s]Running 10000 simulations.:  33%|███▎      | 3342/10000 [00:24<00:51, 128.22it/s]Running 10000 simulations.:  34%|███▎      | 3356/10000 [00:24<00:51, 129.96it/s]Running 10000 simulations.:  34%|███▎      | 3370/10000 [00:24<00:50, 130.56it/s]Running 10000 simulations.:  34%|███▍      | 3384/10000 [00:24<00:50, 131.34it/s]Running 10000 simulations.:  34%|███▍      | 3398/10000 [00:24<00:50, 131.31it/s]Running 10000 simulations.:  34%|███▍      | 3412/10000 [00:24<00:50, 129.51it/s]Running 10000 simulations.:  34%|███▍      | 3425/10000 [00:24<00:51, 128.13it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:24<00:50, 130.87it/s]Running 10000 simulations.:  35%|███▍      | 3454/10000 [00:24<00:48, 133.69it/s]Running 10000 simulations.:  35%|███▍      | 3468/10000 [00:25<00:48, 135.16it/s]Running 10000 simulations.:  35%|███▍      | 3482/10000 [00:25<00:47, 136.42it/s]Running 10000 simulations.:  35%|███▍      | 3497/10000 [00:25<00:47, 138.17it/s]Running 10000 simulations.:  35%|███▌      | 3512/10000 [00:25<00:46, 139.15it/s]Running 10000 simulations.:  35%|███▌      | 3527/10000 [00:25<00:46, 139.84it/s]Running 10000 simulations.:  35%|███▌      | 3541/10000 [00:25<00:46, 139.32it/s]Running 10000 simulations.:  36%|███▌      | 3555/10000 [00:25<00:46, 138.54it/s]Running 10000 simulations.:  36%|███▌      | 3569/10000 [00:25<00:46, 138.82it/s]Running 10000 simulations.:  36%|███▌      | 3584/10000 [00:25<00:45, 139.52it/s]Running 10000 simulations.:  36%|███▌      | 3598/10000 [00:25<00:45, 139.47it/s]Running 10000 simulations.:  36%|███▌      | 3612/10000 [00:26<00:45, 139.34it/s]Running 10000 simulations.:  36%|███▋      | 3626/10000 [00:26<00:45, 139.27it/s]Running 10000 simulations.:  36%|███▋      | 3640/10000 [00:26<00:45, 139.01it/s]Running 10000 simulations.:  37%|███▋      | 3654/10000 [00:26<00:45, 138.99it/s]Running 10000 simulations.:  37%|███▋      | 3669/10000 [00:26<00:45, 139.55it/s]Running 10000 simulations.:  37%|███▋      | 3684/10000 [00:26<00:45, 139.77it/s]Running 10000 simulations.:  37%|███▋      | 3699/10000 [00:26<00:44, 140.20it/s]Running 10000 simulations.:  37%|███▋      | 3714/10000 [00:26<00:44, 140.75it/s]Running 10000 simulations.:  37%|███▋      | 3729/10000 [00:26<00:44, 140.42it/s]Running 10000 simulations.:  37%|███▋      | 3744/10000 [00:26<00:44, 139.47it/s]Running 10000 simulations.:  38%|███▊      | 3758/10000 [00:27<00:44, 139.53it/s]Running 10000 simulations.:  38%|███▊      | 3772/10000 [00:27<00:44, 139.28it/s]Running 10000 simulations.:  38%|███▊      | 3786/10000 [00:27<00:44, 139.26it/s]Running 10000 simulations.:  38%|███▊      | 3800/10000 [00:27<00:44, 138.70it/s]Running 10000 simulations.:  38%|███▊      | 3815/10000 [00:27<00:44, 139.36it/s]Running 10000 simulations.:  38%|███▊      | 3830/10000 [00:27<00:43, 140.59it/s]Running 10000 simulations.:  38%|███▊      | 3845/10000 [00:27<00:43, 141.41it/s]Running 10000 simulations.:  39%|███▊      | 3860/10000 [00:27<00:43, 141.39it/s]Running 10000 simulations.:  39%|███▉      | 3875/10000 [00:27<00:43, 140.00it/s]Running 10000 simulations.:  39%|███▉      | 3890/10000 [00:28<00:43, 138.87it/s]Running 10000 simulations.:  39%|███▉      | 3905/10000 [00:28<00:43, 139.40it/s]Running 10000 simulations.:  39%|███▉      | 3919/10000 [00:28<00:43, 139.50it/s]Running 10000 simulations.:  39%|███▉      | 3934/10000 [00:28<00:43, 140.23it/s]Running 10000 simulations.:  39%|███▉      | 3949/10000 [00:28<00:42, 140.82it/s]Running 10000 simulations.:  40%|███▉      | 3964/10000 [00:28<00:42, 140.86it/s]Running 10000 simulations.:  40%|███▉      | 3979/10000 [00:28<00:42, 140.76it/s]Running 10000 simulations.:  40%|███▉      | 3994/10000 [00:28<00:42, 140.97it/s]Running 10000 simulations.:  40%|████      | 4009/10000 [00:28<00:43, 139.24it/s]Running 10000 simulations.:  40%|████      | 4023/10000 [00:28<00:43, 138.54it/s]Running 10000 simulations.:  40%|████      | 4038/10000 [00:29<00:42, 139.08it/s]Running 10000 simulations.:  41%|████      | 4052/10000 [00:29<00:42, 139.26it/s]Running 10000 simulations.:  41%|████      | 4066/10000 [00:29<00:42, 138.59it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:29<00:42, 138.33it/s]Running 10000 simulations.:  41%|████      | 4095/10000 [00:29<00:42, 139.64it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:29<00:41, 140.92it/s]Running 10000 simulations.:  41%|████▏     | 4125/10000 [00:29<00:41, 141.09it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:29<00:41, 140.68it/s]Running 10000 simulations.:  42%|████▏     | 4155/10000 [00:29<00:41, 140.05it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:30<00:41, 140.33it/s]Running 10000 simulations.:  42%|████▏     | 4185/10000 [00:30<00:41, 140.65it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:30<00:41, 140.42it/s]Running 10000 simulations.:  42%|████▏     | 4215/10000 [00:30<00:41, 140.78it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:30<00:40, 141.23it/s]Running 10000 simulations.:  42%|████▏     | 4245/10000 [00:30<00:41, 139.53it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:30<00:41, 136.83it/s]Running 10000 simulations.:  43%|████▎     | 4273/10000 [00:30<00:42, 134.72it/s]Running 10000 simulations.:  43%|████▎     | 4287/10000 [00:30<00:43, 132.50it/s]Running 10000 simulations.:  43%|████▎     | 4301/10000 [00:30<00:43, 130.78it/s]Running 10000 simulations.:  43%|████▎     | 4315/10000 [00:31<00:43, 129.75it/s]Running 10000 simulations.:  43%|████▎     | 4328/10000 [00:31<00:44, 128.87it/s]Running 10000 simulations.:  43%|████▎     | 4341/10000 [00:31<00:44, 128.50it/s]Running 10000 simulations.:  44%|████▎     | 4355/10000 [00:31<00:43, 129.69it/s]Running 10000 simulations.:  44%|████▎     | 4369/10000 [00:31<00:43, 130.23it/s]Running 10000 simulations.:  44%|████▍     | 4383/10000 [00:31<00:42, 131.26it/s]Running 10000 simulations.:  44%|████▍     | 4397/10000 [00:31<00:42, 131.76it/s]Running 10000 simulations.:  44%|████▍     | 4411/10000 [00:31<00:42, 130.97it/s]Running 10000 simulations.:  44%|████▍     | 4425/10000 [00:31<00:42, 129.94it/s]Running 10000 simulations.:  44%|████▍     | 4438/10000 [00:32<00:42, 129.54it/s]Running 10000 simulations.:  45%|████▍     | 4451/10000 [00:32<00:43, 128.91it/s]Running 10000 simulations.:  45%|████▍     | 4464/10000 [00:32<00:42, 129.19it/s]Running 10000 simulations.:  45%|████▍     | 4477/10000 [00:32<00:42, 128.80it/s]Running 10000 simulations.:  45%|████▍     | 4491/10000 [00:32<00:42, 130.22it/s]Running 10000 simulations.:  45%|████▌     | 4505/10000 [00:32<00:41, 130.86it/s]Running 10000 simulations.:  45%|████▌     | 4519/10000 [00:32<00:41, 131.27it/s]Running 10000 simulations.:  45%|████▌     | 4533/10000 [00:32<00:41, 131.93it/s]Running 10000 simulations.:  45%|████▌     | 4547/10000 [00:32<00:41, 131.21it/s]Running 10000 simulations.:  46%|████▌     | 4561/10000 [00:32<00:41, 130.19it/s]Running 10000 simulations.:  46%|████▌     | 4575/10000 [00:33<00:41, 130.18it/s]Running 10000 simulations.:  46%|████▌     | 4589/10000 [00:33<00:41, 130.18it/s]Running 10000 simulations.:  46%|████▌     | 4603/10000 [00:33<00:41, 129.58it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:33<00:41, 129.60it/s]Running 10000 simulations.:  46%|████▋     | 4630/10000 [00:33<00:41, 130.20it/s]Running 10000 simulations.:  46%|████▋     | 4644/10000 [00:33<00:41, 128.88it/s]Running 10000 simulations.:  47%|████▋     | 4658/10000 [00:33<00:41, 129.70it/s]Running 10000 simulations.:  47%|████▋     | 4671/10000 [00:33<00:41, 129.68it/s]Running 10000 simulations.:  47%|████▋     | 4684/10000 [00:33<00:41, 129.21it/s]Running 10000 simulations.:  47%|████▋     | 4699/10000 [00:34<00:40, 132.31it/s]Running 10000 simulations.:  47%|████▋     | 4714/10000 [00:34<00:39, 135.01it/s]Running 10000 simulations.:  47%|████▋     | 4729/10000 [00:34<00:38, 137.05it/s]Running 10000 simulations.:  47%|████▋     | 4744/10000 [00:34<00:37, 138.43it/s]Running 10000 simulations.:  48%|████▊     | 4759/10000 [00:34<00:37, 139.84it/s]Running 10000 simulations.:  48%|████▊     | 4774/10000 [00:34<00:37, 140.43it/s]Running 10000 simulations.:  48%|████▊     | 4789/10000 [00:34<00:37, 140.35it/s]Running 10000 simulations.:  48%|████▊     | 4804/10000 [00:34<00:36, 140.84it/s]Running 10000 simulations.:  48%|████▊     | 4819/10000 [00:34<00:36, 141.18it/s]Running 10000 simulations.:  48%|████▊     | 4834/10000 [00:34<00:36, 141.31it/s]Running 10000 simulations.:  48%|████▊     | 4849/10000 [00:35<00:36, 141.24it/s]Running 10000 simulations.:  49%|████▊     | 4864/10000 [00:35<00:36, 140.14it/s]Running 10000 simulations.:  49%|████▉     | 4879/10000 [00:35<00:36, 139.82it/s]Running 10000 simulations.:  49%|████▉     | 4894/10000 [00:35<00:36, 141.04it/s]Running 10000 simulations.:  49%|████▉     | 4909/10000 [00:35<00:36, 141.39it/s]Running 10000 simulations.:  49%|████▉     | 4924/10000 [00:35<00:35, 141.55it/s]Running 10000 simulations.:  49%|████▉     | 4939/10000 [00:35<00:35, 141.64it/s]Running 10000 simulations.:  50%|████▉     | 4954/10000 [00:35<00:35, 142.03it/s]Running 10000 simulations.:  50%|████▉     | 4969/10000 [00:35<00:35, 142.17it/s]Running 10000 simulations.:  50%|████▉     | 4984/10000 [00:36<00:35, 141.89it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:36<00:35, 139.74it/s]Running 10000 simulations.:  50%|█████     | 5013/10000 [00:36<00:35, 138.64it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:36<00:35, 138.53it/s]Running 10000 simulations.:  50%|█████     | 5041/10000 [00:36<00:35, 138.79it/s]Running 10000 simulations.:  51%|█████     | 5056/10000 [00:36<00:35, 139.33it/s]Running 10000 simulations.:  51%|█████     | 5070/10000 [00:36<00:35, 139.28it/s]Running 10000 simulations.:  51%|█████     | 5084/10000 [00:36<00:35, 139.27it/s]Running 10000 simulations.:  51%|█████     | 5099/10000 [00:36<00:35, 139.55it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:37<00:38, 125.70it/s]Running 10000 simulations.:  51%|█████▏    | 5127/10000 [00:37<00:37, 129.38it/s]Running 10000 simulations.:  51%|█████▏    | 5141/10000 [00:37<00:39, 123.00it/s]Running 10000 simulations.:  52%|█████▏    | 5155/10000 [00:37<00:38, 127.20it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:37<00:37, 130.21it/s]Running 10000 simulations.:  52%|█████▏    | 5183/10000 [00:37<00:36, 132.64it/s]Running 10000 simulations.:  52%|█████▏    | 5197/10000 [00:37<00:35, 134.64it/s]Running 10000 simulations.:  52%|█████▏    | 5211/10000 [00:37<00:35, 136.05it/s]Running 10000 simulations.:  52%|█████▏    | 5226/10000 [00:37<00:34, 137.26it/s]Running 10000 simulations.:  52%|█████▏    | 5241/10000 [00:37<00:34, 138.47it/s]Running 10000 simulations.:  53%|█████▎    | 5256/10000 [00:38<00:34, 139.10it/s]Running 10000 simulations.:  53%|█████▎    | 5270/10000 [00:38<00:34, 138.20it/s]Running 10000 simulations.:  53%|█████▎    | 5284/10000 [00:38<00:34, 137.97it/s]Running 10000 simulations.:  53%|█████▎    | 5298/10000 [00:38<00:33, 138.38it/s]Running 10000 simulations.:  53%|█████▎    | 5312/10000 [00:38<00:33, 138.82it/s]Running 10000 simulations.:  53%|█████▎    | 5327/10000 [00:38<00:33, 139.47it/s]Running 10000 simulations.:  53%|█████▎    | 5342/10000 [00:38<00:33, 140.23it/s]Running 10000 simulations.:  54%|█████▎    | 5357/10000 [00:38<00:33, 139.92it/s]Running 10000 simulations.:  54%|█████▎    | 5371/10000 [00:38<00:33, 139.63it/s]Running 10000 simulations.:  54%|█████▍    | 5386/10000 [00:39<00:32, 140.08it/s]Running 10000 simulations.:  54%|█████▍    | 5401/10000 [00:39<00:32, 139.81it/s]Running 10000 simulations.:  54%|█████▍    | 5415/10000 [00:39<00:32, 139.54it/s]Running 10000 simulations.:  54%|█████▍    | 5429/10000 [00:39<00:32, 139.57it/s]Running 10000 simulations.:  54%|█████▍    | 5443/10000 [00:39<00:32, 139.52it/s]Running 10000 simulations.:  55%|█████▍    | 5457/10000 [00:39<00:32, 139.62it/s]Running 10000 simulations.:  55%|█████▍    | 5472/10000 [00:39<00:32, 140.29it/s]Running 10000 simulations.:  55%|█████▍    | 5487/10000 [00:39<00:32, 140.34it/s]Running 10000 simulations.:  55%|█████▌    | 5502/10000 [00:39<00:32, 140.13it/s]Running 10000 simulations.:  55%|█████▌    | 5517/10000 [00:39<00:31, 140.29it/s]Running 10000 simulations.:  55%|█████▌    | 5532/10000 [00:40<00:32, 139.44it/s]Running 10000 simulations.:  55%|█████▌    | 5546/10000 [00:40<00:32, 139.08it/s]Running 10000 simulations.:  56%|█████▌    | 5560/10000 [00:40<00:31, 139.16it/s]Running 10000 simulations.:  56%|█████▌    | 5574/10000 [00:40<00:31, 139.23it/s]Running 10000 simulations.:  56%|█████▌    | 5589/10000 [00:40<00:31, 139.56it/s]Running 10000 simulations.:  56%|█████▌    | 5604/10000 [00:40<00:31, 140.21it/s]Running 10000 simulations.:  56%|█████▌    | 5619/10000 [00:40<00:31, 140.18it/s]Running 10000 simulations.:  56%|█████▋    | 5634/10000 [00:40<00:31, 140.24it/s]Running 10000 simulations.:  56%|█████▋    | 5649/10000 [00:40<00:31, 139.89it/s]Running 10000 simulations.:  57%|█████▋    | 5664/10000 [00:40<00:30, 140.17it/s]Running 10000 simulations.:  57%|█████▋    | 5679/10000 [00:41<00:30, 139.93it/s]Running 10000 simulations.:  57%|█████▋    | 5693/10000 [00:41<00:30, 139.49it/s]Running 10000 simulations.:  57%|█████▋    | 5707/10000 [00:41<00:30, 139.44it/s]Running 10000 simulations.:  57%|█████▋    | 5722/10000 [00:41<00:30, 139.82it/s]Running 10000 simulations.:  57%|█████▋    | 5737/10000 [00:41<00:30, 140.24it/s]Running 10000 simulations.:  58%|█████▊    | 5752/10000 [00:41<00:30, 141.11it/s]Running 10000 simulations.:  58%|█████▊    | 5767/10000 [00:41<00:30, 140.82it/s]Running 10000 simulations.:  58%|█████▊    | 5782/10000 [00:41<00:29, 140.61it/s]Running 10000 simulations.:  58%|█████▊    | 5797/10000 [00:41<00:29, 140.22it/s]Running 10000 simulations.:  58%|█████▊    | 5812/10000 [00:42<00:30, 139.04it/s]Running 10000 simulations.:  58%|█████▊    | 5826/10000 [00:42<00:30, 138.62it/s]Running 10000 simulations.:  58%|█████▊    | 5840/10000 [00:42<00:29, 138.79it/s]Running 10000 simulations.:  59%|█████▊    | 5854/10000 [00:42<00:29, 139.07it/s]Running 10000 simulations.:  59%|█████▊    | 5868/10000 [00:42<00:29, 139.08it/s]Running 10000 simulations.:  59%|█████▉    | 5882/10000 [00:42<00:29, 139.29it/s]Running 10000 simulations.:  59%|█████▉    | 5896/10000 [00:42<00:29, 139.47it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:42<00:29, 139.45it/s]Running 10000 simulations.:  59%|█████▉    | 5925/10000 [00:42<00:29, 139.73it/s]Running 10000 simulations.:  59%|█████▉    | 5940/10000 [00:42<00:28, 140.41it/s]Running 10000 simulations.:  60%|█████▉    | 5955/10000 [00:43<00:28, 140.55it/s]Running 10000 simulations.:  60%|█████▉    | 5970/10000 [00:43<00:28, 140.29it/s]Running 10000 simulations.:  60%|█████▉    | 5985/10000 [00:43<00:28, 139.60it/s]Running 10000 simulations.:  60%|█████▉    | 5999/10000 [00:43<00:28, 139.31it/s]Running 10000 simulations.:  60%|██████    | 6013/10000 [00:43<00:28, 139.06it/s]Running 10000 simulations.:  60%|██████    | 6027/10000 [00:43<00:28, 139.34it/s]Running 10000 simulations.:  60%|██████    | 6041/10000 [00:43<00:28, 139.22it/s]Running 10000 simulations.:  61%|██████    | 6055/10000 [00:43<00:28, 139.18it/s]Running 10000 simulations.:  61%|██████    | 6070/10000 [00:43<00:28, 139.63it/s]Running 10000 simulations.:  61%|██████    | 6085/10000 [00:44<00:27, 139.88it/s]Running 10000 simulations.:  61%|██████    | 6100/10000 [00:44<00:27, 140.09it/s]Running 10000 simulations.:  61%|██████    | 6115/10000 [00:44<00:27, 140.03it/s]Running 10000 simulations.:  61%|██████▏   | 6130/10000 [00:44<00:27, 138.95it/s]Running 10000 simulations.:  61%|██████▏   | 6144/10000 [00:44<00:27, 138.05it/s]Running 10000 simulations.:  62%|██████▏   | 6158/10000 [00:44<00:27, 138.13it/s]Running 10000 simulations.:  62%|██████▏   | 6172/10000 [00:44<00:27, 138.44it/s]Running 10000 simulations.:  62%|██████▏   | 6186/10000 [00:44<00:27, 138.82it/s]Running 10000 simulations.:  62%|██████▏   | 6200/10000 [00:44<00:27, 139.02it/s]Running 10000 simulations.:  62%|██████▏   | 6215/10000 [00:44<00:27, 139.38it/s]Running 10000 simulations.:  62%|██████▏   | 6230/10000 [00:45<00:26, 139.71it/s]Running 10000 simulations.:  62%|██████▏   | 6245/10000 [00:45<00:26, 140.14it/s]Running 10000 simulations.:  63%|██████▎   | 6260/10000 [00:45<00:26, 139.90it/s]Running 10000 simulations.:  63%|██████▎   | 6274/10000 [00:45<00:26, 139.74it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:45<00:26, 138.71it/s]Running 10000 simulations.:  63%|██████▎   | 6302/10000 [00:45<00:26, 138.33it/s]Running 10000 simulations.:  63%|██████▎   | 6316/10000 [00:45<00:26, 138.72it/s]Running 10000 simulations.:  63%|██████▎   | 6331/10000 [00:45<00:26, 139.14it/s]Running 10000 simulations.:  63%|██████▎   | 6345/10000 [00:45<00:26, 139.21it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:45<00:26, 139.26it/s]Running 10000 simulations.:  64%|██████▎   | 6373/10000 [00:46<00:26, 139.19it/s]Running 10000 simulations.:  64%|██████▍   | 6387/10000 [00:46<00:26, 138.91it/s]Running 10000 simulations.:  64%|██████▍   | 6401/10000 [00:46<00:25, 139.04it/s]Running 10000 simulations.:  64%|██████▍   | 6415/10000 [00:46<00:25, 138.47it/s]Running 10000 simulations.:  64%|██████▍   | 6429/10000 [00:46<00:25, 138.35it/s]Running 10000 simulations.:  64%|██████▍   | 6443/10000 [00:46<00:25, 138.75it/s]Running 10000 simulations.:  65%|██████▍   | 6457/10000 [00:46<00:25, 138.59it/s]Running 10000 simulations.:  65%|██████▍   | 6471/10000 [00:46<00:25, 138.57it/s]Running 10000 simulations.:  65%|██████▍   | 6485/10000 [00:46<00:25, 138.90it/s]Running 10000 simulations.:  65%|██████▍   | 6499/10000 [00:46<00:25, 139.04it/s]Running 10000 simulations.:  65%|██████▌   | 6513/10000 [00:47<00:25, 138.97it/s]Running 10000 simulations.:  65%|██████▌   | 6527/10000 [00:47<00:24, 139.28it/s]Running 10000 simulations.:  65%|██████▌   | 6541/10000 [00:47<00:24, 138.95it/s]Running 10000 simulations.:  66%|██████▌   | 6555/10000 [00:47<00:24, 138.79it/s]Running 10000 simulations.:  66%|██████▌   | 6569/10000 [00:47<00:24, 138.96it/s]Running 10000 simulations.:  66%|██████▌   | 6583/10000 [00:47<00:24, 138.91it/s]Running 10000 simulations.:  66%|██████▌   | 6597/10000 [00:47<00:24, 138.73it/s]Running 10000 simulations.:  66%|██████▌   | 6611/10000 [00:47<00:24, 138.36it/s]Running 10000 simulations.:  66%|██████▋   | 6625/10000 [00:47<00:24, 138.50it/s]Running 10000 simulations.:  66%|██████▋   | 6640/10000 [00:48<00:24, 138.99it/s]Running 10000 simulations.:  67%|██████▋   | 6654/10000 [00:48<00:24, 139.26it/s]Running 10000 simulations.:  67%|██████▋   | 6669/10000 [00:48<00:23, 139.33it/s]Running 10000 simulations.:  67%|██████▋   | 6683/10000 [00:48<00:23, 139.27it/s]Running 10000 simulations.:  67%|██████▋   | 6697/10000 [00:48<00:23, 139.47it/s]Running 10000 simulations.:  67%|██████▋   | 6712/10000 [00:48<00:23, 139.76it/s]Running 10000 simulations.:  67%|██████▋   | 6726/10000 [00:48<00:23, 139.08it/s]Running 10000 simulations.:  67%|██████▋   | 6740/10000 [00:48<00:23, 138.79it/s]Running 10000 simulations.:  68%|██████▊   | 6754/10000 [00:48<00:23, 138.44it/s]Running 10000 simulations.:  68%|██████▊   | 6768/10000 [00:48<00:23, 138.84it/s]Running 10000 simulations.:  68%|██████▊   | 6783/10000 [00:49<00:23, 139.36it/s]Running 10000 simulations.:  68%|██████▊   | 6798/10000 [00:49<00:22, 139.83it/s]Running 10000 simulations.:  68%|██████▊   | 6812/10000 [00:49<00:22, 139.58it/s]Running 10000 simulations.:  68%|██████▊   | 6826/10000 [00:49<00:22, 139.10it/s]Running 10000 simulations.:  68%|██████▊   | 6840/10000 [00:49<00:22, 139.36it/s]Running 10000 simulations.:  69%|██████▊   | 6854/10000 [00:49<00:22, 139.50it/s]Running 10000 simulations.:  69%|██████▊   | 6868/10000 [00:49<00:22, 139.30it/s]Running 10000 simulations.:  69%|██████▉   | 6882/10000 [00:49<00:22, 139.23it/s]Running 10000 simulations.:  69%|██████▉   | 6896/10000 [00:49<00:22, 139.24it/s]Running 10000 simulations.:  69%|██████▉   | 6910/10000 [00:49<00:22, 138.96it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:50<00:22, 138.64it/s]Running 10000 simulations.:  69%|██████▉   | 6939/10000 [00:50<00:21, 139.51it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:50<00:21, 139.49it/s]Running 10000 simulations.:  70%|██████▉   | 6967/10000 [00:50<00:21, 139.14it/s]Running 10000 simulations.:  70%|██████▉   | 6982/10000 [00:50<00:21, 139.56it/s]Running 10000 simulations.:  70%|██████▉   | 6996/10000 [00:50<00:21, 139.65it/s]Running 10000 simulations.:  70%|███████   | 7011/10000 [00:50<00:21, 140.23it/s]Running 10000 simulations.:  70%|███████   | 7026/10000 [00:50<00:21, 140.52it/s]Running 10000 simulations.:  70%|███████   | 7041/10000 [00:50<00:21, 140.24it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:50<00:21, 138.74it/s]Running 10000 simulations.:  71%|███████   | 7070/10000 [00:51<00:21, 138.10it/s]Running 10000 simulations.:  71%|███████   | 7085/10000 [00:51<00:21, 138.81it/s]Running 10000 simulations.:  71%|███████   | 7100/10000 [00:51<00:20, 141.22it/s]Running 10000 simulations.:  71%|███████   | 7117/10000 [00:51<00:19, 146.68it/s]Running 10000 simulations.:  71%|███████▏  | 7132/10000 [00:51<00:19, 146.11it/s]Running 10000 simulations.:  71%|███████▏  | 7147/10000 [00:51<00:19, 143.57it/s]Running 10000 simulations.:  72%|███████▏  | 7162/10000 [00:51<00:19, 142.99it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:51<00:19, 141.87it/s]Running 10000 simulations.:  72%|███████▏  | 7192/10000 [00:51<00:19, 140.44it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:52<00:19, 140.38it/s]Running 10000 simulations.:  72%|███████▏  | 7222/10000 [00:52<00:19, 140.16it/s]Running 10000 simulations.:  72%|███████▏  | 7237/10000 [00:52<00:19, 140.45it/s]Running 10000 simulations.:  73%|███████▎  | 7252/10000 [00:52<00:19, 140.28it/s]Running 10000 simulations.:  73%|███████▎  | 7267/10000 [00:52<00:19, 140.45it/s]Running 10000 simulations.:  73%|███████▎  | 7282/10000 [00:52<00:19, 139.66it/s]Running 10000 simulations.:  73%|███████▎  | 7296/10000 [00:52<00:19, 139.15it/s]Running 10000 simulations.:  73%|███████▎  | 7310/10000 [00:52<00:19, 139.15it/s]Running 10000 simulations.:  73%|███████▎  | 7324/10000 [00:52<00:19, 138.76it/s]Running 10000 simulations.:  73%|███████▎  | 7338/10000 [00:52<00:19, 138.81it/s]Running 10000 simulations.:  74%|███████▎  | 7352/10000 [00:53<00:19, 139.09it/s]Running 10000 simulations.:  74%|███████▎  | 7367/10000 [00:53<00:18, 139.36it/s]Running 10000 simulations.:  74%|███████▍  | 7382/10000 [00:53<00:18, 139.71it/s]Running 10000 simulations.:  74%|███████▍  | 7397/10000 [00:53<00:18, 140.49it/s]Running 10000 simulations.:  74%|███████▍  | 7412/10000 [00:53<00:18, 140.24it/s]Running 10000 simulations.:  74%|███████▍  | 7427/10000 [00:53<00:18, 139.59it/s]Running 10000 simulations.:  74%|███████▍  | 7441/10000 [00:53<00:18, 139.28it/s]Running 10000 simulations.:  75%|███████▍  | 7455/10000 [00:53<00:18, 138.95it/s]Running 10000 simulations.:  75%|███████▍  | 7469/10000 [00:53<00:18, 138.54it/s]Running 10000 simulations.:  75%|███████▍  | 7483/10000 [00:54<00:18, 138.30it/s]Running 10000 simulations.:  75%|███████▍  | 7497/10000 [00:54<00:18, 138.63it/s]Running 10000 simulations.:  75%|███████▌  | 7512/10000 [00:54<00:17, 139.24it/s]Running 10000 simulations.:  75%|███████▌  | 7526/10000 [00:54<00:17, 139.18it/s]Running 10000 simulations.:  75%|███████▌  | 7540/10000 [00:54<00:17, 139.26it/s]Running 10000 simulations.:  76%|███████▌  | 7554/10000 [00:54<00:17, 138.85it/s]Running 10000 simulations.:  76%|███████▌  | 7568/10000 [00:54<00:17, 138.22it/s]Running 10000 simulations.:  76%|███████▌  | 7582/10000 [00:54<00:17, 138.47it/s]Running 10000 simulations.:  76%|███████▌  | 7596/10000 [00:54<00:17, 138.57it/s]Running 10000 simulations.:  76%|███████▌  | 7610/10000 [00:54<00:17, 138.68it/s]Running 10000 simulations.:  76%|███████▌  | 7624/10000 [00:55<00:17, 138.72it/s]Running 10000 simulations.:  76%|███████▋  | 7638/10000 [00:55<00:17, 138.93it/s]Running 10000 simulations.:  77%|███████▋  | 7652/10000 [00:55<00:16, 139.00it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:55<00:16, 139.05it/s]Running 10000 simulations.:  77%|███████▋  | 7680/10000 [00:55<00:16, 138.45it/s]Running 10000 simulations.:  77%|███████▋  | 7694/10000 [00:55<00:16, 138.31it/s]Running 10000 simulations.:  77%|███████▋  | 7708/10000 [00:55<00:16, 138.02it/s]Running 10000 simulations.:  77%|███████▋  | 7722/10000 [00:55<00:16, 138.07it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:55<00:16, 138.13it/s]Running 10000 simulations.:  78%|███████▊  | 7750/10000 [00:55<00:16, 138.43it/s]Running 10000 simulations.:  78%|███████▊  | 7764/10000 [00:56<00:16, 138.13it/s]Running 10000 simulations.:  78%|███████▊  | 7778/10000 [00:56<00:16, 138.42it/s]Running 10000 simulations.:  78%|███████▊  | 7793/10000 [00:56<00:15, 138.97it/s]Running 10000 simulations.:  78%|███████▊  | 7808/10000 [00:56<00:15, 139.25it/s]Running 10000 simulations.:  78%|███████▊  | 7822/10000 [00:56<00:15, 138.85it/s]Running 10000 simulations.:  78%|███████▊  | 7836/10000 [00:56<00:15, 138.50it/s]Running 10000 simulations.:  78%|███████▊  | 7850/10000 [00:56<00:15, 138.20it/s]Running 10000 simulations.:  79%|███████▊  | 7864/10000 [00:56<00:15, 137.64it/s]Running 10000 simulations.:  79%|███████▉  | 7878/10000 [00:56<00:15, 137.20it/s]Running 10000 simulations.:  79%|███████▉  | 7892/10000 [00:56<00:15, 137.65it/s]Running 10000 simulations.:  79%|███████▉  | 7906/10000 [00:57<00:15, 138.16it/s]Running 10000 simulations.:  79%|███████▉  | 7920/10000 [00:57<00:15, 138.32it/s]Running 10000 simulations.:  79%|███████▉  | 7934/10000 [00:57<00:14, 138.28it/s]Running 10000 simulations.:  79%|███████▉  | 7948/10000 [00:57<00:14, 138.51it/s]Running 10000 simulations.:  80%|███████▉  | 7962/10000 [00:57<00:14, 138.30it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:57<00:14, 138.13it/s]Running 10000 simulations.:  80%|███████▉  | 7991/10000 [00:57<00:14, 138.95it/s]Running 10000 simulations.:  80%|████████  | 8006/10000 [00:57<00:14, 139.64it/s]Running 10000 simulations.:  80%|████████  | 8021/10000 [00:57<00:14, 139.86it/s]Running 10000 simulations.:  80%|████████  | 8036/10000 [00:58<00:13, 140.41it/s]Running 10000 simulations.:  81%|████████  | 8051/10000 [00:58<00:13, 140.57it/s]Running 10000 simulations.:  81%|████████  | 8066/10000 [00:58<00:13, 140.84it/s]Running 10000 simulations.:  81%|████████  | 8081/10000 [00:58<00:13, 141.25it/s]Running 10000 simulations.:  81%|████████  | 8096/10000 [00:58<00:13, 141.90it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:58<00:13, 142.28it/s]Running 10000 simulations.:  81%|████████▏ | 8126/10000 [00:58<00:13, 142.24it/s]Running 10000 simulations.:  81%|████████▏ | 8141/10000 [00:58<00:13, 142.16it/s]Running 10000 simulations.:  82%|████████▏ | 8156/10000 [00:58<00:13, 141.75it/s]Running 10000 simulations.:  82%|████████▏ | 8171/10000 [00:58<00:12, 141.76it/s]Running 10000 simulations.:  82%|████████▏ | 8186/10000 [00:59<00:12, 141.58it/s]Running 10000 simulations.:  82%|████████▏ | 8201/10000 [00:59<00:12, 141.72it/s]Running 10000 simulations.:  82%|████████▏ | 8216/10000 [00:59<00:12, 141.84it/s]Running 10000 simulations.:  82%|████████▏ | 8231/10000 [00:59<00:12, 142.12it/s]Running 10000 simulations.:  82%|████████▏ | 8246/10000 [00:59<00:12, 142.31it/s]Running 10000 simulations.:  83%|████████▎ | 8261/10000 [00:59<00:12, 142.50it/s]Running 10000 simulations.:  83%|████████▎ | 8276/10000 [00:59<00:12, 142.62it/s]Running 10000 simulations.:  83%|████████▎ | 8291/10000 [00:59<00:11, 142.53it/s]Running 10000 simulations.:  83%|████████▎ | 8306/10000 [00:59<00:11, 142.26it/s]Running 10000 simulations.:  83%|████████▎ | 8321/10000 [01:00<00:11, 141.94it/s]Running 10000 simulations.:  83%|████████▎ | 8336/10000 [01:00<00:11, 142.20it/s]Running 10000 simulations.:  84%|████████▎ | 8351/10000 [01:00<00:11, 142.07it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [01:00<00:11, 142.06it/s]Running 10000 simulations.:  84%|████████▍ | 8381/10000 [01:00<00:11, 141.93it/s]Running 10000 simulations.:  84%|████████▍ | 8396/10000 [01:00<00:11, 141.80it/s]Running 10000 simulations.:  84%|████████▍ | 8411/10000 [01:00<00:11, 142.00it/s]Running 10000 simulations.:  84%|████████▍ | 8426/10000 [01:00<00:11, 142.29it/s]Running 10000 simulations.:  84%|████████▍ | 8441/10000 [01:00<00:10, 142.02it/s]Running 10000 simulations.:  85%|████████▍ | 8456/10000 [01:00<00:10, 142.30it/s]Running 10000 simulations.:  85%|████████▍ | 8471/10000 [01:01<00:10, 142.67it/s]Running 10000 simulations.:  85%|████████▍ | 8486/10000 [01:01<00:10, 143.06it/s]Running 10000 simulations.:  85%|████████▌ | 8501/10000 [01:01<00:10, 142.99it/s]Running 10000 simulations.:  85%|████████▌ | 8516/10000 [01:01<00:10, 142.78it/s]Running 10000 simulations.:  85%|████████▌ | 8531/10000 [01:01<00:10, 142.71it/s]Running 10000 simulations.:  85%|████████▌ | 8546/10000 [01:01<00:10, 142.58it/s]Running 10000 simulations.:  86%|████████▌ | 8561/10000 [01:01<00:10, 142.36it/s]Running 10000 simulations.:  86%|████████▌ | 8576/10000 [01:01<00:10, 141.99it/s]Running 10000 simulations.:  86%|████████▌ | 8591/10000 [01:01<00:09, 141.93it/s]Running 10000 simulations.:  86%|████████▌ | 8606/10000 [01:02<00:09, 142.53it/s]Running 10000 simulations.:  86%|████████▌ | 8621/10000 [01:02<00:09, 142.66it/s]Running 10000 simulations.:  86%|████████▋ | 8636/10000 [01:02<00:09, 142.59it/s]Running 10000 simulations.:  87%|████████▋ | 8651/10000 [01:02<00:09, 139.27it/s]Running 10000 simulations.:  87%|████████▋ | 8666/10000 [01:02<00:09, 140.31it/s]Running 10000 simulations.:  87%|████████▋ | 8681/10000 [01:02<00:09, 140.66it/s]Running 10000 simulations.:  87%|████████▋ | 8696/10000 [01:02<00:09, 141.56it/s]Running 10000 simulations.:  87%|████████▋ | 8711/10000 [01:02<00:09, 141.22it/s]Running 10000 simulations.:  87%|████████▋ | 8726/10000 [01:02<00:09, 141.51it/s]Running 10000 simulations.:  87%|████████▋ | 8741/10000 [01:02<00:08, 142.08it/s]Running 10000 simulations.:  88%|████████▊ | 8756/10000 [01:03<00:08, 142.31it/s]Running 10000 simulations.:  88%|████████▊ | 8771/10000 [01:03<00:08, 142.56it/s]Running 10000 simulations.:  88%|████████▊ | 8786/10000 [01:03<00:08, 142.57it/s]Running 10000 simulations.:  88%|████████▊ | 8801/10000 [01:03<00:08, 142.32it/s]Running 10000 simulations.:  88%|████████▊ | 8816/10000 [01:03<00:08, 142.01it/s]Running 10000 simulations.:  88%|████████▊ | 8831/10000 [01:03<00:08, 142.02it/s]Running 10000 simulations.:  88%|████████▊ | 8846/10000 [01:03<00:08, 142.05it/s]Running 10000 simulations.:  89%|████████▊ | 8861/10000 [01:03<00:07, 142.44it/s]Running 10000 simulations.:  89%|████████▉ | 8876/10000 [01:03<00:07, 142.20it/s]Running 10000 simulations.:  89%|████████▉ | 8891/10000 [01:04<00:07, 142.06it/s]Running 10000 simulations.:  89%|████████▉ | 8906/10000 [01:04<00:07, 141.57it/s]Running 10000 simulations.:  89%|████████▉ | 8921/10000 [01:04<00:07, 141.42it/s]Running 10000 simulations.:  89%|████████▉ | 8936/10000 [01:04<00:07, 140.95it/s]Running 10000 simulations.:  90%|████████▉ | 8951/10000 [01:04<00:07, 140.97it/s]Running 10000 simulations.:  90%|████████▉ | 8966/10000 [01:04<00:07, 141.24it/s]Running 10000 simulations.:  90%|████████▉ | 8981/10000 [01:04<00:07, 141.39it/s]Running 10000 simulations.:  90%|████████▉ | 8996/10000 [01:04<00:07, 141.72it/s]Running 10000 simulations.:  90%|█████████ | 9011/10000 [01:04<00:06, 141.69it/s]Running 10000 simulations.:  90%|█████████ | 9026/10000 [01:04<00:06, 141.60it/s]Running 10000 simulations.:  90%|█████████ | 9041/10000 [01:05<00:06, 141.83it/s]Running 10000 simulations.:  91%|█████████ | 9056/10000 [01:05<00:06, 142.19it/s]Running 10000 simulations.:  91%|█████████ | 9071/10000 [01:05<00:06, 142.13it/s]Running 10000 simulations.:  91%|█████████ | 9086/10000 [01:05<00:06, 141.99it/s]Running 10000 simulations.:  91%|█████████ | 9101/10000 [01:05<00:06, 142.24it/s]Running 10000 simulations.:  91%|█████████ | 9116/10000 [01:05<00:06, 142.17it/s]Running 10000 simulations.:  91%|█████████▏| 9131/10000 [01:05<00:06, 142.18it/s]Running 10000 simulations.:  91%|█████████▏| 9146/10000 [01:05<00:05, 142.49it/s]Running 10000 simulations.:  92%|█████████▏| 9161/10000 [01:05<00:05, 142.34it/s]Running 10000 simulations.:  92%|█████████▏| 9176/10000 [01:06<00:05, 142.09it/s]Running 10000 simulations.:  92%|█████████▏| 9191/10000 [01:06<00:05, 142.08it/s]Running 10000 simulations.:  92%|█████████▏| 9206/10000 [01:06<00:05, 142.27it/s]Running 10000 simulations.:  92%|█████████▏| 9221/10000 [01:06<00:05, 142.39it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [01:06<00:05, 142.23it/s]Running 10000 simulations.:  93%|█████████▎| 9251/10000 [01:06<00:05, 142.29it/s]Running 10000 simulations.:  93%|█████████▎| 9266/10000 [01:06<00:05, 142.05it/s]Running 10000 simulations.:  93%|█████████▎| 9281/10000 [01:06<00:05, 142.15it/s]Running 10000 simulations.:  93%|█████████▎| 9296/10000 [01:06<00:04, 142.02it/s]Running 10000 simulations.:  93%|█████████▎| 9311/10000 [01:06<00:04, 141.88it/s]Running 10000 simulations.:  93%|█████████▎| 9326/10000 [01:07<00:04, 141.62it/s]Running 10000 simulations.:  93%|█████████▎| 9341/10000 [01:07<00:04, 132.85it/s]Running 10000 simulations.:  94%|█████████▎| 9356/10000 [01:07<00:04, 135.76it/s]Running 10000 simulations.:  94%|█████████▎| 9371/10000 [01:07<00:04, 137.72it/s]Running 10000 simulations.:  94%|█████████▍| 9386/10000 [01:07<00:04, 139.14it/s]Running 10000 simulations.:  94%|█████████▍| 9401/10000 [01:07<00:04, 140.29it/s]Running 10000 simulations.:  94%|█████████▍| 9416/10000 [01:07<00:04, 140.84it/s]Running 10000 simulations.:  94%|█████████▍| 9431/10000 [01:07<00:04, 141.29it/s]Running 10000 simulations.:  94%|█████████▍| 9446/10000 [01:07<00:03, 141.05it/s]Running 10000 simulations.:  95%|█████████▍| 9461/10000 [01:08<00:03, 140.40it/s]Running 10000 simulations.:  95%|█████████▍| 9476/10000 [01:08<00:03, 140.50it/s]Running 10000 simulations.:  95%|█████████▍| 9491/10000 [01:08<00:03, 140.42it/s]Running 10000 simulations.:  95%|█████████▌| 9506/10000 [01:08<00:03, 140.19it/s]Running 10000 simulations.:  95%|█████████▌| 9521/10000 [01:08<00:03, 140.24it/s]Running 10000 simulations.:  95%|█████████▌| 9536/10000 [01:08<00:03, 140.38it/s]Running 10000 simulations.:  96%|█████████▌| 9551/10000 [01:08<00:03, 139.67it/s]Running 10000 simulations.:  96%|█████████▌| 9565/10000 [01:08<00:03, 139.27it/s]Running 10000 simulations.:  96%|█████████▌| 9580/10000 [01:08<00:03, 139.75it/s]Running 10000 simulations.:  96%|█████████▌| 9594/10000 [01:09<00:02, 139.80it/s]Running 10000 simulations.:  96%|█████████▌| 9608/10000 [01:09<00:02, 139.63it/s]Running 10000 simulations.:  96%|█████████▌| 9622/10000 [01:09<00:02, 139.61it/s]Running 10000 simulations.:  96%|█████████▋| 9637/10000 [01:09<00:02, 140.18it/s]Running 10000 simulations.:  97%|█████████▋| 9652/10000 [01:09<00:02, 141.03it/s]Running 10000 simulations.:  97%|█████████▋| 9667/10000 [01:09<00:02, 141.41it/s]Running 10000 simulations.:  97%|█████████▋| 9682/10000 [01:09<00:02, 141.46it/s]Running 10000 simulations.:  97%|█████████▋| 9697/10000 [01:09<00:02, 141.12it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [01:09<00:02, 140.17it/s]Running 10000 simulations.:  97%|█████████▋| 9727/10000 [01:09<00:01, 140.58it/s]Running 10000 simulations.:  97%|█████████▋| 9742/10000 [01:10<00:01, 140.98it/s]Running 10000 simulations.:  98%|█████████▊| 9757/10000 [01:10<00:01, 141.60it/s]Running 10000 simulations.:  98%|█████████▊| 9772/10000 [01:10<00:01, 141.52it/s]Running 10000 simulations.:  98%|█████████▊| 9787/10000 [01:10<00:01, 141.88it/s]Running 10000 simulations.:  98%|█████████▊| 9802/10000 [01:10<00:01, 142.14it/s]Running 10000 simulations.:  98%|█████████▊| 9817/10000 [01:10<00:01, 142.44it/s]Running 10000 simulations.:  98%|█████████▊| 9832/10000 [01:10<00:01, 142.93it/s]Running 10000 simulations.:  98%|█████████▊| 9847/10000 [01:10<00:01, 143.53it/s]Running 10000 simulations.:  99%|█████████▊| 9862/10000 [01:10<00:00, 143.29it/s]Running 10000 simulations.:  99%|█████████▉| 9877/10000 [01:11<00:00, 142.93it/s]Running 10000 simulations.:  99%|█████████▉| 9892/10000 [01:11<00:00, 142.73it/s]Running 10000 simulations.:  99%|█████████▉| 9907/10000 [01:11<00:00, 142.59it/s]Running 10000 simulations.:  99%|█████████▉| 9922/10000 [01:11<00:00, 142.74it/s]Running 10000 simulations.:  99%|█████████▉| 9937/10000 [01:11<00:00, 142.80it/s]Running 10000 simulations.: 100%|█████████▉| 9952/10000 [01:11<00:00, 142.79it/s]Running 10000 simulations.: 100%|█████████▉| 9967/10000 [01:11<00:00, 142.75it/s]Running 10000 simulations.: 100%|█████████▉| 9982/10000 [01:11<00:00, 143.10it/s]Running 10000 simulations.: 100%|█████████▉| 9997/10000 [01:11<00:00, 142.97it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:11<00:00, 139.11it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 16/10000 [00:00<01:06, 151.27it/s]Running 10000 simulations.:   0%|          | 32/10000 [00:00<01:05, 151.30it/s]Running 10000 simulations.:   0%|          | 48/10000 [00:00<01:05, 151.17it/s]Running 10000 simulations.:   1%|          | 64/10000 [00:00<01:05, 151.07it/s]Running 10000 simulations.:   1%|          | 80/10000 [00:00<01:05, 151.25it/s]Running 10000 simulations.:   1%|          | 96/10000 [00:00<01:05, 151.14it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<01:05, 150.82it/s]Running 10000 simulations.:   1%|▏         | 127/10000 [00:00<01:05, 150.57it/s]Running 10000 simulations.:   1%|▏         | 142/10000 [00:00<01:05, 150.32it/s]Running 10000 simulations.:   2%|▏         | 157/10000 [00:01<01:05, 149.74it/s]Running 10000 simulations.:   2%|▏         | 172/10000 [00:01<01:05, 149.41it/s]Running 10000 simulations.:   2%|▏         | 187/10000 [00:01<01:05, 148.86it/s]Running 10000 simulations.:   2%|▏         | 202/10000 [00:01<01:05, 148.53it/s]Running 10000 simulations.:   2%|▏         | 217/10000 [00:01<01:06, 148.09it/s]Running 10000 simulations.:   2%|▏         | 232/10000 [00:01<01:06, 147.71it/s]Running 10000 simulations.:   2%|▏         | 247/10000 [00:01<01:06, 147.49it/s]Running 10000 simulations.:   3%|▎         | 262/10000 [00:01<01:06, 147.34it/s]Running 10000 simulations.:   3%|▎         | 277/10000 [00:01<01:06, 147.24it/s]Running 10000 simulations.:   3%|▎         | 292/10000 [00:01<01:05, 147.44it/s]Running 10000 simulations.:   3%|▎         | 307/10000 [00:02<01:05, 147.14it/s]Running 10000 simulations.:   3%|▎         | 322/10000 [00:02<01:05, 146.77it/s]Running 10000 simulations.:   3%|▎         | 337/10000 [00:02<01:05, 146.43it/s]Running 10000 simulations.:   4%|▎         | 352/10000 [00:02<01:05, 146.26it/s]Running 10000 simulations.:   4%|▎         | 367/10000 [00:02<01:05, 146.10it/s]Running 10000 simulations.:   4%|▍         | 382/10000 [00:02<01:05, 145.98it/s]Running 10000 simulations.:   4%|▍         | 397/10000 [00:02<01:05, 146.04it/s]Running 10000 simulations.:   4%|▍         | 412/10000 [00:02<01:05, 146.18it/s]Running 10000 simulations.:   4%|▍         | 427/10000 [00:02<01:05, 146.02it/s]Running 10000 simulations.:   4%|▍         | 442/10000 [00:02<01:05, 146.07it/s]Running 10000 simulations.:   5%|▍         | 457/10000 [00:03<01:05, 146.08it/s]Running 10000 simulations.:   5%|▍         | 472/10000 [00:03<01:05, 145.92it/s]Running 10000 simulations.:   5%|▍         | 487/10000 [00:03<01:05, 145.84it/s]Running 10000 simulations.:   5%|▌         | 502/10000 [00:03<01:05, 145.83it/s]Running 10000 simulations.:   5%|▌         | 517/10000 [00:03<01:05, 145.77it/s]Running 10000 simulations.:   5%|▌         | 532/10000 [00:03<01:05, 145.59it/s]Running 10000 simulations.:   5%|▌         | 547/10000 [00:03<01:04, 145.47it/s]Running 10000 simulations.:   6%|▌         | 562/10000 [00:03<01:04, 145.56it/s]Running 10000 simulations.:   6%|▌         | 577/10000 [00:03<01:04, 145.45it/s]Running 10000 simulations.:   6%|▌         | 592/10000 [00:04<01:04, 145.39it/s]Running 10000 simulations.:   6%|▌         | 607/10000 [00:04<01:04, 145.60it/s]Running 10000 simulations.:   6%|▌         | 622/10000 [00:04<01:04, 146.10it/s]Running 10000 simulations.:   6%|▋         | 637/10000 [00:04<01:07, 137.76it/s]Running 10000 simulations.:   7%|▋         | 652/10000 [00:04<01:06, 139.73it/s]Running 10000 simulations.:   7%|▋         | 667/10000 [00:04<01:06, 141.38it/s]Running 10000 simulations.:   7%|▋         | 682/10000 [00:04<01:05, 142.79it/s]Running 10000 simulations.:   7%|▋         | 697/10000 [00:04<01:04, 144.09it/s]Running 10000 simulations.:   7%|▋         | 712/10000 [00:04<01:04, 144.25it/s]Running 10000 simulations.:   7%|▋         | 727/10000 [00:04<01:04, 144.83it/s]Running 10000 simulations.:   7%|▋         | 742/10000 [00:05<01:03, 145.25it/s]Running 10000 simulations.:   8%|▊         | 757/10000 [00:05<01:03, 145.11it/s]Running 10000 simulations.:   8%|▊         | 772/10000 [00:05<01:03, 144.94it/s]Running 10000 simulations.:   8%|▊         | 787/10000 [00:05<01:03, 145.24it/s]Running 10000 simulations.:   8%|▊         | 802/10000 [00:05<01:03, 145.80it/s]Running 10000 simulations.:   8%|▊         | 817/10000 [00:05<01:03, 145.46it/s]Running 10000 simulations.:   8%|▊         | 832/10000 [00:05<01:02, 145.59it/s]Running 10000 simulations.:   8%|▊         | 847/10000 [00:05<01:02, 146.06it/s]Running 10000 simulations.:   9%|▊         | 862/10000 [00:05<01:02, 145.52it/s]Running 10000 simulations.:   9%|▉         | 877/10000 [00:05<01:02, 145.45it/s]Running 10000 simulations.:   9%|▉         | 892/10000 [00:06<01:02, 145.49it/s]Running 10000 simulations.:   9%|▉         | 907/10000 [00:06<01:02, 145.27it/s]Running 10000 simulations.:   9%|▉         | 922/10000 [00:06<01:02, 145.28it/s]Running 10000 simulations.:   9%|▉         | 937/10000 [00:06<01:02, 145.08it/s]Running 10000 simulations.:  10%|▉         | 952/10000 [00:06<01:02, 145.14it/s]Running 10000 simulations.:  10%|▉         | 967/10000 [00:06<01:02, 144.91it/s]Running 10000 simulations.:  10%|▉         | 982/10000 [00:06<01:01, 145.54it/s]Running 10000 simulations.:  10%|▉         | 997/10000 [00:06<01:01, 145.99it/s]Running 10000 simulations.:  10%|█         | 1012/10000 [00:06<01:01, 146.28it/s]Running 10000 simulations.:  10%|█         | 1027/10000 [00:07<01:01, 146.52it/s]Running 10000 simulations.:  10%|█         | 1042/10000 [00:07<01:01, 146.62it/s]Running 10000 simulations.:  11%|█         | 1057/10000 [00:07<01:00, 147.08it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:07<01:00, 146.41it/s]Running 10000 simulations.:  11%|█         | 1087/10000 [00:07<01:00, 146.31it/s]Running 10000 simulations.:  11%|█         | 1102/10000 [00:07<01:00, 146.39it/s]Running 10000 simulations.:  11%|█         | 1117/10000 [00:07<01:00, 146.31it/s]Running 10000 simulations.:  11%|█▏        | 1132/10000 [00:07<01:00, 145.63it/s]Running 10000 simulations.:  11%|█▏        | 1147/10000 [00:07<01:00, 145.42it/s]Running 10000 simulations.:  12%|█▏        | 1162/10000 [00:07<01:00, 145.42it/s]Running 10000 simulations.:  12%|█▏        | 1177/10000 [00:08<01:00, 145.39it/s]Running 10000 simulations.:  12%|█▏        | 1192/10000 [00:08<01:00, 145.71it/s]Running 10000 simulations.:  12%|█▏        | 1207/10000 [00:08<01:00, 145.68it/s]Running 10000 simulations.:  12%|█▏        | 1222/10000 [00:08<01:00, 145.73it/s]Running 10000 simulations.:  12%|█▏        | 1237/10000 [00:08<01:00, 145.91it/s]Running 10000 simulations.:  13%|█▎        | 1252/10000 [00:08<00:59, 146.19it/s]Running 10000 simulations.:  13%|█▎        | 1267/10000 [00:08<00:59, 146.56it/s]Running 10000 simulations.:  13%|█▎        | 1282/10000 [00:08<00:59, 146.14it/s]Running 10000 simulations.:  13%|█▎        | 1297/10000 [00:08<00:59, 145.52it/s]Running 10000 simulations.:  13%|█▎        | 1312/10000 [00:08<00:59, 145.31it/s]Running 10000 simulations.:  13%|█▎        | 1327/10000 [00:09<00:59, 144.96it/s]Running 10000 simulations.:  13%|█▎        | 1342/10000 [00:09<00:59, 144.83it/s]Running 10000 simulations.:  14%|█▎        | 1357/10000 [00:09<00:59, 144.67it/s]Running 10000 simulations.:  14%|█▎        | 1372/10000 [00:09<00:59, 144.65it/s]Running 10000 simulations.:  14%|█▍        | 1387/10000 [00:09<00:59, 144.70it/s]Running 10000 simulations.:  14%|█▍        | 1402/10000 [00:09<00:59, 144.38it/s]Running 10000 simulations.:  14%|█▍        | 1417/10000 [00:09<00:59, 144.73it/s]Running 10000 simulations.:  14%|█▍        | 1432/10000 [00:09<00:59, 144.87it/s]Running 10000 simulations.:  14%|█▍        | 1447/10000 [00:09<00:59, 144.86it/s]Running 10000 simulations.:  15%|█▍        | 1462/10000 [00:10<00:59, 144.12it/s]Running 10000 simulations.:  15%|█▍        | 1477/10000 [00:10<00:59, 143.87it/s]Running 10000 simulations.:  15%|█▍        | 1492/10000 [00:10<00:59, 144.03it/s]Running 10000 simulations.:  15%|█▌        | 1507/10000 [00:10<00:58, 144.19it/s]Running 10000 simulations.:  15%|█▌        | 1522/10000 [00:10<00:58, 144.23it/s]Running 10000 simulations.:  15%|█▌        | 1537/10000 [00:10<00:58, 144.45it/s]Running 10000 simulations.:  16%|█▌        | 1552/10000 [00:10<00:58, 144.57it/s]Running 10000 simulations.:  16%|█▌        | 1567/10000 [00:10<00:58, 144.83it/s]Running 10000 simulations.:  16%|█▌        | 1582/10000 [00:10<00:58, 144.64it/s]Running 10000 simulations.:  16%|█▌        | 1597/10000 [00:10<00:58, 144.74it/s]Running 10000 simulations.:  16%|█▌        | 1612/10000 [00:11<00:57, 144.73it/s]Running 10000 simulations.:  16%|█▋        | 1627/10000 [00:11<00:57, 144.72it/s]Running 10000 simulations.:  16%|█▋        | 1642/10000 [00:11<00:57, 144.73it/s]Running 10000 simulations.:  17%|█▋        | 1657/10000 [00:11<00:57, 144.76it/s]Running 10000 simulations.:  17%|█▋        | 1672/10000 [00:11<00:57, 144.87it/s]Running 10000 simulations.:  17%|█▋        | 1687/10000 [00:11<00:57, 144.99it/s]Running 10000 simulations.:  17%|█▋        | 1702/10000 [00:11<00:57, 145.08it/s]Running 10000 simulations.:  17%|█▋        | 1717/10000 [00:11<00:57, 145.08it/s]Running 10000 simulations.:  17%|█▋        | 1732/10000 [00:11<00:57, 144.66it/s]Running 10000 simulations.:  17%|█▋        | 1747/10000 [00:11<00:57, 144.79it/s]Running 10000 simulations.:  18%|█▊        | 1762/10000 [00:12<00:56, 144.93it/s]Running 10000 simulations.:  18%|█▊        | 1777/10000 [00:12<00:56, 144.84it/s]Running 10000 simulations.:  18%|█▊        | 1792/10000 [00:12<00:56, 144.80it/s]Running 10000 simulations.:  18%|█▊        | 1807/10000 [00:12<00:56, 144.64it/s]Running 10000 simulations.:  18%|█▊        | 1822/10000 [00:12<00:56, 144.63it/s]Running 10000 simulations.:  18%|█▊        | 1837/10000 [00:12<00:56, 144.27it/s]Running 10000 simulations.:  19%|█▊        | 1852/10000 [00:12<00:56, 143.89it/s]Running 10000 simulations.:  19%|█▊        | 1867/10000 [00:12<00:56, 143.87it/s]Running 10000 simulations.:  19%|█▉        | 1882/10000 [00:12<00:56, 144.51it/s]Running 10000 simulations.:  19%|█▉        | 1897/10000 [00:13<00:56, 144.63it/s]Running 10000 simulations.:  19%|█▉        | 1912/10000 [00:13<00:55, 144.43it/s]Running 10000 simulations.:  19%|█▉        | 1927/10000 [00:13<00:55, 144.47it/s]Running 10000 simulations.:  19%|█▉        | 1942/10000 [00:13<00:55, 144.50it/s]Running 10000 simulations.:  20%|█▉        | 1957/10000 [00:13<00:55, 144.43it/s]Running 10000 simulations.:  20%|█▉        | 1972/10000 [00:13<00:55, 144.53it/s]Running 10000 simulations.:  20%|█▉        | 1987/10000 [00:13<00:55, 144.31it/s]Running 10000 simulations.:  20%|██        | 2002/10000 [00:13<00:55, 144.03it/s]Running 10000 simulations.:  20%|██        | 2017/10000 [00:13<00:55, 143.93it/s]Running 10000 simulations.:  20%|██        | 2032/10000 [00:13<00:55, 144.08it/s]Running 10000 simulations.:  20%|██        | 2047/10000 [00:14<00:55, 144.01it/s]Running 10000 simulations.:  21%|██        | 2062/10000 [00:14<00:55, 143.89it/s]Running 10000 simulations.:  21%|██        | 2077/10000 [00:14<00:55, 143.63it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:14<00:54, 143.92it/s]Running 10000 simulations.:  21%|██        | 2107/10000 [00:14<00:54, 143.77it/s]Running 10000 simulations.:  21%|██        | 2122/10000 [00:14<00:54, 143.59it/s]Running 10000 simulations.:  21%|██▏       | 2137/10000 [00:14<00:54, 144.12it/s]Running 10000 simulations.:  22%|██▏       | 2152/10000 [00:14<00:54, 144.39it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:14<00:54, 144.59it/s]Running 10000 simulations.:  22%|██▏       | 2182/10000 [00:14<00:54, 144.73it/s]Running 10000 simulations.:  22%|██▏       | 2197/10000 [00:15<00:53, 144.70it/s]Running 10000 simulations.:  22%|██▏       | 2212/10000 [00:15<00:53, 144.51it/s]Running 10000 simulations.:  22%|██▏       | 2227/10000 [00:15<00:54, 143.92it/s]Running 10000 simulations.:  22%|██▏       | 2242/10000 [00:15<00:54, 143.53it/s]Running 10000 simulations.:  23%|██▎       | 2257/10000 [00:15<00:53, 143.60it/s]Running 10000 simulations.:  23%|██▎       | 2272/10000 [00:15<00:53, 143.32it/s]Running 10000 simulations.:  23%|██▎       | 2287/10000 [00:15<00:53, 143.03it/s]Running 10000 simulations.:  23%|██▎       | 2302/10000 [00:15<00:53, 143.02it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:15<00:53, 143.20it/s]Running 10000 simulations.:  23%|██▎       | 2332/10000 [00:16<00:53, 143.10it/s]Running 10000 simulations.:  23%|██▎       | 2347/10000 [00:16<00:53, 143.08it/s]Running 10000 simulations.:  24%|██▎       | 2362/10000 [00:16<00:53, 143.48it/s]Running 10000 simulations.:  24%|██▍       | 2377/10000 [00:16<00:53, 143.83it/s]Running 10000 simulations.:  24%|██▍       | 2392/10000 [00:16<00:52, 143.76it/s]Running 10000 simulations.:  24%|██▍       | 2407/10000 [00:16<00:52, 143.78it/s]Running 10000 simulations.:  24%|██▍       | 2422/10000 [00:16<00:52, 144.16it/s]Running 10000 simulations.:  24%|██▍       | 2437/10000 [00:16<00:52, 144.44it/s]Running 10000 simulations.:  25%|██▍       | 2452/10000 [00:16<00:52, 144.61it/s]Running 10000 simulations.:  25%|██▍       | 2467/10000 [00:16<00:52, 144.47it/s]Running 10000 simulations.:  25%|██▍       | 2482/10000 [00:17<00:52, 144.17it/s]Running 10000 simulations.:  25%|██▍       | 2497/10000 [00:17<00:52, 144.02it/s]Running 10000 simulations.:  25%|██▌       | 2512/10000 [00:17<00:52, 143.74it/s]Running 10000 simulations.:  25%|██▌       | 2527/10000 [00:17<00:52, 143.43it/s]Running 10000 simulations.:  25%|██▌       | 2542/10000 [00:17<00:51, 143.61it/s]Running 10000 simulations.:  26%|██▌       | 2557/10000 [00:17<00:51, 143.48it/s]Running 10000 simulations.:  26%|██▌       | 2572/10000 [00:17<00:51, 143.54it/s]Running 10000 simulations.:  26%|██▌       | 2587/10000 [00:17<00:51, 143.46it/s]Running 10000 simulations.:  26%|██▌       | 2602/10000 [00:17<00:51, 143.29it/s]Running 10000 simulations.:  26%|██▌       | 2617/10000 [00:18<00:51, 143.15it/s]Running 10000 simulations.:  26%|██▋       | 2632/10000 [00:18<00:51, 143.07it/s]Running 10000 simulations.:  26%|██▋       | 2647/10000 [00:18<00:51, 143.34it/s]Running 10000 simulations.:  27%|██▋       | 2662/10000 [00:18<00:51, 143.42it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:18<00:50, 143.69it/s]Running 10000 simulations.:  27%|██▋       | 2692/10000 [00:18<00:50, 143.82it/s]Running 10000 simulations.:  27%|██▋       | 2707/10000 [00:18<00:50, 143.71it/s]Running 10000 simulations.:  27%|██▋       | 2722/10000 [00:18<00:50, 142.76it/s]Running 10000 simulations.:  27%|██▋       | 2737/10000 [00:18<00:50, 142.73it/s]Running 10000 simulations.:  28%|██▊       | 2752/10000 [00:18<00:50, 143.11it/s]Running 10000 simulations.:  28%|██▊       | 2767/10000 [00:19<00:50, 143.43it/s]Running 10000 simulations.:  28%|██▊       | 2782/10000 [00:19<00:50, 143.26it/s]Running 10000 simulations.:  28%|██▊       | 2797/10000 [00:19<00:50, 143.41it/s]Running 10000 simulations.:  28%|██▊       | 2812/10000 [00:19<00:50, 143.24it/s]Running 10000 simulations.:  28%|██▊       | 2827/10000 [00:19<00:50, 143.11it/s]Running 10000 simulations.:  28%|██▊       | 2842/10000 [00:19<00:50, 143.15it/s]Running 10000 simulations.:  29%|██▊       | 2857/10000 [00:19<00:49, 143.06it/s]Running 10000 simulations.:  29%|██▊       | 2872/10000 [00:19<00:49, 143.07it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:19<00:49, 143.20it/s]Running 10000 simulations.:  29%|██▉       | 2902/10000 [00:20<00:49, 143.26it/s]Running 10000 simulations.:  29%|██▉       | 2919/10000 [00:20<00:47, 148.11it/s]Running 10000 simulations.:  29%|██▉       | 2935/10000 [00:20<00:47, 149.97it/s]Running 10000 simulations.:  30%|██▉       | 2951/10000 [00:20<00:47, 148.30it/s]Running 10000 simulations.:  30%|██▉       | 2966/10000 [00:20<00:47, 146.87it/s]Running 10000 simulations.:  30%|██▉       | 2981/10000 [00:20<00:48, 145.70it/s]Running 10000 simulations.:  30%|██▉       | 2996/10000 [00:20<00:48, 145.19it/s]Running 10000 simulations.:  30%|███       | 3011/10000 [00:20<00:48, 144.45it/s]Running 10000 simulations.:  30%|███       | 3026/10000 [00:20<00:48, 144.05it/s]Running 10000 simulations.:  30%|███       | 3041/10000 [00:20<00:48, 144.05it/s]Running 10000 simulations.:  31%|███       | 3056/10000 [00:21<00:49, 141.53it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:21<00:48, 141.98it/s]Running 10000 simulations.:  31%|███       | 3086/10000 [00:21<00:48, 141.55it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:21<00:48, 141.82it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:21<00:48, 142.28it/s]Running 10000 simulations.:  31%|███▏      | 3131/10000 [00:21<00:48, 142.47it/s]Running 10000 simulations.:  31%|███▏      | 3146/10000 [00:21<00:48, 142.62it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:21<00:47, 142.90it/s]Running 10000 simulations.:  32%|███▏      | 3176/10000 [00:21<00:47, 143.00it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:22<00:47, 142.89it/s]Running 10000 simulations.:  32%|███▏      | 3206/10000 [00:22<00:47, 143.22it/s]Running 10000 simulations.:  32%|███▏      | 3221/10000 [00:22<00:47, 143.24it/s]Running 10000 simulations.:  32%|███▏      | 3236/10000 [00:22<00:47, 143.90it/s]Running 10000 simulations.:  33%|███▎      | 3251/10000 [00:22<00:46, 143.84it/s]Running 10000 simulations.:  33%|███▎      | 3266/10000 [00:22<00:46, 143.94it/s]Running 10000 simulations.:  33%|███▎      | 3281/10000 [00:22<00:46, 143.93it/s]Running 10000 simulations.:  33%|███▎      | 3296/10000 [00:22<00:46, 143.69it/s]Running 10000 simulations.:  33%|███▎      | 3311/10000 [00:22<00:46, 143.75it/s]Running 10000 simulations.:  33%|███▎      | 3326/10000 [00:22<00:46, 143.68it/s]Running 10000 simulations.:  33%|███▎      | 3341/10000 [00:23<00:46, 143.44it/s]Running 10000 simulations.:  34%|███▎      | 3356/10000 [00:23<00:46, 143.29it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:23<00:46, 142.31it/s]Running 10000 simulations.:  34%|███▍      | 3386/10000 [00:23<00:46, 142.91it/s]Running 10000 simulations.:  34%|███▍      | 3401/10000 [00:23<00:45, 143.61it/s]Running 10000 simulations.:  34%|███▍      | 3416/10000 [00:23<00:45, 143.96it/s]Running 10000 simulations.:  34%|███▍      | 3431/10000 [00:23<00:45, 144.32it/s]Running 10000 simulations.:  34%|███▍      | 3446/10000 [00:23<00:45, 144.85it/s]Running 10000 simulations.:  35%|███▍      | 3461/10000 [00:23<00:45, 144.93it/s]Running 10000 simulations.:  35%|███▍      | 3476/10000 [00:24<00:45, 144.79it/s]Running 10000 simulations.:  35%|███▍      | 3491/10000 [00:24<00:45, 144.58it/s]Running 10000 simulations.:  35%|███▌      | 3506/10000 [00:24<00:44, 144.73it/s]Running 10000 simulations.:  35%|███▌      | 3521/10000 [00:24<00:44, 145.14it/s]Running 10000 simulations.:  35%|███▌      | 3536/10000 [00:24<00:44, 145.53it/s]Running 10000 simulations.:  36%|███▌      | 3551/10000 [00:24<00:44, 145.83it/s]Running 10000 simulations.:  36%|███▌      | 3566/10000 [00:24<00:44, 145.87it/s]Running 10000 simulations.:  36%|███▌      | 3581/10000 [00:24<00:44, 145.36it/s]Running 10000 simulations.:  36%|███▌      | 3596/10000 [00:24<00:44, 144.85it/s]Running 10000 simulations.:  36%|███▌      | 3611/10000 [00:24<00:44, 144.85it/s]Running 10000 simulations.:  36%|███▋      | 3626/10000 [00:25<00:44, 144.73it/s]Running 10000 simulations.:  36%|███▋      | 3641/10000 [00:25<00:43, 144.85it/s]Running 10000 simulations.:  37%|███▋      | 3656/10000 [00:25<00:43, 144.70it/s]Running 10000 simulations.:  37%|███▋      | 3671/10000 [00:25<00:43, 144.73it/s]Running 10000 simulations.:  37%|███▋      | 3686/10000 [00:25<00:43, 144.99it/s]Running 10000 simulations.:  37%|███▋      | 3701/10000 [00:25<00:43, 145.09it/s]Running 10000 simulations.:  37%|███▋      | 3716/10000 [00:25<00:43, 144.82it/s]Running 10000 simulations.:  37%|███▋      | 3731/10000 [00:25<00:43, 144.31it/s]Running 10000 simulations.:  37%|███▋      | 3746/10000 [00:25<00:43, 144.15it/s]Running 10000 simulations.:  38%|███▊      | 3761/10000 [00:25<00:43, 144.35it/s]Running 10000 simulations.:  38%|███▊      | 3776/10000 [00:26<00:43, 144.36it/s]Running 10000 simulations.:  38%|███▊      | 3791/10000 [00:26<00:42, 144.46it/s]Running 10000 simulations.:  38%|███▊      | 3806/10000 [00:26<00:42, 144.30it/s]Running 10000 simulations.:  38%|███▊      | 3821/10000 [00:26<00:42, 144.09it/s]Running 10000 simulations.:  38%|███▊      | 3836/10000 [00:26<00:42, 143.65it/s]Running 10000 simulations.:  39%|███▊      | 3851/10000 [00:26<00:42, 144.11it/s]Running 10000 simulations.:  39%|███▊      | 3866/10000 [00:26<00:42, 143.68it/s]Running 10000 simulations.:  39%|███▉      | 3881/10000 [00:26<00:42, 144.10it/s]Running 10000 simulations.:  39%|███▉      | 3896/10000 [00:26<00:42, 144.34it/s]Running 10000 simulations.:  39%|███▉      | 3911/10000 [00:27<00:42, 144.85it/s]Running 10000 simulations.:  39%|███▉      | 3926/10000 [00:27<00:41, 144.73it/s]Running 10000 simulations.:  39%|███▉      | 3941/10000 [00:27<00:41, 144.51it/s]Running 10000 simulations.:  40%|███▉      | 3956/10000 [00:27<00:41, 144.11it/s]Running 10000 simulations.:  40%|███▉      | 3971/10000 [00:27<00:41, 143.75it/s]Running 10000 simulations.:  40%|███▉      | 3986/10000 [00:27<00:41, 144.13it/s]Running 10000 simulations.:  40%|████      | 4001/10000 [00:27<00:41, 144.21it/s]Running 10000 simulations.:  40%|████      | 4016/10000 [00:27<00:41, 143.81it/s]Running 10000 simulations.:  40%|████      | 4031/10000 [00:27<00:41, 143.56it/s]Running 10000 simulations.:  40%|████      | 4046/10000 [00:27<00:41, 143.97it/s]Running 10000 simulations.:  41%|████      | 4061/10000 [00:28<00:41, 144.20it/s]Running 10000 simulations.:  41%|████      | 4076/10000 [00:28<00:41, 144.48it/s]Running 10000 simulations.:  41%|████      | 4091/10000 [00:28<00:40, 144.97it/s]Running 10000 simulations.:  41%|████      | 4106/10000 [00:28<00:40, 145.16it/s]Running 10000 simulations.:  41%|████      | 4121/10000 [00:28<00:40, 145.09it/s]Running 10000 simulations.:  41%|████▏     | 4136/10000 [00:28<00:40, 145.23it/s]Running 10000 simulations.:  42%|████▏     | 4151/10000 [00:28<00:40, 144.79it/s]Running 10000 simulations.:  42%|████▏     | 4166/10000 [00:28<00:40, 144.63it/s]Running 10000 simulations.:  42%|████▏     | 4181/10000 [00:28<00:40, 144.57it/s]Running 10000 simulations.:  42%|████▏     | 4196/10000 [00:28<00:40, 144.48it/s]Running 10000 simulations.:  42%|████▏     | 4211/10000 [00:29<00:40, 144.65it/s]Running 10000 simulations.:  42%|████▏     | 4226/10000 [00:29<00:39, 144.60it/s]Running 10000 simulations.:  42%|████▏     | 4241/10000 [00:29<00:39, 145.22it/s]Running 10000 simulations.:  43%|████▎     | 4256/10000 [00:29<00:39, 144.89it/s]Running 10000 simulations.:  43%|████▎     | 4271/10000 [00:29<00:39, 145.22it/s]Running 10000 simulations.:  43%|████▎     | 4286/10000 [00:29<00:39, 144.80it/s]Running 10000 simulations.:  43%|████▎     | 4301/10000 [00:29<00:39, 144.32it/s]Running 10000 simulations.:  43%|████▎     | 4316/10000 [00:29<00:39, 144.20it/s]Running 10000 simulations.:  43%|████▎     | 4331/10000 [00:29<00:39, 144.58it/s]Running 10000 simulations.:  43%|████▎     | 4346/10000 [00:30<00:39, 144.63it/s]Running 10000 simulations.:  44%|████▎     | 4361/10000 [00:30<00:39, 144.02it/s]Running 10000 simulations.:  44%|████▍     | 4376/10000 [00:30<00:39, 143.98it/s]Running 10000 simulations.:  44%|████▍     | 4391/10000 [00:30<00:38, 143.86it/s]Running 10000 simulations.:  44%|████▍     | 4406/10000 [00:30<00:38, 143.80it/s]Running 10000 simulations.:  44%|████▍     | 4421/10000 [00:30<00:38, 143.95it/s]Running 10000 simulations.:  44%|████▍     | 4436/10000 [00:30<00:38, 144.07it/s]Running 10000 simulations.:  45%|████▍     | 4451/10000 [00:30<00:38, 144.47it/s]Running 10000 simulations.:  45%|████▍     | 4466/10000 [00:30<00:38, 144.47it/s]Running 10000 simulations.:  45%|████▍     | 4481/10000 [00:30<00:38, 144.28it/s]Running 10000 simulations.:  45%|████▍     | 4496/10000 [00:31<00:38, 144.54it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:31<00:37, 144.59it/s]Running 10000 simulations.:  45%|████▌     | 4526/10000 [00:31<00:37, 144.66it/s]Running 10000 simulations.:  45%|████▌     | 4541/10000 [00:31<00:37, 144.56it/s]Running 10000 simulations.:  46%|████▌     | 4556/10000 [00:31<00:37, 144.39it/s]Running 10000 simulations.:  46%|████▌     | 4571/10000 [00:31<00:37, 144.79it/s]Running 10000 simulations.:  46%|████▌     | 4586/10000 [00:31<00:37, 145.26it/s]Running 10000 simulations.:  46%|████▌     | 4601/10000 [00:31<00:37, 145.37it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:31<00:37, 145.01it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:31<00:37, 144.68it/s]Running 10000 simulations.:  46%|████▋     | 4646/10000 [00:32<00:37, 144.64it/s]Running 10000 simulations.:  47%|████▋     | 4661/10000 [00:32<00:36, 144.74it/s]Running 10000 simulations.:  47%|████▋     | 4676/10000 [00:32<00:36, 144.31it/s]Running 10000 simulations.:  47%|████▋     | 4691/10000 [00:32<00:36, 144.47it/s]Running 10000 simulations.:  47%|████▋     | 4706/10000 [00:32<00:36, 144.03it/s]Running 10000 simulations.:  47%|████▋     | 4721/10000 [00:32<00:36, 143.48it/s]Running 10000 simulations.:  47%|████▋     | 4736/10000 [00:32<00:36, 143.91it/s]Running 10000 simulations.:  48%|████▊     | 4751/10000 [00:32<00:36, 142.79it/s]Running 10000 simulations.:  48%|████▊     | 4766/10000 [00:32<00:36, 141.93it/s]Running 10000 simulations.:  48%|████▊     | 4781/10000 [00:33<00:37, 140.27it/s]Running 10000 simulations.:  48%|████▊     | 4796/10000 [00:33<00:36, 141.71it/s]Running 10000 simulations.:  48%|████▊     | 4811/10000 [00:33<00:36, 142.79it/s]Running 10000 simulations.:  48%|████▊     | 4826/10000 [00:33<00:36, 143.65it/s]Running 10000 simulations.:  48%|████▊     | 4841/10000 [00:33<00:36, 142.54it/s]Running 10000 simulations.:  49%|████▊     | 4856/10000 [00:33<00:35, 142.98it/s]Running 10000 simulations.:  49%|████▊     | 4871/10000 [00:33<00:35, 143.85it/s]Running 10000 simulations.:  49%|████▉     | 4886/10000 [00:33<00:35, 145.17it/s]Running 10000 simulations.:  49%|████▉     | 4901/10000 [00:33<00:34, 145.76it/s]Running 10000 simulations.:  49%|████▉     | 4916/10000 [00:33<00:34, 146.58it/s]Running 10000 simulations.:  49%|████▉     | 4931/10000 [00:34<00:34, 146.50it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:34<00:34, 147.09it/s]Running 10000 simulations.:  50%|████▉     | 4961/10000 [00:34<00:34, 147.01it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:34<00:36, 138.91it/s]Running 10000 simulations.:  50%|████▉     | 4991/10000 [00:34<00:35, 140.77it/s]Running 10000 simulations.:  50%|█████     | 5006/10000 [00:34<00:34, 142.81it/s]Running 10000 simulations.:  50%|█████     | 5021/10000 [00:34<00:34, 144.16it/s]Running 10000 simulations.:  50%|█████     | 5036/10000 [00:34<00:34, 144.67it/s]Running 10000 simulations.:  51%|█████     | 5051/10000 [00:34<00:34, 145.50it/s]Running 10000 simulations.:  51%|█████     | 5066/10000 [00:35<00:33, 146.53it/s]Running 10000 simulations.:  51%|█████     | 5081/10000 [00:35<00:33, 146.50it/s]Running 10000 simulations.:  51%|█████     | 5096/10000 [00:35<00:33, 147.18it/s]Running 10000 simulations.:  51%|█████     | 5111/10000 [00:35<00:33, 147.86it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:35<00:33, 147.68it/s]Running 10000 simulations.:  51%|█████▏    | 5141/10000 [00:35<00:33, 147.23it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:35<00:32, 146.85it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:35<00:32, 147.01it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:35<00:32, 147.22it/s]Running 10000 simulations.:  52%|█████▏    | 5201/10000 [00:35<00:32, 147.02it/s]Running 10000 simulations.:  52%|█████▏    | 5216/10000 [00:36<00:32, 146.77it/s]Running 10000 simulations.:  52%|█████▏    | 5231/10000 [00:36<00:32, 146.61it/s]Running 10000 simulations.:  52%|█████▏    | 5246/10000 [00:36<00:32, 146.43it/s]Running 10000 simulations.:  53%|█████▎    | 5261/10000 [00:36<00:32, 146.72it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:36<00:32, 146.86it/s]Running 10000 simulations.:  53%|█████▎    | 5291/10000 [00:36<00:32, 146.74it/s]Running 10000 simulations.:  53%|█████▎    | 5306/10000 [00:36<00:31, 147.15it/s]Running 10000 simulations.:  53%|█████▎    | 5321/10000 [00:36<00:31, 147.91it/s]Running 10000 simulations.:  53%|█████▎    | 5336/10000 [00:36<00:31, 147.95it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:36<00:31, 147.69it/s]Running 10000 simulations.:  54%|█████▎    | 5366/10000 [00:37<00:31, 147.23it/s]Running 10000 simulations.:  54%|█████▍    | 5381/10000 [00:37<00:31, 147.08it/s]Running 10000 simulations.:  54%|█████▍    | 5396/10000 [00:37<00:31, 146.74it/s]Running 10000 simulations.:  54%|█████▍    | 5411/10000 [00:37<00:31, 146.47it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:37<00:31, 146.96it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:37<00:30, 147.54it/s]Running 10000 simulations.:  55%|█████▍    | 5456/10000 [00:37<00:30, 147.96it/s]Running 10000 simulations.:  55%|█████▍    | 5471/10000 [00:37<00:30, 148.41it/s]Running 10000 simulations.:  55%|█████▍    | 5486/10000 [00:37<00:30, 147.89it/s]Running 10000 simulations.:  55%|█████▌    | 5501/10000 [00:37<00:30, 147.09it/s]Running 10000 simulations.:  55%|█████▌    | 5516/10000 [00:38<00:30, 146.82it/s]Running 10000 simulations.:  55%|█████▌    | 5531/10000 [00:38<00:30, 146.56it/s]Running 10000 simulations.:  55%|█████▌    | 5546/10000 [00:38<00:30, 146.64it/s]Running 10000 simulations.:  56%|█████▌    | 5561/10000 [00:38<00:30, 146.98it/s]Running 10000 simulations.:  56%|█████▌    | 5576/10000 [00:38<00:30, 147.05it/s]Running 10000 simulations.:  56%|█████▌    | 5591/10000 [00:38<00:29, 147.08it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:38<00:29, 147.23it/s]Running 10000 simulations.:  56%|█████▌    | 5621/10000 [00:38<00:29, 147.19it/s]Running 10000 simulations.:  56%|█████▋    | 5636/10000 [00:38<00:29, 147.17it/s]Running 10000 simulations.:  57%|█████▋    | 5651/10000 [00:38<00:29, 147.73it/s]Running 10000 simulations.:  57%|█████▋    | 5666/10000 [00:39<00:29, 147.35it/s]Running 10000 simulations.:  57%|█████▋    | 5681/10000 [00:39<00:29, 147.93it/s]Running 10000 simulations.:  57%|█████▋    | 5696/10000 [00:39<00:29, 147.77it/s]Running 10000 simulations.:  57%|█████▋    | 5711/10000 [00:39<00:29, 147.60it/s]Running 10000 simulations.:  57%|█████▋    | 5726/10000 [00:39<00:28, 147.69it/s]Running 10000 simulations.:  57%|█████▋    | 5741/10000 [00:39<00:28, 148.14it/s]Running 10000 simulations.:  58%|█████▊    | 5756/10000 [00:39<00:28, 148.54it/s]Running 10000 simulations.:  58%|█████▊    | 5771/10000 [00:39<00:28, 148.90it/s]Running 10000 simulations.:  58%|█████▊    | 5786/10000 [00:39<00:28, 148.78it/s]Running 10000 simulations.:  58%|█████▊    | 5801/10000 [00:39<00:28, 148.72it/s]Running 10000 simulations.:  58%|█████▊    | 5816/10000 [00:40<00:28, 148.54it/s]Running 10000 simulations.:  58%|█████▊    | 5831/10000 [00:40<00:28, 148.18it/s]Running 10000 simulations.:  58%|█████▊    | 5846/10000 [00:40<00:28, 148.22it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:40<00:27, 148.23it/s]Running 10000 simulations.:  59%|█████▉    | 5877/10000 [00:40<00:27, 150.37it/s]Running 10000 simulations.:  59%|█████▉    | 5894/10000 [00:40<00:26, 154.53it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:40<00:26, 152.60it/s]Running 10000 simulations.:  59%|█████▉    | 5926/10000 [00:40<00:27, 150.61it/s]Running 10000 simulations.:  59%|█████▉    | 5942/10000 [00:40<00:27, 148.93it/s]Running 10000 simulations.:  60%|█████▉    | 5957/10000 [00:41<00:27, 147.75it/s]Running 10000 simulations.:  60%|█████▉    | 5972/10000 [00:41<00:27, 147.27it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:41<00:27, 146.98it/s]Running 10000 simulations.:  60%|██████    | 6002/10000 [00:41<00:27, 146.61it/s]Running 10000 simulations.:  60%|██████    | 6017/10000 [00:41<00:27, 146.45it/s]Running 10000 simulations.:  60%|██████    | 6032/10000 [00:41<00:27, 146.33it/s]Running 10000 simulations.:  60%|██████    | 6047/10000 [00:41<00:27, 146.39it/s]Running 10000 simulations.:  61%|██████    | 6062/10000 [00:41<00:26, 146.02it/s]Running 10000 simulations.:  61%|██████    | 6077/10000 [00:41<00:26, 145.87it/s]Running 10000 simulations.:  61%|██████    | 6092/10000 [00:41<00:26, 145.82it/s]Running 10000 simulations.:  61%|██████    | 6107/10000 [00:42<00:26, 146.42it/s]Running 10000 simulations.:  61%|██████    | 6122/10000 [00:42<00:26, 146.19it/s]Running 10000 simulations.:  61%|██████▏   | 6137/10000 [00:42<00:26, 146.98it/s]Running 10000 simulations.:  62%|██████▏   | 6153/10000 [00:42<00:25, 148.23it/s]Running 10000 simulations.:  62%|██████▏   | 6169/10000 [00:42<00:25, 149.45it/s]Running 10000 simulations.:  62%|██████▏   | 6185/10000 [00:42<00:25, 149.97it/s]Running 10000 simulations.:  62%|██████▏   | 6201/10000 [00:42<00:25, 150.68it/s]Running 10000 simulations.:  62%|██████▏   | 6217/10000 [00:42<00:25, 150.92it/s]Running 10000 simulations.:  62%|██████▏   | 6233/10000 [00:42<00:24, 151.12it/s]Running 10000 simulations.:  62%|██████▏   | 6249/10000 [00:43<00:24, 150.97it/s]Running 10000 simulations.:  63%|██████▎   | 6265/10000 [00:43<00:24, 151.48it/s]Running 10000 simulations.:  63%|██████▎   | 6281/10000 [00:43<00:24, 151.55it/s]Running 10000 simulations.:  63%|██████▎   | 6297/10000 [00:43<00:24, 151.55it/s]Running 10000 simulations.:  63%|██████▎   | 6313/10000 [00:43<00:24, 151.95it/s]Running 10000 simulations.:  63%|██████▎   | 6329/10000 [00:43<00:24, 152.05it/s]Running 10000 simulations.:  63%|██████▎   | 6345/10000 [00:43<00:24, 152.27it/s]Running 10000 simulations.:  64%|██████▎   | 6361/10000 [00:43<00:24, 151.60it/s]Running 10000 simulations.:  64%|██████▍   | 6377/10000 [00:43<00:23, 151.39it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:43<00:23, 151.42it/s]Running 10000 simulations.:  64%|██████▍   | 6409/10000 [00:44<00:23, 151.65it/s]Running 10000 simulations.:  64%|██████▍   | 6425/10000 [00:44<00:23, 152.02it/s]Running 10000 simulations.:  64%|██████▍   | 6441/10000 [00:44<00:23, 152.58it/s]Running 10000 simulations.:  65%|██████▍   | 6457/10000 [00:44<00:23, 152.29it/s]Running 10000 simulations.:  65%|██████▍   | 6473/10000 [00:44<00:23, 152.47it/s]Running 10000 simulations.:  65%|██████▍   | 6489/10000 [00:44<00:23, 150.81it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:44<00:23, 151.27it/s]Running 10000 simulations.:  65%|██████▌   | 6521/10000 [00:44<00:23, 150.73it/s]Running 10000 simulations.:  65%|██████▌   | 6537/10000 [00:44<00:22, 151.40it/s]Running 10000 simulations.:  66%|██████▌   | 6553/10000 [00:45<00:22, 152.39it/s]Running 10000 simulations.:  66%|██████▌   | 6569/10000 [00:45<00:22, 152.78it/s]Running 10000 simulations.:  66%|██████▌   | 6585/10000 [00:45<00:22, 150.44it/s]Running 10000 simulations.:  66%|██████▌   | 6601/10000 [00:45<00:22, 150.71it/s]Running 10000 simulations.:  66%|██████▌   | 6617/10000 [00:45<00:22, 150.81it/s]Running 10000 simulations.:  66%|██████▋   | 6633/10000 [00:45<00:22, 151.22it/s]Running 10000 simulations.:  66%|██████▋   | 6649/10000 [00:45<00:22, 151.70it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:45<00:21, 152.22it/s]Running 10000 simulations.:  67%|██████▋   | 6681/10000 [00:45<00:21, 151.78it/s]Running 10000 simulations.:  67%|██████▋   | 6697/10000 [00:45<00:21, 150.91it/s]Running 10000 simulations.:  67%|██████▋   | 6713/10000 [00:46<00:21, 150.91it/s]Running 10000 simulations.:  67%|██████▋   | 6729/10000 [00:46<00:21, 151.28it/s]Running 10000 simulations.:  67%|██████▋   | 6745/10000 [00:46<00:21, 151.79it/s]Running 10000 simulations.:  68%|██████▊   | 6761/10000 [00:46<00:21, 151.92it/s]Running 10000 simulations.:  68%|██████▊   | 6777/10000 [00:46<00:21, 152.02it/s]Running 10000 simulations.:  68%|██████▊   | 6793/10000 [00:46<00:21, 150.81it/s]Running 10000 simulations.:  68%|██████▊   | 6809/10000 [00:46<00:21, 150.94it/s]Running 10000 simulations.:  68%|██████▊   | 6825/10000 [00:46<00:20, 151.29it/s]Running 10000 simulations.:  68%|██████▊   | 6841/10000 [00:46<00:20, 151.81it/s]Running 10000 simulations.:  69%|██████▊   | 6857/10000 [00:47<00:20, 152.56it/s]Running 10000 simulations.:  69%|██████▊   | 6873/10000 [00:47<00:20, 151.46it/s]Running 10000 simulations.:  69%|██████▉   | 6889/10000 [00:47<00:20, 151.75it/s]Running 10000 simulations.:  69%|██████▉   | 6905/10000 [00:47<00:20, 152.23it/s]Running 10000 simulations.:  69%|██████▉   | 6921/10000 [00:47<00:20, 152.43it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:47<00:20, 152.61it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:47<00:20, 151.82it/s]Running 10000 simulations.:  70%|██████▉   | 6969/10000 [00:47<00:19, 152.17it/s]Running 10000 simulations.:  70%|██████▉   | 6985/10000 [00:47<00:19, 152.59it/s]Running 10000 simulations.:  70%|███████   | 7001/10000 [00:47<00:19, 152.73it/s]Running 10000 simulations.:  70%|███████   | 7017/10000 [00:48<00:19, 152.55it/s]Running 10000 simulations.:  70%|███████   | 7033/10000 [00:48<00:19, 152.21it/s]Running 10000 simulations.:  70%|███████   | 7049/10000 [00:48<00:19, 151.30it/s]Running 10000 simulations.:  71%|███████   | 7065/10000 [00:48<00:19, 152.15it/s]Running 10000 simulations.:  71%|███████   | 7081/10000 [00:48<00:19, 152.94it/s]Running 10000 simulations.:  71%|███████   | 7097/10000 [00:48<00:18, 153.42it/s]Running 10000 simulations.:  71%|███████   | 7113/10000 [00:48<00:18, 153.08it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:48<00:18, 153.17it/s]Running 10000 simulations.:  71%|███████▏  | 7145/10000 [00:48<00:18, 152.05it/s]Running 10000 simulations.:  72%|███████▏  | 7161/10000 [00:49<00:18, 152.32it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:49<00:18, 152.35it/s]Running 10000 simulations.:  72%|███████▏  | 7193/10000 [00:49<00:18, 152.58it/s]Running 10000 simulations.:  72%|███████▏  | 7209/10000 [00:49<00:18, 152.81it/s]Running 10000 simulations.:  72%|███████▏  | 7225/10000 [00:49<00:18, 153.21it/s]Running 10000 simulations.:  72%|███████▏  | 7241/10000 [00:49<00:17, 153.70it/s]Running 10000 simulations.:  73%|███████▎  | 7257/10000 [00:49<00:17, 154.13it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:49<00:17, 152.41it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:49<00:17, 153.06it/s]Running 10000 simulations.:  73%|███████▎  | 7305/10000 [00:49<00:17, 153.67it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:50<00:17, 153.51it/s]Running 10000 simulations.:  73%|███████▎  | 7337/10000 [00:50<00:17, 153.05it/s]Running 10000 simulations.:  74%|███████▎  | 7353/10000 [00:50<00:17, 153.08it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:50<00:17, 151.96it/s]Running 10000 simulations.:  74%|███████▍  | 7385/10000 [00:50<00:17, 152.45it/s]Running 10000 simulations.:  74%|███████▍  | 7401/10000 [00:50<00:17, 152.72it/s]Running 10000 simulations.:  74%|███████▍  | 7417/10000 [00:50<00:16, 152.93it/s]Running 10000 simulations.:  74%|███████▍  | 7433/10000 [00:50<00:16, 152.90it/s]Running 10000 simulations.:  74%|███████▍  | 7449/10000 [00:50<00:16, 153.23it/s]Running 10000 simulations.:  75%|███████▍  | 7465/10000 [00:50<00:16, 152.84it/s]Running 10000 simulations.:  75%|███████▍  | 7481/10000 [00:51<00:16, 151.85it/s]Running 10000 simulations.:  75%|███████▍  | 7497/10000 [00:51<00:16, 150.59it/s]Running 10000 simulations.:  75%|███████▌  | 7513/10000 [00:51<00:16, 150.82it/s]Running 10000 simulations.:  75%|███████▌  | 7529/10000 [00:51<00:16, 150.08it/s]Running 10000 simulations.:  75%|███████▌  | 7545/10000 [00:51<00:16, 151.18it/s]Running 10000 simulations.:  76%|███████▌  | 7561/10000 [00:51<00:16, 152.33it/s]Running 10000 simulations.:  76%|███████▌  | 7577/10000 [00:51<00:15, 153.14it/s]Running 10000 simulations.:  76%|███████▌  | 7593/10000 [00:51<00:15, 153.76it/s]Running 10000 simulations.:  76%|███████▌  | 7609/10000 [00:51<00:15, 154.28it/s]Running 10000 simulations.:  76%|███████▋  | 7625/10000 [00:52<00:15, 153.57it/s]Running 10000 simulations.:  76%|███████▋  | 7641/10000 [00:52<00:15, 153.10it/s]Running 10000 simulations.:  77%|███████▋  | 7657/10000 [00:52<00:15, 153.07it/s]Running 10000 simulations.:  77%|███████▋  | 7673/10000 [00:52<00:15, 153.19it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:52<00:15, 153.28it/s]Running 10000 simulations.:  77%|███████▋  | 7705/10000 [00:52<00:14, 153.10it/s]Running 10000 simulations.:  77%|███████▋  | 7721/10000 [00:52<00:14, 153.11it/s]Running 10000 simulations.:  77%|███████▋  | 7737/10000 [00:52<00:14, 153.51it/s]Running 10000 simulations.:  78%|███████▊  | 7753/10000 [00:52<00:14, 153.73it/s]Running 10000 simulations.:  78%|███████▊  | 7769/10000 [00:52<00:14, 153.85it/s]Running 10000 simulations.:  78%|███████▊  | 7785/10000 [00:53<00:14, 153.67it/s]Running 10000 simulations.:  78%|███████▊  | 7801/10000 [00:53<00:14, 152.79it/s]Running 10000 simulations.:  78%|███████▊  | 7817/10000 [00:53<00:14, 151.35it/s]Running 10000 simulations.:  78%|███████▊  | 7833/10000 [00:53<00:14, 152.02it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:53<00:14, 152.88it/s]Running 10000 simulations.:  79%|███████▊  | 7865/10000 [00:53<00:13, 153.62it/s]Running 10000 simulations.:  79%|███████▉  | 7881/10000 [00:53<00:13, 154.37it/s]Running 10000 simulations.:  79%|███████▉  | 7897/10000 [00:53<00:13, 154.36it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:53<00:13, 153.99it/s]Running 10000 simulations.:  79%|███████▉  | 7929/10000 [00:54<00:13, 153.99it/s]Running 10000 simulations.:  79%|███████▉  | 7945/10000 [00:54<00:13, 153.84it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:54<00:13, 153.82it/s]Running 10000 simulations.:  80%|███████▉  | 7977/10000 [00:54<00:13, 153.24it/s]Running 10000 simulations.:  80%|███████▉  | 7993/10000 [00:54<00:13, 152.66it/s]Running 10000 simulations.:  80%|████████  | 8009/10000 [00:54<00:13, 152.37it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:54<00:13, 151.67it/s]Running 10000 simulations.:  80%|████████  | 8041/10000 [00:54<00:12, 151.88it/s]Running 10000 simulations.:  81%|████████  | 8057/10000 [00:54<00:12, 151.63it/s]Running 10000 simulations.:  81%|████████  | 8073/10000 [00:54<00:12, 149.35it/s]Running 10000 simulations.:  81%|████████  | 8089/10000 [00:55<00:12, 149.89it/s]Running 10000 simulations.:  81%|████████  | 8105/10000 [00:55<00:12, 151.08it/s]Running 10000 simulations.:  81%|████████  | 8121/10000 [00:55<00:12, 151.66it/s]Running 10000 simulations.:  81%|████████▏ | 8137/10000 [00:55<00:12, 152.33it/s]Running 10000 simulations.:  82%|████████▏ | 8153/10000 [00:55<00:12, 151.78it/s]Running 10000 simulations.:  82%|████████▏ | 8169/10000 [00:55<00:12, 151.20it/s]Running 10000 simulations.:  82%|████████▏ | 8185/10000 [00:55<00:11, 151.93it/s]Running 10000 simulations.:  82%|████████▏ | 8201/10000 [00:55<00:11, 152.22it/s]Running 10000 simulations.:  82%|████████▏ | 8217/10000 [00:55<00:11, 152.80it/s]Running 10000 simulations.:  82%|████████▏ | 8233/10000 [00:56<00:11, 153.67it/s]Running 10000 simulations.:  82%|████████▏ | 8249/10000 [00:56<00:11, 154.29it/s]Running 10000 simulations.:  83%|████████▎ | 8265/10000 [00:56<00:11, 153.04it/s]Running 10000 simulations.:  83%|████████▎ | 8281/10000 [00:56<00:11, 152.61it/s]Running 10000 simulations.:  83%|████████▎ | 8297/10000 [00:56<00:11, 150.47it/s]Running 10000 simulations.:  83%|████████▎ | 8313/10000 [00:56<00:11, 151.18it/s]Running 10000 simulations.:  83%|████████▎ | 8329/10000 [00:56<00:11, 151.79it/s]Running 10000 simulations.:  83%|████████▎ | 8345/10000 [00:56<00:10, 151.41it/s]Running 10000 simulations.:  84%|████████▎ | 8361/10000 [00:56<00:10, 151.69it/s]Running 10000 simulations.:  84%|████████▍ | 8377/10000 [00:56<00:10, 151.76it/s]Running 10000 simulations.:  84%|████████▍ | 8393/10000 [00:57<00:10, 152.51it/s]Running 10000 simulations.:  84%|████████▍ | 8409/10000 [00:57<00:10, 153.34it/s]Running 10000 simulations.:  84%|████████▍ | 8425/10000 [00:57<00:10, 153.60it/s]Running 10000 simulations.:  84%|████████▍ | 8441/10000 [00:57<00:10, 152.92it/s]Running 10000 simulations.:  85%|████████▍ | 8457/10000 [00:57<00:10, 152.83it/s]Running 10000 simulations.:  85%|████████▍ | 8473/10000 [00:57<00:10, 152.61it/s]Running 10000 simulations.:  85%|████████▍ | 8489/10000 [00:57<00:09, 152.97it/s]Running 10000 simulations.:  85%|████████▌ | 8505/10000 [00:57<00:09, 153.53it/s]Running 10000 simulations.:  85%|████████▌ | 8521/10000 [00:57<00:09, 153.17it/s]Running 10000 simulations.:  85%|████████▌ | 8537/10000 [00:58<00:09, 153.34it/s]Running 10000 simulations.:  86%|████████▌ | 8553/10000 [00:58<00:09, 151.91it/s]Running 10000 simulations.:  86%|████████▌ | 8569/10000 [00:58<00:09, 152.31it/s]Running 10000 simulations.:  86%|████████▌ | 8585/10000 [00:58<00:09, 152.66it/s]Running 10000 simulations.:  86%|████████▌ | 8601/10000 [00:58<00:09, 153.01it/s]Running 10000 simulations.:  86%|████████▌ | 8617/10000 [00:58<00:09, 153.28it/s]Running 10000 simulations.:  86%|████████▋ | 8633/10000 [00:58<00:08, 153.71it/s]Running 10000 simulations.:  86%|████████▋ | 8649/10000 [00:58<00:08, 153.31it/s]Running 10000 simulations.:  87%|████████▋ | 8665/10000 [00:58<00:08, 152.24it/s]Running 10000 simulations.:  87%|████████▋ | 8681/10000 [00:58<00:08, 152.21it/s]Running 10000 simulations.:  87%|████████▋ | 8697/10000 [00:59<00:08, 152.11it/s]Running 10000 simulations.:  87%|████████▋ | 8713/10000 [00:59<00:08, 152.14it/s]Running 10000 simulations.:  87%|████████▋ | 8729/10000 [00:59<00:08, 152.44it/s]Running 10000 simulations.:  87%|████████▋ | 8745/10000 [00:59<00:08, 152.51it/s]Running 10000 simulations.:  88%|████████▊ | 8761/10000 [00:59<00:08, 152.57it/s]Running 10000 simulations.:  88%|████████▊ | 8777/10000 [00:59<00:08, 152.34it/s]Running 10000 simulations.:  88%|████████▊ | 8793/10000 [00:59<00:08, 149.78it/s]Running 10000 simulations.:  88%|████████▊ | 8809/10000 [00:59<00:07, 150.47it/s]Running 10000 simulations.:  88%|████████▊ | 8825/10000 [00:59<00:07, 151.14it/s]Running 10000 simulations.:  88%|████████▊ | 8841/10000 [01:00<00:07, 152.08it/s]Running 10000 simulations.:  89%|████████▊ | 8857/10000 [01:00<00:07, 152.59it/s]Running 10000 simulations.:  89%|████████▊ | 8873/10000 [01:00<00:07, 152.84it/s]Running 10000 simulations.:  89%|████████▉ | 8889/10000 [01:00<00:07, 153.22it/s]Running 10000 simulations.:  89%|████████▉ | 8905/10000 [01:00<00:07, 153.44it/s]Running 10000 simulations.:  89%|████████▉ | 8921/10000 [01:00<00:07, 153.20it/s]Running 10000 simulations.:  89%|████████▉ | 8937/10000 [01:00<00:06, 152.72it/s]Running 10000 simulations.:  90%|████████▉ | 8953/10000 [01:00<00:06, 152.39it/s]Running 10000 simulations.:  90%|████████▉ | 8969/10000 [01:00<00:06, 150.85it/s]Running 10000 simulations.:  90%|████████▉ | 8985/10000 [01:00<00:06, 149.25it/s]Running 10000 simulations.:  90%|█████████ | 9001/10000 [01:01<00:06, 150.28it/s]Running 10000 simulations.:  90%|█████████ | 9017/10000 [01:01<00:06, 151.14it/s]Running 10000 simulations.:  90%|█████████ | 9033/10000 [01:01<00:06, 152.10it/s]Running 10000 simulations.:  90%|█████████ | 9049/10000 [01:01<00:06, 152.64it/s]Running 10000 simulations.:  91%|█████████ | 9065/10000 [01:01<00:06, 153.05it/s]Running 10000 simulations.:  91%|█████████ | 9081/10000 [01:01<00:05, 153.52it/s]Running 10000 simulations.:  91%|█████████ | 9097/10000 [01:01<00:05, 153.08it/s]Running 10000 simulations.:  91%|█████████ | 9113/10000 [01:01<00:05, 152.45it/s]Running 10000 simulations.:  91%|█████████▏| 9129/10000 [01:01<00:05, 152.91it/s]Running 10000 simulations.:  91%|█████████▏| 9145/10000 [01:02<00:05, 153.30it/s]Running 10000 simulations.:  92%|█████████▏| 9161/10000 [01:02<00:05, 153.37it/s]Running 10000 simulations.:  92%|█████████▏| 9177/10000 [01:02<00:05, 153.51it/s]Running 10000 simulations.:  92%|█████████▏| 9193/10000 [01:02<00:05, 153.48it/s]Running 10000 simulations.:  92%|█████████▏| 9209/10000 [01:02<00:05, 153.57it/s]Running 10000 simulations.:  92%|█████████▏| 9225/10000 [01:02<00:05, 154.11it/s]Running 10000 simulations.:  92%|█████████▏| 9241/10000 [01:02<00:04, 154.14it/s]Running 10000 simulations.:  93%|█████████▎| 9257/10000 [01:02<00:04, 154.31it/s]Running 10000 simulations.:  93%|█████████▎| 9273/10000 [01:02<00:04, 154.41it/s]Running 10000 simulations.:  93%|█████████▎| 9289/10000 [01:02<00:04, 154.36it/s]Running 10000 simulations.:  93%|█████████▎| 9305/10000 [01:03<00:04, 154.12it/s]Running 10000 simulations.:  93%|█████████▎| 9321/10000 [01:03<00:04, 154.28it/s]Running 10000 simulations.:  93%|█████████▎| 9337/10000 [01:03<00:04, 153.66it/s]Running 10000 simulations.:  94%|█████████▎| 9353/10000 [01:03<00:04, 151.56it/s]Running 10000 simulations.:  94%|█████████▎| 9369/10000 [01:03<00:04, 149.62it/s]Running 10000 simulations.:  94%|█████████▍| 9384/10000 [01:03<00:04, 147.70it/s]Running 10000 simulations.:  94%|█████████▍| 9399/10000 [01:03<00:04, 146.90it/s]Running 10000 simulations.:  94%|█████████▍| 9414/10000 [01:03<00:04, 146.46it/s]Running 10000 simulations.:  94%|█████████▍| 9429/10000 [01:03<00:03, 145.70it/s]Running 10000 simulations.:  94%|█████████▍| 9444/10000 [01:03<00:03, 145.82it/s]Running 10000 simulations.:  95%|█████████▍| 9459/10000 [01:04<00:03, 145.11it/s]Running 10000 simulations.:  95%|█████████▍| 9474/10000 [01:04<00:03, 145.51it/s]Running 10000 simulations.:  95%|█████████▍| 9489/10000 [01:04<00:03, 141.48it/s]Running 10000 simulations.:  95%|█████████▌| 9504/10000 [01:04<00:03, 143.76it/s]Running 10000 simulations.:  95%|█████████▌| 9520/10000 [01:04<00:03, 146.83it/s]Running 10000 simulations.:  95%|█████████▌| 9536/10000 [01:04<00:03, 148.26it/s]Running 10000 simulations.:  96%|█████████▌| 9552/10000 [01:04<00:02, 149.66it/s]Running 10000 simulations.:  96%|█████████▌| 9568/10000 [01:04<00:02, 150.67it/s]Running 10000 simulations.:  96%|█████████▌| 9584/10000 [01:04<00:02, 151.27it/s]Running 10000 simulations.:  96%|█████████▌| 9600/10000 [01:05<00:02, 151.70it/s]Running 10000 simulations.:  96%|█████████▌| 9616/10000 [01:05<00:02, 152.00it/s]Running 10000 simulations.:  96%|█████████▋| 9632/10000 [01:05<00:02, 152.10it/s]Running 10000 simulations.:  96%|█████████▋| 9648/10000 [01:05<00:02, 153.10it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [01:05<00:02, 153.78it/s]Running 10000 simulations.:  97%|█████████▋| 9680/10000 [01:05<00:02, 153.69it/s]Running 10000 simulations.:  97%|█████████▋| 9696/10000 [01:05<00:01, 153.06it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [01:05<00:01, 152.69it/s]Running 10000 simulations.:  97%|█████████▋| 9728/10000 [01:05<00:01, 152.62it/s]Running 10000 simulations.:  97%|█████████▋| 9744/10000 [01:05<00:01, 152.80it/s]Running 10000 simulations.:  98%|█████████▊| 9760/10000 [01:06<00:01, 152.98it/s]Running 10000 simulations.:  98%|█████████▊| 9776/10000 [01:06<00:01, 153.30it/s]Running 10000 simulations.:  98%|█████████▊| 9792/10000 [01:06<00:01, 153.83it/s]Running 10000 simulations.:  98%|█████████▊| 9808/10000 [01:06<00:01, 153.54it/s]Running 10000 simulations.:  98%|█████████▊| 9824/10000 [01:06<00:01, 153.35it/s]Running 10000 simulations.:  98%|█████████▊| 9840/10000 [01:06<00:01, 153.46it/s]Running 10000 simulations.:  99%|█████████▊| 9856/10000 [01:06<00:00, 153.87it/s]Running 10000 simulations.:  99%|█████████▊| 9872/10000 [01:06<00:00, 154.02it/s]Running 10000 simulations.:  99%|█████████▉| 9888/10000 [01:06<00:00, 154.60it/s]Running 10000 simulations.:  99%|█████████▉| 9904/10000 [01:07<00:00, 154.57it/s]Running 10000 simulations.:  99%|█████████▉| 9920/10000 [01:07<00:00, 155.41it/s]Running 10000 simulations.:  99%|█████████▉| 9936/10000 [01:07<00:00, 155.89it/s]Running 10000 simulations.: 100%|█████████▉| 9952/10000 [01:07<00:00, 155.68it/s]Running 10000 simulations.: 100%|█████████▉| 9968/10000 [01:07<00:00, 155.45it/s]Running 10000 simulations.: 100%|█████████▉| 9984/10000 [01:07<00:00, 154.72it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:07<00:00, 155.31it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:07<00:00, 147.83it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:08, 146.06it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<01:08, 145.68it/s]Running 10000 simulations.:   0%|          | 45/10000 [00:00<01:08, 145.11it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<01:08, 144.50it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<01:08, 144.48it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<01:08, 144.14it/s]Running 10000 simulations.:   1%|          | 105/10000 [00:00<01:08, 143.78it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<01:08, 143.61it/s]Running 10000 simulations.:   1%|▏         | 135/10000 [00:00<01:07, 145.28it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:01<01:07, 146.40it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:01<01:06, 147.03it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:01<01:06, 147.68it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:01<01:04, 150.94it/s]Running 10000 simulations.:   2%|▏         | 214/10000 [00:01<01:02, 156.26it/s]Running 10000 simulations.:   2%|▏         | 231/10000 [00:01<01:01, 158.28it/s]Running 10000 simulations.:   2%|▏         | 247/10000 [00:01<01:03, 154.00it/s]Running 10000 simulations.:   3%|▎         | 263/10000 [00:01<01:04, 151.93it/s]Running 10000 simulations.:   3%|▎         | 279/10000 [00:01<01:04, 150.10it/s]Running 10000 simulations.:   3%|▎         | 295/10000 [00:01<01:05, 149.05it/s]Running 10000 simulations.:   3%|▎         | 310/10000 [00:02<01:05, 147.61it/s]Running 10000 simulations.:   3%|▎         | 325/10000 [00:02<01:06, 146.50it/s]Running 10000 simulations.:   3%|▎         | 340/10000 [00:02<01:06, 145.96it/s]Running 10000 simulations.:   4%|▎         | 355/10000 [00:02<01:06, 145.98it/s]Running 10000 simulations.:   4%|▎         | 370/10000 [00:02<01:06, 145.71it/s]Running 10000 simulations.:   4%|▍         | 385/10000 [00:02<01:06, 145.26it/s]Running 10000 simulations.:   4%|▍         | 400/10000 [00:02<01:05, 145.62it/s]Running 10000 simulations.:   4%|▍         | 415/10000 [00:02<01:05, 145.78it/s]Running 10000 simulations.:   4%|▍         | 430/10000 [00:02<01:05, 145.11it/s]Running 10000 simulations.:   4%|▍         | 445/10000 [00:03<01:05, 145.40it/s]Running 10000 simulations.:   5%|▍         | 460/10000 [00:03<01:05, 144.95it/s]Running 10000 simulations.:   5%|▍         | 475/10000 [00:03<01:05, 144.95it/s]Running 10000 simulations.:   5%|▍         | 490/10000 [00:03<01:05, 144.31it/s]Running 10000 simulations.:   5%|▌         | 505/10000 [00:03<01:05, 143.94it/s]Running 10000 simulations.:   5%|▌         | 520/10000 [00:03<01:05, 144.67it/s]Running 10000 simulations.:   5%|▌         | 536/10000 [00:03<01:04, 146.69it/s]Running 10000 simulations.:   6%|▌         | 551/10000 [00:03<01:04, 147.52it/s]Running 10000 simulations.:   6%|▌         | 567/10000 [00:03<01:03, 148.36it/s]Running 10000 simulations.:   6%|▌         | 582/10000 [00:03<01:03, 148.85it/s]Running 10000 simulations.:   6%|▌         | 598/10000 [00:04<01:02, 149.39it/s]Running 10000 simulations.:   6%|▌         | 613/10000 [00:04<01:02, 149.44it/s]Running 10000 simulations.:   6%|▋         | 628/10000 [00:04<01:02, 149.48it/s]Running 10000 simulations.:   6%|▋         | 644/10000 [00:04<01:02, 149.65it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:04<01:02, 149.80it/s]Running 10000 simulations.:   7%|▋         | 676/10000 [00:04<01:02, 150.29it/s]Running 10000 simulations.:   7%|▋         | 692/10000 [00:04<01:01, 150.51it/s]Running 10000 simulations.:   7%|▋         | 708/10000 [00:04<01:01, 151.00it/s]Running 10000 simulations.:   7%|▋         | 724/10000 [00:04<01:01, 151.16it/s]Running 10000 simulations.:   7%|▋         | 740/10000 [00:05<01:01, 150.51it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:05<01:01, 150.90it/s]Running 10000 simulations.:   8%|▊         | 772/10000 [00:05<01:01, 150.45it/s]Running 10000 simulations.:   8%|▊         | 788/10000 [00:05<01:01, 150.48it/s]Running 10000 simulations.:   8%|▊         | 804/10000 [00:05<01:01, 150.23it/s]Running 10000 simulations.:   8%|▊         | 820/10000 [00:05<01:01, 150.17it/s]Running 10000 simulations.:   8%|▊         | 836/10000 [00:05<01:01, 149.77it/s]Running 10000 simulations.:   9%|▊         | 851/10000 [00:05<01:01, 149.60it/s]Running 10000 simulations.:   9%|▊         | 866/10000 [00:05<01:01, 148.89it/s]Running 10000 simulations.:   9%|▉         | 882/10000 [00:05<01:00, 149.51it/s]Running 10000 simulations.:   9%|▉         | 897/10000 [00:06<01:00, 149.47it/s]Running 10000 simulations.:   9%|▉         | 912/10000 [00:06<01:01, 148.78it/s]Running 10000 simulations.:   9%|▉         | 927/10000 [00:06<01:00, 148.90it/s]Running 10000 simulations.:   9%|▉         | 942/10000 [00:06<01:00, 149.06it/s]Running 10000 simulations.:  10%|▉         | 957/10000 [00:06<01:00, 149.16it/s]Running 10000 simulations.:  10%|▉         | 972/10000 [00:06<01:00, 149.31it/s]Running 10000 simulations.:  10%|▉         | 987/10000 [00:06<01:00, 149.12it/s]Running 10000 simulations.:  10%|█         | 1002/10000 [00:06<01:00, 149.15it/s]Running 10000 simulations.:  10%|█         | 1017/10000 [00:06<01:00, 149.28it/s]Running 10000 simulations.:  10%|█         | 1032/10000 [00:06<01:00, 149.15it/s]Running 10000 simulations.:  10%|█         | 1047/10000 [00:07<01:00, 149.03it/s]Running 10000 simulations.:  11%|█         | 1062/10000 [00:07<00:59, 149.14it/s]Running 10000 simulations.:  11%|█         | 1077/10000 [00:07<01:00, 148.60it/s]Running 10000 simulations.:  11%|█         | 1092/10000 [00:07<00:59, 148.78it/s]Running 10000 simulations.:  11%|█         | 1107/10000 [00:07<00:59, 148.39it/s]Running 10000 simulations.:  11%|█         | 1122/10000 [00:07<01:00, 147.93it/s]Running 10000 simulations.:  11%|█▏        | 1137/10000 [00:07<00:59, 148.16it/s]Running 10000 simulations.:  12%|█▏        | 1152/10000 [00:07<00:59, 148.29it/s]Running 10000 simulations.:  12%|█▏        | 1167/10000 [00:07<00:59, 148.42it/s]Running 10000 simulations.:  12%|█▏        | 1182/10000 [00:07<00:59, 148.21it/s]Running 10000 simulations.:  12%|█▏        | 1197/10000 [00:08<00:59, 147.44it/s]Running 10000 simulations.:  12%|█▏        | 1212/10000 [00:08<00:59, 147.85it/s]Running 10000 simulations.:  12%|█▏        | 1227/10000 [00:08<00:59, 148.03it/s]Running 10000 simulations.:  12%|█▏        | 1242/10000 [00:08<00:58, 148.51it/s]Running 10000 simulations.:  13%|█▎        | 1257/10000 [00:08<00:58, 148.67it/s]Running 10000 simulations.:  13%|█▎        | 1272/10000 [00:08<00:58, 148.61it/s]Running 10000 simulations.:  13%|█▎        | 1287/10000 [00:08<00:58, 147.80it/s]Running 10000 simulations.:  13%|█▎        | 1302/10000 [00:08<00:59, 145.60it/s]Running 10000 simulations.:  13%|█▎        | 1317/10000 [00:08<01:00, 144.11it/s]Running 10000 simulations.:  13%|█▎        | 1332/10000 [00:08<01:00, 143.99it/s]Running 10000 simulations.:  13%|█▎        | 1347/10000 [00:09<01:00, 143.80it/s]Running 10000 simulations.:  14%|█▎        | 1362/10000 [00:09<01:00, 143.32it/s]Running 10000 simulations.:  14%|█▍        | 1377/10000 [00:09<01:00, 143.16it/s]Running 10000 simulations.:  14%|█▍        | 1392/10000 [00:09<01:00, 142.91it/s]Running 10000 simulations.:  14%|█▍        | 1407/10000 [00:09<01:00, 142.07it/s]Running 10000 simulations.:  14%|█▍        | 1422/10000 [00:09<01:00, 141.72it/s]Running 10000 simulations.:  14%|█▍        | 1437/10000 [00:09<01:00, 141.96it/s]Running 10000 simulations.:  15%|█▍        | 1452/10000 [00:09<00:59, 142.78it/s]Running 10000 simulations.:  15%|█▍        | 1467/10000 [00:09<00:58, 144.71it/s]Running 10000 simulations.:  15%|█▍        | 1483/10000 [00:10<00:58, 146.46it/s]Running 10000 simulations.:  15%|█▍        | 1499/10000 [00:10<00:57, 147.64it/s]Running 10000 simulations.:  15%|█▌        | 1515/10000 [00:10<00:57, 148.62it/s]Running 10000 simulations.:  15%|█▌        | 1531/10000 [00:10<00:56, 149.28it/s]Running 10000 simulations.:  15%|█▌        | 1547/10000 [00:10<00:56, 149.64it/s]Running 10000 simulations.:  16%|█▌        | 1563/10000 [00:10<00:56, 150.07it/s]Running 10000 simulations.:  16%|█▌        | 1579/10000 [00:10<00:56, 149.75it/s]Running 10000 simulations.:  16%|█▌        | 1594/10000 [00:10<00:56, 149.64it/s]Running 10000 simulations.:  16%|█▌        | 1610/10000 [00:10<00:55, 149.85it/s]Running 10000 simulations.:  16%|█▋        | 1626/10000 [00:10<00:55, 150.01it/s]Running 10000 simulations.:  16%|█▋        | 1642/10000 [00:11<00:55, 149.93it/s]Running 10000 simulations.:  17%|█▋        | 1658/10000 [00:11<00:55, 150.37it/s]Running 10000 simulations.:  17%|█▋        | 1674/10000 [00:11<00:55, 149.78it/s]Running 10000 simulations.:  17%|█▋        | 1689/10000 [00:11<00:55, 149.65it/s]Running 10000 simulations.:  17%|█▋        | 1705/10000 [00:11<00:55, 149.87it/s]Running 10000 simulations.:  17%|█▋        | 1721/10000 [00:11<00:55, 150.35it/s]Running 10000 simulations.:  17%|█▋        | 1737/10000 [00:11<00:54, 150.63it/s]Running 10000 simulations.:  18%|█▊        | 1753/10000 [00:11<00:54, 151.03it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:11<00:54, 150.88it/s]Running 10000 simulations.:  18%|█▊        | 1785/10000 [00:12<00:54, 150.32it/s]Running 10000 simulations.:  18%|█▊        | 1801/10000 [00:12<00:54, 149.86it/s]Running 10000 simulations.:  18%|█▊        | 1817/10000 [00:12<00:54, 150.38it/s]Running 10000 simulations.:  18%|█▊        | 1833/10000 [00:12<00:54, 150.82it/s]Running 10000 simulations.:  18%|█▊        | 1849/10000 [00:12<00:54, 149.91it/s]Running 10000 simulations.:  19%|█▊        | 1864/10000 [00:12<00:54, 149.80it/s]Running 10000 simulations.:  19%|█▉        | 1879/10000 [00:12<00:54, 149.80it/s]Running 10000 simulations.:  19%|█▉        | 1895/10000 [00:12<00:54, 149.92it/s]Running 10000 simulations.:  19%|█▉        | 1911/10000 [00:12<00:53, 150.16it/s]Running 10000 simulations.:  19%|█▉        | 1927/10000 [00:12<00:53, 149.53it/s]Running 10000 simulations.:  19%|█▉        | 1942/10000 [00:13<00:54, 149.18it/s]Running 10000 simulations.:  20%|█▉        | 1957/10000 [00:13<00:53, 148.98it/s]Running 10000 simulations.:  20%|█▉        | 1972/10000 [00:13<00:53, 148.78it/s]Running 10000 simulations.:  20%|█▉        | 1987/10000 [00:13<00:53, 148.98it/s]Running 10000 simulations.:  20%|██        | 2003/10000 [00:13<00:53, 149.45it/s]Running 10000 simulations.:  20%|██        | 2018/10000 [00:13<00:53, 149.29it/s]Running 10000 simulations.:  20%|██        | 2033/10000 [00:13<00:53, 149.23it/s]Running 10000 simulations.:  20%|██        | 2048/10000 [00:13<00:53, 149.45it/s]Running 10000 simulations.:  21%|██        | 2063/10000 [00:13<00:53, 148.95it/s]Running 10000 simulations.:  21%|██        | 2078/10000 [00:14<00:53, 149.14it/s]Running 10000 simulations.:  21%|██        | 2093/10000 [00:14<00:53, 149.08it/s]Running 10000 simulations.:  21%|██        | 2108/10000 [00:14<00:53, 148.73it/s]Running 10000 simulations.:  21%|██        | 2123/10000 [00:14<00:53, 148.21it/s]Running 10000 simulations.:  21%|██▏       | 2138/10000 [00:14<00:53, 147.81it/s]Running 10000 simulations.:  22%|██▏       | 2153/10000 [00:14<00:53, 145.91it/s]Running 10000 simulations.:  22%|██▏       | 2168/10000 [00:14<00:54, 145.03it/s]Running 10000 simulations.:  22%|██▏       | 2183/10000 [00:14<00:54, 144.27it/s]Running 10000 simulations.:  22%|██▏       | 2198/10000 [00:14<00:54, 144.02it/s]Running 10000 simulations.:  22%|██▏       | 2213/10000 [00:14<00:54, 143.73it/s]Running 10000 simulations.:  22%|██▏       | 2228/10000 [00:15<00:54, 142.93it/s]Running 10000 simulations.:  22%|██▏       | 2243/10000 [00:15<00:54, 142.90it/s]Running 10000 simulations.:  23%|██▎       | 2258/10000 [00:15<00:54, 142.85it/s]Running 10000 simulations.:  23%|██▎       | 2273/10000 [00:15<00:54, 143.06it/s]Running 10000 simulations.:  23%|██▎       | 2288/10000 [00:15<00:53, 143.34it/s]Running 10000 simulations.:  23%|██▎       | 2303/10000 [00:15<00:53, 143.59it/s]Running 10000 simulations.:  23%|██▎       | 2319/10000 [00:15<00:52, 145.67it/s]Running 10000 simulations.:  23%|██▎       | 2334/10000 [00:15<00:52, 146.91it/s]Running 10000 simulations.:  24%|██▎       | 2350/10000 [00:15<00:51, 147.84it/s]Running 10000 simulations.:  24%|██▎       | 2365/10000 [00:15<00:51, 147.89it/s]Running 10000 simulations.:  24%|██▍       | 2380/10000 [00:16<00:51, 147.83it/s]Running 10000 simulations.:  24%|██▍       | 2395/10000 [00:16<00:51, 148.01it/s]Running 10000 simulations.:  24%|██▍       | 2410/10000 [00:16<00:51, 148.20it/s]Running 10000 simulations.:  24%|██▍       | 2425/10000 [00:16<00:51, 148.17it/s]Running 10000 simulations.:  24%|██▍       | 2440/10000 [00:16<00:51, 148.01it/s]Running 10000 simulations.:  25%|██▍       | 2455/10000 [00:16<00:51, 147.49it/s]Running 10000 simulations.:  25%|██▍       | 2471/10000 [00:16<00:50, 148.34it/s]Running 10000 simulations.:  25%|██▍       | 2486/10000 [00:16<00:50, 148.81it/s]Running 10000 simulations.:  25%|██▌       | 2501/10000 [00:16<00:50, 148.28it/s]Running 10000 simulations.:  25%|██▌       | 2516/10000 [00:17<00:50, 148.71it/s]Running 10000 simulations.:  25%|██▌       | 2531/10000 [00:17<00:50, 149.09it/s]Running 10000 simulations.:  25%|██▌       | 2546/10000 [00:17<00:49, 149.35it/s]Running 10000 simulations.:  26%|██▌       | 2561/10000 [00:17<00:49, 149.34it/s]Running 10000 simulations.:  26%|██▌       | 2576/10000 [00:17<00:49, 149.33it/s]Running 10000 simulations.:  26%|██▌       | 2591/10000 [00:17<00:49, 149.17it/s]Running 10000 simulations.:  26%|██▌       | 2606/10000 [00:17<00:49, 149.10it/s]Running 10000 simulations.:  26%|██▌       | 2621/10000 [00:17<00:49, 148.20it/s]Running 10000 simulations.:  26%|██▋       | 2636/10000 [00:17<00:50, 147.00it/s]Running 10000 simulations.:  27%|██▋       | 2651/10000 [00:17<00:49, 147.26it/s]Running 10000 simulations.:  27%|██▋       | 2666/10000 [00:18<00:49, 147.73it/s]Running 10000 simulations.:  27%|██▋       | 2681/10000 [00:18<00:49, 148.08it/s]Running 10000 simulations.:  27%|██▋       | 2696/10000 [00:18<00:49, 148.23it/s]Running 10000 simulations.:  27%|██▋       | 2711/10000 [00:18<00:49, 148.15it/s]Running 10000 simulations.:  27%|██▋       | 2726/10000 [00:18<00:49, 148.01it/s]Running 10000 simulations.:  27%|██▋       | 2741/10000 [00:18<00:49, 147.81it/s]Running 10000 simulations.:  28%|██▊       | 2756/10000 [00:18<00:49, 145.43it/s]Running 10000 simulations.:  28%|██▊       | 2771/10000 [00:18<00:50, 142.32it/s]Running 10000 simulations.:  28%|██▊       | 2786/10000 [00:18<00:51, 140.68it/s]Running 10000 simulations.:  28%|██▊       | 2801/10000 [00:18<00:50, 141.68it/s]Running 10000 simulations.:  28%|██▊       | 2816/10000 [00:19<00:50, 143.49it/s]Running 10000 simulations.:  28%|██▊       | 2831/10000 [00:19<00:49, 144.75it/s]Running 10000 simulations.:  28%|██▊       | 2846/10000 [00:19<00:49, 145.65it/s]Running 10000 simulations.:  29%|██▊       | 2861/10000 [00:19<00:48, 146.56it/s]Running 10000 simulations.:  29%|██▉       | 2876/10000 [00:19<00:48, 147.51it/s]Running 10000 simulations.:  29%|██▉       | 2891/10000 [00:19<00:47, 148.11it/s]Running 10000 simulations.:  29%|██▉       | 2906/10000 [00:19<00:47, 148.37it/s]Running 10000 simulations.:  29%|██▉       | 2921/10000 [00:19<00:47, 148.72it/s]Running 10000 simulations.:  29%|██▉       | 2936/10000 [00:19<00:47, 148.86it/s]Running 10000 simulations.:  30%|██▉       | 2951/10000 [00:19<00:47, 148.61it/s]Running 10000 simulations.:  30%|██▉       | 2967/10000 [00:20<00:47, 149.03it/s]Running 10000 simulations.:  30%|██▉       | 2983/10000 [00:20<00:46, 149.62it/s]Running 10000 simulations.:  30%|██▉       | 2999/10000 [00:20<00:46, 149.75it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:20<00:46, 149.89it/s]Running 10000 simulations.:  30%|███       | 3030/10000 [00:20<00:46, 149.44it/s]Running 10000 simulations.:  30%|███       | 3045/10000 [00:20<00:46, 148.98it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:20<00:46, 148.26it/s]Running 10000 simulations.:  31%|███       | 3075/10000 [00:20<00:46, 148.26it/s]Running 10000 simulations.:  31%|███       | 3091/10000 [00:20<00:46, 148.99it/s]Running 10000 simulations.:  31%|███       | 3106/10000 [00:21<00:46, 149.07it/s]Running 10000 simulations.:  31%|███       | 3121/10000 [00:21<00:46, 148.89it/s]Running 10000 simulations.:  31%|███▏      | 3136/10000 [00:21<01:10, 97.98it/s] Running 10000 simulations.:  32%|███▏      | 3152/10000 [00:21<01:02, 109.36it/s]Running 10000 simulations.:  32%|███▏      | 3168/10000 [00:21<00:57, 119.18it/s]Running 10000 simulations.:  32%|███▏      | 3183/10000 [00:21<00:53, 126.58it/s]Running 10000 simulations.:  32%|███▏      | 3198/10000 [00:21<00:51, 132.05it/s]Running 10000 simulations.:  32%|███▏      | 3213/10000 [00:21<00:49, 136.76it/s]Running 10000 simulations.:  32%|███▏      | 3228/10000 [00:21<00:48, 140.44it/s]Running 10000 simulations.:  32%|███▏      | 3243/10000 [00:22<00:47, 143.06it/s]Running 10000 simulations.:  33%|███▎      | 3258/10000 [00:22<00:46, 144.87it/s]Running 10000 simulations.:  33%|███▎      | 3273/10000 [00:22<00:46, 146.00it/s]Running 10000 simulations.:  33%|███▎      | 3288/10000 [00:22<00:45, 146.45it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:22<00:45, 146.62it/s]Running 10000 simulations.:  33%|███▎      | 3318/10000 [00:22<00:45, 146.92it/s]Running 10000 simulations.:  33%|███▎      | 3333/10000 [00:22<00:45, 147.28it/s]Running 10000 simulations.:  33%|███▎      | 3348/10000 [00:22<00:45, 147.38it/s]Running 10000 simulations.:  34%|███▎      | 3363/10000 [00:22<00:44, 147.78it/s]Running 10000 simulations.:  34%|███▍      | 3378/10000 [00:23<00:44, 148.22it/s]Running 10000 simulations.:  34%|███▍      | 3394/10000 [00:23<00:44, 148.77it/s]Running 10000 simulations.:  34%|███▍      | 3409/10000 [00:23<00:44, 148.50it/s]Running 10000 simulations.:  34%|███▍      | 3424/10000 [00:23<00:44, 148.61it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:23<00:44, 148.90it/s]Running 10000 simulations.:  35%|███▍      | 3454/10000 [00:23<00:43, 149.20it/s]Running 10000 simulations.:  35%|███▍      | 3470/10000 [00:23<00:43, 149.48it/s]Running 10000 simulations.:  35%|███▍      | 3485/10000 [00:23<00:43, 149.31it/s]Running 10000 simulations.:  35%|███▌      | 3500/10000 [00:23<00:43, 148.76it/s]Running 10000 simulations.:  35%|███▌      | 3515/10000 [00:23<00:43, 148.46it/s]Running 10000 simulations.:  35%|███▌      | 3530/10000 [00:24<00:43, 147.78it/s]Running 10000 simulations.:  35%|███▌      | 3545/10000 [00:24<00:43, 147.71it/s]Running 10000 simulations.:  36%|███▌      | 3560/10000 [00:24<00:43, 147.75it/s]Running 10000 simulations.:  36%|███▌      | 3575/10000 [00:24<00:43, 148.04it/s]Running 10000 simulations.:  36%|███▌      | 3590/10000 [00:24<00:43, 148.19it/s]Running 10000 simulations.:  36%|███▌      | 3605/10000 [00:24<00:43, 148.08it/s]Running 10000 simulations.:  36%|███▌      | 3620/10000 [00:24<00:42, 148.59it/s]Running 10000 simulations.:  36%|███▋      | 3635/10000 [00:24<00:42, 148.35it/s]Running 10000 simulations.:  36%|███▋      | 3650/10000 [00:24<00:42, 147.99it/s]Running 10000 simulations.:  37%|███▋      | 3665/10000 [00:24<00:42, 148.10it/s]Running 10000 simulations.:  37%|███▋      | 3680/10000 [00:25<00:42, 148.25it/s]Running 10000 simulations.:  37%|███▋      | 3695/10000 [00:25<00:42, 148.42it/s]Running 10000 simulations.:  37%|███▋      | 3710/10000 [00:25<00:42, 147.95it/s]Running 10000 simulations.:  37%|███▋      | 3725/10000 [00:25<00:42, 148.20it/s]Running 10000 simulations.:  37%|███▋      | 3740/10000 [00:25<00:42, 148.66it/s]Running 10000 simulations.:  38%|███▊      | 3755/10000 [00:25<00:41, 148.71it/s]Running 10000 simulations.:  38%|███▊      | 3770/10000 [00:25<00:42, 148.31it/s]Running 10000 simulations.:  38%|███▊      | 3785/10000 [00:25<00:42, 147.61it/s]Running 10000 simulations.:  38%|███▊      | 3800/10000 [00:25<00:42, 147.56it/s]Running 10000 simulations.:  38%|███▊      | 3815/10000 [00:25<00:41, 147.44it/s]Running 10000 simulations.:  38%|███▊      | 3830/10000 [00:26<00:41, 147.58it/s]Running 10000 simulations.:  38%|███▊      | 3845/10000 [00:26<00:41, 147.75it/s]Running 10000 simulations.:  39%|███▊      | 3860/10000 [00:26<00:41, 147.76it/s]Running 10000 simulations.:  39%|███▉      | 3875/10000 [00:26<00:41, 147.79it/s]Running 10000 simulations.:  39%|███▉      | 3890/10000 [00:26<00:41, 147.33it/s]Running 10000 simulations.:  39%|███▉      | 3905/10000 [00:26<00:41, 146.73it/s]Running 10000 simulations.:  39%|███▉      | 3920/10000 [00:26<00:41, 147.03it/s]Running 10000 simulations.:  39%|███▉      | 3935/10000 [00:26<00:43, 140.25it/s]Running 10000 simulations.:  40%|███▉      | 3950/10000 [00:26<00:42, 142.68it/s]Running 10000 simulations.:  40%|███▉      | 3965/10000 [00:26<00:41, 144.09it/s]Running 10000 simulations.:  40%|███▉      | 3980/10000 [00:27<00:41, 145.02it/s]Running 10000 simulations.:  40%|███▉      | 3995/10000 [00:27<00:41, 145.79it/s]Running 10000 simulations.:  40%|████      | 4010/10000 [00:27<00:41, 145.85it/s]Running 10000 simulations.:  40%|████      | 4025/10000 [00:27<00:40, 146.47it/s]Running 10000 simulations.:  40%|████      | 4040/10000 [00:27<00:40, 146.90it/s]Running 10000 simulations.:  41%|████      | 4055/10000 [00:27<00:40, 147.44it/s]Running 10000 simulations.:  41%|████      | 4070/10000 [00:27<00:40, 147.44it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:27<00:40, 147.61it/s]Running 10000 simulations.:  41%|████      | 4100/10000 [00:27<00:39, 147.67it/s]Running 10000 simulations.:  41%|████      | 4115/10000 [00:28<00:39, 147.66it/s]Running 10000 simulations.:  41%|████▏     | 4130/10000 [00:28<00:39, 147.40it/s]Running 10000 simulations.:  41%|████▏     | 4145/10000 [00:28<00:39, 147.44it/s]Running 10000 simulations.:  42%|████▏     | 4160/10000 [00:28<00:39, 147.63it/s]Running 10000 simulations.:  42%|████▏     | 4175/10000 [00:28<00:39, 147.75it/s]Running 10000 simulations.:  42%|████▏     | 4190/10000 [00:28<00:39, 148.18it/s]Running 10000 simulations.:  42%|████▏     | 4206/10000 [00:28<00:38, 148.77it/s]Running 10000 simulations.:  42%|████▏     | 4221/10000 [00:28<00:38, 148.86it/s]Running 10000 simulations.:  42%|████▏     | 4236/10000 [00:28<00:38, 148.89it/s]Running 10000 simulations.:  43%|████▎     | 4251/10000 [00:28<00:38, 147.57it/s]Running 10000 simulations.:  43%|████▎     | 4266/10000 [00:29<00:39, 143.62it/s]Running 10000 simulations.:  43%|████▎     | 4281/10000 [00:29<00:40, 140.70it/s]Running 10000 simulations.:  43%|████▎     | 4296/10000 [00:29<00:41, 138.75it/s]Running 10000 simulations.:  43%|████▎     | 4310/10000 [00:29<00:41, 138.10it/s]Running 10000 simulations.:  43%|████▎     | 4324/10000 [00:29<00:41, 136.97it/s]Running 10000 simulations.:  43%|████▎     | 4338/10000 [00:29<00:41, 136.46it/s]Running 10000 simulations.:  44%|████▎     | 4352/10000 [00:29<00:41, 137.19it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:29<00:40, 139.70it/s]Running 10000 simulations.:  44%|████▍     | 4382/10000 [00:29<00:39, 141.58it/s]Running 10000 simulations.:  44%|████▍     | 4397/10000 [00:29<00:39, 143.22it/s]Running 10000 simulations.:  44%|████▍     | 4412/10000 [00:30<00:38, 144.55it/s]Running 10000 simulations.:  44%|████▍     | 4427/10000 [00:30<00:38, 145.66it/s]Running 10000 simulations.:  44%|████▍     | 4442/10000 [00:30<00:38, 145.72it/s]Running 10000 simulations.:  45%|████▍     | 4457/10000 [00:30<00:37, 145.92it/s]Running 10000 simulations.:  45%|████▍     | 4472/10000 [00:30<00:37, 145.91it/s]Running 10000 simulations.:  45%|████▍     | 4487/10000 [00:30<00:37, 146.29it/s]Running 10000 simulations.:  45%|████▌     | 4502/10000 [00:30<00:37, 146.58it/s]Running 10000 simulations.:  45%|████▌     | 4517/10000 [00:30<00:37, 146.25it/s]Running 10000 simulations.:  45%|████▌     | 4532/10000 [00:30<00:37, 146.17it/s]Running 10000 simulations.:  45%|████▌     | 4547/10000 [00:30<00:37, 145.84it/s]Running 10000 simulations.:  46%|████▌     | 4562/10000 [00:31<00:37, 145.59it/s]Running 10000 simulations.:  46%|████▌     | 4577/10000 [00:31<00:37, 144.32it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:31<00:37, 144.78it/s]Running 10000 simulations.:  46%|████▌     | 4607/10000 [00:31<00:37, 144.84it/s]Running 10000 simulations.:  46%|████▌     | 4622/10000 [00:31<00:36, 145.37it/s]Running 10000 simulations.:  46%|████▋     | 4637/10000 [00:31<00:36, 145.39it/s]Running 10000 simulations.:  47%|████▋     | 4652/10000 [00:31<00:36, 145.95it/s]Running 10000 simulations.:  47%|████▋     | 4667/10000 [00:31<00:36, 146.48it/s]Running 10000 simulations.:  47%|████▋     | 4682/10000 [00:31<00:36, 147.26it/s]Running 10000 simulations.:  47%|████▋     | 4697/10000 [00:32<00:35, 147.50it/s]Running 10000 simulations.:  47%|████▋     | 4712/10000 [00:32<00:35, 147.90it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:32<00:35, 147.94it/s]Running 10000 simulations.:  47%|████▋     | 4742/10000 [00:32<00:35, 147.91it/s]Running 10000 simulations.:  48%|████▊     | 4757/10000 [00:32<00:35, 148.12it/s]Running 10000 simulations.:  48%|████▊     | 4772/10000 [00:32<00:35, 147.85it/s]Running 10000 simulations.:  48%|████▊     | 4787/10000 [00:32<00:35, 148.00it/s]Running 10000 simulations.:  48%|████▊     | 4802/10000 [00:32<00:35, 147.94it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:32<00:34, 148.09it/s]Running 10000 simulations.:  48%|████▊     | 4833/10000 [00:32<00:34, 151.46it/s]Running 10000 simulations.:  48%|████▊     | 4850/10000 [00:33<00:33, 155.88it/s]Running 10000 simulations.:  49%|████▊     | 4866/10000 [00:33<00:33, 153.90it/s]Running 10000 simulations.:  49%|████▉     | 4882/10000 [00:33<00:33, 152.25it/s]Running 10000 simulations.:  49%|████▉     | 4898/10000 [00:33<00:33, 150.73it/s]Running 10000 simulations.:  49%|████▉     | 4914/10000 [00:33<00:33, 150.20it/s]Running 10000 simulations.:  49%|████▉     | 4930/10000 [00:33<00:33, 150.09it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:33<00:33, 149.47it/s]Running 10000 simulations.:  50%|████▉     | 4961/10000 [00:33<00:33, 149.45it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:33<00:33, 149.35it/s]Running 10000 simulations.:  50%|████▉     | 4991/10000 [00:33<00:33, 148.80it/s]Running 10000 simulations.:  50%|█████     | 5006/10000 [00:34<00:33, 148.73it/s]Running 10000 simulations.:  50%|█████     | 5021/10000 [00:34<00:33, 148.38it/s]Running 10000 simulations.:  50%|█████     | 5036/10000 [00:34<00:33, 147.60it/s]Running 10000 simulations.:  51%|█████     | 5051/10000 [00:34<00:33, 147.94it/s]Running 10000 simulations.:  51%|█████     | 5066/10000 [00:34<00:33, 147.71it/s]Running 10000 simulations.:  51%|█████     | 5081/10000 [00:34<00:33, 147.61it/s]Running 10000 simulations.:  51%|█████     | 5096/10000 [00:34<00:33, 147.64it/s]Running 10000 simulations.:  51%|█████     | 5111/10000 [00:34<00:33, 147.59it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:34<00:32, 147.78it/s]Running 10000 simulations.:  51%|█████▏    | 5141/10000 [00:35<00:32, 148.00it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:35<00:32, 147.62it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:35<00:32, 147.65it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:35<00:32, 147.76it/s]Running 10000 simulations.:  52%|█████▏    | 5201/10000 [00:35<00:32, 147.94it/s]Running 10000 simulations.:  52%|█████▏    | 5216/10000 [00:35<00:32, 148.37it/s]Running 10000 simulations.:  52%|█████▏    | 5231/10000 [00:35<00:32, 148.08it/s]Running 10000 simulations.:  52%|█████▏    | 5246/10000 [00:35<00:32, 147.86it/s]Running 10000 simulations.:  53%|█████▎    | 5261/10000 [00:35<00:32, 147.98it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:35<00:31, 148.29it/s]Running 10000 simulations.:  53%|█████▎    | 5291/10000 [00:36<00:31, 148.47it/s]Running 10000 simulations.:  53%|█████▎    | 5306/10000 [00:36<00:31, 148.39it/s]Running 10000 simulations.:  53%|█████▎    | 5321/10000 [00:36<00:31, 148.07it/s]Running 10000 simulations.:  53%|█████▎    | 5336/10000 [00:36<00:31, 147.61it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:36<00:31, 147.11it/s]Running 10000 simulations.:  54%|█████▎    | 5366/10000 [00:36<00:31, 147.11it/s]Running 10000 simulations.:  54%|█████▍    | 5381/10000 [00:36<00:31, 147.48it/s]Running 10000 simulations.:  54%|█████▍    | 5396/10000 [00:36<00:31, 147.34it/s]Running 10000 simulations.:  54%|█████▍    | 5411/10000 [00:36<00:31, 148.02it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:36<00:30, 147.79it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:37<00:30, 148.03it/s]Running 10000 simulations.:  55%|█████▍    | 5456/10000 [00:37<00:30, 147.98it/s]Running 10000 simulations.:  55%|█████▍    | 5471/10000 [00:37<00:30, 148.19it/s]Running 10000 simulations.:  55%|█████▍    | 5486/10000 [00:37<00:30, 148.51it/s]Running 10000 simulations.:  55%|█████▌    | 5501/10000 [00:37<00:30, 148.89it/s]Running 10000 simulations.:  55%|█████▌    | 5516/10000 [00:37<00:30, 148.81it/s]Running 10000 simulations.:  55%|█████▌    | 5531/10000 [00:37<00:30, 148.54it/s]Running 10000 simulations.:  55%|█████▌    | 5546/10000 [00:37<00:29, 148.93it/s]Running 10000 simulations.:  56%|█████▌    | 5561/10000 [00:37<00:29, 149.09it/s]Running 10000 simulations.:  56%|█████▌    | 5576/10000 [00:37<00:29, 148.74it/s]Running 10000 simulations.:  56%|█████▌    | 5591/10000 [00:38<00:29, 148.27it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:38<00:29, 148.22it/s]Running 10000 simulations.:  56%|█████▌    | 5621/10000 [00:38<00:29, 147.82it/s]Running 10000 simulations.:  56%|█████▋    | 5636/10000 [00:38<00:29, 147.81it/s]Running 10000 simulations.:  57%|█████▋    | 5651/10000 [00:38<00:29, 147.62it/s]Running 10000 simulations.:  57%|█████▋    | 5666/10000 [00:38<00:29, 148.14it/s]Running 10000 simulations.:  57%|█████▋    | 5681/10000 [00:38<00:29, 148.33it/s]Running 10000 simulations.:  57%|█████▋    | 5696/10000 [00:38<00:29, 148.03it/s]Running 10000 simulations.:  57%|█████▋    | 5711/10000 [00:38<00:29, 147.73it/s]Running 10000 simulations.:  57%|█████▋    | 5726/10000 [00:38<00:29, 147.37it/s]Running 10000 simulations.:  57%|█████▋    | 5741/10000 [00:39<00:28, 147.25it/s]Running 10000 simulations.:  58%|█████▊    | 5756/10000 [00:39<00:28, 147.34it/s]Running 10000 simulations.:  58%|█████▊    | 5771/10000 [00:39<00:28, 147.94it/s]Running 10000 simulations.:  58%|█████▊    | 5786/10000 [00:39<00:28, 148.14it/s]Running 10000 simulations.:  58%|█████▊    | 5801/10000 [00:39<00:28, 148.02it/s]Running 10000 simulations.:  58%|█████▊    | 5816/10000 [00:39<00:28, 147.52it/s]Running 10000 simulations.:  58%|█████▊    | 5831/10000 [00:39<00:28, 147.27it/s]Running 10000 simulations.:  58%|█████▊    | 5846/10000 [00:39<00:28, 147.49it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:39<00:27, 147.82it/s]Running 10000 simulations.:  59%|█████▉    | 5876/10000 [00:39<00:27, 148.06it/s]Running 10000 simulations.:  59%|█████▉    | 5891/10000 [00:40<00:27, 148.23it/s]Running 10000 simulations.:  59%|█████▉    | 5906/10000 [00:40<00:27, 148.05it/s]Running 10000 simulations.:  59%|█████▉    | 5921/10000 [00:40<00:27, 148.43it/s]Running 10000 simulations.:  59%|█████▉    | 5936/10000 [00:40<00:27, 148.53it/s]Running 10000 simulations.:  60%|█████▉    | 5951/10000 [00:40<00:27, 147.65it/s]Running 10000 simulations.:  60%|█████▉    | 5966/10000 [00:40<00:27, 147.43it/s]Running 10000 simulations.:  60%|█████▉    | 5981/10000 [00:40<00:27, 146.93it/s]Running 10000 simulations.:  60%|█████▉    | 5996/10000 [00:40<00:27, 146.88it/s]Running 10000 simulations.:  60%|██████    | 6011/10000 [00:40<00:27, 147.17it/s]Running 10000 simulations.:  60%|██████    | 6026/10000 [00:40<00:27, 147.14it/s]Running 10000 simulations.:  60%|██████    | 6041/10000 [00:41<00:26, 146.80it/s]Running 10000 simulations.:  61%|██████    | 6056/10000 [00:41<00:26, 146.62it/s]Running 10000 simulations.:  61%|██████    | 6071/10000 [00:41<00:26, 147.15it/s]Running 10000 simulations.:  61%|██████    | 6086/10000 [00:41<00:26, 147.21it/s]Running 10000 simulations.:  61%|██████    | 6101/10000 [00:41<00:26, 147.44it/s]Running 10000 simulations.:  61%|██████    | 6116/10000 [00:41<00:26, 147.50it/s]Running 10000 simulations.:  61%|██████▏   | 6131/10000 [00:41<00:26, 147.18it/s]Running 10000 simulations.:  61%|██████▏   | 6146/10000 [00:41<00:26, 147.69it/s]Running 10000 simulations.:  62%|██████▏   | 6161/10000 [00:41<00:26, 147.54it/s]Running 10000 simulations.:  62%|██████▏   | 6176/10000 [00:42<00:25, 147.46it/s]Running 10000 simulations.:  62%|██████▏   | 6191/10000 [00:42<00:25, 147.95it/s]Running 10000 simulations.:  62%|██████▏   | 6206/10000 [00:42<00:25, 147.92it/s]Running 10000 simulations.:  62%|██████▏   | 6221/10000 [00:42<00:25, 147.62it/s]Running 10000 simulations.:  62%|██████▏   | 6236/10000 [00:42<00:25, 147.04it/s]Running 10000 simulations.:  63%|██████▎   | 6251/10000 [00:42<00:25, 147.73it/s]Running 10000 simulations.:  63%|██████▎   | 6266/10000 [00:42<00:25, 147.92it/s]Running 10000 simulations.:  63%|██████▎   | 6281/10000 [00:42<00:25, 147.91it/s]Running 10000 simulations.:  63%|██████▎   | 6296/10000 [00:42<00:24, 148.41it/s]Running 10000 simulations.:  63%|██████▎   | 6311/10000 [00:42<00:24, 148.78it/s]Running 10000 simulations.:  63%|██████▎   | 6326/10000 [00:43<00:24, 148.85it/s]Running 10000 simulations.:  63%|██████▎   | 6341/10000 [00:43<00:24, 149.06it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:43<00:24, 148.83it/s]Running 10000 simulations.:  64%|██████▎   | 6371/10000 [00:43<00:24, 148.99it/s]Running 10000 simulations.:  64%|██████▍   | 6386/10000 [00:43<00:24, 148.84it/s]Running 10000 simulations.:  64%|██████▍   | 6401/10000 [00:43<00:24, 148.09it/s]Running 10000 simulations.:  64%|██████▍   | 6416/10000 [00:43<00:24, 147.44it/s]Running 10000 simulations.:  64%|██████▍   | 6431/10000 [00:43<00:24, 147.35it/s]Running 10000 simulations.:  64%|██████▍   | 6447/10000 [00:43<00:23, 148.33it/s]Running 10000 simulations.:  65%|██████▍   | 6462/10000 [00:43<00:23, 148.76it/s]Running 10000 simulations.:  65%|██████▍   | 6477/10000 [00:44<00:23, 148.12it/s]Running 10000 simulations.:  65%|██████▍   | 6492/10000 [00:44<00:23, 148.14it/s]Running 10000 simulations.:  65%|██████▌   | 6507/10000 [00:44<00:23, 148.42it/s]Running 10000 simulations.:  65%|██████▌   | 6522/10000 [00:44<00:23, 148.87it/s]Running 10000 simulations.:  65%|██████▌   | 6537/10000 [00:44<00:23, 148.93it/s]Running 10000 simulations.:  66%|██████▌   | 6552/10000 [00:44<00:23, 148.79it/s]Running 10000 simulations.:  66%|██████▌   | 6567/10000 [00:44<00:23, 148.05it/s]Running 10000 simulations.:  66%|██████▌   | 6582/10000 [00:44<00:23, 147.77it/s]Running 10000 simulations.:  66%|██████▌   | 6597/10000 [00:44<00:23, 147.49it/s]Running 10000 simulations.:  66%|██████▌   | 6612/10000 [00:44<00:22, 147.38it/s]Running 10000 simulations.:  66%|██████▋   | 6627/10000 [00:45<00:22, 147.41it/s]Running 10000 simulations.:  66%|██████▋   | 6642/10000 [00:45<00:22, 147.63it/s]Running 10000 simulations.:  67%|██████▋   | 6657/10000 [00:45<00:22, 147.69it/s]Running 10000 simulations.:  67%|██████▋   | 6672/10000 [00:45<00:22, 148.09it/s]Running 10000 simulations.:  67%|██████▋   | 6687/10000 [00:45<00:22, 148.12it/s]Running 10000 simulations.:  67%|██████▋   | 6702/10000 [00:45<00:22, 147.89it/s]Running 10000 simulations.:  67%|██████▋   | 6717/10000 [00:45<00:22, 148.34it/s]Running 10000 simulations.:  67%|██████▋   | 6732/10000 [00:45<00:22, 148.54it/s]Running 10000 simulations.:  67%|██████▋   | 6748/10000 [00:45<00:21, 149.03it/s]Running 10000 simulations.:  68%|██████▊   | 6763/10000 [00:45<00:21, 147.41it/s]Running 10000 simulations.:  68%|██████▊   | 6778/10000 [00:46<00:22, 145.66it/s]Running 10000 simulations.:  68%|██████▊   | 6793/10000 [00:46<00:22, 144.77it/s]Running 10000 simulations.:  68%|██████▊   | 6808/10000 [00:46<00:21, 145.96it/s]Running 10000 simulations.:  68%|██████▊   | 6823/10000 [00:46<00:21, 146.72it/s]Running 10000 simulations.:  68%|██████▊   | 6838/10000 [00:46<00:21, 147.49it/s]Running 10000 simulations.:  69%|██████▊   | 6853/10000 [00:46<00:21, 148.08it/s]Running 10000 simulations.:  69%|██████▊   | 6868/10000 [00:46<00:21, 148.24it/s]Running 10000 simulations.:  69%|██████▉   | 6883/10000 [00:46<00:21, 148.34it/s]Running 10000 simulations.:  69%|██████▉   | 6898/10000 [00:46<00:20, 148.14it/s]Running 10000 simulations.:  69%|██████▉   | 6913/10000 [00:46<00:20, 147.75it/s]Running 10000 simulations.:  69%|██████▉   | 6928/10000 [00:47<00:20, 147.32it/s]Running 10000 simulations.:  69%|██████▉   | 6943/10000 [00:47<00:20, 147.33it/s]Running 10000 simulations.:  70%|██████▉   | 6958/10000 [00:47<00:20, 147.84it/s]Running 10000 simulations.:  70%|██████▉   | 6973/10000 [00:47<00:20, 148.38it/s]Running 10000 simulations.:  70%|██████▉   | 6988/10000 [00:47<00:20, 148.37it/s]Running 10000 simulations.:  70%|███████   | 7003/10000 [00:47<00:20, 148.47it/s]Running 10000 simulations.:  70%|███████   | 7018/10000 [00:47<00:20, 148.29it/s]Running 10000 simulations.:  70%|███████   | 7033/10000 [00:47<00:20, 145.31it/s]Running 10000 simulations.:  70%|███████   | 7048/10000 [00:47<00:20, 145.78it/s]Running 10000 simulations.:  71%|███████   | 7063/10000 [00:48<00:20, 146.35it/s]Running 10000 simulations.:  71%|███████   | 7078/10000 [00:48<00:19, 146.70it/s]Running 10000 simulations.:  71%|███████   | 7093/10000 [00:48<00:19, 146.86it/s]Running 10000 simulations.:  71%|███████   | 7108/10000 [00:48<00:19, 146.44it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:48<00:19, 146.68it/s]Running 10000 simulations.:  71%|███████▏  | 7138/10000 [00:48<00:19, 147.49it/s]Running 10000 simulations.:  72%|███████▏  | 7153/10000 [00:48<00:19, 148.04it/s]Running 10000 simulations.:  72%|███████▏  | 7168/10000 [00:48<00:19, 148.17it/s]Running 10000 simulations.:  72%|███████▏  | 7183/10000 [00:48<00:18, 148.58it/s]Running 10000 simulations.:  72%|███████▏  | 7198/10000 [00:48<00:18, 148.78it/s]Running 10000 simulations.:  72%|███████▏  | 7213/10000 [00:49<00:18, 148.19it/s]Running 10000 simulations.:  72%|███████▏  | 7228/10000 [00:49<00:18, 148.41it/s]Running 10000 simulations.:  72%|███████▏  | 7243/10000 [00:49<00:18, 148.78it/s]Running 10000 simulations.:  73%|███████▎  | 7258/10000 [00:49<00:18, 148.99it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:49<00:18, 148.44it/s]Running 10000 simulations.:  73%|███████▎  | 7288/10000 [00:49<00:18, 147.77it/s]Running 10000 simulations.:  73%|███████▎  | 7303/10000 [00:49<00:18, 147.69it/s]Running 10000 simulations.:  73%|███████▎  | 7318/10000 [00:49<00:18, 147.42it/s]Running 10000 simulations.:  73%|███████▎  | 7333/10000 [00:49<00:18, 148.14it/s]Running 10000 simulations.:  73%|███████▎  | 7348/10000 [00:49<00:17, 148.42it/s]Running 10000 simulations.:  74%|███████▎  | 7363/10000 [00:50<00:17, 148.24it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:50<00:17, 148.46it/s]Running 10000 simulations.:  74%|███████▍  | 7393/10000 [00:50<00:17, 148.57it/s]Running 10000 simulations.:  74%|███████▍  | 7408/10000 [00:50<00:17, 148.88it/s]Running 10000 simulations.:  74%|███████▍  | 7423/10000 [00:50<00:17, 149.12it/s]Running 10000 simulations.:  74%|███████▍  | 7438/10000 [00:50<00:17, 149.09it/s]Running 10000 simulations.:  75%|███████▍  | 7453/10000 [00:50<00:17, 148.87it/s]Running 10000 simulations.:  75%|███████▍  | 7468/10000 [00:50<00:17, 148.73it/s]Running 10000 simulations.:  75%|███████▍  | 7483/10000 [00:50<00:16, 148.13it/s]Running 10000 simulations.:  75%|███████▍  | 7498/10000 [00:50<00:16, 147.76it/s]Running 10000 simulations.:  75%|███████▌  | 7513/10000 [00:51<00:16, 147.82it/s]Running 10000 simulations.:  75%|███████▌  | 7528/10000 [00:51<00:16, 148.31it/s]Running 10000 simulations.:  75%|███████▌  | 7543/10000 [00:51<00:16, 148.09it/s]Running 10000 simulations.:  76%|███████▌  | 7558/10000 [00:51<00:16, 148.35it/s]Running 10000 simulations.:  76%|███████▌  | 7573/10000 [00:51<00:16, 148.53it/s]Running 10000 simulations.:  76%|███████▌  | 7588/10000 [00:51<00:16, 148.51it/s]Running 10000 simulations.:  76%|███████▌  | 7603/10000 [00:51<00:16, 147.98it/s]Running 10000 simulations.:  76%|███████▌  | 7618/10000 [00:51<00:16, 147.41it/s]Running 10000 simulations.:  76%|███████▋  | 7633/10000 [00:51<00:16, 144.21it/s]Running 10000 simulations.:  76%|███████▋  | 7648/10000 [00:51<00:16, 142.04it/s]Running 10000 simulations.:  77%|███████▋  | 7663/10000 [00:52<00:16, 141.03it/s]Running 10000 simulations.:  77%|███████▋  | 7678/10000 [00:52<00:16, 141.23it/s]Running 10000 simulations.:  77%|███████▋  | 7693/10000 [00:52<00:16, 140.45it/s]Running 10000 simulations.:  77%|███████▋  | 7708/10000 [00:52<00:16, 139.33it/s]Running 10000 simulations.:  77%|███████▋  | 7722/10000 [00:52<00:16, 138.54it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:52<00:16, 138.56it/s]Running 10000 simulations.:  78%|███████▊  | 7751/10000 [00:52<00:16, 139.03it/s]Running 10000 simulations.:  78%|███████▊  | 7765/10000 [00:52<00:16, 138.93it/s]Running 10000 simulations.:  78%|███████▊  | 7779/10000 [00:52<00:15, 139.25it/s]Running 10000 simulations.:  78%|███████▊  | 7793/10000 [00:53<00:15, 138.87it/s]Running 10000 simulations.:  78%|███████▊  | 7808/10000 [00:53<00:15, 139.62it/s]Running 10000 simulations.:  78%|███████▊  | 7823/10000 [00:53<00:15, 139.95it/s]Running 10000 simulations.:  78%|███████▊  | 7837/10000 [00:53<00:15, 139.88it/s]Running 10000 simulations.:  79%|███████▊  | 7851/10000 [00:53<00:15, 139.45it/s]Running 10000 simulations.:  79%|███████▊  | 7865/10000 [00:53<00:15, 139.35it/s]Running 10000 simulations.:  79%|███████▉  | 7880/10000 [00:53<00:15, 139.84it/s]Running 10000 simulations.:  79%|███████▉  | 7895/10000 [00:53<00:14, 140.80it/s]Running 10000 simulations.:  79%|███████▉  | 7910/10000 [00:53<00:14, 140.70it/s]Running 10000 simulations.:  79%|███████▉  | 7925/10000 [00:53<00:14, 140.36it/s]Running 10000 simulations.:  79%|███████▉  | 7940/10000 [00:54<00:14, 138.31it/s]Running 10000 simulations.:  80%|███████▉  | 7954/10000 [00:54<00:14, 138.43it/s]Running 10000 simulations.:  80%|███████▉  | 7968/10000 [00:54<00:14, 138.26it/s]Running 10000 simulations.:  80%|███████▉  | 7982/10000 [00:54<00:14, 138.12it/s]Running 10000 simulations.:  80%|███████▉  | 7997/10000 [00:54<00:14, 138.64it/s]Running 10000 simulations.:  80%|████████  | 8011/10000 [00:54<00:14, 138.64it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:54<00:14, 137.64it/s]Running 10000 simulations.:  80%|████████  | 8039/10000 [00:54<00:14, 137.81it/s]Running 10000 simulations.:  81%|████████  | 8054/10000 [00:54<00:14, 138.44it/s]Running 10000 simulations.:  81%|████████  | 8068/10000 [00:54<00:13, 138.43it/s]Running 10000 simulations.:  81%|████████  | 8082/10000 [00:55<00:13, 138.43it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:55<00:13, 139.14it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:55<00:13, 139.30it/s]Running 10000 simulations.:  81%|████████▏ | 8125/10000 [00:55<00:13, 139.40it/s]Running 10000 simulations.:  81%|████████▏ | 8139/10000 [00:55<00:13, 139.16it/s]Running 10000 simulations.:  82%|████████▏ | 8153/10000 [00:55<00:13, 138.84it/s]Running 10000 simulations.:  82%|████████▏ | 8167/10000 [00:55<00:13, 138.79it/s]Running 10000 simulations.:  82%|████████▏ | 8181/10000 [00:55<00:13, 138.94it/s]Running 10000 simulations.:  82%|████████▏ | 8195/10000 [00:55<00:13, 138.80it/s]Running 10000 simulations.:  82%|████████▏ | 8209/10000 [00:56<00:12, 138.93it/s]Running 10000 simulations.:  82%|████████▏ | 8224/10000 [00:56<00:12, 140.22it/s]Running 10000 simulations.:  82%|████████▏ | 8239/10000 [00:56<00:12, 142.02it/s]Running 10000 simulations.:  83%|████████▎ | 8254/10000 [00:56<00:12, 143.22it/s]Running 10000 simulations.:  83%|████████▎ | 8269/10000 [00:56<00:12, 144.18it/s]Running 10000 simulations.:  83%|████████▎ | 8284/10000 [00:56<00:11, 145.45it/s]Running 10000 simulations.:  83%|████████▎ | 8299/10000 [00:56<00:11, 146.15it/s]Running 10000 simulations.:  83%|████████▎ | 8314/10000 [00:56<00:11, 146.17it/s]Running 10000 simulations.:  83%|████████▎ | 8329/10000 [00:56<00:11, 140.03it/s]Running 10000 simulations.:  83%|████████▎ | 8344/10000 [00:56<00:11, 142.11it/s]Running 10000 simulations.:  84%|████████▎ | 8359/10000 [00:57<00:11, 143.28it/s]Running 10000 simulations.:  84%|████████▎ | 8374/10000 [00:57<00:11, 144.24it/s]Running 10000 simulations.:  84%|████████▍ | 8389/10000 [00:57<00:11, 145.36it/s]Running 10000 simulations.:  84%|████████▍ | 8404/10000 [00:57<00:10, 145.92it/s]Running 10000 simulations.:  84%|████████▍ | 8419/10000 [00:57<00:10, 146.40it/s]Running 10000 simulations.:  84%|████████▍ | 8434/10000 [00:57<00:10, 147.21it/s]Running 10000 simulations.:  84%|████████▍ | 8449/10000 [00:57<00:10, 146.77it/s]Running 10000 simulations.:  85%|████████▍ | 8464/10000 [00:57<00:10, 146.52it/s]Running 10000 simulations.:  85%|████████▍ | 8479/10000 [00:57<00:10, 146.29it/s]Running 10000 simulations.:  85%|████████▍ | 8494/10000 [00:57<00:10, 147.16it/s]Running 10000 simulations.:  85%|████████▌ | 8509/10000 [00:58<00:10, 147.29it/s]Running 10000 simulations.:  85%|████████▌ | 8524/10000 [00:58<00:10, 146.87it/s]Running 10000 simulations.:  85%|████████▌ | 8539/10000 [00:58<00:09, 146.74it/s]Running 10000 simulations.:  86%|████████▌ | 8554/10000 [00:58<00:09, 146.45it/s]Running 10000 simulations.:  86%|████████▌ | 8569/10000 [00:58<00:09, 146.30it/s]Running 10000 simulations.:  86%|████████▌ | 8584/10000 [00:58<00:09, 146.69it/s]Running 10000 simulations.:  86%|████████▌ | 8599/10000 [00:58<00:09, 147.13it/s]Running 10000 simulations.:  86%|████████▌ | 8614/10000 [00:58<00:09, 147.35it/s]Running 10000 simulations.:  86%|████████▋ | 8629/10000 [00:58<00:09, 147.02it/s]Running 10000 simulations.:  86%|████████▋ | 8644/10000 [00:58<00:09, 145.48it/s]Running 10000 simulations.:  87%|████████▋ | 8659/10000 [00:59<00:09, 146.11it/s]Running 10000 simulations.:  87%|████████▋ | 8674/10000 [00:59<00:09, 147.10it/s]Running 10000 simulations.:  87%|████████▋ | 8689/10000 [00:59<00:08, 147.84it/s]Running 10000 simulations.:  87%|████████▋ | 8705/10000 [00:59<00:08, 148.53it/s]Running 10000 simulations.:  87%|████████▋ | 8721/10000 [00:59<00:08, 149.24it/s]Running 10000 simulations.:  87%|████████▋ | 8737/10000 [00:59<00:08, 149.48it/s]Running 10000 simulations.:  88%|████████▊ | 8752/10000 [00:59<00:08, 148.71it/s]Running 10000 simulations.:  88%|████████▊ | 8767/10000 [00:59<00:08, 148.37it/s]Running 10000 simulations.:  88%|████████▊ | 8782/10000 [00:59<00:08, 148.22it/s]Running 10000 simulations.:  88%|████████▊ | 8797/10000 [01:00<00:08, 148.67it/s]Running 10000 simulations.:  88%|████████▊ | 8812/10000 [01:00<00:07, 148.98it/s]Running 10000 simulations.:  88%|████████▊ | 8828/10000 [01:00<00:07, 149.31it/s]Running 10000 simulations.:  88%|████████▊ | 8843/10000 [01:00<00:07, 148.72it/s]Running 10000 simulations.:  89%|████████▊ | 8858/10000 [01:00<00:07, 147.86it/s]Running 10000 simulations.:  89%|████████▊ | 8873/10000 [01:00<00:07, 147.28it/s]Running 10000 simulations.:  89%|████████▉ | 8888/10000 [01:00<00:07, 147.26it/s]Running 10000 simulations.:  89%|████████▉ | 8903/10000 [01:00<00:07, 147.66it/s]Running 10000 simulations.:  89%|████████▉ | 8918/10000 [01:00<00:07, 147.75it/s]Running 10000 simulations.:  89%|████████▉ | 8933/10000 [01:00<00:07, 147.75it/s]Running 10000 simulations.:  89%|████████▉ | 8948/10000 [01:01<00:07, 147.33it/s]Running 10000 simulations.:  90%|████████▉ | 8963/10000 [01:01<00:07, 147.06it/s]Running 10000 simulations.:  90%|████████▉ | 8978/10000 [01:01<00:06, 146.69it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [01:01<00:06, 147.33it/s]Running 10000 simulations.:  90%|█████████ | 9008/10000 [01:01<00:06, 147.47it/s]Running 10000 simulations.:  90%|█████████ | 9023/10000 [01:01<00:06, 147.58it/s]Running 10000 simulations.:  90%|█████████ | 9038/10000 [01:01<00:06, 147.45it/s]Running 10000 simulations.:  91%|█████████ | 9053/10000 [01:01<00:06, 147.73it/s]Running 10000 simulations.:  91%|█████████ | 9068/10000 [01:01<00:06, 147.66it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [01:01<00:06, 147.45it/s]Running 10000 simulations.:  91%|█████████ | 9098/10000 [01:02<00:06, 147.12it/s]Running 10000 simulations.:  91%|█████████ | 9113/10000 [01:02<00:06, 147.62it/s]Running 10000 simulations.:  91%|█████████▏| 9128/10000 [01:02<00:05, 147.67it/s]Running 10000 simulations.:  91%|█████████▏| 9143/10000 [01:02<00:05, 147.77it/s]Running 10000 simulations.:  92%|█████████▏| 9158/10000 [01:02<00:05, 147.89it/s]Running 10000 simulations.:  92%|█████████▏| 9173/10000 [01:02<00:05, 147.85it/s]Running 10000 simulations.:  92%|█████████▏| 9188/10000 [01:02<00:05, 147.65it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [01:02<00:05, 147.77it/s]Running 10000 simulations.:  92%|█████████▏| 9218/10000 [01:02<00:05, 148.22it/s]Running 10000 simulations.:  92%|█████████▏| 9234/10000 [01:02<00:05, 148.76it/s]Running 10000 simulations.:  92%|█████████▎| 9250/10000 [01:03<00:05, 149.25it/s]Running 10000 simulations.:  93%|█████████▎| 9266/10000 [01:03<00:04, 149.55it/s]Running 10000 simulations.:  93%|█████████▎| 9281/10000 [01:03<00:04, 149.34it/s]Running 10000 simulations.:  93%|█████████▎| 9296/10000 [01:03<00:04, 149.32it/s]Running 10000 simulations.:  93%|█████████▎| 9311/10000 [01:03<00:04, 149.10it/s]Running 10000 simulations.:  93%|█████████▎| 9326/10000 [01:03<00:04, 149.10it/s]Running 10000 simulations.:  93%|█████████▎| 9341/10000 [01:03<00:04, 148.60it/s]Running 10000 simulations.:  94%|█████████▎| 9356/10000 [01:03<00:04, 148.23it/s]Running 10000 simulations.:  94%|█████████▎| 9371/10000 [01:03<00:04, 148.58it/s]Running 10000 simulations.:  94%|█████████▍| 9388/10000 [01:03<00:04, 152.90it/s]Running 10000 simulations.:  94%|█████████▍| 9404/10000 [01:04<00:03, 154.10it/s]Running 10000 simulations.:  94%|█████████▍| 9420/10000 [01:04<00:03, 152.46it/s]Running 10000 simulations.:  94%|█████████▍| 9436/10000 [01:04<00:03, 151.55it/s]Running 10000 simulations.:  95%|█████████▍| 9452/10000 [01:04<00:03, 151.07it/s]Running 10000 simulations.:  95%|█████████▍| 9468/10000 [01:04<00:03, 150.71it/s]Running 10000 simulations.:  95%|█████████▍| 9484/10000 [01:04<00:03, 150.53it/s]Running 10000 simulations.:  95%|█████████▌| 9500/10000 [01:04<00:03, 149.25it/s]Running 10000 simulations.:  95%|█████████▌| 9515/10000 [01:04<00:03, 148.62it/s]Running 10000 simulations.:  95%|█████████▌| 9530/10000 [01:04<00:03, 148.16it/s]Running 10000 simulations.:  95%|█████████▌| 9545/10000 [01:05<00:03, 148.26it/s]Running 10000 simulations.:  96%|█████████▌| 9560/10000 [01:05<00:02, 148.27it/s]Running 10000 simulations.:  96%|█████████▌| 9576/10000 [01:05<00:02, 148.81it/s]Running 10000 simulations.:  96%|█████████▌| 9591/10000 [01:05<00:02, 148.88it/s]Running 10000 simulations.:  96%|█████████▌| 9606/10000 [01:05<00:02, 149.02it/s]Running 10000 simulations.:  96%|█████████▌| 9622/10000 [01:05<00:02, 149.55it/s]Running 10000 simulations.:  96%|█████████▋| 9637/10000 [01:05<00:02, 149.68it/s]Running 10000 simulations.:  97%|█████████▋| 9652/10000 [01:05<00:02, 149.20it/s]Running 10000 simulations.:  97%|█████████▋| 9667/10000 [01:05<00:02, 148.38it/s]Running 10000 simulations.:  97%|█████████▋| 9682/10000 [01:05<00:02, 148.72it/s]Running 10000 simulations.:  97%|█████████▋| 9697/10000 [01:06<00:02, 148.22it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [01:06<00:01, 147.86it/s]Running 10000 simulations.:  97%|█████████▋| 9727/10000 [01:06<00:01, 148.05it/s]Running 10000 simulations.:  97%|█████████▋| 9742/10000 [01:06<00:01, 148.24it/s]Running 10000 simulations.:  98%|█████████▊| 9757/10000 [01:06<00:01, 148.29it/s]Running 10000 simulations.:  98%|█████████▊| 9773/10000 [01:06<00:01, 148.91it/s]Running 10000 simulations.:  98%|█████████▊| 9788/10000 [01:06<00:01, 148.98it/s]Running 10000 simulations.:  98%|█████████▊| 9803/10000 [01:06<00:01, 148.89it/s]Running 10000 simulations.:  98%|█████████▊| 9818/10000 [01:06<00:01, 149.18it/s]Running 10000 simulations.:  98%|█████████▊| 9834/10000 [01:06<00:01, 149.57it/s]Running 10000 simulations.:  98%|█████████▊| 9850/10000 [01:07<00:01, 149.92it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [01:07<00:00, 149.39it/s]Running 10000 simulations.:  99%|█████████▉| 9880/10000 [01:07<00:00, 148.91it/s]Running 10000 simulations.:  99%|█████████▉| 9895/10000 [01:07<00:00, 149.10it/s]Running 10000 simulations.:  99%|█████████▉| 9910/10000 [01:07<00:00, 148.92it/s]Running 10000 simulations.:  99%|█████████▉| 9925/10000 [01:07<00:00, 149.01it/s]Running 10000 simulations.:  99%|█████████▉| 9940/10000 [01:07<00:00, 149.18it/s]Running 10000 simulations.: 100%|█████████▉| 9955/10000 [01:07<00:00, 149.14it/s]Running 10000 simulations.: 100%|█████████▉| 9970/10000 [01:07<00:00, 149.16it/s]Running 10000 simulations.: 100%|█████████▉| 9985/10000 [01:07<00:00, 148.94it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:08<00:00, 149.05it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:08<00:00, 146.84it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 252.54it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 252.53it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:39, 252.30it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:39, 252.97it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:38, 253.62it/s]Running 10000 simulations.:   2%|▏         | 156/10000 [00:00<00:38, 252.74it/s]Running 10000 simulations.:   2%|▏         | 181/10000 [00:00<00:39, 251.02it/s]Running 10000 simulations.:   2%|▏         | 206/10000 [00:00<00:39, 249.61it/s]Running 10000 simulations.:   2%|▏         | 231/10000 [00:00<00:39, 248.33it/s]Running 10000 simulations.:   3%|▎         | 256/10000 [00:01<00:39, 247.50it/s]Running 10000 simulations.:   3%|▎         | 281/10000 [00:01<00:39, 246.57it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:39, 245.66it/s]Running 10000 simulations.:   3%|▎         | 331/10000 [00:01<00:39, 244.81it/s]Running 10000 simulations.:   4%|▎         | 356/10000 [00:01<00:39, 246.19it/s]Running 10000 simulations.:   4%|▍         | 381/10000 [00:01<00:38, 247.27it/s]Running 10000 simulations.:   4%|▍         | 406/10000 [00:01<00:38, 246.57it/s]Running 10000 simulations.:   4%|▍         | 431/10000 [00:01<00:38, 246.97it/s]Running 10000 simulations.:   5%|▍         | 456/10000 [00:01<00:38, 247.25it/s]Running 10000 simulations.:   5%|▍         | 481/10000 [00:01<00:38, 246.29it/s]Running 10000 simulations.:   5%|▌         | 506/10000 [00:02<00:38, 246.47it/s]Running 10000 simulations.:   5%|▌         | 531/10000 [00:02<00:38, 245.02it/s]Running 10000 simulations.:   6%|▌         | 556/10000 [00:02<00:38, 244.18it/s]Running 10000 simulations.:   6%|▌         | 581/10000 [00:02<00:38, 243.99it/s]Running 10000 simulations.:   6%|▌         | 606/10000 [00:02<00:38, 244.22it/s]Running 10000 simulations.:   6%|▋         | 631/10000 [00:02<00:38, 243.71it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:02<00:38, 244.06it/s]Running 10000 simulations.:   7%|▋         | 681/10000 [00:02<00:38, 244.61it/s]Running 10000 simulations.:   7%|▋         | 706/10000 [00:02<00:38, 244.37it/s]Running 10000 simulations.:   7%|▋         | 731/10000 [00:02<00:37, 244.91it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:03<00:37, 243.55it/s]Running 10000 simulations.:   8%|▊         | 781/10000 [00:03<00:38, 242.27it/s]Running 10000 simulations.:   8%|▊         | 806/10000 [00:03<00:38, 241.69it/s]Running 10000 simulations.:   8%|▊         | 831/10000 [00:03<00:37, 241.62it/s]Running 10000 simulations.:   9%|▊         | 856/10000 [00:03<00:37, 241.23it/s]Running 10000 simulations.:   9%|▉         | 881/10000 [00:03<00:37, 241.61it/s]Running 10000 simulations.:   9%|▉         | 906/10000 [00:03<00:37, 242.98it/s]Running 10000 simulations.:   9%|▉         | 931/10000 [00:03<00:37, 244.43it/s]Running 10000 simulations.:  10%|▉         | 956/10000 [00:03<00:36, 244.93it/s]Running 10000 simulations.:  10%|▉         | 981/10000 [00:03<00:36, 245.11it/s]Running 10000 simulations.:  10%|█         | 1006/10000 [00:04<00:36, 244.22it/s]Running 10000 simulations.:  10%|█         | 1031/10000 [00:04<00:36, 243.35it/s]Running 10000 simulations.:  11%|█         | 1056/10000 [00:04<00:36, 242.30it/s]Running 10000 simulations.:  11%|█         | 1081/10000 [00:04<00:37, 240.80it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:04<00:36, 241.55it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:04<00:36, 242.14it/s]Running 10000 simulations.:  12%|█▏        | 1156/10000 [00:04<00:36, 242.64it/s]Running 10000 simulations.:  12%|█▏        | 1181/10000 [00:04<00:36, 242.07it/s]Running 10000 simulations.:  12%|█▏        | 1206/10000 [00:04<00:36, 241.46it/s]Running 10000 simulations.:  12%|█▏        | 1231/10000 [00:05<00:36, 241.18it/s]Running 10000 simulations.:  13%|█▎        | 1256/10000 [00:05<00:36, 240.05it/s]Running 10000 simulations.:  13%|█▎        | 1281/10000 [00:05<00:36, 239.81it/s]Running 10000 simulations.:  13%|█▎        | 1306/10000 [00:05<00:36, 240.58it/s]Running 10000 simulations.:  13%|█▎        | 1331/10000 [00:05<00:36, 239.89it/s]Running 10000 simulations.:  14%|█▎        | 1355/10000 [00:05<00:36, 239.65it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:05<00:35, 240.37it/s]Running 10000 simulations.:  14%|█▍        | 1405/10000 [00:05<00:35, 241.05it/s]Running 10000 simulations.:  14%|█▍        | 1430/10000 [00:05<00:35, 242.30it/s]Running 10000 simulations.:  15%|█▍        | 1455/10000 [00:05<00:35, 242.44it/s]Running 10000 simulations.:  15%|█▍        | 1480/10000 [00:06<00:35, 242.84it/s]Running 10000 simulations.:  15%|█▌        | 1505/10000 [00:06<00:34, 242.79it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:06<00:35, 241.67it/s]Running 10000 simulations.:  16%|█▌        | 1555/10000 [00:06<00:34, 241.35it/s]Running 10000 simulations.:  16%|█▌        | 1580/10000 [00:06<00:34, 241.62it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:06<00:34, 241.20it/s]Running 10000 simulations.:  16%|█▋        | 1630/10000 [00:06<00:34, 241.90it/s]Running 10000 simulations.:  17%|█▋        | 1655/10000 [00:06<00:34, 241.49it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:06<00:34, 241.38it/s]Running 10000 simulations.:  17%|█▋        | 1705/10000 [00:06<00:34, 241.77it/s]Running 10000 simulations.:  17%|█▋        | 1730/10000 [00:07<00:34, 241.28it/s]Running 10000 simulations.:  18%|█▊        | 1755/10000 [00:07<00:34, 240.93it/s]Running 10000 simulations.:  18%|█▊        | 1780/10000 [00:07<00:34, 240.47it/s]Running 10000 simulations.:  18%|█▊        | 1805/10000 [00:07<00:34, 239.79it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:07<00:34, 239.51it/s]Running 10000 simulations.:  19%|█▊        | 1853/10000 [00:07<00:34, 239.47it/s]Running 10000 simulations.:  19%|█▉        | 1877/10000 [00:07<00:33, 239.60it/s]Running 10000 simulations.:  19%|█▉        | 1901/10000 [00:07<00:33, 239.57it/s]Running 10000 simulations.:  19%|█▉        | 1925/10000 [00:07<00:33, 239.05it/s]Running 10000 simulations.:  19%|█▉        | 1949/10000 [00:08<00:33, 239.07it/s]Running 10000 simulations.:  20%|█▉        | 1973/10000 [00:08<00:33, 239.18it/s]Running 10000 simulations.:  20%|█▉        | 1998/10000 [00:08<00:33, 240.84it/s]Running 10000 simulations.:  20%|██        | 2023/10000 [00:08<00:33, 241.33it/s]Running 10000 simulations.:  20%|██        | 2048/10000 [00:08<00:33, 238.37it/s]Running 10000 simulations.:  21%|██        | 2072/10000 [00:08<00:33, 238.02it/s]Running 10000 simulations.:  21%|██        | 2096/10000 [00:08<00:33, 237.60it/s]Running 10000 simulations.:  21%|██        | 2120/10000 [00:08<00:33, 237.54it/s]Running 10000 simulations.:  21%|██▏       | 2144/10000 [00:08<00:33, 237.53it/s]Running 10000 simulations.:  22%|██▏       | 2168/10000 [00:08<00:32, 237.63it/s]Running 10000 simulations.:  22%|██▏       | 2193/10000 [00:09<00:32, 238.48it/s]Running 10000 simulations.:  22%|██▏       | 2217/10000 [00:09<00:32, 238.88it/s]Running 10000 simulations.:  22%|██▏       | 2242/10000 [00:09<00:32, 240.40it/s]Running 10000 simulations.:  23%|██▎       | 2267/10000 [00:09<00:32, 240.78it/s]Running 10000 simulations.:  23%|██▎       | 2292/10000 [00:09<00:32, 239.77it/s]Running 10000 simulations.:  23%|██▎       | 2316/10000 [00:09<00:32, 239.66it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:09<00:32, 238.97it/s]Running 10000 simulations.:  24%|██▎       | 2364/10000 [00:09<00:32, 237.51it/s]Running 10000 simulations.:  24%|██▍       | 2388/10000 [00:09<00:32, 236.24it/s]Running 10000 simulations.:  24%|██▍       | 2412/10000 [00:09<00:32, 235.45it/s]Running 10000 simulations.:  24%|██▍       | 2436/10000 [00:10<00:32, 234.99it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:10<00:32, 234.21it/s]Running 10000 simulations.:  25%|██▍       | 2484/10000 [00:10<00:32, 234.41it/s]Running 10000 simulations.:  25%|██▌       | 2508/10000 [00:10<00:31, 234.89it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:10<00:31, 236.66it/s]Running 10000 simulations.:  26%|██▌       | 2558/10000 [00:10<00:31, 237.74it/s]Running 10000 simulations.:  26%|██▌       | 2582/10000 [00:10<00:31, 237.71it/s]Running 10000 simulations.:  26%|██▌       | 2607/10000 [00:10<00:30, 238.51it/s]Running 10000 simulations.:  26%|██▋       | 2631/10000 [00:10<00:30, 238.68it/s]Running 10000 simulations.:  27%|██▋       | 2656/10000 [00:10<00:30, 239.14it/s]Running 10000 simulations.:  27%|██▋       | 2680/10000 [00:11<00:30, 239.18it/s]Running 10000 simulations.:  27%|██▋       | 2704/10000 [00:11<00:30, 238.69it/s]Running 10000 simulations.:  27%|██▋       | 2728/10000 [00:11<00:30, 237.95it/s]Running 10000 simulations.:  28%|██▊       | 2752/10000 [00:11<00:30, 237.44it/s]Running 10000 simulations.:  28%|██▊       | 2776/10000 [00:11<00:30, 237.67it/s]Running 10000 simulations.:  28%|██▊       | 2801/10000 [00:11<00:30, 239.21it/s]Running 10000 simulations.:  28%|██▊       | 2826/10000 [00:11<00:29, 240.24it/s]Running 10000 simulations.:  29%|██▊       | 2851/10000 [00:11<00:29, 241.43it/s]Running 10000 simulations.:  29%|██▉       | 2876/10000 [00:11<00:29, 242.06it/s]Running 10000 simulations.:  29%|██▉       | 2901/10000 [00:12<00:29, 240.96it/s]Running 10000 simulations.:  29%|██▉       | 2926/10000 [00:12<00:29, 237.49it/s]Running 10000 simulations.:  30%|██▉       | 2950/10000 [00:12<00:30, 229.30it/s]Running 10000 simulations.:  30%|██▉       | 2974/10000 [00:12<00:30, 231.29it/s]Running 10000 simulations.:  30%|██▉       | 2998/10000 [00:12<00:30, 233.23it/s]Running 10000 simulations.:  30%|███       | 3022/10000 [00:12<00:29, 234.69it/s]Running 10000 simulations.:  30%|███       | 3046/10000 [00:12<00:29, 235.29it/s]Running 10000 simulations.:  31%|███       | 3070/10000 [00:12<00:29, 236.44it/s]Running 10000 simulations.:  31%|███       | 3094/10000 [00:12<00:29, 237.42it/s]Running 10000 simulations.:  31%|███       | 3118/10000 [00:12<00:28, 238.00it/s]Running 10000 simulations.:  31%|███▏      | 3142/10000 [00:13<00:28, 238.02it/s]Running 10000 simulations.:  32%|███▏      | 3167/10000 [00:13<00:28, 239.08it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:13<00:28, 239.31it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:13<00:28, 237.91it/s]Running 10000 simulations.:  32%|███▏      | 3239/10000 [00:13<00:28, 237.04it/s]Running 10000 simulations.:  33%|███▎      | 3263/10000 [00:13<00:28, 237.25it/s]Running 10000 simulations.:  33%|███▎      | 3287/10000 [00:13<00:28, 237.27it/s]Running 10000 simulations.:  33%|███▎      | 3311/10000 [00:13<00:28, 237.30it/s]Running 10000 simulations.:  33%|███▎      | 3335/10000 [00:13<00:28, 237.06it/s]Running 10000 simulations.:  34%|███▎      | 3359/10000 [00:13<00:28, 237.02it/s]Running 10000 simulations.:  34%|███▍      | 3383/10000 [00:14<00:27, 237.27it/s]Running 10000 simulations.:  34%|███▍      | 3407/10000 [00:14<00:27, 237.94it/s]Running 10000 simulations.:  34%|███▍      | 3431/10000 [00:14<00:27, 237.91it/s]Running 10000 simulations.:  35%|███▍      | 3456/10000 [00:14<00:27, 238.65it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:14<00:27, 239.01it/s]Running 10000 simulations.:  35%|███▌      | 3505/10000 [00:14<00:27, 239.40it/s]Running 10000 simulations.:  35%|███▌      | 3530/10000 [00:14<00:26, 240.01it/s]Running 10000 simulations.:  36%|███▌      | 3555/10000 [00:14<00:26, 239.54it/s]Running 10000 simulations.:  36%|███▌      | 3579/10000 [00:14<00:26, 239.15it/s]Running 10000 simulations.:  36%|███▌      | 3603/10000 [00:14<00:26, 238.53it/s]Running 10000 simulations.:  36%|███▋      | 3627/10000 [00:15<00:26, 238.63it/s]Running 10000 simulations.:  37%|███▋      | 3652/10000 [00:15<00:26, 239.27it/s]Running 10000 simulations.:  37%|███▋      | 3677/10000 [00:15<00:26, 240.34it/s]Running 10000 simulations.:  37%|███▋      | 3702/10000 [00:15<00:26, 241.20it/s]Running 10000 simulations.:  37%|███▋      | 3727/10000 [00:15<00:25, 241.28it/s]Running 10000 simulations.:  38%|███▊      | 3752/10000 [00:15<00:26, 239.62it/s]Running 10000 simulations.:  38%|███▊      | 3776/10000 [00:15<00:26, 238.05it/s]Running 10000 simulations.:  38%|███▊      | 3800/10000 [00:15<00:26, 238.40it/s]Running 10000 simulations.:  38%|███▊      | 3824/10000 [00:15<00:25, 238.48it/s]Running 10000 simulations.:  38%|███▊      | 3849/10000 [00:15<00:25, 238.94it/s]Running 10000 simulations.:  39%|███▊      | 3873/10000 [00:16<00:25, 238.74it/s]Running 10000 simulations.:  39%|███▉      | 3897/10000 [00:16<00:25, 239.03it/s]Running 10000 simulations.:  39%|███▉      | 3921/10000 [00:16<00:25, 238.85it/s]Running 10000 simulations.:  39%|███▉      | 3946/10000 [00:16<00:25, 240.36it/s]Running 10000 simulations.:  40%|███▉      | 3971/10000 [00:16<00:25, 240.63it/s]Running 10000 simulations.:  40%|███▉      | 3996/10000 [00:16<00:25, 239.85it/s]Running 10000 simulations.:  40%|████      | 4020/10000 [00:16<00:24, 239.33it/s]Running 10000 simulations.:  40%|████      | 4044/10000 [00:16<00:24, 239.34it/s]Running 10000 simulations.:  41%|████      | 4069/10000 [00:16<00:24, 239.54it/s]Running 10000 simulations.:  41%|████      | 4094/10000 [00:17<00:24, 240.55it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:17<00:24, 240.57it/s]Running 10000 simulations.:  41%|████▏     | 4144/10000 [00:17<00:24, 239.98it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:17<00:24, 239.98it/s]Running 10000 simulations.:  42%|████▏     | 4192/10000 [00:17<00:24, 239.65it/s]Running 10000 simulations.:  42%|████▏     | 4217/10000 [00:17<00:23, 240.99it/s]Running 10000 simulations.:  42%|████▏     | 4242/10000 [00:17<00:23, 241.73it/s]Running 10000 simulations.:  43%|████▎     | 4267/10000 [00:17<00:23, 240.50it/s]Running 10000 simulations.:  43%|████▎     | 4292/10000 [00:17<00:23, 239.69it/s]Running 10000 simulations.:  43%|████▎     | 4316/10000 [00:17<00:23, 238.61it/s]Running 10000 simulations.:  43%|████▎     | 4341/10000 [00:18<00:23, 239.28it/s]Running 10000 simulations.:  44%|████▎     | 4365/10000 [00:18<00:23, 239.46it/s]Running 10000 simulations.:  44%|████▍     | 4389/10000 [00:18<00:23, 239.43it/s]Running 10000 simulations.:  44%|████▍     | 4413/10000 [00:18<00:23, 238.88it/s]Running 10000 simulations.:  44%|████▍     | 4437/10000 [00:18<00:23, 239.09it/s]Running 10000 simulations.:  45%|████▍     | 4462/10000 [00:18<00:23, 239.41it/s]Running 10000 simulations.:  45%|████▍     | 4486/10000 [00:18<00:23, 238.94it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:18<00:22, 240.06it/s]Running 10000 simulations.:  45%|████▌     | 4536/10000 [00:18<00:22, 240.99it/s]Running 10000 simulations.:  46%|████▌     | 4561/10000 [00:18<00:22, 240.48it/s]Running 10000 simulations.:  46%|████▌     | 4586/10000 [00:19<00:22, 239.14it/s]Running 10000 simulations.:  46%|████▌     | 4610/10000 [00:19<00:22, 238.09it/s]Running 10000 simulations.:  46%|████▋     | 4634/10000 [00:19<00:22, 238.02it/s]Running 10000 simulations.:  47%|████▋     | 4658/10000 [00:19<00:22, 238.31it/s]Running 10000 simulations.:  47%|████▋     | 4682/10000 [00:19<00:22, 237.82it/s]Running 10000 simulations.:  47%|████▋     | 4706/10000 [00:19<00:22, 237.45it/s]Running 10000 simulations.:  47%|████▋     | 4730/10000 [00:19<00:22, 237.33it/s]Running 10000 simulations.:  48%|████▊     | 4754/10000 [00:19<00:22, 237.23it/s]Running 10000 simulations.:  48%|████▊     | 4778/10000 [00:19<00:21, 238.04it/s]Running 10000 simulations.:  48%|████▊     | 4802/10000 [00:19<00:21, 237.97it/s]Running 10000 simulations.:  48%|████▊     | 4826/10000 [00:20<00:21, 237.26it/s]Running 10000 simulations.:  48%|████▊     | 4850/10000 [00:20<00:21, 236.98it/s]Running 10000 simulations.:  49%|████▊     | 4874/10000 [00:20<00:21, 237.21it/s]Running 10000 simulations.:  49%|████▉     | 4898/10000 [00:20<00:21, 237.05it/s]Running 10000 simulations.:  49%|████▉     | 4922/10000 [00:20<00:21, 237.39it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:20<00:21, 237.40it/s]Running 10000 simulations.:  50%|████▉     | 4970/10000 [00:20<00:21, 237.56it/s]Running 10000 simulations.:  50%|████▉     | 4994/10000 [00:20<00:21, 238.06it/s]Running 10000 simulations.:  50%|█████     | 5019/10000 [00:20<00:20, 239.33it/s]Running 10000 simulations.:  50%|█████     | 5044/10000 [00:20<00:20, 240.47it/s]Running 10000 simulations.:  51%|█████     | 5069/10000 [00:21<00:20, 240.77it/s]Running 10000 simulations.:  51%|█████     | 5094/10000 [00:21<00:20, 235.56it/s]Running 10000 simulations.:  51%|█████     | 5118/10000 [00:21<00:21, 231.61it/s]Running 10000 simulations.:  51%|█████▏    | 5142/10000 [00:21<00:21, 229.37it/s]Running 10000 simulations.:  52%|█████▏    | 5165/10000 [00:21<00:21, 227.93it/s]Running 10000 simulations.:  52%|█████▏    | 5188/10000 [00:21<00:21, 226.13it/s]Running 10000 simulations.:  52%|█████▏    | 5212/10000 [00:21<00:21, 227.33it/s]Running 10000 simulations.:  52%|█████▏    | 5236/10000 [00:21<00:20, 229.82it/s]Running 10000 simulations.:  53%|█████▎    | 5260/10000 [00:21<00:20, 230.91it/s]Running 10000 simulations.:  53%|█████▎    | 5284/10000 [00:22<00:20, 232.22it/s]Running 10000 simulations.:  53%|█████▎    | 5308/10000 [00:22<00:20, 232.52it/s]Running 10000 simulations.:  53%|█████▎    | 5332/10000 [00:22<00:20, 233.01it/s]Running 10000 simulations.:  54%|█████▎    | 5356/10000 [00:22<00:19, 232.46it/s]Running 10000 simulations.:  54%|█████▍    | 5380/10000 [00:22<00:19, 232.80it/s]Running 10000 simulations.:  54%|█████▍    | 5404/10000 [00:22<00:19, 232.31it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:22<00:19, 232.19it/s]Running 10000 simulations.:  55%|█████▍    | 5452/10000 [00:22<00:19, 233.68it/s]Running 10000 simulations.:  55%|█████▍    | 5476/10000 [00:22<00:19, 234.61it/s]Running 10000 simulations.:  55%|█████▌    | 5500/10000 [00:22<00:19, 234.62it/s]Running 10000 simulations.:  55%|█████▌    | 5524/10000 [00:23<00:19, 233.81it/s]Running 10000 simulations.:  55%|█████▌    | 5548/10000 [00:23<00:19, 233.86it/s]Running 10000 simulations.:  56%|█████▌    | 5572/10000 [00:23<00:18, 233.66it/s]Running 10000 simulations.:  56%|█████▌    | 5596/10000 [00:23<00:18, 233.79it/s]Running 10000 simulations.:  56%|█████▌    | 5620/10000 [00:23<00:18, 232.39it/s]Running 10000 simulations.:  56%|█████▋    | 5644/10000 [00:23<00:18, 232.82it/s]Running 10000 simulations.:  57%|█████▋    | 5668/10000 [00:23<00:18, 233.51it/s]Running 10000 simulations.:  57%|█████▋    | 5692/10000 [00:23<00:18, 234.01it/s]Running 10000 simulations.:  57%|█████▋    | 5716/10000 [00:23<00:18, 234.16it/s]Running 10000 simulations.:  57%|█████▋    | 5740/10000 [00:23<00:18, 234.31it/s]Running 10000 simulations.:  58%|█████▊    | 5764/10000 [00:24<00:17, 235.71it/s]Running 10000 simulations.:  58%|█████▊    | 5789/10000 [00:24<00:17, 237.09it/s]Running 10000 simulations.:  58%|█████▊    | 5813/10000 [00:24<00:17, 237.53it/s]Running 10000 simulations.:  58%|█████▊    | 5837/10000 [00:24<00:17, 238.19it/s]Running 10000 simulations.:  59%|█████▊    | 5862/10000 [00:24<00:17, 239.02it/s]Running 10000 simulations.:  59%|█████▉    | 5886/10000 [00:24<00:17, 238.65it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:24<00:17, 238.28it/s]Running 10000 simulations.:  59%|█████▉    | 5935/10000 [00:24<00:16, 239.79it/s]Running 10000 simulations.:  60%|█████▉    | 5960/10000 [00:24<00:16, 240.22it/s]Running 10000 simulations.:  60%|█████▉    | 5985/10000 [00:25<00:16, 239.15it/s]Running 10000 simulations.:  60%|██████    | 6009/10000 [00:25<00:16, 238.78it/s]Running 10000 simulations.:  60%|██████    | 6034/10000 [00:25<00:16, 239.60it/s]Running 10000 simulations.:  61%|██████    | 6059/10000 [00:25<00:16, 239.95it/s]Running 10000 simulations.:  61%|██████    | 6083/10000 [00:25<00:16, 236.97it/s]Running 10000 simulations.:  61%|██████    | 6107/10000 [00:25<00:16, 234.35it/s]Running 10000 simulations.:  61%|██████▏   | 6131/10000 [00:25<00:16, 230.45it/s]Running 10000 simulations.:  62%|██████▏   | 6156/10000 [00:25<00:16, 233.78it/s]Running 10000 simulations.:  62%|██████▏   | 6181/10000 [00:25<00:16, 236.46it/s]Running 10000 simulations.:  62%|██████▏   | 6206/10000 [00:25<00:15, 238.41it/s]Running 10000 simulations.:  62%|██████▏   | 6231/10000 [00:26<00:15, 239.90it/s]Running 10000 simulations.:  63%|██████▎   | 6256/10000 [00:26<00:15, 240.59it/s]Running 10000 simulations.:  63%|██████▎   | 6281/10000 [00:26<00:15, 241.60it/s]Running 10000 simulations.:  63%|██████▎   | 6306/10000 [00:26<00:15, 243.01it/s]Running 10000 simulations.:  63%|██████▎   | 6331/10000 [00:26<00:15, 244.32it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:26<00:14, 245.13it/s]Running 10000 simulations.:  64%|██████▍   | 6381/10000 [00:26<00:14, 245.26it/s]Running 10000 simulations.:  64%|██████▍   | 6406/10000 [00:26<00:14, 244.59it/s]Running 10000 simulations.:  64%|██████▍   | 6431/10000 [00:26<00:14, 243.73it/s]Running 10000 simulations.:  65%|██████▍   | 6456/10000 [00:26<00:14, 243.37it/s]Running 10000 simulations.:  65%|██████▍   | 6481/10000 [00:27<00:14, 242.20it/s]Running 10000 simulations.:  65%|██████▌   | 6506/10000 [00:27<00:14, 242.32it/s]Running 10000 simulations.:  65%|██████▌   | 6531/10000 [00:27<00:14, 241.50it/s]Running 10000 simulations.:  66%|██████▌   | 6556/10000 [00:27<00:14, 241.07it/s]Running 10000 simulations.:  66%|██████▌   | 6581/10000 [00:27<00:14, 241.17it/s]Running 10000 simulations.:  66%|██████▌   | 6606/10000 [00:27<00:14, 241.88it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:27<00:14, 239.78it/s]Running 10000 simulations.:  67%|██████▋   | 6656/10000 [00:27<00:13, 240.53it/s]Running 10000 simulations.:  67%|██████▋   | 6681/10000 [00:27<00:13, 240.81it/s]Running 10000 simulations.:  67%|██████▋   | 6706/10000 [00:28<00:13, 240.79it/s]Running 10000 simulations.:  67%|██████▋   | 6731/10000 [00:28<00:13, 240.55it/s]Running 10000 simulations.:  68%|██████▊   | 6756/10000 [00:28<00:13, 240.73it/s]Running 10000 simulations.:  68%|██████▊   | 6781/10000 [00:28<00:13, 240.98it/s]Running 10000 simulations.:  68%|██████▊   | 6806/10000 [00:28<00:13, 240.49it/s]Running 10000 simulations.:  68%|██████▊   | 6831/10000 [00:28<00:13, 240.22it/s]Running 10000 simulations.:  69%|██████▊   | 6856/10000 [00:28<00:13, 240.48it/s]Running 10000 simulations.:  69%|██████▉   | 6881/10000 [00:28<00:12, 241.02it/s]Running 10000 simulations.:  69%|██████▉   | 6906/10000 [00:28<00:12, 241.02it/s]Running 10000 simulations.:  69%|██████▉   | 6931/10000 [00:28<00:12, 241.10it/s]Running 10000 simulations.:  70%|██████▉   | 6956/10000 [00:29<00:12, 241.34it/s]Running 10000 simulations.:  70%|██████▉   | 6981/10000 [00:29<00:12, 241.27it/s]Running 10000 simulations.:  70%|███████   | 7006/10000 [00:29<00:12, 241.15it/s]Running 10000 simulations.:  70%|███████   | 7031/10000 [00:29<00:12, 240.69it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:29<00:12, 240.51it/s]Running 10000 simulations.:  71%|███████   | 7081/10000 [00:29<00:12, 240.11it/s]Running 10000 simulations.:  71%|███████   | 7106/10000 [00:29<00:12, 240.23it/s]Running 10000 simulations.:  71%|███████▏  | 7131/10000 [00:29<00:12, 237.47it/s]Running 10000 simulations.:  72%|███████▏  | 7155/10000 [00:29<00:11, 238.02it/s]Running 10000 simulations.:  72%|███████▏  | 7180/10000 [00:29<00:11, 240.19it/s]Running 10000 simulations.:  72%|███████▏  | 7205/10000 [00:30<00:11, 241.21it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:30<00:11, 241.72it/s]Running 10000 simulations.:  73%|███████▎  | 7255/10000 [00:30<00:11, 242.67it/s]Running 10000 simulations.:  73%|███████▎  | 7280/10000 [00:30<00:11, 242.57it/s]Running 10000 simulations.:  73%|███████▎  | 7305/10000 [00:30<00:11, 239.64it/s]Running 10000 simulations.:  73%|███████▎  | 7329/10000 [00:30<00:11, 239.42it/s]Running 10000 simulations.:  74%|███████▎  | 7354/10000 [00:30<00:11, 240.08it/s]Running 10000 simulations.:  74%|███████▍  | 7379/10000 [00:30<00:10, 240.37it/s]Running 10000 simulations.:  74%|███████▍  | 7404/10000 [00:30<00:10, 240.42it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:31<00:10, 241.22it/s]Running 10000 simulations.:  75%|███████▍  | 7454/10000 [00:31<00:10, 241.74it/s]Running 10000 simulations.:  75%|███████▍  | 7479/10000 [00:31<00:10, 242.10it/s]Running 10000 simulations.:  75%|███████▌  | 7504/10000 [00:31<00:10, 242.27it/s]Running 10000 simulations.:  75%|███████▌  | 7529/10000 [00:31<00:10, 242.48it/s]Running 10000 simulations.:  76%|███████▌  | 7554/10000 [00:31<00:10, 243.09it/s]Running 10000 simulations.:  76%|███████▌  | 7579/10000 [00:31<00:09, 243.63it/s]Running 10000 simulations.:  76%|███████▌  | 7604/10000 [00:31<00:09, 243.94it/s]Running 10000 simulations.:  76%|███████▋  | 7629/10000 [00:31<00:09, 244.46it/s]Running 10000 simulations.:  77%|███████▋  | 7654/10000 [00:31<00:09, 244.63it/s]Running 10000 simulations.:  77%|███████▋  | 7679/10000 [00:32<00:09, 244.20it/s]Running 10000 simulations.:  77%|███████▋  | 7704/10000 [00:32<00:09, 243.10it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:32<00:09, 242.72it/s]Running 10000 simulations.:  78%|███████▊  | 7754/10000 [00:32<00:09, 241.98it/s]Running 10000 simulations.:  78%|███████▊  | 7779/10000 [00:32<00:09, 243.08it/s]Running 10000 simulations.:  78%|███████▊  | 7804/10000 [00:32<00:09, 243.91it/s]Running 10000 simulations.:  78%|███████▊  | 7829/10000 [00:32<00:08, 244.01it/s]Running 10000 simulations.:  79%|███████▊  | 7854/10000 [00:32<00:08, 243.64it/s]Running 10000 simulations.:  79%|███████▉  | 7879/10000 [00:32<00:08, 243.39it/s]Running 10000 simulations.:  79%|███████▉  | 7904/10000 [00:32<00:08, 242.87it/s]Running 10000 simulations.:  79%|███████▉  | 7929/10000 [00:33<00:08, 242.69it/s]Running 10000 simulations.:  80%|███████▉  | 7954/10000 [00:33<00:08, 241.88it/s]Running 10000 simulations.:  80%|███████▉  | 7979/10000 [00:33<00:08, 241.06it/s]Running 10000 simulations.:  80%|████████  | 8004/10000 [00:33<00:08, 242.91it/s]Running 10000 simulations.:  80%|████████  | 8029/10000 [00:33<00:08, 242.51it/s]Running 10000 simulations.:  81%|████████  | 8054/10000 [00:33<00:08, 242.35it/s]Running 10000 simulations.:  81%|████████  | 8079/10000 [00:33<00:07, 242.02it/s]Running 10000 simulations.:  81%|████████  | 8104/10000 [00:33<00:07, 242.25it/s]Running 10000 simulations.:  81%|████████▏ | 8129/10000 [00:33<00:07, 243.23it/s]Running 10000 simulations.:  82%|████████▏ | 8154/10000 [00:33<00:07, 243.82it/s]Running 10000 simulations.:  82%|████████▏ | 8179/10000 [00:34<00:07, 243.85it/s]Running 10000 simulations.:  82%|████████▏ | 8204/10000 [00:34<00:07, 243.77it/s]Running 10000 simulations.:  82%|████████▏ | 8229/10000 [00:34<00:07, 243.04it/s]Running 10000 simulations.:  83%|████████▎ | 8254/10000 [00:34<00:07, 242.71it/s]Running 10000 simulations.:  83%|████████▎ | 8279/10000 [00:34<00:07, 242.16it/s]Running 10000 simulations.:  83%|████████▎ | 8304/10000 [00:34<00:06, 243.04it/s]Running 10000 simulations.:  83%|████████▎ | 8329/10000 [00:34<00:06, 242.65it/s]Running 10000 simulations.:  84%|████████▎ | 8354/10000 [00:34<00:06, 241.98it/s]Running 10000 simulations.:  84%|████████▍ | 8379/10000 [00:34<00:06, 242.36it/s]Running 10000 simulations.:  84%|████████▍ | 8404/10000 [00:35<00:06, 242.42it/s]Running 10000 simulations.:  84%|████████▍ | 8429/10000 [00:35<00:06, 242.35it/s]Running 10000 simulations.:  85%|████████▍ | 8454/10000 [00:35<00:06, 242.44it/s]Running 10000 simulations.:  85%|████████▍ | 8479/10000 [00:35<00:06, 241.85it/s]Running 10000 simulations.:  85%|████████▌ | 8504/10000 [00:35<00:06, 241.50it/s]Running 10000 simulations.:  85%|████████▌ | 8529/10000 [00:35<00:06, 240.75it/s]Running 10000 simulations.:  86%|████████▌ | 8554/10000 [00:35<00:06, 240.59it/s]Running 10000 simulations.:  86%|████████▌ | 8579/10000 [00:35<00:05, 240.13it/s]Running 10000 simulations.:  86%|████████▌ | 8604/10000 [00:35<00:05, 240.30it/s]Running 10000 simulations.:  86%|████████▋ | 8629/10000 [00:35<00:05, 240.94it/s]Running 10000 simulations.:  87%|████████▋ | 8654/10000 [00:36<00:05, 241.24it/s]Running 10000 simulations.:  87%|████████▋ | 8679/10000 [00:36<00:05, 241.45it/s]Running 10000 simulations.:  87%|████████▋ | 8704/10000 [00:36<00:05, 241.75it/s]Running 10000 simulations.:  87%|████████▋ | 8729/10000 [00:36<00:05, 242.40it/s]Running 10000 simulations.:  88%|████████▊ | 8754/10000 [00:36<00:05, 242.60it/s]Running 10000 simulations.:  88%|████████▊ | 8779/10000 [00:36<00:05, 243.20it/s]Running 10000 simulations.:  88%|████████▊ | 8804/10000 [00:36<00:04, 243.90it/s]Running 10000 simulations.:  88%|████████▊ | 8829/10000 [00:36<00:04, 243.88it/s]Running 10000 simulations.:  89%|████████▊ | 8854/10000 [00:36<00:04, 244.32it/s]Running 10000 simulations.:  89%|████████▉ | 8879/10000 [00:36<00:04, 243.60it/s]Running 10000 simulations.:  89%|████████▉ | 8904/10000 [00:37<00:04, 242.90it/s]Running 10000 simulations.:  89%|████████▉ | 8929/10000 [00:37<00:04, 243.02it/s]Running 10000 simulations.:  90%|████████▉ | 8954/10000 [00:37<00:04, 242.67it/s]Running 10000 simulations.:  90%|████████▉ | 8979/10000 [00:37<00:04, 241.96it/s]Running 10000 simulations.:  90%|█████████ | 9004/10000 [00:37<00:04, 241.68it/s]Running 10000 simulations.:  90%|█████████ | 9029/10000 [00:37<00:04, 241.67it/s]Running 10000 simulations.:  91%|█████████ | 9054/10000 [00:37<00:03, 242.45it/s]Running 10000 simulations.:  91%|█████████ | 9079/10000 [00:37<00:03, 243.39it/s]Running 10000 simulations.:  91%|█████████ | 9104/10000 [00:37<00:03, 244.21it/s]Running 10000 simulations.:  91%|█████████▏| 9129/10000 [00:38<00:03, 243.69it/s]Running 10000 simulations.:  92%|█████████▏| 9154/10000 [00:38<00:03, 242.42it/s]Running 10000 simulations.:  92%|█████████▏| 9179/10000 [00:38<00:03, 241.83it/s]Running 10000 simulations.:  92%|█████████▏| 9204/10000 [00:38<00:03, 241.42it/s]Running 10000 simulations.:  92%|█████████▏| 9229/10000 [00:38<00:03, 240.90it/s]Running 10000 simulations.:  93%|█████████▎| 9254/10000 [00:38<00:03, 240.53it/s]Running 10000 simulations.:  93%|█████████▎| 9279/10000 [00:38<00:02, 240.49it/s]Running 10000 simulations.:  93%|█████████▎| 9304/10000 [00:38<00:02, 240.37it/s]Running 10000 simulations.:  93%|█████████▎| 9329/10000 [00:38<00:02, 240.99it/s]Running 10000 simulations.:  94%|█████████▎| 9354/10000 [00:38<00:02, 241.13it/s]Running 10000 simulations.:  94%|█████████▍| 9379/10000 [00:39<00:02, 241.69it/s]Running 10000 simulations.:  94%|█████████▍| 9404/10000 [00:39<00:02, 241.52it/s]Running 10000 simulations.:  94%|█████████▍| 9429/10000 [00:39<00:02, 241.86it/s]Running 10000 simulations.:  95%|█████████▍| 9454/10000 [00:39<00:02, 242.89it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [00:39<00:02, 243.70it/s]Running 10000 simulations.:  95%|█████████▌| 9504/10000 [00:39<00:02, 244.33it/s]Running 10000 simulations.:  95%|█████████▌| 9529/10000 [00:39<00:01, 244.72it/s]Running 10000 simulations.:  96%|█████████▌| 9554/10000 [00:39<00:01, 245.49it/s]Running 10000 simulations.:  96%|█████████▌| 9579/10000 [00:39<00:01, 245.94it/s]Running 10000 simulations.:  96%|█████████▌| 9604/10000 [00:39<00:01, 245.69it/s]Running 10000 simulations.:  96%|█████████▋| 9629/10000 [00:40<00:01, 244.46it/s]Running 10000 simulations.:  97%|█████████▋| 9654/10000 [00:40<00:01, 242.33it/s]Running 10000 simulations.:  97%|█████████▋| 9679/10000 [00:40<00:01, 241.88it/s]Running 10000 simulations.:  97%|█████████▋| 9704/10000 [00:40<00:01, 242.83it/s]Running 10000 simulations.:  97%|█████████▋| 9729/10000 [00:40<00:01, 244.42it/s]Running 10000 simulations.:  98%|█████████▊| 9754/10000 [00:40<00:01, 245.59it/s]Running 10000 simulations.:  98%|█████████▊| 9779/10000 [00:40<00:00, 246.71it/s]Running 10000 simulations.:  98%|█████████▊| 9804/10000 [00:40<00:00, 247.19it/s]Running 10000 simulations.:  98%|█████████▊| 9829/10000 [00:40<00:00, 247.53it/s]Running 10000 simulations.:  99%|█████████▊| 9854/10000 [00:40<00:00, 246.74it/s]Running 10000 simulations.:  99%|█████████▉| 9879/10000 [00:41<00:00, 246.06it/s]Running 10000 simulations.:  99%|█████████▉| 9904/10000 [00:41<00:00, 246.04it/s]Running 10000 simulations.:  99%|█████████▉| 9929/10000 [00:41<00:00, 246.31it/s]Running 10000 simulations.: 100%|█████████▉| 9955/10000 [00:41<00:00, 247.76it/s]Running 10000 simulations.: 100%|█████████▉| 9980/10000 [00:41<00:00, 247.15it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 240.48it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 250.52it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 251.50it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:39, 252.21it/s]Running 10000 simulations.:   1%|          | 103/10000 [00:00<00:39, 250.19it/s]Running 10000 simulations.:   1%|▏         | 128/10000 [00:00<00:39, 247.66it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:39, 247.23it/s]Running 10000 simulations.:   2%|▏         | 178/10000 [00:00<00:39, 246.50it/s]Running 10000 simulations.:   2%|▏         | 203/10000 [00:00<00:39, 246.25it/s]Running 10000 simulations.:   2%|▏         | 228/10000 [00:00<00:39, 246.20it/s]Running 10000 simulations.:   3%|▎         | 253/10000 [00:01<00:39, 245.95it/s]Running 10000 simulations.:   3%|▎         | 278/10000 [00:01<00:39, 245.50it/s]Running 10000 simulations.:   3%|▎         | 303/10000 [00:01<00:39, 245.96it/s]Running 10000 simulations.:   3%|▎         | 328/10000 [00:01<00:39, 243.34it/s]Running 10000 simulations.:   4%|▎         | 353/10000 [00:01<00:39, 242.68it/s]Running 10000 simulations.:   4%|▍         | 378/10000 [00:01<00:39, 243.15it/s]Running 10000 simulations.:   4%|▍         | 403/10000 [00:01<00:39, 242.42it/s]Running 10000 simulations.:   4%|▍         | 428/10000 [00:01<00:39, 243.29it/s]Running 10000 simulations.:   5%|▍         | 453/10000 [00:01<00:39, 243.45it/s]Running 10000 simulations.:   5%|▍         | 478/10000 [00:01<00:39, 242.17it/s]Running 10000 simulations.:   5%|▌         | 503/10000 [00:02<00:39, 241.75it/s]Running 10000 simulations.:   5%|▌         | 528/10000 [00:02<00:39, 241.85it/s]Running 10000 simulations.:   6%|▌         | 553/10000 [00:02<00:39, 242.18it/s]Running 10000 simulations.:   6%|▌         | 578/10000 [00:02<00:38, 241.88it/s]Running 10000 simulations.:   6%|▌         | 603/10000 [00:02<00:38, 242.75it/s]Running 10000 simulations.:   6%|▋         | 628/10000 [00:02<00:39, 240.24it/s]Running 10000 simulations.:   7%|▋         | 653/10000 [00:02<00:38, 240.38it/s]Running 10000 simulations.:   7%|▋         | 678/10000 [00:02<00:38, 240.92it/s]Running 10000 simulations.:   7%|▋         | 703/10000 [00:02<00:38, 241.16it/s]Running 10000 simulations.:   7%|▋         | 728/10000 [00:02<00:38, 240.11it/s]Running 10000 simulations.:   8%|▊         | 753/10000 [00:03<00:38, 239.53it/s]Running 10000 simulations.:   8%|▊         | 778/10000 [00:03<00:38, 240.09it/s]Running 10000 simulations.:   8%|▊         | 803/10000 [00:03<00:38, 241.09it/s]Running 10000 simulations.:   8%|▊         | 828/10000 [00:03<00:37, 241.82it/s]Running 10000 simulations.:   9%|▊         | 853/10000 [00:03<00:38, 238.88it/s]Running 10000 simulations.:   9%|▉         | 878/10000 [00:03<00:38, 239.74it/s]Running 10000 simulations.:   9%|▉         | 902/10000 [00:03<00:37, 239.42it/s]Running 10000 simulations.:   9%|▉         | 926/10000 [00:03<00:37, 239.35it/s]Running 10000 simulations.:  10%|▉         | 951/10000 [00:03<00:37, 239.76it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:04<00:37, 239.54it/s]Running 10000 simulations.:  10%|▉         | 999/10000 [00:04<00:37, 239.49it/s]Running 10000 simulations.:  10%|█         | 1023/10000 [00:04<00:37, 239.36it/s]Running 10000 simulations.:  10%|█         | 1048/10000 [00:04<00:37, 239.87it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:04<00:37, 239.17it/s]Running 10000 simulations.:  11%|█         | 1096/10000 [00:04<00:37, 237.48it/s]Running 10000 simulations.:  11%|█         | 1121/10000 [00:04<00:37, 238.39it/s]Running 10000 simulations.:  11%|█▏        | 1146/10000 [00:04<00:36, 240.00it/s]Running 10000 simulations.:  12%|█▏        | 1171/10000 [00:04<00:36, 239.83it/s]Running 10000 simulations.:  12%|█▏        | 1196/10000 [00:04<00:36, 240.11it/s]Running 10000 simulations.:  12%|█▏        | 1221/10000 [00:05<00:36, 240.74it/s]Running 10000 simulations.:  12%|█▏        | 1246/10000 [00:05<00:36, 240.14it/s]Running 10000 simulations.:  13%|█▎        | 1271/10000 [00:05<00:36, 240.29it/s]Running 10000 simulations.:  13%|█▎        | 1296/10000 [00:05<00:36, 239.90it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:05<00:36, 237.40it/s]Running 10000 simulations.:  13%|█▎        | 1345/10000 [00:05<00:36, 238.80it/s]Running 10000 simulations.:  14%|█▎        | 1369/10000 [00:05<00:36, 238.42it/s]Running 10000 simulations.:  14%|█▍        | 1393/10000 [00:05<00:36, 238.05it/s]Running 10000 simulations.:  14%|█▍        | 1417/10000 [00:05<00:35, 238.42it/s]Running 10000 simulations.:  14%|█▍        | 1441/10000 [00:05<00:35, 237.93it/s]Running 10000 simulations.:  15%|█▍        | 1465/10000 [00:06<00:35, 237.77it/s]Running 10000 simulations.:  15%|█▍        | 1490/10000 [00:06<00:35, 238.38it/s]Running 10000 simulations.:  15%|█▌        | 1515/10000 [00:06<00:35, 239.40it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:06<00:35, 236.66it/s]Running 10000 simulations.:  16%|█▌        | 1563/10000 [00:06<00:35, 236.32it/s]Running 10000 simulations.:  16%|█▌        | 1587/10000 [00:06<00:35, 236.64it/s]Running 10000 simulations.:  16%|█▌        | 1611/10000 [00:06<00:35, 236.57it/s]Running 10000 simulations.:  16%|█▋        | 1635/10000 [00:06<00:35, 236.01it/s]Running 10000 simulations.:  17%|█▋        | 1660/10000 [00:06<00:35, 237.44it/s]Running 10000 simulations.:  17%|█▋        | 1684/10000 [00:06<00:34, 237.93it/s]Running 10000 simulations.:  17%|█▋        | 1709/10000 [00:07<00:34, 238.98it/s]Running 10000 simulations.:  17%|█▋        | 1734/10000 [00:07<00:34, 240.71it/s]Running 10000 simulations.:  18%|█▊        | 1759/10000 [00:07<00:34, 239.45it/s]Running 10000 simulations.:  18%|█▊        | 1783/10000 [00:07<00:34, 236.18it/s]Running 10000 simulations.:  18%|█▊        | 1807/10000 [00:07<00:34, 237.05it/s]Running 10000 simulations.:  18%|█▊        | 1831/10000 [00:07<00:34, 235.59it/s]Running 10000 simulations.:  19%|█▊        | 1855/10000 [00:07<00:34, 233.48it/s]Running 10000 simulations.:  19%|█▉        | 1879/10000 [00:07<00:34, 234.54it/s]Running 10000 simulations.:  19%|█▉        | 1903/10000 [00:07<00:34, 235.04it/s]Running 10000 simulations.:  19%|█▉        | 1928/10000 [00:08<00:34, 236.51it/s]Running 10000 simulations.:  20%|█▉        | 1953/10000 [00:08<00:33, 238.61it/s]Running 10000 simulations.:  20%|█▉        | 1977/10000 [00:08<00:33, 236.67it/s]Running 10000 simulations.:  20%|██        | 2001/10000 [00:08<00:34, 229.88it/s]Running 10000 simulations.:  20%|██        | 2025/10000 [00:08<00:34, 229.05it/s]Running 10000 simulations.:  20%|██        | 2048/10000 [00:08<00:34, 228.15it/s]Running 10000 simulations.:  21%|██        | 2071/10000 [00:08<00:34, 227.50it/s]Running 10000 simulations.:  21%|██        | 2095/10000 [00:08<00:34, 230.07it/s]Running 10000 simulations.:  21%|██        | 2119/10000 [00:08<00:33, 232.23it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:08<00:34, 230.86it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:09<00:34, 229.59it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:09<00:33, 229.86it/s]Running 10000 simulations.:  22%|██▏       | 2215/10000 [00:09<00:33, 231.46it/s]Running 10000 simulations.:  22%|██▏       | 2239/10000 [00:09<00:33, 232.03it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:09<00:33, 233.76it/s]Running 10000 simulations.:  23%|██▎       | 2287/10000 [00:09<00:32, 234.89it/s]Running 10000 simulations.:  23%|██▎       | 2311/10000 [00:09<00:33, 228.90it/s]Running 10000 simulations.:  23%|██▎       | 2334/10000 [00:09<00:33, 228.59it/s]Running 10000 simulations.:  24%|██▎       | 2357/10000 [00:09<00:33, 227.88it/s]Running 10000 simulations.:  24%|██▍       | 2380/10000 [00:09<00:33, 227.63it/s]Running 10000 simulations.:  24%|██▍       | 2404/10000 [00:10<00:33, 229.78it/s]Running 10000 simulations.:  24%|██▍       | 2428/10000 [00:10<00:32, 232.01it/s]Running 10000 simulations.:  25%|██▍       | 2452/10000 [00:10<00:32, 234.21it/s]Running 10000 simulations.:  25%|██▍       | 2477/10000 [00:10<00:31, 236.31it/s]Running 10000 simulations.:  25%|██▌       | 2501/10000 [00:10<00:31, 237.31it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:10<00:32, 232.41it/s]Running 10000 simulations.:  25%|██▌       | 2549/10000 [00:10<00:32, 230.13it/s]Running 10000 simulations.:  26%|██▌       | 2573/10000 [00:10<00:31, 232.61it/s]Running 10000 simulations.:  26%|██▌       | 2597/10000 [00:10<00:31, 234.63it/s]Running 10000 simulations.:  26%|██▌       | 2621/10000 [00:11<00:31, 235.77it/s]Running 10000 simulations.:  26%|██▋       | 2645/10000 [00:11<00:31, 236.11it/s]Running 10000 simulations.:  27%|██▋       | 2669/10000 [00:11<00:30, 236.75it/s]Running 10000 simulations.:  27%|██▋       | 2693/10000 [00:11<00:30, 237.57it/s]Running 10000 simulations.:  27%|██▋       | 2718/10000 [00:11<00:30, 239.04it/s]Running 10000 simulations.:  27%|██▋       | 2742/10000 [00:11<00:30, 237.71it/s]Running 10000 simulations.:  28%|██▊       | 2766/10000 [00:11<00:30, 238.33it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:11<00:30, 238.73it/s]Running 10000 simulations.:  28%|██▊       | 2814/10000 [00:11<00:30, 238.46it/s]Running 10000 simulations.:  28%|██▊       | 2838/10000 [00:11<00:30, 238.52it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:12<00:29, 239.36it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:12<00:29, 239.33it/s]Running 10000 simulations.:  29%|██▉       | 2912/10000 [00:12<00:29, 239.60it/s]Running 10000 simulations.:  29%|██▉       | 2936/10000 [00:12<00:29, 239.67it/s]Running 10000 simulations.:  30%|██▉       | 2960/10000 [00:12<00:29, 236.95it/s]Running 10000 simulations.:  30%|██▉       | 2984/10000 [00:12<00:29, 237.27it/s]Running 10000 simulations.:  30%|███       | 3008/10000 [00:12<00:29, 237.76it/s]Running 10000 simulations.:  30%|███       | 3032/10000 [00:12<00:29, 238.09it/s]Running 10000 simulations.:  31%|███       | 3057/10000 [00:12<00:28, 239.50it/s]Running 10000 simulations.:  31%|███       | 3082/10000 [00:12<00:28, 241.07it/s]Running 10000 simulations.:  31%|███       | 3107/10000 [00:13<00:28, 241.80it/s]Running 10000 simulations.:  31%|███▏      | 3132/10000 [00:13<00:28, 242.36it/s]Running 10000 simulations.:  32%|███▏      | 3157/10000 [00:13<00:28, 242.27it/s]Running 10000 simulations.:  32%|███▏      | 3182/10000 [00:13<00:28, 240.49it/s]Running 10000 simulations.:  32%|███▏      | 3207/10000 [00:13<00:28, 240.86it/s]Running 10000 simulations.:  32%|███▏      | 3232/10000 [00:13<00:28, 240.34it/s]Running 10000 simulations.:  33%|███▎      | 3257/10000 [00:13<00:28, 240.18it/s]Running 10000 simulations.:  33%|███▎      | 3282/10000 [00:13<00:27, 241.52it/s]Running 10000 simulations.:  33%|███▎      | 3307/10000 [00:13<00:27, 242.16it/s]Running 10000 simulations.:  33%|███▎      | 3332/10000 [00:13<00:27, 242.35it/s]Running 10000 simulations.:  34%|███▎      | 3357/10000 [00:14<00:27, 241.96it/s]Running 10000 simulations.:  34%|███▍      | 3382/10000 [00:14<00:27, 241.69it/s]Running 10000 simulations.:  34%|███▍      | 3407/10000 [00:14<00:27, 240.22it/s]Running 10000 simulations.:  34%|███▍      | 3432/10000 [00:14<00:27, 241.24it/s]Running 10000 simulations.:  35%|███▍      | 3457/10000 [00:14<00:27, 242.18it/s]Running 10000 simulations.:  35%|███▍      | 3482/10000 [00:14<00:26, 243.13it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:14<00:26, 243.79it/s]Running 10000 simulations.:  35%|███▌      | 3532/10000 [00:14<00:26, 243.44it/s]Running 10000 simulations.:  36%|███▌      | 3557/10000 [00:14<00:26, 241.55it/s]Running 10000 simulations.:  36%|███▌      | 3582/10000 [00:15<00:26, 239.36it/s]Running 10000 simulations.:  36%|███▌      | 3607/10000 [00:15<00:26, 241.09it/s]Running 10000 simulations.:  36%|███▋      | 3632/10000 [00:15<00:26, 240.85it/s]Running 10000 simulations.:  37%|███▋      | 3657/10000 [00:15<00:26, 241.42it/s]Running 10000 simulations.:  37%|███▋      | 3682/10000 [00:15<00:26, 241.37it/s]Running 10000 simulations.:  37%|███▋      | 3707/10000 [00:15<00:26, 241.33it/s]Running 10000 simulations.:  37%|███▋      | 3732/10000 [00:15<00:26, 241.07it/s]Running 10000 simulations.:  38%|███▊      | 3757/10000 [00:15<00:25, 240.97it/s]Running 10000 simulations.:  38%|███▊      | 3782/10000 [00:15<00:25, 240.64it/s]Running 10000 simulations.:  38%|███▊      | 3807/10000 [00:15<00:25, 241.00it/s]Running 10000 simulations.:  38%|███▊      | 3832/10000 [00:16<00:25, 240.66it/s]Running 10000 simulations.:  39%|███▊      | 3857/10000 [00:16<00:25, 239.46it/s]Running 10000 simulations.:  39%|███▉      | 3882/10000 [00:16<00:25, 240.35it/s]Running 10000 simulations.:  39%|███▉      | 3907/10000 [00:16<00:25, 241.73it/s]Running 10000 simulations.:  39%|███▉      | 3932/10000 [00:16<00:25, 242.55it/s]Running 10000 simulations.:  40%|███▉      | 3957/10000 [00:16<00:25, 241.47it/s]Running 10000 simulations.:  40%|███▉      | 3982/10000 [00:16<00:25, 239.25it/s]Running 10000 simulations.:  40%|████      | 4007/10000 [00:16<00:24, 240.12it/s]Running 10000 simulations.:  40%|████      | 4032/10000 [00:16<00:24, 240.18it/s]Running 10000 simulations.:  41%|████      | 4057/10000 [00:16<00:24, 239.95it/s]Running 10000 simulations.:  41%|████      | 4082/10000 [00:17<00:24, 240.93it/s]Running 10000 simulations.:  41%|████      | 4107/10000 [00:17<00:24, 240.49it/s]Running 10000 simulations.:  41%|████▏     | 4132/10000 [00:17<00:24, 238.60it/s]Running 10000 simulations.:  42%|████▏     | 4157/10000 [00:17<00:24, 240.33it/s]Running 10000 simulations.:  42%|████▏     | 4182/10000 [00:17<00:24, 240.72it/s]Running 10000 simulations.:  42%|████▏     | 4207/10000 [00:17<00:23, 241.46it/s]Running 10000 simulations.:  42%|████▏     | 4232/10000 [00:17<00:23, 241.45it/s]Running 10000 simulations.:  43%|████▎     | 4257/10000 [00:17<00:23, 241.95it/s]Running 10000 simulations.:  43%|████▎     | 4282/10000 [00:17<00:23, 243.05it/s]Running 10000 simulations.:  43%|████▎     | 4307/10000 [00:18<00:23, 243.83it/s]Running 10000 simulations.:  43%|████▎     | 4332/10000 [00:18<00:23, 242.08it/s]Running 10000 simulations.:  44%|████▎     | 4357/10000 [00:18<00:23, 240.21it/s]Running 10000 simulations.:  44%|████▍     | 4382/10000 [00:18<00:23, 239.79it/s]Running 10000 simulations.:  44%|████▍     | 4407/10000 [00:18<00:23, 239.94it/s]Running 10000 simulations.:  44%|████▍     | 4431/10000 [00:18<00:23, 239.93it/s]Running 10000 simulations.:  45%|████▍     | 4456/10000 [00:18<00:23, 240.41it/s]Running 10000 simulations.:  45%|████▍     | 4481/10000 [00:18<00:23, 239.92it/s]Running 10000 simulations.:  45%|████▌     | 4506/10000 [00:18<00:22, 240.06it/s]Running 10000 simulations.:  45%|████▌     | 4531/10000 [00:18<00:22, 239.42it/s]Running 10000 simulations.:  46%|████▌     | 4555/10000 [00:19<00:22, 237.22it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:19<00:22, 236.03it/s]Running 10000 simulations.:  46%|████▌     | 4604/10000 [00:19<00:22, 237.76it/s]Running 10000 simulations.:  46%|████▋     | 4629/10000 [00:19<00:22, 240.15it/s]Running 10000 simulations.:  47%|████▋     | 4654/10000 [00:19<00:22, 241.53it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:19<00:21, 242.60it/s]Running 10000 simulations.:  47%|████▋     | 4704/10000 [00:19<00:22, 235.41it/s]Running 10000 simulations.:  47%|████▋     | 4729/10000 [00:19<00:22, 237.51it/s]Running 10000 simulations.:  48%|████▊     | 4754/10000 [00:19<00:21, 238.99it/s]Running 10000 simulations.:  48%|████▊     | 4778/10000 [00:19<00:21, 239.09it/s]Running 10000 simulations.:  48%|████▊     | 4802/10000 [00:20<00:21, 237.69it/s]Running 10000 simulations.:  48%|████▊     | 4826/10000 [00:20<00:21, 236.85it/s]Running 10000 simulations.:  49%|████▊     | 4851/10000 [00:20<00:21, 239.47it/s]Running 10000 simulations.:  49%|████▉     | 4876/10000 [00:20<00:21, 240.82it/s]Running 10000 simulations.:  49%|████▉     | 4901/10000 [00:20<00:21, 241.34it/s]Running 10000 simulations.:  49%|████▉     | 4926/10000 [00:20<00:21, 241.42it/s]Running 10000 simulations.:  50%|████▉     | 4951/10000 [00:20<00:20, 242.17it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:20<00:20, 242.74it/s]Running 10000 simulations.:  50%|█████     | 5001/10000 [00:20<00:20, 241.80it/s]Running 10000 simulations.:  50%|█████     | 5026/10000 [00:21<00:20, 240.62it/s]Running 10000 simulations.:  51%|█████     | 5051/10000 [00:21<00:20, 240.92it/s]Running 10000 simulations.:  51%|█████     | 5076/10000 [00:21<00:20, 241.21it/s]Running 10000 simulations.:  51%|█████     | 5101/10000 [00:21<00:20, 241.94it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:21<00:20, 241.96it/s]Running 10000 simulations.:  52%|█████▏    | 5151/10000 [00:21<00:20, 241.69it/s]Running 10000 simulations.:  52%|█████▏    | 5176/10000 [00:21<00:19, 241.62it/s]Running 10000 simulations.:  52%|█████▏    | 5201/10000 [00:21<00:19, 241.55it/s]Running 10000 simulations.:  52%|█████▏    | 5226/10000 [00:21<00:19, 241.56it/s]Running 10000 simulations.:  53%|█████▎    | 5251/10000 [00:21<00:19, 240.22it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:22<00:19, 240.40it/s]Running 10000 simulations.:  53%|█████▎    | 5301/10000 [00:22<00:19, 240.88it/s]Running 10000 simulations.:  53%|█████▎    | 5326/10000 [00:22<00:19, 241.11it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:22<00:19, 241.39it/s]Running 10000 simulations.:  54%|█████▍    | 5376/10000 [00:22<00:19, 241.12it/s]Running 10000 simulations.:  54%|█████▍    | 5401/10000 [00:22<00:19, 241.45it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:22<00:18, 241.36it/s]Running 10000 simulations.:  55%|█████▍    | 5451/10000 [00:22<00:18, 240.98it/s]Running 10000 simulations.:  55%|█████▍    | 5476/10000 [00:22<00:18, 240.60it/s]Running 10000 simulations.:  55%|█████▌    | 5501/10000 [00:22<00:18, 239.63it/s]Running 10000 simulations.:  55%|█████▌    | 5526/10000 [00:23<00:18, 239.85it/s]Running 10000 simulations.:  56%|█████▌    | 5551/10000 [00:23<00:18, 240.01it/s]Running 10000 simulations.:  56%|█████▌    | 5576/10000 [00:23<00:18, 240.39it/s]Running 10000 simulations.:  56%|█████▌    | 5601/10000 [00:23<00:18, 240.82it/s]Running 10000 simulations.:  56%|█████▋    | 5626/10000 [00:23<00:18, 240.53it/s]Running 10000 simulations.:  57%|█████▋    | 5651/10000 [00:23<00:18, 239.87it/s]Running 10000 simulations.:  57%|█████▋    | 5676/10000 [00:23<00:18, 239.92it/s]Running 10000 simulations.:  57%|█████▋    | 5701/10000 [00:23<00:17, 240.65it/s]Running 10000 simulations.:  57%|█████▋    | 5726/10000 [00:23<00:17, 242.75it/s]Running 10000 simulations.:  58%|█████▊    | 5751/10000 [00:24<00:17, 242.00it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:24<00:17, 240.93it/s]Running 10000 simulations.:  58%|█████▊    | 5801/10000 [00:24<00:17, 241.09it/s]Running 10000 simulations.:  58%|█████▊    | 5826/10000 [00:24<00:17, 241.30it/s]Running 10000 simulations.:  59%|█████▊    | 5851/10000 [00:24<00:17, 241.39it/s]Running 10000 simulations.:  59%|█████▉    | 5876/10000 [00:24<00:17, 241.66it/s]Running 10000 simulations.:  59%|█████▉    | 5901/10000 [00:24<00:16, 241.35it/s]Running 10000 simulations.:  59%|█████▉    | 5926/10000 [00:24<00:16, 241.40it/s]Running 10000 simulations.:  60%|█████▉    | 5951/10000 [00:24<00:16, 242.06it/s]Running 10000 simulations.:  60%|█████▉    | 5976/10000 [00:24<00:16, 239.90it/s]Running 10000 simulations.:  60%|██████    | 6001/10000 [00:25<00:16, 240.30it/s]Running 10000 simulations.:  60%|██████    | 6026/10000 [00:25<00:16, 240.64it/s]Running 10000 simulations.:  61%|██████    | 6051/10000 [00:25<00:16, 240.77it/s]Running 10000 simulations.:  61%|██████    | 6076/10000 [00:25<00:16, 241.12it/s]Running 10000 simulations.:  61%|██████    | 6101/10000 [00:25<00:16, 240.96it/s]Running 10000 simulations.:  61%|██████▏   | 6126/10000 [00:25<00:16, 239.38it/s]Running 10000 simulations.:  62%|██████▏   | 6151/10000 [00:25<00:16, 239.81it/s]Running 10000 simulations.:  62%|██████▏   | 6176/10000 [00:25<00:15, 240.18it/s]Running 10000 simulations.:  62%|██████▏   | 6201/10000 [00:25<00:15, 239.26it/s]Running 10000 simulations.:  62%|██████▏   | 6226/10000 [00:26<00:15, 240.08it/s]Running 10000 simulations.:  63%|██████▎   | 6251/10000 [00:26<00:15, 240.50it/s]Running 10000 simulations.:  63%|██████▎   | 6276/10000 [00:26<00:15, 240.51it/s]Running 10000 simulations.:  63%|██████▎   | 6301/10000 [00:26<00:15, 240.60it/s]Running 10000 simulations.:  63%|██████▎   | 6326/10000 [00:26<00:15, 240.82it/s]Running 10000 simulations.:  64%|██████▎   | 6351/10000 [00:26<00:15, 241.38it/s]Running 10000 simulations.:  64%|██████▍   | 6376/10000 [00:26<00:14, 242.81it/s]Running 10000 simulations.:  64%|██████▍   | 6401/10000 [00:26<00:14, 243.01it/s]Running 10000 simulations.:  64%|██████▍   | 6426/10000 [00:26<00:14, 242.14it/s]Running 10000 simulations.:  65%|██████▍   | 6451/10000 [00:26<00:14, 243.16it/s]Running 10000 simulations.:  65%|██████▍   | 6476/10000 [00:27<00:14, 244.04it/s]Running 10000 simulations.:  65%|██████▌   | 6501/10000 [00:27<00:14, 244.17it/s]Running 10000 simulations.:  65%|██████▌   | 6526/10000 [00:27<00:14, 244.06it/s]Running 10000 simulations.:  66%|██████▌   | 6551/10000 [00:27<00:14, 243.38it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:27<00:14, 243.53it/s]Running 10000 simulations.:  66%|██████▌   | 6601/10000 [00:27<00:13, 244.45it/s]Running 10000 simulations.:  66%|██████▋   | 6626/10000 [00:27<00:13, 243.99it/s]Running 10000 simulations.:  67%|██████▋   | 6651/10000 [00:27<00:13, 242.17it/s]Running 10000 simulations.:  67%|██████▋   | 6676/10000 [00:27<00:13, 242.33it/s]Running 10000 simulations.:  67%|██████▋   | 6701/10000 [00:27<00:13, 242.68it/s]Running 10000 simulations.:  67%|██████▋   | 6726/10000 [00:28<00:13, 243.28it/s]Running 10000 simulations.:  68%|██████▊   | 6751/10000 [00:28<00:13, 243.52it/s]Running 10000 simulations.:  68%|██████▊   | 6776/10000 [00:28<00:13, 244.36it/s]Running 10000 simulations.:  68%|██████▊   | 6801/10000 [00:28<00:13, 244.74it/s]Running 10000 simulations.:  68%|██████▊   | 6826/10000 [00:28<00:12, 244.27it/s]Running 10000 simulations.:  69%|██████▊   | 6851/10000 [00:28<00:12, 243.84it/s]Running 10000 simulations.:  69%|██████▉   | 6876/10000 [00:28<00:12, 242.31it/s]Running 10000 simulations.:  69%|██████▉   | 6901/10000 [00:28<00:12, 242.04it/s]Running 10000 simulations.:  69%|██████▉   | 6926/10000 [00:28<00:12, 242.04it/s]Running 10000 simulations.:  70%|██████▉   | 6951/10000 [00:28<00:12, 241.73it/s]Running 10000 simulations.:  70%|██████▉   | 6976/10000 [00:29<00:12, 242.19it/s]Running 10000 simulations.:  70%|███████   | 7001/10000 [00:29<00:12, 243.24it/s]Running 10000 simulations.:  70%|███████   | 7026/10000 [00:29<00:12, 243.33it/s]Running 10000 simulations.:  71%|███████   | 7051/10000 [00:29<00:12, 244.31it/s]Running 10000 simulations.:  71%|███████   | 7076/10000 [00:29<00:11, 245.20it/s]Running 10000 simulations.:  71%|███████   | 7101/10000 [00:29<00:11, 242.67it/s]Running 10000 simulations.:  71%|███████▏  | 7126/10000 [00:29<00:11, 242.83it/s]Running 10000 simulations.:  72%|███████▏  | 7151/10000 [00:29<00:11, 242.96it/s]Running 10000 simulations.:  72%|███████▏  | 7176/10000 [00:29<00:11, 243.67it/s]Running 10000 simulations.:  72%|███████▏  | 7201/10000 [00:30<00:11, 244.21it/s]Running 10000 simulations.:  72%|███████▏  | 7226/10000 [00:30<00:11, 244.83it/s]Running 10000 simulations.:  73%|███████▎  | 7251/10000 [00:30<00:11, 245.08it/s]Running 10000 simulations.:  73%|███████▎  | 7276/10000 [00:30<00:11, 243.97it/s]Running 10000 simulations.:  73%|███████▎  | 7301/10000 [00:30<00:11, 242.95it/s]Running 10000 simulations.:  73%|███████▎  | 7326/10000 [00:30<00:11, 241.12it/s]Running 10000 simulations.:  74%|███████▎  | 7351/10000 [00:30<00:10, 241.19it/s]Running 10000 simulations.:  74%|███████▍  | 7376/10000 [00:30<00:10, 241.68it/s]Running 10000 simulations.:  74%|███████▍  | 7401/10000 [00:30<00:10, 242.84it/s]Running 10000 simulations.:  74%|███████▍  | 7426/10000 [00:30<00:10, 243.33it/s]Running 10000 simulations.:  75%|███████▍  | 7451/10000 [00:31<00:10, 240.74it/s]Running 10000 simulations.:  75%|███████▍  | 7476/10000 [00:31<00:10, 240.50it/s]Running 10000 simulations.:  75%|███████▌  | 7501/10000 [00:31<00:10, 241.04it/s]Running 10000 simulations.:  75%|███████▌  | 7526/10000 [00:31<00:10, 241.08it/s]Running 10000 simulations.:  76%|███████▌  | 7551/10000 [00:31<00:10, 241.72it/s]Running 10000 simulations.:  76%|███████▌  | 7576/10000 [00:31<00:09, 242.59it/s]Running 10000 simulations.:  76%|███████▌  | 7601/10000 [00:31<00:09, 241.59it/s]Running 10000 simulations.:  76%|███████▋  | 7626/10000 [00:31<00:09, 241.43it/s]Running 10000 simulations.:  77%|███████▋  | 7651/10000 [00:31<00:09, 241.58it/s]Running 10000 simulations.:  77%|███████▋  | 7676/10000 [00:31<00:09, 242.27it/s]Running 10000 simulations.:  77%|███████▋  | 7701/10000 [00:32<00:09, 242.48it/s]Running 10000 simulations.:  77%|███████▋  | 7726/10000 [00:32<00:09, 243.41it/s]Running 10000 simulations.:  78%|███████▊  | 7751/10000 [00:32<00:09, 243.95it/s]Running 10000 simulations.:  78%|███████▊  | 7776/10000 [00:32<00:09, 244.90it/s]Running 10000 simulations.:  78%|███████▊  | 7801/10000 [00:32<00:08, 245.33it/s]Running 10000 simulations.:  78%|███████▊  | 7826/10000 [00:32<00:08, 243.30it/s]Running 10000 simulations.:  79%|███████▊  | 7851/10000 [00:32<00:08, 241.36it/s]Running 10000 simulations.:  79%|███████▉  | 7876/10000 [00:32<00:08, 242.30it/s]Running 10000 simulations.:  79%|███████▉  | 7901/10000 [00:32<00:08, 242.46it/s]Running 10000 simulations.:  79%|███████▉  | 7926/10000 [00:33<00:08, 242.85it/s]Running 10000 simulations.:  80%|███████▉  | 7951/10000 [00:33<00:08, 242.77it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:33<00:08, 241.60it/s]Running 10000 simulations.:  80%|████████  | 8001/10000 [00:33<00:08, 241.08it/s]Running 10000 simulations.:  80%|████████  | 8026/10000 [00:33<00:08, 241.97it/s]Running 10000 simulations.:  81%|████████  | 8051/10000 [00:33<00:08, 241.74it/s]Running 10000 simulations.:  81%|████████  | 8076/10000 [00:33<00:08, 239.99it/s]Running 10000 simulations.:  81%|████████  | 8101/10000 [00:33<00:07, 240.72it/s]Running 10000 simulations.:  81%|████████▏ | 8126/10000 [00:33<00:07, 242.29it/s]Running 10000 simulations.:  82%|████████▏ | 8151/10000 [00:33<00:07, 243.23it/s]Running 10000 simulations.:  82%|████████▏ | 8176/10000 [00:34<00:07, 243.18it/s]Running 10000 simulations.:  82%|████████▏ | 8201/10000 [00:34<00:07, 242.42it/s]Running 10000 simulations.:  82%|████████▏ | 8226/10000 [00:34<00:07, 242.86it/s]Running 10000 simulations.:  83%|████████▎ | 8251/10000 [00:34<00:07, 243.42it/s]Running 10000 simulations.:  83%|████████▎ | 8276/10000 [00:34<00:07, 243.58it/s]Running 10000 simulations.:  83%|████████▎ | 8301/10000 [00:34<00:07, 242.70it/s]Running 10000 simulations.:  83%|████████▎ | 8326/10000 [00:34<00:06, 242.63it/s]Running 10000 simulations.:  84%|████████▎ | 8351/10000 [00:34<00:06, 242.03it/s]Running 10000 simulations.:  84%|████████▍ | 8376/10000 [00:34<00:06, 241.73it/s]Running 10000 simulations.:  84%|████████▍ | 8401/10000 [00:34<00:06, 242.31it/s]Running 10000 simulations.:  84%|████████▍ | 8426/10000 [00:35<00:06, 243.61it/s]Running 10000 simulations.:  85%|████████▍ | 8451/10000 [00:35<00:06, 244.15it/s]Running 10000 simulations.:  85%|████████▍ | 8476/10000 [00:35<00:06, 243.30it/s]Running 10000 simulations.:  85%|████████▌ | 8501/10000 [00:35<00:06, 244.73it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [00:35<00:06, 243.83it/s]Running 10000 simulations.:  86%|████████▌ | 8551/10000 [00:35<00:05, 242.29it/s]Running 10000 simulations.:  86%|████████▌ | 8576/10000 [00:35<00:05, 242.17it/s]Running 10000 simulations.:  86%|████████▌ | 8601/10000 [00:35<00:05, 242.98it/s]Running 10000 simulations.:  86%|████████▋ | 8626/10000 [00:35<00:05, 243.86it/s]Running 10000 simulations.:  87%|████████▋ | 8651/10000 [00:35<00:05, 241.86it/s]Running 10000 simulations.:  87%|████████▋ | 8676/10000 [00:36<00:05, 241.93it/s]Running 10000 simulations.:  87%|████████▋ | 8701/10000 [00:36<00:05, 242.88it/s]Running 10000 simulations.:  87%|████████▋ | 8726/10000 [00:36<00:05, 242.61it/s]Running 10000 simulations.:  88%|████████▊ | 8751/10000 [00:36<00:05, 242.56it/s]Running 10000 simulations.:  88%|████████▊ | 8776/10000 [00:36<00:05, 240.76it/s]Running 10000 simulations.:  88%|████████▊ | 8801/10000 [00:36<00:04, 240.83it/s]Running 10000 simulations.:  88%|████████▊ | 8826/10000 [00:36<00:04, 240.66it/s]Running 10000 simulations.:  89%|████████▊ | 8851/10000 [00:36<00:04, 241.47it/s]Running 10000 simulations.:  89%|████████▉ | 8876/10000 [00:36<00:04, 242.99it/s]Running 10000 simulations.:  89%|████████▉ | 8901/10000 [00:37<00:04, 242.53it/s]Running 10000 simulations.:  89%|████████▉ | 8926/10000 [00:37<00:04, 242.10it/s]Running 10000 simulations.:  90%|████████▉ | 8951/10000 [00:37<00:04, 242.19it/s]Running 10000 simulations.:  90%|████████▉ | 8976/10000 [00:37<00:04, 241.11it/s]Running 10000 simulations.:  90%|█████████ | 9001/10000 [00:37<00:04, 239.46it/s]Running 10000 simulations.:  90%|█████████ | 9025/10000 [00:37<00:04, 239.59it/s]Running 10000 simulations.:  90%|█████████ | 9050/10000 [00:37<00:03, 239.87it/s]Running 10000 simulations.:  91%|█████████ | 9075/10000 [00:37<00:03, 240.37it/s]Running 10000 simulations.:  91%|█████████ | 9100/10000 [00:37<00:03, 241.72it/s]Running 10000 simulations.:  91%|█████████▏| 9125/10000 [00:37<00:03, 241.45it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [00:38<00:03, 240.19it/s]Running 10000 simulations.:  92%|█████████▏| 9175/10000 [00:38<00:03, 240.42it/s]Running 10000 simulations.:  92%|█████████▏| 9200/10000 [00:38<00:03, 241.13it/s]Running 10000 simulations.:  92%|█████████▏| 9225/10000 [00:38<00:03, 241.71it/s]Running 10000 simulations.:  92%|█████████▎| 9250/10000 [00:38<00:03, 241.17it/s]Running 10000 simulations.:  93%|█████████▎| 9275/10000 [00:38<00:03, 239.66it/s]Running 10000 simulations.:  93%|█████████▎| 9300/10000 [00:38<00:02, 239.85it/s]Running 10000 simulations.:  93%|█████████▎| 9325/10000 [00:38<00:02, 239.98it/s]Running 10000 simulations.:  94%|█████████▎| 9350/10000 [00:38<00:02, 240.39it/s]Running 10000 simulations.:  94%|█████████▍| 9375/10000 [00:38<00:02, 241.28it/s]Running 10000 simulations.:  94%|█████████▍| 9400/10000 [00:39<00:02, 241.26it/s]Running 10000 simulations.:  94%|█████████▍| 9425/10000 [00:39<00:02, 241.30it/s]Running 10000 simulations.:  94%|█████████▍| 9450/10000 [00:39<00:02, 241.49it/s]Running 10000 simulations.:  95%|█████████▍| 9475/10000 [00:39<00:02, 241.35it/s]Running 10000 simulations.:  95%|█████████▌| 9500/10000 [00:39<00:02, 239.96it/s]Running 10000 simulations.:  95%|█████████▌| 9525/10000 [00:39<00:01, 241.27it/s]Running 10000 simulations.:  96%|█████████▌| 9550/10000 [00:39<00:01, 241.43it/s]Running 10000 simulations.:  96%|█████████▌| 9575/10000 [00:39<00:01, 239.42it/s]Running 10000 simulations.:  96%|█████████▌| 9599/10000 [00:39<00:01, 238.73it/s]Running 10000 simulations.:  96%|█████████▌| 9624/10000 [00:40<00:01, 239.26it/s]Running 10000 simulations.:  96%|█████████▋| 9649/10000 [00:40<00:01, 239.86it/s]Running 10000 simulations.:  97%|█████████▋| 9674/10000 [00:40<00:01, 241.07it/s]Running 10000 simulations.:  97%|█████████▋| 9699/10000 [00:40<00:01, 240.72it/s]Running 10000 simulations.:  97%|█████████▋| 9724/10000 [00:40<00:01, 240.20it/s]Running 10000 simulations.:  97%|█████████▋| 9749/10000 [00:40<00:01, 240.86it/s]Running 10000 simulations.:  98%|█████████▊| 9774/10000 [00:40<00:00, 241.26it/s]Running 10000 simulations.:  98%|█████████▊| 9799/10000 [00:40<00:00, 242.09it/s]Running 10000 simulations.:  98%|█████████▊| 9824/10000 [00:40<00:00, 242.65it/s]Running 10000 simulations.:  98%|█████████▊| 9849/10000 [00:40<00:00, 243.66it/s]Running 10000 simulations.:  99%|█████████▊| 9874/10000 [00:41<00:00, 245.16it/s]Running 10000 simulations.:  99%|█████████▉| 9900/10000 [00:41<00:00, 247.25it/s]Running 10000 simulations.:  99%|█████████▉| 9925/10000 [00:41<00:00, 245.84it/s]Running 10000 simulations.: 100%|█████████▉| 9950/10000 [00:41<00:00, 245.82it/s]Running 10000 simulations.: 100%|█████████▉| 9975/10000 [00:41<00:00, 245.32it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 245.09it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 240.55it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 27/10000 [00:00<00:37, 264.74it/s]Running 10000 simulations.:   1%|          | 54/10000 [00:00<00:37, 264.43it/s]Running 10000 simulations.:   1%|          | 81/10000 [00:00<00:37, 263.22it/s]Running 10000 simulations.:   1%|          | 107/10000 [00:00<00:37, 261.64it/s]Running 10000 simulations.:   1%|▏         | 133/10000 [00:00<00:37, 260.60it/s]Running 10000 simulations.:   2%|▏         | 159/10000 [00:00<00:37, 259.88it/s]Running 10000 simulations.:   2%|▏         | 185/10000 [00:00<00:37, 259.49it/s]Running 10000 simulations.:   2%|▏         | 211/10000 [00:00<00:37, 259.10it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:00<00:37, 259.81it/s]Running 10000 simulations.:   3%|▎         | 264/10000 [00:01<00:37, 259.63it/s]Running 10000 simulations.:   3%|▎         | 290/10000 [00:01<00:37, 259.11it/s]Running 10000 simulations.:   3%|▎         | 316/10000 [00:01<00:37, 259.30it/s]Running 10000 simulations.:   3%|▎         | 342/10000 [00:01<00:37, 257.91it/s]Running 10000 simulations.:   4%|▎         | 368/10000 [00:01<00:37, 257.34it/s]Running 10000 simulations.:   4%|▍         | 394/10000 [00:01<00:37, 256.25it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:37, 256.00it/s]Running 10000 simulations.:   4%|▍         | 446/10000 [00:01<00:37, 256.09it/s]Running 10000 simulations.:   5%|▍         | 472/10000 [00:01<00:37, 256.47it/s]Running 10000 simulations.:   5%|▍         | 498/10000 [00:01<00:37, 256.54it/s]Running 10000 simulations.:   5%|▌         | 524/10000 [00:02<00:36, 256.90it/s]Running 10000 simulations.:   6%|▌         | 550/10000 [00:02<00:36, 256.97it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:02<00:36, 256.40it/s]Running 10000 simulations.:   6%|▌         | 602/10000 [00:02<00:36, 256.06it/s]Running 10000 simulations.:   6%|▋         | 628/10000 [00:02<00:36, 255.77it/s]Running 10000 simulations.:   7%|▋         | 654/10000 [00:02<00:36, 254.37it/s]Running 10000 simulations.:   7%|▋         | 680/10000 [00:02<00:36, 254.09it/s]Running 10000 simulations.:   7%|▋         | 706/10000 [00:02<00:36, 253.54it/s]Running 10000 simulations.:   7%|▋         | 732/10000 [00:02<00:36, 253.90it/s]Running 10000 simulations.:   8%|▊         | 758/10000 [00:02<00:36, 254.16it/s]Running 10000 simulations.:   8%|▊         | 784/10000 [00:03<00:36, 254.22it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:03<00:36, 254.34it/s]Running 10000 simulations.:   8%|▊         | 836/10000 [00:03<00:35, 254.79it/s]Running 10000 simulations.:   9%|▊         | 862/10000 [00:03<00:35, 255.66it/s]Running 10000 simulations.:   9%|▉         | 888/10000 [00:03<00:35, 255.63it/s]Running 10000 simulations.:   9%|▉         | 914/10000 [00:03<00:35, 255.77it/s]Running 10000 simulations.:   9%|▉         | 940/10000 [00:03<00:35, 255.81it/s]Running 10000 simulations.:  10%|▉         | 966/10000 [00:03<00:35, 254.80it/s]Running 10000 simulations.:  10%|▉         | 992/10000 [00:03<00:35, 254.92it/s]Running 10000 simulations.:  10%|█         | 1018/10000 [00:03<00:35, 255.51it/s]Running 10000 simulations.:  10%|█         | 1044/10000 [00:04<00:35, 254.91it/s]Running 10000 simulations.:  11%|█         | 1070/10000 [00:04<00:34, 255.45it/s]Running 10000 simulations.:  11%|█         | 1096/10000 [00:04<00:34, 254.79it/s]Running 10000 simulations.:  11%|█         | 1122/10000 [00:04<00:34, 254.52it/s]Running 10000 simulations.:  11%|█▏        | 1148/10000 [00:04<00:34, 253.76it/s]Running 10000 simulations.:  12%|█▏        | 1174/10000 [00:04<00:35, 249.98it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:35, 250.90it/s]Running 10000 simulations.:  12%|█▏        | 1226/10000 [00:04<00:34, 252.12it/s]Running 10000 simulations.:  13%|█▎        | 1252/10000 [00:04<00:34, 252.63it/s]Running 10000 simulations.:  13%|█▎        | 1278/10000 [00:04<00:34, 252.51it/s]Running 10000 simulations.:  13%|█▎        | 1304/10000 [00:05<00:34, 252.61it/s]Running 10000 simulations.:  13%|█▎        | 1330/10000 [00:05<00:34, 253.22it/s]Running 10000 simulations.:  14%|█▎        | 1356/10000 [00:05<00:34, 251.24it/s]Running 10000 simulations.:  14%|█▍        | 1382/10000 [00:05<00:34, 250.06it/s]Running 10000 simulations.:  14%|█▍        | 1408/10000 [00:05<00:34, 250.50it/s]Running 10000 simulations.:  14%|█▍        | 1434/10000 [00:05<00:34, 250.82it/s]Running 10000 simulations.:  15%|█▍        | 1460/10000 [00:05<00:33, 251.85it/s]Running 10000 simulations.:  15%|█▍        | 1486/10000 [00:05<00:33, 252.06it/s]Running 10000 simulations.:  15%|█▌        | 1512/10000 [00:05<00:33, 251.94it/s]Running 10000 simulations.:  15%|█▌        | 1538/10000 [00:06<00:33, 252.75it/s]Running 10000 simulations.:  16%|█▌        | 1564/10000 [00:06<00:33, 252.75it/s]Running 10000 simulations.:  16%|█▌        | 1590/10000 [00:06<00:33, 252.84it/s]Running 10000 simulations.:  16%|█▌        | 1616/10000 [00:06<00:33, 251.31it/s]Running 10000 simulations.:  16%|█▋        | 1642/10000 [00:06<00:33, 251.31it/s]Running 10000 simulations.:  17%|█▋        | 1668/10000 [00:06<00:33, 251.95it/s]Running 10000 simulations.:  17%|█▋        | 1694/10000 [00:06<00:32, 252.31it/s]Running 10000 simulations.:  17%|█▋        | 1720/10000 [00:06<00:32, 252.99it/s]Running 10000 simulations.:  17%|█▋        | 1746/10000 [00:06<00:32, 253.18it/s]Running 10000 simulations.:  18%|█▊        | 1772/10000 [00:06<00:32, 252.92it/s]Running 10000 simulations.:  18%|█▊        | 1798/10000 [00:07<00:32, 252.68it/s]Running 10000 simulations.:  18%|█▊        | 1824/10000 [00:07<00:32, 251.90it/s]Running 10000 simulations.:  18%|█▊        | 1850/10000 [00:07<00:32, 251.73it/s]Running 10000 simulations.:  19%|█▉        | 1876/10000 [00:07<00:32, 251.03it/s]Running 10000 simulations.:  19%|█▉        | 1902/10000 [00:07<00:32, 250.90it/s]Running 10000 simulations.:  19%|█▉        | 1928/10000 [00:07<00:32, 251.14it/s]Running 10000 simulations.:  20%|█▉        | 1954/10000 [00:07<00:32, 248.10it/s]Running 10000 simulations.:  20%|█▉        | 1979/10000 [00:07<00:32, 247.77it/s]Running 10000 simulations.:  20%|██        | 2005/10000 [00:07<00:32, 248.87it/s]Running 10000 simulations.:  20%|██        | 2031/10000 [00:07<00:31, 250.06it/s]Running 10000 simulations.:  21%|██        | 2057/10000 [00:08<00:31, 250.27it/s]Running 10000 simulations.:  21%|██        | 2083/10000 [00:08<00:31, 250.67it/s]Running 10000 simulations.:  21%|██        | 2109/10000 [00:08<00:31, 251.22it/s]Running 10000 simulations.:  21%|██▏       | 2135/10000 [00:08<00:31, 251.43it/s]Running 10000 simulations.:  22%|██▏       | 2161/10000 [00:08<00:31, 252.30it/s]Running 10000 simulations.:  22%|██▏       | 2187/10000 [00:08<00:31, 251.50it/s]Running 10000 simulations.:  22%|██▏       | 2213/10000 [00:08<00:31, 250.83it/s]Running 10000 simulations.:  22%|██▏       | 2239/10000 [00:08<00:30, 250.77it/s]Running 10000 simulations.:  23%|██▎       | 2265/10000 [00:08<00:30, 250.79it/s]Running 10000 simulations.:  23%|██▎       | 2291/10000 [00:09<00:30, 250.93it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:09<00:30, 251.95it/s]Running 10000 simulations.:  23%|██▎       | 2343/10000 [00:09<00:30, 251.75it/s]Running 10000 simulations.:  24%|██▎       | 2369/10000 [00:09<00:30, 251.42it/s]Running 10000 simulations.:  24%|██▍       | 2395/10000 [00:09<00:30, 250.77it/s]Running 10000 simulations.:  24%|██▍       | 2421/10000 [00:09<00:30, 250.77it/s]Running 10000 simulations.:  24%|██▍       | 2447/10000 [00:09<00:30, 250.64it/s]Running 10000 simulations.:  25%|██▍       | 2473/10000 [00:09<00:29, 251.35it/s]Running 10000 simulations.:  25%|██▍       | 2499/10000 [00:09<00:29, 251.71it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:09<00:29, 251.79it/s]Running 10000 simulations.:  26%|██▌       | 2551/10000 [00:10<00:29, 252.07it/s]Running 10000 simulations.:  26%|██▌       | 2577/10000 [00:10<00:29, 252.08it/s]Running 10000 simulations.:  26%|██▌       | 2603/10000 [00:10<00:29, 252.32it/s]Running 10000 simulations.:  26%|██▋       | 2629/10000 [00:10<00:29, 251.96it/s]Running 10000 simulations.:  27%|██▋       | 2655/10000 [00:10<00:29, 251.78it/s]Running 10000 simulations.:  27%|██▋       | 2681/10000 [00:10<00:29, 251.31it/s]Running 10000 simulations.:  27%|██▋       | 2707/10000 [00:10<00:29, 250.90it/s]Running 10000 simulations.:  27%|██▋       | 2733/10000 [00:10<00:29, 250.46it/s]Running 10000 simulations.:  28%|██▊       | 2759/10000 [00:10<00:28, 251.50it/s]Running 10000 simulations.:  28%|██▊       | 2785/10000 [00:10<00:28, 251.99it/s]Running 10000 simulations.:  28%|██▊       | 2811/10000 [00:11<00:28, 251.59it/s]Running 10000 simulations.:  28%|██▊       | 2837/10000 [00:11<00:28, 251.23it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:11<00:28, 251.88it/s]Running 10000 simulations.:  29%|██▉       | 2889/10000 [00:11<00:28, 251.09it/s]Running 10000 simulations.:  29%|██▉       | 2915/10000 [00:11<00:28, 250.48it/s]Running 10000 simulations.:  29%|██▉       | 2941/10000 [00:11<00:28, 250.26it/s]Running 10000 simulations.:  30%|██▉       | 2967/10000 [00:11<00:28, 250.18it/s]Running 10000 simulations.:  30%|██▉       | 2993/10000 [00:11<00:28, 250.09it/s]Running 10000 simulations.:  30%|███       | 3019/10000 [00:11<00:27, 250.30it/s]Running 10000 simulations.:  30%|███       | 3045/10000 [00:12<00:27, 250.53it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:12<00:27, 250.76it/s]Running 10000 simulations.:  31%|███       | 3097/10000 [00:12<00:27, 250.93it/s]Running 10000 simulations.:  31%|███       | 3123/10000 [00:12<00:27, 251.22it/s]Running 10000 simulations.:  31%|███▏      | 3149/10000 [00:12<00:27, 251.26it/s]Running 10000 simulations.:  32%|███▏      | 3175/10000 [00:12<00:27, 250.84it/s]Running 10000 simulations.:  32%|███▏      | 3201/10000 [00:12<00:27, 250.51it/s]Running 10000 simulations.:  32%|███▏      | 3227/10000 [00:12<00:26, 250.87it/s]Running 10000 simulations.:  33%|███▎      | 3253/10000 [00:12<00:26, 250.64it/s]Running 10000 simulations.:  33%|███▎      | 3279/10000 [00:12<00:26, 250.21it/s]Running 10000 simulations.:  33%|███▎      | 3305/10000 [00:13<00:26, 250.84it/s]Running 10000 simulations.:  33%|███▎      | 3331/10000 [00:13<00:26, 251.36it/s]Running 10000 simulations.:  34%|███▎      | 3357/10000 [00:13<00:26, 250.98it/s]Running 10000 simulations.:  34%|███▍      | 3383/10000 [00:13<00:26, 250.85it/s]Running 10000 simulations.:  34%|███▍      | 3409/10000 [00:13<00:26, 251.03it/s]Running 10000 simulations.:  34%|███▍      | 3435/10000 [00:13<00:26, 250.58it/s]Running 10000 simulations.:  35%|███▍      | 3461/10000 [00:13<00:26, 250.56it/s]Running 10000 simulations.:  35%|███▍      | 3487/10000 [00:13<00:25, 250.71it/s]Running 10000 simulations.:  35%|███▌      | 3513/10000 [00:13<00:25, 250.95it/s]Running 10000 simulations.:  35%|███▌      | 3539/10000 [00:13<00:25, 251.01it/s]Running 10000 simulations.:  36%|███▌      | 3565/10000 [00:14<00:25, 251.33it/s]Running 10000 simulations.:  36%|███▌      | 3591/10000 [00:14<00:25, 251.92it/s]Running 10000 simulations.:  36%|███▌      | 3617/10000 [00:14<00:25, 252.51it/s]Running 10000 simulations.:  36%|███▋      | 3643/10000 [00:14<00:25, 252.16it/s]Running 10000 simulations.:  37%|███▋      | 3669/10000 [00:14<00:25, 251.84it/s]Running 10000 simulations.:  37%|███▋      | 3695/10000 [00:14<00:25, 248.44it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:14<00:25, 248.36it/s]Running 10000 simulations.:  37%|███▋      | 3746/10000 [00:14<00:25, 249.25it/s]Running 10000 simulations.:  38%|███▊      | 3772/10000 [00:14<00:24, 250.14it/s]Running 10000 simulations.:  38%|███▊      | 3798/10000 [00:15<00:24, 250.22it/s]Running 10000 simulations.:  38%|███▊      | 3824/10000 [00:15<00:24, 249.88it/s]Running 10000 simulations.:  38%|███▊      | 3850/10000 [00:15<00:24, 250.31it/s]Running 10000 simulations.:  39%|███▉      | 3876/10000 [00:15<00:24, 250.37it/s]Running 10000 simulations.:  39%|███▉      | 3902/10000 [00:15<00:24, 250.39it/s]Running 10000 simulations.:  39%|███▉      | 3928/10000 [00:15<00:24, 250.16it/s]Running 10000 simulations.:  40%|███▉      | 3954/10000 [00:15<00:24, 249.82it/s]Running 10000 simulations.:  40%|███▉      | 3979/10000 [00:15<00:24, 249.15it/s]Running 10000 simulations.:  40%|████      | 4004/10000 [00:15<00:24, 249.23it/s]Running 10000 simulations.:  40%|████      | 4030/10000 [00:15<00:23, 249.56it/s]Running 10000 simulations.:  41%|████      | 4056/10000 [00:16<00:23, 250.32it/s]Running 10000 simulations.:  41%|████      | 4082/10000 [00:16<00:23, 250.08it/s]Running 10000 simulations.:  41%|████      | 4108/10000 [00:16<00:23, 250.46it/s]Running 10000 simulations.:  41%|████▏     | 4134/10000 [00:16<00:23, 250.67it/s]Running 10000 simulations.:  42%|████▏     | 4160/10000 [00:16<00:23, 251.17it/s]Running 10000 simulations.:  42%|████▏     | 4186/10000 [00:16<00:23, 250.89it/s]Running 10000 simulations.:  42%|████▏     | 4212/10000 [00:16<00:23, 250.50it/s]Running 10000 simulations.:  42%|████▏     | 4238/10000 [00:16<00:23, 250.05it/s]Running 10000 simulations.:  43%|████▎     | 4264/10000 [00:16<00:22, 249.79it/s]Running 10000 simulations.:  43%|████▎     | 4289/10000 [00:16<00:22, 249.61it/s]Running 10000 simulations.:  43%|████▎     | 4314/10000 [00:17<00:22, 249.60it/s]Running 10000 simulations.:  43%|████▎     | 4340/10000 [00:17<00:22, 249.91it/s]Running 10000 simulations.:  44%|████▎     | 4365/10000 [00:17<00:22, 249.56it/s]Running 10000 simulations.:  44%|████▍     | 4390/10000 [00:17<00:22, 249.36it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:17<00:22, 248.55it/s]Running 10000 simulations.:  44%|████▍     | 4440/10000 [00:17<00:22, 248.41it/s]Running 10000 simulations.:  45%|████▍     | 4465/10000 [00:17<00:22, 248.16it/s]Running 10000 simulations.:  45%|████▍     | 4490/10000 [00:17<00:22, 248.71it/s]Running 10000 simulations.:  45%|████▌     | 4516/10000 [00:17<00:21, 249.27it/s]Running 10000 simulations.:  45%|████▌     | 4541/10000 [00:18<00:21, 249.16it/s]Running 10000 simulations.:  46%|████▌     | 4567/10000 [00:18<00:21, 249.45it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:18<00:21, 249.40it/s]Running 10000 simulations.:  46%|████▌     | 4617/10000 [00:18<00:21, 249.48it/s]Running 10000 simulations.:  46%|████▋     | 4642/10000 [00:18<00:21, 249.35it/s]Running 10000 simulations.:  47%|████▋     | 4667/10000 [00:18<00:21, 248.90it/s]Running 10000 simulations.:  47%|████▋     | 4692/10000 [00:18<00:21, 248.97it/s]Running 10000 simulations.:  47%|████▋     | 4717/10000 [00:18<00:21, 245.43it/s]Running 10000 simulations.:  47%|████▋     | 4742/10000 [00:18<00:21, 245.61it/s]Running 10000 simulations.:  48%|████▊     | 4768/10000 [00:18<00:21, 246.92it/s]Running 10000 simulations.:  48%|████▊     | 4793/10000 [00:19<00:21, 247.25it/s]Running 10000 simulations.:  48%|████▊     | 4818/10000 [00:19<00:21, 246.75it/s]Running 10000 simulations.:  48%|████▊     | 4843/10000 [00:19<00:20, 246.77it/s]Running 10000 simulations.:  49%|████▊     | 4868/10000 [00:19<00:20, 247.14it/s]Running 10000 simulations.:  49%|████▉     | 4893/10000 [00:19<00:20, 247.36it/s]Running 10000 simulations.:  49%|████▉     | 4918/10000 [00:19<00:20, 247.13it/s]Running 10000 simulations.:  49%|████▉     | 4943/10000 [00:19<00:20, 247.41it/s]Running 10000 simulations.:  50%|████▉     | 4968/10000 [00:19<00:20, 247.59it/s]Running 10000 simulations.:  50%|████▉     | 4993/10000 [00:19<00:20, 247.63it/s]Running 10000 simulations.:  50%|█████     | 5018/10000 [00:19<00:20, 247.53it/s]Running 10000 simulations.:  50%|█████     | 5043/10000 [00:20<00:20, 247.27it/s]Running 10000 simulations.:  51%|█████     | 5068/10000 [00:20<00:19, 247.88it/s]Running 10000 simulations.:  51%|█████     | 5094/10000 [00:20<00:19, 248.63it/s]Running 10000 simulations.:  51%|█████     | 5120/10000 [00:20<00:19, 249.56it/s]Running 10000 simulations.:  51%|█████▏    | 5145/10000 [00:20<00:19, 248.94it/s]Running 10000 simulations.:  52%|█████▏    | 5170/10000 [00:20<00:19, 249.01it/s]Running 10000 simulations.:  52%|█████▏    | 5195/10000 [00:20<00:19, 248.92it/s]Running 10000 simulations.:  52%|█████▏    | 5221/10000 [00:20<00:19, 249.39it/s]Running 10000 simulations.:  52%|█████▏    | 5246/10000 [00:20<00:19, 248.74it/s]Running 10000 simulations.:  53%|█████▎    | 5271/10000 [00:20<00:19, 248.80it/s]Running 10000 simulations.:  53%|█████▎    | 5296/10000 [00:21<00:18, 248.75it/s]Running 10000 simulations.:  53%|█████▎    | 5322/10000 [00:21<00:18, 249.65it/s]Running 10000 simulations.:  53%|█████▎    | 5347/10000 [00:21<00:18, 249.20it/s]Running 10000 simulations.:  54%|█████▎    | 5372/10000 [00:21<00:18, 248.70it/s]Running 10000 simulations.:  54%|█████▍    | 5397/10000 [00:21<00:18, 248.07it/s]Running 10000 simulations.:  54%|█████▍    | 5422/10000 [00:21<00:18, 248.57it/s]Running 10000 simulations.:  54%|█████▍    | 5447/10000 [00:21<00:18, 248.24it/s]Running 10000 simulations.:  55%|█████▍    | 5472/10000 [00:21<00:18, 248.25it/s]Running 10000 simulations.:  55%|█████▍    | 5497/10000 [00:21<00:18, 247.76it/s]Running 10000 simulations.:  55%|█████▌    | 5522/10000 [00:21<00:18, 248.06it/s]Running 10000 simulations.:  55%|█████▌    | 5547/10000 [00:22<00:17, 247.94it/s]Running 10000 simulations.:  56%|█████▌    | 5572/10000 [00:22<00:17, 248.14it/s]Running 10000 simulations.:  56%|█████▌    | 5597/10000 [00:22<00:17, 248.06it/s]Running 10000 simulations.:  56%|█████▌    | 5623/10000 [00:22<00:17, 248.72it/s]Running 10000 simulations.:  56%|█████▋    | 5649/10000 [00:22<00:17, 249.47it/s]Running 10000 simulations.:  57%|█████▋    | 5675/10000 [00:22<00:17, 249.87it/s]Running 10000 simulations.:  57%|█████▋    | 5701/10000 [00:22<00:17, 249.95it/s]Running 10000 simulations.:  57%|█████▋    | 5726/10000 [00:22<00:17, 248.37it/s]Running 10000 simulations.:  58%|█████▊    | 5751/10000 [00:22<00:17, 248.71it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:22<00:17, 248.29it/s]Running 10000 simulations.:  58%|█████▊    | 5801/10000 [00:23<00:16, 248.55it/s]Running 10000 simulations.:  58%|█████▊    | 5827/10000 [00:23<00:16, 249.05it/s]Running 10000 simulations.:  59%|█████▊    | 5852/10000 [00:23<00:16, 249.20it/s]Running 10000 simulations.:  59%|█████▉    | 5877/10000 [00:23<00:16, 249.22it/s]Running 10000 simulations.:  59%|█████▉    | 5902/10000 [00:23<00:16, 249.04it/s]Running 10000 simulations.:  59%|█████▉    | 5927/10000 [00:23<00:16, 248.92it/s]Running 10000 simulations.:  60%|█████▉    | 5952/10000 [00:23<00:16, 249.12it/s]Running 10000 simulations.:  60%|█████▉    | 5977/10000 [00:23<00:16, 248.62it/s]Running 10000 simulations.:  60%|██████    | 6003/10000 [00:23<00:16, 249.20it/s]Running 10000 simulations.:  60%|██████    | 6028/10000 [00:23<00:15, 249.28it/s]Running 10000 simulations.:  61%|██████    | 6053/10000 [00:24<00:15, 249.03it/s]Running 10000 simulations.:  61%|██████    | 6079/10000 [00:24<00:15, 249.75it/s]Running 10000 simulations.:  61%|██████    | 6104/10000 [00:24<00:15, 249.69it/s]Running 10000 simulations.:  61%|██████▏   | 6129/10000 [00:24<00:15, 249.10it/s]Running 10000 simulations.:  62%|██████▏   | 6154/10000 [00:24<00:15, 248.50it/s]Running 10000 simulations.:  62%|██████▏   | 6179/10000 [00:24<00:15, 248.93it/s]Running 10000 simulations.:  62%|██████▏   | 6204/10000 [00:24<00:15, 246.97it/s]Running 10000 simulations.:  62%|██████▏   | 6229/10000 [00:24<00:15, 247.28it/s]Running 10000 simulations.:  63%|██████▎   | 6254/10000 [00:24<00:15, 247.85it/s]Running 10000 simulations.:  63%|██████▎   | 6279/10000 [00:25<00:14, 248.40it/s]Running 10000 simulations.:  63%|██████▎   | 6305/10000 [00:25<00:14, 249.03it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:25<00:14, 248.97it/s]Running 10000 simulations.:  64%|██████▎   | 6355/10000 [00:25<00:14, 248.43it/s]Running 10000 simulations.:  64%|██████▍   | 6380/10000 [00:25<00:14, 248.30it/s]Running 10000 simulations.:  64%|██████▍   | 6405/10000 [00:25<00:14, 247.69it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:25<00:14, 248.01it/s]Running 10000 simulations.:  65%|██████▍   | 6455/10000 [00:25<00:14, 247.84it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:25<00:14, 246.97it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:25<00:14, 247.16it/s]Running 10000 simulations.:  65%|██████▌   | 6531/10000 [00:26<00:13, 247.99it/s]Running 10000 simulations.:  66%|██████▌   | 6557/10000 [00:26<00:13, 249.19it/s]Running 10000 simulations.:  66%|██████▌   | 6583/10000 [00:26<00:13, 249.74it/s]Running 10000 simulations.:  66%|██████▌   | 6608/10000 [00:26<00:13, 249.30it/s]Running 10000 simulations.:  66%|██████▋   | 6633/10000 [00:26<00:13, 249.41it/s]Running 10000 simulations.:  67%|██████▋   | 6658/10000 [00:26<00:13, 246.14it/s]Running 10000 simulations.:  67%|██████▋   | 6683/10000 [00:26<00:13, 246.99it/s]Running 10000 simulations.:  67%|██████▋   | 6708/10000 [00:26<00:13, 247.27it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:26<00:13, 247.33it/s]Running 10000 simulations.:  68%|██████▊   | 6759/10000 [00:26<00:13, 248.20it/s]Running 10000 simulations.:  68%|██████▊   | 6785/10000 [00:27<00:12, 248.99it/s]Running 10000 simulations.:  68%|██████▊   | 6811/10000 [00:27<00:12, 249.38it/s]Running 10000 simulations.:  68%|██████▊   | 6837/10000 [00:27<00:12, 249.90it/s]Running 10000 simulations.:  69%|██████▊   | 6862/10000 [00:27<00:12, 249.90it/s]Running 10000 simulations.:  69%|██████▉   | 6887/10000 [00:27<00:12, 249.77it/s]Running 10000 simulations.:  69%|██████▉   | 6912/10000 [00:27<00:12, 249.79it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:27<00:12, 249.73it/s]Running 10000 simulations.:  70%|██████▉   | 6963/10000 [00:27<00:12, 250.08it/s]Running 10000 simulations.:  70%|██████▉   | 6989/10000 [00:27<00:12, 250.08it/s]Running 10000 simulations.:  70%|███████   | 7015/10000 [00:27<00:11, 250.80it/s]Running 10000 simulations.:  70%|███████   | 7041/10000 [00:28<00:11, 250.26it/s]Running 10000 simulations.:  71%|███████   | 7067/10000 [00:28<00:11, 250.81it/s]Running 10000 simulations.:  71%|███████   | 7093/10000 [00:28<00:11, 250.54it/s]Running 10000 simulations.:  71%|███████   | 7119/10000 [00:28<00:11, 250.58it/s]Running 10000 simulations.:  71%|███████▏  | 7145/10000 [00:28<00:11, 250.89it/s]Running 10000 simulations.:  72%|███████▏  | 7171/10000 [00:28<00:11, 243.11it/s]Running 10000 simulations.:  72%|███████▏  | 7196/10000 [00:28<00:11, 244.93it/s]Running 10000 simulations.:  72%|███████▏  | 7221/10000 [00:28<00:11, 243.10it/s]Running 10000 simulations.:  72%|███████▏  | 7247/10000 [00:28<00:11, 245.89it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:29<00:11, 247.19it/s]Running 10000 simulations.:  73%|███████▎  | 7299/10000 [00:29<00:10, 248.65it/s]Running 10000 simulations.:  73%|███████▎  | 7325/10000 [00:29<00:10, 249.83it/s]Running 10000 simulations.:  74%|███████▎  | 7351/10000 [00:29<00:10, 250.18it/s]Running 10000 simulations.:  74%|███████▍  | 7377/10000 [00:29<00:10, 250.56it/s]Running 10000 simulations.:  74%|███████▍  | 7403/10000 [00:29<00:10, 250.31it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:29<00:10, 250.85it/s]Running 10000 simulations.:  75%|███████▍  | 7455/10000 [00:29<00:10, 251.16it/s]Running 10000 simulations.:  75%|███████▍  | 7481/10000 [00:29<00:10, 250.63it/s]Running 10000 simulations.:  75%|███████▌  | 7507/10000 [00:29<00:09, 250.78it/s]Running 10000 simulations.:  75%|███████▌  | 7533/10000 [00:30<00:09, 250.64it/s]Running 10000 simulations.:  76%|███████▌  | 7559/10000 [00:30<00:09, 249.76it/s]Running 10000 simulations.:  76%|███████▌  | 7585/10000 [00:30<00:09, 249.88it/s]Running 10000 simulations.:  76%|███████▌  | 7611/10000 [00:30<00:09, 250.09it/s]Running 10000 simulations.:  76%|███████▋  | 7637/10000 [00:30<00:09, 250.29it/s]Running 10000 simulations.:  77%|███████▋  | 7663/10000 [00:30<00:09, 249.63it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:30<00:09, 250.26it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:30<00:09, 250.81it/s]Running 10000 simulations.:  77%|███████▋  | 7741/10000 [00:30<00:09, 249.98it/s]Running 10000 simulations.:  78%|███████▊  | 7766/10000 [00:30<00:08, 249.74it/s]Running 10000 simulations.:  78%|███████▊  | 7792/10000 [00:31<00:08, 249.89it/s]Running 10000 simulations.:  78%|███████▊  | 7818/10000 [00:31<00:08, 250.34it/s]Running 10000 simulations.:  78%|███████▊  | 7844/10000 [00:31<00:08, 250.82it/s]Running 10000 simulations.:  79%|███████▊  | 7870/10000 [00:31<00:08, 250.92it/s]Running 10000 simulations.:  79%|███████▉  | 7896/10000 [00:31<00:08, 250.91it/s]Running 10000 simulations.:  79%|███████▉  | 7922/10000 [00:31<00:08, 250.35it/s]Running 10000 simulations.:  79%|███████▉  | 7948/10000 [00:31<00:08, 250.63it/s]Running 10000 simulations.:  80%|███████▉  | 7974/10000 [00:31<00:08, 250.34it/s]Running 10000 simulations.:  80%|████████  | 8000/10000 [00:31<00:07, 251.10it/s]Running 10000 simulations.:  80%|████████  | 8026/10000 [00:32<00:07, 251.19it/s]Running 10000 simulations.:  81%|████████  | 8052/10000 [00:32<00:07, 250.52it/s]Running 10000 simulations.:  81%|████████  | 8078/10000 [00:32<00:07, 250.68it/s]Running 10000 simulations.:  81%|████████  | 8104/10000 [00:32<00:07, 251.04it/s]Running 10000 simulations.:  81%|████████▏ | 8130/10000 [00:32<00:07, 251.53it/s]Running 10000 simulations.:  82%|████████▏ | 8156/10000 [00:32<00:07, 251.57it/s]Running 10000 simulations.:  82%|████████▏ | 8182/10000 [00:32<00:07, 252.24it/s]Running 10000 simulations.:  82%|████████▏ | 8208/10000 [00:32<00:07, 252.28it/s]Running 10000 simulations.:  82%|████████▏ | 8234/10000 [00:32<00:07, 251.56it/s]Running 10000 simulations.:  83%|████████▎ | 8260/10000 [00:32<00:06, 250.97it/s]Running 10000 simulations.:  83%|████████▎ | 8286/10000 [00:33<00:06, 250.74it/s]Running 10000 simulations.:  83%|████████▎ | 8312/10000 [00:33<00:06, 250.61it/s]Running 10000 simulations.:  83%|████████▎ | 8338/10000 [00:33<00:06, 250.97it/s]Running 10000 simulations.:  84%|████████▎ | 8364/10000 [00:33<00:06, 250.89it/s]Running 10000 simulations.:  84%|████████▍ | 8390/10000 [00:33<00:06, 250.33it/s]Running 10000 simulations.:  84%|████████▍ | 8416/10000 [00:33<00:06, 250.00it/s]Running 10000 simulations.:  84%|████████▍ | 8442/10000 [00:33<00:06, 250.20it/s]Running 10000 simulations.:  85%|████████▍ | 8468/10000 [00:33<00:06, 250.74it/s]Running 10000 simulations.:  85%|████████▍ | 8494/10000 [00:33<00:06, 250.57it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:33<00:05, 250.45it/s]Running 10000 simulations.:  85%|████████▌ | 8546/10000 [00:34<00:05, 250.47it/s]Running 10000 simulations.:  86%|████████▌ | 8572/10000 [00:34<00:05, 251.17it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [00:34<00:05, 251.87it/s]Running 10000 simulations.:  86%|████████▌ | 8624/10000 [00:34<00:05, 252.45it/s]Running 10000 simulations.:  86%|████████▋ | 8650/10000 [00:34<00:05, 252.88it/s]Running 10000 simulations.:  87%|████████▋ | 8676/10000 [00:34<00:05, 252.49it/s]Running 10000 simulations.:  87%|████████▋ | 8702/10000 [00:34<00:05, 251.44it/s]Running 10000 simulations.:  87%|████████▋ | 8728/10000 [00:34<00:05, 247.67it/s]Running 10000 simulations.:  88%|████████▊ | 8753/10000 [00:34<00:05, 248.15it/s]Running 10000 simulations.:  88%|████████▊ | 8779/10000 [00:35<00:04, 248.85it/s]Running 10000 simulations.:  88%|████████▊ | 8804/10000 [00:35<00:04, 248.45it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [00:35<00:04, 249.07it/s]Running 10000 simulations.:  89%|████████▊ | 8856/10000 [00:35<00:04, 250.01it/s]Running 10000 simulations.:  89%|████████▉ | 8882/10000 [00:35<00:04, 251.63it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:35<00:04, 251.82it/s]Running 10000 simulations.:  89%|████████▉ | 8934/10000 [00:35<00:04, 251.88it/s]Running 10000 simulations.:  90%|████████▉ | 8960/10000 [00:35<00:04, 252.19it/s]Running 10000 simulations.:  90%|████████▉ | 8986/10000 [00:35<00:04, 252.04it/s]Running 10000 simulations.:  90%|█████████ | 9012/10000 [00:35<00:03, 253.45it/s]Running 10000 simulations.:  90%|█████████ | 9038/10000 [00:36<00:03, 253.33it/s]Running 10000 simulations.:  91%|█████████ | 9064/10000 [00:36<00:03, 253.37it/s]Running 10000 simulations.:  91%|█████████ | 9090/10000 [00:36<00:03, 253.64it/s]Running 10000 simulations.:  91%|█████████ | 9116/10000 [00:36<00:03, 254.08it/s]Running 10000 simulations.:  91%|█████████▏| 9142/10000 [00:36<00:03, 254.18it/s]Running 10000 simulations.:  92%|█████████▏| 9168/10000 [00:36<00:03, 253.81it/s]Running 10000 simulations.:  92%|█████████▏| 9194/10000 [00:36<00:03, 252.37it/s]Running 10000 simulations.:  92%|█████████▏| 9220/10000 [00:36<00:03, 252.17it/s]Running 10000 simulations.:  92%|█████████▏| 9246/10000 [00:36<00:02, 251.45it/s]Running 10000 simulations.:  93%|█████████▎| 9272/10000 [00:36<00:02, 251.61it/s]Running 10000 simulations.:  93%|█████████▎| 9298/10000 [00:37<00:02, 251.84it/s]Running 10000 simulations.:  93%|█████████▎| 9324/10000 [00:37<00:02, 252.53it/s]Running 10000 simulations.:  94%|█████████▎| 9350/10000 [00:37<00:02, 252.85it/s]Running 10000 simulations.:  94%|█████████▍| 9376/10000 [00:37<00:02, 253.18it/s]Running 10000 simulations.:  94%|█████████▍| 9402/10000 [00:37<00:02, 253.22it/s]Running 10000 simulations.:  94%|█████████▍| 9428/10000 [00:37<00:02, 253.58it/s]Running 10000 simulations.:  95%|█████████▍| 9454/10000 [00:37<00:02, 252.32it/s]Running 10000 simulations.:  95%|█████████▍| 9480/10000 [00:37<00:02, 252.83it/s]Running 10000 simulations.:  95%|█████████▌| 9506/10000 [00:37<00:01, 253.12it/s]Running 10000 simulations.:  95%|█████████▌| 9532/10000 [00:37<00:01, 253.40it/s]Running 10000 simulations.:  96%|█████████▌| 9558/10000 [00:38<00:01, 253.48it/s]Running 10000 simulations.:  96%|█████████▌| 9584/10000 [00:38<00:01, 253.76it/s]Running 10000 simulations.:  96%|█████████▌| 9610/10000 [00:38<00:01, 253.69it/s]Running 10000 simulations.:  96%|█████████▋| 9636/10000 [00:38<00:01, 254.15it/s]Running 10000 simulations.:  97%|█████████▋| 9662/10000 [00:38<00:01, 253.99it/s]Running 10000 simulations.:  97%|█████████▋| 9688/10000 [00:38<00:01, 254.56it/s]Running 10000 simulations.:  97%|█████████▋| 9714/10000 [00:38<00:01, 254.53it/s]Running 10000 simulations.:  97%|█████████▋| 9740/10000 [00:38<00:01, 254.74it/s]Running 10000 simulations.:  98%|█████████▊| 9766/10000 [00:38<00:00, 255.87it/s]Running 10000 simulations.:  98%|█████████▊| 9792/10000 [00:39<00:00, 256.97it/s]Running 10000 simulations.:  98%|█████████▊| 9818/10000 [00:39<00:00, 257.78it/s]Running 10000 simulations.:  98%|█████████▊| 9844/10000 [00:39<00:00, 256.98it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [00:39<00:00, 254.56it/s]Running 10000 simulations.:  99%|█████████▉| 9896/10000 [00:39<00:00, 255.30it/s]Running 10000 simulations.:  99%|█████████▉| 9922/10000 [00:39<00:00, 255.85it/s]Running 10000 simulations.:  99%|█████████▉| 9948/10000 [00:39<00:00, 255.27it/s]Running 10000 simulations.: 100%|█████████▉| 9974/10000 [00:39<00:00, 252.71it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:39<00:00, 253.51it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:39<00:00, 251.07it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 271.82it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<00:36, 272.81it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<00:36, 272.81it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<00:36, 273.24it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:36, 273.06it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:35, 273.37it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:00<00:35, 273.56it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:00<00:35, 273.74it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:00<00:35, 272.81it/s]Running 10000 simulations.:   3%|▎         | 280/10000 [00:01<00:35, 272.95it/s]Running 10000 simulations.:   3%|▎         | 308/10000 [00:01<00:35, 273.70it/s]Running 10000 simulations.:   3%|▎         | 336/10000 [00:01<00:35, 273.57it/s]Running 10000 simulations.:   4%|▎         | 364/10000 [00:01<00:35, 273.03it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:01<00:35, 271.54it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:35, 271.22it/s]Running 10000 simulations.:   4%|▍         | 447/10000 [00:01<00:35, 270.82it/s]Running 10000 simulations.:   5%|▍         | 475/10000 [00:01<00:35, 271.11it/s]Running 10000 simulations.:   5%|▌         | 503/10000 [00:01<00:35, 270.63it/s]Running 10000 simulations.:   5%|▌         | 531/10000 [00:01<00:34, 270.78it/s]Running 10000 simulations.:   6%|▌         | 559/10000 [00:02<00:34, 270.43it/s]Running 10000 simulations.:   6%|▌         | 587/10000 [00:02<00:34, 270.64it/s]Running 10000 simulations.:   6%|▌         | 615/10000 [00:02<00:34, 269.88it/s]Running 10000 simulations.:   6%|▋         | 642/10000 [00:02<00:34, 268.57it/s]Running 10000 simulations.:   7%|▋         | 669/10000 [00:02<00:34, 268.67it/s]Running 10000 simulations.:   7%|▋         | 696/10000 [00:02<00:34, 268.76it/s]Running 10000 simulations.:   7%|▋         | 723/10000 [00:02<00:34, 268.87it/s]Running 10000 simulations.:   8%|▊         | 751/10000 [00:02<00:34, 269.81it/s]Running 10000 simulations.:   8%|▊         | 778/10000 [00:02<00:34, 269.73it/s]Running 10000 simulations.:   8%|▊         | 806/10000 [00:02<00:34, 270.17it/s]Running 10000 simulations.:   8%|▊         | 834/10000 [00:03<00:33, 269.75it/s]Running 10000 simulations.:   9%|▊         | 862/10000 [00:03<00:33, 269.90it/s]Running 10000 simulations.:   9%|▉         | 889/10000 [00:03<00:33, 269.32it/s]Running 10000 simulations.:   9%|▉         | 916/10000 [00:03<00:34, 263.86it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:03<00:34, 266.21it/s]Running 10000 simulations.:  10%|▉         | 971/10000 [00:03<00:33, 267.32it/s]Running 10000 simulations.:  10%|▉         | 999/10000 [00:03<00:33, 268.21it/s]Running 10000 simulations.:  10%|█         | 1027/10000 [00:03<00:33, 268.77it/s]Running 10000 simulations.:  11%|█         | 1054/10000 [00:03<00:33, 268.80it/s]Running 10000 simulations.:  11%|█         | 1081/10000 [00:03<00:33, 268.47it/s]Running 10000 simulations.:  11%|█         | 1108/10000 [00:04<00:33, 268.05it/s]Running 10000 simulations.:  11%|█▏        | 1135/10000 [00:04<00:33, 267.73it/s]Running 10000 simulations.:  12%|█▏        | 1162/10000 [00:04<00:32, 268.28it/s]Running 10000 simulations.:  12%|█▏        | 1189/10000 [00:04<00:33, 266.49it/s]Running 10000 simulations.:  12%|█▏        | 1216/10000 [00:04<00:33, 264.44it/s]Running 10000 simulations.:  12%|█▏        | 1243/10000 [00:04<00:32, 265.79it/s]Running 10000 simulations.:  13%|█▎        | 1270/10000 [00:04<00:32, 266.37it/s]Running 10000 simulations.:  13%|█▎        | 1297/10000 [00:04<00:32, 266.26it/s]Running 10000 simulations.:  13%|█▎        | 1324/10000 [00:04<00:32, 266.33it/s]Running 10000 simulations.:  14%|█▎        | 1352/10000 [00:05<00:32, 267.91it/s]Running 10000 simulations.:  14%|█▍        | 1379/10000 [00:05<00:32, 268.49it/s]Running 10000 simulations.:  14%|█▍        | 1407/10000 [00:05<00:31, 269.14it/s]Running 10000 simulations.:  14%|█▍        | 1434/10000 [00:05<00:31, 268.91it/s]Running 10000 simulations.:  15%|█▍        | 1461/10000 [00:05<00:31, 268.15it/s]Running 10000 simulations.:  15%|█▍        | 1488/10000 [00:05<00:31, 267.29it/s]Running 10000 simulations.:  15%|█▌        | 1515/10000 [00:05<00:31, 267.33it/s]Running 10000 simulations.:  15%|█▌        | 1542/10000 [00:05<00:31, 267.66it/s]Running 10000 simulations.:  16%|█▌        | 1570/10000 [00:05<00:31, 268.41it/s]Running 10000 simulations.:  16%|█▌        | 1597/10000 [00:05<00:31, 268.31it/s]Running 10000 simulations.:  16%|█▌        | 1624/10000 [00:06<00:31, 267.29it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:06<00:31, 267.20it/s]Running 10000 simulations.:  17%|█▋        | 1678/10000 [00:06<00:31, 267.13it/s]Running 10000 simulations.:  17%|█▋        | 1705/10000 [00:06<00:31, 266.38it/s]Running 10000 simulations.:  17%|█▋        | 1732/10000 [00:06<00:31, 266.21it/s]Running 10000 simulations.:  18%|█▊        | 1759/10000 [00:06<00:30, 266.02it/s]Running 10000 simulations.:  18%|█▊        | 1786/10000 [00:06<00:30, 266.65it/s]Running 10000 simulations.:  18%|█▊        | 1813/10000 [00:06<00:30, 266.87it/s]Running 10000 simulations.:  18%|█▊        | 1840/10000 [00:06<00:30, 266.77it/s]Running 10000 simulations.:  19%|█▊        | 1867/10000 [00:06<00:30, 266.95it/s]Running 10000 simulations.:  19%|█▉        | 1894/10000 [00:07<00:30, 267.19it/s]Running 10000 simulations.:  19%|█▉        | 1921/10000 [00:07<00:30, 267.34it/s]Running 10000 simulations.:  19%|█▉        | 1948/10000 [00:07<00:30, 266.28it/s]Running 10000 simulations.:  20%|█▉        | 1975/10000 [00:07<00:30, 266.35it/s]Running 10000 simulations.:  20%|██        | 2002/10000 [00:07<00:29, 267.11it/s]Running 10000 simulations.:  20%|██        | 2029/10000 [00:07<00:29, 267.49it/s]Running 10000 simulations.:  21%|██        | 2056/10000 [00:07<00:29, 266.71it/s]Running 10000 simulations.:  21%|██        | 2083/10000 [00:07<00:29, 266.44it/s]Running 10000 simulations.:  21%|██        | 2110/10000 [00:07<00:29, 266.04it/s]Running 10000 simulations.:  21%|██▏       | 2137/10000 [00:07<00:29, 265.63it/s]Running 10000 simulations.:  22%|██▏       | 2164/10000 [00:08<00:29, 265.07it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:08<00:29, 264.79it/s]Running 10000 simulations.:  22%|██▏       | 2218/10000 [00:08<00:29, 265.41it/s]Running 10000 simulations.:  22%|██▏       | 2245/10000 [00:08<00:29, 266.61it/s]Running 10000 simulations.:  23%|██▎       | 2272/10000 [00:08<00:28, 266.84it/s]Running 10000 simulations.:  23%|██▎       | 2299/10000 [00:08<00:28, 266.20it/s]Running 10000 simulations.:  23%|██▎       | 2326/10000 [00:08<00:28, 265.57it/s]Running 10000 simulations.:  24%|██▎       | 2353/10000 [00:08<00:28, 264.92it/s]Running 10000 simulations.:  24%|██▍       | 2380/10000 [00:08<00:28, 263.59it/s]Running 10000 simulations.:  24%|██▍       | 2407/10000 [00:08<00:28, 263.30it/s]Running 10000 simulations.:  24%|██▍       | 2434/10000 [00:09<00:28, 264.67it/s]Running 10000 simulations.:  25%|██▍       | 2461/10000 [00:09<00:28, 264.06it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:09<00:28, 264.49it/s]Running 10000 simulations.:  25%|██▌       | 2515/10000 [00:09<00:28, 264.03it/s]Running 10000 simulations.:  25%|██▌       | 2542/10000 [00:09<00:28, 263.65it/s]Running 10000 simulations.:  26%|██▌       | 2569/10000 [00:09<00:28, 263.92it/s]Running 10000 simulations.:  26%|██▌       | 2596/10000 [00:09<00:27, 264.87it/s]Running 10000 simulations.:  26%|██▌       | 2623/10000 [00:09<00:27, 264.89it/s]Running 10000 simulations.:  26%|██▋       | 2650/10000 [00:09<00:27, 264.58it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:09<00:27, 264.38it/s]Running 10000 simulations.:  27%|██▋       | 2704/10000 [00:10<00:27, 264.44it/s]Running 10000 simulations.:  27%|██▋       | 2731/10000 [00:10<00:27, 263.39it/s]Running 10000 simulations.:  28%|██▊       | 2758/10000 [00:10<00:27, 263.91it/s]Running 10000 simulations.:  28%|██▊       | 2785/10000 [00:10<00:27, 264.23it/s]Running 10000 simulations.:  28%|██▊       | 2812/10000 [00:10<00:27, 264.13it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:10<00:27, 263.96it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:10<00:27, 263.66it/s]Running 10000 simulations.:  29%|██▉       | 2893/10000 [00:10<00:26, 263.34it/s]Running 10000 simulations.:  29%|██▉       | 2920/10000 [00:10<00:26, 263.41it/s]Running 10000 simulations.:  29%|██▉       | 2947/10000 [00:11<00:26, 263.47it/s]Running 10000 simulations.:  30%|██▉       | 2974/10000 [00:11<00:26, 263.48it/s]Running 10000 simulations.:  30%|███       | 3001/10000 [00:11<00:26, 264.27it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:11<00:26, 264.02it/s]Running 10000 simulations.:  31%|███       | 3055/10000 [00:11<00:26, 263.74it/s]Running 10000 simulations.:  31%|███       | 3082/10000 [00:11<00:26, 264.11it/s]Running 10000 simulations.:  31%|███       | 3109/10000 [00:11<00:26, 264.90it/s]Running 10000 simulations.:  31%|███▏      | 3136/10000 [00:11<00:25, 264.56it/s]Running 10000 simulations.:  32%|███▏      | 3163/10000 [00:11<00:25, 264.69it/s]Running 10000 simulations.:  32%|███▏      | 3190/10000 [00:11<00:25, 263.82it/s]Running 10000 simulations.:  32%|███▏      | 3217/10000 [00:12<00:25, 264.55it/s]Running 10000 simulations.:  32%|███▏      | 3244/10000 [00:12<00:25, 264.78it/s]Running 10000 simulations.:  33%|███▎      | 3271/10000 [00:12<00:25, 265.24it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:12<00:25, 264.09it/s]Running 10000 simulations.:  33%|███▎      | 3325/10000 [00:12<00:25, 264.49it/s]Running 10000 simulations.:  34%|███▎      | 3352/10000 [00:12<00:25, 265.07it/s]Running 10000 simulations.:  34%|███▍      | 3379/10000 [00:12<00:24, 265.11it/s]Running 10000 simulations.:  34%|███▍      | 3406/10000 [00:12<00:24, 264.66it/s]Running 10000 simulations.:  34%|███▍      | 3433/10000 [00:12<00:24, 265.03it/s]Running 10000 simulations.:  35%|███▍      | 3460/10000 [00:12<00:24, 262.01it/s]Running 10000 simulations.:  35%|███▍      | 3487/10000 [00:13<00:24, 261.43it/s]Running 10000 simulations.:  35%|███▌      | 3514/10000 [00:13<00:24, 262.69it/s]Running 10000 simulations.:  35%|███▌      | 3541/10000 [00:13<00:24, 262.95it/s]Running 10000 simulations.:  36%|███▌      | 3568/10000 [00:13<00:24, 263.78it/s]Running 10000 simulations.:  36%|███▌      | 3595/10000 [00:13<00:24, 263.70it/s]Running 10000 simulations.:  36%|███▌      | 3622/10000 [00:13<00:24, 263.47it/s]Running 10000 simulations.:  36%|███▋      | 3649/10000 [00:13<00:24, 258.77it/s]Running 10000 simulations.:  37%|███▋      | 3676/10000 [00:13<00:24, 260.80it/s]Running 10000 simulations.:  37%|███▋      | 3703/10000 [00:13<00:24, 262.31it/s]Running 10000 simulations.:  37%|███▋      | 3730/10000 [00:13<00:23, 263.07it/s]Running 10000 simulations.:  38%|███▊      | 3757/10000 [00:14<00:23, 263.64it/s]Running 10000 simulations.:  38%|███▊      | 3784/10000 [00:14<00:23, 263.11it/s]Running 10000 simulations.:  38%|███▊      | 3811/10000 [00:14<00:23, 263.74it/s]Running 10000 simulations.:  38%|███▊      | 3838/10000 [00:14<00:23, 263.20it/s]Running 10000 simulations.:  39%|███▊      | 3865/10000 [00:14<00:23, 264.07it/s]Running 10000 simulations.:  39%|███▉      | 3892/10000 [00:14<00:23, 264.54it/s]Running 10000 simulations.:  39%|███▉      | 3919/10000 [00:14<00:23, 264.06it/s]Running 10000 simulations.:  39%|███▉      | 3946/10000 [00:14<00:22, 264.43it/s]Running 10000 simulations.:  40%|███▉      | 3973/10000 [00:14<00:22, 264.03it/s]Running 10000 simulations.:  40%|████      | 4000/10000 [00:15<00:22, 265.26it/s]Running 10000 simulations.:  40%|████      | 4027/10000 [00:15<00:22, 265.88it/s]Running 10000 simulations.:  41%|████      | 4054/10000 [00:15<00:22, 266.38it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:15<00:22, 266.12it/s]Running 10000 simulations.:  41%|████      | 4108/10000 [00:15<00:22, 266.62it/s]Running 10000 simulations.:  41%|████▏     | 4135/10000 [00:15<00:22, 265.69it/s]Running 10000 simulations.:  42%|████▏     | 4162/10000 [00:15<00:22, 265.20it/s]Running 10000 simulations.:  42%|████▏     | 4189/10000 [00:15<00:21, 265.43it/s]Running 10000 simulations.:  42%|████▏     | 4216/10000 [00:15<00:21, 265.00it/s]Running 10000 simulations.:  42%|████▏     | 4243/10000 [00:15<00:21, 264.91it/s]Running 10000 simulations.:  43%|████▎     | 4270/10000 [00:16<00:21, 265.53it/s]Running 10000 simulations.:  43%|████▎     | 4297/10000 [00:16<00:21, 266.67it/s]Running 10000 simulations.:  43%|████▎     | 4324/10000 [00:16<00:21, 266.81it/s]Running 10000 simulations.:  44%|████▎     | 4351/10000 [00:16<00:21, 266.87it/s]Running 10000 simulations.:  44%|████▍     | 4378/10000 [00:16<00:21, 265.49it/s]Running 10000 simulations.:  44%|████▍     | 4405/10000 [00:16<00:21, 264.93it/s]Running 10000 simulations.:  44%|████▍     | 4432/10000 [00:16<00:21, 263.59it/s]Running 10000 simulations.:  45%|████▍     | 4459/10000 [00:16<00:20, 264.07it/s]Running 10000 simulations.:  45%|████▍     | 4486/10000 [00:16<00:20, 263.10it/s]Running 10000 simulations.:  45%|████▌     | 4513/10000 [00:16<00:20, 263.64it/s]Running 10000 simulations.:  45%|████▌     | 4540/10000 [00:17<00:20, 264.75it/s]Running 10000 simulations.:  46%|████▌     | 4567/10000 [00:17<00:20, 265.74it/s]Running 10000 simulations.:  46%|████▌     | 4594/10000 [00:17<00:20, 266.57it/s]Running 10000 simulations.:  46%|████▌     | 4621/10000 [00:17<00:20, 266.48it/s]Running 10000 simulations.:  46%|████▋     | 4648/10000 [00:17<00:20, 267.05it/s]Running 10000 simulations.:  47%|████▋     | 4675/10000 [00:17<00:19, 267.30it/s]Running 10000 simulations.:  47%|████▋     | 4702/10000 [00:17<00:19, 266.68it/s]Running 10000 simulations.:  47%|████▋     | 4729/10000 [00:17<00:19, 266.94it/s]Running 10000 simulations.:  48%|████▊     | 4756/10000 [00:17<00:19, 266.92it/s]Running 10000 simulations.:  48%|████▊     | 4783/10000 [00:17<00:19, 266.68it/s]Running 10000 simulations.:  48%|████▊     | 4810/10000 [00:18<00:19, 267.44it/s]Running 10000 simulations.:  48%|████▊     | 4837/10000 [00:18<00:19, 268.03it/s]Running 10000 simulations.:  49%|████▊     | 4864/10000 [00:18<00:19, 267.49it/s]Running 10000 simulations.:  49%|████▉     | 4891/10000 [00:18<00:19, 267.76it/s]Running 10000 simulations.:  49%|████▉     | 4918/10000 [00:18<00:19, 267.40it/s]Running 10000 simulations.:  49%|████▉     | 4945/10000 [00:18<00:18, 267.61it/s]Running 10000 simulations.:  50%|████▉     | 4972/10000 [00:18<00:18, 267.14it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:18<00:18, 267.81it/s]Running 10000 simulations.:  50%|█████     | 5026/10000 [00:18<00:18, 266.61it/s]Running 10000 simulations.:  51%|█████     | 5053/10000 [00:18<00:18, 265.99it/s]Running 10000 simulations.:  51%|█████     | 5080/10000 [00:19<00:18, 265.91it/s]Running 10000 simulations.:  51%|█████     | 5107/10000 [00:19<00:18, 265.58it/s]Running 10000 simulations.:  51%|█████▏    | 5134/10000 [00:19<00:18, 266.37it/s]Running 10000 simulations.:  52%|█████▏    | 5161/10000 [00:19<00:18, 265.42it/s]Running 10000 simulations.:  52%|█████▏    | 5188/10000 [00:19<00:18, 265.14it/s]Running 10000 simulations.:  52%|█████▏    | 5215/10000 [00:19<00:18, 265.21it/s]Running 10000 simulations.:  52%|█████▏    | 5242/10000 [00:19<00:17, 265.25it/s]Running 10000 simulations.:  53%|█████▎    | 5269/10000 [00:19<00:17, 264.86it/s]Running 10000 simulations.:  53%|█████▎    | 5296/10000 [00:19<00:17, 264.92it/s]Running 10000 simulations.:  53%|█████▎    | 5323/10000 [00:19<00:17, 264.67it/s]Running 10000 simulations.:  54%|█████▎    | 5350/10000 [00:20<00:17, 264.99it/s]Running 10000 simulations.:  54%|█████▍    | 5377/10000 [00:20<00:17, 264.88it/s]Running 10000 simulations.:  54%|█████▍    | 5404/10000 [00:20<00:17, 264.86it/s]Running 10000 simulations.:  54%|█████▍    | 5431/10000 [00:20<00:17, 265.21it/s]Running 10000 simulations.:  55%|█████▍    | 5458/10000 [00:20<00:17, 265.15it/s]Running 10000 simulations.:  55%|█████▍    | 5485/10000 [00:20<00:17, 265.42it/s]Running 10000 simulations.:  55%|█████▌    | 5512/10000 [00:20<00:16, 265.04it/s]Running 10000 simulations.:  55%|█████▌    | 5539/10000 [00:20<00:16, 265.15it/s]Running 10000 simulations.:  56%|█████▌    | 5566/10000 [00:20<00:16, 264.16it/s]Running 10000 simulations.:  56%|█████▌    | 5593/10000 [00:21<00:16, 263.44it/s]Running 10000 simulations.:  56%|█████▌    | 5620/10000 [00:21<00:16, 264.12it/s]Running 10000 simulations.:  56%|█████▋    | 5647/10000 [00:21<00:16, 264.35it/s]Running 10000 simulations.:  57%|█████▋    | 5674/10000 [00:21<00:16, 264.24it/s]Running 10000 simulations.:  57%|█████▋    | 5701/10000 [00:21<00:16, 263.31it/s]Running 10000 simulations.:  57%|█████▋    | 5728/10000 [00:21<00:16, 263.91it/s]Running 10000 simulations.:  58%|█████▊    | 5755/10000 [00:21<00:16, 264.69it/s]Running 10000 simulations.:  58%|█████▊    | 5782/10000 [00:21<00:15, 265.26it/s]Running 10000 simulations.:  58%|█████▊    | 5809/10000 [00:21<00:15, 264.49it/s]Running 10000 simulations.:  58%|█████▊    | 5836/10000 [00:21<00:15, 264.84it/s]Running 10000 simulations.:  59%|█████▊    | 5863/10000 [00:22<00:15, 265.06it/s]Running 10000 simulations.:  59%|█████▉    | 5890/10000 [00:22<00:15, 265.37it/s]Running 10000 simulations.:  59%|█████▉    | 5917/10000 [00:22<00:15, 265.31it/s]Running 10000 simulations.:  59%|█████▉    | 5944/10000 [00:22<00:15, 265.03it/s]Running 10000 simulations.:  60%|█████▉    | 5971/10000 [00:22<00:15, 264.90it/s]Running 10000 simulations.:  60%|█████▉    | 5998/10000 [00:22<00:15, 265.33it/s]Running 10000 simulations.:  60%|██████    | 6025/10000 [00:22<00:14, 265.40it/s]Running 10000 simulations.:  61%|██████    | 6052/10000 [00:22<00:14, 265.20it/s]Running 10000 simulations.:  61%|██████    | 6079/10000 [00:22<00:14, 264.82it/s]Running 10000 simulations.:  61%|██████    | 6106/10000 [00:22<00:14, 261.48it/s]Running 10000 simulations.:  61%|██████▏   | 6133/10000 [00:23<00:14, 260.70it/s]Running 10000 simulations.:  62%|██████▏   | 6160/10000 [00:23<00:14, 261.53it/s]Running 10000 simulations.:  62%|██████▏   | 6187/10000 [00:23<00:14, 260.94it/s]Running 10000 simulations.:  62%|██████▏   | 6214/10000 [00:23<00:14, 258.17it/s]Running 10000 simulations.:  62%|██████▏   | 6241/10000 [00:23<00:14, 259.14it/s]Running 10000 simulations.:  63%|██████▎   | 6268/10000 [00:23<00:14, 259.92it/s]Running 10000 simulations.:  63%|██████▎   | 6295/10000 [00:23<00:14, 261.13it/s]Running 10000 simulations.:  63%|██████▎   | 6322/10000 [00:23<00:14, 261.78it/s]Running 10000 simulations.:  63%|██████▎   | 6349/10000 [00:23<00:13, 262.47it/s]Running 10000 simulations.:  64%|██████▍   | 6376/10000 [00:23<00:13, 261.71it/s]Running 10000 simulations.:  64%|██████▍   | 6403/10000 [00:24<00:13, 262.80it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:24<00:13, 263.66it/s]Running 10000 simulations.:  65%|██████▍   | 6457/10000 [00:24<00:13, 264.10it/s]Running 10000 simulations.:  65%|██████▍   | 6484/10000 [00:24<00:13, 264.02it/s]Running 10000 simulations.:  65%|██████▌   | 6511/10000 [00:24<00:13, 264.30it/s]Running 10000 simulations.:  65%|██████▌   | 6538/10000 [00:24<00:13, 265.22it/s]Running 10000 simulations.:  66%|██████▌   | 6565/10000 [00:24<00:12, 264.57it/s]Running 10000 simulations.:  66%|██████▌   | 6592/10000 [00:24<00:12, 264.19it/s]Running 10000 simulations.:  66%|██████▌   | 6619/10000 [00:24<00:12, 263.50it/s]Running 10000 simulations.:  66%|██████▋   | 6646/10000 [00:25<00:12, 262.80it/s]Running 10000 simulations.:  67%|██████▋   | 6673/10000 [00:25<00:12, 263.28it/s]Running 10000 simulations.:  67%|██████▋   | 6700/10000 [00:25<00:12, 262.97it/s]Running 10000 simulations.:  67%|██████▋   | 6727/10000 [00:25<00:12, 262.75it/s]Running 10000 simulations.:  68%|██████▊   | 6754/10000 [00:25<00:12, 262.55it/s]Running 10000 simulations.:  68%|██████▊   | 6781/10000 [00:25<00:12, 263.26it/s]Running 10000 simulations.:  68%|██████▊   | 6808/10000 [00:25<00:12, 263.77it/s]Running 10000 simulations.:  68%|██████▊   | 6835/10000 [00:25<00:11, 263.95it/s]Running 10000 simulations.:  69%|██████▊   | 6862/10000 [00:25<00:11, 262.77it/s]Running 10000 simulations.:  69%|██████▉   | 6889/10000 [00:25<00:11, 263.55it/s]Running 10000 simulations.:  69%|██████▉   | 6916/10000 [00:26<00:11, 263.51it/s]Running 10000 simulations.:  69%|██████▉   | 6943/10000 [00:26<00:11, 263.82it/s]Running 10000 simulations.:  70%|██████▉   | 6970/10000 [00:26<00:11, 263.89it/s]Running 10000 simulations.:  70%|██████▉   | 6997/10000 [00:26<00:11, 264.41it/s]Running 10000 simulations.:  70%|███████   | 7024/10000 [00:26<00:11, 265.12it/s]Running 10000 simulations.:  71%|███████   | 7051/10000 [00:26<00:11, 265.19it/s]Running 10000 simulations.:  71%|███████   | 7078/10000 [00:26<00:10, 266.18it/s]Running 10000 simulations.:  71%|███████   | 7105/10000 [00:26<00:10, 265.22it/s]Running 10000 simulations.:  71%|███████▏  | 7132/10000 [00:26<00:10, 265.49it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:26<00:10, 264.93it/s]Running 10000 simulations.:  72%|███████▏  | 7186/10000 [00:27<00:10, 264.62it/s]Running 10000 simulations.:  72%|███████▏  | 7213/10000 [00:27<00:10, 264.85it/s]Running 10000 simulations.:  72%|███████▏  | 7240/10000 [00:27<00:10, 265.29it/s]Running 10000 simulations.:  73%|███████▎  | 7267/10000 [00:27<00:10, 265.30it/s]Running 10000 simulations.:  73%|███████▎  | 7294/10000 [00:27<00:10, 265.00it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:27<00:10, 264.43it/s]Running 10000 simulations.:  73%|███████▎  | 7348/10000 [00:27<00:10, 263.90it/s]Running 10000 simulations.:  74%|███████▍  | 7375/10000 [00:27<00:09, 263.91it/s]Running 10000 simulations.:  74%|███████▍  | 7402/10000 [00:27<00:09, 264.54it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:27<00:09, 264.69it/s]Running 10000 simulations.:  75%|███████▍  | 7456/10000 [00:28<00:09, 265.22it/s]Running 10000 simulations.:  75%|███████▍  | 7483/10000 [00:28<00:09, 265.41it/s]Running 10000 simulations.:  75%|███████▌  | 7510/10000 [00:28<00:09, 265.32it/s]Running 10000 simulations.:  75%|███████▌  | 7537/10000 [00:28<00:09, 265.86it/s]Running 10000 simulations.:  76%|███████▌  | 7564/10000 [00:28<00:09, 266.18it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:28<00:09, 265.87it/s]Running 10000 simulations.:  76%|███████▌  | 7618/10000 [00:28<00:08, 265.76it/s]Running 10000 simulations.:  76%|███████▋  | 7645/10000 [00:28<00:08, 265.69it/s]Running 10000 simulations.:  77%|███████▋  | 7672/10000 [00:28<00:08, 266.33it/s]Running 10000 simulations.:  77%|███████▋  | 7699/10000 [00:28<00:08, 266.43it/s]Running 10000 simulations.:  77%|███████▋  | 7726/10000 [00:29<00:08, 267.06it/s]Running 10000 simulations.:  78%|███████▊  | 7753/10000 [00:29<00:08, 267.64it/s]Running 10000 simulations.:  78%|███████▊  | 7780/10000 [00:29<00:08, 267.72it/s]Running 10000 simulations.:  78%|███████▊  | 7807/10000 [00:29<00:08, 268.17it/s]Running 10000 simulations.:  78%|███████▊  | 7834/10000 [00:29<00:08, 267.85it/s]Running 10000 simulations.:  79%|███████▊  | 7861/10000 [00:29<00:08, 266.60it/s]Running 10000 simulations.:  79%|███████▉  | 7888/10000 [00:29<00:07, 266.95it/s]Running 10000 simulations.:  79%|███████▉  | 7915/10000 [00:29<00:07, 266.07it/s]Running 10000 simulations.:  79%|███████▉  | 7942/10000 [00:29<00:08, 256.63it/s]Running 10000 simulations.:  80%|███████▉  | 7969/10000 [00:30<00:07, 258.83it/s]Running 10000 simulations.:  80%|███████▉  | 7996/10000 [00:30<00:07, 260.12it/s]Running 10000 simulations.:  80%|████████  | 8023/10000 [00:30<00:07, 261.47it/s]Running 10000 simulations.:  80%|████████  | 8050/10000 [00:30<00:07, 261.99it/s]Running 10000 simulations.:  81%|████████  | 8077/10000 [00:30<00:07, 261.55it/s]Running 10000 simulations.:  81%|████████  | 8104/10000 [00:30<00:07, 262.00it/s]Running 10000 simulations.:  81%|████████▏ | 8131/10000 [00:30<00:07, 261.21it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:30<00:07, 261.00it/s]Running 10000 simulations.:  82%|████████▏ | 8185/10000 [00:30<00:06, 260.06it/s]Running 10000 simulations.:  82%|████████▏ | 8212/10000 [00:30<00:06, 261.14it/s]Running 10000 simulations.:  82%|████████▏ | 8239/10000 [00:31<00:06, 261.80it/s]Running 10000 simulations.:  83%|████████▎ | 8266/10000 [00:31<00:06, 261.93it/s]Running 10000 simulations.:  83%|████████▎ | 8293/10000 [00:31<00:06, 262.51it/s]Running 10000 simulations.:  83%|████████▎ | 8320/10000 [00:31<00:06, 262.81it/s]Running 10000 simulations.:  83%|████████▎ | 8347/10000 [00:31<00:06, 262.54it/s]Running 10000 simulations.:  84%|████████▎ | 8374/10000 [00:31<00:06, 263.11it/s]Running 10000 simulations.:  84%|████████▍ | 8401/10000 [00:31<00:06, 263.27it/s]Running 10000 simulations.:  84%|████████▍ | 8428/10000 [00:31<00:05, 262.73it/s]Running 10000 simulations.:  85%|████████▍ | 8455/10000 [00:31<00:05, 262.48it/s]Running 10000 simulations.:  85%|████████▍ | 8482/10000 [00:31<00:05, 262.43it/s]Running 10000 simulations.:  85%|████████▌ | 8509/10000 [00:32<00:05, 262.23it/s]Running 10000 simulations.:  85%|████████▌ | 8536/10000 [00:32<00:05, 262.18it/s]Running 10000 simulations.:  86%|████████▌ | 8563/10000 [00:32<00:05, 261.87it/s]Running 10000 simulations.:  86%|████████▌ | 8590/10000 [00:32<00:05, 262.14it/s]Running 10000 simulations.:  86%|████████▌ | 8617/10000 [00:32<00:05, 262.99it/s]Running 10000 simulations.:  86%|████████▋ | 8644/10000 [00:32<00:05, 263.04it/s]Running 10000 simulations.:  87%|████████▋ | 8671/10000 [00:32<00:05, 259.81it/s]Running 10000 simulations.:  87%|████████▋ | 8697/10000 [00:32<00:05, 257.83it/s]Running 10000 simulations.:  87%|████████▋ | 8724/10000 [00:32<00:04, 259.71it/s]Running 10000 simulations.:  88%|████████▊ | 8751/10000 [00:32<00:04, 260.17it/s]Running 10000 simulations.:  88%|████████▊ | 8778/10000 [00:33<00:04, 260.53it/s]Running 10000 simulations.:  88%|████████▊ | 8805/10000 [00:33<00:04, 259.38it/s]Running 10000 simulations.:  88%|████████▊ | 8831/10000 [00:33<00:04, 256.83it/s]Running 10000 simulations.:  89%|████████▊ | 8858/10000 [00:33<00:04, 259.34it/s]Running 10000 simulations.:  89%|████████▉ | 8885/10000 [00:33<00:04, 260.18it/s]Running 10000 simulations.:  89%|████████▉ | 8912/10000 [00:33<00:04, 261.77it/s]Running 10000 simulations.:  89%|████████▉ | 8939/10000 [00:33<00:04, 262.87it/s]Running 10000 simulations.:  90%|████████▉ | 8966/10000 [00:33<00:03, 263.29it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [00:33<00:03, 263.64it/s]Running 10000 simulations.:  90%|█████████ | 9020/10000 [00:34<00:03, 263.66it/s]Running 10000 simulations.:  90%|█████████ | 9047/10000 [00:34<00:03, 264.03it/s]Running 10000 simulations.:  91%|█████████ | 9074/10000 [00:34<00:03, 263.81it/s]Running 10000 simulations.:  91%|█████████ | 9101/10000 [00:34<00:03, 262.73it/s]Running 10000 simulations.:  91%|█████████▏| 9128/10000 [00:34<00:03, 263.16it/s]Running 10000 simulations.:  92%|█████████▏| 9155/10000 [00:34<00:03, 263.49it/s]Running 10000 simulations.:  92%|█████████▏| 9182/10000 [00:34<00:03, 263.42it/s]Running 10000 simulations.:  92%|█████████▏| 9209/10000 [00:34<00:03, 263.28it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [00:34<00:02, 263.25it/s]Running 10000 simulations.:  93%|█████████▎| 9263/10000 [00:34<00:02, 263.95it/s]Running 10000 simulations.:  93%|█████████▎| 9290/10000 [00:35<00:02, 264.47it/s]Running 10000 simulations.:  93%|█████████▎| 9317/10000 [00:35<00:02, 264.80it/s]Running 10000 simulations.:  93%|█████████▎| 9344/10000 [00:35<00:02, 265.25it/s]Running 10000 simulations.:  94%|█████████▎| 9371/10000 [00:35<00:02, 266.10it/s]Running 10000 simulations.:  94%|█████████▍| 9398/10000 [00:35<00:02, 266.47it/s]Running 10000 simulations.:  94%|█████████▍| 9425/10000 [00:35<00:02, 265.95it/s]Running 10000 simulations.:  95%|█████████▍| 9452/10000 [00:35<00:02, 265.72it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [00:35<00:01, 265.25it/s]Running 10000 simulations.:  95%|█████████▌| 9506/10000 [00:35<00:01, 265.49it/s]Running 10000 simulations.:  95%|█████████▌| 9533/10000 [00:35<00:01, 266.12it/s]Running 10000 simulations.:  96%|█████████▌| 9560/10000 [00:36<00:01, 265.63it/s]Running 10000 simulations.:  96%|█████████▌| 9587/10000 [00:36<00:01, 265.23it/s]Running 10000 simulations.:  96%|█████████▌| 9614/10000 [00:36<00:01, 265.26it/s]Running 10000 simulations.:  96%|█████████▋| 9641/10000 [00:36<00:01, 266.11it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [00:36<00:01, 266.75it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:36<00:01, 265.39it/s]Running 10000 simulations.:  97%|█████████▋| 9722/10000 [00:36<00:01, 266.06it/s]Running 10000 simulations.:  97%|█████████▋| 9749/10000 [00:36<00:00, 266.61it/s]Running 10000 simulations.:  98%|█████████▊| 9776/10000 [00:36<00:00, 265.65it/s]Running 10000 simulations.:  98%|█████████▊| 9803/10000 [00:36<00:00, 266.05it/s]Running 10000 simulations.:  98%|█████████▊| 9830/10000 [00:37<00:00, 266.09it/s]Running 10000 simulations.:  99%|█████████▊| 9858/10000 [00:37<00:00, 267.41it/s]Running 10000 simulations.:  99%|█████████▉| 9886/10000 [00:37<00:00, 268.47it/s]Running 10000 simulations.:  99%|█████████▉| 9914/10000 [00:37<00:00, 269.48it/s]Running 10000 simulations.:  99%|█████████▉| 9941/10000 [00:37<00:00, 269.14it/s]Running 10000 simulations.: 100%|█████████▉| 9968/10000 [00:37<00:00, 268.38it/s]Running 10000 simulations.: 100%|█████████▉| 9995/10000 [00:37<00:00, 268.41it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:37<00:00, 265.22it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54896it [00:00, 542710.87it/s]           Drawing 50000 posterior samples: 54896it [00:00, 540448.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53568it [00:00, 543102.64it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54884it [00:00, 549291.03it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54850it [00:00, 544231.58it/s]           Drawing 50000 posterior samples: 54850it [00:00, 541866.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50794it [00:00, 500476.83it/s]           Drawing 50000 posterior samples: 50794it [00:00, 498354.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54877it [00:00, 542903.08it/s]           Drawing 50000 posterior samples: 54877it [00:00, 540643.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54992it [00:00, 556147.23it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54850it [00:00, 535646.69it/s]           Drawing 50000 posterior samples: 54850it [00:00, 533041.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55034it [00:00, 554515.62it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55029it [00:00, 546257.06it/s]           Drawing 50000 posterior samples: 55029it [00:00, 543754.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54996it [00:00, 540427.06it/s]           Drawing 50000 posterior samples: 54996it [00:00, 537872.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54971it [00:00, 550974.23it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54961it [00:00, 552789.43it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54985it [00:00, 542485.97it/s]           Drawing 50000 posterior samples: 54985it [00:00, 539811.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54915it [00:00, 553673.05it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55031it [00:00, 545965.50it/s]           Drawing 50000 posterior samples: 55031it [00:00, 543608.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54945it [00:00, 554934.64it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55027it [00:00, 555555.47it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54927it [00:00, 549002.19it/s]           Drawing 50000 posterior samples: 54927it [00:00, 546724.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54997it [00:00, 549551.25it/s]           Drawing 50000 posterior samples: 54997it [00:00, 546577.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54915it [00:00, 540544.19it/s]           Drawing 50000 posterior samples: 54915it [00:00, 538171.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55004it [00:00, 545433.15it/s]           Drawing 50000 posterior samples: 55004it [00:00, 542653.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54695it [00:00, 545857.32it/s]           Drawing 50000 posterior samples: 54695it [00:00, 543019.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54889it [00:00, 565156.82it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54927it [00:00, 557015.59it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54891it [00:00, 558061.87it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54904it [00:00, 552030.81it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54979it [00:00, 543590.36it/s]           Drawing 50000 posterior samples: 54979it [00:00, 540886.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54958it [00:00, 548398.56it/s]           Drawing 50000 posterior samples: 54958it [00:00, 545757.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54913it [00:00, 545371.45it/s]           Drawing 50000 posterior samples: 54913it [00:00, 543046.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587827.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59571it [00:00, 595865.42it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 584581.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59996it [00:00, 592287.09it/s]           Drawing 50000 posterior samples: 59996it [00:00, 589327.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  99%|█████████▉| 49445/50000 [00:00<00:00, 488710.80it/s]Drawing 50000 posterior samples: 57653it [00:00, 487334.11it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54658it [00:00, 537849.11it/s]           Drawing 50000 posterior samples: 54658it [00:00, 535220.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 604176.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595983.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591371.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597673.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59969it [00:00, 599413.32it/s]           Drawing 50000 posterior samples: 59969it [00:00, 596891.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590728.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590613.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587402.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595161.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59467it [00:00, 591877.90it/s]           Drawing 50000 posterior samples: 59467it [00:00, 589274.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59925it [00:00, 590203.96it/s]           Drawing 50000 posterior samples: 59925it [00:00, 587732.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591285.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59419it [00:00, 596176.26it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590958.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598591.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 583198.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 594452.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 600249.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 594671.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 592919.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596970.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596929.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590875.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53328it [00:00, 530321.84it/s]           Drawing 50000 posterior samples: 53328it [00:00, 528108.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54951it [00:00, 539580.33it/s]           Drawing 50000 posterior samples: 54951it [00:00, 537308.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55057it [00:00, 550449.79it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55031it [00:00, 556846.43it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55007it [00:00, 553428.60it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52541it [00:00, 523680.01it/s]           Drawing 50000 posterior samples: 52541it [00:00, 521371.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54938it [00:00, 545645.58it/s]           Drawing 50000 posterior samples: 54938it [00:00, 543199.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54992it [00:00, 558422.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55150it [00:00, 561137.11it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55017it [00:00, 553519.91it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55066it [00:00, 543867.21it/s]           Drawing 50000 posterior samples: 55066it [00:00, 541604.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54998it [00:00, 541706.97it/s]           Drawing 50000 posterior samples: 54998it [00:00, 539470.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54983it [00:00, 556965.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54977it [00:00, 547786.67it/s]           Drawing 50000 posterior samples: 54977it [00:00, 545414.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54985it [00:00, 557741.32it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55018it [00:00, 570980.20it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55009it [00:00, 558262.89it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54996it [00:00, 561303.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55092it [00:00, 556047.09it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55052it [00:00, 539855.47it/s]           Drawing 50000 posterior samples: 55052it [00:00, 537389.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55105it [00:00, 554564.90it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55189it [00:00, 550581.77it/s]           Drawing 50000 posterior samples: 55189it [00:00, 548180.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55089it [00:00, 541404.36it/s]           Drawing 50000 posterior samples: 55089it [00:00, 537931.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55030it [00:00, 548480.23it/s]           Drawing 50000 posterior samples: 55030it [00:00, 546111.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54995it [00:00, 559182.92it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55069it [00:00, 550087.23it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55142it [00:00, 553420.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54902it [00:00, 550653.72it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54974it [00:00, 554117.40it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55071it [00:00, 559113.96it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54985it [00:00, 549824.31it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55172it [00:00, 546378.28it/s]           Drawing 50000 posterior samples: 55172it [00:00, 543626.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55083it [00:00, 540849.89it/s]           Drawing 50000 posterior samples: 55083it [00:00, 538463.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55053it [00:00, 542736.84it/s]           Drawing 50000 posterior samples: 55053it [00:00, 540428.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55202it [00:00, 543459.77it/s]           Drawing 50000 posterior samples: 55202it [00:00, 541055.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  99%|█████████▉| 49438/50000 [00:00<00:00, 492561.39it/s]Drawing 50000 posterior samples: 57676it [00:00, 490629.33it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55191it [00:00, 543494.35it/s]           Drawing 50000 posterior samples: 55191it [00:00, 541089.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55104it [00:00, 550713.59it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55095it [00:00, 546419.50it/s]           Drawing 50000 posterior samples: 55095it [00:00, 543948.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55177it [00:00, 544492.96it/s]           Drawing 50000 posterior samples: 55177it [00:00, 542135.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55197it [00:00, 540201.32it/s]           Drawing 50000 posterior samples: 55197it [00:00, 537911.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55055it [00:00, 473554.34it/s]           Drawing 50000 posterior samples: 55055it [00:00, 471848.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55173it [00:00, 548790.51it/s]           Drawing 50000 posterior samples: 55173it [00:00, 546528.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55065it [00:00, 552765.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55105it [00:00, 545556.33it/s]           Drawing 50000 posterior samples: 55105it [00:00, 543398.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55170it [00:00, 545622.87it/s]           Drawing 50000 posterior samples: 55170it [00:00, 543366.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55114it [00:00, 549146.51it/s]           Drawing 50000 posterior samples: 55114it [00:00, 546761.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55161it [00:00, 544501.61it/s]           Drawing 50000 posterior samples: 55161it [00:00, 542228.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55157it [00:00, 536542.28it/s]           Drawing 50000 posterior samples: 55157it [00:00, 534254.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55107it [00:00, 541667.57it/s]           Drawing 50000 posterior samples: 55107it [00:00, 539319.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55101it [00:00, 549604.51it/s]           Drawing 50000 posterior samples: 55101it [00:00, 547044.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55159it [00:00, 545646.60it/s]           Drawing 50000 posterior samples: 55159it [00:00, 543438.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55145it [00:00, 547984.39it/s]           Drawing 50000 posterior samples: 55145it [00:00, 545527.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55170it [00:00, 545840.38it/s]           Drawing 50000 posterior samples: 55170it [00:00, 543583.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55110it [00:00, 544741.76it/s]           Drawing 50000 posterior samples: 55110it [00:00, 542249.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55194it [00:00, 548821.08it/s]           Drawing 50000 posterior samples: 55194it [00:00, 546473.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55187it [00:00, 541764.51it/s]           Drawing 50000 posterior samples: 55187it [00:00, 539469.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55161it [00:00, 547739.79it/s]           Drawing 50000 posterior samples: 55161it [00:00, 544938.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55155it [00:00, 545527.26it/s]           Drawing 50000 posterior samples: 55155it [00:00, 543143.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55127it [00:00, 550124.19it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55145it [00:00, 547557.58it/s]           Drawing 50000 posterior samples: 55145it [00:00, 545204.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589518.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59969it [00:00, 592201.75it/s]           Drawing 50000 posterior samples: 59969it [00:00, 589304.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591708.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595409.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50693it [00:00, 500052.57it/s]           Drawing 50000 posterior samples: 50693it [00:00, 497776.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58372it [00:00, 581041.36it/s]           Drawing 50000 posterior samples: 58372it [00:00, 578308.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591471.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 585788.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593705.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 587636.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59944it [00:00, 595334.28it/s]           Drawing 50000 posterior samples: 59944it [00:00, 592684.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590990.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 592816.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601798.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 600184.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59392it [00:00, 590475.67it/s]           Drawing 50000 posterior samples: 59392it [00:00, 587967.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59969it [00:00, 599023.61it/s]           Drawing 50000 posterior samples: 59969it [00:00, 595730.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591991.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58801it [00:00, 585146.42it/s]           Drawing 50000 posterior samples: 58801it [00:00, 582376.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601634.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 588289.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 572795.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589380.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590195.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 583253.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 588302.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 607081.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591753.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 582909.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  95%|█████████▍| 47392/50000 [00:00<00:00, 448523.07it/s]Drawing 50000 posterior samples: 55280it [00:00, 449254.46it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593589.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59240it [00:00, 584126.72it/s]           Drawing 50000 posterior samples: 59240it [00:00, 581815.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 577614.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 583175.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36399/50000 [00:00<00:00, 347357.47it/s]Drawing 50000 posterior samples: 54663it [00:00, 349090.54it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53372it [00:00, 511848.31it/s]           Drawing 50000 posterior samples: 53372it [00:00, 509638.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590926.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 594174.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 584650.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 590891.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59990it [00:00, 576358.68it/s]           Drawing 50000 posterior samples: 59990it [00:00, 573885.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589969.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591243.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 594102.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 564179.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59795it [00:00, 592334.11it/s]           Drawing 50000 posterior samples: 59795it [00:00, 589852.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59430it [00:00, 593993.25it/s]           Drawing 50000 posterior samples: 59430it [00:00, 591621.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591723.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59968it [00:00, 590533.17it/s]           Drawing 50000 posterior samples: 59968it [00:00, 588105.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 570002.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 565376.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 582196.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 586895.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 576877.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 568642.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 581639.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59991it [00:00, 595386.58it/s]           Drawing 50000 posterior samples: 59991it [00:00, 592820.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 593325.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 589766.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54118it [00:00, 527675.06it/s]           Drawing 50000 posterior samples: 54118it [00:00, 525364.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55068it [00:00, 539727.19it/s]           Drawing 50000 posterior samples: 55068it [00:00, 537343.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54039it [00:00, 470909.89it/s]           Drawing 50000 posterior samples: 54039it [00:00, 469112.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54941it [00:00, 550844.67it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54987it [00:00, 547757.49it/s]           Drawing 50000 posterior samples: 54987it [00:00, 545170.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54628it [00:00, 541969.88it/s]           Drawing 50000 posterior samples: 54628it [00:00, 539350.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54918it [00:00, 534617.88it/s]           Drawing 50000 posterior samples: 54918it [00:00, 532217.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54918it [00:00, 523463.51it/s]           Drawing 50000 posterior samples: 54918it [00:00, 521218.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54802it [00:00, 531348.96it/s]           Drawing 50000 posterior samples: 54802it [00:00, 529221.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54954it [00:00, 553050.57it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55022it [00:00, 536852.65it/s]           Drawing 50000 posterior samples: 55022it [00:00, 534497.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54925it [00:00, 541713.06it/s]           Drawing 50000 posterior samples: 54925it [00:00, 539428.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54977it [00:00, 533920.80it/s]           Drawing 50000 posterior samples: 54977it [00:00, 531463.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55002it [00:00, 523684.59it/s]           Drawing 50000 posterior samples: 55002it [00:00, 521281.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54922it [00:00, 538658.74it/s]           Drawing 50000 posterior samples: 54922it [00:00, 536577.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54868it [00:00, 555862.22it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54907it [00:00, 549332.47it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54885it [00:00, 550071.51it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54989it [00:00, 549080.19it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55007it [00:00, 541440.88it/s]           Drawing 50000 posterior samples: 55007it [00:00, 538429.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54902it [00:00, 533448.11it/s]           Drawing 50000 posterior samples: 54902it [00:00, 531215.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54910it [00:00, 545814.68it/s]           Drawing 50000 posterior samples: 54910it [00:00, 543602.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54841it [00:00, 533770.43it/s]           Drawing 50000 posterior samples: 54841it [00:00, 531505.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54947it [00:00, 556434.08it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55006it [00:00, 528415.19it/s]           Drawing 50000 posterior samples: 55006it [00:00, 526140.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54921it [00:00, 562459.70it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54946it [00:00, 545475.74it/s]           Drawing 50000 posterior samples: 54946it [00:00, 543308.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54961it [00:00, 547029.47it/s]           Drawing 50000 posterior samples: 54961it [00:00, 544647.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54890it [00:00, 531527.63it/s]           Drawing 50000 posterior samples: 54890it [00:00, 529316.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54956it [00:00, 550837.05it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54924it [00:00, 514612.78it/s]           Drawing 50000 posterior samples: 54924it [00:00, 512497.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55104it [00:00, 536378.76it/s]           Drawing 50000 posterior samples: 55104it [00:00, 534049.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55014it [00:00, 543508.48it/s]           Drawing 50000 posterior samples: 55014it [00:00, 541302.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54957it [00:00, 543128.30it/s]           Drawing 50000 posterior samples: 54957it [00:00, 540692.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55037it [00:00, 538011.51it/s]           Drawing 50000 posterior samples: 55037it [00:00, 535671.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51311it [00:00, 507306.04it/s]           Drawing 50000 posterior samples: 51311it [00:00, 505136.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55225it [00:00, 530482.57it/s]           Drawing 50000 posterior samples: 55225it [00:00, 528140.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55097it [00:00, 519973.92it/s]           Drawing 50000 posterior samples: 55097it [00:00, 517507.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54974it [00:00, 539205.30it/s]           Drawing 50000 posterior samples: 54974it [00:00, 537274.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55133it [00:00, 544721.35it/s]           Drawing 50000 posterior samples: 55133it [00:00, 542298.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55099it [00:00, 538285.13it/s]           Drawing 50000 posterior samples: 55099it [00:00, 536047.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55166it [00:00, 516801.70it/s]           Drawing 50000 posterior samples: 55166it [00:00, 514654.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55099it [00:00, 551174.50it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55061it [00:00, 541720.69it/s]           Drawing 50000 posterior samples: 55061it [00:00, 539198.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55160it [00:00, 551189.20it/s]           Drawing 50000 posterior samples: 55160it [00:00, 548947.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55140it [00:00, 539453.40it/s]           Drawing 50000 posterior samples: 55140it [00:00, 537212.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55056it [00:00, 541047.08it/s]           Drawing 50000 posterior samples: 55056it [00:00, 538827.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55108it [00:00, 524915.47it/s]           Drawing 50000 posterior samples: 55108it [00:00, 522738.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55122it [00:00, 543092.84it/s]           Drawing 50000 posterior samples: 55122it [00:00, 540741.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55150it [00:00, 530498.39it/s]           Drawing 50000 posterior samples: 55150it [00:00, 528275.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55119it [00:00, 537988.06it/s]           Drawing 50000 posterior samples: 55119it [00:00, 535813.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55075it [00:00, 526511.87it/s]           Drawing 50000 posterior samples: 55075it [00:00, 524085.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55057it [00:00, 523475.08it/s]           Drawing 50000 posterior samples: 55057it [00:00, 521211.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55050it [00:00, 530952.64it/s]           Drawing 50000 posterior samples: 55050it [00:00, 528680.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55163it [00:00, 548773.03it/s]           Drawing 50000 posterior samples: 55163it [00:00, 546556.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55086it [00:00, 540483.32it/s]           Drawing 50000 posterior samples: 55086it [00:00, 538163.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55098it [00:00, 537429.16it/s]           Drawing 50000 posterior samples: 55098it [00:00, 534808.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55087it [00:00, 508945.58it/s]           Drawing 50000 posterior samples: 55087it [00:00, 506796.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55095it [00:00, 522618.50it/s]           Drawing 50000 posterior samples: 55095it [00:00, 520169.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54978it [00:00, 524783.16it/s]           Drawing 50000 posterior samples: 54978it [00:00, 521066.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55035it [00:00, 543724.92it/s]           Drawing 50000 posterior samples: 55035it [00:00, 540522.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54968it [00:00, 529059.53it/s]           Drawing 50000 posterior samples: 54968it [00:00, 526617.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54872it [00:00, 507089.90it/s]           Drawing 50000 posterior samples: 54872it [00:00, 504737.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54834it [00:00, 538813.68it/s]           Drawing 50000 posterior samples: 54834it [00:00, 536772.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54821it [00:00, 535240.11it/s]           Drawing 50000 posterior samples: 54821it [00:00, 532799.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  95%|█████████▍| 47468/50000 [00:00<00:00, 461450.72it/s]Drawing 50000 posterior samples: 55452it [00:00, 460342.54it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54918it [00:00, 531174.56it/s]           Drawing 50000 posterior samples: 54918it [00:00, 528878.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54915it [00:00, 539047.64it/s]           Drawing 50000 posterior samples: 54915it [00:00, 536327.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54856it [00:00, 551451.69it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54839it [00:00, 553914.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54813it [00:00, 542319.81it/s]           Drawing 50000 posterior samples: 54813it [00:00, 539991.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54891it [00:00, 530564.72it/s]           Drawing 50000 posterior samples: 54891it [00:00, 528086.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54773it [00:00, 536924.94it/s]           Drawing 50000 posterior samples: 54773it [00:00, 534230.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54993it [00:00, 540809.37it/s]           Drawing 50000 posterior samples: 54993it [00:00, 538474.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54850it [00:00, 542106.60it/s]           Drawing 50000 posterior samples: 54850it [00:00, 539329.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54954it [00:00, 540801.16it/s]           Drawing 50000 posterior samples: 54954it [00:00, 538050.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54852it [00:00, 538844.12it/s]           Drawing 50000 posterior samples: 54852it [00:00, 536348.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54876it [00:00, 507837.38it/s]           Drawing 50000 posterior samples: 54876it [00:00, 504631.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54852it [00:00, 542951.59it/s]           Drawing 50000 posterior samples: 54852it [00:00, 540690.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54884it [00:00, 539690.63it/s]           Drawing 50000 posterior samples: 54884it [00:00, 537619.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54900it [00:00, 542570.09it/s]           Drawing 50000 posterior samples: 54900it [00:00, 540267.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54898it [00:00, 526312.07it/s]           Drawing 50000 posterior samples: 54898it [00:00, 524100.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54893it [00:00, 518777.06it/s]           Drawing 50000 posterior samples: 54893it [00:00, 516425.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54858it [00:00, 558580.72it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54828it [00:00, 554393.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54799it [00:00, 531705.82it/s]           Drawing 50000 posterior samples: 54799it [00:00, 529511.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54810it [00:00, 548904.06it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54892it [00:00, 534734.62it/s]           Drawing 50000 posterior samples: 54892it [00:00, 532315.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54832it [00:00, 556232.41it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54821it [00:00, 549357.88it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54848it [00:00, 536010.29it/s]           Drawing 50000 posterior samples: 54848it [00:00, 533656.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54730it [00:00, 545884.50it/s]           Drawing 50000 posterior samples: 54730it [00:00, 543421.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54830it [00:00, 552054.33it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54852it [00:00, 544295.20it/s]           Drawing 50000 posterior samples: 54852it [00:00, 541794.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54948it [00:00, 540789.06it/s]           Drawing 50000 posterior samples: 54948it [00:00, 538353.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50825it [00:00, 487903.99it/s]           Drawing 50000 posterior samples: 50825it [00:00, 485923.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54878it [00:00, 533301.39it/s]           Drawing 50000 posterior samples: 54878it [00:00, 530775.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54859it [00:00, 517807.04it/s]           Drawing 50000 posterior samples: 54859it [00:00, 513948.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54749it [00:00, 542487.68it/s]           Drawing 50000 posterior samples: 54749it [00:00, 539468.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54839it [00:00, 554231.07it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54843it [00:00, 555035.15it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54922it [00:00, 548402.03it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54850it [00:00, 551645.23it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54872it [00:00, 525882.51it/s]           Drawing 50000 posterior samples: 54872it [00:00, 523392.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54762it [00:00, 526130.25it/s]           Drawing 50000 posterior samples: 54762it [00:00, 523384.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54851it [00:00, 561852.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54802it [00:00, 564563.17it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54863it [00:00, 543443.95it/s]           Drawing 50000 posterior samples: 54863it [00:00, 540853.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54756it [00:00, 519821.35it/s]           Drawing 50000 posterior samples: 54756it [00:00, 517373.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54796it [00:00, 494740.24it/s]           Drawing 50000 posterior samples: 54796it [00:00, 492510.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54860it [00:00, 511122.13it/s]           Drawing 50000 posterior samples: 54860it [00:00, 508155.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54811it [00:00, 536751.75it/s]           Drawing 50000 posterior samples: 54811it [00:00, 534132.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54697it [00:00, 535978.26it/s]           Drawing 50000 posterior samples: 54697it [00:00, 533366.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54881it [00:00, 524137.58it/s]           Drawing 50000 posterior samples: 54881it [00:00, 521437.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54905it [00:00, 478678.22it/s]           Drawing 50000 posterior samples: 54905it [00:00, 476220.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54834it [00:00, 542261.53it/s]           Drawing 50000 posterior samples: 54834it [00:00, 539950.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54852it [00:00, 561567.94it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54865it [00:00, 542032.62it/s]           Drawing 50000 posterior samples: 54865it [00:00, 539445.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54949it [00:00, 551242.44it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54813it [00:00, 516861.06it/s]           Drawing 50000 posterior samples: 54813it [00:00, 514430.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54705it [00:00, 538233.31it/s]           Drawing 50000 posterior samples: 54705it [00:00, 535800.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
30
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Neural network successfully converged after 162 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Neural network successfully converged after 292 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Neural network successfully converged after 228 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Neural network successfully converged after 154 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Neural network successfully converged after 271 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Neural network successfully converged after 367 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Neural network successfully converged after 215 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Neural network successfully converged after 242 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Neural network successfully converged after 228 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Neural network successfully converged after 296 epochs.
log prob true 4.060056
log prob true 3.9657724
log prob true 4.206128
log prob true 3.0043662
log prob true 3.3554733
log prob true 2.99037
log prob true 3.58411
log prob true 3.835428
log prob true 3.7481177
log prob true 3.6309671
log prob true 3.052086
log prob true 4.0737762
log prob true 4.1503115
log prob true 3.848326
log prob true 3.3719523
log prob true 3.0424678
log prob true 3.7837574
log prob true 4.086988
log prob true 3.0579226
log prob true 4.0813117
log prob true 3.896534
log prob true 3.4872265
log prob true 4.392362
log prob true 3.7833552
log prob true 4.254222
log prob true 3.9700742
log prob true 3.1549344
log prob true 3.276802
log prob true 4.1265454
log prob true 2.5348754
log prob true 6.9817276
log prob true 6.563162
log prob true 6.834834
log prob true 6.4000254
log prob true 6.2516704
log prob true 6.2585382
log prob true 6.4087176
log prob true 6.682544
log prob true 6.4183235
log prob true 6.5644064
log prob true 6.290721
log prob true 6.790726
log prob true 7.186564
log prob true 6.4931393
log prob true 6.303418
log prob true 5.9653068
log prob true 6.1404195
log prob true 6.656887
log prob true 6.3246927
log prob true 6.8762293
log prob true 6.557535
log prob true 6.5214934
log prob true 6.995743
log prob true 6.2725043
log prob true 6.678884
log prob true 6.5600877
log prob true 6.015939
log prob true 6.297018
log prob true 6.838131
log prob true 5.997828
log prob true 4.358534
log prob true 4.1437664
log prob true 4.200355
log prob true 3.2903543
log prob true 3.5593605
log prob true 3.2116983
log prob true 3.806685
log prob true 4.3428397
log prob true 3.8132737
log prob true 4.0077243
log prob true 3.3811386
log prob true 4.288553
log prob true 4.1056795
log prob true 4.0618606
log prob true 3.4357786
log prob true 3.1447937
log prob true 3.912322
log prob true 4.1862617
log prob true 3.201123
log prob true 4.3805013
log prob true 3.8496523
log prob true 3.5208619
log prob true 4.229039
log prob true 4.032452
log prob true 4.3595195
log prob true 4.225729
log prob true 3.3610177
log prob true 3.7924635
log prob true 4.3282795
log prob true 2.9798834
log prob true 4.3169208
log prob true 3.8677878
log prob true 4.1996565
log prob true 3.2113497
log prob true 3.450177
log prob true 2.9230354
log prob true 3.5760503
log prob true 4.057574
log prob true 3.7718995
log prob true 3.7440646
log prob true 3.142197
log prob true 4.034898
log prob true 4.289413
log prob true 3.9895408
log prob true 3.411788
log prob true 2.9396667
log prob true 3.7023227
log prob true 4.0290847
log prob true 3.0008655
log prob true 4.150886
log prob true 4.104288
log prob true 3.5280182
log prob true 4.32261
log prob true 3.6789846
log prob true 4.2155323
log prob true 4.000416
log prob true 3.0766845
log prob true 3.4104054
log prob true 4.149646
log prob true 2.7897398
log prob true 7.31694
log prob true 6.7989726
log prob true 7.121488
log prob true 6.76209
log prob true 6.361327
log prob true 5.994213
log prob true 6.7271857
log prob true 7.0530734
log prob true 6.6907663
log prob true 6.868668
log prob true 6.514371
log prob true 7.070626
log prob true 7.3772173
log prob true 7.0635877
log prob true 6.577559
log prob true 5.9952755
log prob true 6.2178164
log prob true 6.7558093
log prob true 6.55923
log prob true 7.1450577
log prob true 7.100011
log prob true 6.723745
log prob true 7.142517
log prob true 6.6933956
log prob true 7.047176
log prob true 6.943751
log prob true 6.1245036
log prob true 6.5966825
log prob true 6.9550138
log prob true 6.579652
log prob true 7.117163
log prob true 6.586987
log prob true 6.79528
log prob true 6.611674
log prob true 6.7553573
log prob true 6.664132
log prob true 6.550396
log prob true 7.0106363
log prob true 6.580607
log prob true 6.9043055
log prob true 6.5977225
log prob true 6.947236
log prob true 7.4232655
log prob true 6.937905
log prob true 6.4897985
log prob true 6.1523137
log prob true 6.4806023
log prob true 6.8576493
log prob true 6.404206
log prob true 7.0739684
log prob true 7.175164
log prob true 6.745936
log prob true 6.989628
log prob true 6.4309645
log prob true 7.057171
log prob true 6.892286
log prob true 5.92849
log prob true 6.651468
log prob true 6.86366
log prob true 6.553618
log prob true 4.4935355
log prob true 3.6476612
log prob true 4.316539
log prob true 3.760287
log prob true 3.5809956
log prob true 3.2352693
log prob true 3.8026054
log prob true 4.286577
log prob true 3.90851
log prob true 3.9989605
log prob true 3.398008
log prob true 4.029226
log prob true 4.382155
log prob true 4.169858
log prob true 3.5134807
log prob true 3.2456229
log prob true 3.9680445
log prob true 4.247851
log prob true 3.2218988
log prob true 4.2580576
log prob true 3.9733977
log prob true 3.8169816
log prob true 4.457818
log prob true 3.8966305
log prob true 4.4122295
log prob true 4.140977
log prob true 3.1235898
log prob true 3.705337
log prob true 4.3668895
log prob true 3.0950067
log prob true 4.4854794
log prob true 4.0902414
log prob true 3.9980564
log prob true 3.5685246
log prob true 3.1514878
log prob true 3.21488
log prob true 3.7716677
log prob true 4.342472
log prob true 3.7638946
log prob true 4.01779
log prob true 3.467597
log prob true 4.232532
log prob true 4.6058345
log prob true 4.1972384
log prob true 2.987002
log prob true 3.0997014
log prob true 3.5534158
log prob true 4.01791
log prob true 3.5324113
log prob true 4.3636003
log prob true 4.2847834
log prob true 3.996493
log prob true 4.4299626
log prob true 3.9291837
log prob true 4.386407
log prob true 4.1555653
log prob true 3.3016171
log prob true 3.7558506
log prob true 4.3479023
log prob true 3.0584924
log prob true 4.352613
log prob true 4.2581563
log prob true 4.419547
log prob true 3.5433202
log prob true 3.2514184
log prob true 2.9722316
log prob true 3.8754206
log prob true 4.543234
log prob true 4.000166
log prob true 4.0931416
log prob true 3.4765744
log prob true 4.3866086
log prob true 4.4837604
log prob true 4.0330153
log prob true 3.6048992
log prob true 3.290313
log prob true 3.641452
log prob true 4.1024766
log prob true 3.4219253
log prob true 4.482338
log prob true 4.181863
log prob true 3.8408215
log prob true 4.6472654
log prob true 4.11404
log prob true 4.4567313
log prob true 4.276432
log prob true 3.46503
log prob true 3.8960292
log prob true 4.183365
log prob true 3.2488215
log prob true 4.696636
log prob true 4.328329
log prob true 4.1899614
log prob true 3.7796662
log prob true 3.2335005
log prob true 3.1520612
log prob true 3.9158185
log prob true 4.50734
log prob true 3.7693486
log prob true 4.182891
log prob true 3.8320014
log prob true 4.436691
log prob true 4.536627
log prob true 4.35211
log prob true 3.381493
log prob true 3.3526223
log prob true 3.7632291
log prob true 4.174063
log prob true 3.269213
log prob true 4.5435996
log prob true 4.3461676
log prob true 3.93244
log prob true 4.5062623
log prob true 4.154859
log prob true 4.433627
log prob true 4.3250623
log prob true 3.5898657
log prob true 3.9213438
log prob true 4.2468567
log prob true 3.2231774
script complete
