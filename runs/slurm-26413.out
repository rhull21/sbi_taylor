Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 252.09it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 253.40it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:38, 254.60it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:38, 255.30it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:38, 254.16it/s]Running 10000 simulations.:   2%|▏         | 156/10000 [00:00<00:38, 253.91it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:00<00:38, 253.49it/s]Running 10000 simulations.:   2%|▏         | 208/10000 [00:00<00:38, 254.01it/s]Running 10000 simulations.:   2%|▏         | 234/10000 [00:00<00:38, 253.75it/s]Running 10000 simulations.:   3%|▎         | 260/10000 [00:01<00:38, 253.82it/s]Running 10000 simulations.:   3%|▎         | 286/10000 [00:01<00:38, 253.83it/s]Running 10000 simulations.:   3%|▎         | 312/10000 [00:01<00:38, 253.51it/s]Running 10000 simulations.:   3%|▎         | 338/10000 [00:01<00:38, 253.24it/s]Running 10000 simulations.:   4%|▎         | 364/10000 [00:01<00:38, 252.67it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:38, 252.60it/s]Running 10000 simulations.:   4%|▍         | 416/10000 [00:01<00:37, 252.36it/s]Running 10000 simulations.:   4%|▍         | 442/10000 [00:01<00:38, 248.69it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:01<00:38, 249.63it/s]Running 10000 simulations.:   5%|▍         | 494/10000 [00:01<00:37, 250.62it/s]Running 10000 simulations.:   5%|▌         | 520/10000 [00:02<00:37, 250.98it/s]Running 10000 simulations.:   5%|▌         | 546/10000 [00:02<00:37, 251.18it/s]Running 10000 simulations.:   6%|▌         | 572/10000 [00:02<00:37, 250.29it/s]Running 10000 simulations.:   6%|▌         | 598/10000 [00:02<00:37, 250.22it/s]Running 10000 simulations.:   6%|▌         | 624/10000 [00:02<00:37, 249.53it/s]Running 10000 simulations.:   6%|▋         | 650/10000 [00:02<00:37, 249.68it/s]Running 10000 simulations.:   7%|▋         | 675/10000 [00:02<00:37, 248.68it/s]Running 10000 simulations.:   7%|▋         | 700/10000 [00:02<00:37, 248.76it/s]Running 10000 simulations.:   7%|▋         | 725/10000 [00:02<00:37, 247.12it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:02<00:37, 247.38it/s]Running 10000 simulations.:   8%|▊         | 775/10000 [00:03<00:37, 246.53it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:03<00:37, 245.91it/s]Running 10000 simulations.:   8%|▊         | 825/10000 [00:03<00:37, 246.70it/s]Running 10000 simulations.:   8%|▊         | 850/10000 [00:03<00:37, 247.01it/s]Running 10000 simulations.:   9%|▉         | 875/10000 [00:03<00:36, 247.13it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:36, 247.22it/s]Running 10000 simulations.:   9%|▉         | 925/10000 [00:03<00:36, 247.85it/s]Running 10000 simulations.:  10%|▉         | 950/10000 [00:03<00:36, 247.87it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:03<00:36, 248.04it/s]Running 10000 simulations.:  10%|█         | 1000/10000 [00:03<00:36, 247.95it/s]Running 10000 simulations.:  10%|█         | 1025/10000 [00:04<00:36, 247.97it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:04<00:36, 248.05it/s]Running 10000 simulations.:  11%|█         | 1075/10000 [00:04<00:35, 248.36it/s]Running 10000 simulations.:  11%|█         | 1100/10000 [00:04<00:36, 247.15it/s]Running 10000 simulations.:  11%|█▏        | 1125/10000 [00:04<00:36, 245.98it/s]Running 10000 simulations.:  12%|█▏        | 1150/10000 [00:04<00:36, 245.65it/s]Running 10000 simulations.:  12%|█▏        | 1175/10000 [00:04<00:35, 246.19it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:35, 246.18it/s]Running 10000 simulations.:  12%|█▏        | 1225/10000 [00:04<00:36, 243.69it/s]Running 10000 simulations.:  12%|█▎        | 1250/10000 [00:05<00:35, 243.28it/s]Running 10000 simulations.:  13%|█▎        | 1275/10000 [00:05<00:35, 243.93it/s]Running 10000 simulations.:  13%|█▎        | 1300/10000 [00:05<00:35, 243.57it/s]Running 10000 simulations.:  13%|█▎        | 1325/10000 [00:05<00:35, 242.86it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:05<00:35, 242.33it/s]Running 10000 simulations.:  14%|█▍        | 1375/10000 [00:05<00:35, 242.02it/s]Running 10000 simulations.:  14%|█▍        | 1400/10000 [00:05<00:35, 242.16it/s]Running 10000 simulations.:  14%|█▍        | 1425/10000 [00:05<00:35, 243.14it/s]Running 10000 simulations.:  14%|█▍        | 1450/10000 [00:05<00:34, 244.30it/s]Running 10000 simulations.:  15%|█▍        | 1475/10000 [00:05<00:34, 244.32it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:06<00:34, 244.78it/s]Running 10000 simulations.:  15%|█▌        | 1525/10000 [00:06<00:34, 244.28it/s]Running 10000 simulations.:  16%|█▌        | 1550/10000 [00:06<00:34, 243.91it/s]Running 10000 simulations.:  16%|█▌        | 1575/10000 [00:06<00:34, 244.09it/s]Running 10000 simulations.:  16%|█▌        | 1600/10000 [00:06<00:34, 244.71it/s]Running 10000 simulations.:  16%|█▋        | 1625/10000 [00:06<00:34, 245.08it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:06<00:33, 245.68it/s]Running 10000 simulations.:  17%|█▋        | 1675/10000 [00:06<00:33, 245.97it/s]Running 10000 simulations.:  17%|█▋        | 1700/10000 [00:06<00:33, 245.99it/s]Running 10000 simulations.:  17%|█▋        | 1725/10000 [00:06<00:33, 245.31it/s]Running 10000 simulations.:  18%|█▊        | 1750/10000 [00:07<00:33, 244.80it/s]Running 10000 simulations.:  18%|█▊        | 1775/10000 [00:07<00:33, 244.81it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:07<00:33, 245.42it/s]Running 10000 simulations.:  18%|█▊        | 1825/10000 [00:07<00:33, 246.34it/s]Running 10000 simulations.:  18%|█▊        | 1850/10000 [00:07<00:33, 245.39it/s]Running 10000 simulations.:  19%|█▉        | 1875/10000 [00:07<00:33, 244.50it/s]Running 10000 simulations.:  19%|█▉        | 1900/10000 [00:07<00:33, 244.78it/s]Running 10000 simulations.:  19%|█▉        | 1925/10000 [00:07<00:32, 245.33it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:07<00:32, 245.93it/s]Running 10000 simulations.:  20%|█▉        | 1975/10000 [00:07<00:32, 246.19it/s]Running 10000 simulations.:  20%|██        | 2000/10000 [00:08<00:32, 245.07it/s]Running 10000 simulations.:  20%|██        | 2025/10000 [00:08<00:32, 243.83it/s]Running 10000 simulations.:  20%|██        | 2050/10000 [00:08<00:32, 242.07it/s]Running 10000 simulations.:  21%|██        | 2075/10000 [00:08<00:32, 242.96it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:08<00:32, 244.03it/s]Running 10000 simulations.:  21%|██▏       | 2125/10000 [00:08<00:32, 244.41it/s]Running 10000 simulations.:  22%|██▏       | 2150/10000 [00:08<00:32, 244.88it/s]Running 10000 simulations.:  22%|██▏       | 2175/10000 [00:08<00:31, 244.95it/s]Running 10000 simulations.:  22%|██▏       | 2200/10000 [00:08<00:32, 242.90it/s]Running 10000 simulations.:  22%|██▏       | 2225/10000 [00:09<00:32, 242.95it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:09<00:31, 242.30it/s]Running 10000 simulations.:  23%|██▎       | 2275/10000 [00:09<00:31, 241.65it/s]Running 10000 simulations.:  23%|██▎       | 2300/10000 [00:09<00:31, 241.53it/s]Running 10000 simulations.:  23%|██▎       | 2325/10000 [00:09<00:31, 241.38it/s]Running 10000 simulations.:  24%|██▎       | 2350/10000 [00:09<00:31, 241.16it/s]Running 10000 simulations.:  24%|██▍       | 2375/10000 [00:09<00:31, 240.75it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:09<00:31, 240.35it/s]Running 10000 simulations.:  24%|██▍       | 2425/10000 [00:09<00:31, 240.98it/s]Running 10000 simulations.:  24%|██▍       | 2450/10000 [00:09<00:31, 242.21it/s]Running 10000 simulations.:  25%|██▍       | 2475/10000 [00:10<00:30, 243.05it/s]Running 10000 simulations.:  25%|██▌       | 2500/10000 [00:10<00:31, 241.83it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:10<00:31, 240.92it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:10<00:30, 240.50it/s]Running 10000 simulations.:  26%|██▌       | 2575/10000 [00:10<00:30, 240.28it/s]Running 10000 simulations.:  26%|██▌       | 2600/10000 [00:10<00:30, 240.21it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:10<00:30, 239.41it/s]Running 10000 simulations.:  26%|██▋       | 2649/10000 [00:10<00:30, 239.17it/s]Running 10000 simulations.:  27%|██▋       | 2673/10000 [00:10<00:30, 238.24it/s]Running 10000 simulations.:  27%|██▋       | 2697/10000 [00:10<00:30, 237.45it/s]Running 10000 simulations.:  27%|██▋       | 2721/10000 [00:11<00:30, 237.37it/s]Running 10000 simulations.:  27%|██▋       | 2745/10000 [00:11<00:30, 236.58it/s]Running 10000 simulations.:  28%|██▊       | 2770/10000 [00:11<00:30, 238.05it/s]Running 10000 simulations.:  28%|██▊       | 2794/10000 [00:11<00:30, 238.52it/s]Running 10000 simulations.:  28%|██▊       | 2818/10000 [00:11<00:30, 237.95it/s]Running 10000 simulations.:  28%|██▊       | 2842/10000 [00:11<00:30, 237.68it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:11<00:30, 237.72it/s]Running 10000 simulations.:  29%|██▉       | 2890/10000 [00:11<00:29, 237.74it/s]Running 10000 simulations.:  29%|██▉       | 2914/10000 [00:11<00:29, 238.09it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:11<00:29, 237.71it/s]Running 10000 simulations.:  30%|██▉       | 2962/10000 [00:12<00:29, 237.39it/s]Running 10000 simulations.:  30%|██▉       | 2986/10000 [00:12<00:29, 237.45it/s]Running 10000 simulations.:  30%|███       | 3010/10000 [00:12<00:29, 236.10it/s]Running 10000 simulations.:  30%|███       | 3034/10000 [00:12<00:29, 233.87it/s]Running 10000 simulations.:  31%|███       | 3058/10000 [00:12<00:29, 233.73it/s]Running 10000 simulations.:  31%|███       | 3082/10000 [00:12<00:29, 234.10it/s]Running 10000 simulations.:  31%|███       | 3106/10000 [00:12<00:29, 235.02it/s]Running 10000 simulations.:  31%|███▏      | 3130/10000 [00:12<00:29, 235.58it/s]Running 10000 simulations.:  32%|███▏      | 3154/10000 [00:12<00:29, 235.99it/s]Running 10000 simulations.:  32%|███▏      | 3178/10000 [00:13<00:28, 236.04it/s]Running 10000 simulations.:  32%|███▏      | 3202/10000 [00:13<00:28, 235.76it/s]Running 10000 simulations.:  32%|███▏      | 3226/10000 [00:13<00:28, 236.20it/s]Running 10000 simulations.:  32%|███▎      | 3250/10000 [00:13<00:28, 236.07it/s]Running 10000 simulations.:  33%|███▎      | 3274/10000 [00:13<00:28, 236.14it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:13<00:28, 236.31it/s]Running 10000 simulations.:  33%|███▎      | 3322/10000 [00:13<00:28, 236.33it/s]Running 10000 simulations.:  33%|███▎      | 3346/10000 [00:13<00:28, 236.12it/s]Running 10000 simulations.:  34%|███▎      | 3370/10000 [00:13<00:28, 235.50it/s]Running 10000 simulations.:  34%|███▍      | 3394/10000 [00:13<00:28, 235.85it/s]Running 10000 simulations.:  34%|███▍      | 3418/10000 [00:14<00:27, 236.12it/s]Running 10000 simulations.:  34%|███▍      | 3442/10000 [00:14<00:27, 236.23it/s]Running 10000 simulations.:  35%|███▍      | 3466/10000 [00:14<00:27, 236.68it/s]Running 10000 simulations.:  35%|███▍      | 3490/10000 [00:14<00:27, 236.73it/s]Running 10000 simulations.:  35%|███▌      | 3514/10000 [00:14<00:27, 236.84it/s]Running 10000 simulations.:  35%|███▌      | 3538/10000 [00:14<00:27, 236.54it/s]Running 10000 simulations.:  36%|███▌      | 3562/10000 [00:14<00:27, 236.28it/s]Running 10000 simulations.:  36%|███▌      | 3586/10000 [00:14<00:27, 235.36it/s]Running 10000 simulations.:  36%|███▌      | 3610/10000 [00:14<00:27, 234.50it/s]Running 10000 simulations.:  36%|███▋      | 3634/10000 [00:14<00:27, 233.75it/s]Running 10000 simulations.:  37%|███▋      | 3658/10000 [00:15<00:27, 234.03it/s]Running 10000 simulations.:  37%|███▋      | 3682/10000 [00:15<00:26, 234.65it/s]Running 10000 simulations.:  37%|███▋      | 3706/10000 [00:15<00:26, 234.48it/s]Running 10000 simulations.:  37%|███▋      | 3730/10000 [00:15<00:26, 233.65it/s]Running 10000 simulations.:  38%|███▊      | 3754/10000 [00:15<00:26, 233.17it/s]Running 10000 simulations.:  38%|███▊      | 3778/10000 [00:15<00:26, 232.93it/s]Running 10000 simulations.:  38%|███▊      | 3802/10000 [00:15<00:26, 233.52it/s]Running 10000 simulations.:  38%|███▊      | 3826/10000 [00:15<00:26, 234.58it/s]Running 10000 simulations.:  38%|███▊      | 3850/10000 [00:15<00:26, 235.34it/s]Running 10000 simulations.:  39%|███▊      | 3874/10000 [00:15<00:25, 235.64it/s]Running 10000 simulations.:  39%|███▉      | 3898/10000 [00:16<00:25, 235.48it/s]Running 10000 simulations.:  39%|███▉      | 3922/10000 [00:16<00:25, 235.10it/s]Running 10000 simulations.:  39%|███▉      | 3946/10000 [00:16<00:25, 235.94it/s]Running 10000 simulations.:  40%|███▉      | 3971/10000 [00:16<00:25, 237.36it/s]Running 10000 simulations.:  40%|███▉      | 3995/10000 [00:16<00:25, 237.70it/s]Running 10000 simulations.:  40%|████      | 4019/10000 [00:16<00:25, 238.01it/s]Running 10000 simulations.:  40%|████      | 4043/10000 [00:16<00:25, 237.92it/s]Running 10000 simulations.:  41%|████      | 4067/10000 [00:16<00:24, 237.97it/s]Running 10000 simulations.:  41%|████      | 4091/10000 [00:16<00:24, 237.78it/s]Running 10000 simulations.:  41%|████      | 4115/10000 [00:16<00:25, 234.35it/s]Running 10000 simulations.:  41%|████▏     | 4139/10000 [00:17<00:24, 235.54it/s]Running 10000 simulations.:  42%|████▏     | 4163/10000 [00:17<00:24, 236.40it/s]Running 10000 simulations.:  42%|████▏     | 4187/10000 [00:17<00:24, 236.96it/s]Running 10000 simulations.:  42%|████▏     | 4211/10000 [00:17<00:24, 237.11it/s]Running 10000 simulations.:  42%|████▏     | 4235/10000 [00:17<00:24, 236.71it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:17<00:24, 236.86it/s]Running 10000 simulations.:  43%|████▎     | 4283/10000 [00:17<00:24, 236.47it/s]Running 10000 simulations.:  43%|████▎     | 4307/10000 [00:17<00:24, 235.88it/s]Running 10000 simulations.:  43%|████▎     | 4331/10000 [00:17<00:24, 235.69it/s]Running 10000 simulations.:  44%|████▎     | 4355/10000 [00:17<00:24, 235.16it/s]Running 10000 simulations.:  44%|████▍     | 4379/10000 [00:18<00:23, 234.74it/s]Running 10000 simulations.:  44%|████▍     | 4403/10000 [00:18<00:23, 235.32it/s]Running 10000 simulations.:  44%|████▍     | 4427/10000 [00:18<00:23, 234.87it/s]Running 10000 simulations.:  45%|████▍     | 4451/10000 [00:18<00:23, 235.24it/s]Running 10000 simulations.:  45%|████▍     | 4475/10000 [00:18<00:23, 235.96it/s]Running 10000 simulations.:  45%|████▍     | 4499/10000 [00:18<00:23, 236.14it/s]Running 10000 simulations.:  45%|████▌     | 4523/10000 [00:18<00:23, 236.67it/s]Running 10000 simulations.:  45%|████▌     | 4547/10000 [00:18<00:23, 236.99it/s]Running 10000 simulations.:  46%|████▌     | 4571/10000 [00:18<00:22, 237.40it/s]Running 10000 simulations.:  46%|████▌     | 4595/10000 [00:19<00:22, 237.76it/s]Running 10000 simulations.:  46%|████▌     | 4619/10000 [00:19<00:22, 237.45it/s]Running 10000 simulations.:  46%|████▋     | 4644/10000 [00:19<00:22, 238.32it/s]Running 10000 simulations.:  47%|████▋     | 4668/10000 [00:19<00:22, 238.31it/s]Running 10000 simulations.:  47%|████▋     | 4692/10000 [00:19<00:22, 238.33it/s]Running 10000 simulations.:  47%|████▋     | 4716/10000 [00:19<00:22, 237.93it/s]Running 10000 simulations.:  47%|████▋     | 4740/10000 [00:19<00:22, 237.99it/s]Running 10000 simulations.:  48%|████▊     | 4764/10000 [00:19<00:21, 238.19it/s]Running 10000 simulations.:  48%|████▊     | 4788/10000 [00:19<00:21, 237.02it/s]Running 10000 simulations.:  48%|████▊     | 4812/10000 [00:19<00:21, 237.15it/s]Running 10000 simulations.:  48%|████▊     | 4836/10000 [00:20<00:21, 236.05it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:20<00:21, 236.88it/s]Running 10000 simulations.:  49%|████▉     | 4885/10000 [00:20<00:21, 238.38it/s]Running 10000 simulations.:  49%|████▉     | 4910/10000 [00:20<00:21, 238.88it/s]Running 10000 simulations.:  49%|████▉     | 4934/10000 [00:20<00:21, 238.67it/s]Running 10000 simulations.:  50%|████▉     | 4958/10000 [00:20<00:21, 237.92it/s]Running 10000 simulations.:  50%|████▉     | 4982/10000 [00:20<00:21, 237.73it/s]Running 10000 simulations.:  50%|█████     | 5006/10000 [00:20<00:21, 237.76it/s]Running 10000 simulations.:  50%|█████     | 5030/10000 [00:20<00:20, 237.32it/s]Running 10000 simulations.:  51%|█████     | 5054/10000 [00:20<00:20, 236.46it/s]Running 10000 simulations.:  51%|█████     | 5078/10000 [00:21<00:20, 236.88it/s]Running 10000 simulations.:  51%|█████     | 5102/10000 [00:21<00:20, 236.99it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:21<00:20, 237.28it/s]Running 10000 simulations.:  52%|█████▏    | 5150/10000 [00:21<00:20, 237.66it/s]Running 10000 simulations.:  52%|█████▏    | 5174/10000 [00:21<00:20, 237.93it/s]Running 10000 simulations.:  52%|█████▏    | 5198/10000 [00:21<00:20, 237.56it/s]Running 10000 simulations.:  52%|█████▏    | 5222/10000 [00:21<00:20, 237.57it/s]Running 10000 simulations.:  52%|█████▏    | 5246/10000 [00:21<00:20, 237.36it/s]Running 10000 simulations.:  53%|█████▎    | 5270/10000 [00:21<00:19, 237.35it/s]Running 10000 simulations.:  53%|█████▎    | 5294/10000 [00:21<00:19, 237.99it/s]Running 10000 simulations.:  53%|█████▎    | 5318/10000 [00:22<00:19, 237.82it/s]Running 10000 simulations.:  53%|█████▎    | 5342/10000 [00:22<00:19, 238.18it/s]Running 10000 simulations.:  54%|█████▎    | 5366/10000 [00:22<00:19, 237.17it/s]Running 10000 simulations.:  54%|█████▍    | 5390/10000 [00:22<00:19, 237.24it/s]Running 10000 simulations.:  54%|█████▍    | 5414/10000 [00:22<00:19, 237.28it/s]Running 10000 simulations.:  54%|█████▍    | 5438/10000 [00:22<00:19, 236.29it/s]Running 10000 simulations.:  55%|█████▍    | 5462/10000 [00:22<00:19, 236.52it/s]Running 10000 simulations.:  55%|█████▍    | 5486/10000 [00:22<00:19, 236.36it/s]Running 10000 simulations.:  55%|█████▌    | 5510/10000 [00:22<00:19, 235.32it/s]Running 10000 simulations.:  55%|█████▌    | 5534/10000 [00:22<00:18, 235.07it/s]Running 10000 simulations.:  56%|█████▌    | 5558/10000 [00:23<00:18, 234.88it/s]Running 10000 simulations.:  56%|█████▌    | 5582/10000 [00:23<00:18, 234.76it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:23<00:18, 235.27it/s]Running 10000 simulations.:  56%|█████▋    | 5630/10000 [00:23<00:18, 234.71it/s]Running 10000 simulations.:  57%|█████▋    | 5654/10000 [00:23<00:18, 235.76it/s]Running 10000 simulations.:  57%|█████▋    | 5678/10000 [00:23<00:18, 235.71it/s]Running 10000 simulations.:  57%|█████▋    | 5702/10000 [00:23<00:18, 234.49it/s]Running 10000 simulations.:  57%|█████▋    | 5726/10000 [00:23<00:18, 234.43it/s]Running 10000 simulations.:  57%|█████▊    | 5750/10000 [00:23<00:18, 234.80it/s]Running 10000 simulations.:  58%|█████▊    | 5775/10000 [00:23<00:17, 236.46it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:24<00:17, 236.65it/s]Running 10000 simulations.:  58%|█████▊    | 5823/10000 [00:24<00:17, 236.83it/s]Running 10000 simulations.:  58%|█████▊    | 5847/10000 [00:24<00:17, 236.21it/s]Running 10000 simulations.:  59%|█████▊    | 5871/10000 [00:24<00:17, 234.66it/s]Running 10000 simulations.:  59%|█████▉    | 5895/10000 [00:24<00:17, 234.34it/s]Running 10000 simulations.:  59%|█████▉    | 5919/10000 [00:24<00:17, 234.09it/s]Running 10000 simulations.:  59%|█████▉    | 5943/10000 [00:24<00:17, 233.78it/s]Running 10000 simulations.:  60%|█████▉    | 5967/10000 [00:24<00:17, 234.01it/s]Running 10000 simulations.:  60%|█████▉    | 5991/10000 [00:24<00:17, 234.10it/s]Running 10000 simulations.:  60%|██████    | 6015/10000 [00:25<00:17, 233.66it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:25<00:16, 234.97it/s]Running 10000 simulations.:  61%|██████    | 6063/10000 [00:25<00:16, 235.66it/s]Running 10000 simulations.:  61%|██████    | 6087/10000 [00:25<00:16, 236.10it/s]Running 10000 simulations.:  61%|██████    | 6111/10000 [00:25<00:16, 235.74it/s]Running 10000 simulations.:  61%|██████▏   | 6135/10000 [00:25<00:16, 235.69it/s]Running 10000 simulations.:  62%|██████▏   | 6159/10000 [00:25<00:16, 236.46it/s]Running 10000 simulations.:  62%|██████▏   | 6183/10000 [00:25<00:16, 236.72it/s]Running 10000 simulations.:  62%|██████▏   | 6208/10000 [00:25<00:15, 238.42it/s]Running 10000 simulations.:  62%|██████▏   | 6233/10000 [00:25<00:15, 239.81it/s]Running 10000 simulations.:  63%|██████▎   | 6258/10000 [00:26<00:15, 241.34it/s]Running 10000 simulations.:  63%|██████▎   | 6283/10000 [00:26<00:15, 242.00it/s]Running 10000 simulations.:  63%|██████▎   | 6308/10000 [00:26<00:15, 242.09it/s]Running 10000 simulations.:  63%|██████▎   | 6333/10000 [00:26<00:15, 241.63it/s]Running 10000 simulations.:  64%|██████▎   | 6358/10000 [00:26<00:15, 242.52it/s]Running 10000 simulations.:  64%|██████▍   | 6383/10000 [00:26<00:14, 243.54it/s]Running 10000 simulations.:  64%|██████▍   | 6408/10000 [00:26<00:14, 244.09it/s]Running 10000 simulations.:  64%|██████▍   | 6433/10000 [00:26<00:14, 245.17it/s]Running 10000 simulations.:  65%|██████▍   | 6458/10000 [00:26<00:14, 245.78it/s]Running 10000 simulations.:  65%|██████▍   | 6483/10000 [00:26<00:14, 245.76it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:27<00:14, 234.43it/s]Running 10000 simulations.:  65%|██████▌   | 6532/10000 [00:27<00:15, 227.80it/s]Running 10000 simulations.:  66%|██████▌   | 6555/10000 [00:27<00:15, 220.46it/s]Running 10000 simulations.:  66%|██████▌   | 6578/10000 [00:27<00:16, 211.36it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:27<00:16, 211.65it/s]Running 10000 simulations.:  66%|██████▌   | 6622/10000 [00:27<00:16, 210.01it/s]Running 10000 simulations.:  66%|██████▋   | 6644/10000 [00:27<00:16, 208.68it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:27<00:16, 208.27it/s]Running 10000 simulations.:  67%|██████▋   | 6686/10000 [00:27<00:15, 207.71it/s]Running 10000 simulations.:  67%|██████▋   | 6707/10000 [00:28<00:15, 207.07it/s]Running 10000 simulations.:  67%|██████▋   | 6728/10000 [00:28<00:15, 207.44it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:28<00:15, 208.35it/s]Running 10000 simulations.:  68%|██████▊   | 6771/10000 [00:28<00:15, 208.46it/s]Running 10000 simulations.:  68%|██████▊   | 6792/10000 [00:28<00:15, 208.53it/s]Running 10000 simulations.:  68%|██████▊   | 6814/10000 [00:28<00:15, 209.78it/s]Running 10000 simulations.:  68%|██████▊   | 6836/10000 [00:28<00:15, 210.90it/s]Running 10000 simulations.:  69%|██████▊   | 6858/10000 [00:28<00:14, 210.39it/s]Running 10000 simulations.:  69%|██████▉   | 6880/10000 [00:28<00:14, 211.03it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:28<00:14, 212.29it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:29<00:14, 210.65it/s]Running 10000 simulations.:  69%|██████▉   | 6946/10000 [00:29<00:14, 212.14it/s]Running 10000 simulations.:  70%|██████▉   | 6968/10000 [00:29<00:14, 209.93it/s]Running 10000 simulations.:  70%|██████▉   | 6990/10000 [00:29<00:14, 208.29it/s]Running 10000 simulations.:  70%|███████   | 7011/10000 [00:29<00:14, 207.50it/s]Running 10000 simulations.:  70%|███████   | 7033/10000 [00:29<00:14, 208.68it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:29<00:13, 213.50it/s]Running 10000 simulations.:  71%|███████   | 7079/10000 [00:29<00:13, 217.17it/s]Running 10000 simulations.:  71%|███████   | 7102/10000 [00:29<00:13, 219.56it/s]Running 10000 simulations.:  71%|███████▏  | 7125/10000 [00:29<00:12, 221.77it/s]Running 10000 simulations.:  71%|███████▏  | 7148/10000 [00:30<00:12, 222.42it/s]Running 10000 simulations.:  72%|███████▏  | 7171/10000 [00:30<00:12, 223.21it/s]Running 10000 simulations.:  72%|███████▏  | 7194/10000 [00:30<00:12, 223.18it/s]Running 10000 simulations.:  72%|███████▏  | 7217/10000 [00:30<00:12, 223.89it/s]Running 10000 simulations.:  72%|███████▏  | 7240/10000 [00:30<00:12, 224.43it/s]Running 10000 simulations.:  73%|███████▎  | 7263/10000 [00:30<00:12, 224.54it/s]Running 10000 simulations.:  73%|███████▎  | 7286/10000 [00:30<00:12, 225.10it/s]Running 10000 simulations.:  73%|███████▎  | 7309/10000 [00:30<00:11, 225.33it/s]Running 10000 simulations.:  73%|███████▎  | 7332/10000 [00:30<00:11, 225.66it/s]Running 10000 simulations.:  74%|███████▎  | 7355/10000 [00:31<00:11, 225.24it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:31<00:11, 225.25it/s]Running 10000 simulations.:  74%|███████▍  | 7401/10000 [00:31<00:11, 225.39it/s]Running 10000 simulations.:  74%|███████▍  | 7424/10000 [00:31<00:11, 225.58it/s]Running 10000 simulations.:  74%|███████▍  | 7447/10000 [00:31<00:11, 225.54it/s]Running 10000 simulations.:  75%|███████▍  | 7470/10000 [00:31<00:11, 225.96it/s]Running 10000 simulations.:  75%|███████▍  | 7493/10000 [00:31<00:11, 225.85it/s]Running 10000 simulations.:  75%|███████▌  | 7516/10000 [00:31<00:11, 225.58it/s]Running 10000 simulations.:  75%|███████▌  | 7539/10000 [00:31<00:10, 225.43it/s]Running 10000 simulations.:  76%|███████▌  | 7562/10000 [00:31<00:10, 223.43it/s]Running 10000 simulations.:  76%|███████▌  | 7585/10000 [00:32<00:10, 224.56it/s]Running 10000 simulations.:  76%|███████▌  | 7608/10000 [00:32<00:10, 225.51it/s]Running 10000 simulations.:  76%|███████▋  | 7631/10000 [00:32<00:10, 225.98it/s]Running 10000 simulations.:  77%|███████▋  | 7654/10000 [00:32<00:10, 226.30it/s]Running 10000 simulations.:  77%|███████▋  | 7677/10000 [00:32<00:10, 225.88it/s]Running 10000 simulations.:  77%|███████▋  | 7700/10000 [00:32<00:10, 225.94it/s]Running 10000 simulations.:  77%|███████▋  | 7723/10000 [00:32<00:10, 225.87it/s]Running 10000 simulations.:  77%|███████▋  | 7746/10000 [00:32<00:09, 225.77it/s]Running 10000 simulations.:  78%|███████▊  | 7769/10000 [00:32<00:09, 226.03it/s]Running 10000 simulations.:  78%|███████▊  | 7792/10000 [00:32<00:09, 225.82it/s]Running 10000 simulations.:  78%|███████▊  | 7815/10000 [00:33<00:09, 222.89it/s]Running 10000 simulations.:  78%|███████▊  | 7838/10000 [00:33<00:09, 222.56it/s]Running 10000 simulations.:  79%|███████▊  | 7861/10000 [00:33<00:09, 223.30it/s]Running 10000 simulations.:  79%|███████▉  | 7884/10000 [00:33<00:09, 223.84it/s]Running 10000 simulations.:  79%|███████▉  | 7907/10000 [00:33<00:09, 224.64it/s]Running 10000 simulations.:  79%|███████▉  | 7930/10000 [00:33<00:09, 224.55it/s]Running 10000 simulations.:  80%|███████▉  | 7953/10000 [00:33<00:09, 224.60it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:33<00:08, 224.90it/s]Running 10000 simulations.:  80%|███████▉  | 7999/10000 [00:33<00:08, 224.87it/s]Running 10000 simulations.:  80%|████████  | 8022/10000 [00:33<00:08, 224.60it/s]Running 10000 simulations.:  80%|████████  | 8045/10000 [00:34<00:08, 224.62it/s]Running 10000 simulations.:  81%|████████  | 8068/10000 [00:34<00:08, 224.91it/s]Running 10000 simulations.:  81%|████████  | 8091/10000 [00:34<00:08, 225.11it/s]Running 10000 simulations.:  81%|████████  | 8114/10000 [00:34<00:08, 225.38it/s]Running 10000 simulations.:  81%|████████▏ | 8137/10000 [00:34<00:08, 225.46it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:34<00:08, 225.38it/s]Running 10000 simulations.:  82%|████████▏ | 8183/10000 [00:34<00:08, 224.55it/s]Running 10000 simulations.:  82%|████████▏ | 8206/10000 [00:34<00:08, 223.43it/s]Running 10000 simulations.:  82%|████████▏ | 8229/10000 [00:34<00:07, 222.86it/s]Running 10000 simulations.:  83%|████████▎ | 8252/10000 [00:35<00:11, 154.23it/s]Running 10000 simulations.:  83%|████████▎ | 8274/10000 [00:35<00:10, 169.28it/s]Running 10000 simulations.:  83%|████████▎ | 8297/10000 [00:35<00:09, 182.07it/s]Running 10000 simulations.:  83%|████████▎ | 8319/10000 [00:35<00:08, 191.72it/s]Running 10000 simulations.:  83%|████████▎ | 8341/10000 [00:35<00:08, 199.05it/s]Running 10000 simulations.:  84%|████████▎ | 8363/10000 [00:35<00:08, 204.21it/s]Running 10000 simulations.:  84%|████████▍ | 8385/10000 [00:35<00:07, 208.06it/s]Running 10000 simulations.:  84%|████████▍ | 8407/10000 [00:35<00:07, 211.16it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:35<00:07, 213.88it/s]Running 10000 simulations.:  85%|████████▍ | 8453/10000 [00:36<00:07, 216.16it/s]Running 10000 simulations.:  85%|████████▍ | 8476/10000 [00:36<00:07, 217.57it/s]Running 10000 simulations.:  85%|████████▍ | 8498/10000 [00:36<00:06, 218.24it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:36<00:06, 218.29it/s]Running 10000 simulations.:  85%|████████▌ | 8542/10000 [00:36<00:06, 218.57it/s]Running 10000 simulations.:  86%|████████▌ | 8564/10000 [00:36<00:06, 218.21it/s]Running 10000 simulations.:  86%|████████▌ | 8586/10000 [00:36<00:06, 218.00it/s]Running 10000 simulations.:  86%|████████▌ | 8608/10000 [00:36<00:06, 218.33it/s]Running 10000 simulations.:  86%|████████▋ | 8631/10000 [00:36<00:06, 219.19it/s]Running 10000 simulations.:  87%|████████▋ | 8653/10000 [00:36<00:06, 219.16it/s]Running 10000 simulations.:  87%|████████▋ | 8675/10000 [00:37<00:06, 219.02it/s]Running 10000 simulations.:  87%|████████▋ | 8697/10000 [00:37<00:05, 218.98it/s]Running 10000 simulations.:  87%|████████▋ | 8719/10000 [00:37<00:05, 219.14it/s]Running 10000 simulations.:  87%|████████▋ | 8742/10000 [00:37<00:05, 219.43it/s]Running 10000 simulations.:  88%|████████▊ | 8764/10000 [00:37<00:05, 219.45it/s]Running 10000 simulations.:  88%|████████▊ | 8786/10000 [00:37<00:05, 219.18it/s]Running 10000 simulations.:  88%|████████▊ | 8808/10000 [00:37<00:05, 218.99it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [00:37<00:05, 218.86it/s]Running 10000 simulations.:  89%|████████▊ | 8852/10000 [00:37<00:05, 218.77it/s]Running 10000 simulations.:  89%|████████▊ | 8874/10000 [00:38<00:05, 218.98it/s]Running 10000 simulations.:  89%|████████▉ | 8896/10000 [00:38<00:05, 218.74it/s]Running 10000 simulations.:  89%|████████▉ | 8918/10000 [00:38<00:04, 218.62it/s]Running 10000 simulations.:  89%|████████▉ | 8940/10000 [00:38<00:04, 218.84it/s]Running 10000 simulations.:  90%|████████▉ | 8962/10000 [00:38<00:04, 218.42it/s]Running 10000 simulations.:  90%|████████▉ | 8984/10000 [00:38<00:04, 218.83it/s]Running 10000 simulations.:  90%|█████████ | 9006/10000 [00:38<00:04, 218.85it/s]Running 10000 simulations.:  90%|█████████ | 9028/10000 [00:38<00:04, 218.64it/s]Running 10000 simulations.:  90%|█████████ | 9050/10000 [00:38<00:04, 218.15it/s]Running 10000 simulations.:  91%|█████████ | 9072/10000 [00:38<00:04, 218.37it/s]Running 10000 simulations.:  91%|█████████ | 9094/10000 [00:39<00:04, 218.47it/s]Running 10000 simulations.:  91%|█████████ | 9116/10000 [00:39<00:04, 218.32it/s]Running 10000 simulations.:  91%|█████████▏| 9138/10000 [00:39<00:03, 217.70it/s]Running 10000 simulations.:  92%|█████████▏| 9160/10000 [00:39<00:03, 218.02it/s]Running 10000 simulations.:  92%|█████████▏| 9182/10000 [00:39<00:03, 217.99it/s]Running 10000 simulations.:  92%|█████████▏| 9204/10000 [00:39<00:03, 217.95it/s]Running 10000 simulations.:  92%|█████████▏| 9227/10000 [00:39<00:03, 219.95it/s]Running 10000 simulations.:  93%|█████████▎| 9252/10000 [00:39<00:03, 227.64it/s]Running 10000 simulations.:  93%|█████████▎| 9277/10000 [00:39<00:03, 233.03it/s]Running 10000 simulations.:  93%|█████████▎| 9302/10000 [00:39<00:02, 236.72it/s]Running 10000 simulations.:  93%|█████████▎| 9327/10000 [00:40<00:02, 238.74it/s]Running 10000 simulations.:  94%|█████████▎| 9352/10000 [00:40<00:02, 239.10it/s]Running 10000 simulations.:  94%|█████████▍| 9377/10000 [00:40<00:02, 239.85it/s]Running 10000 simulations.:  94%|█████████▍| 9402/10000 [00:40<00:02, 240.64it/s]Running 10000 simulations.:  94%|█████████▍| 9427/10000 [00:40<00:02, 241.76it/s]Running 10000 simulations.:  95%|█████████▍| 9452/10000 [00:40<00:02, 242.67it/s]Running 10000 simulations.:  95%|█████████▍| 9477/10000 [00:40<00:02, 241.34it/s]Running 10000 simulations.:  95%|█████████▌| 9502/10000 [00:40<00:02, 242.51it/s]Running 10000 simulations.:  95%|█████████▌| 9527/10000 [00:40<00:01, 240.70it/s]Running 10000 simulations.:  96%|█████████▌| 9552/10000 [00:40<00:01, 238.93it/s]Running 10000 simulations.:  96%|█████████▌| 9577/10000 [00:41<00:01, 241.30it/s]Running 10000 simulations.:  96%|█████████▌| 9602/10000 [00:41<00:01, 243.18it/s]Running 10000 simulations.:  96%|█████████▋| 9627/10000 [00:41<00:01, 244.28it/s]Running 10000 simulations.:  97%|█████████▋| 9653/10000 [00:41<00:01, 245.66it/s]Running 10000 simulations.:  97%|█████████▋| 9678/10000 [00:41<00:01, 242.30it/s]Running 10000 simulations.:  97%|█████████▋| 9703/10000 [00:41<00:01, 243.04it/s]Running 10000 simulations.:  97%|█████████▋| 9728/10000 [00:41<00:01, 237.63it/s]Running 10000 simulations.:  98%|█████████▊| 9752/10000 [00:41<00:01, 234.29it/s]Running 10000 simulations.:  98%|█████████▊| 9776/10000 [00:41<00:00, 231.85it/s]Running 10000 simulations.:  98%|█████████▊| 9800/10000 [00:42<00:00, 230.56it/s]Running 10000 simulations.:  98%|█████████▊| 9824/10000 [00:42<00:00, 229.75it/s]Running 10000 simulations.:  98%|█████████▊| 9847/10000 [00:42<00:00, 229.17it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [00:42<00:00, 228.89it/s]Running 10000 simulations.:  99%|█████████▉| 9893/10000 [00:42<00:00, 228.65it/s]Running 10000 simulations.:  99%|█████████▉| 9916/10000 [00:42<00:00, 229.03it/s]Running 10000 simulations.:  99%|█████████▉| 9939/10000 [00:42<00:00, 229.31it/s]Running 10000 simulations.: 100%|█████████▉| 9962/10000 [00:42<00:00, 229.08it/s]Running 10000 simulations.: 100%|█████████▉| 9985/10000 [00:42<00:00, 228.54it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 233.21it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:41, 241.49it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:41, 242.05it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:40, 242.16it/s]Running 10000 simulations.:   1%|          | 100/10000 [00:00<00:40, 242.68it/s]Running 10000 simulations.:   1%|▏         | 125/10000 [00:00<00:40, 242.90it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:40, 243.01it/s]Running 10000 simulations.:   2%|▏         | 175/10000 [00:00<00:40, 242.29it/s]Running 10000 simulations.:   2%|▏         | 200/10000 [00:00<00:40, 242.44it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:00<00:40, 241.30it/s]Running 10000 simulations.:   2%|▏         | 248/10000 [00:01<00:40, 240.34it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<00:40, 238.38it/s]Running 10000 simulations.:   3%|▎         | 296/10000 [00:01<00:40, 237.38it/s]Running 10000 simulations.:   3%|▎         | 320/10000 [00:01<00:40, 237.27it/s]Running 10000 simulations.:   3%|▎         | 344/10000 [00:01<00:40, 237.25it/s]Running 10000 simulations.:   4%|▎         | 368/10000 [00:01<00:40, 236.78it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:01<00:40, 236.54it/s]Running 10000 simulations.:   4%|▍         | 416/10000 [00:01<00:40, 236.14it/s]Running 10000 simulations.:   4%|▍         | 440/10000 [00:01<00:40, 235.39it/s]Running 10000 simulations.:   5%|▍         | 464/10000 [00:01<00:40, 234.95it/s]Running 10000 simulations.:   5%|▍         | 488/10000 [00:02<00:40, 234.94it/s]Running 10000 simulations.:   5%|▌         | 512/10000 [00:02<00:40, 234.88it/s]Running 10000 simulations.:   5%|▌         | 536/10000 [00:02<00:40, 235.01it/s]Running 10000 simulations.:   6%|▌         | 560/10000 [00:02<00:40, 234.75it/s]Running 10000 simulations.:   6%|▌         | 584/10000 [00:02<00:40, 234.51it/s]Running 10000 simulations.:   6%|▌         | 608/10000 [00:02<00:40, 234.41it/s]Running 10000 simulations.:   6%|▋         | 632/10000 [00:02<00:40, 233.71it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:02<00:39, 233.88it/s]Running 10000 simulations.:   7%|▋         | 680/10000 [00:02<00:39, 234.01it/s]Running 10000 simulations.:   7%|▋         | 704/10000 [00:02<00:39, 234.12it/s]Running 10000 simulations.:   7%|▋         | 728/10000 [00:03<00:39, 233.68it/s]Running 10000 simulations.:   8%|▊         | 752/10000 [00:03<00:41, 224.22it/s]Running 10000 simulations.:   8%|▊         | 776/10000 [00:03<00:40, 226.82it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:03<00:40, 228.30it/s]Running 10000 simulations.:   8%|▊         | 824/10000 [00:03<00:40, 229.06it/s]Running 10000 simulations.:   8%|▊         | 848/10000 [00:03<00:39, 229.80it/s]Running 10000 simulations.:   9%|▊         | 872/10000 [00:03<00:39, 230.26it/s]Running 10000 simulations.:   9%|▉         | 896/10000 [00:03<00:39, 230.63it/s]Running 10000 simulations.:   9%|▉         | 920/10000 [00:03<00:39, 231.26it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:04<00:39, 231.78it/s]Running 10000 simulations.:  10%|▉         | 968/10000 [00:04<00:38, 231.70it/s]Running 10000 simulations.:  10%|▉         | 992/10000 [00:04<00:38, 231.98it/s]Running 10000 simulations.:  10%|█         | 1016/10000 [00:04<00:38, 232.73it/s]Running 10000 simulations.:  10%|█         | 1040/10000 [00:04<00:38, 233.66it/s]Running 10000 simulations.:  11%|█         | 1064/10000 [00:04<00:38, 233.56it/s]Running 10000 simulations.:  11%|█         | 1088/10000 [00:04<00:38, 233.30it/s]Running 10000 simulations.:  11%|█         | 1112/10000 [00:04<00:38, 232.75it/s]Running 10000 simulations.:  11%|█▏        | 1136/10000 [00:04<00:38, 232.20it/s]Running 10000 simulations.:  12%|█▏        | 1160/10000 [00:04<00:38, 231.81it/s]Running 10000 simulations.:  12%|█▏        | 1184/10000 [00:05<00:38, 231.76it/s]Running 10000 simulations.:  12%|█▏        | 1208/10000 [00:05<00:37, 232.08it/s]Running 10000 simulations.:  12%|█▏        | 1232/10000 [00:05<00:37, 232.05it/s]Running 10000 simulations.:  13%|█▎        | 1256/10000 [00:05<00:37, 231.88it/s]Running 10000 simulations.:  13%|█▎        | 1280/10000 [00:05<00:37, 231.59it/s]Running 10000 simulations.:  13%|█▎        | 1304/10000 [00:05<00:37, 231.52it/s]Running 10000 simulations.:  13%|█▎        | 1328/10000 [00:05<00:37, 232.46it/s]Running 10000 simulations.:  14%|█▎        | 1352/10000 [00:05<00:37, 233.05it/s]Running 10000 simulations.:  14%|█▍        | 1376/10000 [00:05<00:37, 232.72it/s]Running 10000 simulations.:  14%|█▍        | 1400/10000 [00:05<00:36, 232.84it/s]Running 10000 simulations.:  14%|█▍        | 1424/10000 [00:06<00:36, 232.92it/s]Running 10000 simulations.:  14%|█▍        | 1448/10000 [00:06<00:36, 233.75it/s]Running 10000 simulations.:  15%|█▍        | 1472/10000 [00:06<00:36, 233.87it/s]Running 10000 simulations.:  15%|█▍        | 1496/10000 [00:06<00:36, 234.18it/s]Running 10000 simulations.:  15%|█▌        | 1520/10000 [00:06<00:36, 234.26it/s]Running 10000 simulations.:  15%|█▌        | 1544/10000 [00:06<00:35, 234.94it/s]Running 10000 simulations.:  16%|█▌        | 1568/10000 [00:06<00:35, 234.63it/s]Running 10000 simulations.:  16%|█▌        | 1592/10000 [00:06<00:35, 234.33it/s]Running 10000 simulations.:  16%|█▌        | 1616/10000 [00:06<00:35, 234.31it/s]Running 10000 simulations.:  16%|█▋        | 1640/10000 [00:07<00:35, 234.42it/s]Running 10000 simulations.:  17%|█▋        | 1664/10000 [00:07<00:35, 234.07it/s]Running 10000 simulations.:  17%|█▋        | 1688/10000 [00:07<00:35, 233.23it/s]Running 10000 simulations.:  17%|█▋        | 1712/10000 [00:07<00:35, 232.30it/s]Running 10000 simulations.:  17%|█▋        | 1736/10000 [00:07<00:35, 232.23it/s]Running 10000 simulations.:  18%|█▊        | 1760/10000 [00:07<00:35, 232.05it/s]Running 10000 simulations.:  18%|█▊        | 1784/10000 [00:07<00:35, 232.13it/s]Running 10000 simulations.:  18%|█▊        | 1808/10000 [00:07<00:35, 231.75it/s]Running 10000 simulations.:  18%|█▊        | 1832/10000 [00:07<00:35, 231.82it/s]Running 10000 simulations.:  19%|█▊        | 1856/10000 [00:07<00:35, 231.88it/s]Running 10000 simulations.:  19%|█▉        | 1880/10000 [00:08<00:34, 232.20it/s]Running 10000 simulations.:  19%|█▉        | 1904/10000 [00:08<00:34, 232.72it/s]Running 10000 simulations.:  19%|█▉        | 1928/10000 [00:08<00:34, 234.05it/s]Running 10000 simulations.:  20%|█▉        | 1952/10000 [00:08<00:34, 234.99it/s]Running 10000 simulations.:  20%|█▉        | 1976/10000 [00:08<00:34, 234.30it/s]Running 10000 simulations.:  20%|██        | 2000/10000 [00:08<00:34, 233.36it/s]Running 10000 simulations.:  20%|██        | 2024/10000 [00:08<00:34, 232.43it/s]Running 10000 simulations.:  20%|██        | 2048/10000 [00:08<00:34, 232.52it/s]Running 10000 simulations.:  21%|██        | 2072/10000 [00:08<00:34, 232.41it/s]Running 10000 simulations.:  21%|██        | 2096/10000 [00:08<00:33, 232.71it/s]Running 10000 simulations.:  21%|██        | 2120/10000 [00:09<00:33, 232.51it/s]Running 10000 simulations.:  21%|██▏       | 2144/10000 [00:09<00:33, 232.33it/s]Running 10000 simulations.:  22%|██▏       | 2168/10000 [00:09<00:33, 231.93it/s]Running 10000 simulations.:  22%|██▏       | 2192/10000 [00:09<00:33, 232.35it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:09<00:33, 231.71it/s]Running 10000 simulations.:  22%|██▏       | 2240/10000 [00:09<00:33, 231.74it/s]Running 10000 simulations.:  23%|██▎       | 2264/10000 [00:09<00:33, 230.81it/s]Running 10000 simulations.:  23%|██▎       | 2288/10000 [00:09<00:33, 231.33it/s]Running 10000 simulations.:  23%|██▎       | 2312/10000 [00:09<00:33, 231.60it/s]Running 10000 simulations.:  23%|██▎       | 2336/10000 [00:09<00:32, 232.52it/s]Running 10000 simulations.:  24%|██▎       | 2360/10000 [00:10<00:32, 233.37it/s]Running 10000 simulations.:  24%|██▍       | 2384/10000 [00:10<00:32, 233.27it/s]Running 10000 simulations.:  24%|██▍       | 2408/10000 [00:10<00:32, 233.42it/s]Running 10000 simulations.:  24%|██▍       | 2433/10000 [00:10<00:32, 236.41it/s]Running 10000 simulations.:  25%|██▍       | 2458/10000 [00:10<00:31, 239.10it/s]Running 10000 simulations.:  25%|██▍       | 2483/10000 [00:10<00:31, 240.14it/s]Running 10000 simulations.:  25%|██▌       | 2508/10000 [00:10<00:31, 241.67it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:10<00:30, 241.94it/s]Running 10000 simulations.:  26%|██▌       | 2558/10000 [00:10<00:30, 243.04it/s]Running 10000 simulations.:  26%|██▌       | 2583/10000 [00:11<00:30, 243.60it/s]Running 10000 simulations.:  26%|██▌       | 2608/10000 [00:11<00:30, 242.75it/s]Running 10000 simulations.:  26%|██▋       | 2633/10000 [00:11<00:30, 243.63it/s]Running 10000 simulations.:  27%|██▋       | 2658/10000 [00:11<00:30, 243.65it/s]Running 10000 simulations.:  27%|██▋       | 2683/10000 [00:11<00:29, 244.92it/s]Running 10000 simulations.:  27%|██▋       | 2708/10000 [00:11<00:30, 238.07it/s]Running 10000 simulations.:  27%|██▋       | 2732/10000 [00:11<00:32, 227.08it/s]Running 10000 simulations.:  28%|██▊       | 2755/10000 [00:11<00:32, 222.60it/s]Running 10000 simulations.:  28%|██▊       | 2778/10000 [00:11<00:33, 218.66it/s]Running 10000 simulations.:  28%|██▊       | 2800/10000 [00:11<00:33, 217.73it/s]Running 10000 simulations.:  28%|██▊       | 2822/10000 [00:12<00:33, 214.14it/s]Running 10000 simulations.:  28%|██▊       | 2844/10000 [00:12<00:33, 211.01it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:12<00:34, 208.96it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:12<00:34, 207.40it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:12<00:34, 206.26it/s]Running 10000 simulations.:  29%|██▉       | 2929/10000 [00:12<00:34, 205.89it/s]Running 10000 simulations.:  30%|██▉       | 2950/10000 [00:12<00:34, 206.36it/s]Running 10000 simulations.:  30%|██▉       | 2971/10000 [00:12<00:34, 206.61it/s]Running 10000 simulations.:  30%|██▉       | 2992/10000 [00:12<00:33, 206.89it/s]Running 10000 simulations.:  30%|███       | 3013/10000 [00:13<00:33, 206.63it/s]Running 10000 simulations.:  30%|███       | 3035/10000 [00:13<00:33, 208.29it/s]Running 10000 simulations.:  31%|███       | 3057/10000 [00:13<00:33, 209.88it/s]Running 10000 simulations.:  31%|███       | 3078/10000 [00:13<00:33, 209.43it/s]Running 10000 simulations.:  31%|███       | 3100/10000 [00:13<00:32, 210.55it/s]Running 10000 simulations.:  31%|███       | 3122/10000 [00:13<00:32, 211.79it/s]Running 10000 simulations.:  31%|███▏      | 3144/10000 [00:13<00:32, 210.39it/s]Running 10000 simulations.:  32%|███▏      | 3166/10000 [00:13<00:32, 210.91it/s]Running 10000 simulations.:  32%|███▏      | 3188/10000 [00:13<00:32, 209.40it/s]Running 10000 simulations.:  32%|███▏      | 3209/10000 [00:13<00:32, 208.68it/s]Running 10000 simulations.:  32%|███▏      | 3230/10000 [00:14<00:32, 208.39it/s]Running 10000 simulations.:  33%|███▎      | 3252/10000 [00:14<00:32, 209.27it/s]Running 10000 simulations.:  33%|███▎      | 3275/10000 [00:14<00:31, 213.25it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:14<00:30, 216.39it/s]Running 10000 simulations.:  33%|███▎      | 3321/10000 [00:14<00:30, 218.83it/s]Running 10000 simulations.:  33%|███▎      | 3343/10000 [00:14<00:30, 219.16it/s]Running 10000 simulations.:  34%|███▎      | 3366/10000 [00:14<00:30, 220.34it/s]Running 10000 simulations.:  34%|███▍      | 3389/10000 [00:14<00:29, 221.88it/s]Running 10000 simulations.:  34%|███▍      | 3412/10000 [00:14<00:29, 223.34it/s]Running 10000 simulations.:  34%|███▍      | 3435/10000 [00:14<00:29, 223.85it/s]Running 10000 simulations.:  35%|███▍      | 3458/10000 [00:15<00:29, 224.34it/s]Running 10000 simulations.:  35%|███▍      | 3481/10000 [00:15<00:29, 224.47it/s]Running 10000 simulations.:  35%|███▌      | 3504/10000 [00:15<00:28, 224.34it/s]Running 10000 simulations.:  35%|███▌      | 3527/10000 [00:15<00:28, 224.39it/s]Running 10000 simulations.:  36%|███▌      | 3550/10000 [00:15<00:28, 224.29it/s]Running 10000 simulations.:  36%|███▌      | 3573/10000 [00:15<00:28, 224.49it/s]Running 10000 simulations.:  36%|███▌      | 3596/10000 [00:15<00:28, 224.91it/s]Running 10000 simulations.:  36%|███▌      | 3619/10000 [00:15<00:28, 225.26it/s]Running 10000 simulations.:  36%|███▋      | 3642/10000 [00:15<00:28, 224.57it/s]Running 10000 simulations.:  37%|███▋      | 3665/10000 [00:15<00:28, 224.97it/s]Running 10000 simulations.:  37%|███▋      | 3688/10000 [00:16<00:28, 225.23it/s]Running 10000 simulations.:  37%|███▋      | 3711/10000 [00:16<00:28, 224.60it/s]Running 10000 simulations.:  37%|███▋      | 3734/10000 [00:16<00:27, 224.71it/s]Running 10000 simulations.:  38%|███▊      | 3757/10000 [00:16<00:27, 224.21it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:16<00:27, 223.93it/s]Running 10000 simulations.:  38%|███▊      | 3803/10000 [00:16<00:27, 224.17it/s]Running 10000 simulations.:  38%|███▊      | 3826/10000 [00:16<00:27, 224.17it/s]Running 10000 simulations.:  38%|███▊      | 3849/10000 [00:16<00:27, 223.90it/s]Running 10000 simulations.:  39%|███▊      | 3872/10000 [00:16<00:27, 223.74it/s]Running 10000 simulations.:  39%|███▉      | 3895/10000 [00:17<00:27, 223.18it/s]Running 10000 simulations.:  39%|███▉      | 3918/10000 [00:17<00:27, 222.97it/s]Running 10000 simulations.:  39%|███▉      | 3941/10000 [00:17<00:27, 222.94it/s]Running 10000 simulations.:  40%|███▉      | 3964/10000 [00:17<00:27, 223.05it/s]Running 10000 simulations.:  40%|███▉      | 3987/10000 [00:17<00:26, 223.17it/s]Running 10000 simulations.:  40%|████      | 4010/10000 [00:17<00:26, 222.74it/s]Running 10000 simulations.:  40%|████      | 4033/10000 [00:17<00:26, 222.55it/s]Running 10000 simulations.:  41%|████      | 4056/10000 [00:17<00:26, 222.51it/s]Running 10000 simulations.:  41%|████      | 4079/10000 [00:17<00:26, 222.82it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:17<00:26, 223.18it/s]Running 10000 simulations.:  41%|████▏     | 4125/10000 [00:18<00:26, 222.99it/s]Running 10000 simulations.:  41%|████▏     | 4148/10000 [00:18<00:26, 222.80it/s]Running 10000 simulations.:  42%|████▏     | 4171/10000 [00:18<00:26, 222.09it/s]Running 10000 simulations.:  42%|████▏     | 4194/10000 [00:18<00:26, 221.71it/s]Running 10000 simulations.:  42%|████▏     | 4217/10000 [00:18<00:26, 221.88it/s]Running 10000 simulations.:  42%|████▏     | 4240/10000 [00:18<00:25, 222.30it/s]Running 10000 simulations.:  43%|████▎     | 4263/10000 [00:18<00:25, 222.27it/s]Running 10000 simulations.:  43%|████▎     | 4286/10000 [00:18<00:25, 222.50it/s]Running 10000 simulations.:  43%|████▎     | 4309/10000 [00:18<00:25, 222.52it/s]Running 10000 simulations.:  43%|████▎     | 4332/10000 [00:18<00:25, 222.74it/s]Running 10000 simulations.:  44%|████▎     | 4355/10000 [00:19<00:25, 222.36it/s]Running 10000 simulations.:  44%|████▍     | 4378/10000 [00:19<00:25, 222.64it/s]Running 10000 simulations.:  44%|████▍     | 4401/10000 [00:19<00:25, 222.89it/s]Running 10000 simulations.:  44%|████▍     | 4424/10000 [00:19<00:25, 222.93it/s]Running 10000 simulations.:  44%|████▍     | 4447/10000 [00:19<00:24, 223.25it/s]Running 10000 simulations.:  45%|████▍     | 4470/10000 [00:19<00:24, 223.36it/s]Running 10000 simulations.:  45%|████▍     | 4493/10000 [00:19<00:24, 222.74it/s]Running 10000 simulations.:  45%|████▌     | 4516/10000 [00:19<00:24, 222.76it/s]Running 10000 simulations.:  45%|████▌     | 4539/10000 [00:19<00:24, 223.03it/s]Running 10000 simulations.:  46%|████▌     | 4562/10000 [00:20<00:24, 222.48it/s]Running 10000 simulations.:  46%|████▌     | 4585/10000 [00:20<00:24, 222.50it/s]Running 10000 simulations.:  46%|████▌     | 4608/10000 [00:20<00:24, 222.55it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:20<00:24, 222.85it/s]Running 10000 simulations.:  47%|████▋     | 4654/10000 [00:20<00:23, 223.11it/s]Running 10000 simulations.:  47%|████▋     | 4677/10000 [00:20<00:23, 222.98it/s]Running 10000 simulations.:  47%|████▋     | 4700/10000 [00:20<00:23, 222.63it/s]Running 10000 simulations.:  47%|████▋     | 4723/10000 [00:20<00:23, 222.74it/s]Running 10000 simulations.:  47%|████▋     | 4746/10000 [00:20<00:23, 222.44it/s]Running 10000 simulations.:  48%|████▊     | 4769/10000 [00:20<00:23, 222.08it/s]Running 10000 simulations.:  48%|████▊     | 4792/10000 [00:21<00:23, 222.11it/s]Running 10000 simulations.:  48%|████▊     | 4815/10000 [00:21<00:23, 221.50it/s]Running 10000 simulations.:  48%|████▊     | 4838/10000 [00:21<00:23, 221.91it/s]Running 10000 simulations.:  49%|████▊     | 4861/10000 [00:21<00:23, 222.54it/s]Running 10000 simulations.:  49%|████▉     | 4884/10000 [00:21<00:22, 222.95it/s]Running 10000 simulations.:  49%|████▉     | 4907/10000 [00:21<00:22, 223.76it/s]Running 10000 simulations.:  49%|████▉     | 4930/10000 [00:21<00:22, 224.22it/s]Running 10000 simulations.:  50%|████▉     | 4953/10000 [00:21<00:22, 224.54it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:21<00:22, 224.31it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:21<00:22, 224.15it/s]Running 10000 simulations.:  50%|█████     | 5022/10000 [00:22<00:22, 224.72it/s]Running 10000 simulations.:  50%|█████     | 5045/10000 [00:22<00:21, 225.40it/s]Running 10000 simulations.:  51%|█████     | 5068/10000 [00:22<00:21, 225.17it/s]Running 10000 simulations.:  51%|█████     | 5091/10000 [00:22<00:21, 224.80it/s]Running 10000 simulations.:  51%|█████     | 5114/10000 [00:22<00:21, 224.57it/s]Running 10000 simulations.:  51%|█████▏    | 5137/10000 [00:22<00:21, 224.93it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:22<00:21, 225.11it/s]Running 10000 simulations.:  52%|█████▏    | 5183/10000 [00:22<00:21, 224.97it/s]Running 10000 simulations.:  52%|█████▏    | 5206/10000 [00:22<00:21, 224.92it/s]Running 10000 simulations.:  52%|█████▏    | 5229/10000 [00:22<00:21, 224.70it/s]Running 10000 simulations.:  53%|█████▎    | 5252/10000 [00:23<00:21, 224.99it/s]Running 10000 simulations.:  53%|█████▎    | 5275/10000 [00:23<00:20, 225.58it/s]Running 10000 simulations.:  53%|█████▎    | 5298/10000 [00:23<00:20, 225.66it/s]Running 10000 simulations.:  53%|█████▎    | 5321/10000 [00:23<00:20, 225.17it/s]Running 10000 simulations.:  53%|█████▎    | 5344/10000 [00:23<00:20, 225.94it/s]Running 10000 simulations.:  54%|█████▎    | 5367/10000 [00:23<00:20, 225.90it/s]Running 10000 simulations.:  54%|█████▍    | 5390/10000 [00:23<00:20, 226.52it/s]Running 10000 simulations.:  54%|█████▍    | 5413/10000 [00:23<00:20, 226.57it/s]Running 10000 simulations.:  54%|█████▍    | 5436/10000 [00:23<00:20, 226.22it/s]Running 10000 simulations.:  55%|█████▍    | 5459/10000 [00:24<00:20, 226.06it/s]Running 10000 simulations.:  55%|█████▍    | 5482/10000 [00:24<00:19, 226.06it/s]Running 10000 simulations.:  55%|█████▌    | 5505/10000 [00:24<00:19, 226.16it/s]Running 10000 simulations.:  55%|█████▌    | 5528/10000 [00:24<00:19, 226.46it/s]Running 10000 simulations.:  56%|█████▌    | 5551/10000 [00:24<00:19, 226.08it/s]Running 10000 simulations.:  56%|█████▌    | 5574/10000 [00:24<00:19, 225.78it/s]Running 10000 simulations.:  56%|█████▌    | 5597/10000 [00:24<00:19, 225.43it/s]Running 10000 simulations.:  56%|█████▌    | 5620/10000 [00:24<00:19, 224.77it/s]Running 10000 simulations.:  56%|█████▋    | 5643/10000 [00:24<00:19, 224.66it/s]Running 10000 simulations.:  57%|█████▋    | 5666/10000 [00:24<00:19, 224.28it/s]Running 10000 simulations.:  57%|█████▋    | 5689/10000 [00:25<00:19, 223.51it/s]Running 10000 simulations.:  57%|█████▋    | 5712/10000 [00:25<00:19, 223.25it/s]Running 10000 simulations.:  57%|█████▋    | 5735/10000 [00:25<00:19, 223.63it/s]Running 10000 simulations.:  58%|█████▊    | 5758/10000 [00:25<00:18, 223.41it/s]Running 10000 simulations.:  58%|█████▊    | 5781/10000 [00:25<00:18, 223.04it/s]Running 10000 simulations.:  58%|█████▊    | 5804/10000 [00:25<00:18, 222.91it/s]Running 10000 simulations.:  58%|█████▊    | 5827/10000 [00:25<00:18, 223.64it/s]Running 10000 simulations.:  58%|█████▊    | 5850/10000 [00:25<00:18, 223.99it/s]Running 10000 simulations.:  59%|█████▊    | 5873/10000 [00:25<00:18, 224.11it/s]Running 10000 simulations.:  59%|█████▉    | 5896/10000 [00:25<00:18, 225.47it/s]Running 10000 simulations.:  59%|█████▉    | 5921/10000 [00:26<00:17, 231.40it/s]Running 10000 simulations.:  59%|█████▉    | 5946/10000 [00:26<00:17, 236.28it/s]Running 10000 simulations.:  60%|█████▉    | 5971/10000 [00:26<00:16, 239.74it/s]Running 10000 simulations.:  60%|█████▉    | 5996/10000 [00:26<00:16, 242.00it/s]Running 10000 simulations.:  60%|██████    | 6021/10000 [00:26<00:16, 241.91it/s]Running 10000 simulations.:  60%|██████    | 6046/10000 [00:26<00:16, 242.30it/s]Running 10000 simulations.:  61%|██████    | 6071/10000 [00:26<00:16, 243.47it/s]Running 10000 simulations.:  61%|██████    | 6096/10000 [00:26<00:15, 244.63it/s]Running 10000 simulations.:  61%|██████    | 6122/10000 [00:26<00:15, 246.27it/s]Running 10000 simulations.:  61%|██████▏   | 6147/10000 [00:26<00:15, 244.88it/s]Running 10000 simulations.:  62%|██████▏   | 6172/10000 [00:27<00:15, 239.32it/s]Running 10000 simulations.:  62%|██████▏   | 6196/10000 [00:27<00:16, 236.12it/s]Running 10000 simulations.:  62%|██████▏   | 6220/10000 [00:27<00:16, 234.08it/s]Running 10000 simulations.:  62%|██████▏   | 6244/10000 [00:27<00:16, 232.60it/s]Running 10000 simulations.:  63%|██████▎   | 6268/10000 [00:27<00:16, 231.41it/s]Running 10000 simulations.:  63%|██████▎   | 6292/10000 [00:27<00:16, 230.58it/s]Running 10000 simulations.:  63%|██████▎   | 6316/10000 [00:27<00:15, 230.33it/s]Running 10000 simulations.:  63%|██████▎   | 6340/10000 [00:27<00:15, 229.91it/s]Running 10000 simulations.:  64%|██████▎   | 6363/10000 [00:27<00:15, 229.86it/s]Running 10000 simulations.:  64%|██████▍   | 6387/10000 [00:28<00:15, 230.12it/s]Running 10000 simulations.:  64%|██████▍   | 6411/10000 [00:28<00:15, 230.10it/s]Running 10000 simulations.:  64%|██████▍   | 6435/10000 [00:28<00:15, 229.86it/s]Running 10000 simulations.:  65%|██████▍   | 6458/10000 [00:28<00:15, 229.62it/s]Running 10000 simulations.:  65%|██████▍   | 6481/10000 [00:28<00:15, 229.50it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:28<00:15, 229.97it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:28<00:15, 229.42it/s]Running 10000 simulations.:  66%|██████▌   | 6552/10000 [00:28<00:15, 229.72it/s]Running 10000 simulations.:  66%|██████▌   | 6575/10000 [00:28<00:14, 228.79it/s]Running 10000 simulations.:  66%|██████▌   | 6598/10000 [00:28<00:14, 228.63it/s]Running 10000 simulations.:  66%|██████▌   | 6622/10000 [00:29<00:14, 229.24it/s]Running 10000 simulations.:  66%|██████▋   | 6645/10000 [00:29<00:14, 229.04it/s]Running 10000 simulations.:  67%|██████▋   | 6668/10000 [00:29<00:14, 228.58it/s]Running 10000 simulations.:  67%|██████▋   | 6691/10000 [00:29<00:14, 228.87it/s]Running 10000 simulations.:  67%|██████▋   | 6714/10000 [00:29<00:14, 228.77it/s]Running 10000 simulations.:  67%|██████▋   | 6737/10000 [00:29<00:14, 228.83it/s]Running 10000 simulations.:  68%|██████▊   | 6761/10000 [00:29<00:14, 229.50it/s]Running 10000 simulations.:  68%|██████▊   | 6784/10000 [00:29<00:14, 229.25it/s]Running 10000 simulations.:  68%|██████▊   | 6807/10000 [00:29<00:13, 229.36it/s]Running 10000 simulations.:  68%|██████▊   | 6831/10000 [00:29<00:13, 229.36it/s]Running 10000 simulations.:  69%|██████▊   | 6854/10000 [00:30<00:13, 229.34it/s]Running 10000 simulations.:  69%|██████▉   | 6877/10000 [00:30<00:13, 229.40it/s]Running 10000 simulations.:  69%|██████▉   | 6901/10000 [00:30<00:13, 229.93it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:30<00:13, 228.95it/s]Running 10000 simulations.:  69%|██████▉   | 6947/10000 [00:30<00:13, 229.07it/s]Running 10000 simulations.:  70%|██████▉   | 6970/10000 [00:30<00:13, 228.61it/s]Running 10000 simulations.:  70%|██████▉   | 6993/10000 [00:30<00:13, 228.27it/s]Running 10000 simulations.:  70%|███████   | 7016/10000 [00:30<00:13, 228.40it/s]Running 10000 simulations.:  70%|███████   | 7039/10000 [00:30<00:12, 228.23it/s]Running 10000 simulations.:  71%|███████   | 7062/10000 [00:30<00:12, 228.45it/s]Running 10000 simulations.:  71%|███████   | 7085/10000 [00:31<00:12, 228.11it/s]Running 10000 simulations.:  71%|███████   | 7108/10000 [00:31<00:12, 227.70it/s]Running 10000 simulations.:  71%|███████▏  | 7131/10000 [00:31<00:12, 227.98it/s]Running 10000 simulations.:  72%|███████▏  | 7154/10000 [00:31<00:12, 227.81it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:31<00:12, 228.21it/s]Running 10000 simulations.:  72%|███████▏  | 7200/10000 [00:31<00:12, 227.89it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:31<00:12, 227.77it/s]Running 10000 simulations.:  72%|███████▏  | 7246/10000 [00:31<00:12, 227.83it/s]Running 10000 simulations.:  73%|███████▎  | 7269/10000 [00:31<00:12, 227.12it/s]Running 10000 simulations.:  73%|███████▎  | 7292/10000 [00:31<00:11, 227.21it/s]Running 10000 simulations.:  73%|███████▎  | 7315/10000 [00:32<00:11, 227.77it/s]Running 10000 simulations.:  73%|███████▎  | 7338/10000 [00:32<00:11, 227.29it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:32<00:11, 227.32it/s]Running 10000 simulations.:  74%|███████▍  | 7384/10000 [00:32<00:11, 227.10it/s]Running 10000 simulations.:  74%|███████▍  | 7407/10000 [00:32<00:11, 226.99it/s]Running 10000 simulations.:  74%|███████▍  | 7430/10000 [00:32<00:11, 226.68it/s]Running 10000 simulations.:  75%|███████▍  | 7453/10000 [00:32<00:11, 227.07it/s]Running 10000 simulations.:  75%|███████▍  | 7476/10000 [00:32<00:11, 227.35it/s]Running 10000 simulations.:  75%|███████▍  | 7499/10000 [00:32<00:11, 227.20it/s]Running 10000 simulations.:  75%|███████▌  | 7522/10000 [00:32<00:11, 225.17it/s]Running 10000 simulations.:  75%|███████▌  | 7545/10000 [00:33<00:11, 216.84it/s]Running 10000 simulations.:  76%|███████▌  | 7568/10000 [00:33<00:11, 219.68it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:33<00:10, 221.40it/s]Running 10000 simulations.:  76%|███████▌  | 7614/10000 [00:33<00:10, 223.28it/s]Running 10000 simulations.:  76%|███████▋  | 7637/10000 [00:33<00:10, 224.27it/s]Running 10000 simulations.:  77%|███████▋  | 7660/10000 [00:33<00:10, 224.74it/s]Running 10000 simulations.:  77%|███████▋  | 7683/10000 [00:33<00:10, 225.16it/s]Running 10000 simulations.:  77%|███████▋  | 7706/10000 [00:33<00:10, 225.91it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:33<00:10, 225.79it/s]Running 10000 simulations.:  78%|███████▊  | 7752/10000 [00:34<00:09, 225.50it/s]Running 10000 simulations.:  78%|███████▊  | 7775/10000 [00:34<00:09, 225.73it/s]Running 10000 simulations.:  78%|███████▊  | 7798/10000 [00:34<00:09, 226.37it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:34<00:09, 226.95it/s]Running 10000 simulations.:  78%|███████▊  | 7844/10000 [00:34<00:09, 227.04it/s]Running 10000 simulations.:  79%|███████▊  | 7867/10000 [00:34<00:09, 226.83it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:34<00:09, 227.10it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:34<00:09, 226.85it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:34<00:09, 227.54it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:34<00:08, 231.42it/s]Running 10000 simulations.:  80%|███████▉  | 7985/10000 [00:35<00:08, 233.48it/s]Running 10000 simulations.:  80%|████████  | 8009/10000 [00:35<00:08, 232.82it/s]Running 10000 simulations.:  80%|████████  | 8034/10000 [00:35<00:08, 235.24it/s]Running 10000 simulations.:  81%|████████  | 8059/10000 [00:35<00:08, 238.76it/s]Running 10000 simulations.:  81%|████████  | 8084/10000 [00:35<00:07, 241.36it/s]Running 10000 simulations.:  81%|████████  | 8109/10000 [00:35<00:07, 242.85it/s]Running 10000 simulations.:  81%|████████▏ | 8134/10000 [00:35<00:07, 240.27it/s]Running 10000 simulations.:  82%|████████▏ | 8159/10000 [00:35<00:07, 240.26it/s]Running 10000 simulations.:  82%|████████▏ | 8184/10000 [00:35<00:07, 237.75it/s]Running 10000 simulations.:  82%|████████▏ | 8208/10000 [00:35<00:07, 233.96it/s]Running 10000 simulations.:  82%|████████▏ | 8232/10000 [00:36<00:07, 232.19it/s]Running 10000 simulations.:  83%|████████▎ | 8256/10000 [00:36<00:07, 230.69it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:36<00:07, 228.90it/s]Running 10000 simulations.:  83%|████████▎ | 8303/10000 [00:36<00:07, 228.79it/s]Running 10000 simulations.:  83%|████████▎ | 8326/10000 [00:36<00:07, 228.31it/s]Running 10000 simulations.:  83%|████████▎ | 8349/10000 [00:36<00:07, 228.38it/s]Running 10000 simulations.:  84%|████████▎ | 8372/10000 [00:36<00:07, 228.45it/s]Running 10000 simulations.:  84%|████████▍ | 8395/10000 [00:36<00:07, 228.59it/s]Running 10000 simulations.:  84%|████████▍ | 8418/10000 [00:36<00:06, 228.81it/s]Running 10000 simulations.:  84%|████████▍ | 8441/10000 [00:37<00:06, 228.77it/s]Running 10000 simulations.:  85%|████████▍ | 8464/10000 [00:37<00:06, 228.36it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [00:37<00:06, 228.67it/s]Running 10000 simulations.:  85%|████████▌ | 8510/10000 [00:37<00:06, 228.84it/s]Running 10000 simulations.:  85%|████████▌ | 8533/10000 [00:37<00:06, 228.59it/s]Running 10000 simulations.:  86%|████████▌ | 8556/10000 [00:37<00:06, 228.64it/s]Running 10000 simulations.:  86%|████████▌ | 8579/10000 [00:37<00:06, 228.83it/s]Running 10000 simulations.:  86%|████████▌ | 8603/10000 [00:37<00:06, 229.73it/s]Running 10000 simulations.:  86%|████████▋ | 8626/10000 [00:37<00:05, 229.72it/s]Running 10000 simulations.:  86%|████████▋ | 8650/10000 [00:37<00:05, 230.17it/s]Running 10000 simulations.:  87%|████████▋ | 8674/10000 [00:38<00:05, 230.62it/s]Running 10000 simulations.:  87%|████████▋ | 8698/10000 [00:38<00:05, 230.17it/s]Running 10000 simulations.:  87%|████████▋ | 8722/10000 [00:38<00:05, 229.84it/s]Running 10000 simulations.:  87%|████████▋ | 8745/10000 [00:38<00:05, 229.69it/s]Running 10000 simulations.:  88%|████████▊ | 8768/10000 [00:38<00:05, 229.55it/s]Running 10000 simulations.:  88%|████████▊ | 8791/10000 [00:38<00:05, 229.35it/s]Running 10000 simulations.:  88%|████████▊ | 8815/10000 [00:38<00:05, 229.91it/s]Running 10000 simulations.:  88%|████████▊ | 8838/10000 [00:38<00:05, 229.54it/s]Running 10000 simulations.:  89%|████████▊ | 8861/10000 [00:38<00:04, 229.64it/s]Running 10000 simulations.:  89%|████████▉ | 8884/10000 [00:38<00:04, 229.62it/s]Running 10000 simulations.:  89%|████████▉ | 8907/10000 [00:39<00:04, 229.73it/s]Running 10000 simulations.:  89%|████████▉ | 8930/10000 [00:39<00:04, 229.75it/s]Running 10000 simulations.:  90%|████████▉ | 8954/10000 [00:39<00:04, 230.31it/s]Running 10000 simulations.:  90%|████████▉ | 8978/10000 [00:39<00:04, 229.89it/s]Running 10000 simulations.:  90%|█████████ | 9001/10000 [00:39<00:04, 229.33it/s]Running 10000 simulations.:  90%|█████████ | 9025/10000 [00:39<00:04, 229.79it/s]Running 10000 simulations.:  90%|█████████ | 9048/10000 [00:39<00:04, 229.64it/s]Running 10000 simulations.:  91%|█████████ | 9072/10000 [00:39<00:04, 229.92it/s]Running 10000 simulations.:  91%|█████████ | 9096/10000 [00:39<00:03, 230.11it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:39<00:03, 229.57it/s]Running 10000 simulations.:  91%|█████████▏| 9143/10000 [00:40<00:03, 228.84it/s]Running 10000 simulations.:  92%|█████████▏| 9166/10000 [00:40<00:03, 228.74it/s]Running 10000 simulations.:  92%|█████████▏| 9190/10000 [00:40<00:03, 229.52it/s]Running 10000 simulations.:  92%|█████████▏| 9214/10000 [00:40<00:03, 230.29it/s]Running 10000 simulations.:  92%|█████████▏| 9238/10000 [00:40<00:03, 230.42it/s]Running 10000 simulations.:  93%|█████████▎| 9262/10000 [00:40<00:03, 229.52it/s]Running 10000 simulations.:  93%|█████████▎| 9285/10000 [00:40<00:03, 229.03it/s]Running 10000 simulations.:  93%|█████████▎| 9308/10000 [00:40<00:03, 229.20it/s]Running 10000 simulations.:  93%|█████████▎| 9331/10000 [00:40<00:02, 228.89it/s]Running 10000 simulations.:  94%|█████████▎| 9354/10000 [00:40<00:02, 229.20it/s]Running 10000 simulations.:  94%|█████████▍| 9378/10000 [00:41<00:02, 229.70it/s]Running 10000 simulations.:  94%|█████████▍| 9402/10000 [00:41<00:02, 229.83it/s]Running 10000 simulations.:  94%|█████████▍| 9425/10000 [00:41<00:02, 229.48it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [00:41<00:02, 229.63it/s]Running 10000 simulations.:  95%|█████████▍| 9471/10000 [00:41<00:02, 229.56it/s]Running 10000 simulations.:  95%|█████████▍| 9494/10000 [00:41<00:02, 229.48it/s]Running 10000 simulations.:  95%|█████████▌| 9518/10000 [00:41<00:02, 229.71it/s]Running 10000 simulations.:  95%|█████████▌| 9541/10000 [00:41<00:01, 229.54it/s]Running 10000 simulations.:  96%|█████████▌| 9565/10000 [00:41<00:01, 229.77it/s]Running 10000 simulations.:  96%|█████████▌| 9588/10000 [00:41<00:01, 229.35it/s]Running 10000 simulations.:  96%|█████████▌| 9611/10000 [00:42<00:01, 229.20it/s]Running 10000 simulations.:  96%|█████████▋| 9635/10000 [00:42<00:01, 229.96it/s]Running 10000 simulations.:  97%|█████████▋| 9659/10000 [00:42<00:01, 229.98it/s]Running 10000 simulations.:  97%|█████████▋| 9682/10000 [00:42<00:01, 229.97it/s]Running 10000 simulations.:  97%|█████████▋| 9705/10000 [00:42<00:01, 229.64it/s]Running 10000 simulations.:  97%|█████████▋| 9729/10000 [00:42<00:01, 230.26it/s]Running 10000 simulations.:  98%|█████████▊| 9753/10000 [00:42<00:01, 230.72it/s]Running 10000 simulations.:  98%|█████████▊| 9777/10000 [00:42<00:00, 230.53it/s]Running 10000 simulations.:  98%|█████████▊| 9801/10000 [00:42<00:00, 231.30it/s]Running 10000 simulations.:  98%|█████████▊| 9825/10000 [00:43<00:00, 229.72it/s]Running 10000 simulations.:  98%|█████████▊| 9848/10000 [00:43<00:00, 222.95it/s]Running 10000 simulations.:  99%|█████████▊| 9871/10000 [00:43<00:00, 218.79it/s]Running 10000 simulations.:  99%|█████████▉| 9893/10000 [00:43<00:00, 215.79it/s]Running 10000 simulations.:  99%|█████████▉| 9915/10000 [00:43<00:00, 213.58it/s]Running 10000 simulations.:  99%|█████████▉| 9937/10000 [00:43<00:00, 212.25it/s]Running 10000 simulations.: 100%|█████████▉| 9959/10000 [00:43<00:00, 210.93it/s]Running 10000 simulations.: 100%|█████████▉| 9981/10000 [00:43<00:00, 209.99it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:43<00:00, 227.97it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 24/10000 [00:00<00:42, 233.38it/s]Running 10000 simulations.:   0%|          | 48/10000 [00:00<00:42, 233.46it/s]Running 10000 simulations.:   1%|          | 72/10000 [00:00<00:42, 233.39it/s]Running 10000 simulations.:   1%|          | 96/10000 [00:00<00:42, 233.62it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<00:42, 233.69it/s]Running 10000 simulations.:   1%|▏         | 144/10000 [00:00<00:42, 234.16it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:42, 233.36it/s]Running 10000 simulations.:   2%|▏         | 192/10000 [00:00<00:42, 233.26it/s]Running 10000 simulations.:   2%|▏         | 215/10000 [00:00<00:42, 232.05it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:01<00:42, 231.03it/s]Running 10000 simulations.:   3%|▎         | 262/10000 [00:01<00:42, 230.82it/s]Running 10000 simulations.:   3%|▎         | 285/10000 [00:01<00:42, 230.54it/s]Running 10000 simulations.:   3%|▎         | 309/10000 [00:01<00:42, 230.53it/s]Running 10000 simulations.:   3%|▎         | 332/10000 [00:01<00:42, 229.78it/s]Running 10000 simulations.:   4%|▎         | 355/10000 [00:01<00:42, 228.88it/s]Running 10000 simulations.:   4%|▍         | 378/10000 [00:01<00:42, 228.33it/s]Running 10000 simulations.:   4%|▍         | 402/10000 [00:01<00:41, 229.06it/s]Running 10000 simulations.:   4%|▍         | 425/10000 [00:01<00:41, 229.13it/s]Running 10000 simulations.:   4%|▍         | 448/10000 [00:01<00:41, 229.05it/s]Running 10000 simulations.:   5%|▍         | 471/10000 [00:02<00:41, 228.74it/s]Running 10000 simulations.:   5%|▍         | 494/10000 [00:02<00:41, 228.98it/s]Running 10000 simulations.:   5%|▌         | 517/10000 [00:02<00:41, 229.23it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:02<00:41, 228.13it/s]Running 10000 simulations.:   6%|▌         | 563/10000 [00:02<00:41, 227.59it/s]Running 10000 simulations.:   6%|▌         | 586/10000 [00:02<00:41, 227.49it/s]Running 10000 simulations.:   6%|▌         | 609/10000 [00:02<00:41, 227.21it/s]Running 10000 simulations.:   6%|▋         | 632/10000 [00:02<00:41, 226.86it/s]Running 10000 simulations.:   7%|▋         | 655/10000 [00:02<00:41, 227.67it/s]Running 10000 simulations.:   7%|▋         | 678/10000 [00:02<00:41, 227.00it/s]Running 10000 simulations.:   7%|▋         | 701/10000 [00:03<00:41, 226.26it/s]Running 10000 simulations.:   7%|▋         | 724/10000 [00:03<00:40, 226.27it/s]Running 10000 simulations.:   7%|▋         | 747/10000 [00:03<00:40, 227.09it/s]Running 10000 simulations.:   8%|▊         | 770/10000 [00:03<00:40, 226.51it/s]Running 10000 simulations.:   8%|▊         | 793/10000 [00:03<00:40, 226.91it/s]Running 10000 simulations.:   8%|▊         | 816/10000 [00:03<00:40, 227.34it/s]Running 10000 simulations.:   8%|▊         | 839/10000 [00:03<00:40, 227.56it/s]Running 10000 simulations.:   9%|▊         | 862/10000 [00:03<00:40, 226.89it/s]Running 10000 simulations.:   9%|▉         | 885/10000 [00:03<00:40, 226.42it/s]Running 10000 simulations.:   9%|▉         | 908/10000 [00:03<00:40, 226.24it/s]Running 10000 simulations.:   9%|▉         | 931/10000 [00:04<00:40, 225.93it/s]Running 10000 simulations.:  10%|▉         | 954/10000 [00:04<00:40, 225.83it/s]Running 10000 simulations.:  10%|▉         | 977/10000 [00:04<00:39, 225.96it/s]Running 10000 simulations.:  10%|█         | 1000/10000 [00:04<00:39, 225.35it/s]Running 10000 simulations.:  10%|█         | 1023/10000 [00:04<00:39, 225.14it/s]Running 10000 simulations.:  10%|█         | 1046/10000 [00:04<00:39, 225.42it/s]Running 10000 simulations.:  11%|█         | 1069/10000 [00:04<00:39, 225.48it/s]Running 10000 simulations.:  11%|█         | 1092/10000 [00:04<00:39, 225.60it/s]Running 10000 simulations.:  11%|█         | 1115/10000 [00:04<00:39, 225.89it/s]Running 10000 simulations.:  11%|█▏        | 1138/10000 [00:04<00:39, 225.88it/s]Running 10000 simulations.:  12%|█▏        | 1161/10000 [00:05<00:39, 225.64it/s]Running 10000 simulations.:  12%|█▏        | 1184/10000 [00:05<00:39, 225.95it/s]Running 10000 simulations.:  12%|█▏        | 1207/10000 [00:05<00:38, 225.60it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:05<00:38, 225.05it/s]Running 10000 simulations.:  13%|█▎        | 1253/10000 [00:05<00:38, 224.67it/s]Running 10000 simulations.:  13%|█▎        | 1276/10000 [00:05<00:38, 225.12it/s]Running 10000 simulations.:  13%|█▎        | 1299/10000 [00:05<00:38, 225.46it/s]Running 10000 simulations.:  13%|█▎        | 1322/10000 [00:05<00:38, 225.35it/s]Running 10000 simulations.:  13%|█▎        | 1345/10000 [00:05<00:38, 225.56it/s]Running 10000 simulations.:  14%|█▎        | 1368/10000 [00:06<00:38, 224.85it/s]Running 10000 simulations.:  14%|█▍        | 1391/10000 [00:06<00:38, 225.04it/s]Running 10000 simulations.:  14%|█▍        | 1414/10000 [00:06<00:38, 224.30it/s]Running 10000 simulations.:  14%|█▍        | 1437/10000 [00:06<00:38, 224.28it/s]Running 10000 simulations.:  15%|█▍        | 1460/10000 [00:06<00:38, 224.61it/s]Running 10000 simulations.:  15%|█▍        | 1483/10000 [00:06<00:37, 224.80it/s]Running 10000 simulations.:  15%|█▌        | 1506/10000 [00:06<00:37, 224.46it/s]Running 10000 simulations.:  15%|█▌        | 1529/10000 [00:06<00:37, 224.85it/s]Running 10000 simulations.:  16%|█▌        | 1552/10000 [00:06<00:37, 224.61it/s]Running 10000 simulations.:  16%|█▌        | 1576/10000 [00:06<00:37, 227.08it/s]Running 10000 simulations.:  16%|█▌        | 1601/10000 [00:07<00:36, 230.84it/s]Running 10000 simulations.:  16%|█▋        | 1626/10000 [00:07<00:35, 233.56it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:07<00:35, 235.69it/s]Running 10000 simulations.:  17%|█▋        | 1675/10000 [00:07<00:35, 236.83it/s]Running 10000 simulations.:  17%|█▋        | 1699/10000 [00:07<00:34, 237.75it/s]Running 10000 simulations.:  17%|█▋        | 1723/10000 [00:07<00:34, 238.32it/s]Running 10000 simulations.:  17%|█▋        | 1747/10000 [00:07<00:34, 238.78it/s]Running 10000 simulations.:  18%|█▊        | 1772/10000 [00:07<00:34, 239.54it/s]Running 10000 simulations.:  18%|█▊        | 1797/10000 [00:07<00:34, 240.23it/s]Running 10000 simulations.:  18%|█▊        | 1822/10000 [00:07<00:33, 241.39it/s]Running 10000 simulations.:  18%|█▊        | 1847/10000 [00:08<00:33, 242.48it/s]Running 10000 simulations.:  19%|█▊        | 1872/10000 [00:08<00:35, 231.86it/s]Running 10000 simulations.:  19%|█▉        | 1896/10000 [00:08<00:36, 225.01it/s]Running 10000 simulations.:  19%|█▉        | 1919/10000 [00:08<00:36, 220.43it/s]Running 10000 simulations.:  19%|█▉        | 1942/10000 [00:08<00:36, 221.29it/s]Running 10000 simulations.:  20%|█▉        | 1966/10000 [00:08<00:35, 224.47it/s]Running 10000 simulations.:  20%|█▉        | 1990/10000 [00:08<00:35, 227.15it/s]Running 10000 simulations.:  20%|██        | 2014/10000 [00:08<00:34, 228.32it/s]Running 10000 simulations.:  20%|██        | 2038/10000 [00:08<00:34, 229.19it/s]Running 10000 simulations.:  21%|██        | 2062/10000 [00:09<00:34, 230.06it/s]Running 10000 simulations.:  21%|██        | 2086/10000 [00:09<00:34, 230.72it/s]Running 10000 simulations.:  21%|██        | 2110/10000 [00:09<00:34, 230.72it/s]Running 10000 simulations.:  21%|██▏       | 2134/10000 [00:09<00:33, 231.93it/s]Running 10000 simulations.:  22%|██▏       | 2158/10000 [00:09<00:33, 231.23it/s]Running 10000 simulations.:  22%|██▏       | 2182/10000 [00:09<00:33, 230.78it/s]Running 10000 simulations.:  22%|██▏       | 2206/10000 [00:09<00:33, 230.98it/s]Running 10000 simulations.:  22%|██▏       | 2230/10000 [00:09<00:33, 231.30it/s]Running 10000 simulations.:  23%|██▎       | 2254/10000 [00:09<00:33, 230.88it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:09<00:33, 231.03it/s]Running 10000 simulations.:  23%|██▎       | 2302/10000 [00:10<00:33, 231.34it/s]Running 10000 simulations.:  23%|██▎       | 2326/10000 [00:10<00:33, 232.27it/s]Running 10000 simulations.:  24%|██▎       | 2350/10000 [00:10<00:32, 232.07it/s]Running 10000 simulations.:  24%|██▎       | 2374/10000 [00:10<00:32, 231.81it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:10<00:32, 232.29it/s]Running 10000 simulations.:  24%|██▍       | 2422/10000 [00:10<00:32, 232.96it/s]Running 10000 simulations.:  24%|██▍       | 2446/10000 [00:10<00:32, 232.89it/s]Running 10000 simulations.:  25%|██▍       | 2470/10000 [00:10<00:32, 232.69it/s]Running 10000 simulations.:  25%|██▍       | 2494/10000 [00:10<00:32, 232.26it/s]Running 10000 simulations.:  25%|██▌       | 2518/10000 [00:10<00:32, 232.40it/s]Running 10000 simulations.:  25%|██▌       | 2542/10000 [00:11<00:32, 233.00it/s]Running 10000 simulations.:  26%|██▌       | 2566/10000 [00:11<00:31, 232.87it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:11<00:31, 231.97it/s]Running 10000 simulations.:  26%|██▌       | 2614/10000 [00:11<00:31, 230.89it/s]Running 10000 simulations.:  26%|██▋       | 2638/10000 [00:11<00:32, 227.54it/s]Running 10000 simulations.:  27%|██▋       | 2661/10000 [00:11<00:32, 225.68it/s]Running 10000 simulations.:  27%|██▋       | 2684/10000 [00:11<00:32, 223.74it/s]Running 10000 simulations.:  27%|██▋       | 2707/10000 [00:11<00:32, 222.93it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:11<00:32, 222.01it/s]Running 10000 simulations.:  28%|██▊       | 2753/10000 [00:12<00:32, 221.42it/s]Running 10000 simulations.:  28%|██▊       | 2776/10000 [00:12<00:32, 221.15it/s]Running 10000 simulations.:  28%|██▊       | 2799/10000 [00:12<00:32, 221.28it/s]Running 10000 simulations.:  28%|██▊       | 2822/10000 [00:12<00:32, 221.12it/s]Running 10000 simulations.:  28%|██▊       | 2845/10000 [00:12<00:32, 220.80it/s]Running 10000 simulations.:  29%|██▊       | 2868/10000 [00:12<00:32, 221.50it/s]Running 10000 simulations.:  29%|██▉       | 2891/10000 [00:12<00:32, 220.90it/s]Running 10000 simulations.:  29%|██▉       | 2914/10000 [00:12<00:32, 220.93it/s]Running 10000 simulations.:  29%|██▉       | 2937/10000 [00:12<00:31, 220.97it/s]Running 10000 simulations.:  30%|██▉       | 2960/10000 [00:12<00:33, 210.91it/s]Running 10000 simulations.:  30%|██▉       | 2983/10000 [00:13<00:32, 213.94it/s]Running 10000 simulations.:  30%|███       | 3006/10000 [00:13<00:32, 216.07it/s]Running 10000 simulations.:  30%|███       | 3029/10000 [00:13<00:32, 217.53it/s]Running 10000 simulations.:  31%|███       | 3053/10000 [00:13<00:31, 223.42it/s]Running 10000 simulations.:  31%|███       | 3077/10000 [00:13<00:30, 227.94it/s]Running 10000 simulations.:  31%|███       | 3102/10000 [00:13<00:29, 232.33it/s]Running 10000 simulations.:  31%|███▏      | 3126/10000 [00:13<00:29, 234.29it/s]Running 10000 simulations.:  32%|███▏      | 3151/10000 [00:13<00:28, 236.42it/s]Running 10000 simulations.:  32%|███▏      | 3176/10000 [00:13<00:28, 238.03it/s]Running 10000 simulations.:  32%|███▏      | 3200/10000 [00:14<00:28, 235.91it/s]Running 10000 simulations.:  32%|███▏      | 3224/10000 [00:14<00:28, 236.06it/s]Running 10000 simulations.:  32%|███▏      | 3249/10000 [00:14<00:28, 237.50it/s]Running 10000 simulations.:  33%|███▎      | 3274/10000 [00:14<00:28, 238.33it/s]Running 10000 simulations.:  33%|███▎      | 3299/10000 [00:14<00:28, 239.25it/s]Running 10000 simulations.:  33%|███▎      | 3323/10000 [00:14<00:28, 237.64it/s]Running 10000 simulations.:  33%|███▎      | 3347/10000 [00:14<00:28, 236.56it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:14<00:28, 236.65it/s]Running 10000 simulations.:  34%|███▍      | 3395/10000 [00:14<00:27, 236.72it/s]Running 10000 simulations.:  34%|███▍      | 3419/10000 [00:14<00:27, 236.63it/s]Running 10000 simulations.:  34%|███▍      | 3443/10000 [00:15<00:27, 237.16it/s]Running 10000 simulations.:  35%|███▍      | 3467/10000 [00:15<00:27, 237.47it/s]Running 10000 simulations.:  35%|███▍      | 3491/10000 [00:15<00:27, 237.58it/s]Running 10000 simulations.:  35%|███▌      | 3515/10000 [00:15<00:27, 237.71it/s]Running 10000 simulations.:  35%|███▌      | 3539/10000 [00:15<00:27, 237.02it/s]Running 10000 simulations.:  36%|███▌      | 3563/10000 [00:15<00:27, 236.48it/s]Running 10000 simulations.:  36%|███▌      | 3587/10000 [00:15<00:27, 236.26it/s]Running 10000 simulations.:  36%|███▌      | 3612/10000 [00:15<00:26, 238.62it/s]Running 10000 simulations.:  36%|███▋      | 3637/10000 [00:15<00:26, 240.25it/s]Running 10000 simulations.:  37%|███▋      | 3662/10000 [00:15<00:26, 241.68it/s]Running 10000 simulations.:  37%|███▋      | 3687/10000 [00:16<00:26, 238.02it/s]Running 10000 simulations.:  37%|███▋      | 3711/10000 [00:16<00:26, 234.49it/s]Running 10000 simulations.:  37%|███▋      | 3735/10000 [00:16<00:26, 232.35it/s]Running 10000 simulations.:  38%|███▊      | 3759/10000 [00:16<00:27, 230.87it/s]Running 10000 simulations.:  38%|███▊      | 3783/10000 [00:16<00:27, 229.84it/s]Running 10000 simulations.:  38%|███▊      | 3806/10000 [00:16<00:27, 229.05it/s]Running 10000 simulations.:  38%|███▊      | 3829/10000 [00:16<00:26, 229.27it/s]Running 10000 simulations.:  39%|███▊      | 3852/10000 [00:16<00:26, 228.94it/s]Running 10000 simulations.:  39%|███▉      | 3875/10000 [00:16<00:26, 229.14it/s]Running 10000 simulations.:  39%|███▉      | 3898/10000 [00:16<00:26, 228.36it/s]Running 10000 simulations.:  39%|███▉      | 3921/10000 [00:17<00:26, 228.00it/s]Running 10000 simulations.:  39%|███▉      | 3944/10000 [00:17<00:26, 228.05it/s]Running 10000 simulations.:  40%|███▉      | 3967/10000 [00:17<00:26, 228.08it/s]Running 10000 simulations.:  40%|███▉      | 3990/10000 [00:17<00:26, 227.79it/s]Running 10000 simulations.:  40%|████      | 4013/10000 [00:17<00:26, 227.45it/s]Running 10000 simulations.:  40%|████      | 4036/10000 [00:17<00:26, 224.58it/s]Running 10000 simulations.:  41%|████      | 4059/10000 [00:17<00:27, 218.88it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:17<00:27, 214.75it/s]Running 10000 simulations.:  41%|████      | 4103/10000 [00:17<00:27, 212.42it/s]Running 10000 simulations.:  41%|████▏     | 4125/10000 [00:18<00:27, 210.65it/s]Running 10000 simulations.:  41%|████▏     | 4147/10000 [00:18<00:27, 209.42it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:18<00:27, 208.97it/s]Running 10000 simulations.:  42%|████▏     | 4189/10000 [00:18<00:27, 208.23it/s]Running 10000 simulations.:  42%|████▏     | 4210/10000 [00:18<00:27, 207.97it/s]Running 10000 simulations.:  42%|████▏     | 4231/10000 [00:18<00:27, 207.49it/s]Running 10000 simulations.:  43%|████▎     | 4252/10000 [00:18<00:27, 207.54it/s]Running 10000 simulations.:  43%|████▎     | 4275/10000 [00:18<00:26, 212.50it/s]Running 10000 simulations.:  43%|████▎     | 4298/10000 [00:18<00:26, 217.19it/s]Running 10000 simulations.:  43%|████▎     | 4321/10000 [00:18<00:25, 220.81it/s]Running 10000 simulations.:  43%|████▎     | 4344/10000 [00:19<00:25, 223.08it/s]Running 10000 simulations.:  44%|████▎     | 4368/10000 [00:19<00:25, 225.18it/s]Running 10000 simulations.:  44%|████▍     | 4392/10000 [00:19<00:24, 226.65it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:19<00:24, 227.21it/s]Running 10000 simulations.:  44%|████▍     | 4438/10000 [00:19<00:24, 227.19it/s]Running 10000 simulations.:  45%|████▍     | 4461/10000 [00:19<00:24, 227.43it/s]Running 10000 simulations.:  45%|████▍     | 4484/10000 [00:19<00:24, 227.51it/s]Running 10000 simulations.:  45%|████▌     | 4508/10000 [00:19<00:24, 228.28it/s]Running 10000 simulations.:  45%|████▌     | 4532/10000 [00:19<00:23, 229.19it/s]Running 10000 simulations.:  46%|████▌     | 4556/10000 [00:19<00:23, 229.51it/s]Running 10000 simulations.:  46%|████▌     | 4580/10000 [00:20<00:23, 229.75it/s]Running 10000 simulations.:  46%|████▌     | 4603/10000 [00:20<00:23, 229.43it/s]Running 10000 simulations.:  46%|████▋     | 4626/10000 [00:20<00:23, 224.72it/s]Running 10000 simulations.:  46%|████▋     | 4649/10000 [00:20<00:24, 219.03it/s]Running 10000 simulations.:  47%|████▋     | 4671/10000 [00:20<00:24, 214.54it/s]Running 10000 simulations.:  47%|████▋     | 4693/10000 [00:20<00:25, 211.50it/s]Running 10000 simulations.:  47%|████▋     | 4715/10000 [00:20<00:25, 210.01it/s]Running 10000 simulations.:  47%|████▋     | 4737/10000 [00:20<00:25, 208.74it/s]Running 10000 simulations.:  48%|████▊     | 4758/10000 [00:20<00:25, 207.56it/s]Running 10000 simulations.:  48%|████▊     | 4779/10000 [00:21<00:25, 206.48it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:21<00:25, 205.82it/s]Running 10000 simulations.:  48%|████▊     | 4821/10000 [00:21<00:25, 205.18it/s]Running 10000 simulations.:  48%|████▊     | 4844/10000 [00:21<00:24, 210.71it/s]Running 10000 simulations.:  49%|████▊     | 4868/10000 [00:21<00:23, 217.88it/s]Running 10000 simulations.:  49%|████▉     | 4892/10000 [00:21<00:22, 223.61it/s]Running 10000 simulations.:  49%|████▉     | 4915/10000 [00:21<00:22, 225.15it/s]Running 10000 simulations.:  49%|████▉     | 4939/10000 [00:21<00:22, 227.95it/s]Running 10000 simulations.:  50%|████▉     | 4963/10000 [00:21<00:21, 230.19it/s]Running 10000 simulations.:  50%|████▉     | 4987/10000 [00:21<00:21, 231.75it/s]Running 10000 simulations.:  50%|█████     | 5011/10000 [00:22<00:21, 233.03it/s]Running 10000 simulations.:  50%|█████     | 5035/10000 [00:22<00:21, 234.06it/s]Running 10000 simulations.:  51%|█████     | 5059/10000 [00:22<00:21, 234.69it/s]Running 10000 simulations.:  51%|█████     | 5083/10000 [00:22<00:20, 235.31it/s]Running 10000 simulations.:  51%|█████     | 5107/10000 [00:22<00:20, 235.10it/s]Running 10000 simulations.:  51%|█████▏    | 5131/10000 [00:22<00:20, 235.18it/s]Running 10000 simulations.:  52%|█████▏    | 5155/10000 [00:22<00:20, 235.70it/s]Running 10000 simulations.:  52%|█████▏    | 5179/10000 [00:22<00:20, 235.52it/s]Running 10000 simulations.:  52%|█████▏    | 5203/10000 [00:22<00:20, 236.06it/s]Running 10000 simulations.:  52%|█████▏    | 5227/10000 [00:22<00:20, 235.97it/s]Running 10000 simulations.:  53%|█████▎    | 5251/10000 [00:23<00:20, 236.27it/s]Running 10000 simulations.:  53%|█████▎    | 5275/10000 [00:23<00:19, 236.49it/s]Running 10000 simulations.:  53%|█████▎    | 5299/10000 [00:23<00:19, 236.65it/s]Running 10000 simulations.:  53%|█████▎    | 5323/10000 [00:23<00:19, 236.47it/s]Running 10000 simulations.:  53%|█████▎    | 5347/10000 [00:23<00:19, 237.05it/s]Running 10000 simulations.:  54%|█████▎    | 5371/10000 [00:23<00:19, 237.14it/s]Running 10000 simulations.:  54%|█████▍    | 5395/10000 [00:23<00:19, 236.96it/s]Running 10000 simulations.:  54%|█████▍    | 5419/10000 [00:23<00:19, 237.06it/s]Running 10000 simulations.:  54%|█████▍    | 5443/10000 [00:23<00:19, 237.13it/s]Running 10000 simulations.:  55%|█████▍    | 5467/10000 [00:23<00:19, 235.53it/s]Running 10000 simulations.:  55%|█████▍    | 5491/10000 [00:24<00:19, 236.09it/s]Running 10000 simulations.:  55%|█████▌    | 5515/10000 [00:24<00:18, 237.21it/s]Running 10000 simulations.:  55%|█████▌    | 5539/10000 [00:24<00:18, 237.30it/s]Running 10000 simulations.:  56%|█████▌    | 5563/10000 [00:24<00:18, 236.78it/s]Running 10000 simulations.:  56%|█████▌    | 5587/10000 [00:24<00:18, 236.95it/s]Running 10000 simulations.:  56%|█████▌    | 5611/10000 [00:24<00:18, 236.69it/s]Running 10000 simulations.:  56%|█████▋    | 5635/10000 [00:24<00:18, 234.52it/s]Running 10000 simulations.:  57%|█████▋    | 5659/10000 [00:24<00:18, 233.06it/s]Running 10000 simulations.:  57%|█████▋    | 5683/10000 [00:24<00:18, 233.68it/s]Running 10000 simulations.:  57%|█████▋    | 5707/10000 [00:24<00:18, 234.58it/s]Running 10000 simulations.:  57%|█████▋    | 5731/10000 [00:25<00:18, 234.82it/s]Running 10000 simulations.:  58%|█████▊    | 5755/10000 [00:25<00:18, 235.01it/s]Running 10000 simulations.:  58%|█████▊    | 5779/10000 [00:25<00:17, 235.36it/s]Running 10000 simulations.:  58%|█████▊    | 5803/10000 [00:25<00:17, 235.00it/s]Running 10000 simulations.:  58%|█████▊    | 5827/10000 [00:25<00:17, 235.26it/s]Running 10000 simulations.:  59%|█████▊    | 5851/10000 [00:25<00:17, 235.19it/s]Running 10000 simulations.:  59%|█████▉    | 5875/10000 [00:25<00:17, 235.50it/s]Running 10000 simulations.:  59%|█████▉    | 5899/10000 [00:25<00:17, 235.07it/s]Running 10000 simulations.:  59%|█████▉    | 5923/10000 [00:25<00:17, 234.96it/s]Running 10000 simulations.:  59%|█████▉    | 5947/10000 [00:26<00:17, 235.44it/s]Running 10000 simulations.:  60%|█████▉    | 5971/10000 [00:26<00:17, 235.50it/s]Running 10000 simulations.:  60%|█████▉    | 5995/10000 [00:26<00:16, 236.18it/s]Running 10000 simulations.:  60%|██████    | 6019/10000 [00:26<00:16, 236.28it/s]Running 10000 simulations.:  60%|██████    | 6043/10000 [00:26<00:16, 236.15it/s]Running 10000 simulations.:  61%|██████    | 6067/10000 [00:26<00:16, 236.33it/s]Running 10000 simulations.:  61%|██████    | 6091/10000 [00:26<00:16, 235.89it/s]Running 10000 simulations.:  61%|██████    | 6115/10000 [00:26<00:16, 235.45it/s]Running 10000 simulations.:  61%|██████▏   | 6139/10000 [00:26<00:16, 235.66it/s]Running 10000 simulations.:  62%|██████▏   | 6163/10000 [00:26<00:16, 235.70it/s]Running 10000 simulations.:  62%|██████▏   | 6187/10000 [00:27<00:16, 236.43it/s]Running 10000 simulations.:  62%|██████▏   | 6211/10000 [00:27<00:16, 236.56it/s]Running 10000 simulations.:  62%|██████▏   | 6235/10000 [00:27<00:15, 236.68it/s]Running 10000 simulations.:  63%|██████▎   | 6259/10000 [00:27<00:15, 237.38it/s]Running 10000 simulations.:  63%|██████▎   | 6283/10000 [00:27<00:15, 236.19it/s]Running 10000 simulations.:  63%|██████▎   | 6307/10000 [00:27<00:15, 233.37it/s]Running 10000 simulations.:  63%|██████▎   | 6331/10000 [00:27<00:15, 231.72it/s]Running 10000 simulations.:  64%|██████▎   | 6355/10000 [00:27<00:15, 230.65it/s]Running 10000 simulations.:  64%|██████▍   | 6379/10000 [00:27<00:15, 229.94it/s]Running 10000 simulations.:  64%|██████▍   | 6403/10000 [00:27<00:15, 229.07it/s]Running 10000 simulations.:  64%|██████▍   | 6426/10000 [00:28<00:15, 228.87it/s]Running 10000 simulations.:  64%|██████▍   | 6449/10000 [00:28<00:15, 228.44it/s]Running 10000 simulations.:  65%|██████▍   | 6472/10000 [00:28<00:15, 228.39it/s]Running 10000 simulations.:  65%|██████▍   | 6495/10000 [00:28<00:15, 228.36it/s]Running 10000 simulations.:  65%|██████▌   | 6518/10000 [00:28<00:15, 228.56it/s]Running 10000 simulations.:  65%|██████▌   | 6541/10000 [00:28<00:15, 228.76it/s]Running 10000 simulations.:  66%|██████▌   | 6565/10000 [00:28<00:14, 229.21it/s]Running 10000 simulations.:  66%|██████▌   | 6588/10000 [00:28<00:14, 228.90it/s]Running 10000 simulations.:  66%|██████▌   | 6611/10000 [00:28<00:14, 228.45it/s]Running 10000 simulations.:  66%|██████▋   | 6634/10000 [00:28<00:14, 228.13it/s]Running 10000 simulations.:  67%|██████▋   | 6657/10000 [00:29<00:14, 228.21it/s]Running 10000 simulations.:  67%|██████▋   | 6680/10000 [00:29<00:14, 228.26it/s]Running 10000 simulations.:  67%|██████▋   | 6703/10000 [00:29<00:14, 228.14it/s]Running 10000 simulations.:  67%|██████▋   | 6727/10000 [00:29<00:14, 229.21it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:29<00:14, 229.25it/s]Running 10000 simulations.:  68%|██████▊   | 6773/10000 [00:29<00:14, 228.75it/s]Running 10000 simulations.:  68%|██████▊   | 6796/10000 [00:29<00:14, 228.32it/s]Running 10000 simulations.:  68%|██████▊   | 6819/10000 [00:29<00:13, 227.84it/s]Running 10000 simulations.:  68%|██████▊   | 6842/10000 [00:29<00:13, 228.14it/s]Running 10000 simulations.:  69%|██████▊   | 6865/10000 [00:29<00:13, 227.97it/s]Running 10000 simulations.:  69%|██████▉   | 6888/10000 [00:30<00:13, 227.51it/s]Running 10000 simulations.:  69%|██████▉   | 6912/10000 [00:30<00:13, 228.70it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:30<00:13, 232.38it/s]Running 10000 simulations.:  70%|██████▉   | 6961/10000 [00:30<00:12, 234.43it/s]Running 10000 simulations.:  70%|██████▉   | 6985/10000 [00:30<00:12, 235.85it/s]Running 10000 simulations.:  70%|███████   | 7009/10000 [00:30<00:12, 230.17it/s]Running 10000 simulations.:  70%|███████   | 7033/10000 [00:30<00:13, 219.95it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:30<00:13, 214.25it/s]Running 10000 simulations.:  71%|███████   | 7078/10000 [00:30<00:13, 209.07it/s]Running 10000 simulations.:  71%|███████   | 7100/10000 [00:31<00:13, 207.67it/s]Running 10000 simulations.:  71%|███████   | 7121/10000 [00:31<00:13, 205.82it/s]Running 10000 simulations.:  71%|███████▏  | 7142/10000 [00:31<00:13, 204.38it/s]Running 10000 simulations.:  72%|███████▏  | 7164/10000 [00:31<00:13, 206.58it/s]Running 10000 simulations.:  72%|███████▏  | 7186/10000 [00:31<00:13, 209.30it/s]Running 10000 simulations.:  72%|███████▏  | 7208/10000 [00:31<00:13, 211.70it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:31<00:12, 213.86it/s]Running 10000 simulations.:  73%|███████▎  | 7252/10000 [00:31<00:12, 215.30it/s]Running 10000 simulations.:  73%|███████▎  | 7274/10000 [00:31<00:12, 215.86it/s]Running 10000 simulations.:  73%|███████▎  | 7296/10000 [00:31<00:12, 216.09it/s]Running 10000 simulations.:  73%|███████▎  | 7318/10000 [00:32<00:12, 216.11it/s]Running 10000 simulations.:  73%|███████▎  | 7340/10000 [00:32<00:12, 215.71it/s]Running 10000 simulations.:  74%|███████▎  | 7362/10000 [00:32<00:12, 215.85it/s]Running 10000 simulations.:  74%|███████▍  | 7384/10000 [00:32<00:12, 216.05it/s]Running 10000 simulations.:  74%|███████▍  | 7406/10000 [00:32<00:12, 215.89it/s]Running 10000 simulations.:  74%|███████▍  | 7428/10000 [00:32<00:11, 215.63it/s]Running 10000 simulations.:  74%|███████▍  | 7450/10000 [00:32<00:11, 216.01it/s]Running 10000 simulations.:  75%|███████▍  | 7472/10000 [00:32<00:11, 215.77it/s]Running 10000 simulations.:  75%|███████▍  | 7494/10000 [00:32<00:11, 215.36it/s]Running 10000 simulations.:  75%|███████▌  | 7516/10000 [00:32<00:11, 215.07it/s]Running 10000 simulations.:  75%|███████▌  | 7538/10000 [00:33<00:11, 214.86it/s]Running 10000 simulations.:  76%|███████▌  | 7560/10000 [00:33<00:11, 215.29it/s]Running 10000 simulations.:  76%|███████▌  | 7582/10000 [00:33<00:11, 215.49it/s]Running 10000 simulations.:  76%|███████▌  | 7606/10000 [00:33<00:10, 219.78it/s]Running 10000 simulations.:  76%|███████▋  | 7631/10000 [00:33<00:10, 225.91it/s]Running 10000 simulations.:  77%|███████▋  | 7656/10000 [00:33<00:10, 230.06it/s]Running 10000 simulations.:  77%|███████▋  | 7680/10000 [00:33<00:10, 229.27it/s]Running 10000 simulations.:  77%|███████▋  | 7703/10000 [00:33<00:10, 227.75it/s]Running 10000 simulations.:  77%|███████▋  | 7726/10000 [00:33<00:10, 226.47it/s]Running 10000 simulations.:  77%|███████▋  | 7749/10000 [00:34<00:09, 225.45it/s]Running 10000 simulations.:  78%|███████▊  | 7772/10000 [00:34<00:09, 225.18it/s]Running 10000 simulations.:  78%|███████▊  | 7795/10000 [00:34<00:09, 225.25it/s]Running 10000 simulations.:  78%|███████▊  | 7818/10000 [00:34<00:09, 225.25it/s]Running 10000 simulations.:  78%|███████▊  | 7841/10000 [00:34<00:09, 225.53it/s]Running 10000 simulations.:  79%|███████▊  | 7864/10000 [00:34<00:09, 225.76it/s]Running 10000 simulations.:  79%|███████▉  | 7887/10000 [00:34<00:09, 225.93it/s]Running 10000 simulations.:  79%|███████▉  | 7910/10000 [00:34<00:09, 225.56it/s]Running 10000 simulations.:  79%|███████▉  | 7933/10000 [00:34<00:09, 225.74it/s]Running 10000 simulations.:  80%|███████▉  | 7956/10000 [00:34<00:09, 226.18it/s]Running 10000 simulations.:  80%|███████▉  | 7979/10000 [00:35<00:08, 225.61it/s]Running 10000 simulations.:  80%|████████  | 8002/10000 [00:35<00:08, 225.51it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:35<00:08, 225.02it/s]Running 10000 simulations.:  80%|████████  | 8048/10000 [00:35<00:08, 224.76it/s]Running 10000 simulations.:  81%|████████  | 8071/10000 [00:35<00:08, 225.25it/s]Running 10000 simulations.:  81%|████████  | 8094/10000 [00:35<00:08, 225.07it/s]Running 10000 simulations.:  81%|████████  | 8117/10000 [00:35<00:08, 224.66it/s]Running 10000 simulations.:  81%|████████▏ | 8140/10000 [00:35<00:08, 224.29it/s]Running 10000 simulations.:  82%|████████▏ | 8163/10000 [00:35<00:08, 224.28it/s]Running 10000 simulations.:  82%|████████▏ | 8186/10000 [00:35<00:08, 224.75it/s]Running 10000 simulations.:  82%|████████▏ | 8209/10000 [00:36<00:07, 224.41it/s]Running 10000 simulations.:  82%|████████▏ | 8232/10000 [00:36<00:07, 224.43it/s]Running 10000 simulations.:  83%|████████▎ | 8255/10000 [00:36<00:07, 224.24it/s]Running 10000 simulations.:  83%|████████▎ | 8278/10000 [00:36<00:07, 224.08it/s]Running 10000 simulations.:  83%|████████▎ | 8301/10000 [00:36<00:07, 224.00it/s]Running 10000 simulations.:  83%|████████▎ | 8324/10000 [00:36<00:07, 224.41it/s]Running 10000 simulations.:  83%|████████▎ | 8347/10000 [00:36<00:07, 224.27it/s]Running 10000 simulations.:  84%|████████▎ | 8370/10000 [00:36<00:07, 224.81it/s]Running 10000 simulations.:  84%|████████▍ | 8393/10000 [00:36<00:07, 224.56it/s]Running 10000 simulations.:  84%|████████▍ | 8416/10000 [00:36<00:07, 224.37it/s]Running 10000 simulations.:  84%|████████▍ | 8439/10000 [00:37<00:06, 224.16it/s]Running 10000 simulations.:  85%|████████▍ | 8462/10000 [00:37<00:06, 224.72it/s]Running 10000 simulations.:  85%|████████▍ | 8485/10000 [00:37<00:06, 225.13it/s]Running 10000 simulations.:  85%|████████▌ | 8508/10000 [00:37<00:06, 225.32it/s]Running 10000 simulations.:  85%|████████▌ | 8531/10000 [00:37<00:06, 224.79it/s]Running 10000 simulations.:  86%|████████▌ | 8554/10000 [00:37<00:06, 224.53it/s]Running 10000 simulations.:  86%|████████▌ | 8577/10000 [00:37<00:06, 224.01it/s]Running 10000 simulations.:  86%|████████▌ | 8600/10000 [00:37<00:06, 224.04it/s]Running 10000 simulations.:  86%|████████▌ | 8623/10000 [00:37<00:06, 224.84it/s]Running 10000 simulations.:  86%|████████▋ | 8646/10000 [00:38<00:06, 225.21it/s]Running 10000 simulations.:  87%|████████▋ | 8669/10000 [00:38<00:05, 224.85it/s]Running 10000 simulations.:  87%|████████▋ | 8692/10000 [00:38<00:05, 224.60it/s]Running 10000 simulations.:  87%|████████▋ | 8715/10000 [00:38<00:05, 225.05it/s]Running 10000 simulations.:  87%|████████▋ | 8738/10000 [00:38<00:05, 225.30it/s]Running 10000 simulations.:  88%|████████▊ | 8761/10000 [00:38<00:05, 225.67it/s]Running 10000 simulations.:  88%|████████▊ | 8784/10000 [00:38<00:05, 225.02it/s]Running 10000 simulations.:  88%|████████▊ | 8807/10000 [00:38<00:05, 225.08it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [00:38<00:05, 225.62it/s]Running 10000 simulations.:  89%|████████▊ | 8853/10000 [00:38<00:05, 225.32it/s]Running 10000 simulations.:  89%|████████▉ | 8876/10000 [00:39<00:04, 225.04it/s]Running 10000 simulations.:  89%|████████▉ | 8899/10000 [00:39<00:04, 224.66it/s]Running 10000 simulations.:  89%|████████▉ | 8922/10000 [00:39<00:04, 224.87it/s]Running 10000 simulations.:  89%|████████▉ | 8945/10000 [00:39<00:04, 225.07it/s]Running 10000 simulations.:  90%|████████▉ | 8968/10000 [00:39<00:04, 224.93it/s]Running 10000 simulations.:  90%|████████▉ | 8991/10000 [00:39<00:04, 224.84it/s]Running 10000 simulations.:  90%|█████████ | 9014/10000 [00:39<00:04, 225.17it/s]Running 10000 simulations.:  90%|█████████ | 9037/10000 [00:39<00:04, 225.38it/s]Running 10000 simulations.:  91%|█████████ | 9060/10000 [00:39<00:04, 226.55it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [00:39<00:04, 226.97it/s]Running 10000 simulations.:  91%|█████████ | 9106/10000 [00:40<00:03, 227.66it/s]Running 10000 simulations.:  91%|█████████▏| 9129/10000 [00:40<00:03, 227.25it/s]Running 10000 simulations.:  92%|█████████▏| 9152/10000 [00:40<00:03, 221.94it/s]Running 10000 simulations.:  92%|█████████▏| 9175/10000 [00:40<00:03, 216.19it/s]Running 10000 simulations.:  92%|█████████▏| 9197/10000 [00:40<00:03, 212.22it/s]Running 10000 simulations.:  92%|█████████▏| 9219/10000 [00:40<00:03, 209.44it/s]Running 10000 simulations.:  92%|█████████▏| 9240/10000 [00:40<00:03, 206.99it/s]Running 10000 simulations.:  93%|█████████▎| 9261/10000 [00:40<00:03, 205.18it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [00:40<00:03, 204.11it/s]Running 10000 simulations.:  93%|█████████▎| 9303/10000 [00:41<00:03, 203.50it/s]Running 10000 simulations.:  93%|█████████▎| 9324/10000 [00:41<00:03, 203.05it/s]Running 10000 simulations.:  93%|█████████▎| 9345/10000 [00:41<00:03, 203.11it/s]Running 10000 simulations.:  94%|█████████▎| 9366/10000 [00:41<00:03, 202.90it/s]Running 10000 simulations.:  94%|█████████▍| 9387/10000 [00:41<00:03, 202.87it/s]Running 10000 simulations.:  94%|█████████▍| 9408/10000 [00:41<00:02, 202.38it/s]Running 10000 simulations.:  94%|█████████▍| 9429/10000 [00:41<00:02, 202.86it/s]Running 10000 simulations.:  94%|█████████▍| 9450/10000 [00:41<00:02, 202.71it/s]Running 10000 simulations.:  95%|█████████▍| 9471/10000 [00:41<00:02, 203.11it/s]Running 10000 simulations.:  95%|█████████▍| 9492/10000 [00:41<00:02, 203.27it/s]Running 10000 simulations.:  95%|█████████▌| 9513/10000 [00:42<00:02, 202.61it/s]Running 10000 simulations.:  95%|█████████▌| 9534/10000 [00:42<00:02, 202.22it/s]Running 10000 simulations.:  96%|█████████▌| 9555/10000 [00:42<00:02, 202.10it/s]Running 10000 simulations.:  96%|█████████▌| 9576/10000 [00:42<00:02, 202.23it/s]Running 10000 simulations.:  96%|█████████▌| 9597/10000 [00:42<00:01, 202.52it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [00:42<00:01, 202.61it/s]Running 10000 simulations.:  96%|█████████▋| 9639/10000 [00:42<00:01, 202.57it/s]Running 10000 simulations.:  97%|█████████▋| 9660/10000 [00:42<00:01, 202.93it/s]Running 10000 simulations.:  97%|█████████▋| 9681/10000 [00:42<00:01, 203.16it/s]Running 10000 simulations.:  97%|█████████▋| 9702/10000 [00:42<00:01, 193.15it/s]Running 10000 simulations.:  97%|█████████▋| 9723/10000 [00:43<00:01, 196.63it/s]Running 10000 simulations.:  97%|█████████▋| 9744/10000 [00:43<00:01, 199.43it/s]Running 10000 simulations.:  98%|█████████▊| 9765/10000 [00:43<00:01, 201.11it/s]Running 10000 simulations.:  98%|█████████▊| 9786/10000 [00:43<00:01, 202.45it/s]Running 10000 simulations.:  98%|█████████▊| 9807/10000 [00:43<00:00, 202.91it/s]Running 10000 simulations.:  98%|█████████▊| 9828/10000 [00:43<00:00, 199.53it/s]Running 10000 simulations.:  98%|█████████▊| 9849/10000 [00:43<00:00, 201.29it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [00:43<00:00, 202.41it/s]Running 10000 simulations.:  99%|█████████▉| 9891/10000 [00:43<00:00, 203.30it/s]Running 10000 simulations.:  99%|█████████▉| 9912/10000 [00:44<00:00, 203.45it/s]Running 10000 simulations.:  99%|█████████▉| 9933/10000 [00:44<00:00, 203.78it/s]Running 10000 simulations.: 100%|█████████▉| 9954/10000 [00:44<00:00, 204.05it/s]Running 10000 simulations.: 100%|█████████▉| 9975/10000 [00:44<00:00, 204.48it/s]Running 10000 simulations.: 100%|█████████▉| 9996/10000 [00:44<00:00, 204.66it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:44<00:00, 224.94it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:40, 246.76it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:40, 247.30it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:40, 246.88it/s]Running 10000 simulations.:   1%|          | 100/10000 [00:00<00:40, 246.30it/s]Running 10000 simulations.:   1%|▏         | 125/10000 [00:00<00:40, 246.32it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:39, 246.59it/s]Running 10000 simulations.:   2%|▏         | 175/10000 [00:00<00:39, 246.46it/s]Running 10000 simulations.:   2%|▏         | 200/10000 [00:00<00:39, 245.88it/s]Running 10000 simulations.:   2%|▏         | 225/10000 [00:00<00:39, 245.53it/s]Running 10000 simulations.:   2%|▎         | 250/10000 [00:01<00:39, 244.52it/s]Running 10000 simulations.:   3%|▎         | 274/10000 [00:01<00:40, 242.08it/s]Running 10000 simulations.:   3%|▎         | 298/10000 [00:01<00:40, 240.44it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:40, 240.60it/s]Running 10000 simulations.:   3%|▎         | 348/10000 [00:01<00:40, 240.67it/s]Running 10000 simulations.:   4%|▎         | 372/10000 [00:01<00:40, 240.42it/s]Running 10000 simulations.:   4%|▍         | 396/10000 [00:01<00:40, 239.28it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:40, 238.76it/s]Running 10000 simulations.:   4%|▍         | 444/10000 [00:01<00:40, 238.60it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:01<00:39, 238.67it/s]Running 10000 simulations.:   5%|▍         | 492/10000 [00:02<00:39, 238.75it/s]Running 10000 simulations.:   5%|▌         | 516/10000 [00:02<00:39, 238.35it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:02<00:39, 238.55it/s]Running 10000 simulations.:   6%|▌         | 564/10000 [00:02<00:39, 238.09it/s]Running 10000 simulations.:   6%|▌         | 588/10000 [00:02<00:39, 237.67it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:02<00:39, 237.40it/s]Running 10000 simulations.:   6%|▋         | 636/10000 [00:02<00:39, 236.82it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:02<00:39, 236.55it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:02<00:39, 236.47it/s]Running 10000 simulations.:   7%|▋         | 708/10000 [00:02<00:39, 236.47it/s]Running 10000 simulations.:   7%|▋         | 732/10000 [00:03<00:39, 236.88it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:03<00:38, 237.19it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:03<00:38, 236.83it/s]Running 10000 simulations.:   8%|▊         | 804/10000 [00:03<00:38, 237.24it/s]Running 10000 simulations.:   8%|▊         | 828/10000 [00:03<00:38, 236.66it/s]Running 10000 simulations.:   9%|▊         | 852/10000 [00:03<00:38, 235.41it/s]Running 10000 simulations.:   9%|▉         | 876/10000 [00:03<00:38, 235.78it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:38, 236.51it/s]Running 10000 simulations.:   9%|▉         | 924/10000 [00:03<00:38, 236.54it/s]Running 10000 simulations.:   9%|▉         | 948/10000 [00:03<00:38, 236.82it/s]Running 10000 simulations.:  10%|▉         | 972/10000 [00:04<00:38, 237.40it/s]Running 10000 simulations.:  10%|▉         | 996/10000 [00:04<00:37, 237.94it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:04<00:37, 237.99it/s]Running 10000 simulations.:  10%|█         | 1044/10000 [00:04<00:37, 236.65it/s]Running 10000 simulations.:  11%|█         | 1068/10000 [00:04<00:38, 233.04it/s]Running 10000 simulations.:  11%|█         | 1092/10000 [00:04<00:38, 230.39it/s]Running 10000 simulations.:  11%|█         | 1116/10000 [00:04<00:38, 229.02it/s]Running 10000 simulations.:  11%|█▏        | 1139/10000 [00:04<00:38, 227.91it/s]Running 10000 simulations.:  12%|█▏        | 1162/10000 [00:04<00:38, 227.37it/s]Running 10000 simulations.:  12%|█▏        | 1185/10000 [00:04<00:38, 226.42it/s]Running 10000 simulations.:  12%|█▏        | 1208/10000 [00:05<00:38, 225.46it/s]Running 10000 simulations.:  12%|█▏        | 1231/10000 [00:05<00:38, 225.20it/s]Running 10000 simulations.:  13%|█▎        | 1254/10000 [00:05<00:38, 225.28it/s]Running 10000 simulations.:  13%|█▎        | 1277/10000 [00:05<00:38, 224.84it/s]Running 10000 simulations.:  13%|█▎        | 1300/10000 [00:05<00:38, 224.79it/s]Running 10000 simulations.:  13%|█▎        | 1323/10000 [00:05<00:38, 224.73it/s]Running 10000 simulations.:  13%|█▎        | 1346/10000 [00:05<00:38, 224.88it/s]Running 10000 simulations.:  14%|█▎        | 1369/10000 [00:05<00:38, 225.55it/s]Running 10000 simulations.:  14%|█▍        | 1392/10000 [00:05<00:38, 224.61it/s]Running 10000 simulations.:  14%|█▍        | 1415/10000 [00:06<00:38, 221.66it/s]Running 10000 simulations.:  14%|█▍        | 1438/10000 [00:06<00:39, 217.93it/s]Running 10000 simulations.:  15%|█▍        | 1460/10000 [00:06<00:39, 214.93it/s]Running 10000 simulations.:  15%|█▍        | 1482/10000 [00:06<00:39, 213.17it/s]Running 10000 simulations.:  15%|█▌        | 1504/10000 [00:06<00:40, 211.81it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:06<00:40, 211.66it/s]Running 10000 simulations.:  15%|█▌        | 1548/10000 [00:06<00:40, 211.02it/s]Running 10000 simulations.:  16%|█▌        | 1570/10000 [00:06<00:40, 210.29it/s]Running 10000 simulations.:  16%|█▌        | 1592/10000 [00:06<00:40, 209.53it/s]Running 10000 simulations.:  16%|█▌        | 1614/10000 [00:06<00:39, 209.71it/s]Running 10000 simulations.:  16%|█▋        | 1636/10000 [00:07<00:39, 209.94it/s]Running 10000 simulations.:  17%|█▋        | 1657/10000 [00:07<00:39, 209.05it/s]Running 10000 simulations.:  17%|█▋        | 1678/10000 [00:07<00:39, 208.53it/s]Running 10000 simulations.:  17%|█▋        | 1699/10000 [00:07<00:39, 208.21it/s]Running 10000 simulations.:  17%|█▋        | 1720/10000 [00:07<00:39, 208.05it/s]Running 10000 simulations.:  17%|█▋        | 1741/10000 [00:07<00:39, 208.53it/s]Running 10000 simulations.:  18%|█▊        | 1762/10000 [00:07<00:39, 208.78it/s]Running 10000 simulations.:  18%|█▊        | 1784/10000 [00:07<00:39, 209.24it/s]Running 10000 simulations.:  18%|█▊        | 1805/10000 [00:07<00:39, 209.37it/s]Running 10000 simulations.:  18%|█▊        | 1827/10000 [00:07<00:38, 209.87it/s]Running 10000 simulations.:  18%|█▊        | 1849/10000 [00:08<00:38, 209.97it/s]Running 10000 simulations.:  19%|█▊        | 1870/10000 [00:08<00:38, 209.90it/s]Running 10000 simulations.:  19%|█▉        | 1891/10000 [00:08<00:38, 209.55it/s]Running 10000 simulations.:  19%|█▉        | 1912/10000 [00:08<00:38, 209.08it/s]Running 10000 simulations.:  19%|█▉        | 1933/10000 [00:08<00:38, 208.73it/s]Running 10000 simulations.:  20%|█▉        | 1954/10000 [00:08<00:38, 208.55it/s]Running 10000 simulations.:  20%|█▉        | 1975/10000 [00:08<00:38, 208.70it/s]Running 10000 simulations.:  20%|█▉        | 1996/10000 [00:08<00:38, 206.07it/s]Running 10000 simulations.:  20%|██        | 2017/10000 [00:08<00:39, 204.13it/s]Running 10000 simulations.:  20%|██        | 2041/10000 [00:09<00:37, 211.55it/s]Running 10000 simulations.:  21%|██        | 2065/10000 [00:09<00:36, 217.36it/s]Running 10000 simulations.:  21%|██        | 2089/10000 [00:09<00:35, 222.02it/s]Running 10000 simulations.:  21%|██        | 2113/10000 [00:09<00:34, 225.86it/s]Running 10000 simulations.:  21%|██▏       | 2137/10000 [00:09<00:34, 228.25it/s]Running 10000 simulations.:  22%|██▏       | 2161/10000 [00:09<00:33, 230.83it/s]Running 10000 simulations.:  22%|██▏       | 2185/10000 [00:09<00:33, 231.70it/s]Running 10000 simulations.:  22%|██▏       | 2209/10000 [00:09<00:33, 232.31it/s]Running 10000 simulations.:  22%|██▏       | 2233/10000 [00:09<00:33, 233.32it/s]Running 10000 simulations.:  23%|██▎       | 2257/10000 [00:09<00:33, 233.28it/s]Running 10000 simulations.:  23%|██▎       | 2281/10000 [00:10<00:33, 232.83it/s]Running 10000 simulations.:  23%|██▎       | 2305/10000 [00:10<00:33, 232.85it/s]Running 10000 simulations.:  23%|██▎       | 2329/10000 [00:10<00:32, 232.73it/s]Running 10000 simulations.:  24%|██▎       | 2353/10000 [00:10<00:32, 232.97it/s]Running 10000 simulations.:  24%|██▍       | 2377/10000 [00:10<00:32, 233.05it/s]Running 10000 simulations.:  24%|██▍       | 2401/10000 [00:10<00:32, 233.81it/s]Running 10000 simulations.:  24%|██▍       | 2425/10000 [00:10<00:32, 234.74it/s]Running 10000 simulations.:  24%|██▍       | 2449/10000 [00:10<00:32, 235.21it/s]Running 10000 simulations.:  25%|██▍       | 2473/10000 [00:10<00:32, 234.47it/s]Running 10000 simulations.:  25%|██▍       | 2497/10000 [00:10<00:31, 234.53it/s]Running 10000 simulations.:  25%|██▌       | 2521/10000 [00:11<00:31, 235.02it/s]Running 10000 simulations.:  25%|██▌       | 2545/10000 [00:11<00:31, 235.13it/s]Running 10000 simulations.:  26%|██▌       | 2569/10000 [00:11<00:31, 235.46it/s]Running 10000 simulations.:  26%|██▌       | 2593/10000 [00:11<00:31, 235.19it/s]Running 10000 simulations.:  26%|██▌       | 2617/10000 [00:11<00:31, 234.73it/s]Running 10000 simulations.:  26%|██▋       | 2641/10000 [00:11<00:31, 234.74it/s]Running 10000 simulations.:  27%|██▋       | 2665/10000 [00:11<00:31, 234.57it/s]Running 10000 simulations.:  27%|██▋       | 2689/10000 [00:11<00:31, 234.87it/s]Running 10000 simulations.:  27%|██▋       | 2713/10000 [00:11<00:31, 234.90it/s]Running 10000 simulations.:  27%|██▋       | 2737/10000 [00:11<00:30, 235.18it/s]Running 10000 simulations.:  28%|██▊       | 2761/10000 [00:12<00:30, 235.00it/s]Running 10000 simulations.:  28%|██▊       | 2785/10000 [00:12<00:30, 233.89it/s]Running 10000 simulations.:  28%|██▊       | 2809/10000 [00:12<00:30, 233.29it/s]Running 10000 simulations.:  28%|██▊       | 2833/10000 [00:12<00:30, 232.76it/s]Running 10000 simulations.:  29%|██▊       | 2857/10000 [00:12<00:30, 232.47it/s]Running 10000 simulations.:  29%|██▉       | 2881/10000 [00:12<00:30, 232.36it/s]Running 10000 simulations.:  29%|██▉       | 2905/10000 [00:12<00:30, 233.30it/s]Running 10000 simulations.:  29%|██▉       | 2929/10000 [00:12<00:30, 233.81it/s]Running 10000 simulations.:  30%|██▉       | 2953/10000 [00:12<00:30, 233.06it/s]Running 10000 simulations.:  30%|██▉       | 2977/10000 [00:13<00:30, 232.82it/s]Running 10000 simulations.:  30%|███       | 3001/10000 [00:13<00:29, 233.49it/s]Running 10000 simulations.:  30%|███       | 3025/10000 [00:13<00:29, 233.07it/s]Running 10000 simulations.:  30%|███       | 3049/10000 [00:13<00:29, 233.04it/s]Running 10000 simulations.:  31%|███       | 3073/10000 [00:13<00:29, 233.36it/s]Running 10000 simulations.:  31%|███       | 3097/10000 [00:13<00:29, 232.97it/s]Running 10000 simulations.:  31%|███       | 3121/10000 [00:13<00:29, 232.75it/s]Running 10000 simulations.:  31%|███▏      | 3145/10000 [00:13<00:29, 232.87it/s]Running 10000 simulations.:  32%|███▏      | 3169/10000 [00:13<00:30, 220.59it/s]Running 10000 simulations.:  32%|███▏      | 3192/10000 [00:13<00:32, 210.91it/s]Running 10000 simulations.:  32%|███▏      | 3214/10000 [00:14<00:33, 205.54it/s]Running 10000 simulations.:  32%|███▏      | 3235/10000 [00:14<00:33, 203.98it/s]Running 10000 simulations.:  33%|███▎      | 3256/10000 [00:14<00:33, 202.92it/s]Running 10000 simulations.:  33%|███▎      | 3277/10000 [00:14<00:33, 202.09it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:14<00:33, 202.01it/s]Running 10000 simulations.:  33%|███▎      | 3319/10000 [00:14<00:33, 202.10it/s]Running 10000 simulations.:  33%|███▎      | 3341/10000 [00:14<00:32, 205.65it/s]Running 10000 simulations.:  34%|███▎      | 3364/10000 [00:14<00:31, 212.05it/s]Running 10000 simulations.:  34%|███▍      | 3387/10000 [00:14<00:30, 216.04it/s]Running 10000 simulations.:  34%|███▍      | 3410/10000 [00:15<00:29, 219.82it/s]Running 10000 simulations.:  34%|███▍      | 3434/10000 [00:15<00:29, 223.34it/s]Running 10000 simulations.:  35%|███▍      | 3457/10000 [00:15<00:29, 224.67it/s]Running 10000 simulations.:  35%|███▍      | 3481/10000 [00:15<00:28, 226.36it/s]Running 10000 simulations.:  35%|███▌      | 3505/10000 [00:15<00:28, 227.90it/s]Running 10000 simulations.:  35%|███▌      | 3528/10000 [00:15<00:28, 228.15it/s]Running 10000 simulations.:  36%|███▌      | 3551/10000 [00:15<00:28, 228.16it/s]Running 10000 simulations.:  36%|███▌      | 3574/10000 [00:15<00:28, 228.66it/s]Running 10000 simulations.:  36%|███▌      | 3598/10000 [00:15<00:27, 229.17it/s]Running 10000 simulations.:  36%|███▌      | 3621/10000 [00:15<00:27, 229.18it/s]Running 10000 simulations.:  36%|███▋      | 3645/10000 [00:16<00:27, 229.46it/s]Running 10000 simulations.:  37%|███▋      | 3668/10000 [00:16<00:27, 229.04it/s]Running 10000 simulations.:  37%|███▋      | 3692/10000 [00:16<00:27, 229.39it/s]Running 10000 simulations.:  37%|███▋      | 3716/10000 [00:16<00:27, 229.65it/s]Running 10000 simulations.:  37%|███▋      | 3739/10000 [00:16<00:27, 229.56it/s]Running 10000 simulations.:  38%|███▊      | 3762/10000 [00:16<00:27, 229.35it/s]Running 10000 simulations.:  38%|███▊      | 3786/10000 [00:16<00:27, 229.84it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:16<00:26, 230.15it/s]Running 10000 simulations.:  38%|███▊      | 3834/10000 [00:16<00:26, 230.56it/s]Running 10000 simulations.:  39%|███▊      | 3858/10000 [00:16<00:26, 231.49it/s]Running 10000 simulations.:  39%|███▉      | 3882/10000 [00:17<00:26, 231.68it/s]Running 10000 simulations.:  39%|███▉      | 3906/10000 [00:17<00:26, 231.10it/s]Running 10000 simulations.:  39%|███▉      | 3930/10000 [00:17<00:26, 230.52it/s]Running 10000 simulations.:  40%|███▉      | 3954/10000 [00:17<00:26, 230.37it/s]Running 10000 simulations.:  40%|███▉      | 3978/10000 [00:17<00:26, 230.00it/s]Running 10000 simulations.:  40%|████      | 4002/10000 [00:17<00:26, 230.45it/s]Running 10000 simulations.:  40%|████      | 4026/10000 [00:17<00:25, 230.28it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:17<00:25, 230.35it/s]Running 10000 simulations.:  41%|████      | 4074/10000 [00:17<00:25, 230.26it/s]Running 10000 simulations.:  41%|████      | 4098/10000 [00:18<00:25, 229.86it/s]Running 10000 simulations.:  41%|████      | 4122/10000 [00:18<00:25, 230.25it/s]Running 10000 simulations.:  41%|████▏     | 4146/10000 [00:18<00:25, 229.95it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:18<00:25, 230.51it/s]Running 10000 simulations.:  42%|████▏     | 4194/10000 [00:18<00:25, 230.35it/s]Running 10000 simulations.:  42%|████▏     | 4218/10000 [00:18<00:25, 230.84it/s]Running 10000 simulations.:  42%|████▏     | 4242/10000 [00:18<00:24, 230.71it/s]Running 10000 simulations.:  43%|████▎     | 4266/10000 [00:18<00:24, 231.31it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:18<00:24, 231.27it/s]Running 10000 simulations.:  43%|████▎     | 4314/10000 [00:18<00:24, 230.70it/s]Running 10000 simulations.:  43%|████▎     | 4338/10000 [00:19<00:24, 229.97it/s]Running 10000 simulations.:  44%|████▎     | 4361/10000 [00:19<00:24, 229.51it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:19<00:24, 229.03it/s]Running 10000 simulations.:  44%|████▍     | 4408/10000 [00:19<00:24, 229.64it/s]Running 10000 simulations.:  44%|████▍     | 4432/10000 [00:19<00:24, 230.30it/s]Running 10000 simulations.:  45%|████▍     | 4456/10000 [00:19<00:24, 229.90it/s]Running 10000 simulations.:  45%|████▍     | 4479/10000 [00:19<00:24, 229.61it/s]Running 10000 simulations.:  45%|████▌     | 4502/10000 [00:19<00:23, 229.62it/s]Running 10000 simulations.:  45%|████▌     | 4526/10000 [00:19<00:23, 230.35it/s]Running 10000 simulations.:  46%|████▌     | 4550/10000 [00:19<00:23, 229.92it/s]Running 10000 simulations.:  46%|████▌     | 4574/10000 [00:20<00:23, 230.29it/s]Running 10000 simulations.:  46%|████▌     | 4598/10000 [00:20<00:23, 230.62it/s]Running 10000 simulations.:  46%|████▌     | 4622/10000 [00:20<00:24, 221.23it/s]Running 10000 simulations.:  46%|████▋     | 4646/10000 [00:20<00:23, 224.62it/s]Running 10000 simulations.:  47%|████▋     | 4670/10000 [00:20<00:23, 226.24it/s]Running 10000 simulations.:  47%|████▋     | 4694/10000 [00:20<00:23, 227.50it/s]Running 10000 simulations.:  47%|████▋     | 4717/10000 [00:20<00:23, 228.07it/s]Running 10000 simulations.:  47%|████▋     | 4741/10000 [00:20<00:22, 229.13it/s]Running 10000 simulations.:  48%|████▊     | 4765/10000 [00:20<00:22, 230.69it/s]Running 10000 simulations.:  48%|████▊     | 4790/10000 [00:21<00:22, 234.54it/s]Running 10000 simulations.:  48%|████▊     | 4815/10000 [00:21<00:21, 237.90it/s]Running 10000 simulations.:  48%|████▊     | 4839/10000 [00:21<00:21, 237.61it/s]Running 10000 simulations.:  49%|████▊     | 4864/10000 [00:21<00:21, 239.80it/s]Running 10000 simulations.:  49%|████▉     | 4889/10000 [00:21<00:21, 242.18it/s]Running 10000 simulations.:  49%|████▉     | 4914/10000 [00:21<00:20, 243.63it/s]Running 10000 simulations.:  49%|████▉     | 4939/10000 [00:21<00:20, 244.55it/s]Running 10000 simulations.:  50%|████▉     | 4964/10000 [00:21<00:20, 244.76it/s]Running 10000 simulations.:  50%|████▉     | 4989/10000 [00:21<00:20, 245.02it/s]Running 10000 simulations.:  50%|█████     | 5014/10000 [00:21<00:20, 245.34it/s]Running 10000 simulations.:  50%|█████     | 5039/10000 [00:22<00:20, 245.26it/s]Running 10000 simulations.:  51%|█████     | 5064/10000 [00:22<00:20, 244.68it/s]Running 10000 simulations.:  51%|█████     | 5089/10000 [00:22<00:20, 244.46it/s]Running 10000 simulations.:  51%|█████     | 5114/10000 [00:22<00:19, 244.93it/s]Running 10000 simulations.:  51%|█████▏    | 5139/10000 [00:22<00:19, 246.13it/s]Running 10000 simulations.:  52%|█████▏    | 5164/10000 [00:22<00:19, 246.07it/s]Running 10000 simulations.:  52%|█████▏    | 5189/10000 [00:22<00:19, 245.89it/s]Running 10000 simulations.:  52%|█████▏    | 5214/10000 [00:22<00:19, 246.00it/s]Running 10000 simulations.:  52%|█████▏    | 5239/10000 [00:22<00:19, 245.86it/s]Running 10000 simulations.:  53%|█████▎    | 5264/10000 [00:22<00:19, 245.55it/s]Running 10000 simulations.:  53%|█████▎    | 5289/10000 [00:23<00:19, 246.60it/s]Running 10000 simulations.:  53%|█████▎    | 5314/10000 [00:23<00:19, 246.20it/s]Running 10000 simulations.:  53%|█████▎    | 5339/10000 [00:23<00:18, 245.94it/s]Running 10000 simulations.:  54%|█████▎    | 5364/10000 [00:23<00:18, 246.04it/s]Running 10000 simulations.:  54%|█████▍    | 5389/10000 [00:23<00:18, 246.53it/s]Running 10000 simulations.:  54%|█████▍    | 5414/10000 [00:23<00:18, 246.96it/s]Running 10000 simulations.:  54%|█████▍    | 5439/10000 [00:23<00:18, 246.83it/s]Running 10000 simulations.:  55%|█████▍    | 5464/10000 [00:23<00:18, 246.83it/s]Running 10000 simulations.:  55%|█████▍    | 5489/10000 [00:23<00:18, 246.62it/s]Running 10000 simulations.:  55%|█████▌    | 5514/10000 [00:23<00:18, 247.00it/s]Running 10000 simulations.:  55%|█████▌    | 5539/10000 [00:24<00:18, 247.12it/s]Running 10000 simulations.:  56%|█████▌    | 5564/10000 [00:24<00:17, 246.61it/s]Running 10000 simulations.:  56%|█████▌    | 5589/10000 [00:24<00:17, 246.58it/s]Running 10000 simulations.:  56%|█████▌    | 5614/10000 [00:24<00:17, 246.70it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:24<00:17, 245.59it/s]Running 10000 simulations.:  57%|█████▋    | 5664/10000 [00:24<00:17, 245.51it/s]Running 10000 simulations.:  57%|█████▋    | 5689/10000 [00:24<00:17, 246.18it/s]Running 10000 simulations.:  57%|█████▋    | 5714/10000 [00:24<00:17, 246.85it/s]Running 10000 simulations.:  57%|█████▋    | 5739/10000 [00:24<00:17, 247.29it/s]Running 10000 simulations.:  58%|█████▊    | 5764/10000 [00:24<00:17, 246.70it/s]Running 10000 simulations.:  58%|█████▊    | 5789/10000 [00:25<00:17, 245.34it/s]Running 10000 simulations.:  58%|█████▊    | 5814/10000 [00:25<00:17, 245.24it/s]Running 10000 simulations.:  58%|█████▊    | 5839/10000 [00:25<00:16, 245.45it/s]Running 10000 simulations.:  59%|█████▊    | 5864/10000 [00:25<00:16, 245.44it/s]Running 10000 simulations.:  59%|█████▉    | 5889/10000 [00:25<00:16, 244.88it/s]Running 10000 simulations.:  59%|█████▉    | 5914/10000 [00:25<00:16, 245.10it/s]Running 10000 simulations.:  59%|█████▉    | 5939/10000 [00:25<00:16, 245.16it/s]Running 10000 simulations.:  60%|█████▉    | 5964/10000 [00:25<00:16, 244.30it/s]Running 10000 simulations.:  60%|█████▉    | 5989/10000 [00:25<00:16, 244.08it/s]Running 10000 simulations.:  60%|██████    | 6014/10000 [00:25<00:16, 244.36it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:26<00:16, 244.00it/s]Running 10000 simulations.:  61%|██████    | 6064/10000 [00:26<00:16, 243.73it/s]Running 10000 simulations.:  61%|██████    | 6089/10000 [00:26<00:16, 243.82it/s]Running 10000 simulations.:  61%|██████    | 6114/10000 [00:26<00:15, 243.32it/s]Running 10000 simulations.:  61%|██████▏   | 6139/10000 [00:26<00:15, 244.06it/s]Running 10000 simulations.:  62%|██████▏   | 6164/10000 [00:26<00:15, 244.40it/s]Running 10000 simulations.:  62%|██████▏   | 6189/10000 [00:26<00:15, 244.69it/s]Running 10000 simulations.:  62%|██████▏   | 6214/10000 [00:26<00:15, 245.98it/s]Running 10000 simulations.:  62%|██████▏   | 6239/10000 [00:26<00:15, 245.85it/s]Running 10000 simulations.:  63%|██████▎   | 6264/10000 [00:27<00:15, 246.66it/s]Running 10000 simulations.:  63%|██████▎   | 6289/10000 [00:27<00:15, 246.61it/s]Running 10000 simulations.:  63%|██████▎   | 6314/10000 [00:27<00:14, 246.93it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:27<00:14, 246.76it/s]Running 10000 simulations.:  64%|██████▎   | 6364/10000 [00:27<00:14, 246.98it/s]Running 10000 simulations.:  64%|██████▍   | 6389/10000 [00:27<00:14, 246.58it/s]Running 10000 simulations.:  64%|██████▍   | 6414/10000 [00:27<00:14, 246.20it/s]Running 10000 simulations.:  64%|██████▍   | 6439/10000 [00:27<00:14, 246.19it/s]Running 10000 simulations.:  65%|██████▍   | 6464/10000 [00:27<00:14, 246.45it/s]Running 10000 simulations.:  65%|██████▍   | 6489/10000 [00:27<00:14, 245.67it/s]Running 10000 simulations.:  65%|██████▌   | 6514/10000 [00:28<00:14, 245.05it/s]Running 10000 simulations.:  65%|██████▌   | 6539/10000 [00:28<00:14, 244.37it/s]Running 10000 simulations.:  66%|██████▌   | 6564/10000 [00:28<00:14, 244.30it/s]Running 10000 simulations.:  66%|██████▌   | 6589/10000 [00:28<00:13, 244.79it/s]Running 10000 simulations.:  66%|██████▌   | 6614/10000 [00:28<00:13, 244.26it/s]Running 10000 simulations.:  66%|██████▋   | 6639/10000 [00:28<00:13, 245.25it/s]Running 10000 simulations.:  67%|██████▋   | 6664/10000 [00:28<00:13, 246.43it/s]Running 10000 simulations.:  67%|██████▋   | 6689/10000 [00:28<00:13, 246.78it/s]Running 10000 simulations.:  67%|██████▋   | 6714/10000 [00:28<00:13, 246.94it/s]Running 10000 simulations.:  67%|██████▋   | 6739/10000 [00:28<00:13, 246.57it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:29<00:13, 247.05it/s]Running 10000 simulations.:  68%|██████▊   | 6789/10000 [00:29<00:13, 246.36it/s]Running 10000 simulations.:  68%|██████▊   | 6814/10000 [00:29<00:13, 244.98it/s]Running 10000 simulations.:  68%|██████▊   | 6839/10000 [00:29<00:12, 244.26it/s]Running 10000 simulations.:  69%|██████▊   | 6864/10000 [00:29<00:12, 243.83it/s]Running 10000 simulations.:  69%|██████▉   | 6889/10000 [00:29<00:12, 243.86it/s]Running 10000 simulations.:  69%|██████▉   | 6914/10000 [00:29<00:12, 244.17it/s]Running 10000 simulations.:  69%|██████▉   | 6939/10000 [00:29<00:12, 244.24it/s]Running 10000 simulations.:  70%|██████▉   | 6964/10000 [00:29<00:12, 244.72it/s]Running 10000 simulations.:  70%|██████▉   | 6989/10000 [00:29<00:12, 244.71it/s]Running 10000 simulations.:  70%|███████   | 7014/10000 [00:30<00:12, 244.42it/s]Running 10000 simulations.:  70%|███████   | 7039/10000 [00:30<00:12, 243.80it/s]Running 10000 simulations.:  71%|███████   | 7064/10000 [00:30<00:12, 243.38it/s]Running 10000 simulations.:  71%|███████   | 7089/10000 [00:30<00:11, 242.74it/s]Running 10000 simulations.:  71%|███████   | 7114/10000 [00:30<00:11, 243.71it/s]Running 10000 simulations.:  71%|███████▏  | 7139/10000 [00:30<00:11, 244.16it/s]Running 10000 simulations.:  72%|███████▏  | 7164/10000 [00:30<00:11, 243.38it/s]Running 10000 simulations.:  72%|███████▏  | 7189/10000 [00:30<00:11, 243.38it/s]Running 10000 simulations.:  72%|███████▏  | 7214/10000 [00:30<00:11, 243.54it/s]Running 10000 simulations.:  72%|███████▏  | 7239/10000 [00:30<00:11, 243.28it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:31<00:11, 243.86it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:31<00:11, 244.22it/s]Running 10000 simulations.:  73%|███████▎  | 7314/10000 [00:31<00:11, 244.17it/s]Running 10000 simulations.:  73%|███████▎  | 7339/10000 [00:31<00:10, 243.65it/s]Running 10000 simulations.:  74%|███████▎  | 7364/10000 [00:31<00:10, 243.50it/s]Running 10000 simulations.:  74%|███████▍  | 7389/10000 [00:31<00:10, 243.45it/s]Running 10000 simulations.:  74%|███████▍  | 7414/10000 [00:31<00:10, 244.21it/s]Running 10000 simulations.:  74%|███████▍  | 7439/10000 [00:31<00:10, 244.85it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:31<00:10, 245.17it/s]Running 10000 simulations.:  75%|███████▍  | 7489/10000 [00:32<00:10, 244.70it/s]Running 10000 simulations.:  75%|███████▌  | 7514/10000 [00:32<00:10, 245.10it/s]Running 10000 simulations.:  75%|███████▌  | 7539/10000 [00:32<00:10, 244.94it/s]Running 10000 simulations.:  76%|███████▌  | 7564/10000 [00:32<00:09, 244.88it/s]Running 10000 simulations.:  76%|███████▌  | 7589/10000 [00:32<00:09, 246.27it/s]Running 10000 simulations.:  76%|███████▌  | 7614/10000 [00:32<00:09, 245.80it/s]Running 10000 simulations.:  76%|███████▋  | 7639/10000 [00:32<00:09, 245.81it/s]Running 10000 simulations.:  77%|███████▋  | 7664/10000 [00:32<00:09, 246.35it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:32<00:09, 246.63it/s]Running 10000 simulations.:  77%|███████▋  | 7714/10000 [00:32<00:09, 246.75it/s]Running 10000 simulations.:  77%|███████▋  | 7739/10000 [00:33<00:09, 247.60it/s]Running 10000 simulations.:  78%|███████▊  | 7764/10000 [00:33<00:09, 246.78it/s]Running 10000 simulations.:  78%|███████▊  | 7789/10000 [00:33<00:09, 245.53it/s]Running 10000 simulations.:  78%|███████▊  | 7814/10000 [00:33<00:08, 244.64it/s]Running 10000 simulations.:  78%|███████▊  | 7839/10000 [00:33<00:08, 244.61it/s]Running 10000 simulations.:  79%|███████▊  | 7864/10000 [00:33<00:08, 244.77it/s]Running 10000 simulations.:  79%|███████▉  | 7889/10000 [00:33<00:08, 245.22it/s]Running 10000 simulations.:  79%|███████▉  | 7914/10000 [00:33<00:08, 245.20it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:33<00:08, 244.78it/s]Running 10000 simulations.:  80%|███████▉  | 7964/10000 [00:33<00:08, 244.03it/s]Running 10000 simulations.:  80%|███████▉  | 7989/10000 [00:34<00:08, 244.03it/s]Running 10000 simulations.:  80%|████████  | 8014/10000 [00:34<00:08, 243.88it/s]Running 10000 simulations.:  80%|████████  | 8039/10000 [00:34<00:08, 244.12it/s]Running 10000 simulations.:  81%|████████  | 8064/10000 [00:34<00:07, 243.90it/s]Running 10000 simulations.:  81%|████████  | 8089/10000 [00:34<00:07, 244.02it/s]Running 10000 simulations.:  81%|████████  | 8114/10000 [00:34<00:07, 244.45it/s]Running 10000 simulations.:  81%|████████▏ | 8139/10000 [00:34<00:07, 244.23it/s]Running 10000 simulations.:  82%|████████▏ | 8164/10000 [00:34<00:07, 245.05it/s]Running 10000 simulations.:  82%|████████▏ | 8189/10000 [00:34<00:07, 244.99it/s]Running 10000 simulations.:  82%|████████▏ | 8214/10000 [00:34<00:07, 245.99it/s]Running 10000 simulations.:  82%|████████▏ | 8239/10000 [00:35<00:07, 245.47it/s]Running 10000 simulations.:  83%|████████▎ | 8264/10000 [00:35<00:07, 245.92it/s]Running 10000 simulations.:  83%|████████▎ | 8289/10000 [00:35<00:06, 245.55it/s]Running 10000 simulations.:  83%|████████▎ | 8314/10000 [00:35<00:06, 245.50it/s]Running 10000 simulations.:  83%|████████▎ | 8339/10000 [00:35<00:06, 245.80it/s]Running 10000 simulations.:  84%|████████▎ | 8364/10000 [00:35<00:06, 245.29it/s]Running 10000 simulations.:  84%|████████▍ | 8389/10000 [00:35<00:06, 245.53it/s]Running 10000 simulations.:  84%|████████▍ | 8414/10000 [00:35<00:06, 245.97it/s]Running 10000 simulations.:  84%|████████▍ | 8439/10000 [00:35<00:06, 245.88it/s]Running 10000 simulations.:  85%|████████▍ | 8464/10000 [00:35<00:06, 246.96it/s]Running 10000 simulations.:  85%|████████▍ | 8489/10000 [00:36<00:06, 246.72it/s]Running 10000 simulations.:  85%|████████▌ | 8514/10000 [00:36<00:06, 247.01it/s]Running 10000 simulations.:  85%|████████▌ | 8539/10000 [00:36<00:05, 247.53it/s]Running 10000 simulations.:  86%|████████▌ | 8564/10000 [00:36<00:05, 247.28it/s]Running 10000 simulations.:  86%|████████▌ | 8589/10000 [00:36<00:05, 247.63it/s]Running 10000 simulations.:  86%|████████▌ | 8614/10000 [00:36<00:05, 247.47it/s]Running 10000 simulations.:  86%|████████▋ | 8639/10000 [00:36<00:05, 246.10it/s]Running 10000 simulations.:  87%|████████▋ | 8664/10000 [00:36<00:05, 245.60it/s]Running 10000 simulations.:  87%|████████▋ | 8689/10000 [00:36<00:05, 245.43it/s]Running 10000 simulations.:  87%|████████▋ | 8714/10000 [00:37<00:05, 244.72it/s]Running 10000 simulations.:  87%|████████▋ | 8739/10000 [00:37<00:05, 243.91it/s]Running 10000 simulations.:  88%|████████▊ | 8764/10000 [00:37<00:05, 243.59it/s]Running 10000 simulations.:  88%|████████▊ | 8789/10000 [00:37<00:04, 243.71it/s]Running 10000 simulations.:  88%|████████▊ | 8814/10000 [00:37<00:04, 243.25it/s]Running 10000 simulations.:  88%|████████▊ | 8839/10000 [00:37<00:04, 244.25it/s]Running 10000 simulations.:  89%|████████▊ | 8864/10000 [00:37<00:04, 244.68it/s]Running 10000 simulations.:  89%|████████▉ | 8889/10000 [00:37<00:04, 244.68it/s]Running 10000 simulations.:  89%|████████▉ | 8914/10000 [00:37<00:04, 244.28it/s]Running 10000 simulations.:  89%|████████▉ | 8939/10000 [00:37<00:04, 244.46it/s]Running 10000 simulations.:  90%|████████▉ | 8964/10000 [00:38<00:04, 244.42it/s]Running 10000 simulations.:  90%|████████▉ | 8989/10000 [00:38<00:04, 244.63it/s]Running 10000 simulations.:  90%|█████████ | 9014/10000 [00:38<00:04, 244.37it/s]Running 10000 simulations.:  90%|█████████ | 9039/10000 [00:38<00:03, 242.38it/s]Running 10000 simulations.:  91%|█████████ | 9064/10000 [00:38<00:03, 237.63it/s]Running 10000 simulations.:  91%|█████████ | 9088/10000 [00:38<00:03, 237.15it/s]Running 10000 simulations.:  91%|█████████ | 9112/10000 [00:38<00:03, 237.21it/s]Running 10000 simulations.:  91%|█████████▏| 9136/10000 [00:38<00:03, 237.04it/s]Running 10000 simulations.:  92%|█████████▏| 9160/10000 [00:38<00:03, 236.76it/s]Running 10000 simulations.:  92%|█████████▏| 9184/10000 [00:38<00:03, 236.69it/s]Running 10000 simulations.:  92%|█████████▏| 9208/10000 [00:39<00:03, 236.88it/s]Running 10000 simulations.:  92%|█████████▏| 9232/10000 [00:39<00:03, 236.83it/s]Running 10000 simulations.:  93%|█████████▎| 9256/10000 [00:39<00:03, 237.73it/s]Running 10000 simulations.:  93%|█████████▎| 9280/10000 [00:39<00:03, 237.31it/s]Running 10000 simulations.:  93%|█████████▎| 9304/10000 [00:39<00:02, 237.05it/s]Running 10000 simulations.:  93%|█████████▎| 9328/10000 [00:39<00:02, 237.21it/s]Running 10000 simulations.:  94%|█████████▎| 9352/10000 [00:39<00:02, 237.28it/s]Running 10000 simulations.:  94%|█████████▍| 9376/10000 [00:39<00:02, 237.57it/s]Running 10000 simulations.:  94%|█████████▍| 9400/10000 [00:39<00:02, 237.02it/s]Running 10000 simulations.:  94%|█████████▍| 9424/10000 [00:39<00:02, 236.48it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [00:40<00:02, 236.00it/s]Running 10000 simulations.:  95%|█████████▍| 9472/10000 [00:40<00:02, 236.42it/s]Running 10000 simulations.:  95%|█████████▍| 9496/10000 [00:40<00:02, 236.45it/s]Running 10000 simulations.:  95%|█████████▌| 9521/10000 [00:40<00:02, 237.58it/s]Running 10000 simulations.:  95%|█████████▌| 9546/10000 [00:40<00:01, 238.49it/s]Running 10000 simulations.:  96%|█████████▌| 9570/10000 [00:40<00:01, 238.09it/s]Running 10000 simulations.:  96%|█████████▌| 9594/10000 [00:40<00:01, 237.55it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [00:40<00:01, 237.00it/s]Running 10000 simulations.:  96%|█████████▋| 9642/10000 [00:40<00:01, 236.71it/s]Running 10000 simulations.:  97%|█████████▋| 9666/10000 [00:40<00:01, 236.72it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [00:41<00:01, 236.91it/s]Running 10000 simulations.:  97%|█████████▋| 9714/10000 [00:41<00:01, 236.79it/s]Running 10000 simulations.:  97%|█████████▋| 9738/10000 [00:41<00:01, 236.43it/s]Running 10000 simulations.:  98%|█████████▊| 9762/10000 [00:41<00:01, 236.68it/s]Running 10000 simulations.:  98%|█████████▊| 9786/10000 [00:41<00:00, 237.05it/s]Running 10000 simulations.:  98%|█████████▊| 9810/10000 [00:41<00:00, 236.92it/s]Running 10000 simulations.:  98%|█████████▊| 9834/10000 [00:41<00:00, 237.15it/s]Running 10000 simulations.:  99%|█████████▊| 9858/10000 [00:41<00:00, 237.92it/s]Running 10000 simulations.:  99%|█████████▉| 9882/10000 [00:41<00:00, 238.25it/s]Running 10000 simulations.:  99%|█████████▉| 9906/10000 [00:42<00:00, 238.07it/s]Running 10000 simulations.:  99%|█████████▉| 9930/10000 [00:42<00:00, 236.63it/s]Running 10000 simulations.: 100%|█████████▉| 9954/10000 [00:42<00:00, 235.14it/s]Running 10000 simulations.: 100%|█████████▉| 9978/10000 [00:42<00:00, 232.97it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 235.79it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 252.09it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 253.98it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:38, 254.78it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:38, 255.42it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:38, 255.71it/s]Running 10000 simulations.:   2%|▏         | 156/10000 [00:00<00:38, 255.32it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:00<00:38, 255.44it/s]Running 10000 simulations.:   2%|▏         | 208/10000 [00:00<00:38, 255.53it/s]Running 10000 simulations.:   2%|▏         | 234/10000 [00:00<00:38, 255.54it/s]Running 10000 simulations.:   3%|▎         | 260/10000 [00:01<00:38, 255.32it/s]Running 10000 simulations.:   3%|▎         | 286/10000 [00:01<00:38, 255.00it/s]Running 10000 simulations.:   3%|▎         | 312/10000 [00:01<00:37, 255.09it/s]Running 10000 simulations.:   3%|▎         | 338/10000 [00:01<00:38, 253.92it/s]Running 10000 simulations.:   4%|▎         | 364/10000 [00:01<00:38, 253.39it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:38, 252.71it/s]Running 10000 simulations.:   4%|▍         | 416/10000 [00:01<00:38, 252.12it/s]Running 10000 simulations.:   4%|▍         | 442/10000 [00:01<00:37, 251.72it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:01<00:37, 252.67it/s]Running 10000 simulations.:   5%|▍         | 494/10000 [00:01<00:37, 253.06it/s]Running 10000 simulations.:   5%|▌         | 520/10000 [00:02<00:37, 252.58it/s]Running 10000 simulations.:   5%|▌         | 546/10000 [00:02<00:37, 251.18it/s]Running 10000 simulations.:   6%|▌         | 572/10000 [00:02<00:37, 250.28it/s]Running 10000 simulations.:   6%|▌         | 598/10000 [00:02<00:37, 249.70it/s]Running 10000 simulations.:   6%|▌         | 623/10000 [00:02<00:37, 249.76it/s]Running 10000 simulations.:   6%|▋         | 648/10000 [00:02<00:38, 244.14it/s]Running 10000 simulations.:   7%|▋         | 673/10000 [00:02<00:38, 240.35it/s]Running 10000 simulations.:   7%|▋         | 698/10000 [00:02<00:38, 238.91it/s]Running 10000 simulations.:   7%|▋         | 722/10000 [00:02<00:39, 236.84it/s]Running 10000 simulations.:   7%|▋         | 746/10000 [00:02<00:39, 235.19it/s]Running 10000 simulations.:   8%|▊         | 770/10000 [00:03<00:39, 234.90it/s]Running 10000 simulations.:   8%|▊         | 794/10000 [00:03<00:39, 235.55it/s]Running 10000 simulations.:   8%|▊         | 818/10000 [00:03<00:39, 234.38it/s]Running 10000 simulations.:   8%|▊         | 842/10000 [00:03<00:39, 233.86it/s]Running 10000 simulations.:   9%|▊         | 866/10000 [00:03<00:39, 234.03it/s]Running 10000 simulations.:   9%|▉         | 890/10000 [00:03<00:38, 233.60it/s]Running 10000 simulations.:   9%|▉         | 914/10000 [00:03<00:39, 232.87it/s]Running 10000 simulations.:   9%|▉         | 938/10000 [00:03<00:39, 231.97it/s]Running 10000 simulations.:  10%|▉         | 962/10000 [00:03<00:38, 231.99it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:04<00:38, 232.04it/s]Running 10000 simulations.:  10%|█         | 1010/10000 [00:04<00:38, 231.90it/s]Running 10000 simulations.:  10%|█         | 1034/10000 [00:04<00:38, 231.56it/s]Running 10000 simulations.:  11%|█         | 1058/10000 [00:04<00:38, 230.65it/s]Running 10000 simulations.:  11%|█         | 1082/10000 [00:04<00:38, 229.96it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:04<00:38, 230.14it/s]Running 10000 simulations.:  11%|█▏        | 1130/10000 [00:04<00:38, 230.11it/s]Running 10000 simulations.:  12%|█▏        | 1154/10000 [00:04<00:38, 230.02it/s]Running 10000 simulations.:  12%|█▏        | 1178/10000 [00:04<00:38, 229.68it/s]Running 10000 simulations.:  12%|█▏        | 1201/10000 [00:04<00:38, 229.56it/s]Running 10000 simulations.:  12%|█▏        | 1225/10000 [00:05<00:38, 229.95it/s]Running 10000 simulations.:  12%|█▏        | 1249/10000 [00:05<00:38, 230.28it/s]Running 10000 simulations.:  13%|█▎        | 1273/10000 [00:05<00:37, 230.00it/s]Running 10000 simulations.:  13%|█▎        | 1297/10000 [00:05<00:37, 230.35it/s]Running 10000 simulations.:  13%|█▎        | 1321/10000 [00:05<00:37, 230.27it/s]Running 10000 simulations.:  13%|█▎        | 1345/10000 [00:05<00:37, 229.80it/s]Running 10000 simulations.:  14%|█▎        | 1368/10000 [00:05<00:37, 229.39it/s]Running 10000 simulations.:  14%|█▍        | 1391/10000 [00:05<00:37, 229.26it/s]Running 10000 simulations.:  14%|█▍        | 1415/10000 [00:05<00:37, 230.26it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:05<00:36, 231.63it/s]Running 10000 simulations.:  15%|█▍        | 1463/10000 [00:06<00:36, 232.01it/s]Running 10000 simulations.:  15%|█▍        | 1487/10000 [00:06<00:36, 232.50it/s]Running 10000 simulations.:  15%|█▌        | 1511/10000 [00:06<00:36, 233.04it/s]Running 10000 simulations.:  15%|█▌        | 1535/10000 [00:06<00:36, 233.01it/s]Running 10000 simulations.:  16%|█▌        | 1559/10000 [00:06<00:36, 232.07it/s]Running 10000 simulations.:  16%|█▌        | 1583/10000 [00:06<00:36, 231.55it/s]Running 10000 simulations.:  16%|█▌        | 1607/10000 [00:06<00:36, 231.20it/s]Running 10000 simulations.:  16%|█▋        | 1631/10000 [00:06<00:36, 230.63it/s]Running 10000 simulations.:  17%|█▋        | 1655/10000 [00:06<00:36, 230.32it/s]Running 10000 simulations.:  17%|█▋        | 1679/10000 [00:07<00:36, 230.05it/s]Running 10000 simulations.:  17%|█▋        | 1703/10000 [00:07<00:36, 230.38it/s]Running 10000 simulations.:  17%|█▋        | 1727/10000 [00:07<00:35, 230.48it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:07<00:35, 230.58it/s]Running 10000 simulations.:  18%|█▊        | 1775/10000 [00:07<00:35, 230.98it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:07<00:35, 231.05it/s]Running 10000 simulations.:  18%|█▊        | 1823/10000 [00:07<00:35, 232.09it/s]Running 10000 simulations.:  18%|█▊        | 1847/10000 [00:07<00:35, 232.22it/s]Running 10000 simulations.:  19%|█▊        | 1871/10000 [00:07<00:34, 233.46it/s]Running 10000 simulations.:  19%|█▉        | 1896/10000 [00:07<00:34, 235.91it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:08<00:34, 235.86it/s]Running 10000 simulations.:  19%|█▉        | 1944/10000 [00:08<00:34, 233.87it/s]Running 10000 simulations.:  20%|█▉        | 1968/10000 [00:08<00:34, 232.90it/s]Running 10000 simulations.:  20%|█▉        | 1992/10000 [00:08<00:34, 232.40it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:08<00:34, 232.00it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:08<00:34, 231.84it/s]Running 10000 simulations.:  21%|██        | 2064/10000 [00:08<00:34, 231.62it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:08<00:34, 231.23it/s]Running 10000 simulations.:  21%|██        | 2112/10000 [00:08<00:33, 232.01it/s]Running 10000 simulations.:  21%|██▏       | 2136/10000 [00:08<00:33, 233.94it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:09<00:33, 234.42it/s]Running 10000 simulations.:  22%|██▏       | 2184/10000 [00:09<00:33, 233.39it/s]Running 10000 simulations.:  22%|██▏       | 2208/10000 [00:09<00:33, 232.01it/s]Running 10000 simulations.:  22%|██▏       | 2232/10000 [00:09<00:33, 231.12it/s]Running 10000 simulations.:  23%|██▎       | 2256/10000 [00:09<00:33, 230.72it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:09<00:33, 231.39it/s]Running 10000 simulations.:  23%|██▎       | 2304/10000 [00:09<00:33, 232.15it/s]Running 10000 simulations.:  23%|██▎       | 2328/10000 [00:09<00:33, 232.45it/s]Running 10000 simulations.:  24%|██▎       | 2352/10000 [00:09<00:32, 233.07it/s]Running 10000 simulations.:  24%|██▍       | 2376/10000 [00:10<00:32, 232.80it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:10<00:32, 231.78it/s]Running 10000 simulations.:  24%|██▍       | 2424/10000 [00:10<00:32, 231.23it/s]Running 10000 simulations.:  24%|██▍       | 2448/10000 [00:10<00:32, 231.04it/s]Running 10000 simulations.:  25%|██▍       | 2473/10000 [00:10<00:31, 236.28it/s]Running 10000 simulations.:  25%|██▍       | 2499/10000 [00:10<00:30, 242.08it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:10<00:30, 246.16it/s]Running 10000 simulations.:  26%|██▌       | 2551/10000 [00:10<00:29, 248.87it/s]Running 10000 simulations.:  26%|██▌       | 2577/10000 [00:10<00:29, 250.41it/s]Running 10000 simulations.:  26%|██▌       | 2603/10000 [00:10<00:29, 250.56it/s]Running 10000 simulations.:  26%|██▋       | 2629/10000 [00:11<00:29, 251.24it/s]Running 10000 simulations.:  27%|██▋       | 2655/10000 [00:11<00:29, 251.56it/s]Running 10000 simulations.:  27%|██▋       | 2681/10000 [00:11<00:29, 251.72it/s]Running 10000 simulations.:  27%|██▋       | 2707/10000 [00:11<00:29, 246.17it/s]Running 10000 simulations.:  27%|██▋       | 2732/10000 [00:11<00:29, 242.88it/s]Running 10000 simulations.:  28%|██▊       | 2757/10000 [00:11<00:30, 240.36it/s]Running 10000 simulations.:  28%|██▊       | 2782/10000 [00:11<00:30, 237.39it/s]Running 10000 simulations.:  28%|██▊       | 2806/10000 [00:11<00:30, 235.47it/s]Running 10000 simulations.:  28%|██▊       | 2830/10000 [00:11<00:30, 234.27it/s]Running 10000 simulations.:  29%|██▊       | 2854/10000 [00:11<00:30, 233.62it/s]Running 10000 simulations.:  29%|██▉       | 2878/10000 [00:12<00:30, 233.74it/s]Running 10000 simulations.:  29%|██▉       | 2902/10000 [00:12<00:30, 234.46it/s]Running 10000 simulations.:  29%|██▉       | 2926/10000 [00:12<00:30, 234.93it/s]Running 10000 simulations.:  30%|██▉       | 2950/10000 [00:12<00:29, 235.33it/s]Running 10000 simulations.:  30%|██▉       | 2974/10000 [00:12<00:29, 234.89it/s]Running 10000 simulations.:  30%|██▉       | 2998/10000 [00:12<00:29, 235.65it/s]Running 10000 simulations.:  30%|███       | 3022/10000 [00:12<00:29, 235.87it/s]Running 10000 simulations.:  30%|███       | 3046/10000 [00:12<00:30, 229.97it/s]Running 10000 simulations.:  31%|███       | 3070/10000 [00:12<00:31, 217.15it/s]Running 10000 simulations.:  31%|███       | 3092/10000 [00:13<00:33, 208.68it/s]Running 10000 simulations.:  31%|███       | 3114/10000 [00:13<00:33, 203.11it/s]Running 10000 simulations.:  31%|███▏      | 3135/10000 [00:13<00:34, 200.55it/s]Running 10000 simulations.:  32%|███▏      | 3156/10000 [00:13<00:33, 201.35it/s]Running 10000 simulations.:  32%|███▏      | 3177/10000 [00:13<00:33, 201.08it/s]Running 10000 simulations.:  32%|███▏      | 3198/10000 [00:13<00:33, 201.28it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:13<00:33, 203.05it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:13<00:33, 203.98it/s]Running 10000 simulations.:  33%|███▎      | 3261/10000 [00:13<00:33, 203.87it/s]Running 10000 simulations.:  33%|███▎      | 3282/10000 [00:14<00:32, 205.49it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:14<00:32, 205.79it/s]Running 10000 simulations.:  33%|███▎      | 3325/10000 [00:14<00:32, 207.27it/s]Running 10000 simulations.:  33%|███▎      | 3346/10000 [00:14<00:32, 205.57it/s]Running 10000 simulations.:  34%|███▎      | 3367/10000 [00:14<00:32, 204.37it/s]Running 10000 simulations.:  34%|███▍      | 3388/10000 [00:14<00:32, 202.91it/s]Running 10000 simulations.:  34%|███▍      | 3410/10000 [00:14<00:32, 205.91it/s]Running 10000 simulations.:  34%|███▍      | 3433/10000 [00:14<00:31, 211.50it/s]Running 10000 simulations.:  35%|███▍      | 3456/10000 [00:14<00:30, 214.99it/s]Running 10000 simulations.:  35%|███▍      | 3479/10000 [00:14<00:29, 217.91it/s]Running 10000 simulations.:  35%|███▌      | 3502/10000 [00:15<00:29, 219.74it/s]Running 10000 simulations.:  35%|███▌      | 3525/10000 [00:15<00:30, 212.56it/s]Running 10000 simulations.:  35%|███▌      | 3548/10000 [00:15<00:29, 216.76it/s]Running 10000 simulations.:  36%|███▌      | 3571/10000 [00:15<00:29, 219.50it/s]Running 10000 simulations.:  36%|███▌      | 3594/10000 [00:15<00:28, 221.64it/s]Running 10000 simulations.:  36%|███▌      | 3617/10000 [00:15<00:28, 223.33it/s]Running 10000 simulations.:  36%|███▋      | 3640/10000 [00:15<00:28, 224.47it/s]Running 10000 simulations.:  37%|███▋      | 3663/10000 [00:15<00:28, 225.03it/s]Running 10000 simulations.:  37%|███▋      | 3686/10000 [00:15<00:27, 225.79it/s]Running 10000 simulations.:  37%|███▋      | 3709/10000 [00:15<00:27, 226.25it/s]Running 10000 simulations.:  37%|███▋      | 3732/10000 [00:16<00:27, 226.63it/s]Running 10000 simulations.:  38%|███▊      | 3755/10000 [00:16<00:27, 226.79it/s]Running 10000 simulations.:  38%|███▊      | 3778/10000 [00:16<00:27, 226.82it/s]Running 10000 simulations.:  38%|███▊      | 3801/10000 [00:16<00:27, 227.19it/s]Running 10000 simulations.:  38%|███▊      | 3824/10000 [00:16<00:27, 226.84it/s]Running 10000 simulations.:  38%|███▊      | 3847/10000 [00:16<00:27, 226.30it/s]Running 10000 simulations.:  39%|███▊      | 3870/10000 [00:16<00:27, 226.11it/s]Running 10000 simulations.:  39%|███▉      | 3893/10000 [00:16<00:26, 227.23it/s]Running 10000 simulations.:  39%|███▉      | 3916/10000 [00:16<00:26, 228.05it/s]Running 10000 simulations.:  39%|███▉      | 3939/10000 [00:16<00:26, 228.63it/s]Running 10000 simulations.:  40%|███▉      | 3962/10000 [00:17<00:26, 228.57it/s]Running 10000 simulations.:  40%|███▉      | 3985/10000 [00:17<00:26, 228.72it/s]Running 10000 simulations.:  40%|████      | 4008/10000 [00:17<00:26, 228.82it/s]Running 10000 simulations.:  40%|████      | 4032/10000 [00:17<00:26, 229.23it/s]Running 10000 simulations.:  41%|████      | 4055/10000 [00:17<00:25, 229.46it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:17<00:25, 229.50it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:17<00:25, 230.12it/s]Running 10000 simulations.:  41%|████▏     | 4126/10000 [00:17<00:25, 229.93it/s]Running 10000 simulations.:  42%|████▏     | 4150/10000 [00:17<00:25, 230.12it/s]Running 10000 simulations.:  42%|████▏     | 4174/10000 [00:17<00:25, 230.27it/s]Running 10000 simulations.:  42%|████▏     | 4198/10000 [00:18<00:25, 230.33it/s]Running 10000 simulations.:  42%|████▏     | 4222/10000 [00:18<00:25, 228.93it/s]Running 10000 simulations.:  42%|████▏     | 4245/10000 [00:18<00:25, 228.01it/s]Running 10000 simulations.:  43%|████▎     | 4268/10000 [00:18<00:25, 228.19it/s]Running 10000 simulations.:  43%|████▎     | 4291/10000 [00:18<00:24, 228.41it/s]Running 10000 simulations.:  43%|████▎     | 4314/10000 [00:18<00:24, 228.44it/s]Running 10000 simulations.:  43%|████▎     | 4337/10000 [00:18<00:24, 228.54it/s]Running 10000 simulations.:  44%|████▎     | 4361/10000 [00:18<00:24, 229.75it/s]Running 10000 simulations.:  44%|████▍     | 4385/10000 [00:18<00:24, 230.58it/s]Running 10000 simulations.:  44%|████▍     | 4409/10000 [00:19<00:24, 231.31it/s]Running 10000 simulations.:  44%|████▍     | 4433/10000 [00:19<00:24, 231.86it/s]Running 10000 simulations.:  45%|████▍     | 4457/10000 [00:19<00:23, 232.45it/s]Running 10000 simulations.:  45%|████▍     | 4481/10000 [00:19<00:23, 233.26it/s]Running 10000 simulations.:  45%|████▌     | 4505/10000 [00:19<00:23, 233.60it/s]Running 10000 simulations.:  45%|████▌     | 4529/10000 [00:19<00:23, 233.73it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:19<00:23, 232.79it/s]Running 10000 simulations.:  46%|████▌     | 4577/10000 [00:19<00:23, 231.96it/s]Running 10000 simulations.:  46%|████▌     | 4601/10000 [00:19<00:23, 231.66it/s]Running 10000 simulations.:  46%|████▋     | 4625/10000 [00:19<00:23, 231.20it/s]Running 10000 simulations.:  46%|████▋     | 4649/10000 [00:20<00:23, 230.55it/s]Running 10000 simulations.:  47%|████▋     | 4673/10000 [00:20<00:23, 230.01it/s]Running 10000 simulations.:  47%|████▋     | 4697/10000 [00:20<00:23, 229.98it/s]Running 10000 simulations.:  47%|████▋     | 4721/10000 [00:20<00:22, 230.22it/s]Running 10000 simulations.:  47%|████▋     | 4745/10000 [00:20<00:22, 230.79it/s]Running 10000 simulations.:  48%|████▊     | 4769/10000 [00:20<00:22, 231.20it/s]Running 10000 simulations.:  48%|████▊     | 4793/10000 [00:20<00:22, 231.63it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:20<00:22, 231.80it/s]Running 10000 simulations.:  48%|████▊     | 4841/10000 [00:20<00:22, 231.53it/s]Running 10000 simulations.:  49%|████▊     | 4865/10000 [00:20<00:22, 231.31it/s]Running 10000 simulations.:  49%|████▉     | 4889/10000 [00:21<00:22, 231.69it/s]Running 10000 simulations.:  49%|████▉     | 4913/10000 [00:21<00:21, 232.22it/s]Running 10000 simulations.:  49%|████▉     | 4937/10000 [00:21<00:21, 231.47it/s]Running 10000 simulations.:  50%|████▉     | 4961/10000 [00:21<00:21, 231.62it/s]Running 10000 simulations.:  50%|████▉     | 4985/10000 [00:21<00:21, 232.15it/s]Running 10000 simulations.:  50%|█████     | 5009/10000 [00:21<00:21, 232.66it/s]Running 10000 simulations.:  50%|█████     | 5033/10000 [00:21<00:21, 233.64it/s]Running 10000 simulations.:  51%|█████     | 5057/10000 [00:21<00:21, 232.99it/s]Running 10000 simulations.:  51%|█████     | 5081/10000 [00:21<00:21, 233.20it/s]Running 10000 simulations.:  51%|█████     | 5105/10000 [00:22<00:21, 232.83it/s]Running 10000 simulations.:  51%|█████▏    | 5129/10000 [00:22<00:20, 232.92it/s]Running 10000 simulations.:  52%|█████▏    | 5153/10000 [00:22<00:20, 232.85it/s]Running 10000 simulations.:  52%|█████▏    | 5177/10000 [00:22<00:20, 232.23it/s]Running 10000 simulations.:  52%|█████▏    | 5201/10000 [00:22<00:20, 232.44it/s]Running 10000 simulations.:  52%|█████▏    | 5225/10000 [00:22<00:20, 231.84it/s]Running 10000 simulations.:  52%|█████▏    | 5249/10000 [00:22<00:20, 232.02it/s]Running 10000 simulations.:  53%|█████▎    | 5273/10000 [00:22<00:20, 231.61it/s]Running 10000 simulations.:  53%|█████▎    | 5297/10000 [00:22<00:20, 231.59it/s]Running 10000 simulations.:  53%|█████▎    | 5321/10000 [00:22<00:20, 231.19it/s]Running 10000 simulations.:  53%|█████▎    | 5345/10000 [00:23<00:20, 230.80it/s]Running 10000 simulations.:  54%|█████▎    | 5369/10000 [00:23<00:20, 230.57it/s]Running 10000 simulations.:  54%|█████▍    | 5393/10000 [00:23<00:19, 230.73it/s]Running 10000 simulations.:  54%|█████▍    | 5417/10000 [00:23<00:19, 230.47it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:23<00:19, 230.20it/s]Running 10000 simulations.:  55%|█████▍    | 5465/10000 [00:23<00:19, 229.98it/s]Running 10000 simulations.:  55%|█████▍    | 5489/10000 [00:23<00:19, 230.13it/s]Running 10000 simulations.:  55%|█████▌    | 5513/10000 [00:23<00:19, 229.87it/s]Running 10000 simulations.:  55%|█████▌    | 5536/10000 [00:23<00:19, 229.79it/s]Running 10000 simulations.:  56%|█████▌    | 5559/10000 [00:23<00:19, 229.82it/s]Running 10000 simulations.:  56%|█████▌    | 5583/10000 [00:24<00:19, 230.03it/s]Running 10000 simulations.:  56%|█████▌    | 5607/10000 [00:24<00:19, 230.96it/s]Running 10000 simulations.:  56%|█████▋    | 5631/10000 [00:24<00:18, 231.58it/s]Running 10000 simulations.:  57%|█████▋    | 5655/10000 [00:24<00:18, 232.10it/s]Running 10000 simulations.:  57%|█████▋    | 5679/10000 [00:24<00:18, 232.18it/s]Running 10000 simulations.:  57%|█████▋    | 5703/10000 [00:24<00:18, 232.27it/s]Running 10000 simulations.:  57%|█████▋    | 5727/10000 [00:24<00:18, 231.95it/s]Running 10000 simulations.:  58%|█████▊    | 5751/10000 [00:24<00:18, 231.78it/s]Running 10000 simulations.:  58%|█████▊    | 5775/10000 [00:24<00:18, 231.17it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:25<00:18, 230.99it/s]Running 10000 simulations.:  58%|█████▊    | 5823/10000 [00:25<00:18, 230.72it/s]Running 10000 simulations.:  58%|█████▊    | 5847/10000 [00:25<00:17, 230.93it/s]Running 10000 simulations.:  59%|█████▊    | 5871/10000 [00:25<00:17, 230.90it/s]Running 10000 simulations.:  59%|█████▉    | 5895/10000 [00:25<00:17, 230.83it/s]Running 10000 simulations.:  59%|█████▉    | 5919/10000 [00:25<00:17, 230.11it/s]Running 10000 simulations.:  59%|█████▉    | 5943/10000 [00:25<00:17, 230.05it/s]Running 10000 simulations.:  60%|█████▉    | 5967/10000 [00:25<00:17, 230.66it/s]Running 10000 simulations.:  60%|█████▉    | 5991/10000 [00:25<00:17, 230.89it/s]Running 10000 simulations.:  60%|██████    | 6015/10000 [00:25<00:17, 231.05it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:26<00:17, 230.79it/s]Running 10000 simulations.:  61%|██████    | 6063/10000 [00:26<00:17, 230.18it/s]Running 10000 simulations.:  61%|██████    | 6087/10000 [00:26<00:17, 229.66it/s]Running 10000 simulations.:  61%|██████    | 6110/10000 [00:26<00:16, 229.70it/s]Running 10000 simulations.:  61%|██████▏   | 6133/10000 [00:26<00:16, 229.69it/s]Running 10000 simulations.:  62%|██████▏   | 6158/10000 [00:26<00:16, 234.21it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:26<00:15, 239.93it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:26<00:15, 244.57it/s]Running 10000 simulations.:  62%|██████▏   | 6236/10000 [00:26<00:15, 246.28it/s]Running 10000 simulations.:  63%|██████▎   | 6262/10000 [00:26<00:15, 247.47it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:27<00:14, 248.84it/s]Running 10000 simulations.:  63%|██████▎   | 6314/10000 [00:27<00:14, 251.24it/s]Running 10000 simulations.:  63%|██████▎   | 6340/10000 [00:27<00:14, 250.60it/s]Running 10000 simulations.:  64%|██████▎   | 6366/10000 [00:27<00:14, 249.93it/s]Running 10000 simulations.:  64%|██████▍   | 6392/10000 [00:27<00:14, 247.85it/s]Running 10000 simulations.:  64%|██████▍   | 6419/10000 [00:27<00:14, 251.48it/s]Running 10000 simulations.:  64%|██████▍   | 6445/10000 [00:27<00:14, 253.42it/s]Running 10000 simulations.:  65%|██████▍   | 6471/10000 [00:27<00:13, 253.61it/s]Running 10000 simulations.:  65%|██████▍   | 6497/10000 [00:27<00:13, 251.85it/s]Running 10000 simulations.:  65%|██████▌   | 6523/10000 [00:28<00:14, 246.36it/s]Running 10000 simulations.:  65%|██████▌   | 6548/10000 [00:28<00:14, 241.49it/s]Running 10000 simulations.:  66%|██████▌   | 6573/10000 [00:28<00:14, 238.10it/s]Running 10000 simulations.:  66%|██████▌   | 6597/10000 [00:28<00:14, 236.25it/s]Running 10000 simulations.:  66%|██████▌   | 6621/10000 [00:28<00:14, 235.61it/s]Running 10000 simulations.:  66%|██████▋   | 6645/10000 [00:28<00:14, 235.09it/s]Running 10000 simulations.:  67%|██████▋   | 6669/10000 [00:28<00:14, 234.99it/s]Running 10000 simulations.:  67%|██████▋   | 6693/10000 [00:28<00:14, 234.69it/s]Running 10000 simulations.:  67%|██████▋   | 6717/10000 [00:28<00:14, 233.68it/s]Running 10000 simulations.:  67%|██████▋   | 6741/10000 [00:28<00:13, 232.88it/s]Running 10000 simulations.:  68%|██████▊   | 6765/10000 [00:29<00:14, 226.37it/s]Running 10000 simulations.:  68%|██████▊   | 6788/10000 [00:29<00:14, 219.97it/s]Running 10000 simulations.:  68%|██████▊   | 6811/10000 [00:29<00:14, 216.69it/s]Running 10000 simulations.:  68%|██████▊   | 6833/10000 [00:29<00:14, 213.83it/s]Running 10000 simulations.:  69%|██████▊   | 6855/10000 [00:29<00:14, 211.65it/s]Running 10000 simulations.:  69%|██████▉   | 6877/10000 [00:29<00:14, 210.27it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:29<00:14, 209.28it/s]Running 10000 simulations.:  69%|██████▉   | 6920/10000 [00:29<00:14, 208.39it/s]Running 10000 simulations.:  69%|██████▉   | 6941/10000 [00:29<00:14, 207.78it/s]Running 10000 simulations.:  70%|██████▉   | 6962/10000 [00:30<00:14, 207.09it/s]Running 10000 simulations.:  70%|██████▉   | 6983/10000 [00:30<00:14, 207.11it/s]Running 10000 simulations.:  70%|███████   | 7004/10000 [00:30<00:14, 207.58it/s]Running 10000 simulations.:  70%|███████   | 7025/10000 [00:30<00:14, 208.10it/s]Running 10000 simulations.:  70%|███████   | 7046/10000 [00:30<00:14, 208.61it/s]Running 10000 simulations.:  71%|███████   | 7069/10000 [00:30<00:13, 214.41it/s]Running 10000 simulations.:  71%|███████   | 7095/10000 [00:30<00:12, 225.10it/s]Running 10000 simulations.:  71%|███████   | 7120/10000 [00:30<00:12, 229.64it/s]Running 10000 simulations.:  71%|███████▏  | 7147/10000 [00:30<00:11, 238.64it/s]Running 10000 simulations.:  72%|███████▏  | 7174/10000 [00:30<00:11, 245.68it/s]Running 10000 simulations.:  72%|███████▏  | 7200/10000 [00:31<00:11, 249.57it/s]Running 10000 simulations.:  72%|███████▏  | 7226/10000 [00:31<00:11, 249.57it/s]Running 10000 simulations.:  73%|███████▎  | 7252/10000 [00:31<00:11, 241.18it/s]Running 10000 simulations.:  73%|███████▎  | 7277/10000 [00:31<00:11, 229.97it/s]Running 10000 simulations.:  73%|███████▎  | 7301/10000 [00:31<00:12, 221.86it/s]Running 10000 simulations.:  73%|███████▎  | 7324/10000 [00:31<00:12, 217.22it/s]Running 10000 simulations.:  73%|███████▎  | 7346/10000 [00:31<00:12, 214.14it/s]Running 10000 simulations.:  74%|███████▎  | 7368/10000 [00:31<00:12, 211.60it/s]Running 10000 simulations.:  74%|███████▍  | 7390/10000 [00:31<00:12, 210.17it/s]Running 10000 simulations.:  74%|███████▍  | 7412/10000 [00:32<00:12, 209.10it/s]Running 10000 simulations.:  74%|███████▍  | 7433/10000 [00:32<00:12, 208.32it/s]Running 10000 simulations.:  75%|███████▍  | 7454/10000 [00:32<00:12, 207.75it/s]Running 10000 simulations.:  75%|███████▍  | 7475/10000 [00:32<00:12, 208.04it/s]Running 10000 simulations.:  75%|███████▍  | 7496/10000 [00:32<00:12, 207.91it/s]Running 10000 simulations.:  75%|███████▌  | 7517/10000 [00:32<00:11, 207.93it/s]Running 10000 simulations.:  75%|███████▌  | 7538/10000 [00:32<00:11, 207.77it/s]Running 10000 simulations.:  76%|███████▌  | 7559/10000 [00:32<00:11, 208.18it/s]Running 10000 simulations.:  76%|███████▌  | 7580/10000 [00:32<00:11, 207.56it/s]Running 10000 simulations.:  76%|███████▌  | 7601/10000 [00:32<00:11, 207.50it/s]Running 10000 simulations.:  76%|███████▌  | 7624/10000 [00:33<00:11, 213.19it/s]Running 10000 simulations.:  76%|███████▋  | 7647/10000 [00:33<00:10, 217.62it/s]Running 10000 simulations.:  77%|███████▋  | 7671/10000 [00:33<00:10, 221.96it/s]Running 10000 simulations.:  77%|███████▋  | 7695/10000 [00:33<00:10, 224.86it/s]Running 10000 simulations.:  77%|███████▋  | 7719/10000 [00:33<00:10, 226.84it/s]Running 10000 simulations.:  77%|███████▋  | 7743/10000 [00:33<00:09, 228.96it/s]Running 10000 simulations.:  78%|███████▊  | 7767/10000 [00:33<00:09, 229.81it/s]Running 10000 simulations.:  78%|███████▊  | 7791/10000 [00:33<00:09, 230.55it/s]Running 10000 simulations.:  78%|███████▊  | 7815/10000 [00:33<00:09, 231.16it/s]Running 10000 simulations.:  78%|███████▊  | 7839/10000 [00:33<00:09, 231.74it/s]Running 10000 simulations.:  79%|███████▊  | 7863/10000 [00:34<00:09, 232.30it/s]Running 10000 simulations.:  79%|███████▉  | 7887/10000 [00:34<00:09, 233.28it/s]Running 10000 simulations.:  79%|███████▉  | 7911/10000 [00:34<00:08, 234.05it/s]Running 10000 simulations.:  79%|███████▉  | 7935/10000 [00:34<00:08, 234.67it/s]Running 10000 simulations.:  80%|███████▉  | 7959/10000 [00:34<00:08, 234.74it/s]Running 10000 simulations.:  80%|███████▉  | 7983/10000 [00:34<00:08, 234.53it/s]Running 10000 simulations.:  80%|████████  | 8007/10000 [00:34<00:08, 234.45it/s]Running 10000 simulations.:  80%|████████  | 8031/10000 [00:34<00:08, 234.41it/s]Running 10000 simulations.:  81%|████████  | 8055/10000 [00:34<00:08, 234.67it/s]Running 10000 simulations.:  81%|████████  | 8079/10000 [00:34<00:08, 235.42it/s]Running 10000 simulations.:  81%|████████  | 8103/10000 [00:35<00:08, 236.02it/s]Running 10000 simulations.:  81%|████████▏ | 8127/10000 [00:35<00:07, 236.26it/s]Running 10000 simulations.:  82%|████████▏ | 8151/10000 [00:35<00:07, 236.35it/s]Running 10000 simulations.:  82%|████████▏ | 8175/10000 [00:35<00:07, 236.53it/s]Running 10000 simulations.:  82%|████████▏ | 8199/10000 [00:35<00:07, 236.63it/s]Running 10000 simulations.:  82%|████████▏ | 8223/10000 [00:35<00:07, 235.24it/s]Running 10000 simulations.:  82%|████████▏ | 8247/10000 [00:35<00:07, 235.68it/s]Running 10000 simulations.:  83%|████████▎ | 8271/10000 [00:35<00:07, 235.42it/s]Running 10000 simulations.:  83%|████████▎ | 8295/10000 [00:35<00:07, 235.38it/s]Running 10000 simulations.:  83%|████████▎ | 8319/10000 [00:36<00:07, 235.27it/s]Running 10000 simulations.:  83%|████████▎ | 8343/10000 [00:36<00:07, 235.37it/s]Running 10000 simulations.:  84%|████████▎ | 8367/10000 [00:36<00:06, 235.35it/s]Running 10000 simulations.:  84%|████████▍ | 8391/10000 [00:36<00:06, 235.43it/s]Running 10000 simulations.:  84%|████████▍ | 8415/10000 [00:36<00:06, 235.37it/s]Running 10000 simulations.:  84%|████████▍ | 8439/10000 [00:36<00:06, 234.88it/s]Running 10000 simulations.:  85%|████████▍ | 8463/10000 [00:36<00:06, 234.60it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [00:36<00:06, 233.37it/s]Running 10000 simulations.:  85%|████████▌ | 8511/10000 [00:36<00:06, 233.14it/s]Running 10000 simulations.:  85%|████████▌ | 8535/10000 [00:36<00:06, 233.40it/s]Running 10000 simulations.:  86%|████████▌ | 8559/10000 [00:37<00:06, 232.74it/s]Running 10000 simulations.:  86%|████████▌ | 8583/10000 [00:37<00:06, 232.24it/s]Running 10000 simulations.:  86%|████████▌ | 8607/10000 [00:37<00:05, 232.31it/s]Running 10000 simulations.:  86%|████████▋ | 8631/10000 [00:37<00:05, 232.77it/s]Running 10000 simulations.:  87%|████████▋ | 8655/10000 [00:37<00:05, 233.15it/s]Running 10000 simulations.:  87%|████████▋ | 8679/10000 [00:37<00:05, 232.60it/s]Running 10000 simulations.:  87%|████████▋ | 8703/10000 [00:37<00:05, 230.30it/s]Running 10000 simulations.:  87%|████████▋ | 8727/10000 [00:37<00:05, 230.40it/s]Running 10000 simulations.:  88%|████████▊ | 8751/10000 [00:37<00:05, 231.19it/s]Running 10000 simulations.:  88%|████████▊ | 8775/10000 [00:37<00:05, 231.32it/s]Running 10000 simulations.:  88%|████████▊ | 8799/10000 [00:38<00:05, 231.88it/s]Running 10000 simulations.:  88%|████████▊ | 8823/10000 [00:38<00:05, 233.20it/s]Running 10000 simulations.:  88%|████████▊ | 8847/10000 [00:38<00:04, 234.10it/s]Running 10000 simulations.:  89%|████████▊ | 8871/10000 [00:38<00:04, 233.69it/s]Running 10000 simulations.:  89%|████████▉ | 8895/10000 [00:38<00:04, 233.30it/s]Running 10000 simulations.:  89%|████████▉ | 8919/10000 [00:38<00:04, 233.22it/s]Running 10000 simulations.:  89%|████████▉ | 8943/10000 [00:38<00:04, 233.03it/s]Running 10000 simulations.:  90%|████████▉ | 8967/10000 [00:38<00:04, 232.70it/s]Running 10000 simulations.:  90%|████████▉ | 8991/10000 [00:38<00:04, 232.51it/s]Running 10000 simulations.:  90%|█████████ | 9015/10000 [00:39<00:04, 233.24it/s]Running 10000 simulations.:  90%|█████████ | 9039/10000 [00:39<00:04, 232.86it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [00:39<00:04, 233.56it/s]Running 10000 simulations.:  91%|█████████ | 9087/10000 [00:39<00:03, 234.03it/s]Running 10000 simulations.:  91%|█████████ | 9111/10000 [00:39<00:03, 233.92it/s]Running 10000 simulations.:  91%|█████████▏| 9135/10000 [00:39<00:03, 234.10it/s]Running 10000 simulations.:  92%|█████████▏| 9159/10000 [00:39<00:03, 234.35it/s]Running 10000 simulations.:  92%|█████████▏| 9183/10000 [00:39<00:03, 234.42it/s]Running 10000 simulations.:  92%|█████████▏| 9207/10000 [00:39<00:03, 235.76it/s]Running 10000 simulations.:  92%|█████████▏| 9233/10000 [00:39<00:03, 241.83it/s]Running 10000 simulations.:  93%|█████████▎| 9258/10000 [00:40<00:03, 240.69it/s]Running 10000 simulations.:  93%|█████████▎| 9285/10000 [00:40<00:02, 247.24it/s]Running 10000 simulations.:  93%|█████████▎| 9312/10000 [00:40<00:02, 251.74it/s]Running 10000 simulations.:  93%|█████████▎| 9338/10000 [00:40<00:02, 251.20it/s]Running 10000 simulations.:  94%|█████████▎| 9364/10000 [00:40<00:02, 248.64it/s]Running 10000 simulations.:  94%|█████████▍| 9389/10000 [00:40<00:02, 241.24it/s]Running 10000 simulations.:  94%|█████████▍| 9414/10000 [00:40<00:02, 229.26it/s]Running 10000 simulations.:  94%|█████████▍| 9438/10000 [00:40<00:02, 221.20it/s]Running 10000 simulations.:  95%|█████████▍| 9461/10000 [00:40<00:02, 216.31it/s]Running 10000 simulations.:  95%|█████████▍| 9483/10000 [00:41<00:02, 212.94it/s]Running 10000 simulations.:  95%|█████████▌| 9505/10000 [00:41<00:02, 211.16it/s]Running 10000 simulations.:  95%|█████████▌| 9527/10000 [00:41<00:02, 209.97it/s]Running 10000 simulations.:  95%|█████████▌| 9549/10000 [00:41<00:02, 209.14it/s]Running 10000 simulations.:  96%|█████████▌| 9571/10000 [00:41<00:02, 210.64it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:41<00:01, 212.94it/s]Running 10000 simulations.:  96%|█████████▌| 9615/10000 [00:41<00:01, 214.11it/s]Running 10000 simulations.:  96%|█████████▋| 9637/10000 [00:41<00:01, 214.93it/s]Running 10000 simulations.:  97%|█████████▋| 9660/10000 [00:41<00:01, 216.83it/s]Running 10000 simulations.:  97%|█████████▋| 9682/10000 [00:41<00:01, 217.49it/s]Running 10000 simulations.:  97%|█████████▋| 9704/10000 [00:42<00:01, 213.77it/s]Running 10000 simulations.:  97%|█████████▋| 9726/10000 [00:42<00:01, 210.96it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [00:42<00:01, 208.76it/s]Running 10000 simulations.:  98%|█████████▊| 9769/10000 [00:42<00:01, 207.34it/s]Running 10000 simulations.:  98%|█████████▊| 9790/10000 [00:42<00:01, 206.13it/s]Running 10000 simulations.:  98%|█████████▊| 9811/10000 [00:42<00:00, 205.76it/s]Running 10000 simulations.:  98%|█████████▊| 9833/10000 [00:42<00:00, 207.04it/s]Running 10000 simulations.:  99%|█████████▊| 9854/10000 [00:42<00:00, 206.50it/s]Running 10000 simulations.:  99%|█████████▉| 9875/10000 [00:42<00:00, 206.34it/s]Running 10000 simulations.:  99%|█████████▉| 9896/10000 [00:42<00:00, 206.22it/s]Running 10000 simulations.:  99%|█████████▉| 9917/10000 [00:43<00:00, 205.94it/s]Running 10000 simulations.:  99%|█████████▉| 9938/10000 [00:43<00:00, 205.94it/s]Running 10000 simulations.: 100%|█████████▉| 9959/10000 [00:43<00:00, 205.73it/s]Running 10000 simulations.: 100%|█████████▉| 9980/10000 [00:43<00:00, 205.40it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:43<00:00, 229.93it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 251.25it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<00:39, 250.54it/s]Running 10000 simulations.:   1%|          | 76/10000 [00:00<00:39, 249.58it/s]Running 10000 simulations.:   1%|          | 101/10000 [00:00<00:39, 248.75it/s]Running 10000 simulations.:   1%|▏         | 126/10000 [00:00<00:39, 248.25it/s]Running 10000 simulations.:   2%|▏         | 151/10000 [00:00<00:39, 247.67it/s]Running 10000 simulations.:   2%|▏         | 176/10000 [00:00<00:39, 247.07it/s]Running 10000 simulations.:   2%|▏         | 201/10000 [00:00<00:39, 247.05it/s]Running 10000 simulations.:   2%|▏         | 226/10000 [00:00<00:39, 247.20it/s]Running 10000 simulations.:   3%|▎         | 251/10000 [00:01<00:39, 246.92it/s]Running 10000 simulations.:   3%|▎         | 276/10000 [00:01<00:39, 246.13it/s]Running 10000 simulations.:   3%|▎         | 301/10000 [00:01<00:39, 246.22it/s]Running 10000 simulations.:   3%|▎         | 326/10000 [00:01<00:39, 247.02it/s]Running 10000 simulations.:   4%|▎         | 351/10000 [00:01<00:39, 246.54it/s]Running 10000 simulations.:   4%|▍         | 376/10000 [00:01<00:39, 246.63it/s]Running 10000 simulations.:   4%|▍         | 401/10000 [00:01<00:38, 246.63it/s]Running 10000 simulations.:   4%|▍         | 426/10000 [00:01<00:39, 245.35it/s]Running 10000 simulations.:   5%|▍         | 451/10000 [00:01<00:39, 244.77it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:01<00:39, 243.25it/s]Running 10000 simulations.:   5%|▌         | 501/10000 [00:02<00:39, 242.56it/s]Running 10000 simulations.:   5%|▌         | 526/10000 [00:02<00:39, 242.90it/s]Running 10000 simulations.:   6%|▌         | 551/10000 [00:02<00:38, 242.84it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:02<00:38, 243.31it/s]Running 10000 simulations.:   6%|▌         | 601/10000 [00:02<00:38, 244.09it/s]Running 10000 simulations.:   6%|▋         | 627/10000 [00:02<00:37, 247.08it/s]Running 10000 simulations.:   7%|▋         | 652/10000 [00:02<00:38, 245.74it/s]Running 10000 simulations.:   7%|▋         | 677/10000 [00:02<00:38, 245.04it/s]Running 10000 simulations.:   7%|▋         | 702/10000 [00:02<00:37, 244.81it/s]Running 10000 simulations.:   7%|▋         | 727/10000 [00:02<00:37, 244.30it/s]Running 10000 simulations.:   8%|▊         | 752/10000 [00:03<00:37, 243.65it/s]Running 10000 simulations.:   8%|▊         | 777/10000 [00:03<00:37, 243.89it/s]Running 10000 simulations.:   8%|▊         | 802/10000 [00:03<00:37, 244.38it/s]Running 10000 simulations.:   8%|▊         | 827/10000 [00:03<00:37, 246.00it/s]Running 10000 simulations.:   9%|▊         | 852/10000 [00:03<00:37, 245.52it/s]Running 10000 simulations.:   9%|▉         | 877/10000 [00:03<00:37, 244.84it/s]Running 10000 simulations.:   9%|▉         | 902/10000 [00:03<00:37, 243.72it/s]Running 10000 simulations.:   9%|▉         | 927/10000 [00:03<00:37, 242.31it/s]Running 10000 simulations.:  10%|▉         | 952/10000 [00:03<00:37, 241.00it/s]Running 10000 simulations.:  10%|▉         | 977/10000 [00:03<00:37, 242.80it/s]Running 10000 simulations.:  10%|█         | 1003/10000 [00:04<00:36, 246.39it/s]Running 10000 simulations.:  10%|█         | 1028/10000 [00:04<00:36, 246.52it/s]Running 10000 simulations.:  11%|█         | 1053/10000 [00:04<00:36, 246.02it/s]Running 10000 simulations.:  11%|█         | 1078/10000 [00:04<00:36, 243.94it/s]Running 10000 simulations.:  11%|█         | 1103/10000 [00:04<00:37, 239.70it/s]Running 10000 simulations.:  11%|█▏        | 1128/10000 [00:04<00:36, 240.09it/s]Running 10000 simulations.:  12%|█▏        | 1153/10000 [00:04<00:36, 241.94it/s]Running 10000 simulations.:  12%|█▏        | 1179/10000 [00:04<00:36, 244.74it/s]Running 10000 simulations.:  12%|█▏        | 1204/10000 [00:04<00:36, 243.08it/s]Running 10000 simulations.:  12%|█▏        | 1229/10000 [00:05<00:36, 242.87it/s]Running 10000 simulations.:  13%|█▎        | 1254/10000 [00:05<00:36, 240.31it/s]Running 10000 simulations.:  13%|█▎        | 1279/10000 [00:05<00:36, 238.69it/s]Running 10000 simulations.:  13%|█▎        | 1303/10000 [00:05<00:36, 238.05it/s]Running 10000 simulations.:  13%|█▎        | 1327/10000 [00:05<00:36, 238.00it/s]Running 10000 simulations.:  14%|█▎        | 1351/10000 [00:05<00:36, 237.04it/s]Running 10000 simulations.:  14%|█▍        | 1376/10000 [00:05<00:36, 238.11it/s]Running 10000 simulations.:  14%|█▍        | 1401/10000 [00:05<00:35, 240.16it/s]Running 10000 simulations.:  14%|█▍        | 1426/10000 [00:05<00:35, 240.60it/s]Running 10000 simulations.:  15%|█▍        | 1451/10000 [00:05<00:35, 240.20it/s]Running 10000 simulations.:  15%|█▍        | 1476/10000 [00:06<00:35, 242.16it/s]Running 10000 simulations.:  15%|█▌        | 1501/10000 [00:06<00:35, 242.01it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:06<00:35, 237.85it/s]Running 10000 simulations.:  16%|█▌        | 1550/10000 [00:06<00:37, 227.67it/s]Running 10000 simulations.:  16%|█▌        | 1573/10000 [00:06<00:38, 221.23it/s]Running 10000 simulations.:  16%|█▌        | 1596/10000 [00:06<00:38, 216.82it/s]Running 10000 simulations.:  16%|█▌        | 1618/10000 [00:06<00:39, 214.29it/s]Running 10000 simulations.:  16%|█▋        | 1640/10000 [00:06<00:39, 212.07it/s]Running 10000 simulations.:  17%|█▋        | 1662/10000 [00:06<00:39, 210.64it/s]Running 10000 simulations.:  17%|█▋        | 1684/10000 [00:07<00:39, 209.53it/s]Running 10000 simulations.:  17%|█▋        | 1705/10000 [00:07<00:39, 209.07it/s]Running 10000 simulations.:  17%|█▋        | 1726/10000 [00:07<00:39, 207.98it/s]Running 10000 simulations.:  17%|█▋        | 1747/10000 [00:07<00:39, 207.60it/s]Running 10000 simulations.:  18%|█▊        | 1768/10000 [00:07<00:39, 207.39it/s]Running 10000 simulations.:  18%|█▊        | 1789/10000 [00:07<00:39, 207.36it/s]Running 10000 simulations.:  18%|█▊        | 1810/10000 [00:07<00:39, 207.23it/s]Running 10000 simulations.:  18%|█▊        | 1831/10000 [00:07<00:39, 207.52it/s]Running 10000 simulations.:  19%|█▊        | 1852/10000 [00:07<00:39, 205.65it/s]Running 10000 simulations.:  19%|█▊        | 1873/10000 [00:07<00:39, 205.98it/s]Running 10000 simulations.:  19%|█▉        | 1894/10000 [00:08<00:39, 206.88it/s]Running 10000 simulations.:  19%|█▉        | 1915/10000 [00:08<00:38, 207.66it/s]Running 10000 simulations.:  19%|█▉        | 1936/10000 [00:08<00:38, 207.18it/s]Running 10000 simulations.:  20%|█▉        | 1957/10000 [00:08<00:38, 206.83it/s]Running 10000 simulations.:  20%|█▉        | 1978/10000 [00:08<00:40, 196.68it/s]Running 10000 simulations.:  20%|█▉        | 1999/10000 [00:08<00:40, 199.22it/s]Running 10000 simulations.:  20%|██        | 2020/10000 [00:08<00:39, 201.68it/s]Running 10000 simulations.:  20%|██        | 2041/10000 [00:08<00:39, 203.56it/s]Running 10000 simulations.:  21%|██        | 2062/10000 [00:08<00:38, 205.45it/s]Running 10000 simulations.:  21%|██        | 2083/10000 [00:08<00:38, 205.81it/s]Running 10000 simulations.:  21%|██        | 2104/10000 [00:09<00:38, 205.72it/s]Running 10000 simulations.:  21%|██▏       | 2125/10000 [00:09<00:38, 205.53it/s]Running 10000 simulations.:  21%|██▏       | 2146/10000 [00:09<00:38, 205.75it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:09<00:38, 206.01it/s]Running 10000 simulations.:  22%|██▏       | 2188/10000 [00:09<00:37, 206.08it/s]Running 10000 simulations.:  22%|██▏       | 2209/10000 [00:09<00:37, 206.24it/s]Running 10000 simulations.:  22%|██▏       | 2230/10000 [00:09<00:37, 206.33it/s]Running 10000 simulations.:  23%|██▎       | 2252/10000 [00:09<00:37, 209.38it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:09<00:34, 221.81it/s]Running 10000 simulations.:  23%|██▎       | 2304/10000 [00:09<00:33, 231.01it/s]Running 10000 simulations.:  23%|██▎       | 2330/10000 [00:10<00:32, 237.06it/s]Running 10000 simulations.:  24%|██▎       | 2356/10000 [00:10<00:31, 242.27it/s]Running 10000 simulations.:  24%|██▍       | 2382/10000 [00:10<00:30, 246.13it/s]Running 10000 simulations.:  24%|██▍       | 2408/10000 [00:10<00:30, 249.15it/s]Running 10000 simulations.:  24%|██▍       | 2434/10000 [00:10<00:30, 250.64it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:10<00:29, 252.22it/s]Running 10000 simulations.:  25%|██▍       | 2486/10000 [00:10<00:30, 242.63it/s]Running 10000 simulations.:  25%|██▌       | 2511/10000 [00:10<00:32, 230.53it/s]Running 10000 simulations.:  25%|██▌       | 2535/10000 [00:10<00:33, 220.58it/s]Running 10000 simulations.:  26%|██▌       | 2559/10000 [00:11<00:32, 225.64it/s]Running 10000 simulations.:  26%|██▌       | 2584/10000 [00:11<00:32, 230.67it/s]Running 10000 simulations.:  26%|██▌       | 2609/10000 [00:11<00:31, 233.99it/s]Running 10000 simulations.:  26%|██▋       | 2633/10000 [00:11<00:31, 234.96it/s]Running 10000 simulations.:  27%|██▋       | 2657/10000 [00:11<00:31, 235.46it/s]Running 10000 simulations.:  27%|██▋       | 2681/10000 [00:11<00:30, 236.58it/s]Running 10000 simulations.:  27%|██▋       | 2706/10000 [00:11<00:30, 237.65it/s]Running 10000 simulations.:  27%|██▋       | 2731/10000 [00:11<00:30, 239.19it/s]Running 10000 simulations.:  28%|██▊       | 2756/10000 [00:11<00:30, 239.50it/s]Running 10000 simulations.:  28%|██▊       | 2780/10000 [00:11<00:30, 238.90it/s]Running 10000 simulations.:  28%|██▊       | 2804/10000 [00:12<00:30, 238.59it/s]Running 10000 simulations.:  28%|██▊       | 2828/10000 [00:12<00:30, 238.32it/s]Running 10000 simulations.:  29%|██▊       | 2852/10000 [00:12<00:29, 238.68it/s]Running 10000 simulations.:  29%|██▉       | 2876/10000 [00:12<00:29, 237.68it/s]Running 10000 simulations.:  29%|██▉       | 2900/10000 [00:12<00:30, 236.66it/s]Running 10000 simulations.:  29%|██▉       | 2924/10000 [00:12<00:29, 236.35it/s]Running 10000 simulations.:  29%|██▉       | 2948/10000 [00:12<00:29, 236.03it/s]Running 10000 simulations.:  30%|██▉       | 2972/10000 [00:12<00:29, 235.58it/s]Running 10000 simulations.:  30%|██▉       | 2996/10000 [00:12<00:29, 235.93it/s]Running 10000 simulations.:  30%|███       | 3020/10000 [00:12<00:29, 235.26it/s]Running 10000 simulations.:  30%|███       | 3044/10000 [00:13<00:29, 235.15it/s]Running 10000 simulations.:  31%|███       | 3068/10000 [00:13<00:29, 235.04it/s]Running 10000 simulations.:  31%|███       | 3092/10000 [00:13<00:29, 235.11it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:13<00:29, 236.01it/s]Running 10000 simulations.:  31%|███▏      | 3140/10000 [00:13<00:29, 236.44it/s]Running 10000 simulations.:  32%|███▏      | 3164/10000 [00:13<00:28, 236.85it/s]Running 10000 simulations.:  32%|███▏      | 3188/10000 [00:13<00:28, 237.05it/s]Running 10000 simulations.:  32%|███▏      | 3212/10000 [00:13<00:28, 237.46it/s]Running 10000 simulations.:  32%|███▏      | 3236/10000 [00:13<00:28, 236.49it/s]Running 10000 simulations.:  33%|███▎      | 3260/10000 [00:14<00:28, 236.72it/s]Running 10000 simulations.:  33%|███▎      | 3284/10000 [00:14<00:28, 237.06it/s]Running 10000 simulations.:  33%|███▎      | 3308/10000 [00:14<00:28, 237.19it/s]Running 10000 simulations.:  33%|███▎      | 3332/10000 [00:14<00:28, 236.40it/s]Running 10000 simulations.:  34%|███▎      | 3356/10000 [00:14<00:28, 235.94it/s]Running 10000 simulations.:  34%|███▍      | 3380/10000 [00:14<00:28, 236.27it/s]Running 10000 simulations.:  34%|███▍      | 3404/10000 [00:14<00:27, 237.36it/s]Running 10000 simulations.:  34%|███▍      | 3428/10000 [00:14<00:27, 236.75it/s]Running 10000 simulations.:  35%|███▍      | 3452/10000 [00:14<00:27, 235.95it/s]Running 10000 simulations.:  35%|███▍      | 3476/10000 [00:14<00:27, 235.47it/s]Running 10000 simulations.:  35%|███▌      | 3500/10000 [00:15<00:27, 235.81it/s]Running 10000 simulations.:  35%|███▌      | 3524/10000 [00:15<00:27, 236.31it/s]Running 10000 simulations.:  35%|███▌      | 3548/10000 [00:15<00:27, 237.14it/s]Running 10000 simulations.:  36%|███▌      | 3572/10000 [00:15<00:27, 236.99it/s]Running 10000 simulations.:  36%|███▌      | 3596/10000 [00:15<00:26, 237.42it/s]Running 10000 simulations.:  36%|███▌      | 3622/10000 [00:15<00:26, 243.67it/s]Running 10000 simulations.:  36%|███▋      | 3648/10000 [00:15<00:25, 247.77it/s]Running 10000 simulations.:  37%|███▋      | 3674/10000 [00:15<00:25, 249.91it/s]Running 10000 simulations.:  37%|███▋      | 3701/10000 [00:15<00:24, 253.76it/s]Running 10000 simulations.:  37%|███▋      | 3727/10000 [00:15<00:25, 248.89it/s]Running 10000 simulations.:  38%|███▊      | 3753/10000 [00:16<00:24, 250.30it/s]Running 10000 simulations.:  38%|███▊      | 3779/10000 [00:16<00:24, 251.15it/s]Running 10000 simulations.:  38%|███▊      | 3805/10000 [00:16<00:24, 251.46it/s]Running 10000 simulations.:  38%|███▊      | 3831/10000 [00:16<00:24, 252.09it/s]Running 10000 simulations.:  39%|███▊      | 3857/10000 [00:16<00:24, 251.32it/s]Running 10000 simulations.:  39%|███▉      | 3883/10000 [00:16<00:24, 252.09it/s]Running 10000 simulations.:  39%|███▉      | 3909/10000 [00:16<00:24, 251.28it/s]Running 10000 simulations.:  39%|███▉      | 3935/10000 [00:16<00:24, 251.74it/s]Running 10000 simulations.:  40%|███▉      | 3961/10000 [00:16<00:23, 253.38it/s]Running 10000 simulations.:  40%|███▉      | 3987/10000 [00:16<00:23, 253.56it/s]Running 10000 simulations.:  40%|████      | 4013/10000 [00:17<00:23, 251.45it/s]Running 10000 simulations.:  40%|████      | 4040/10000 [00:17<00:23, 254.32it/s]Running 10000 simulations.:  41%|████      | 4067/10000 [00:17<00:23, 256.08it/s]Running 10000 simulations.:  41%|████      | 4093/10000 [00:17<00:23, 249.18it/s]Running 10000 simulations.:  41%|████      | 4118/10000 [00:17<00:24, 244.27it/s]Running 10000 simulations.:  41%|████▏     | 4143/10000 [00:17<00:24, 239.92it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:17<00:24, 237.09it/s]Running 10000 simulations.:  42%|████▏     | 4192/10000 [00:17<00:24, 235.32it/s]Running 10000 simulations.:  42%|████▏     | 4216/10000 [00:17<00:24, 234.64it/s]Running 10000 simulations.:  42%|████▏     | 4240/10000 [00:18<00:24, 234.40it/s]Running 10000 simulations.:  43%|████▎     | 4264/10000 [00:18<00:24, 233.15it/s]Running 10000 simulations.:  43%|████▎     | 4288/10000 [00:18<00:24, 232.65it/s]Running 10000 simulations.:  43%|████▎     | 4312/10000 [00:18<00:24, 232.99it/s]Running 10000 simulations.:  43%|████▎     | 4336/10000 [00:18<00:24, 232.84it/s]Running 10000 simulations.:  44%|████▎     | 4360/10000 [00:18<00:24, 232.42it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:18<00:24, 232.44it/s]Running 10000 simulations.:  44%|████▍     | 4408/10000 [00:18<00:24, 226.25it/s]Running 10000 simulations.:  44%|████▍     | 4431/10000 [00:18<00:25, 219.91it/s]Running 10000 simulations.:  45%|████▍     | 4454/10000 [00:18<00:25, 215.93it/s]Running 10000 simulations.:  45%|████▍     | 4476/10000 [00:19<00:25, 212.75it/s]Running 10000 simulations.:  45%|████▍     | 4498/10000 [00:19<00:26, 210.45it/s]Running 10000 simulations.:  45%|████▌     | 4520/10000 [00:19<00:26, 208.67it/s]Running 10000 simulations.:  45%|████▌     | 4541/10000 [00:19<00:26, 207.30it/s]Running 10000 simulations.:  46%|████▌     | 4562/10000 [00:19<00:26, 206.43it/s]Running 10000 simulations.:  46%|████▌     | 4583/10000 [00:19<00:26, 206.29it/s]Running 10000 simulations.:  46%|████▌     | 4606/10000 [00:19<00:25, 210.70it/s]Running 10000 simulations.:  46%|████▋     | 4630/10000 [00:19<00:24, 216.90it/s]Running 10000 simulations.:  47%|████▋     | 4654/10000 [00:19<00:24, 221.92it/s]Running 10000 simulations.:  47%|████▋     | 4678/10000 [00:20<00:23, 224.69it/s]Running 10000 simulations.:  47%|████▋     | 4702/10000 [00:20<00:23, 227.19it/s]Running 10000 simulations.:  47%|████▋     | 4726/10000 [00:20<00:23, 228.68it/s]Running 10000 simulations.:  48%|████▊     | 4750/10000 [00:20<00:22, 229.34it/s]Running 10000 simulations.:  48%|████▊     | 4773/10000 [00:20<00:22, 229.41it/s]Running 10000 simulations.:  48%|████▊     | 4797/10000 [00:20<00:22, 230.21it/s]Running 10000 simulations.:  48%|████▊     | 4821/10000 [00:20<00:22, 231.18it/s]Running 10000 simulations.:  48%|████▊     | 4845/10000 [00:20<00:22, 231.99it/s]Running 10000 simulations.:  49%|████▊     | 4869/10000 [00:20<00:22, 232.79it/s]Running 10000 simulations.:  49%|████▉     | 4893/10000 [00:20<00:21, 233.12it/s]Running 10000 simulations.:  49%|████▉     | 4917/10000 [00:21<00:21, 231.58it/s]Running 10000 simulations.:  49%|████▉     | 4941/10000 [00:21<00:23, 219.52it/s]Running 10000 simulations.:  50%|████▉     | 4964/10000 [00:21<00:23, 211.43it/s]Running 10000 simulations.:  50%|████▉     | 4986/10000 [00:21<00:24, 206.48it/s]Running 10000 simulations.:  50%|█████     | 5007/10000 [00:21<00:24, 203.08it/s]Running 10000 simulations.:  50%|█████     | 5028/10000 [00:21<00:24, 200.95it/s]Running 10000 simulations.:  50%|█████     | 5049/10000 [00:21<00:24, 199.20it/s]Running 10000 simulations.:  51%|█████     | 5069/10000 [00:21<00:24, 198.22it/s]Running 10000 simulations.:  51%|█████     | 5089/10000 [00:21<00:24, 197.60it/s]Running 10000 simulations.:  51%|█████     | 5112/10000 [00:22<00:23, 205.50it/s]Running 10000 simulations.:  51%|█████▏    | 5137/10000 [00:22<00:22, 216.51it/s]Running 10000 simulations.:  52%|█████▏    | 5162/10000 [00:22<00:21, 224.69it/s]Running 10000 simulations.:  52%|█████▏    | 5187/10000 [00:22<00:20, 230.55it/s]Running 10000 simulations.:  52%|█████▏    | 5212/10000 [00:22<00:20, 234.58it/s]Running 10000 simulations.:  52%|█████▏    | 5237/10000 [00:22<00:20, 237.81it/s]Running 10000 simulations.:  53%|█████▎    | 5262/10000 [00:22<00:19, 240.32it/s]Running 10000 simulations.:  53%|█████▎    | 5287/10000 [00:22<00:19, 242.10it/s]Running 10000 simulations.:  53%|█████▎    | 5312/10000 [00:22<00:19, 243.71it/s]Running 10000 simulations.:  53%|█████▎    | 5337/10000 [00:22<00:19, 244.80it/s]Running 10000 simulations.:  54%|█████▎    | 5362/10000 [00:23<00:18, 244.40it/s]Running 10000 simulations.:  54%|█████▍    | 5387/10000 [00:23<00:18, 243.64it/s]Running 10000 simulations.:  54%|█████▍    | 5412/10000 [00:23<00:18, 243.27it/s]Running 10000 simulations.:  54%|█████▍    | 5437/10000 [00:23<00:18, 242.99it/s]Running 10000 simulations.:  55%|█████▍    | 5462/10000 [00:23<00:18, 242.90it/s]Running 10000 simulations.:  55%|█████▍    | 5487/10000 [00:23<00:18, 244.34it/s]Running 10000 simulations.:  55%|█████▌    | 5512/10000 [00:23<00:18, 245.17it/s]Running 10000 simulations.:  55%|█████▌    | 5537/10000 [00:23<00:18, 245.45it/s]Running 10000 simulations.:  56%|█████▌    | 5562/10000 [00:23<00:18, 245.57it/s]Running 10000 simulations.:  56%|█████▌    | 5587/10000 [00:23<00:17, 245.19it/s]Running 10000 simulations.:  56%|█████▌    | 5612/10000 [00:24<00:17, 245.21it/s]Running 10000 simulations.:  56%|█████▋    | 5637/10000 [00:24<00:17, 244.44it/s]Running 10000 simulations.:  57%|█████▋    | 5662/10000 [00:24<00:17, 243.72it/s]Running 10000 simulations.:  57%|█████▋    | 5687/10000 [00:24<00:17, 243.60it/s]Running 10000 simulations.:  57%|█████▋    | 5712/10000 [00:24<00:17, 243.14it/s]Running 10000 simulations.:  57%|█████▋    | 5737/10000 [00:24<00:17, 243.35it/s]Running 10000 simulations.:  58%|█████▊    | 5762/10000 [00:24<00:17, 241.41it/s]Running 10000 simulations.:  58%|█████▊    | 5787/10000 [00:24<00:17, 240.83it/s]Running 10000 simulations.:  58%|█████▊    | 5812/10000 [00:24<00:17, 241.94it/s]Running 10000 simulations.:  58%|█████▊    | 5837/10000 [00:25<00:17, 242.59it/s]Running 10000 simulations.:  59%|█████▊    | 5862/10000 [00:25<00:17, 242.98it/s]Running 10000 simulations.:  59%|█████▉    | 5887/10000 [00:25<00:16, 242.46it/s]Running 10000 simulations.:  59%|█████▉    | 5912/10000 [00:25<00:16, 242.51it/s]Running 10000 simulations.:  59%|█████▉    | 5937/10000 [00:25<00:16, 242.97it/s]Running 10000 simulations.:  60%|█████▉    | 5962/10000 [00:25<00:16, 243.92it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:25<00:16, 243.59it/s]Running 10000 simulations.:  60%|██████    | 6012/10000 [00:25<00:16, 242.92it/s]Running 10000 simulations.:  60%|██████    | 6037/10000 [00:25<00:16, 242.84it/s]Running 10000 simulations.:  61%|██████    | 6062/10000 [00:25<00:16, 243.67it/s]Running 10000 simulations.:  61%|██████    | 6087/10000 [00:26<00:16, 243.78it/s]Running 10000 simulations.:  61%|██████    | 6112/10000 [00:26<00:15, 244.09it/s]Running 10000 simulations.:  61%|██████▏   | 6137/10000 [00:26<00:15, 244.50it/s]Running 10000 simulations.:  62%|██████▏   | 6162/10000 [00:26<00:15, 244.88it/s]Running 10000 simulations.:  62%|██████▏   | 6187/10000 [00:26<00:15, 244.50it/s]Running 10000 simulations.:  62%|██████▏   | 6212/10000 [00:26<00:15, 240.05it/s]Running 10000 simulations.:  62%|██████▏   | 6237/10000 [00:26<00:15, 236.97it/s]Running 10000 simulations.:  63%|██████▎   | 6261/10000 [00:26<00:15, 234.31it/s]Running 10000 simulations.:  63%|██████▎   | 6285/10000 [00:26<00:16, 231.86it/s]Running 10000 simulations.:  63%|██████▎   | 6309/10000 [00:26<00:16, 230.24it/s]Running 10000 simulations.:  63%|██████▎   | 6333/10000 [00:27<00:15, 229.73it/s]Running 10000 simulations.:  64%|██████▎   | 6357/10000 [00:27<00:15, 230.27it/s]Running 10000 simulations.:  64%|██████▍   | 6381/10000 [00:27<00:15, 229.80it/s]Running 10000 simulations.:  64%|██████▍   | 6404/10000 [00:27<00:15, 228.97it/s]Running 10000 simulations.:  64%|██████▍   | 6427/10000 [00:27<00:15, 228.44it/s]Running 10000 simulations.:  64%|██████▍   | 6450/10000 [00:27<00:15, 228.39it/s]Running 10000 simulations.:  65%|██████▍   | 6473/10000 [00:27<00:15, 228.52it/s]Running 10000 simulations.:  65%|██████▍   | 6496/10000 [00:27<00:15, 228.90it/s]Running 10000 simulations.:  65%|██████▌   | 6519/10000 [00:27<00:15, 227.94it/s]Running 10000 simulations.:  65%|██████▌   | 6542/10000 [00:27<00:15, 228.33it/s]Running 10000 simulations.:  66%|██████▌   | 6565/10000 [00:28<00:15, 228.11it/s]Running 10000 simulations.:  66%|██████▌   | 6588/10000 [00:28<00:14, 227.55it/s]Running 10000 simulations.:  66%|██████▌   | 6611/10000 [00:28<00:14, 227.62it/s]Running 10000 simulations.:  66%|██████▋   | 6634/10000 [00:28<00:14, 228.06it/s]Running 10000 simulations.:  67%|██████▋   | 6657/10000 [00:28<00:14, 228.07it/s]Running 10000 simulations.:  67%|██████▋   | 6683/10000 [00:28<00:14, 234.40it/s]Running 10000 simulations.:  67%|██████▋   | 6708/10000 [00:28<00:13, 238.76it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:28<00:13, 238.80it/s]Running 10000 simulations.:  68%|██████▊   | 6757/10000 [00:28<00:14, 223.12it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:29<00:15, 214.27it/s]Running 10000 simulations.:  68%|██████▊   | 6802/10000 [00:29<00:15, 207.70it/s]Running 10000 simulations.:  68%|██████▊   | 6823/10000 [00:29<00:15, 205.53it/s]Running 10000 simulations.:  68%|██████▊   | 6844/10000 [00:29<00:15, 202.67it/s]Running 10000 simulations.:  69%|██████▊   | 6865/10000 [00:29<00:15, 204.36it/s]Running 10000 simulations.:  69%|██████▉   | 6887/10000 [00:29<00:15, 206.17it/s]Running 10000 simulations.:  69%|██████▉   | 6909/10000 [00:29<00:14, 207.35it/s]Running 10000 simulations.:  69%|██████▉   | 6930/10000 [00:29<00:14, 207.52it/s]Running 10000 simulations.:  70%|██████▉   | 6951/10000 [00:29<00:14, 207.02it/s]Running 10000 simulations.:  70%|██████▉   | 6972/10000 [00:29<00:14, 205.68it/s]Running 10000 simulations.:  70%|██████▉   | 6993/10000 [00:30<00:14, 201.38it/s]Running 10000 simulations.:  70%|███████   | 7014/10000 [00:30<00:14, 202.13it/s]Running 10000 simulations.:  70%|███████   | 7035/10000 [00:30<00:14, 202.14it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:30<00:14, 202.32it/s]Running 10000 simulations.:  71%|███████   | 7077/10000 [00:30<00:14, 202.47it/s]Running 10000 simulations.:  71%|███████   | 7101/10000 [00:30<00:13, 210.75it/s]Running 10000 simulations.:  71%|███████▏  | 7126/10000 [00:30<00:13, 220.97it/s]Running 10000 simulations.:  72%|███████▏  | 7151/10000 [00:30<00:12, 227.14it/s]Running 10000 simulations.:  72%|███████▏  | 7175/10000 [00:30<00:12, 228.46it/s]Running 10000 simulations.:  72%|███████▏  | 7199/10000 [00:31<00:12, 229.74it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:31<00:12, 230.67it/s]Running 10000 simulations.:  72%|███████▏  | 7247/10000 [00:31<00:11, 231.32it/s]Running 10000 simulations.:  73%|███████▎  | 7271/10000 [00:31<00:11, 232.04it/s]Running 10000 simulations.:  73%|███████▎  | 7295/10000 [00:31<00:11, 232.22it/s]Running 10000 simulations.:  73%|███████▎  | 7319/10000 [00:31<00:11, 232.74it/s]Running 10000 simulations.:  73%|███████▎  | 7343/10000 [00:31<00:11, 232.73it/s]Running 10000 simulations.:  74%|███████▎  | 7367/10000 [00:31<00:11, 232.43it/s]Running 10000 simulations.:  74%|███████▍  | 7391/10000 [00:31<00:11, 232.26it/s]Running 10000 simulations.:  74%|███████▍  | 7415/10000 [00:31<00:11, 232.50it/s]Running 10000 simulations.:  74%|███████▍  | 7439/10000 [00:32<00:11, 232.70it/s]Running 10000 simulations.:  75%|███████▍  | 7463/10000 [00:32<00:10, 232.41it/s]Running 10000 simulations.:  75%|███████▍  | 7487/10000 [00:32<00:10, 232.16it/s]Running 10000 simulations.:  75%|███████▌  | 7511/10000 [00:32<00:10, 231.41it/s]Running 10000 simulations.:  75%|███████▌  | 7535/10000 [00:32<00:10, 231.02it/s]Running 10000 simulations.:  76%|███████▌  | 7559/10000 [00:32<00:10, 230.97it/s]Running 10000 simulations.:  76%|███████▌  | 7583/10000 [00:32<00:10, 231.09it/s]Running 10000 simulations.:  76%|███████▌  | 7607/10000 [00:32<00:10, 231.62it/s]Running 10000 simulations.:  76%|███████▋  | 7631/10000 [00:32<00:10, 232.13it/s]Running 10000 simulations.:  77%|███████▋  | 7655/10000 [00:32<00:10, 232.04it/s]Running 10000 simulations.:  77%|███████▋  | 7679/10000 [00:33<00:10, 231.54it/s]Running 10000 simulations.:  77%|███████▋  | 7703/10000 [00:33<00:09, 231.49it/s]Running 10000 simulations.:  77%|███████▋  | 7727/10000 [00:33<00:09, 231.39it/s]Running 10000 simulations.:  78%|███████▊  | 7751/10000 [00:33<00:09, 230.86it/s]Running 10000 simulations.:  78%|███████▊  | 7775/10000 [00:33<00:09, 230.76it/s]Running 10000 simulations.:  78%|███████▊  | 7799/10000 [00:33<00:09, 230.30it/s]Running 10000 simulations.:  78%|███████▊  | 7823/10000 [00:33<00:09, 229.95it/s]Running 10000 simulations.:  78%|███████▊  | 7846/10000 [00:33<00:09, 229.79it/s]Running 10000 simulations.:  79%|███████▊  | 7870/10000 [00:33<00:09, 230.35it/s]Running 10000 simulations.:  79%|███████▉  | 7894/10000 [00:34<00:09, 231.17it/s]Running 10000 simulations.:  79%|███████▉  | 7918/10000 [00:34<00:08, 231.89it/s]Running 10000 simulations.:  79%|███████▉  | 7942/10000 [00:34<00:08, 231.74it/s]Running 10000 simulations.:  80%|███████▉  | 7966/10000 [00:34<00:08, 231.59it/s]Running 10000 simulations.:  80%|███████▉  | 7990/10000 [00:34<00:08, 231.62it/s]Running 10000 simulations.:  80%|████████  | 8014/10000 [00:34<00:08, 232.19it/s]Running 10000 simulations.:  80%|████████  | 8038/10000 [00:34<00:08, 231.81it/s]Running 10000 simulations.:  81%|████████  | 8062/10000 [00:34<00:08, 231.04it/s]Running 10000 simulations.:  81%|████████  | 8086/10000 [00:34<00:08, 230.46it/s]Running 10000 simulations.:  81%|████████  | 8110/10000 [00:34<00:08, 230.60it/s]Running 10000 simulations.:  81%|████████▏ | 8134/10000 [00:35<00:08, 231.11it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:35<00:07, 232.13it/s]Running 10000 simulations.:  82%|████████▏ | 8182/10000 [00:35<00:07, 232.19it/s]Running 10000 simulations.:  82%|████████▏ | 8206/10000 [00:35<00:07, 232.53it/s]Running 10000 simulations.:  82%|████████▏ | 8230/10000 [00:35<00:07, 232.07it/s]Running 10000 simulations.:  83%|████████▎ | 8254/10000 [00:35<00:07, 231.24it/s]Running 10000 simulations.:  83%|████████▎ | 8278/10000 [00:35<00:07, 230.55it/s]Running 10000 simulations.:  83%|████████▎ | 8302/10000 [00:35<00:07, 230.16it/s]Running 10000 simulations.:  83%|████████▎ | 8326/10000 [00:35<00:07, 230.28it/s]Running 10000 simulations.:  84%|████████▎ | 8350/10000 [00:36<00:07, 231.04it/s]Running 10000 simulations.:  84%|████████▎ | 8374/10000 [00:36<00:07, 231.06it/s]Running 10000 simulations.:  84%|████████▍ | 8398/10000 [00:36<00:06, 230.87it/s]Running 10000 simulations.:  84%|████████▍ | 8422/10000 [00:36<00:06, 230.72it/s]Running 10000 simulations.:  84%|████████▍ | 8446/10000 [00:36<00:06, 229.99it/s]Running 10000 simulations.:  85%|████████▍ | 8469/10000 [00:36<00:06, 227.11it/s]Running 10000 simulations.:  85%|████████▍ | 8492/10000 [00:36<00:06, 225.12it/s]Running 10000 simulations.:  85%|████████▌ | 8515/10000 [00:36<00:06, 223.58it/s]Running 10000 simulations.:  85%|████████▌ | 8538/10000 [00:36<00:06, 222.02it/s]Running 10000 simulations.:  86%|████████▌ | 8561/10000 [00:36<00:06, 220.79it/s]Running 10000 simulations.:  86%|████████▌ | 8584/10000 [00:37<00:06, 220.56it/s]Running 10000 simulations.:  86%|████████▌ | 8607/10000 [00:37<00:06, 220.55it/s]Running 10000 simulations.:  86%|████████▋ | 8630/10000 [00:37<00:06, 220.62it/s]Running 10000 simulations.:  87%|████████▋ | 8653/10000 [00:37<00:06, 220.86it/s]Running 10000 simulations.:  87%|████████▋ | 8676/10000 [00:37<00:05, 221.36it/s]Running 10000 simulations.:  87%|████████▋ | 8699/10000 [00:37<00:05, 220.82it/s]Running 10000 simulations.:  87%|████████▋ | 8722/10000 [00:37<00:05, 220.22it/s]Running 10000 simulations.:  87%|████████▋ | 8745/10000 [00:37<00:05, 219.96it/s]Running 10000 simulations.:  88%|████████▊ | 8768/10000 [00:37<00:05, 220.19it/s]Running 10000 simulations.:  88%|████████▊ | 8791/10000 [00:37<00:05, 220.34it/s]Running 10000 simulations.:  88%|████████▊ | 8814/10000 [00:38<00:05, 220.16it/s]Running 10000 simulations.:  88%|████████▊ | 8837/10000 [00:38<00:05, 219.88it/s]Running 10000 simulations.:  89%|████████▊ | 8859/10000 [00:38<00:05, 219.51it/s]Running 10000 simulations.:  89%|████████▉ | 8881/10000 [00:38<00:05, 218.91it/s]Running 10000 simulations.:  89%|████████▉ | 8903/10000 [00:38<00:05, 209.15it/s]Running 10000 simulations.:  89%|████████▉ | 8925/10000 [00:38<00:05, 211.76it/s]Running 10000 simulations.:  89%|████████▉ | 8948/10000 [00:38<00:04, 214.57it/s]Running 10000 simulations.:  90%|████████▉ | 8970/10000 [00:38<00:04, 216.14it/s]Running 10000 simulations.:  90%|████████▉ | 8992/10000 [00:38<00:04, 216.88it/s]Running 10000 simulations.:  90%|█████████ | 9014/10000 [00:39<00:04, 217.23it/s]Running 10000 simulations.:  90%|█████████ | 9036/10000 [00:39<00:04, 217.58it/s]Running 10000 simulations.:  91%|█████████ | 9058/10000 [00:39<00:04, 217.87it/s]Running 10000 simulations.:  91%|█████████ | 9080/10000 [00:39<00:04, 218.21it/s]Running 10000 simulations.:  91%|█████████ | 9103/10000 [00:39<00:04, 219.14it/s]Running 10000 simulations.:  91%|█████████▏| 9126/10000 [00:39<00:03, 219.90it/s]Running 10000 simulations.:  91%|█████████▏| 9148/10000 [00:39<00:03, 219.37it/s]Running 10000 simulations.:  92%|█████████▏| 9170/10000 [00:39<00:03, 219.26it/s]Running 10000 simulations.:  92%|█████████▏| 9192/10000 [00:39<00:03, 218.81it/s]Running 10000 simulations.:  92%|█████████▏| 9214/10000 [00:39<00:03, 218.75it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [00:40<00:03, 218.36it/s]Running 10000 simulations.:  93%|█████████▎| 9258/10000 [00:40<00:03, 218.45it/s]Running 10000 simulations.:  93%|█████████▎| 9280/10000 [00:40<00:03, 218.56it/s]Running 10000 simulations.:  93%|█████████▎| 9303/10000 [00:40<00:03, 218.97it/s]Running 10000 simulations.:  93%|█████████▎| 9325/10000 [00:40<00:03, 219.26it/s]Running 10000 simulations.:  93%|█████████▎| 9347/10000 [00:40<00:02, 219.40it/s]Running 10000 simulations.:  94%|█████████▎| 9370/10000 [00:40<00:02, 220.02it/s]Running 10000 simulations.:  94%|█████████▍| 9393/10000 [00:40<00:02, 220.42it/s]Running 10000 simulations.:  94%|█████████▍| 9416/10000 [00:40<00:02, 220.34it/s]Running 10000 simulations.:  94%|█████████▍| 9439/10000 [00:40<00:02, 220.39it/s]Running 10000 simulations.:  95%|█████████▍| 9462/10000 [00:41<00:02, 220.70it/s]Running 10000 simulations.:  95%|█████████▍| 9485/10000 [00:41<00:02, 220.97it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [00:41<00:02, 220.28it/s]Running 10000 simulations.:  95%|█████████▌| 9531/10000 [00:41<00:02, 219.85it/s]Running 10000 simulations.:  96%|█████████▌| 9553/10000 [00:41<00:02, 219.61it/s]Running 10000 simulations.:  96%|█████████▌| 9576/10000 [00:41<00:01, 220.13it/s]Running 10000 simulations.:  96%|█████████▌| 9599/10000 [00:41<00:01, 219.92it/s]Running 10000 simulations.:  96%|█████████▌| 9622/10000 [00:41<00:01, 220.39it/s]Running 10000 simulations.:  96%|█████████▋| 9645/10000 [00:41<00:01, 220.97it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [00:41<00:01, 221.39it/s]Running 10000 simulations.:  97%|█████████▋| 9691/10000 [00:42<00:01, 221.57it/s]Running 10000 simulations.:  97%|█████████▋| 9714/10000 [00:42<00:01, 222.14it/s]Running 10000 simulations.:  97%|█████████▋| 9737/10000 [00:42<00:01, 222.63it/s]Running 10000 simulations.:  98%|█████████▊| 9760/10000 [00:42<00:01, 222.98it/s]Running 10000 simulations.:  98%|█████████▊| 9783/10000 [00:42<00:00, 222.86it/s]Running 10000 simulations.:  98%|█████████▊| 9806/10000 [00:42<00:00, 221.16it/s]Running 10000 simulations.:  98%|█████████▊| 9829/10000 [00:42<00:00, 214.33it/s]Running 10000 simulations.:  99%|█████████▊| 9851/10000 [00:42<00:00, 213.05it/s]Running 10000 simulations.:  99%|█████████▉| 9875/10000 [00:42<00:00, 219.22it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:43<00:00, 224.01it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [00:43<00:00, 227.76it/s]Running 10000 simulations.:  99%|█████████▉| 9947/10000 [00:43<00:00, 230.58it/s]Running 10000 simulations.: 100%|█████████▉| 9971/10000 [00:43<00:00, 231.85it/s]Running 10000 simulations.: 100%|█████████▉| 9995/10000 [00:43<00:00, 232.93it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:43<00:00, 230.06it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 27/10000 [00:00<00:38, 259.86it/s]Running 10000 simulations.:   1%|          | 54/10000 [00:00<00:38, 260.42it/s]Running 10000 simulations.:   1%|          | 80/10000 [00:00<00:38, 260.02it/s]Running 10000 simulations.:   1%|          | 107/10000 [00:00<00:38, 260.20it/s]Running 10000 simulations.:   1%|▏         | 134/10000 [00:00<00:37, 260.06it/s]Running 10000 simulations.:   2%|▏         | 161/10000 [00:00<00:37, 260.59it/s]Running 10000 simulations.:   2%|▏         | 188/10000 [00:00<00:37, 260.55it/s]Running 10000 simulations.:   2%|▏         | 214/10000 [00:00<00:37, 259.63it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:00<00:37, 258.97it/s]Running 10000 simulations.:   3%|▎         | 266/10000 [00:01<00:37, 258.95it/s]Running 10000 simulations.:   3%|▎         | 292/10000 [00:01<00:37, 258.52it/s]Running 10000 simulations.:   3%|▎         | 318/10000 [00:01<00:37, 257.32it/s]Running 10000 simulations.:   3%|▎         | 344/10000 [00:01<00:37, 256.73it/s]Running 10000 simulations.:   4%|▎         | 370/10000 [00:01<00:37, 256.52it/s]Running 10000 simulations.:   4%|▍         | 396/10000 [00:01<00:37, 256.79it/s]Running 10000 simulations.:   4%|▍         | 422/10000 [00:01<00:37, 257.52it/s]Running 10000 simulations.:   4%|▍         | 448/10000 [00:01<00:37, 257.05it/s]Running 10000 simulations.:   5%|▍         | 474/10000 [00:01<00:37, 256.43it/s]Running 10000 simulations.:   5%|▌         | 500/10000 [00:01<00:37, 256.42it/s]Running 10000 simulations.:   5%|▌         | 526/10000 [00:02<00:36, 257.24it/s]Running 10000 simulations.:   6%|▌         | 552/10000 [00:02<00:36, 256.97it/s]Running 10000 simulations.:   6%|▌         | 578/10000 [00:02<00:36, 256.92it/s]Running 10000 simulations.:   6%|▌         | 604/10000 [00:02<00:36, 257.56it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:02<00:36, 257.48it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:02<00:36, 256.51it/s]Running 10000 simulations.:   7%|▋         | 682/10000 [00:02<00:36, 255.55it/s]Running 10000 simulations.:   7%|▋         | 708/10000 [00:02<00:36, 255.83it/s]Running 10000 simulations.:   7%|▋         | 734/10000 [00:02<00:36, 256.63it/s]Running 10000 simulations.:   8%|▊         | 760/10000 [00:02<00:36, 256.43it/s]Running 10000 simulations.:   8%|▊         | 786/10000 [00:03<00:35, 256.91it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:03<00:35, 257.45it/s]Running 10000 simulations.:   8%|▊         | 838/10000 [00:03<00:35, 257.76it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:03<00:35, 257.93it/s]Running 10000 simulations.:   9%|▉         | 890/10000 [00:03<00:35, 256.86it/s]Running 10000 simulations.:   9%|▉         | 916/10000 [00:03<00:35, 255.57it/s]Running 10000 simulations.:   9%|▉         | 942/10000 [00:03<00:35, 254.42it/s]Running 10000 simulations.:  10%|▉         | 968/10000 [00:03<00:35, 254.71it/s]Running 10000 simulations.:  10%|▉         | 994/10000 [00:03<00:35, 254.90it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:03<00:35, 253.95it/s]Running 10000 simulations.:  10%|█         | 1046/10000 [00:04<00:35, 253.30it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:04<00:35, 252.90it/s]Running 10000 simulations.:  11%|█         | 1098/10000 [00:04<00:35, 252.33it/s]Running 10000 simulations.:  11%|█         | 1124/10000 [00:04<00:35, 251.87it/s]Running 10000 simulations.:  12%|█▏        | 1150/10000 [00:04<00:36, 244.79it/s]Running 10000 simulations.:  12%|█▏        | 1175/10000 [00:04<00:36, 240.37it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:37, 236.87it/s]Running 10000 simulations.:  12%|█▏        | 1224/10000 [00:04<00:37, 234.58it/s]Running 10000 simulations.:  12%|█▏        | 1248/10000 [00:04<00:37, 233.41it/s]Running 10000 simulations.:  13%|█▎        | 1272/10000 [00:05<00:37, 232.96it/s]Running 10000 simulations.:  13%|█▎        | 1296/10000 [00:05<00:37, 232.61it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:05<00:37, 231.59it/s]Running 10000 simulations.:  13%|█▎        | 1344/10000 [00:05<00:37, 231.52it/s]Running 10000 simulations.:  14%|█▎        | 1368/10000 [00:05<00:37, 231.17it/s]Running 10000 simulations.:  14%|█▍        | 1392/10000 [00:05<00:37, 231.29it/s]Running 10000 simulations.:  14%|█▍        | 1416/10000 [00:05<00:37, 231.11it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:05<00:37, 230.97it/s]Running 10000 simulations.:  15%|█▍        | 1464/10000 [00:05<00:36, 231.01it/s]Running 10000 simulations.:  15%|█▍        | 1488/10000 [00:05<00:36, 230.46it/s]Running 10000 simulations.:  15%|█▌        | 1512/10000 [00:06<00:36, 230.20it/s]Running 10000 simulations.:  15%|█▌        | 1536/10000 [00:06<00:36, 229.88it/s]Running 10000 simulations.:  16%|█▌        | 1559/10000 [00:06<00:36, 229.57it/s]Running 10000 simulations.:  16%|█▌        | 1582/10000 [00:06<00:36, 229.14it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:06<00:36, 228.83it/s]Running 10000 simulations.:  16%|█▋        | 1628/10000 [00:06<00:36, 228.89it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:06<00:36, 229.04it/s]Running 10000 simulations.:  17%|█▋        | 1674/10000 [00:06<00:36, 228.97it/s]Running 10000 simulations.:  17%|█▋        | 1697/10000 [00:06<00:36, 229.11it/s]Running 10000 simulations.:  17%|█▋        | 1721/10000 [00:06<00:36, 229.61it/s]Running 10000 simulations.:  17%|█▋        | 1745/10000 [00:07<00:35, 230.25it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:07<00:35, 230.31it/s]Running 10000 simulations.:  18%|█▊        | 1793/10000 [00:07<00:35, 230.64it/s]Running 10000 simulations.:  18%|█▊        | 1817/10000 [00:07<00:35, 231.05it/s]Running 10000 simulations.:  18%|█▊        | 1841/10000 [00:07<00:35, 231.40it/s]Running 10000 simulations.:  19%|█▊        | 1865/10000 [00:07<00:35, 231.77it/s]Running 10000 simulations.:  19%|█▉        | 1889/10000 [00:07<00:34, 232.81it/s]Running 10000 simulations.:  19%|█▉        | 1913/10000 [00:07<00:34, 234.19it/s]Running 10000 simulations.:  19%|█▉        | 1938/10000 [00:07<00:34, 235.84it/s]Running 10000 simulations.:  20%|█▉        | 1962/10000 [00:08<00:34, 235.58it/s]Running 10000 simulations.:  20%|█▉        | 1986/10000 [00:08<00:34, 235.34it/s]Running 10000 simulations.:  20%|██        | 2010/10000 [00:08<00:33, 235.15it/s]Running 10000 simulations.:  20%|██        | 2034/10000 [00:08<00:33, 234.78it/s]Running 10000 simulations.:  21%|██        | 2058/10000 [00:08<00:33, 234.69it/s]Running 10000 simulations.:  21%|██        | 2082/10000 [00:08<00:33, 234.84it/s]Running 10000 simulations.:  21%|██        | 2106/10000 [00:08<00:33, 235.11it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:08<00:33, 234.97it/s]Running 10000 simulations.:  22%|██▏       | 2154/10000 [00:08<00:33, 234.49it/s]Running 10000 simulations.:  22%|██▏       | 2178/10000 [00:08<00:33, 234.48it/s]Running 10000 simulations.:  22%|██▏       | 2202/10000 [00:09<00:33, 234.65it/s]Running 10000 simulations.:  22%|██▏       | 2226/10000 [00:09<00:33, 234.61it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:09<00:32, 235.23it/s]Running 10000 simulations.:  23%|██▎       | 2274/10000 [00:09<00:32, 235.61it/s]Running 10000 simulations.:  23%|██▎       | 2298/10000 [00:09<00:32, 235.49it/s]Running 10000 simulations.:  23%|██▎       | 2322/10000 [00:09<00:32, 235.72it/s]Running 10000 simulations.:  23%|██▎       | 2346/10000 [00:09<00:32, 235.50it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:09<00:32, 234.93it/s]Running 10000 simulations.:  24%|██▍       | 2394/10000 [00:09<00:32, 236.29it/s]Running 10000 simulations.:  24%|██▍       | 2418/10000 [00:09<00:32, 236.54it/s]Running 10000 simulations.:  24%|██▍       | 2442/10000 [00:10<00:32, 235.50it/s]Running 10000 simulations.:  25%|██▍       | 2466/10000 [00:10<00:32, 234.65it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:10<00:32, 233.64it/s]Running 10000 simulations.:  25%|██▌       | 2514/10000 [00:10<00:32, 232.85it/s]Running 10000 simulations.:  25%|██▌       | 2538/10000 [00:10<00:32, 232.34it/s]Running 10000 simulations.:  26%|██▌       | 2562/10000 [00:10<00:32, 232.16it/s]Running 10000 simulations.:  26%|██▌       | 2586/10000 [00:10<00:31, 232.03it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:10<00:31, 233.07it/s]Running 10000 simulations.:  26%|██▋       | 2634/10000 [00:10<00:31, 234.21it/s]Running 10000 simulations.:  27%|██▋       | 2658/10000 [00:10<00:31, 234.84it/s]Running 10000 simulations.:  27%|██▋       | 2682/10000 [00:11<00:31, 234.01it/s]Running 10000 simulations.:  27%|██▋       | 2706/10000 [00:11<00:31, 232.67it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:11<00:31, 232.52it/s]Running 10000 simulations.:  28%|██▊       | 2754/10000 [00:11<00:31, 233.01it/s]Running 10000 simulations.:  28%|██▊       | 2778/10000 [00:11<00:30, 233.16it/s]Running 10000 simulations.:  28%|██▊       | 2802/10000 [00:11<00:30, 233.68it/s]Running 10000 simulations.:  28%|██▊       | 2826/10000 [00:11<00:30, 233.71it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:11<00:30, 233.81it/s]Running 10000 simulations.:  29%|██▊       | 2874/10000 [00:11<00:30, 233.76it/s]Running 10000 simulations.:  29%|██▉       | 2898/10000 [00:12<00:30, 233.57it/s]Running 10000 simulations.:  29%|██▉       | 2922/10000 [00:12<00:30, 233.97it/s]Running 10000 simulations.:  29%|██▉       | 2946/10000 [00:12<00:30, 235.09it/s]Running 10000 simulations.:  30%|██▉       | 2973/10000 [00:12<00:29, 242.13it/s]Running 10000 simulations.:  30%|██▉       | 2999/10000 [00:12<00:28, 245.54it/s]Running 10000 simulations.:  30%|███       | 3025/10000 [00:12<00:28, 247.29it/s]Running 10000 simulations.:  31%|███       | 3051/10000 [00:12<00:27, 248.74it/s]Running 10000 simulations.:  31%|███       | 3077/10000 [00:12<00:27, 250.90it/s]Running 10000 simulations.:  31%|███       | 3103/10000 [00:12<00:27, 251.63it/s]Running 10000 simulations.:  31%|███▏      | 3129/10000 [00:12<00:27, 252.86it/s]Running 10000 simulations.:  32%|███▏      | 3155/10000 [00:13<00:26, 253.63it/s]Running 10000 simulations.:  32%|███▏      | 3181/10000 [00:13<00:27, 247.02it/s]Running 10000 simulations.:  32%|███▏      | 3206/10000 [00:13<00:29, 229.90it/s]Running 10000 simulations.:  32%|███▏      | 3230/10000 [00:13<00:30, 222.67it/s]Running 10000 simulations.:  33%|███▎      | 3253/10000 [00:13<00:31, 214.45it/s]Running 10000 simulations.:  33%|███▎      | 3275/10000 [00:13<00:32, 206.09it/s]Running 10000 simulations.:  33%|███▎      | 3296/10000 [00:13<00:33, 201.23it/s]Running 10000 simulations.:  33%|███▎      | 3317/10000 [00:13<00:33, 198.75it/s]Running 10000 simulations.:  33%|███▎      | 3338/10000 [00:13<00:33, 197.31it/s]Running 10000 simulations.:  34%|███▎      | 3358/10000 [00:14<00:33, 195.86it/s]Running 10000 simulations.:  34%|███▍      | 3379/10000 [00:14<00:33, 197.68it/s]Running 10000 simulations.:  34%|███▍      | 3400/10000 [00:14<00:33, 199.05it/s]Running 10000 simulations.:  34%|███▍      | 3421/10000 [00:14<00:32, 201.27it/s]Running 10000 simulations.:  34%|███▍      | 3442/10000 [00:14<00:32, 203.37it/s]Running 10000 simulations.:  35%|███▍      | 3464/10000 [00:14<00:31, 206.35it/s]Running 10000 simulations.:  35%|███▍      | 3485/10000 [00:14<00:31, 206.66it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:14<00:31, 207.82it/s]Running 10000 simulations.:  35%|███▌      | 3529/10000 [00:14<00:30, 209.55it/s]Running 10000 simulations.:  36%|███▌      | 3550/10000 [00:14<00:30, 209.52it/s]Running 10000 simulations.:  36%|███▌      | 3571/10000 [00:15<00:30, 208.39it/s]Running 10000 simulations.:  36%|███▌      | 3592/10000 [00:15<00:30, 207.16it/s]Running 10000 simulations.:  36%|███▌      | 3613/10000 [00:15<00:30, 206.22it/s]Running 10000 simulations.:  36%|███▋      | 3634/10000 [00:15<00:30, 206.71it/s]Running 10000 simulations.:  37%|███▋      | 3658/10000 [00:15<00:29, 213.90it/s]Running 10000 simulations.:  37%|███▋      | 3682/10000 [00:15<00:28, 219.10it/s]Running 10000 simulations.:  37%|███▋      | 3706/10000 [00:15<00:28, 222.88it/s]Running 10000 simulations.:  37%|███▋      | 3730/10000 [00:15<00:27, 225.18it/s]Running 10000 simulations.:  38%|███▊      | 3754/10000 [00:15<00:27, 226.65it/s]Running 10000 simulations.:  38%|███▊      | 3778/10000 [00:15<00:27, 228.15it/s]Running 10000 simulations.:  38%|███▊      | 3802/10000 [00:16<00:26, 229.76it/s]Running 10000 simulations.:  38%|███▊      | 3826/10000 [00:16<00:26, 231.57it/s]Running 10000 simulations.:  38%|███▊      | 3850/10000 [00:16<00:26, 232.81it/s]Running 10000 simulations.:  39%|███▊      | 3874/10000 [00:16<00:26, 234.02it/s]Running 10000 simulations.:  39%|███▉      | 3898/10000 [00:16<00:25, 235.24it/s]Running 10000 simulations.:  39%|███▉      | 3922/10000 [00:16<00:25, 235.53it/s]Running 10000 simulations.:  39%|███▉      | 3946/10000 [00:16<00:25, 235.23it/s]Running 10000 simulations.:  40%|███▉      | 3970/10000 [00:16<00:25, 233.78it/s]Running 10000 simulations.:  40%|███▉      | 3994/10000 [00:16<00:25, 233.12it/s]Running 10000 simulations.:  40%|████      | 4018/10000 [00:17<00:25, 232.78it/s]Running 10000 simulations.:  40%|████      | 4042/10000 [00:17<00:25, 232.32it/s]Running 10000 simulations.:  41%|████      | 4066/10000 [00:17<00:25, 232.31it/s]Running 10000 simulations.:  41%|████      | 4090/10000 [00:17<00:25, 232.96it/s]Running 10000 simulations.:  41%|████      | 4114/10000 [00:17<00:25, 233.33it/s]Running 10000 simulations.:  41%|████▏     | 4138/10000 [00:17<00:25, 233.81it/s]Running 10000 simulations.:  42%|████▏     | 4162/10000 [00:17<00:24, 233.67it/s]Running 10000 simulations.:  42%|████▏     | 4186/10000 [00:17<00:24, 233.58it/s]Running 10000 simulations.:  42%|████▏     | 4210/10000 [00:17<00:24, 233.46it/s]Running 10000 simulations.:  42%|████▏     | 4234/10000 [00:17<00:24, 233.53it/s]Running 10000 simulations.:  43%|████▎     | 4258/10000 [00:18<00:24, 233.18it/s]Running 10000 simulations.:  43%|████▎     | 4282/10000 [00:18<00:24, 233.78it/s]Running 10000 simulations.:  43%|████▎     | 4306/10000 [00:18<00:24, 233.91it/s]Running 10000 simulations.:  43%|████▎     | 4330/10000 [00:18<00:24, 234.11it/s]Running 10000 simulations.:  44%|████▎     | 4354/10000 [00:18<00:24, 233.45it/s]Running 10000 simulations.:  44%|████▍     | 4378/10000 [00:18<00:24, 233.27it/s]Running 10000 simulations.:  44%|████▍     | 4402/10000 [00:18<00:23, 233.65it/s]Running 10000 simulations.:  44%|████▍     | 4426/10000 [00:18<00:23, 233.90it/s]Running 10000 simulations.:  44%|████▍     | 4450/10000 [00:18<00:23, 233.82it/s]Running 10000 simulations.:  45%|████▍     | 4474/10000 [00:18<00:23, 233.76it/s]Running 10000 simulations.:  45%|████▍     | 4498/10000 [00:19<00:23, 232.73it/s]Running 10000 simulations.:  45%|████▌     | 4522/10000 [00:19<00:23, 232.02it/s]Running 10000 simulations.:  45%|████▌     | 4546/10000 [00:19<00:23, 231.46it/s]Running 10000 simulations.:  46%|████▌     | 4570/10000 [00:19<00:23, 231.10it/s]Running 10000 simulations.:  46%|████▌     | 4594/10000 [00:19<00:23, 230.77it/s]Running 10000 simulations.:  46%|████▌     | 4618/10000 [00:19<00:23, 231.54it/s]Running 10000 simulations.:  46%|████▋     | 4642/10000 [00:19<00:23, 232.12it/s]Running 10000 simulations.:  47%|████▋     | 4666/10000 [00:19<00:22, 232.36it/s]Running 10000 simulations.:  47%|████▋     | 4690/10000 [00:19<00:22, 232.79it/s]Running 10000 simulations.:  47%|████▋     | 4714/10000 [00:20<00:22, 232.94it/s]Running 10000 simulations.:  47%|████▋     | 4738/10000 [00:20<00:22, 233.30it/s]Running 10000 simulations.:  48%|████▊     | 4762/10000 [00:20<00:22, 233.06it/s]Running 10000 simulations.:  48%|████▊     | 4786/10000 [00:20<00:22, 233.19it/s]Running 10000 simulations.:  48%|████▊     | 4810/10000 [00:20<00:22, 233.28it/s]Running 10000 simulations.:  48%|████▊     | 4834/10000 [00:20<00:22, 232.60it/s]Running 10000 simulations.:  49%|████▊     | 4858/10000 [00:20<00:22, 232.03it/s]Running 10000 simulations.:  49%|████▉     | 4882/10000 [00:20<00:22, 231.77it/s]Running 10000 simulations.:  49%|████▉     | 4906/10000 [00:20<00:22, 231.52it/s]Running 10000 simulations.:  49%|████▉     | 4930/10000 [00:20<00:21, 231.74it/s]Running 10000 simulations.:  50%|████▉     | 4954/10000 [00:21<00:21, 232.91it/s]Running 10000 simulations.:  50%|████▉     | 4978/10000 [00:21<00:21, 232.96it/s]Running 10000 simulations.:  50%|█████     | 5002/10000 [00:21<00:21, 232.66it/s]Running 10000 simulations.:  50%|█████     | 5026/10000 [00:21<00:21, 233.14it/s]Running 10000 simulations.:  50%|█████     | 5050/10000 [00:21<00:21, 233.61it/s]Running 10000 simulations.:  51%|█████     | 5074/10000 [00:21<00:21, 232.99it/s]Running 10000 simulations.:  51%|█████     | 5098/10000 [00:21<00:21, 232.42it/s]Running 10000 simulations.:  51%|█████     | 5122/10000 [00:21<00:20, 232.55it/s]Running 10000 simulations.:  51%|█████▏    | 5146/10000 [00:21<00:20, 233.04it/s]Running 10000 simulations.:  52%|█████▏    | 5170/10000 [00:21<00:20, 233.43it/s]Running 10000 simulations.:  52%|█████▏    | 5194/10000 [00:22<00:20, 233.61it/s]Running 10000 simulations.:  52%|█████▏    | 5218/10000 [00:22<00:20, 233.85it/s]Running 10000 simulations.:  52%|█████▏    | 5242/10000 [00:22<00:20, 234.14it/s]Running 10000 simulations.:  53%|█████▎    | 5266/10000 [00:22<00:20, 233.55it/s]Running 10000 simulations.:  53%|█████▎    | 5290/10000 [00:22<00:20, 232.83it/s]Running 10000 simulations.:  53%|█████▎    | 5314/10000 [00:22<00:20, 232.78it/s]Running 10000 simulations.:  53%|█████▎    | 5338/10000 [00:22<00:20, 232.94it/s]Running 10000 simulations.:  54%|█████▎    | 5362/10000 [00:22<00:19, 233.29it/s]Running 10000 simulations.:  54%|█████▍    | 5386/10000 [00:22<00:19, 234.04it/s]Running 10000 simulations.:  54%|█████▍    | 5410/10000 [00:22<00:19, 234.81it/s]Running 10000 simulations.:  54%|█████▍    | 5434/10000 [00:23<00:19, 235.27it/s]Running 10000 simulations.:  55%|█████▍    | 5458/10000 [00:23<00:19, 235.48it/s]Running 10000 simulations.:  55%|█████▍    | 5482/10000 [00:23<00:19, 235.75it/s]Running 10000 simulations.:  55%|█████▌    | 5506/10000 [00:23<00:19, 235.83it/s]Running 10000 simulations.:  55%|█████▌    | 5530/10000 [00:23<00:18, 235.37it/s]Running 10000 simulations.:  56%|█████▌    | 5554/10000 [00:23<00:18, 234.14it/s]Running 10000 simulations.:  56%|█████▌    | 5578/10000 [00:23<00:18, 233.62it/s]Running 10000 simulations.:  56%|█████▌    | 5602/10000 [00:23<00:18, 232.73it/s]Running 10000 simulations.:  56%|█████▋    | 5626/10000 [00:23<00:18, 232.28it/s]Running 10000 simulations.:  56%|█████▋    | 5650/10000 [00:24<00:18, 231.66it/s]Running 10000 simulations.:  57%|█████▋    | 5674/10000 [00:24<00:18, 231.44it/s]Running 10000 simulations.:  57%|█████▋    | 5698/10000 [00:24<00:18, 232.12it/s]Running 10000 simulations.:  57%|█████▋    | 5722/10000 [00:24<00:18, 232.94it/s]Running 10000 simulations.:  57%|█████▋    | 5746/10000 [00:24<00:18, 233.23it/s]Running 10000 simulations.:  58%|█████▊    | 5770/10000 [00:24<00:18, 233.25it/s]Running 10000 simulations.:  58%|█████▊    | 5794/10000 [00:24<00:18, 233.10it/s]Running 10000 simulations.:  58%|█████▊    | 5818/10000 [00:24<00:17, 233.37it/s]Running 10000 simulations.:  58%|█████▊    | 5842/10000 [00:24<00:17, 233.54it/s]Running 10000 simulations.:  59%|█████▊    | 5866/10000 [00:24<00:17, 234.02it/s]Running 10000 simulations.:  59%|█████▉    | 5890/10000 [00:25<00:17, 234.08it/s]Running 10000 simulations.:  59%|█████▉    | 5914/10000 [00:25<00:17, 233.82it/s]Running 10000 simulations.:  59%|█████▉    | 5938/10000 [00:25<00:17, 234.13it/s]Running 10000 simulations.:  60%|█████▉    | 5962/10000 [00:25<00:17, 234.12it/s]Running 10000 simulations.:  60%|█████▉    | 5986/10000 [00:25<00:17, 234.16it/s]Running 10000 simulations.:  60%|██████    | 6010/10000 [00:25<00:17, 233.67it/s]Running 10000 simulations.:  60%|██████    | 6034/10000 [00:25<00:16, 233.81it/s]Running 10000 simulations.:  61%|██████    | 6058/10000 [00:25<00:16, 233.42it/s]Running 10000 simulations.:  61%|██████    | 6082/10000 [00:25<00:16, 233.04it/s]Running 10000 simulations.:  61%|██████    | 6106/10000 [00:25<00:16, 233.15it/s]Running 10000 simulations.:  61%|██████▏   | 6130/10000 [00:26<00:16, 232.69it/s]Running 10000 simulations.:  62%|██████▏   | 6154/10000 [00:26<00:16, 232.65it/s]Running 10000 simulations.:  62%|██████▏   | 6178/10000 [00:26<00:16, 233.98it/s]Running 10000 simulations.:  62%|██████▏   | 6202/10000 [00:26<00:16, 233.13it/s]Running 10000 simulations.:  62%|██████▏   | 6226/10000 [00:26<00:16, 232.49it/s]Running 10000 simulations.:  62%|██████▎   | 6250/10000 [00:26<00:16, 232.57it/s]Running 10000 simulations.:  63%|██████▎   | 6274/10000 [00:26<00:16, 232.54it/s]Running 10000 simulations.:  63%|██████▎   | 6298/10000 [00:26<00:15, 232.77it/s]Running 10000 simulations.:  63%|██████▎   | 6322/10000 [00:26<00:15, 232.76it/s]Running 10000 simulations.:  63%|██████▎   | 6346/10000 [00:27<00:15, 232.57it/s]Running 10000 simulations.:  64%|██████▎   | 6370/10000 [00:27<00:15, 232.03it/s]Running 10000 simulations.:  64%|██████▍   | 6394/10000 [00:27<00:15, 231.53it/s]Running 10000 simulations.:  64%|██████▍   | 6418/10000 [00:27<00:15, 231.15it/s]Running 10000 simulations.:  64%|██████▍   | 6442/10000 [00:27<00:15, 231.03it/s]Running 10000 simulations.:  65%|██████▍   | 6466/10000 [00:27<00:15, 230.79it/s]Running 10000 simulations.:  65%|██████▍   | 6490/10000 [00:27<00:15, 230.68it/s]Running 10000 simulations.:  65%|██████▌   | 6514/10000 [00:27<00:15, 230.46it/s]Running 10000 simulations.:  65%|██████▌   | 6538/10000 [00:27<00:15, 230.43it/s]Running 10000 simulations.:  66%|██████▌   | 6562/10000 [00:27<00:14, 230.52it/s]Running 10000 simulations.:  66%|██████▌   | 6586/10000 [00:28<00:14, 231.36it/s]Running 10000 simulations.:  66%|██████▌   | 6610/10000 [00:28<00:14, 231.82it/s]Running 10000 simulations.:  66%|██████▋   | 6634/10000 [00:28<00:14, 232.17it/s]Running 10000 simulations.:  67%|██████▋   | 6658/10000 [00:28<00:14, 232.32it/s]Running 10000 simulations.:  67%|██████▋   | 6682/10000 [00:28<00:14, 232.79it/s]Running 10000 simulations.:  67%|██████▋   | 6706/10000 [00:28<00:14, 233.67it/s]Running 10000 simulations.:  67%|██████▋   | 6732/10000 [00:28<00:13, 239.33it/s]Running 10000 simulations.:  68%|██████▊   | 6758/10000 [00:28<00:13, 244.04it/s]Running 10000 simulations.:  68%|██████▊   | 6784/10000 [00:28<00:13, 245.93it/s]Running 10000 simulations.:  68%|██████▊   | 6809/10000 [00:28<00:12, 245.78it/s]Running 10000 simulations.:  68%|██████▊   | 6834/10000 [00:29<00:12, 245.53it/s]Running 10000 simulations.:  69%|██████▊   | 6860/10000 [00:29<00:12, 248.15it/s]Running 10000 simulations.:  69%|██████▉   | 6886/10000 [00:29<00:12, 250.80it/s]Running 10000 simulations.:  69%|██████▉   | 6912/10000 [00:29<00:12, 246.67it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:29<00:12, 242.71it/s]Running 10000 simulations.:  70%|██████▉   | 6962/10000 [00:29<00:12, 239.19it/s]Running 10000 simulations.:  70%|██████▉   | 6986/10000 [00:29<00:12, 236.53it/s]Running 10000 simulations.:  70%|███████   | 7010/10000 [00:29<00:12, 234.51it/s]Running 10000 simulations.:  70%|███████   | 7034/10000 [00:29<00:13, 224.30it/s]Running 10000 simulations.:  71%|███████   | 7058/10000 [00:30<00:13, 226.15it/s]Running 10000 simulations.:  71%|███████   | 7082/10000 [00:30<00:12, 227.47it/s]Running 10000 simulations.:  71%|███████   | 7105/10000 [00:30<00:12, 228.14it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:30<00:12, 228.80it/s]Running 10000 simulations.:  72%|███████▏  | 7153/10000 [00:30<00:12, 229.87it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:30<00:12, 231.08it/s]Running 10000 simulations.:  72%|███████▏  | 7201/10000 [00:30<00:12, 231.88it/s]Running 10000 simulations.:  72%|███████▏  | 7225/10000 [00:30<00:11, 232.63it/s]Running 10000 simulations.:  72%|███████▏  | 7249/10000 [00:30<00:11, 233.37it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:30<00:11, 233.68it/s]Running 10000 simulations.:  73%|███████▎  | 7297/10000 [00:31<00:11, 233.74it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:31<00:11, 233.97it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:31<00:11, 233.72it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:31<00:11, 233.98it/s]Running 10000 simulations.:  74%|███████▍  | 7393/10000 [00:31<00:11, 234.40it/s]Running 10000 simulations.:  74%|███████▍  | 7417/10000 [00:31<00:11, 234.47it/s]Running 10000 simulations.:  74%|███████▍  | 7441/10000 [00:31<00:10, 234.44it/s]Running 10000 simulations.:  75%|███████▍  | 7465/10000 [00:31<00:10, 234.50it/s]Running 10000 simulations.:  75%|███████▍  | 7489/10000 [00:31<00:10, 234.53it/s]Running 10000 simulations.:  75%|███████▌  | 7513/10000 [00:31<00:10, 234.68it/s]Running 10000 simulations.:  75%|███████▌  | 7537/10000 [00:32<00:10, 231.87it/s]Running 10000 simulations.:  76%|███████▌  | 7561/10000 [00:32<00:10, 232.42it/s]Running 10000 simulations.:  76%|███████▌  | 7585/10000 [00:32<00:10, 233.01it/s]Running 10000 simulations.:  76%|███████▌  | 7609/10000 [00:32<00:10, 233.15it/s]Running 10000 simulations.:  76%|███████▋  | 7633/10000 [00:32<00:10, 233.36it/s]Running 10000 simulations.:  77%|███████▋  | 7657/10000 [00:32<00:10, 232.47it/s]Running 10000 simulations.:  77%|███████▋  | 7681/10000 [00:32<00:10, 231.84it/s]Running 10000 simulations.:  77%|███████▋  | 7705/10000 [00:32<00:09, 231.30it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:32<00:09, 231.19it/s]Running 10000 simulations.:  78%|███████▊  | 7753/10000 [00:33<00:09, 230.95it/s]Running 10000 simulations.:  78%|███████▊  | 7777/10000 [00:33<00:09, 230.86it/s]Running 10000 simulations.:  78%|███████▊  | 7801/10000 [00:33<00:09, 230.64it/s]Running 10000 simulations.:  78%|███████▊  | 7825/10000 [00:33<00:09, 230.70it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:33<00:09, 230.49it/s]Running 10000 simulations.:  79%|███████▊  | 7873/10000 [00:33<00:09, 230.49it/s]Running 10000 simulations.:  79%|███████▉  | 7897/10000 [00:33<00:09, 230.52it/s]Running 10000 simulations.:  79%|███████▉  | 7921/10000 [00:33<00:08, 231.98it/s]Running 10000 simulations.:  79%|███████▉  | 7945/10000 [00:33<00:08, 232.40it/s]Running 10000 simulations.:  80%|███████▉  | 7969/10000 [00:33<00:08, 232.00it/s]Running 10000 simulations.:  80%|███████▉  | 7993/10000 [00:34<00:08, 232.19it/s]Running 10000 simulations.:  80%|████████  | 8017/10000 [00:34<00:08, 232.54it/s]Running 10000 simulations.:  80%|████████  | 8041/10000 [00:34<00:08, 232.36it/s]Running 10000 simulations.:  81%|████████  | 8065/10000 [00:34<00:08, 231.68it/s]Running 10000 simulations.:  81%|████████  | 8089/10000 [00:34<00:08, 232.09it/s]Running 10000 simulations.:  81%|████████  | 8113/10000 [00:34<00:08, 232.10it/s]Running 10000 simulations.:  81%|████████▏ | 8137/10000 [00:34<00:08, 231.77it/s]Running 10000 simulations.:  82%|████████▏ | 8161/10000 [00:34<00:07, 231.36it/s]Running 10000 simulations.:  82%|████████▏ | 8185/10000 [00:34<00:07, 230.87it/s]Running 10000 simulations.:  82%|████████▏ | 8209/10000 [00:34<00:07, 230.62it/s]Running 10000 simulations.:  82%|████████▏ | 8233/10000 [00:35<00:07, 230.59it/s]Running 10000 simulations.:  83%|████████▎ | 8257/10000 [00:35<00:07, 230.38it/s]Running 10000 simulations.:  83%|████████▎ | 8281/10000 [00:35<00:07, 230.45it/s]Running 10000 simulations.:  83%|████████▎ | 8305/10000 [00:35<00:07, 230.74it/s]Running 10000 simulations.:  83%|████████▎ | 8329/10000 [00:35<00:07, 230.70it/s]Running 10000 simulations.:  84%|████████▎ | 8353/10000 [00:35<00:07, 230.94it/s]Running 10000 simulations.:  84%|████████▍ | 8377/10000 [00:35<00:07, 230.48it/s]Running 10000 simulations.:  84%|████████▍ | 8401/10000 [00:35<00:06, 230.53it/s]Running 10000 simulations.:  84%|████████▍ | 8425/10000 [00:35<00:06, 230.88it/s]Running 10000 simulations.:  84%|████████▍ | 8449/10000 [00:36<00:06, 231.10it/s]Running 10000 simulations.:  85%|████████▍ | 8473/10000 [00:36<00:06, 233.59it/s]Running 10000 simulations.:  85%|████████▍ | 8498/10000 [00:36<00:06, 237.44it/s]Running 10000 simulations.:  85%|████████▌ | 8522/10000 [00:36<00:06, 236.98it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:36<00:05, 242.57it/s]Running 10000 simulations.:  86%|████████▌ | 8574/10000 [00:36<00:05, 246.74it/s]Running 10000 simulations.:  86%|████████▌ | 8600/10000 [00:36<00:05, 249.11it/s]Running 10000 simulations.:  86%|████████▋ | 8625/10000 [00:36<00:05, 246.86it/s]Running 10000 simulations.:  86%|████████▋ | 8650/10000 [00:36<00:05, 243.57it/s]Running 10000 simulations.:  87%|████████▋ | 8675/10000 [00:36<00:05, 237.98it/s]Running 10000 simulations.:  87%|████████▋ | 8699/10000 [00:37<00:05, 234.41it/s]Running 10000 simulations.:  87%|████████▋ | 8723/10000 [00:37<00:05, 232.12it/s]Running 10000 simulations.:  87%|████████▋ | 8747/10000 [00:37<00:05, 231.59it/s]Running 10000 simulations.:  88%|████████▊ | 8771/10000 [00:37<00:05, 231.09it/s]Running 10000 simulations.:  88%|████████▊ | 8795/10000 [00:37<00:05, 230.50it/s]Running 10000 simulations.:  88%|████████▊ | 8819/10000 [00:37<00:05, 230.38it/s]Running 10000 simulations.:  88%|████████▊ | 8843/10000 [00:37<00:05, 230.78it/s]Running 10000 simulations.:  89%|████████▊ | 8867/10000 [00:37<00:04, 230.64it/s]Running 10000 simulations.:  89%|████████▉ | 8891/10000 [00:37<00:04, 231.48it/s]Running 10000 simulations.:  89%|████████▉ | 8915/10000 [00:37<00:04, 232.33it/s]Running 10000 simulations.:  89%|████████▉ | 8939/10000 [00:38<00:04, 232.99it/s]Running 10000 simulations.:  90%|████████▉ | 8963/10000 [00:38<00:04, 233.46it/s]Running 10000 simulations.:  90%|████████▉ | 8987/10000 [00:38<00:04, 233.38it/s]Running 10000 simulations.:  90%|█████████ | 9011/10000 [00:38<00:04, 233.26it/s]Running 10000 simulations.:  90%|█████████ | 9035/10000 [00:38<00:04, 233.16it/s]Running 10000 simulations.:  91%|█████████ | 9059/10000 [00:38<00:04, 233.06it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [00:38<00:03, 232.50it/s]Running 10000 simulations.:  91%|█████████ | 9107/10000 [00:38<00:03, 226.78it/s]Running 10000 simulations.:  91%|█████████▏| 9130/10000 [00:38<00:03, 220.20it/s]Running 10000 simulations.:  92%|█████████▏| 9153/10000 [00:39<00:03, 215.55it/s]Running 10000 simulations.:  92%|█████████▏| 9175/10000 [00:39<00:03, 212.43it/s]Running 10000 simulations.:  92%|█████████▏| 9197/10000 [00:39<00:03, 210.56it/s]Running 10000 simulations.:  92%|█████████▏| 9219/10000 [00:39<00:03, 209.45it/s]Running 10000 simulations.:  92%|█████████▏| 9240/10000 [00:39<00:03, 208.83it/s]Running 10000 simulations.:  93%|█████████▎| 9261/10000 [00:39<00:03, 208.08it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [00:39<00:03, 207.87it/s]Running 10000 simulations.:  93%|█████████▎| 9303/10000 [00:39<00:03, 207.78it/s]Running 10000 simulations.:  93%|█████████▎| 9324/10000 [00:39<00:03, 208.00it/s]Running 10000 simulations.:  93%|█████████▎| 9346/10000 [00:39<00:03, 209.60it/s]Running 10000 simulations.:  94%|█████████▎| 9367/10000 [00:40<00:03, 208.91it/s]Running 10000 simulations.:  94%|█████████▍| 9388/10000 [00:40<00:02, 208.81it/s]Running 10000 simulations.:  94%|█████████▍| 9410/10000 [00:40<00:02, 211.66it/s]Running 10000 simulations.:  94%|█████████▍| 9434/10000 [00:40<00:02, 218.17it/s]Running 10000 simulations.:  95%|█████████▍| 9458/10000 [00:40<00:02, 222.91it/s]Running 10000 simulations.:  95%|█████████▍| 9482/10000 [00:40<00:02, 226.42it/s]Running 10000 simulations.:  95%|█████████▌| 9506/10000 [00:40<00:02, 228.87it/s]Running 10000 simulations.:  95%|█████████▌| 9530/10000 [00:40<00:02, 230.87it/s]Running 10000 simulations.:  96%|█████████▌| 9554/10000 [00:40<00:01, 231.86it/s]Running 10000 simulations.:  96%|█████████▌| 9578/10000 [00:41<00:01, 228.46it/s]Running 10000 simulations.:  96%|█████████▌| 9601/10000 [00:41<00:01, 221.86it/s]Running 10000 simulations.:  96%|█████████▌| 9624/10000 [00:41<00:01, 217.51it/s]Running 10000 simulations.:  96%|█████████▋| 9646/10000 [00:41<00:01, 214.10it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [00:41<00:01, 211.78it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [00:41<00:01, 209.75it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [00:41<00:01, 208.34it/s]Running 10000 simulations.:  97%|█████████▋| 9733/10000 [00:41<00:01, 207.39it/s]Running 10000 simulations.:  98%|█████████▊| 9754/10000 [00:41<00:01, 206.96it/s]Running 10000 simulations.:  98%|█████████▊| 9776/10000 [00:41<00:01, 210.60it/s]Running 10000 simulations.:  98%|█████████▊| 9800/10000 [00:42<00:00, 218.45it/s]Running 10000 simulations.:  98%|█████████▊| 9824/10000 [00:42<00:00, 223.86it/s]Running 10000 simulations.:  98%|█████████▊| 9848/10000 [00:42<00:00, 227.60it/s]Running 10000 simulations.:  99%|█████████▊| 9872/10000 [00:42<00:00, 230.56it/s]Running 10000 simulations.:  99%|█████████▉| 9896/10000 [00:42<00:00, 232.65it/s]Running 10000 simulations.:  99%|█████████▉| 9920/10000 [00:42<00:00, 234.57it/s]Running 10000 simulations.:  99%|█████████▉| 9944/10000 [00:42<00:00, 236.07it/s]Running 10000 simulations.: 100%|█████████▉| 9969/10000 [00:42<00:00, 237.88it/s]Running 10000 simulations.: 100%|█████████▉| 9994/10000 [00:42<00:00, 239.31it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:42<00:00, 233.13it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:40, 246.15it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:40, 246.38it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:40, 246.74it/s]Running 10000 simulations.:   1%|          | 98/10000 [00:00<00:41, 241.40it/s]Running 10000 simulations.:   1%|          | 122/10000 [00:00<00:41, 239.01it/s]Running 10000 simulations.:   1%|▏         | 147/10000 [00:00<00:40, 240.48it/s]Running 10000 simulations.:   2%|▏         | 172/10000 [00:00<00:40, 241.77it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:00<00:40, 241.90it/s]Running 10000 simulations.:   2%|▏         | 220/10000 [00:00<00:41, 236.70it/s]Running 10000 simulations.:   2%|▏         | 244/10000 [00:01<00:41, 236.03it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:01<00:40, 237.60it/s]Running 10000 simulations.:   3%|▎         | 294/10000 [00:01<00:40, 239.11it/s]Running 10000 simulations.:   3%|▎         | 318/10000 [00:01<00:40, 236.85it/s]Running 10000 simulations.:   3%|▎         | 342/10000 [00:01<00:41, 232.71it/s]Running 10000 simulations.:   4%|▎         | 367/10000 [00:01<00:40, 235.28it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:01<00:42, 226.79it/s]Running 10000 simulations.:   4%|▍         | 414/10000 [00:01<00:44, 216.44it/s]Running 10000 simulations.:   4%|▍         | 436/10000 [00:01<00:47, 202.70it/s]Running 10000 simulations.:   5%|▍         | 457/10000 [00:02<00:49, 194.17it/s]Running 10000 simulations.:   5%|▍         | 477/10000 [00:02<00:50, 189.05it/s]Running 10000 simulations.:   5%|▍         | 497/10000 [00:02<00:50, 189.08it/s]Running 10000 simulations.:   5%|▌         | 518/10000 [00:02<00:49, 192.93it/s]Running 10000 simulations.:   5%|▌         | 539/10000 [00:02<00:48, 195.78it/s]Running 10000 simulations.:   6%|▌         | 560/10000 [00:02<00:47, 197.92it/s]Running 10000 simulations.:   6%|▌         | 580/10000 [00:02<00:48, 194.14it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:02<00:49, 189.11it/s]Running 10000 simulations.:   6%|▌         | 620/10000 [00:02<00:49, 190.05it/s]Running 10000 simulations.:   6%|▋         | 641/10000 [00:02<00:48, 193.76it/s]Running 10000 simulations.:   7%|▋         | 662/10000 [00:03<00:47, 196.73it/s]Running 10000 simulations.:   7%|▋         | 683/10000 [00:03<00:47, 197.80it/s]Running 10000 simulations.:   7%|▋         | 703/10000 [00:03<00:48, 191.84it/s]Running 10000 simulations.:   7%|▋         | 723/10000 [00:03<00:49, 186.74it/s]Running 10000 simulations.:   7%|▋         | 742/10000 [00:03<00:50, 184.23it/s]Running 10000 simulations.:   8%|▊         | 761/10000 [00:03<00:50, 184.10it/s]Running 10000 simulations.:   8%|▊         | 781/10000 [00:03<00:49, 186.16it/s]Running 10000 simulations.:   8%|▊         | 801/10000 [00:03<00:48, 188.28it/s]Running 10000 simulations.:   8%|▊         | 821/10000 [00:03<00:47, 191.40it/s]Running 10000 simulations.:   8%|▊         | 842/10000 [00:04<00:47, 194.20it/s]Running 10000 simulations.:   9%|▊         | 863/10000 [00:04<00:46, 196.41it/s]Running 10000 simulations.:   9%|▉         | 884/10000 [00:04<00:46, 198.09it/s]Running 10000 simulations.:   9%|▉         | 904/10000 [00:04<00:46, 195.02it/s]Running 10000 simulations.:   9%|▉         | 924/10000 [00:04<00:48, 188.85it/s]Running 10000 simulations.:   9%|▉         | 943/10000 [00:04<00:48, 188.25it/s]Running 10000 simulations.:  10%|▉         | 964/10000 [00:04<00:46, 192.28it/s]Running 10000 simulations.:  10%|▉         | 985/10000 [00:04<00:46, 195.43it/s]Running 10000 simulations.:  10%|█         | 1006/10000 [00:04<00:45, 198.11it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:04<00:46, 193.67it/s]Running 10000 simulations.:  10%|█         | 1046/10000 [00:05<00:47, 188.50it/s]Running 10000 simulations.:  11%|█         | 1066/10000 [00:05<00:47, 189.65it/s]Running 10000 simulations.:  11%|█         | 1090/10000 [00:05<00:44, 201.64it/s]Running 10000 simulations.:  11%|█         | 1116/10000 [00:05<00:41, 214.29it/s]Running 10000 simulations.:  11%|█▏        | 1141/10000 [00:05<00:39, 221.99it/s]Running 10000 simulations.:  12%|█▏        | 1165/10000 [00:05<00:39, 225.49it/s]Running 10000 simulations.:  12%|█▏        | 1189/10000 [00:05<00:38, 227.95it/s]Running 10000 simulations.:  12%|█▏        | 1214/10000 [00:05<00:37, 233.13it/s]Running 10000 simulations.:  12%|█▏        | 1239/10000 [00:05<00:36, 237.59it/s]Running 10000 simulations.:  13%|█▎        | 1265/10000 [00:06<00:36, 241.63it/s]Running 10000 simulations.:  13%|█▎        | 1290/10000 [00:06<00:36, 236.48it/s]Running 10000 simulations.:  13%|█▎        | 1314/10000 [00:06<00:36, 235.68it/s]Running 10000 simulations.:  13%|█▎        | 1338/10000 [00:06<00:36, 236.10it/s]Running 10000 simulations.:  14%|█▎        | 1363/10000 [00:06<00:36, 239.78it/s]Running 10000 simulations.:  14%|█▍        | 1388/10000 [00:06<00:35, 242.28it/s]Running 10000 simulations.:  14%|█▍        | 1413/10000 [00:06<00:35, 243.49it/s]Running 10000 simulations.:  14%|█▍        | 1438/10000 [00:06<00:35, 239.23it/s]Running 10000 simulations.:  15%|█▍        | 1463/10000 [00:06<00:35, 240.48it/s]Running 10000 simulations.:  15%|█▍        | 1488/10000 [00:06<00:35, 242.42it/s]Running 10000 simulations.:  15%|█▌        | 1514/10000 [00:07<00:34, 245.42it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:07<00:34, 242.21it/s]Running 10000 simulations.:  16%|█▌        | 1564/10000 [00:07<00:34, 241.35it/s]Running 10000 simulations.:  16%|█▌        | 1589/10000 [00:07<00:34, 242.87it/s]Running 10000 simulations.:  16%|█▌        | 1614/10000 [00:07<00:34, 244.21it/s]Running 10000 simulations.:  16%|█▋        | 1639/10000 [00:07<00:34, 245.65it/s]Running 10000 simulations.:  17%|█▋        | 1664/10000 [00:07<00:34, 241.16it/s]Running 10000 simulations.:  17%|█▋        | 1689/10000 [00:07<00:34, 240.98it/s]Running 10000 simulations.:  17%|█▋        | 1714/10000 [00:07<00:34, 242.06it/s]Running 10000 simulations.:  17%|█▋        | 1739/10000 [00:07<00:34, 239.88it/s]Running 10000 simulations.:  18%|█▊        | 1764/10000 [00:08<00:34, 241.17it/s]Running 10000 simulations.:  18%|█▊        | 1790/10000 [00:08<00:33, 244.04it/s]Running 10000 simulations.:  18%|█▊        | 1815/10000 [00:08<00:33, 240.99it/s]Running 10000 simulations.:  18%|█▊        | 1840/10000 [00:08<00:33, 240.80it/s]Running 10000 simulations.:  19%|█▊        | 1865/10000 [00:08<00:33, 243.18it/s]Running 10000 simulations.:  19%|█▉        | 1891/10000 [00:08<00:33, 245.65it/s]Running 10000 simulations.:  19%|█▉        | 1916/10000 [00:08<00:32, 246.47it/s]Running 10000 simulations.:  19%|█▉        | 1941/10000 [00:08<00:33, 241.84it/s]Running 10000 simulations.:  20%|█▉        | 1966/10000 [00:08<00:33, 239.76it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:09<00:33, 240.37it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:09<00:33, 241.85it/s]Running 10000 simulations.:  20%|██        | 2041/10000 [00:09<00:32, 244.06it/s]Running 10000 simulations.:  21%|██        | 2066/10000 [00:09<00:32, 244.35it/s]Running 10000 simulations.:  21%|██        | 2091/10000 [00:09<00:32, 240.83it/s]Running 10000 simulations.:  21%|██        | 2116/10000 [00:09<00:32, 241.74it/s]Running 10000 simulations.:  21%|██▏       | 2141/10000 [00:09<00:32, 243.98it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:09<00:31, 246.60it/s]Running 10000 simulations.:  22%|██▏       | 2192/10000 [00:09<00:32, 242.41it/s]Running 10000 simulations.:  22%|██▏       | 2217/10000 [00:09<00:32, 241.52it/s]Running 10000 simulations.:  22%|██▏       | 2242/10000 [00:10<00:31, 242.54it/s]Running 10000 simulations.:  23%|██▎       | 2268/10000 [00:10<00:31, 244.83it/s]Running 10000 simulations.:  23%|██▎       | 2293/10000 [00:10<00:31, 244.96it/s]Running 10000 simulations.:  23%|██▎       | 2318/10000 [00:10<00:31, 240.86it/s]Running 10000 simulations.:  23%|██▎       | 2343/10000 [00:10<00:31, 241.60it/s]Running 10000 simulations.:  24%|██▎       | 2368/10000 [00:10<00:31, 243.29it/s]Running 10000 simulations.:  24%|██▍       | 2393/10000 [00:10<00:31, 245.00it/s]Running 10000 simulations.:  24%|██▍       | 2418/10000 [00:10<00:31, 242.29it/s]Running 10000 simulations.:  24%|██▍       | 2443/10000 [00:10<00:31, 238.17it/s]Running 10000 simulations.:  25%|██▍       | 2468/10000 [00:10<00:31, 239.78it/s]Running 10000 simulations.:  25%|██▍       | 2493/10000 [00:11<00:31, 241.75it/s]Running 10000 simulations.:  25%|██▌       | 2518/10000 [00:11<00:30, 242.97it/s]Running 10000 simulations.:  25%|██▌       | 2543/10000 [00:11<00:31, 239.39it/s]Running 10000 simulations.:  26%|██▌       | 2567/10000 [00:11<00:31, 236.30it/s]Running 10000 simulations.:  26%|██▌       | 2591/10000 [00:11<00:31, 237.35it/s]Running 10000 simulations.:  26%|██▌       | 2616/10000 [00:11<00:30, 240.92it/s]Running 10000 simulations.:  26%|██▋       | 2641/10000 [00:11<00:30, 243.48it/s]Running 10000 simulations.:  27%|██▋       | 2666/10000 [00:11<00:30, 242.56it/s]Running 10000 simulations.:  27%|██▋       | 2691/10000 [00:11<00:30, 239.50it/s]Running 10000 simulations.:  27%|██▋       | 2715/10000 [00:12<00:30, 238.59it/s]Running 10000 simulations.:  27%|██▋       | 2739/10000 [00:12<00:30, 238.39it/s]Running 10000 simulations.:  28%|██▊       | 2764/10000 [00:12<00:30, 239.74it/s]Running 10000 simulations.:  28%|██▊       | 2789/10000 [00:12<00:29, 241.13it/s]Running 10000 simulations.:  28%|██▊       | 2814/10000 [00:12<00:29, 243.53it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:12<00:29, 241.08it/s]Running 10000 simulations.:  29%|██▊       | 2864/10000 [00:12<00:29, 238.67it/s]Running 10000 simulations.:  29%|██▉       | 2889/10000 [00:12<00:29, 240.99it/s]Running 10000 simulations.:  29%|██▉       | 2914/10000 [00:12<00:29, 243.36it/s]Running 10000 simulations.:  29%|██▉       | 2939/10000 [00:12<00:28, 244.15it/s]Running 10000 simulations.:  30%|██▉       | 2964/10000 [00:13<00:29, 239.87it/s]Running 10000 simulations.:  30%|██▉       | 2989/10000 [00:13<00:29, 237.38it/s]Running 10000 simulations.:  30%|███       | 3014/10000 [00:13<00:29, 238.53it/s]Running 10000 simulations.:  30%|███       | 3039/10000 [00:13<00:28, 240.40it/s]Running 10000 simulations.:  31%|███       | 3064/10000 [00:13<00:28, 242.70it/s]Running 10000 simulations.:  31%|███       | 3089/10000 [00:13<00:28, 239.58it/s]Running 10000 simulations.:  31%|███       | 3113/10000 [00:13<00:28, 237.77it/s]Running 10000 simulations.:  31%|███▏      | 3138/10000 [00:13<00:28, 239.74it/s]Running 10000 simulations.:  32%|███▏      | 3163/10000 [00:13<00:28, 241.37it/s]Running 10000 simulations.:  32%|███▏      | 3188/10000 [00:13<00:28, 242.80it/s]Running 10000 simulations.:  32%|███▏      | 3213/10000 [00:14<00:28, 238.60it/s]Running 10000 simulations.:  32%|███▏      | 3238/10000 [00:14<00:28, 239.36it/s]Running 10000 simulations.:  33%|███▎      | 3263/10000 [00:14<00:27, 241.71it/s]Running 10000 simulations.:  33%|███▎      | 3289/10000 [00:14<00:27, 244.56it/s]Running 10000 simulations.:  33%|███▎      | 3314/10000 [00:14<00:27, 240.93it/s]Running 10000 simulations.:  33%|███▎      | 3339/10000 [00:14<00:27, 239.76it/s]Running 10000 simulations.:  34%|███▎      | 3364/10000 [00:14<00:27, 241.83it/s]Running 10000 simulations.:  34%|███▍      | 3389/10000 [00:14<00:27, 243.13it/s]Running 10000 simulations.:  34%|███▍      | 3414/10000 [00:14<00:27, 243.05it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:15<00:27, 238.39it/s]Running 10000 simulations.:  35%|███▍      | 3464/10000 [00:15<00:27, 239.34it/s]Running 10000 simulations.:  35%|███▍      | 3489/10000 [00:15<00:27, 240.27it/s]Running 10000 simulations.:  35%|███▌      | 3514/10000 [00:15<00:26, 242.12it/s]Running 10000 simulations.:  35%|███▌      | 3539/10000 [00:15<00:27, 237.64it/s]Running 10000 simulations.:  36%|███▌      | 3563/10000 [00:15<00:27, 236.78it/s]Running 10000 simulations.:  36%|███▌      | 3588/10000 [00:15<00:26, 239.04it/s]Running 10000 simulations.:  36%|███▌      | 3612/10000 [00:15<00:26, 237.64it/s]Running 10000 simulations.:  36%|███▋      | 3637/10000 [00:15<00:26, 238.75it/s]Running 10000 simulations.:  37%|███▋      | 3662/10000 [00:15<00:26, 241.34it/s]Running 10000 simulations.:  37%|███▋      | 3687/10000 [00:16<00:26, 237.30it/s]Running 10000 simulations.:  37%|███▋      | 3711/10000 [00:16<00:26, 236.01it/s]Running 10000 simulations.:  37%|███▋      | 3736/10000 [00:16<00:26, 238.40it/s]Running 10000 simulations.:  38%|███▊      | 3761/10000 [00:16<00:25, 240.27it/s]Running 10000 simulations.:  38%|███▊      | 3786/10000 [00:16<00:25, 240.50it/s]Running 10000 simulations.:  38%|███▊      | 3811/10000 [00:16<00:26, 236.38it/s]Running 10000 simulations.:  38%|███▊      | 3836/10000 [00:16<00:25, 238.17it/s]Running 10000 simulations.:  39%|███▊      | 3861/10000 [00:16<00:25, 240.17it/s]Running 10000 simulations.:  39%|███▉      | 3886/10000 [00:16<00:25, 242.87it/s]Running 10000 simulations.:  39%|███▉      | 3911/10000 [00:16<00:25, 239.16it/s]Running 10000 simulations.:  39%|███▉      | 3935/10000 [00:17<00:25, 238.23it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:17<00:25, 239.71it/s]Running 10000 simulations.:  40%|███▉      | 3985/10000 [00:17<00:24, 241.35it/s]Running 10000 simulations.:  40%|████      | 4010/10000 [00:17<00:24, 240.46it/s]Running 10000 simulations.:  40%|████      | 4035/10000 [00:17<00:25, 237.55it/s]Running 10000 simulations.:  41%|████      | 4060/10000 [00:17<00:24, 239.79it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:17<00:24, 241.84it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:17<00:24, 243.06it/s]Running 10000 simulations.:  41%|████▏     | 4135/10000 [00:17<00:24, 238.60it/s]Running 10000 simulations.:  42%|████▏     | 4159/10000 [00:18<00:24, 237.31it/s]Running 10000 simulations.:  42%|████▏     | 4184/10000 [00:18<00:24, 239.38it/s]Running 10000 simulations.:  42%|████▏     | 4209/10000 [00:18<00:23, 241.32it/s]Running 10000 simulations.:  42%|████▏     | 4234/10000 [00:18<00:23, 240.37it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:18<00:24, 237.05it/s]Running 10000 simulations.:  43%|████▎     | 4283/10000 [00:18<00:24, 234.95it/s]Running 10000 simulations.:  43%|████▎     | 4308/10000 [00:18<00:23, 237.78it/s]Running 10000 simulations.:  43%|████▎     | 4333/10000 [00:18<00:23, 240.15it/s]Running 10000 simulations.:  44%|████▎     | 4359/10000 [00:18<00:23, 243.55it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:18<00:23, 239.74it/s]Running 10000 simulations.:  44%|████▍     | 4409/10000 [00:19<00:23, 236.59it/s]Running 10000 simulations.:  44%|████▍     | 4433/10000 [00:19<00:23, 236.25it/s]Running 10000 simulations.:  45%|████▍     | 4458/10000 [00:19<00:23, 239.95it/s]Running 10000 simulations.:  45%|████▍     | 4484/10000 [00:19<00:22, 243.20it/s]Running 10000 simulations.:  45%|████▌     | 4509/10000 [00:19<00:22, 242.49it/s]Running 10000 simulations.:  45%|████▌     | 4534/10000 [00:19<00:22, 238.19it/s]Running 10000 simulations.:  46%|████▌     | 4558/10000 [00:19<00:23, 235.84it/s]Running 10000 simulations.:  46%|████▌     | 4582/10000 [00:19<00:22, 236.40it/s]Running 10000 simulations.:  46%|████▌     | 4606/10000 [00:19<00:22, 235.86it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:20<00:22, 238.18it/s]Running 10000 simulations.:  47%|████▋     | 4656/10000 [00:20<00:22, 240.66it/s]Running 10000 simulations.:  47%|████▋     | 4681/10000 [00:20<00:21, 242.98it/s]Running 10000 simulations.:  47%|████▋     | 4706/10000 [00:20<00:22, 237.92it/s]Running 10000 simulations.:  47%|████▋     | 4730/10000 [00:20<00:22, 234.61it/s]Running 10000 simulations.:  48%|████▊     | 4754/10000 [00:20<00:22, 234.86it/s]Running 10000 simulations.:  48%|████▊     | 4779/10000 [00:20<00:21, 238.19it/s]Running 10000 simulations.:  48%|████▊     | 4804/10000 [00:20<00:21, 240.67it/s]Running 10000 simulations.:  48%|████▊     | 4829/10000 [00:20<00:21, 241.02it/s]Running 10000 simulations.:  49%|████▊     | 4854/10000 [00:20<00:21, 238.20it/s]Running 10000 simulations.:  49%|████▉     | 4878/10000 [00:21<00:21, 234.94it/s]Running 10000 simulations.:  49%|████▉     | 4902/10000 [00:21<00:21, 235.88it/s]Running 10000 simulations.:  49%|████▉     | 4927/10000 [00:21<00:21, 238.38it/s]Running 10000 simulations.:  50%|████▉     | 4952/10000 [00:21<00:20, 240.50it/s]Running 10000 simulations.:  50%|████▉     | 4977/10000 [00:21<00:20, 240.19it/s]Running 10000 simulations.:  50%|█████     | 5002/10000 [00:21<00:21, 236.61it/s]Running 10000 simulations.:  50%|█████     | 5026/10000 [00:21<00:21, 235.94it/s]Running 10000 simulations.:  51%|█████     | 5051/10000 [00:21<00:20, 237.46it/s]Running 10000 simulations.:  51%|█████     | 5076/10000 [00:21<00:20, 240.42it/s]Running 10000 simulations.:  51%|█████     | 5101/10000 [00:21<00:20, 242.93it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:22<00:20, 238.55it/s]Running 10000 simulations.:  52%|█████▏    | 5150/10000 [00:22<00:20, 235.33it/s]Running 10000 simulations.:  52%|█████▏    | 5174/10000 [00:22<00:20, 234.16it/s]Running 10000 simulations.:  52%|█████▏    | 5199/10000 [00:22<00:20, 237.75it/s]Running 10000 simulations.:  52%|█████▏    | 5224/10000 [00:22<00:19, 239.26it/s]Running 10000 simulations.:  52%|█████▏    | 5249/10000 [00:22<00:19, 239.46it/s]Running 10000 simulations.:  53%|█████▎    | 5273/10000 [00:22<00:20, 234.56it/s]Running 10000 simulations.:  53%|█████▎    | 5297/10000 [00:22<00:20, 230.48it/s]Running 10000 simulations.:  53%|█████▎    | 5321/10000 [00:22<00:20, 230.04it/s]Running 10000 simulations.:  53%|█████▎    | 5345/10000 [00:23<00:20, 230.65it/s]Running 10000 simulations.:  54%|█████▎    | 5369/10000 [00:23<00:19, 231.90it/s]Running 10000 simulations.:  54%|█████▍    | 5393/10000 [00:23<00:20, 229.88it/s]Running 10000 simulations.:  54%|█████▍    | 5417/10000 [00:23<00:20, 224.77it/s]Running 10000 simulations.:  54%|█████▍    | 5440/10000 [00:23<00:20, 221.95it/s]Running 10000 simulations.:  55%|█████▍    | 5463/10000 [00:23<00:20, 222.63it/s]Running 10000 simulations.:  55%|█████▍    | 5487/10000 [00:23<00:19, 226.42it/s]Running 10000 simulations.:  55%|█████▌    | 5511/10000 [00:23<00:19, 229.12it/s]Running 10000 simulations.:  55%|█████▌    | 5534/10000 [00:23<00:19, 228.55it/s]Running 10000 simulations.:  56%|█████▌    | 5557/10000 [00:23<00:19, 222.92it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:24<00:20, 220.15it/s]Running 10000 simulations.:  56%|█████▌    | 5603/10000 [00:24<00:19, 220.38it/s]Running 10000 simulations.:  56%|█████▋    | 5626/10000 [00:24<00:19, 223.06it/s]Running 10000 simulations.:  56%|█████▋    | 5649/10000 [00:24<00:19, 223.07it/s]Running 10000 simulations.:  57%|█████▋    | 5672/10000 [00:24<00:19, 224.52it/s]Running 10000 simulations.:  57%|█████▋    | 5696/10000 [00:24<00:19, 226.52it/s]Running 10000 simulations.:  57%|█████▋    | 5719/10000 [00:24<00:19, 225.02it/s]Running 10000 simulations.:  57%|█████▋    | 5742/10000 [00:24<00:19, 221.82it/s]Running 10000 simulations.:  58%|█████▊    | 5765/10000 [00:24<00:19, 219.44it/s]Running 10000 simulations.:  58%|█████▊    | 5788/10000 [00:25<00:19, 221.21it/s]Running 10000 simulations.:  58%|█████▊    | 5811/10000 [00:25<00:18, 223.15it/s]Running 10000 simulations.:  58%|█████▊    | 5834/10000 [00:25<00:18, 224.75it/s]Running 10000 simulations.:  59%|█████▊    | 5857/10000 [00:25<00:18, 221.83it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:25<00:18, 218.16it/s]Running 10000 simulations.:  59%|█████▉    | 5902/10000 [00:25<00:18, 216.23it/s]Running 10000 simulations.:  59%|█████▉    | 5925/10000 [00:25<00:18, 218.57it/s]Running 10000 simulations.:  59%|█████▉    | 5948/10000 [00:25<00:18, 221.16it/s]Running 10000 simulations.:  60%|█████▉    | 5971/10000 [00:25<00:18, 222.67it/s]Running 10000 simulations.:  60%|█████▉    | 5994/10000 [00:25<00:18, 220.28it/s]Running 10000 simulations.:  60%|██████    | 6017/10000 [00:26<00:19, 207.62it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:26<00:18, 209.83it/s]Running 10000 simulations.:  61%|██████    | 6062/10000 [00:26<00:18, 214.82it/s]Running 10000 simulations.:  61%|██████    | 6085/10000 [00:26<00:17, 218.55it/s]Running 10000 simulations.:  61%|██████    | 6109/10000 [00:26<00:17, 222.03it/s]Running 10000 simulations.:  61%|██████▏   | 6132/10000 [00:26<00:17, 220.50it/s]Running 10000 simulations.:  62%|██████▏   | 6155/10000 [00:26<00:17, 218.65it/s]Running 10000 simulations.:  62%|██████▏   | 6178/10000 [00:26<00:17, 220.93it/s]Running 10000 simulations.:  62%|██████▏   | 6202/10000 [00:26<00:16, 224.43it/s]Running 10000 simulations.:  62%|██████▏   | 6226/10000 [00:26<00:16, 226.41it/s]Running 10000 simulations.:  62%|██████▏   | 6249/10000 [00:27<00:16, 226.05it/s]Running 10000 simulations.:  63%|██████▎   | 6272/10000 [00:27<00:16, 222.12it/s]Running 10000 simulations.:  63%|██████▎   | 6295/10000 [00:27<00:16, 220.52it/s]Running 10000 simulations.:  63%|██████▎   | 6318/10000 [00:27<00:16, 221.23it/s]Running 10000 simulations.:  63%|██████▎   | 6342/10000 [00:27<00:16, 223.83it/s]Running 10000 simulations.:  64%|██████▎   | 6366/10000 [00:27<00:16, 226.19it/s]Running 10000 simulations.:  64%|██████▍   | 6389/10000 [00:27<00:16, 224.91it/s]Running 10000 simulations.:  64%|██████▍   | 6412/10000 [00:27<00:16, 222.10it/s]Running 10000 simulations.:  64%|██████▍   | 6435/10000 [00:27<00:16, 220.60it/s]Running 10000 simulations.:  65%|██████▍   | 6459/10000 [00:28<00:15, 223.66it/s]Running 10000 simulations.:  65%|██████▍   | 6483/10000 [00:28<00:15, 226.64it/s]Running 10000 simulations.:  65%|██████▌   | 6507/10000 [00:28<00:15, 228.59it/s]Running 10000 simulations.:  65%|██████▌   | 6530/10000 [00:28<00:15, 225.39it/s]Running 10000 simulations.:  66%|██████▌   | 6553/10000 [00:28<00:15, 223.10it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:28<00:15, 221.90it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:28<00:15, 225.96it/s]Running 10000 simulations.:  66%|██████▌   | 6624/10000 [00:28<00:14, 228.05it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:28<00:14, 228.78it/s]Running 10000 simulations.:  67%|██████▋   | 6671/10000 [00:28<00:14, 224.64it/s]Running 10000 simulations.:  67%|██████▋   | 6694/10000 [00:29<00:14, 221.65it/s]Running 10000 simulations.:  67%|██████▋   | 6717/10000 [00:29<00:14, 220.66it/s]Running 10000 simulations.:  67%|██████▋   | 6740/10000 [00:29<00:14, 222.89it/s]Running 10000 simulations.:  68%|██████▊   | 6763/10000 [00:29<00:14, 222.28it/s]Running 10000 simulations.:  68%|██████▊   | 6786/10000 [00:29<00:14, 223.67it/s]Running 10000 simulations.:  68%|██████▊   | 6810/10000 [00:29<00:14, 227.26it/s]Running 10000 simulations.:  68%|██████▊   | 6833/10000 [00:29<00:13, 226.92it/s]Running 10000 simulations.:  69%|██████▊   | 6856/10000 [00:29<00:14, 222.68it/s]Running 10000 simulations.:  69%|██████▉   | 6879/10000 [00:29<00:14, 220.23it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:30<00:14, 220.65it/s]Running 10000 simulations.:  69%|██████▉   | 6925/10000 [00:30<00:13, 222.95it/s]Running 10000 simulations.:  69%|██████▉   | 6948/10000 [00:30<00:13, 224.71it/s]Running 10000 simulations.:  70%|██████▉   | 6971/10000 [00:30<00:13, 223.58it/s]Running 10000 simulations.:  70%|██████▉   | 6994/10000 [00:30<00:13, 220.58it/s]Running 10000 simulations.:  70%|███████   | 7017/10000 [00:30<00:13, 218.28it/s]Running 10000 simulations.:  70%|███████   | 7040/10000 [00:30<00:13, 219.78it/s]Running 10000 simulations.:  71%|███████   | 7063/10000 [00:30<00:13, 221.94it/s]Running 10000 simulations.:  71%|███████   | 7086/10000 [00:30<00:13, 223.97it/s]Running 10000 simulations.:  71%|███████   | 7109/10000 [00:30<00:13, 221.57it/s]Running 10000 simulations.:  71%|███████▏  | 7132/10000 [00:31<00:13, 219.44it/s]Running 10000 simulations.:  72%|███████▏  | 7154/10000 [00:31<00:12, 218.93it/s]Running 10000 simulations.:  72%|███████▏  | 7178/10000 [00:31<00:12, 224.13it/s]Running 10000 simulations.:  72%|███████▏  | 7204/10000 [00:31<00:12, 232.57it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:31<00:11, 238.62it/s]Running 10000 simulations.:  73%|███████▎  | 7254/10000 [00:31<00:11, 236.96it/s]Running 10000 simulations.:  73%|███████▎  | 7278/10000 [00:31<00:11, 235.57it/s]Running 10000 simulations.:  73%|███████▎  | 7302/10000 [00:31<00:11, 236.76it/s]Running 10000 simulations.:  73%|███████▎  | 7328/10000 [00:31<00:11, 241.76it/s]Running 10000 simulations.:  74%|███████▎  | 7354/10000 [00:31<00:10, 245.85it/s]Running 10000 simulations.:  74%|███████▍  | 7379/10000 [00:32<00:10, 247.03it/s]Running 10000 simulations.:  74%|███████▍  | 7404/10000 [00:32<00:10, 238.09it/s]Running 10000 simulations.:  74%|███████▍  | 7428/10000 [00:32<00:11, 230.69it/s]Running 10000 simulations.:  75%|███████▍  | 7452/10000 [00:32<00:11, 231.01it/s]Running 10000 simulations.:  75%|███████▍  | 7476/10000 [00:32<00:10, 233.06it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:32<00:10, 233.97it/s]Running 10000 simulations.:  75%|███████▌  | 7524/10000 [00:32<00:10, 229.85it/s]Running 10000 simulations.:  75%|███████▌  | 7548/10000 [00:32<00:10, 226.84it/s]Running 10000 simulations.:  76%|███████▌  | 7571/10000 [00:32<00:10, 223.87it/s]Running 10000 simulations.:  76%|███████▌  | 7594/10000 [00:33<00:10, 225.60it/s]Running 10000 simulations.:  76%|███████▌  | 7618/10000 [00:33<00:10, 228.56it/s]Running 10000 simulations.:  76%|███████▋  | 7642/10000 [00:33<00:10, 230.43it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:33<00:10, 225.16it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:33<00:10, 220.95it/s]Running 10000 simulations.:  77%|███████▋  | 7712/10000 [00:33<00:10, 218.66it/s]Running 10000 simulations.:  77%|███████▋  | 7735/10000 [00:33<00:10, 220.99it/s]Running 10000 simulations.:  78%|███████▊  | 7758/10000 [00:33<00:10, 223.01it/s]Running 10000 simulations.:  78%|███████▊  | 7781/10000 [00:33<00:09, 224.31it/s]Running 10000 simulations.:  78%|███████▊  | 7804/10000 [00:33<00:09, 221.54it/s]Running 10000 simulations.:  78%|███████▊  | 7827/10000 [00:34<00:09, 218.46it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:34<00:09, 217.78it/s]Running 10000 simulations.:  79%|███████▊  | 7872/10000 [00:34<00:09, 220.89it/s]Running 10000 simulations.:  79%|███████▉  | 7895/10000 [00:34<00:09, 217.58it/s]Running 10000 simulations.:  79%|███████▉  | 7917/10000 [00:34<00:09, 211.64it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:34<00:09, 208.50it/s]Running 10000 simulations.:  80%|███████▉  | 7960/10000 [00:34<00:09, 206.89it/s]Running 10000 simulations.:  80%|███████▉  | 7981/10000 [00:34<00:09, 202.27it/s]Running 10000 simulations.:  80%|████████  | 8002/10000 [00:34<00:10, 194.78it/s]Running 10000 simulations.:  80%|████████  | 8022/10000 [00:35<00:10, 190.17it/s]Running 10000 simulations.:  80%|████████  | 8042/10000 [00:35<00:10, 188.64it/s]Running 10000 simulations.:  81%|████████  | 8063/10000 [00:35<00:10, 192.83it/s]Running 10000 simulations.:  81%|████████  | 8084/10000 [00:35<00:09, 197.36it/s]Running 10000 simulations.:  81%|████████  | 8104/10000 [00:35<00:09, 197.53it/s]Running 10000 simulations.:  81%|████████  | 8124/10000 [00:35<00:09, 196.13it/s]Running 10000 simulations.:  81%|████████▏ | 8144/10000 [00:35<00:09, 190.32it/s]Running 10000 simulations.:  82%|████████▏ | 8164/10000 [00:35<00:09, 187.87it/s]Running 10000 simulations.:  82%|████████▏ | 8186/10000 [00:35<00:09, 194.26it/s]Running 10000 simulations.:  82%|████████▏ | 8209/10000 [00:35<00:08, 201.66it/s]Running 10000 simulations.:  82%|████████▏ | 8232/10000 [00:36<00:08, 207.45it/s]Running 10000 simulations.:  83%|████████▎ | 8255/10000 [00:36<00:08, 211.56it/s]Running 10000 simulations.:  83%|████████▎ | 8277/10000 [00:36<00:08, 211.26it/s]Running 10000 simulations.:  83%|████████▎ | 8299/10000 [00:36<00:08, 210.81it/s]Running 10000 simulations.:  83%|████████▎ | 8321/10000 [00:36<00:07, 211.67it/s]Running 10000 simulations.:  83%|████████▎ | 8344/10000 [00:36<00:07, 215.14it/s]Running 10000 simulations.:  84%|████████▎ | 8367/10000 [00:36<00:07, 217.62it/s]Running 10000 simulations.:  84%|████████▍ | 8390/10000 [00:36<00:07, 219.42it/s]Running 10000 simulations.:  84%|████████▍ | 8412/10000 [00:36<00:07, 216.71it/s]Running 10000 simulations.:  84%|████████▍ | 8434/10000 [00:37<00:07, 214.63it/s]Running 10000 simulations.:  85%|████████▍ | 8456/10000 [00:37<00:07, 214.85it/s]Running 10000 simulations.:  85%|████████▍ | 8479/10000 [00:37<00:06, 217.80it/s]Running 10000 simulations.:  85%|████████▌ | 8502/10000 [00:37<00:06, 220.13it/s]Running 10000 simulations.:  85%|████████▌ | 8525/10000 [00:37<00:06, 222.09it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:37<00:06, 218.72it/s]Running 10000 simulations.:  86%|████████▌ | 8570/10000 [00:37<00:06, 216.19it/s]Running 10000 simulations.:  86%|████████▌ | 8592/10000 [00:37<00:06, 214.87it/s]Running 10000 simulations.:  86%|████████▌ | 8615/10000 [00:37<00:06, 216.90it/s]Running 10000 simulations.:  86%|████████▋ | 8638/10000 [00:37<00:06, 218.31it/s]Running 10000 simulations.:  87%|████████▋ | 8661/10000 [00:38<00:06, 219.20it/s]Running 10000 simulations.:  87%|████████▋ | 8683/10000 [00:38<00:06, 215.71it/s]Running 10000 simulations.:  87%|████████▋ | 8705/10000 [00:38<00:06, 215.67it/s]Running 10000 simulations.:  87%|████████▋ | 8728/10000 [00:38<00:05, 217.65it/s]Running 10000 simulations.:  88%|████████▊ | 8751/10000 [00:38<00:05, 219.48it/s]Running 10000 simulations.:  88%|████████▊ | 8773/10000 [00:38<00:05, 219.38it/s]Running 10000 simulations.:  88%|████████▊ | 8795/10000 [00:38<00:05, 214.58it/s]Running 10000 simulations.:  88%|████████▊ | 8817/10000 [00:38<00:05, 213.10it/s]Running 10000 simulations.:  88%|████████▊ | 8839/10000 [00:38<00:05, 214.20it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [00:39<00:05, 216.91it/s]Running 10000 simulations.:  89%|████████▉ | 8885/10000 [00:39<00:05, 219.13it/s]Running 10000 simulations.:  89%|████████▉ | 8907/10000 [00:39<00:04, 218.60it/s]Running 10000 simulations.:  89%|████████▉ | 8929/10000 [00:39<00:04, 215.68it/s]Running 10000 simulations.:  90%|████████▉ | 8951/10000 [00:39<00:04, 216.42it/s]Running 10000 simulations.:  90%|████████▉ | 8974/10000 [00:39<00:04, 217.62it/s]Running 10000 simulations.:  90%|████████▉ | 8997/10000 [00:39<00:04, 219.60it/s]Running 10000 simulations.:  90%|█████████ | 9020/10000 [00:39<00:04, 220.82it/s]Running 10000 simulations.:  90%|█████████ | 9043/10000 [00:39<00:04, 222.83it/s]Running 10000 simulations.:  91%|█████████ | 9066/10000 [00:39<00:04, 220.68it/s]Running 10000 simulations.:  91%|█████████ | 9089/10000 [00:40<00:04, 220.07it/s]Running 10000 simulations.:  91%|█████████ | 9112/10000 [00:40<00:04, 221.96it/s]Running 10000 simulations.:  91%|█████████▏| 9135/10000 [00:40<00:03, 223.79it/s]Running 10000 simulations.:  92%|█████████▏| 9158/10000 [00:40<00:03, 224.88it/s]Running 10000 simulations.:  92%|█████████▏| 9181/10000 [00:40<00:03, 221.60it/s]Running 10000 simulations.:  92%|█████████▏| 9204/10000 [00:40<00:03, 219.11it/s]Running 10000 simulations.:  92%|█████████▏| 9226/10000 [00:40<00:03, 219.34it/s]Running 10000 simulations.:  92%|█████████▏| 9249/10000 [00:40<00:03, 222.00it/s]Running 10000 simulations.:  93%|█████████▎| 9272/10000 [00:40<00:03, 223.67it/s]Running 10000 simulations.:  93%|█████████▎| 9295/10000 [00:40<00:03, 223.84it/s]Running 10000 simulations.:  93%|█████████▎| 9318/10000 [00:41<00:03, 220.73it/s]Running 10000 simulations.:  93%|█████████▎| 9341/10000 [00:41<00:03, 219.52it/s]Running 10000 simulations.:  94%|█████████▎| 9364/10000 [00:41<00:02, 220.65it/s]Running 10000 simulations.:  94%|█████████▍| 9387/10000 [00:41<00:02, 222.50it/s]Running 10000 simulations.:  94%|█████████▍| 9410/10000 [00:41<00:02, 224.68it/s]Running 10000 simulations.:  94%|█████████▍| 9433/10000 [00:41<00:02, 224.38it/s]Running 10000 simulations.:  95%|█████████▍| 9456/10000 [00:41<00:02, 221.25it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [00:41<00:02, 223.37it/s]Running 10000 simulations.:  95%|█████████▌| 9502/10000 [00:41<00:02, 224.93it/s]Running 10000 simulations.:  95%|█████████▌| 9526/10000 [00:41<00:02, 228.03it/s]Running 10000 simulations.:  95%|█████████▌| 9549/10000 [00:42<00:02, 224.98it/s]Running 10000 simulations.:  96%|█████████▌| 9572/10000 [00:42<00:01, 224.28it/s]Running 10000 simulations.:  96%|█████████▌| 9595/10000 [00:42<00:01, 225.21it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [00:42<00:01, 226.23it/s]Running 10000 simulations.:  96%|█████████▋| 9641/10000 [00:42<00:01, 225.40it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [00:42<00:01, 222.20it/s]Running 10000 simulations.:  97%|█████████▋| 9687/10000 [00:42<00:01, 223.30it/s]Running 10000 simulations.:  97%|█████████▋| 9711/10000 [00:42<00:01, 225.32it/s]Running 10000 simulations.:  97%|█████████▋| 9735/10000 [00:42<00:01, 227.59it/s]Running 10000 simulations.:  98%|█████████▊| 9758/10000 [00:43<00:01, 224.83it/s]Running 10000 simulations.:  98%|█████████▊| 9781/10000 [00:43<00:00, 224.05it/s]Running 10000 simulations.:  98%|█████████▊| 9805/10000 [00:43<00:00, 226.39it/s]Running 10000 simulations.:  98%|█████████▊| 9828/10000 [00:43<00:00, 225.94it/s]Running 10000 simulations.:  99%|█████████▊| 9851/10000 [00:43<00:00, 226.95it/s]Running 10000 simulations.:  99%|█████████▉| 9875/10000 [00:43<00:00, 229.02it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:43<00:00, 229.31it/s]Running 10000 simulations.:  99%|█████████▉| 9922/10000 [00:43<00:00, 226.33it/s]Running 10000 simulations.:  99%|█████████▉| 9945/10000 [00:43<00:00, 225.69it/s]Running 10000 simulations.: 100%|█████████▉| 9969/10000 [00:43<00:00, 228.36it/s]Running 10000 simulations.: 100%|█████████▉| 9993/10000 [00:44<00:00, 230.62it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:44<00:00, 226.85it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 270.04it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<00:36, 270.73it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<00:36, 270.83it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<00:36, 272.82it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:36, 273.27it/s]Running 10000 simulations.:   2%|▏         | 167/10000 [00:00<00:36, 272.09it/s]Running 10000 simulations.:   2%|▏         | 195/10000 [00:00<00:35, 272.59it/s]Running 10000 simulations.:   2%|▏         | 223/10000 [00:00<00:35, 272.92it/s]Running 10000 simulations.:   3%|▎         | 251/10000 [00:00<00:35, 273.97it/s]Running 10000 simulations.:   3%|▎         | 279/10000 [00:01<00:35, 274.44it/s]Running 10000 simulations.:   3%|▎         | 307/10000 [00:01<00:35, 274.48it/s]Running 10000 simulations.:   3%|▎         | 335/10000 [00:01<00:35, 273.45it/s]Running 10000 simulations.:   4%|▎         | 363/10000 [00:01<00:35, 273.46it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:01<00:35, 273.93it/s]Running 10000 simulations.:   4%|▍         | 419/10000 [00:01<00:34, 273.92it/s]Running 10000 simulations.:   4%|▍         | 447/10000 [00:01<00:34, 273.76it/s]Running 10000 simulations.:   5%|▍         | 475/10000 [00:01<00:34, 273.90it/s]Running 10000 simulations.:   5%|▌         | 503/10000 [00:01<00:34, 273.80it/s]Running 10000 simulations.:   5%|▌         | 531/10000 [00:01<00:34, 273.32it/s]Running 10000 simulations.:   6%|▌         | 559/10000 [00:02<00:34, 271.99it/s]Running 10000 simulations.:   6%|▌         | 587/10000 [00:02<00:34, 270.89it/s]Running 10000 simulations.:   6%|▌         | 615/10000 [00:02<00:34, 270.19it/s]Running 10000 simulations.:   6%|▋         | 643/10000 [00:02<00:34, 269.02it/s]Running 10000 simulations.:   7%|▋         | 670/10000 [00:02<00:34, 268.80it/s]Running 10000 simulations.:   7%|▋         | 697/10000 [00:02<00:34, 267.44it/s]Running 10000 simulations.:   7%|▋         | 724/10000 [00:02<00:34, 267.45it/s]Running 10000 simulations.:   8%|▊         | 751/10000 [00:02<00:34, 266.61it/s]Running 10000 simulations.:   8%|▊         | 778/10000 [00:02<00:34, 264.98it/s]Running 10000 simulations.:   8%|▊         | 805/10000 [00:02<00:34, 264.01it/s]Running 10000 simulations.:   8%|▊         | 832/10000 [00:03<00:34, 264.86it/s]Running 10000 simulations.:   9%|▊         | 859/10000 [00:03<00:34, 265.88it/s]Running 10000 simulations.:   9%|▉         | 886/10000 [00:03<00:34, 265.84it/s]Running 10000 simulations.:   9%|▉         | 913/10000 [00:03<00:34, 264.95it/s]Running 10000 simulations.:   9%|▉         | 940/10000 [00:03<00:34, 265.27it/s]Running 10000 simulations.:  10%|▉         | 967/10000 [00:03<00:34, 265.06it/s]Running 10000 simulations.:  10%|▉         | 994/10000 [00:03<00:34, 264.65it/s]Running 10000 simulations.:  10%|█         | 1021/10000 [00:03<00:33, 266.03it/s]Running 10000 simulations.:  10%|█         | 1048/10000 [00:03<00:33, 266.01it/s]Running 10000 simulations.:  11%|█         | 1075/10000 [00:03<00:33, 265.46it/s]Running 10000 simulations.:  11%|█         | 1102/10000 [00:04<00:33, 266.12it/s]Running 10000 simulations.:  11%|█▏        | 1129/10000 [00:04<00:33, 266.91it/s]Running 10000 simulations.:  12%|█▏        | 1156/10000 [00:04<00:33, 267.02it/s]Running 10000 simulations.:  12%|█▏        | 1183/10000 [00:04<00:33, 265.85it/s]Running 10000 simulations.:  12%|█▏        | 1210/10000 [00:04<00:33, 265.29it/s]Running 10000 simulations.:  12%|█▏        | 1237/10000 [00:04<00:33, 264.91it/s]Running 10000 simulations.:  13%|█▎        | 1264/10000 [00:04<00:32, 265.65it/s]Running 10000 simulations.:  13%|█▎        | 1291/10000 [00:04<00:32, 266.39it/s]Running 10000 simulations.:  13%|█▎        | 1318/10000 [00:04<00:32, 267.13it/s]Running 10000 simulations.:  13%|█▎        | 1345/10000 [00:05<00:32, 266.65it/s]Running 10000 simulations.:  14%|█▎        | 1373/10000 [00:05<00:32, 267.88it/s]Running 10000 simulations.:  14%|█▍        | 1400/10000 [00:05<00:32, 268.49it/s]Running 10000 simulations.:  14%|█▍        | 1427/10000 [00:05<00:31, 268.46it/s]Running 10000 simulations.:  15%|█▍        | 1454/10000 [00:05<00:31, 268.19it/s]Running 10000 simulations.:  15%|█▍        | 1481/10000 [00:05<00:31, 268.21it/s]Running 10000 simulations.:  15%|█▌        | 1508/10000 [00:05<00:31, 267.14it/s]Running 10000 simulations.:  15%|█▌        | 1535/10000 [00:05<00:31, 266.77it/s]Running 10000 simulations.:  16%|█▌        | 1562/10000 [00:05<00:31, 267.21it/s]Running 10000 simulations.:  16%|█▌        | 1589/10000 [00:05<00:31, 267.76it/s]Running 10000 simulations.:  16%|█▌        | 1616/10000 [00:06<00:31, 268.19it/s]Running 10000 simulations.:  16%|█▋        | 1643/10000 [00:06<00:31, 264.76it/s]Running 10000 simulations.:  17%|█▋        | 1670/10000 [00:06<00:31, 262.40it/s]Running 10000 simulations.:  17%|█▋        | 1697/10000 [00:06<00:32, 256.74it/s]Running 10000 simulations.:  17%|█▋        | 1723/10000 [00:06<00:32, 253.32it/s]Running 10000 simulations.:  17%|█▋        | 1749/10000 [00:06<00:32, 251.25it/s]Running 10000 simulations.:  18%|█▊        | 1775/10000 [00:06<00:32, 251.11it/s]Running 10000 simulations.:  18%|█▊        | 1801/10000 [00:06<00:32, 249.90it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:06<00:31, 255.63it/s]Running 10000 simulations.:  19%|█▊        | 1857/10000 [00:06<00:31, 259.89it/s]Running 10000 simulations.:  19%|█▉        | 1884/10000 [00:07<00:30, 262.26it/s]Running 10000 simulations.:  19%|█▉        | 1911/10000 [00:07<00:30, 264.06it/s]Running 10000 simulations.:  19%|█▉        | 1938/10000 [00:07<00:30, 264.80it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:07<00:30, 265.51it/s]Running 10000 simulations.:  20%|█▉        | 1992/10000 [00:07<00:30, 265.01it/s]Running 10000 simulations.:  20%|██        | 2019/10000 [00:07<00:30, 264.62it/s]Running 10000 simulations.:  20%|██        | 2046/10000 [00:07<00:29, 265.27it/s]Running 10000 simulations.:  21%|██        | 2073/10000 [00:07<00:29, 266.05it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:07<00:29, 264.46it/s]Running 10000 simulations.:  21%|██▏       | 2127/10000 [00:07<00:29, 264.37it/s]Running 10000 simulations.:  22%|██▏       | 2154/10000 [00:08<00:29, 265.14it/s]Running 10000 simulations.:  22%|██▏       | 2181/10000 [00:08<00:29, 265.95it/s]Running 10000 simulations.:  22%|██▏       | 2208/10000 [00:08<00:29, 266.20it/s]Running 10000 simulations.:  22%|██▏       | 2235/10000 [00:08<00:29, 266.69it/s]Running 10000 simulations.:  23%|██▎       | 2262/10000 [00:08<00:28, 267.50it/s]Running 10000 simulations.:  23%|██▎       | 2289/10000 [00:08<00:28, 268.15it/s]Running 10000 simulations.:  23%|██▎       | 2316/10000 [00:08<00:28, 268.44it/s]Running 10000 simulations.:  23%|██▎       | 2343/10000 [00:08<00:28, 266.88it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:08<00:28, 265.46it/s]Running 10000 simulations.:  24%|██▍       | 2397/10000 [00:08<00:28, 264.93it/s]Running 10000 simulations.:  24%|██▍       | 2424/10000 [00:09<00:28, 265.03it/s]Running 10000 simulations.:  25%|██▍       | 2451/10000 [00:09<00:28, 265.61it/s]Running 10000 simulations.:  25%|██▍       | 2478/10000 [00:09<00:28, 263.94it/s]Running 10000 simulations.:  25%|██▌       | 2505/10000 [00:09<00:28, 263.26it/s]Running 10000 simulations.:  25%|██▌       | 2532/10000 [00:09<00:28, 262.99it/s]Running 10000 simulations.:  26%|██▌       | 2559/10000 [00:09<00:29, 252.89it/s]Running 10000 simulations.:  26%|██▌       | 2586/10000 [00:09<00:28, 256.48it/s]Running 10000 simulations.:  26%|██▌       | 2613/10000 [00:09<00:28, 259.34it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:09<00:28, 261.43it/s]Running 10000 simulations.:  27%|██▋       | 2667/10000 [00:10<00:28, 260.90it/s]Running 10000 simulations.:  27%|██▋       | 2694/10000 [00:10<00:27, 261.20it/s]Running 10000 simulations.:  27%|██▋       | 2721/10000 [00:10<00:27, 262.29it/s]Running 10000 simulations.:  27%|██▋       | 2748/10000 [00:10<00:27, 264.00it/s]Running 10000 simulations.:  28%|██▊       | 2775/10000 [00:10<00:27, 263.98it/s]Running 10000 simulations.:  28%|██▊       | 2802/10000 [00:10<00:28, 256.07it/s]Running 10000 simulations.:  28%|██▊       | 2828/10000 [00:10<00:28, 250.09it/s]Running 10000 simulations.:  29%|██▊       | 2854/10000 [00:10<00:29, 244.79it/s]Running 10000 simulations.:  29%|██▉       | 2879/10000 [00:10<00:29, 242.88it/s]Running 10000 simulations.:  29%|██▉       | 2904/10000 [00:10<00:29, 240.93it/s]Running 10000 simulations.:  29%|██▉       | 2929/10000 [00:11<00:29, 240.77it/s]Running 10000 simulations.:  30%|██▉       | 2954/10000 [00:11<00:29, 241.08it/s]Running 10000 simulations.:  30%|██▉       | 2979/10000 [00:11<00:29, 239.69it/s]Running 10000 simulations.:  30%|███       | 3003/10000 [00:11<00:29, 237.74it/s]Running 10000 simulations.:  30%|███       | 3027/10000 [00:11<00:29, 236.29it/s]Running 10000 simulations.:  31%|███       | 3051/10000 [00:11<00:29, 235.60it/s]Running 10000 simulations.:  31%|███       | 3075/10000 [00:11<00:29, 235.02it/s]Running 10000 simulations.:  31%|███       | 3099/10000 [00:11<00:29, 234.19it/s]Running 10000 simulations.:  31%|███       | 3123/10000 [00:11<00:29, 233.75it/s]Running 10000 simulations.:  31%|███▏      | 3147/10000 [00:12<00:29, 234.34it/s]Running 10000 simulations.:  32%|███▏      | 3171/10000 [00:12<00:29, 234.78it/s]Running 10000 simulations.:  32%|███▏      | 3195/10000 [00:12<00:29, 234.17it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:12<00:28, 234.35it/s]Running 10000 simulations.:  32%|███▏      | 3243/10000 [00:12<00:28, 233.55it/s]Running 10000 simulations.:  33%|███▎      | 3267/10000 [00:12<00:28, 233.38it/s]Running 10000 simulations.:  33%|███▎      | 3291/10000 [00:12<00:28, 233.28it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:12<00:28, 233.08it/s]Running 10000 simulations.:  33%|███▎      | 3339/10000 [00:12<00:28, 232.90it/s]Running 10000 simulations.:  34%|███▎      | 3363/10000 [00:12<00:28, 232.82it/s]Running 10000 simulations.:  34%|███▍      | 3387/10000 [00:13<00:28, 232.47it/s]Running 10000 simulations.:  34%|███▍      | 3411/10000 [00:13<00:28, 232.49it/s]Running 10000 simulations.:  34%|███▍      | 3435/10000 [00:13<00:28, 233.11it/s]Running 10000 simulations.:  35%|███▍      | 3459/10000 [00:13<00:28, 233.31it/s]Running 10000 simulations.:  35%|███▍      | 3483/10000 [00:13<00:28, 232.14it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:13<00:28, 231.27it/s]Running 10000 simulations.:  35%|███▌      | 3531/10000 [00:13<00:28, 230.38it/s]Running 10000 simulations.:  36%|███▌      | 3555/10000 [00:13<00:27, 230.96it/s]Running 10000 simulations.:  36%|███▌      | 3580/10000 [00:13<00:27, 234.32it/s]Running 10000 simulations.:  36%|███▌      | 3605/10000 [00:13<00:27, 236.07it/s]Running 10000 simulations.:  36%|███▋      | 3629/10000 [00:14<00:27, 235.01it/s]Running 10000 simulations.:  37%|███▋      | 3653/10000 [00:14<00:27, 234.89it/s]Running 10000 simulations.:  37%|███▋      | 3677/10000 [00:14<00:26, 234.51it/s]Running 10000 simulations.:  37%|███▋      | 3701/10000 [00:14<00:26, 234.12it/s]Running 10000 simulations.:  37%|███▋      | 3725/10000 [00:14<00:26, 235.14it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:14<00:26, 236.39it/s]Running 10000 simulations.:  38%|███▊      | 3773/10000 [00:14<00:26, 237.36it/s]Running 10000 simulations.:  38%|███▊      | 3797/10000 [00:14<00:26, 236.07it/s]Running 10000 simulations.:  38%|███▊      | 3821/10000 [00:14<00:26, 235.28it/s]Running 10000 simulations.:  38%|███▊      | 3845/10000 [00:14<00:26, 236.10it/s]Running 10000 simulations.:  39%|███▊      | 3869/10000 [00:15<00:26, 235.37it/s]Running 10000 simulations.:  39%|███▉      | 3893/10000 [00:15<00:25, 235.86it/s]Running 10000 simulations.:  39%|███▉      | 3917/10000 [00:15<00:25, 236.79it/s]Running 10000 simulations.:  39%|███▉      | 3941/10000 [00:15<00:25, 237.59it/s]Running 10000 simulations.:  40%|███▉      | 3965/10000 [00:15<00:25, 237.28it/s]Running 10000 simulations.:  40%|███▉      | 3989/10000 [00:15<00:25, 236.89it/s]Running 10000 simulations.:  40%|████      | 4013/10000 [00:15<00:25, 237.35it/s]Running 10000 simulations.:  40%|████      | 4037/10000 [00:15<00:25, 237.94it/s]Running 10000 simulations.:  41%|████      | 4062/10000 [00:15<00:24, 238.67it/s]Running 10000 simulations.:  41%|████      | 4086/10000 [00:16<00:24, 238.71it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:16<00:24, 238.35it/s]Running 10000 simulations.:  41%|████▏     | 4134/10000 [00:16<00:24, 237.26it/s]Running 10000 simulations.:  42%|████▏     | 4158/10000 [00:16<00:24, 236.81it/s]Running 10000 simulations.:  42%|████▏     | 4182/10000 [00:16<00:24, 236.34it/s]Running 10000 simulations.:  42%|████▏     | 4206/10000 [00:16<00:24, 236.56it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:16<00:24, 236.50it/s]Running 10000 simulations.:  43%|████▎     | 4254/10000 [00:16<00:24, 236.42it/s]Running 10000 simulations.:  43%|████▎     | 4278/10000 [00:16<00:24, 236.93it/s]Running 10000 simulations.:  43%|████▎     | 4303/10000 [00:16<00:23, 237.88it/s]Running 10000 simulations.:  43%|████▎     | 4327/10000 [00:17<00:23, 238.21it/s]Running 10000 simulations.:  44%|████▎     | 4351/10000 [00:17<00:23, 237.61it/s]Running 10000 simulations.:  44%|████▍     | 4375/10000 [00:17<00:23, 237.03it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:17<00:23, 237.07it/s]Running 10000 simulations.:  44%|████▍     | 4423/10000 [00:17<00:23, 236.25it/s]Running 10000 simulations.:  44%|████▍     | 4447/10000 [00:17<00:23, 235.56it/s]Running 10000 simulations.:  45%|████▍     | 4471/10000 [00:17<00:23, 236.07it/s]Running 10000 simulations.:  45%|████▍     | 4495/10000 [00:17<00:23, 237.23it/s]Running 10000 simulations.:  45%|████▌     | 4519/10000 [00:17<00:23, 237.97it/s]Running 10000 simulations.:  45%|████▌     | 4544/10000 [00:17<00:22, 238.68it/s]Running 10000 simulations.:  46%|████▌     | 4568/10000 [00:18<00:22, 238.30it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:18<00:22, 238.06it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:18<00:22, 237.78it/s]Running 10000 simulations.:  46%|████▋     | 4643/10000 [00:18<00:21, 245.50it/s]Running 10000 simulations.:  47%|████▋     | 4670/10000 [00:18<00:21, 251.76it/s]Running 10000 simulations.:  47%|████▋     | 4697/10000 [00:18<00:20, 256.62it/s]Running 10000 simulations.:  47%|████▋     | 4724/10000 [00:18<00:20, 258.82it/s]Running 10000 simulations.:  48%|████▊     | 4751/10000 [00:18<00:20, 260.31it/s]Running 10000 simulations.:  48%|████▊     | 4778/10000 [00:18<00:19, 261.26it/s]Running 10000 simulations.:  48%|████▊     | 4805/10000 [00:18<00:19, 262.06it/s]Running 10000 simulations.:  48%|████▊     | 4832/10000 [00:19<00:19, 263.64it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:19<00:19, 264.19it/s]Running 10000 simulations.:  49%|████▉     | 4886/10000 [00:19<00:21, 242.65it/s]Running 10000 simulations.:  49%|████▉     | 4911/10000 [00:19<00:22, 229.99it/s]Running 10000 simulations.:  49%|████▉     | 4935/10000 [00:19<00:22, 222.78it/s]Running 10000 simulations.:  50%|████▉     | 4958/10000 [00:19<00:23, 218.67it/s]Running 10000 simulations.:  50%|████▉     | 4981/10000 [00:19<00:23, 213.78it/s]Running 10000 simulations.:  50%|█████     | 5003/10000 [00:19<00:23, 209.18it/s]Running 10000 simulations.:  50%|█████     | 5025/10000 [00:19<00:24, 206.39it/s]Running 10000 simulations.:  50%|█████     | 5046/10000 [00:20<00:24, 204.04it/s]Running 10000 simulations.:  51%|█████     | 5067/10000 [00:20<00:24, 203.91it/s]Running 10000 simulations.:  51%|█████     | 5088/10000 [00:20<00:24, 203.55it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:20<00:23, 204.35it/s]Running 10000 simulations.:  51%|█████▏    | 5131/10000 [00:20<00:23, 206.28it/s]Running 10000 simulations.:  52%|█████▏    | 5153/10000 [00:20<00:23, 207.84it/s]Running 10000 simulations.:  52%|█████▏    | 5174/10000 [00:20<00:23, 206.70it/s]Running 10000 simulations.:  52%|█████▏    | 5197/10000 [00:20<00:22, 211.29it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:20<00:22, 212.15it/s]Running 10000 simulations.:  52%|█████▏    | 5241/10000 [00:21<00:22, 214.28it/s]Running 10000 simulations.:  53%|█████▎    | 5263/10000 [00:21<00:22, 211.23it/s]Running 10000 simulations.:  53%|█████▎    | 5285/10000 [00:21<00:22, 209.48it/s]Running 10000 simulations.:  53%|█████▎    | 5306/10000 [00:21<00:22, 208.84it/s]Running 10000 simulations.:  53%|█████▎    | 5329/10000 [00:21<00:21, 213.99it/s]Running 10000 simulations.:  54%|█████▎    | 5354/10000 [00:21<00:20, 221.81it/s]Running 10000 simulations.:  54%|█████▍    | 5379/10000 [00:21<00:20, 227.33it/s]Running 10000 simulations.:  54%|█████▍    | 5404/10000 [00:21<00:19, 231.37it/s]Running 10000 simulations.:  54%|█████▍    | 5429/10000 [00:21<00:19, 234.76it/s]Running 10000 simulations.:  55%|█████▍    | 5454/10000 [00:21<00:19, 236.50it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:22<00:18, 238.41it/s]Running 10000 simulations.:  55%|█████▌    | 5504/10000 [00:22<00:18, 239.06it/s]Running 10000 simulations.:  55%|█████▌    | 5528/10000 [00:22<00:18, 238.76it/s]Running 10000 simulations.:  56%|█████▌    | 5553/10000 [00:22<00:18, 239.50it/s]Running 10000 simulations.:  56%|█████▌    | 5578/10000 [00:22<00:18, 241.00it/s]Running 10000 simulations.:  56%|█████▌    | 5603/10000 [00:22<00:18, 241.70it/s]Running 10000 simulations.:  56%|█████▋    | 5628/10000 [00:22<00:18, 242.00it/s]Running 10000 simulations.:  57%|█████▋    | 5653/10000 [00:22<00:17, 241.94it/s]Running 10000 simulations.:  57%|█████▋    | 5678/10000 [00:22<00:17, 241.65it/s]Running 10000 simulations.:  57%|█████▋    | 5703/10000 [00:22<00:17, 241.23it/s]Running 10000 simulations.:  57%|█████▋    | 5728/10000 [00:23<00:17, 240.93it/s]Running 10000 simulations.:  58%|█████▊    | 5753/10000 [00:23<00:17, 240.11it/s]Running 10000 simulations.:  58%|█████▊    | 5778/10000 [00:23<00:17, 240.01it/s]Running 10000 simulations.:  58%|█████▊    | 5803/10000 [00:23<00:17, 239.44it/s]Running 10000 simulations.:  58%|█████▊    | 5828/10000 [00:23<00:17, 240.02it/s]Running 10000 simulations.:  59%|█████▊    | 5853/10000 [00:23<00:17, 240.32it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:23<00:17, 240.21it/s]Running 10000 simulations.:  59%|█████▉    | 5903/10000 [00:23<00:17, 238.88it/s]Running 10000 simulations.:  59%|█████▉    | 5927/10000 [00:23<00:17, 238.21it/s]Running 10000 simulations.:  60%|█████▉    | 5951/10000 [00:24<00:17, 237.66it/s]Running 10000 simulations.:  60%|█████▉    | 5975/10000 [00:24<00:16, 237.16it/s]Running 10000 simulations.:  60%|█████▉    | 5999/10000 [00:24<00:16, 237.71it/s]Running 10000 simulations.:  60%|██████    | 6023/10000 [00:24<00:16, 238.22it/s]Running 10000 simulations.:  60%|██████    | 6047/10000 [00:24<00:16, 238.31it/s]Running 10000 simulations.:  61%|██████    | 6071/10000 [00:24<00:16, 237.07it/s]Running 10000 simulations.:  61%|██████    | 6095/10000 [00:24<00:16, 236.83it/s]Running 10000 simulations.:  61%|██████    | 6119/10000 [00:24<00:16, 236.75it/s]Running 10000 simulations.:  61%|██████▏   | 6143/10000 [00:24<00:16, 235.95it/s]Running 10000 simulations.:  62%|██████▏   | 6167/10000 [00:24<00:16, 235.30it/s]Running 10000 simulations.:  62%|██████▏   | 6191/10000 [00:25<00:16, 234.76it/s]Running 10000 simulations.:  62%|██████▏   | 6215/10000 [00:25<00:16, 234.44it/s]Running 10000 simulations.:  62%|██████▏   | 6239/10000 [00:25<00:15, 235.13it/s]Running 10000 simulations.:  63%|██████▎   | 6263/10000 [00:25<00:15, 236.03it/s]Running 10000 simulations.:  63%|██████▎   | 6287/10000 [00:25<00:15, 236.93it/s]Running 10000 simulations.:  63%|██████▎   | 6311/10000 [00:25<00:15, 237.24it/s]Running 10000 simulations.:  63%|██████▎   | 6335/10000 [00:25<00:15, 237.33it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:25<00:15, 237.16it/s]Running 10000 simulations.:  64%|██████▍   | 6383/10000 [00:25<00:15, 236.14it/s]Running 10000 simulations.:  64%|██████▍   | 6407/10000 [00:25<00:15, 236.56it/s]Running 10000 simulations.:  64%|██████▍   | 6431/10000 [00:26<00:15, 236.86it/s]Running 10000 simulations.:  65%|██████▍   | 6455/10000 [00:26<00:14, 237.39it/s]Running 10000 simulations.:  65%|██████▍   | 6479/10000 [00:26<00:14, 237.79it/s]Running 10000 simulations.:  65%|██████▌   | 6503/10000 [00:26<00:14, 238.06it/s]Running 10000 simulations.:  65%|██████▌   | 6527/10000 [00:26<00:14, 237.89it/s]Running 10000 simulations.:  66%|██████▌   | 6551/10000 [00:26<00:14, 237.70it/s]Running 10000 simulations.:  66%|██████▌   | 6575/10000 [00:26<00:14, 237.36it/s]Running 10000 simulations.:  66%|██████▌   | 6599/10000 [00:26<00:14, 237.51it/s]Running 10000 simulations.:  66%|██████▌   | 6623/10000 [00:26<00:14, 236.97it/s]Running 10000 simulations.:  66%|██████▋   | 6647/10000 [00:26<00:14, 236.10it/s]Running 10000 simulations.:  67%|██████▋   | 6671/10000 [00:27<00:14, 235.66it/s]Running 10000 simulations.:  67%|██████▋   | 6695/10000 [00:27<00:13, 236.57it/s]Running 10000 simulations.:  67%|██████▋   | 6719/10000 [00:27<00:13, 237.32it/s]Running 10000 simulations.:  67%|██████▋   | 6743/10000 [00:27<00:13, 237.08it/s]Running 10000 simulations.:  68%|██████▊   | 6767/10000 [00:27<00:13, 237.20it/s]Running 10000 simulations.:  68%|██████▊   | 6791/10000 [00:27<00:13, 237.03it/s]Running 10000 simulations.:  68%|██████▊   | 6815/10000 [00:27<00:13, 237.37it/s]Running 10000 simulations.:  68%|██████▊   | 6839/10000 [00:27<00:13, 237.38it/s]Running 10000 simulations.:  69%|██████▊   | 6863/10000 [00:27<00:13, 237.25it/s]Running 10000 simulations.:  69%|██████▉   | 6887/10000 [00:27<00:13, 237.38it/s]Running 10000 simulations.:  69%|██████▉   | 6911/10000 [00:28<00:13, 236.87it/s]Running 10000 simulations.:  69%|██████▉   | 6935/10000 [00:28<00:12, 236.49it/s]Running 10000 simulations.:  70%|██████▉   | 6959/10000 [00:28<00:12, 236.42it/s]Running 10000 simulations.:  70%|██████▉   | 6983/10000 [00:28<00:12, 236.76it/s]Running 10000 simulations.:  70%|███████   | 7007/10000 [00:28<00:12, 237.03it/s]Running 10000 simulations.:  70%|███████   | 7031/10000 [00:28<00:12, 237.47it/s]Running 10000 simulations.:  71%|███████   | 7055/10000 [00:28<00:12, 237.90it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:28<00:12, 238.96it/s]Running 10000 simulations.:  71%|███████   | 7104/10000 [00:28<00:12, 239.08it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:28<00:11, 239.72it/s]Running 10000 simulations.:  72%|███████▏  | 7154/10000 [00:29<00:11, 239.96it/s]Running 10000 simulations.:  72%|███████▏  | 7179/10000 [00:29<00:11, 240.56it/s]Running 10000 simulations.:  72%|███████▏  | 7204/10000 [00:29<00:11, 240.08it/s]Running 10000 simulations.:  72%|███████▏  | 7229/10000 [00:29<00:11, 240.74it/s]Running 10000 simulations.:  73%|███████▎  | 7254/10000 [00:29<00:11, 241.23it/s]Running 10000 simulations.:  73%|███████▎  | 7279/10000 [00:29<00:11, 241.17it/s]Running 10000 simulations.:  73%|███████▎  | 7304/10000 [00:29<00:11, 240.91it/s]Running 10000 simulations.:  73%|███████▎  | 7329/10000 [00:29<00:11, 240.54it/s]Running 10000 simulations.:  74%|███████▎  | 7354/10000 [00:29<00:11, 239.34it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:30<00:10, 238.91it/s]Running 10000 simulations.:  74%|███████▍  | 7402/10000 [00:30<00:10, 237.83it/s]Running 10000 simulations.:  74%|███████▍  | 7426/10000 [00:30<00:10, 237.05it/s]Running 10000 simulations.:  75%|███████▍  | 7451/10000 [00:30<00:10, 238.29it/s]Running 10000 simulations.:  75%|███████▍  | 7475/10000 [00:30<00:10, 238.32it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:30<00:10, 238.98it/s]Running 10000 simulations.:  75%|███████▌  | 7524/10000 [00:30<00:10, 239.28it/s]Running 10000 simulations.:  75%|███████▌  | 7549/10000 [00:30<00:10, 239.72it/s]Running 10000 simulations.:  76%|███████▌  | 7574/10000 [00:30<00:10, 240.09it/s]Running 10000 simulations.:  76%|███████▌  | 7599/10000 [00:30<00:09, 240.41it/s]Running 10000 simulations.:  76%|███████▌  | 7624/10000 [00:31<00:09, 239.92it/s]Running 10000 simulations.:  76%|███████▋  | 7649/10000 [00:31<00:09, 240.12it/s]Running 10000 simulations.:  77%|███████▋  | 7674/10000 [00:31<00:09, 239.81it/s]Running 10000 simulations.:  77%|███████▋  | 7698/10000 [00:31<00:09, 239.26it/s]Running 10000 simulations.:  77%|███████▋  | 7722/10000 [00:31<00:09, 237.70it/s]Running 10000 simulations.:  77%|███████▋  | 7746/10000 [00:31<00:09, 236.99it/s]Running 10000 simulations.:  78%|███████▊  | 7770/10000 [00:31<00:09, 237.30it/s]Running 10000 simulations.:  78%|███████▊  | 7794/10000 [00:31<00:09, 237.93it/s]Running 10000 simulations.:  78%|███████▊  | 7819/10000 [00:31<00:09, 238.65it/s]Running 10000 simulations.:  78%|███████▊  | 7843/10000 [00:31<00:09, 238.05it/s]Running 10000 simulations.:  79%|███████▊  | 7867/10000 [00:32<00:09, 236.86it/s]Running 10000 simulations.:  79%|███████▉  | 7891/10000 [00:32<00:08, 235.79it/s]Running 10000 simulations.:  79%|███████▉  | 7915/10000 [00:32<00:08, 235.04it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:32<00:08, 234.45it/s]Running 10000 simulations.:  80%|███████▉  | 7963/10000 [00:32<00:08, 234.28it/s]Running 10000 simulations.:  80%|███████▉  | 7987/10000 [00:32<00:08, 234.17it/s]Running 10000 simulations.:  80%|████████  | 8011/10000 [00:32<00:08, 234.42it/s]Running 10000 simulations.:  80%|████████  | 8035/10000 [00:32<00:08, 234.63it/s]Running 10000 simulations.:  81%|████████  | 8059/10000 [00:32<00:08, 234.79it/s]Running 10000 simulations.:  81%|████████  | 8083/10000 [00:32<00:08, 234.77it/s]Running 10000 simulations.:  81%|████████  | 8107/10000 [00:33<00:08, 234.95it/s]Running 10000 simulations.:  81%|████████▏ | 8131/10000 [00:33<00:07, 236.16it/s]Running 10000 simulations.:  82%|████████▏ | 8155/10000 [00:33<00:07, 236.76it/s]Running 10000 simulations.:  82%|████████▏ | 8179/10000 [00:33<00:07, 236.49it/s]Running 10000 simulations.:  82%|████████▏ | 8203/10000 [00:33<00:07, 235.91it/s]Running 10000 simulations.:  82%|████████▏ | 8227/10000 [00:33<00:07, 235.34it/s]Running 10000 simulations.:  83%|████████▎ | 8251/10000 [00:33<00:07, 234.71it/s]Running 10000 simulations.:  83%|████████▎ | 8275/10000 [00:33<00:07, 235.48it/s]Running 10000 simulations.:  83%|████████▎ | 8299/10000 [00:33<00:07, 236.40it/s]Running 10000 simulations.:  83%|████████▎ | 8323/10000 [00:33<00:07, 236.87it/s]Running 10000 simulations.:  84%|████████▎ | 8350/10000 [00:34<00:06, 244.29it/s]Running 10000 simulations.:  84%|████████▍ | 8378/10000 [00:34<00:06, 251.93it/s]Running 10000 simulations.:  84%|████████▍ | 8406/10000 [00:34<00:06, 258.26it/s]Running 10000 simulations.:  84%|████████▍ | 8433/10000 [00:34<00:05, 261.58it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:34<00:05, 263.48it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [00:34<00:05, 264.94it/s]Running 10000 simulations.:  85%|████████▌ | 8515/10000 [00:34<00:05, 266.93it/s]Running 10000 simulations.:  85%|████████▌ | 8542/10000 [00:34<00:05, 260.11it/s]Running 10000 simulations.:  86%|████████▌ | 8569/10000 [00:34<00:05, 254.69it/s]Running 10000 simulations.:  86%|████████▌ | 8595/10000 [00:35<00:05, 251.31it/s]Running 10000 simulations.:  86%|████████▌ | 8621/10000 [00:35<00:05, 248.93it/s]Running 10000 simulations.:  86%|████████▋ | 8646/10000 [00:35<00:05, 247.50it/s]Running 10000 simulations.:  87%|████████▋ | 8671/10000 [00:35<00:05, 246.04it/s]Running 10000 simulations.:  87%|████████▋ | 8696/10000 [00:35<00:05, 244.97it/s]Running 10000 simulations.:  87%|████████▋ | 8721/10000 [00:35<00:05, 243.35it/s]Running 10000 simulations.:  87%|████████▋ | 8746/10000 [00:35<00:05, 242.49it/s]Running 10000 simulations.:  88%|████████▊ | 8771/10000 [00:35<00:05, 241.94it/s]Running 10000 simulations.:  88%|████████▊ | 8796/10000 [00:35<00:04, 241.63it/s]Running 10000 simulations.:  88%|████████▊ | 8821/10000 [00:35<00:04, 239.84it/s]Running 10000 simulations.:  88%|████████▊ | 8845/10000 [00:36<00:04, 238.03it/s]Running 10000 simulations.:  89%|████████▊ | 8869/10000 [00:36<00:04, 236.78it/s]Running 10000 simulations.:  89%|████████▉ | 8893/10000 [00:36<00:04, 236.13it/s]Running 10000 simulations.:  89%|████████▉ | 8917/10000 [00:36<00:04, 236.52it/s]Running 10000 simulations.:  89%|████████▉ | 8942/10000 [00:36<00:04, 238.14it/s]Running 10000 simulations.:  90%|████████▉ | 8966/10000 [00:36<00:04, 238.69it/s]Running 10000 simulations.:  90%|████████▉ | 8990/10000 [00:36<00:04, 238.37it/s]Running 10000 simulations.:  90%|█████████ | 9014/10000 [00:36<00:04, 237.80it/s]Running 10000 simulations.:  90%|█████████ | 9038/10000 [00:36<00:04, 237.70it/s]Running 10000 simulations.:  91%|█████████ | 9062/10000 [00:36<00:03, 237.63it/s]Running 10000 simulations.:  91%|█████████ | 9086/10000 [00:37<00:03, 237.58it/s]Running 10000 simulations.:  91%|█████████ | 9111/10000 [00:37<00:03, 238.33it/s]Running 10000 simulations.:  91%|█████████▏| 9136/10000 [00:37<00:03, 239.13it/s]Running 10000 simulations.:  92%|█████████▏| 9161/10000 [00:37<00:03, 239.77it/s]Running 10000 simulations.:  92%|█████████▏| 9186/10000 [00:37<00:03, 239.95it/s]Running 10000 simulations.:  92%|█████████▏| 9210/10000 [00:37<00:03, 239.05it/s]Running 10000 simulations.:  92%|█████████▏| 9234/10000 [00:37<00:03, 238.56it/s]Running 10000 simulations.:  93%|█████████▎| 9258/10000 [00:37<00:03, 238.19it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [00:37<00:03, 238.69it/s]Running 10000 simulations.:  93%|█████████▎| 9306/10000 [00:38<00:02, 238.85it/s]Running 10000 simulations.:  93%|█████████▎| 9330/10000 [00:38<00:02, 239.13it/s]Running 10000 simulations.:  94%|█████████▎| 9354/10000 [00:38<00:02, 239.10it/s]Running 10000 simulations.:  94%|█████████▍| 9378/10000 [00:38<00:02, 238.71it/s]Running 10000 simulations.:  94%|█████████▍| 9403/10000 [00:38<00:02, 239.30it/s]Running 10000 simulations.:  94%|█████████▍| 9428/10000 [00:38<00:02, 240.28it/s]Running 10000 simulations.:  95%|█████████▍| 9453/10000 [00:38<00:02, 239.62it/s]Running 10000 simulations.:  95%|█████████▍| 9478/10000 [00:38<00:02, 240.00it/s]Running 10000 simulations.:  95%|█████████▌| 9503/10000 [00:38<00:02, 239.31it/s]Running 10000 simulations.:  95%|█████████▌| 9527/10000 [00:38<00:01, 238.88it/s]Running 10000 simulations.:  96%|█████████▌| 9551/10000 [00:39<00:01, 238.93it/s]Running 10000 simulations.:  96%|█████████▌| 9575/10000 [00:39<00:01, 238.83it/s]Running 10000 simulations.:  96%|█████████▌| 9599/10000 [00:39<00:01, 238.94it/s]Running 10000 simulations.:  96%|█████████▌| 9624/10000 [00:39<00:01, 239.81it/s]Running 10000 simulations.:  96%|█████████▋| 9649/10000 [00:39<00:01, 241.47it/s]Running 10000 simulations.:  97%|█████████▋| 9674/10000 [00:39<00:01, 241.22it/s]Running 10000 simulations.:  97%|█████████▋| 9699/10000 [00:39<00:01, 230.87it/s]Running 10000 simulations.:  97%|█████████▋| 9723/10000 [00:39<00:01, 230.64it/s]Running 10000 simulations.:  97%|█████████▋| 9747/10000 [00:39<00:01, 224.18it/s]Running 10000 simulations.:  98%|█████████▊| 9770/10000 [00:39<00:01, 220.30it/s]Running 10000 simulations.:  98%|█████████▊| 9793/10000 [00:40<00:00, 216.99it/s]Running 10000 simulations.:  98%|█████████▊| 9815/10000 [00:40<00:00, 215.17it/s]Running 10000 simulations.:  98%|█████████▊| 9837/10000 [00:40<00:00, 213.74it/s]Running 10000 simulations.:  99%|█████████▊| 9859/10000 [00:40<00:00, 213.03it/s]Running 10000 simulations.:  99%|█████████▉| 9881/10000 [00:40<00:00, 212.28it/s]Running 10000 simulations.:  99%|█████████▉| 9903/10000 [00:40<00:00, 211.68it/s]Running 10000 simulations.:  99%|█████████▉| 9925/10000 [00:40<00:00, 212.88it/s]Running 10000 simulations.: 100%|█████████▉| 9952/10000 [00:40<00:00, 227.29it/s]Running 10000 simulations.: 100%|█████████▉| 9977/10000 [00:40<00:00, 233.01it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 243.82it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 23/10000 [00:00<00:44, 222.94it/s]Running 10000 simulations.:   0%|          | 46/10000 [00:00<00:44, 222.31it/s]Running 10000 simulations.:   1%|          | 69/10000 [00:00<00:44, 221.63it/s]Running 10000 simulations.:   1%|          | 91/10000 [00:00<00:44, 220.61it/s]Running 10000 simulations.:   1%|          | 114/10000 [00:00<00:44, 220.66it/s]Running 10000 simulations.:   1%|▏         | 138/10000 [00:00<00:43, 225.01it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:00<00:41, 234.53it/s]Running 10000 simulations.:   2%|▏         | 192/10000 [00:00<00:40, 242.10it/s]Running 10000 simulations.:   2%|▏         | 219/10000 [00:00<00:39, 247.57it/s]Running 10000 simulations.:   2%|▏         | 245/10000 [00:01<00:39, 249.69it/s]Running 10000 simulations.:   3%|▎         | 271/10000 [00:01<00:38, 252.14it/s]Running 10000 simulations.:   3%|▎         | 297/10000 [00:01<00:38, 253.38it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:38, 254.31it/s]Running 10000 simulations.:   3%|▎         | 349/10000 [00:01<00:38, 253.95it/s]Running 10000 simulations.:   4%|▍         | 375/10000 [00:01<00:37, 254.01it/s]Running 10000 simulations.:   4%|▍         | 401/10000 [00:01<00:37, 254.20it/s]Running 10000 simulations.:   4%|▍         | 427/10000 [00:01<00:37, 254.62it/s]Running 10000 simulations.:   5%|▍         | 453/10000 [00:01<00:37, 256.18it/s]Running 10000 simulations.:   5%|▍         | 479/10000 [00:01<00:37, 256.80it/s]Running 10000 simulations.:   5%|▌         | 505/10000 [00:02<00:36, 257.33it/s]Running 10000 simulations.:   5%|▌         | 531/10000 [00:02<00:36, 257.19it/s]Running 10000 simulations.:   6%|▌         | 557/10000 [00:02<00:36, 255.90it/s]Running 10000 simulations.:   6%|▌         | 583/10000 [00:02<00:36, 254.86it/s]Running 10000 simulations.:   6%|▌         | 609/10000 [00:02<00:36, 253.93it/s]Running 10000 simulations.:   6%|▋         | 635/10000 [00:02<00:36, 253.43it/s]Running 10000 simulations.:   7%|▋         | 661/10000 [00:02<00:36, 254.02it/s]Running 10000 simulations.:   7%|▋         | 687/10000 [00:02<00:36, 253.32it/s]Running 10000 simulations.:   7%|▋         | 713/10000 [00:02<00:36, 252.48it/s]Running 10000 simulations.:   7%|▋         | 739/10000 [00:02<00:36, 252.74it/s]Running 10000 simulations.:   8%|▊         | 765/10000 [00:03<00:36, 253.55it/s]Running 10000 simulations.:   8%|▊         | 791/10000 [00:03<00:36, 253.47it/s]Running 10000 simulations.:   8%|▊         | 817/10000 [00:03<00:36, 252.91it/s]Running 10000 simulations.:   8%|▊         | 843/10000 [00:03<00:36, 252.39it/s]Running 10000 simulations.:   9%|▊         | 869/10000 [00:03<00:36, 252.33it/s]Running 10000 simulations.:   9%|▉         | 895/10000 [00:03<00:36, 252.23it/s]Running 10000 simulations.:   9%|▉         | 921/10000 [00:03<00:35, 253.48it/s]Running 10000 simulations.:   9%|▉         | 947/10000 [00:03<00:35, 253.17it/s]Running 10000 simulations.:  10%|▉         | 973/10000 [00:03<00:35, 253.04it/s]Running 10000 simulations.:  10%|▉         | 999/10000 [00:03<00:35, 252.09it/s]Running 10000 simulations.:  10%|█         | 1025/10000 [00:04<00:35, 251.33it/s]Running 10000 simulations.:  11%|█         | 1051/10000 [00:04<00:35, 251.34it/s]Running 10000 simulations.:  11%|█         | 1077/10000 [00:04<00:35, 252.82it/s]Running 10000 simulations.:  11%|█         | 1103/10000 [00:04<00:35, 254.10it/s]Running 10000 simulations.:  11%|█▏        | 1129/10000 [00:04<00:34, 254.13it/s]Running 10000 simulations.:  12%|█▏        | 1155/10000 [00:04<00:35, 252.69it/s]Running 10000 simulations.:  12%|█▏        | 1181/10000 [00:04<00:34, 252.91it/s]Running 10000 simulations.:  12%|█▏        | 1207/10000 [00:04<00:34, 253.25it/s]Running 10000 simulations.:  12%|█▏        | 1233/10000 [00:04<00:34, 253.55it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:05<00:34, 253.42it/s]Running 10000 simulations.:  13%|█▎        | 1285/10000 [00:05<00:34, 253.15it/s]Running 10000 simulations.:  13%|█▎        | 1311/10000 [00:05<00:34, 252.31it/s]Running 10000 simulations.:  13%|█▎        | 1337/10000 [00:05<00:34, 251.19it/s]Running 10000 simulations.:  14%|█▎        | 1363/10000 [00:05<00:34, 250.46it/s]Running 10000 simulations.:  14%|█▍        | 1389/10000 [00:05<00:34, 250.53it/s]Running 10000 simulations.:  14%|█▍        | 1415/10000 [00:05<00:34, 251.38it/s]Running 10000 simulations.:  14%|█▍        | 1441/10000 [00:05<00:33, 253.39it/s]Running 10000 simulations.:  15%|█▍        | 1468/10000 [00:05<00:33, 255.81it/s]Running 10000 simulations.:  15%|█▍        | 1494/10000 [00:05<00:33, 256.26it/s]Running 10000 simulations.:  15%|█▌        | 1520/10000 [00:06<00:33, 256.51it/s]Running 10000 simulations.:  15%|█▌        | 1546/10000 [00:06<00:33, 255.90it/s]Running 10000 simulations.:  16%|█▌        | 1572/10000 [00:06<00:33, 255.20it/s]Running 10000 simulations.:  16%|█▌        | 1598/10000 [00:06<00:32, 254.85it/s]Running 10000 simulations.:  16%|█▌        | 1624/10000 [00:06<00:32, 255.20it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:06<00:32, 255.69it/s]Running 10000 simulations.:  17%|█▋        | 1676/10000 [00:06<00:32, 255.43it/s]Running 10000 simulations.:  17%|█▋        | 1702/10000 [00:06<00:32, 254.16it/s]Running 10000 simulations.:  17%|█▋        | 1728/10000 [00:06<00:32, 254.17it/s]Running 10000 simulations.:  18%|█▊        | 1754/10000 [00:06<00:32, 255.11it/s]Running 10000 simulations.:  18%|█▊        | 1780/10000 [00:07<00:32, 253.55it/s]Running 10000 simulations.:  18%|█▊        | 1806/10000 [00:07<00:32, 252.91it/s]Running 10000 simulations.:  18%|█▊        | 1832/10000 [00:07<00:32, 252.41it/s]Running 10000 simulations.:  19%|█▊        | 1858/10000 [00:07<00:32, 252.33it/s]Running 10000 simulations.:  19%|█▉        | 1884/10000 [00:07<00:33, 240.00it/s]Running 10000 simulations.:  19%|█▉        | 1909/10000 [00:07<00:35, 229.43it/s]Running 10000 simulations.:  19%|█▉        | 1933/10000 [00:07<00:36, 221.79it/s]Running 10000 simulations.:  20%|█▉        | 1956/10000 [00:07<00:36, 218.00it/s]Running 10000 simulations.:  20%|█▉        | 1978/10000 [00:07<00:37, 214.76it/s]Running 10000 simulations.:  20%|██        | 2000/10000 [00:08<00:37, 212.18it/s]Running 10000 simulations.:  20%|██        | 2022/10000 [00:08<00:37, 210.28it/s]Running 10000 simulations.:  20%|██        | 2044/10000 [00:08<00:37, 210.12it/s]Running 10000 simulations.:  21%|██        | 2066/10000 [00:08<00:37, 210.16it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:08<00:37, 209.29it/s]Running 10000 simulations.:  21%|██        | 2109/10000 [00:08<00:37, 208.60it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:08<00:37, 208.12it/s]Running 10000 simulations.:  22%|██▏       | 2151/10000 [00:08<00:37, 207.73it/s]Running 10000 simulations.:  22%|██▏       | 2172/10000 [00:08<00:37, 207.35it/s]Running 10000 simulations.:  22%|██▏       | 2193/10000 [00:08<00:37, 207.06it/s]Running 10000 simulations.:  22%|██▏       | 2214/10000 [00:09<00:37, 207.03it/s]Running 10000 simulations.:  22%|██▏       | 2235/10000 [00:09<00:37, 207.36it/s]Running 10000 simulations.:  23%|██▎       | 2256/10000 [00:09<00:37, 207.23it/s]Running 10000 simulations.:  23%|██▎       | 2277/10000 [00:09<00:37, 207.04it/s]Running 10000 simulations.:  23%|██▎       | 2298/10000 [00:09<00:37, 207.09it/s]Running 10000 simulations.:  23%|██▎       | 2319/10000 [00:09<00:37, 207.57it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:09<00:36, 208.07it/s]Running 10000 simulations.:  24%|██▎       | 2361/10000 [00:09<00:36, 208.29it/s]Running 10000 simulations.:  24%|██▍       | 2382/10000 [00:09<00:36, 208.14it/s]Running 10000 simulations.:  24%|██▍       | 2403/10000 [00:10<00:36, 207.42it/s]Running 10000 simulations.:  24%|██▍       | 2424/10000 [00:10<00:36, 207.17it/s]Running 10000 simulations.:  24%|██▍       | 2445/10000 [00:10<00:36, 206.57it/s]Running 10000 simulations.:  25%|██▍       | 2466/10000 [00:10<00:36, 206.03it/s]Running 10000 simulations.:  25%|██▍       | 2487/10000 [00:10<00:36, 206.02it/s]Running 10000 simulations.:  25%|██▌       | 2508/10000 [00:10<00:36, 206.07it/s]Running 10000 simulations.:  25%|██▌       | 2529/10000 [00:10<00:36, 206.26it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:10<00:36, 206.01it/s]Running 10000 simulations.:  26%|██▌       | 2571/10000 [00:10<00:36, 205.66it/s]Running 10000 simulations.:  26%|██▌       | 2594/10000 [00:10<00:34, 211.99it/s]Running 10000 simulations.:  26%|██▌       | 2622/10000 [00:11<00:32, 227.18it/s]Running 10000 simulations.:  26%|██▋       | 2650/10000 [00:11<00:30, 238.67it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:11<00:29, 247.20it/s]Running 10000 simulations.:  27%|██▋       | 2704/10000 [00:11<00:28, 252.90it/s]Running 10000 simulations.:  27%|██▋       | 2731/10000 [00:11<00:28, 257.30it/s]Running 10000 simulations.:  28%|██▊       | 2759/10000 [00:11<00:27, 261.06it/s]Running 10000 simulations.:  28%|██▊       | 2786/10000 [00:11<00:27, 263.58it/s]Running 10000 simulations.:  28%|██▊       | 2814/10000 [00:11<00:26, 266.20it/s]Running 10000 simulations.:  28%|██▊       | 2841/10000 [00:11<00:28, 252.05it/s]Running 10000 simulations.:  29%|██▊       | 2867/10000 [00:11<00:29, 238.24it/s]Running 10000 simulations.:  29%|██▉       | 2892/10000 [00:12<00:30, 232.01it/s]Running 10000 simulations.:  29%|██▉       | 2917/10000 [00:12<00:29, 236.97it/s]Running 10000 simulations.:  29%|██▉       | 2942/10000 [00:12<00:29, 240.50it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:12<00:28, 243.78it/s]Running 10000 simulations.:  30%|██▉       | 2994/10000 [00:12<00:28, 245.98it/s]Running 10000 simulations.:  30%|███       | 3019/10000 [00:12<00:28, 246.62it/s]Running 10000 simulations.:  30%|███       | 3044/10000 [00:12<00:28, 247.48it/s]Running 10000 simulations.:  31%|███       | 3070/10000 [00:12<00:27, 248.31it/s]Running 10000 simulations.:  31%|███       | 3096/10000 [00:12<00:27, 249.49it/s]Running 10000 simulations.:  31%|███       | 3122/10000 [00:13<00:27, 249.92it/s]Running 10000 simulations.:  31%|███▏      | 3148/10000 [00:13<00:27, 248.98it/s]Running 10000 simulations.:  32%|███▏      | 3173/10000 [00:13<00:27, 249.28it/s]Running 10000 simulations.:  32%|███▏      | 3199/10000 [00:13<00:27, 249.85it/s]Running 10000 simulations.:  32%|███▏      | 3225/10000 [00:13<00:26, 250.95it/s]Running 10000 simulations.:  33%|███▎      | 3251/10000 [00:13<00:26, 251.18it/s]Running 10000 simulations.:  33%|███▎      | 3277/10000 [00:13<00:26, 250.63it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:13<00:26, 249.25it/s]Running 10000 simulations.:  33%|███▎      | 3328/10000 [00:13<00:26, 248.12it/s]Running 10000 simulations.:  34%|███▎      | 3353/10000 [00:13<00:26, 247.25it/s]Running 10000 simulations.:  34%|███▍      | 3378/10000 [00:14<00:27, 244.93it/s]Running 10000 simulations.:  34%|███▍      | 3403/10000 [00:14<00:27, 243.59it/s]Running 10000 simulations.:  34%|███▍      | 3428/10000 [00:14<00:27, 242.85it/s]Running 10000 simulations.:  35%|███▍      | 3453/10000 [00:14<00:26, 244.12it/s]Running 10000 simulations.:  35%|███▍      | 3478/10000 [00:14<00:26, 245.42it/s]Running 10000 simulations.:  35%|███▌      | 3503/10000 [00:14<00:26, 246.43it/s]Running 10000 simulations.:  35%|███▌      | 3528/10000 [00:14<00:26, 247.31it/s]Running 10000 simulations.:  36%|███▌      | 3553/10000 [00:14<00:26, 247.85it/s]Running 10000 simulations.:  36%|███▌      | 3578/10000 [00:14<00:25, 247.87it/s]Running 10000 simulations.:  36%|███▌      | 3603/10000 [00:14<00:25, 247.87it/s]Running 10000 simulations.:  36%|███▋      | 3628/10000 [00:15<00:25, 248.04it/s]Running 10000 simulations.:  37%|███▋      | 3654/10000 [00:15<00:25, 248.89it/s]Running 10000 simulations.:  37%|███▋      | 3679/10000 [00:15<00:25, 248.48it/s]Running 10000 simulations.:  37%|███▋      | 3704/10000 [00:15<00:25, 248.39it/s]Running 10000 simulations.:  37%|███▋      | 3729/10000 [00:15<00:25, 248.14it/s]Running 10000 simulations.:  38%|███▊      | 3754/10000 [00:15<00:25, 247.12it/s]Running 10000 simulations.:  38%|███▊      | 3779/10000 [00:15<00:25, 246.04it/s]Running 10000 simulations.:  38%|███▊      | 3804/10000 [00:15<00:25, 246.24it/s]Running 10000 simulations.:  38%|███▊      | 3829/10000 [00:15<00:24, 246.87it/s]Running 10000 simulations.:  39%|███▊      | 3854/10000 [00:15<00:24, 246.61it/s]Running 10000 simulations.:  39%|███▉      | 3879/10000 [00:16<00:24, 245.53it/s]Running 10000 simulations.:  39%|███▉      | 3904/10000 [00:16<00:24, 245.15it/s]Running 10000 simulations.:  39%|███▉      | 3929/10000 [00:16<00:24, 244.92it/s]Running 10000 simulations.:  40%|███▉      | 3954/10000 [00:16<00:24, 245.34it/s]Running 10000 simulations.:  40%|███▉      | 3979/10000 [00:16<00:24, 245.52it/s]Running 10000 simulations.:  40%|████      | 4005/10000 [00:16<00:24, 249.28it/s]Running 10000 simulations.:  40%|████      | 4033/10000 [00:16<00:23, 255.64it/s]Running 10000 simulations.:  41%|████      | 4060/10000 [00:16<00:22, 259.51it/s]Running 10000 simulations.:  41%|████      | 4087/10000 [00:16<00:22, 261.15it/s]Running 10000 simulations.:  41%|████      | 4114/10000 [00:16<00:22, 259.77it/s]Running 10000 simulations.:  41%|████▏     | 4141/10000 [00:17<00:22, 256.46it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:17<00:22, 258.74it/s]Running 10000 simulations.:  42%|████▏     | 4195/10000 [00:17<00:22, 259.86it/s]Running 10000 simulations.:  42%|████▏     | 4222/10000 [00:17<00:22, 260.62it/s]Running 10000 simulations.:  42%|████▏     | 4249/10000 [00:17<00:22, 260.46it/s]Running 10000 simulations.:  43%|████▎     | 4277/10000 [00:17<00:21, 263.41it/s]Running 10000 simulations.:  43%|████▎     | 4305/10000 [00:17<00:21, 265.51it/s]Running 10000 simulations.:  43%|████▎     | 4333/10000 [00:17<00:21, 267.24it/s]Running 10000 simulations.:  44%|████▎     | 4361/10000 [00:17<00:21, 268.18it/s]Running 10000 simulations.:  44%|████▍     | 4388/10000 [00:18<00:20, 268.57it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:18<00:21, 265.18it/s]Running 10000 simulations.:  44%|████▍     | 4442/10000 [00:18<00:20, 265.87it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:18<00:20, 267.01it/s]Running 10000 simulations.:  45%|████▍     | 4496/10000 [00:18<00:21, 261.37it/s]Running 10000 simulations.:  45%|████▌     | 4523/10000 [00:18<00:21, 255.27it/s]Running 10000 simulations.:  45%|████▌     | 4549/10000 [00:18<00:21, 251.73it/s]Running 10000 simulations.:  46%|████▌     | 4575/10000 [00:18<00:21, 249.53it/s]Running 10000 simulations.:  46%|████▌     | 4600/10000 [00:18<00:21, 248.09it/s]Running 10000 simulations.:  46%|████▋     | 4625/10000 [00:18<00:21, 245.72it/s]Running 10000 simulations.:  46%|████▋     | 4650/10000 [00:19<00:21, 244.71it/s]Running 10000 simulations.:  47%|████▋     | 4675/10000 [00:19<00:21, 243.71it/s]Running 10000 simulations.:  47%|████▋     | 4700/10000 [00:19<00:21, 243.02it/s]Running 10000 simulations.:  47%|████▋     | 4725/10000 [00:19<00:21, 242.56it/s]Running 10000 simulations.:  48%|████▊     | 4750/10000 [00:19<00:21, 242.40it/s]Running 10000 simulations.:  48%|████▊     | 4775/10000 [00:19<00:21, 242.20it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:19<00:21, 241.96it/s]Running 10000 simulations.:  48%|████▊     | 4825/10000 [00:19<00:21, 235.52it/s]Running 10000 simulations.:  48%|████▊     | 4849/10000 [00:19<00:22, 226.63it/s]Running 10000 simulations.:  49%|████▊     | 4872/10000 [00:20<00:23, 220.69it/s]Running 10000 simulations.:  49%|████▉     | 4895/10000 [00:20<00:23, 215.67it/s]Running 10000 simulations.:  49%|████▉     | 4917/10000 [00:20<00:23, 212.55it/s]Running 10000 simulations.:  49%|████▉     | 4939/10000 [00:20<00:24, 210.15it/s]Running 10000 simulations.:  50%|████▉     | 4961/10000 [00:20<00:24, 208.36it/s]Running 10000 simulations.:  50%|████▉     | 4982/10000 [00:20<00:24, 207.98it/s]Running 10000 simulations.:  50%|█████     | 5004/10000 [00:20<00:23, 210.37it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:20<00:23, 213.21it/s]Running 10000 simulations.:  50%|█████     | 5050/10000 [00:20<00:22, 216.57it/s]Running 10000 simulations.:  51%|█████     | 5074/10000 [00:20<00:22, 222.16it/s]Running 10000 simulations.:  51%|█████     | 5098/10000 [00:21<00:21, 225.73it/s]Running 10000 simulations.:  51%|█████     | 5123/10000 [00:21<00:21, 230.11it/s]Running 10000 simulations.:  51%|█████▏    | 5147/10000 [00:21<00:20, 232.85it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:21<00:20, 234.22it/s]Running 10000 simulations.:  52%|█████▏    | 5195/10000 [00:21<00:20, 235.57it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:21<00:20, 236.88it/s]Running 10000 simulations.:  52%|█████▏    | 5244/10000 [00:21<00:19, 238.27it/s]Running 10000 simulations.:  53%|█████▎    | 5269/10000 [00:21<00:19, 238.96it/s]Running 10000 simulations.:  53%|█████▎    | 5294/10000 [00:21<00:19, 239.77it/s]Running 10000 simulations.:  53%|█████▎    | 5319/10000 [00:22<00:19, 240.59it/s]Running 10000 simulations.:  53%|█████▎    | 5344/10000 [00:22<00:19, 240.90it/s]Running 10000 simulations.:  54%|█████▎    | 5369/10000 [00:22<00:19, 240.40it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:22<00:19, 240.72it/s]Running 10000 simulations.:  54%|█████▍    | 5419/10000 [00:22<00:19, 237.51it/s]Running 10000 simulations.:  54%|█████▍    | 5443/10000 [00:22<00:20, 224.31it/s]Running 10000 simulations.:  55%|█████▍    | 5466/10000 [00:22<00:20, 216.80it/s]Running 10000 simulations.:  55%|█████▍    | 5488/10000 [00:22<00:21, 210.92it/s]Running 10000 simulations.:  55%|█████▌    | 5510/10000 [00:22<00:21, 207.47it/s]Running 10000 simulations.:  55%|█████▌    | 5531/10000 [00:22<00:21, 204.95it/s]Running 10000 simulations.:  56%|█████▌    | 5552/10000 [00:23<00:21, 203.20it/s]Running 10000 simulations.:  56%|█████▌    | 5573/10000 [00:23<00:21, 201.58it/s]Running 10000 simulations.:  56%|█████▌    | 5594/10000 [00:23<00:21, 201.01it/s]Running 10000 simulations.:  56%|█████▌    | 5620/10000 [00:23<00:20, 213.77it/s]Running 10000 simulations.:  56%|█████▋    | 5646/10000 [00:23<00:19, 225.43it/s]Running 10000 simulations.:  57%|█████▋    | 5673/10000 [00:23<00:18, 235.03it/s]Running 10000 simulations.:  57%|█████▋    | 5699/10000 [00:23<00:17, 241.56it/s]Running 10000 simulations.:  57%|█████▋    | 5725/10000 [00:23<00:17, 245.57it/s]Running 10000 simulations.:  58%|█████▊    | 5751/10000 [00:23<00:17, 249.33it/s]Running 10000 simulations.:  58%|█████▊    | 5777/10000 [00:24<00:16, 251.99it/s]Running 10000 simulations.:  58%|█████▊    | 5803/10000 [00:24<00:16, 253.18it/s]Running 10000 simulations.:  58%|█████▊    | 5829/10000 [00:24<00:16, 254.04it/s]Running 10000 simulations.:  59%|█████▊    | 5855/10000 [00:24<00:16, 244.04it/s]Running 10000 simulations.:  59%|█████▉    | 5881/10000 [00:24<00:16, 247.81it/s]Running 10000 simulations.:  59%|█████▉    | 5907/10000 [00:24<00:16, 251.33it/s]Running 10000 simulations.:  59%|█████▉    | 5934/10000 [00:24<00:15, 254.13it/s]Running 10000 simulations.:  60%|█████▉    | 5960/10000 [00:24<00:15, 255.23it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:24<00:15, 256.77it/s]Running 10000 simulations.:  60%|██████    | 6013/10000 [00:24<00:15, 257.17it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:25<00:15, 257.41it/s]Running 10000 simulations.:  61%|██████    | 6066/10000 [00:25<00:15, 258.57it/s]Running 10000 simulations.:  61%|██████    | 6092/10000 [00:25<00:15, 258.45it/s]Running 10000 simulations.:  61%|██████    | 6119/10000 [00:25<00:14, 259.46it/s]Running 10000 simulations.:  61%|██████▏   | 6146/10000 [00:25<00:14, 260.01it/s]Running 10000 simulations.:  62%|██████▏   | 6173/10000 [00:25<00:14, 260.63it/s]Running 10000 simulations.:  62%|██████▏   | 6200/10000 [00:25<00:14, 261.03it/s]Running 10000 simulations.:  62%|██████▏   | 6227/10000 [00:25<00:14, 261.30it/s]Running 10000 simulations.:  63%|██████▎   | 6254/10000 [00:25<00:14, 260.94it/s]Running 10000 simulations.:  63%|██████▎   | 6281/10000 [00:25<00:14, 261.24it/s]Running 10000 simulations.:  63%|██████▎   | 6308/10000 [00:26<00:14, 261.43it/s]Running 10000 simulations.:  63%|██████▎   | 6335/10000 [00:26<00:14, 260.38it/s]Running 10000 simulations.:  64%|██████▎   | 6362/10000 [00:26<00:14, 259.58it/s]Running 10000 simulations.:  64%|██████▍   | 6388/10000 [00:26<00:13, 259.52it/s]Running 10000 simulations.:  64%|██████▍   | 6415/10000 [00:26<00:13, 259.97it/s]Running 10000 simulations.:  64%|██████▍   | 6442/10000 [00:26<00:13, 260.61it/s]Running 10000 simulations.:  65%|██████▍   | 6469/10000 [00:26<00:13, 260.74it/s]Running 10000 simulations.:  65%|██████▍   | 6496/10000 [00:26<00:13, 261.04it/s]Running 10000 simulations.:  65%|██████▌   | 6523/10000 [00:26<00:13, 259.95it/s]Running 10000 simulations.:  66%|██████▌   | 6550/10000 [00:27<00:13, 260.51it/s]Running 10000 simulations.:  66%|██████▌   | 6577/10000 [00:27<00:13, 260.98it/s]Running 10000 simulations.:  66%|██████▌   | 6604/10000 [00:27<00:13, 260.73it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:27<00:12, 260.87it/s]Running 10000 simulations.:  67%|██████▋   | 6658/10000 [00:27<00:12, 260.91it/s]Running 10000 simulations.:  67%|██████▋   | 6685/10000 [00:27<00:12, 260.96it/s]Running 10000 simulations.:  67%|██████▋   | 6712/10000 [00:27<00:12, 258.06it/s]Running 10000 simulations.:  67%|██████▋   | 6738/10000 [00:27<00:12, 257.87it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:27<00:12, 250.60it/s]Running 10000 simulations.:  68%|██████▊   | 6790/10000 [00:27<00:13, 246.04it/s]Running 10000 simulations.:  68%|██████▊   | 6815/10000 [00:28<00:13, 242.74it/s]Running 10000 simulations.:  68%|██████▊   | 6840/10000 [00:28<00:13, 237.76it/s]Running 10000 simulations.:  69%|██████▊   | 6864/10000 [00:28<00:13, 235.81it/s]Running 10000 simulations.:  69%|██████▉   | 6888/10000 [00:28<00:13, 234.91it/s]Running 10000 simulations.:  69%|██████▉   | 6912/10000 [00:28<00:13, 234.84it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:28<00:12, 236.41it/s]Running 10000 simulations.:  70%|██████▉   | 6961/10000 [00:28<00:12, 236.27it/s]Running 10000 simulations.:  70%|██████▉   | 6985/10000 [00:28<00:12, 235.09it/s]Running 10000 simulations.:  70%|███████   | 7009/10000 [00:28<00:12, 234.26it/s]Running 10000 simulations.:  70%|███████   | 7033/10000 [00:28<00:12, 234.42it/s]Running 10000 simulations.:  71%|███████   | 7057/10000 [00:29<00:12, 233.74it/s]Running 10000 simulations.:  71%|███████   | 7081/10000 [00:29<00:12, 234.27it/s]Running 10000 simulations.:  71%|███████   | 7105/10000 [00:29<00:12, 235.47it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:29<00:12, 234.20it/s]Running 10000 simulations.:  72%|███████▏  | 7153/10000 [00:29<00:12, 233.62it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:29<00:12, 233.31it/s]Running 10000 simulations.:  72%|███████▏  | 7201/10000 [00:29<00:11, 233.46it/s]Running 10000 simulations.:  72%|███████▏  | 7225/10000 [00:29<00:11, 235.33it/s]Running 10000 simulations.:  73%|███████▎  | 7252/10000 [00:29<00:11, 244.64it/s]Running 10000 simulations.:  73%|███████▎  | 7280/10000 [00:30<00:10, 251.72it/s]Running 10000 simulations.:  73%|███████▎  | 7306/10000 [00:30<00:10, 248.15it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:30<00:11, 230.50it/s]Running 10000 simulations.:  74%|███████▎  | 7355/10000 [00:30<00:12, 220.39it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:30<00:12, 213.03it/s]Running 10000 simulations.:  74%|███████▍  | 7400/10000 [00:30<00:12, 210.65it/s]Running 10000 simulations.:  74%|███████▍  | 7422/10000 [00:30<00:12, 207.73it/s]Running 10000 simulations.:  74%|███████▍  | 7444/10000 [00:30<00:12, 209.09it/s]Running 10000 simulations.:  75%|███████▍  | 7466/10000 [00:30<00:12, 209.95it/s]Running 10000 simulations.:  75%|███████▍  | 7488/10000 [00:31<00:11, 210.51it/s]Running 10000 simulations.:  75%|███████▌  | 7510/10000 [00:31<00:11, 210.23it/s]Running 10000 simulations.:  75%|███████▌  | 7532/10000 [00:31<00:11, 209.37it/s]Running 10000 simulations.:  76%|███████▌  | 7553/10000 [00:31<00:11, 208.63it/s]Running 10000 simulations.:  76%|███████▌  | 7574/10000 [00:31<00:11, 208.25it/s]Running 10000 simulations.:  76%|███████▌  | 7595/10000 [00:31<00:11, 207.23it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:31<00:11, 206.86it/s]Running 10000 simulations.:  76%|███████▋  | 7637/10000 [00:31<00:11, 206.30it/s]Running 10000 simulations.:  77%|███████▋  | 7660/10000 [00:31<00:11, 211.41it/s]Running 10000 simulations.:  77%|███████▋  | 7687/10000 [00:31<00:10, 224.06it/s]Running 10000 simulations.:  77%|███████▋  | 7714/10000 [00:32<00:09, 233.46it/s]Running 10000 simulations.:  77%|███████▋  | 7738/10000 [00:32<00:09, 235.05it/s]Running 10000 simulations.:  78%|███████▊  | 7763/10000 [00:32<00:09, 237.11it/s]Running 10000 simulations.:  78%|███████▊  | 7788/10000 [00:32<00:09, 238.95it/s]Running 10000 simulations.:  78%|███████▊  | 7813/10000 [00:32<00:09, 239.87it/s]Running 10000 simulations.:  78%|███████▊  | 7838/10000 [00:32<00:09, 240.07it/s]Running 10000 simulations.:  79%|███████▊  | 7863/10000 [00:32<00:08, 240.20it/s]Running 10000 simulations.:  79%|███████▉  | 7888/10000 [00:32<00:08, 240.36it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:32<00:08, 240.34it/s]Running 10000 simulations.:  79%|███████▉  | 7938/10000 [00:32<00:08, 239.50it/s]Running 10000 simulations.:  80%|███████▉  | 7962/10000 [00:33<00:08, 239.38it/s]Running 10000 simulations.:  80%|███████▉  | 7987/10000 [00:33<00:08, 240.19it/s]Running 10000 simulations.:  80%|████████  | 8012/10000 [00:33<00:08, 240.07it/s]Running 10000 simulations.:  80%|████████  | 8037/10000 [00:33<00:08, 240.27it/s]Running 10000 simulations.:  81%|████████  | 8062/10000 [00:33<00:08, 239.88it/s]Running 10000 simulations.:  81%|████████  | 8087/10000 [00:33<00:07, 240.41it/s]Running 10000 simulations.:  81%|████████  | 8112/10000 [00:33<00:07, 240.46it/s]Running 10000 simulations.:  81%|████████▏ | 8137/10000 [00:33<00:07, 239.97it/s]Running 10000 simulations.:  82%|████████▏ | 8162/10000 [00:33<00:07, 240.11it/s]Running 10000 simulations.:  82%|████████▏ | 8187/10000 [00:34<00:07, 240.38it/s]Running 10000 simulations.:  82%|████████▏ | 8212/10000 [00:34<00:07, 240.86it/s]Running 10000 simulations.:  82%|████████▏ | 8237/10000 [00:34<00:07, 241.21it/s]Running 10000 simulations.:  83%|████████▎ | 8262/10000 [00:34<00:07, 241.04it/s]Running 10000 simulations.:  83%|████████▎ | 8287/10000 [00:34<00:07, 241.15it/s]Running 10000 simulations.:  83%|████████▎ | 8312/10000 [00:34<00:06, 241.45it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:34<00:06, 241.55it/s]Running 10000 simulations.:  84%|████████▎ | 8362/10000 [00:34<00:06, 239.90it/s]Running 10000 simulations.:  84%|████████▍ | 8386/10000 [00:34<00:06, 239.27it/s]Running 10000 simulations.:  84%|████████▍ | 8410/10000 [00:34<00:06, 239.43it/s]Running 10000 simulations.:  84%|████████▍ | 8435/10000 [00:35<00:06, 240.11it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:35<00:06, 239.71it/s]Running 10000 simulations.:  85%|████████▍ | 8484/10000 [00:35<00:06, 238.77it/s]Running 10000 simulations.:  85%|████████▌ | 8508/10000 [00:35<00:06, 238.61it/s]Running 10000 simulations.:  85%|████████▌ | 8533/10000 [00:35<00:06, 239.52it/s]Running 10000 simulations.:  86%|████████▌ | 8558/10000 [00:35<00:06, 240.32it/s]Running 10000 simulations.:  86%|████████▌ | 8583/10000 [00:35<00:05, 240.56it/s]Running 10000 simulations.:  86%|████████▌ | 8608/10000 [00:35<00:05, 241.25it/s]Running 10000 simulations.:  86%|████████▋ | 8633/10000 [00:35<00:05, 241.83it/s]Running 10000 simulations.:  87%|████████▋ | 8658/10000 [00:35<00:05, 241.89it/s]Running 10000 simulations.:  87%|████████▋ | 8683/10000 [00:36<00:05, 241.34it/s]Running 10000 simulations.:  87%|████████▋ | 8708/10000 [00:36<00:05, 240.90it/s]Running 10000 simulations.:  87%|████████▋ | 8733/10000 [00:36<00:05, 240.62it/s]Running 10000 simulations.:  88%|████████▊ | 8758/10000 [00:36<00:05, 239.96it/s]Running 10000 simulations.:  88%|████████▊ | 8782/10000 [00:36<00:05, 239.23it/s]Running 10000 simulations.:  88%|████████▊ | 8806/10000 [00:36<00:05, 238.66it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [00:36<00:04, 238.11it/s]Running 10000 simulations.:  89%|████████▊ | 8855/10000 [00:36<00:04, 239.11it/s]Running 10000 simulations.:  89%|████████▉ | 8880/10000 [00:36<00:04, 239.85it/s]Running 10000 simulations.:  89%|████████▉ | 8904/10000 [00:36<00:04, 239.83it/s]Running 10000 simulations.:  89%|████████▉ | 8929/10000 [00:37<00:04, 240.67it/s]Running 10000 simulations.:  90%|████████▉ | 8954/10000 [00:37<00:04, 240.90it/s]Running 10000 simulations.:  90%|████████▉ | 8979/10000 [00:37<00:04, 241.43it/s]Running 10000 simulations.:  90%|█████████ | 9004/10000 [00:37<00:04, 236.78it/s]Running 10000 simulations.:  90%|█████████ | 9028/10000 [00:37<00:04, 233.08it/s]Running 10000 simulations.:  91%|█████████ | 9052/10000 [00:37<00:04, 230.45it/s]Running 10000 simulations.:  91%|█████████ | 9076/10000 [00:37<00:04, 228.68it/s]Running 10000 simulations.:  91%|█████████ | 9099/10000 [00:37<00:03, 227.58it/s]Running 10000 simulations.:  91%|█████████ | 9122/10000 [00:37<00:03, 225.68it/s]Running 10000 simulations.:  91%|█████████▏| 9145/10000 [00:38<00:03, 225.26it/s]Running 10000 simulations.:  92%|█████████▏| 9168/10000 [00:38<00:03, 225.11it/s]Running 10000 simulations.:  92%|█████████▏| 9191/10000 [00:38<00:03, 224.48it/s]Running 10000 simulations.:  92%|█████████▏| 9214/10000 [00:38<00:03, 224.18it/s]Running 10000 simulations.:  92%|█████████▏| 9237/10000 [00:38<00:03, 224.28it/s]Running 10000 simulations.:  93%|█████████▎| 9260/10000 [00:38<00:03, 223.24it/s]Running 10000 simulations.:  93%|█████████▎| 9283/10000 [00:38<00:03, 223.60it/s]Running 10000 simulations.:  93%|█████████▎| 9306/10000 [00:38<00:03, 223.67it/s]Running 10000 simulations.:  93%|█████████▎| 9329/10000 [00:38<00:03, 223.45it/s]Running 10000 simulations.:  94%|█████████▎| 9352/10000 [00:38<00:02, 222.90it/s]Running 10000 simulations.:  94%|█████████▍| 9375/10000 [00:39<00:02, 222.19it/s]Running 10000 simulations.:  94%|█████████▍| 9398/10000 [00:39<00:02, 222.36it/s]Running 10000 simulations.:  94%|█████████▍| 9421/10000 [00:39<00:02, 222.97it/s]Running 10000 simulations.:  94%|█████████▍| 9444/10000 [00:39<00:02, 222.54it/s]Running 10000 simulations.:  95%|█████████▍| 9467/10000 [00:39<00:02, 222.48it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [00:39<00:02, 222.67it/s]Running 10000 simulations.:  95%|█████████▌| 9513/10000 [00:39<00:02, 223.18it/s]Running 10000 simulations.:  95%|█████████▌| 9536/10000 [00:39<00:02, 223.61it/s]Running 10000 simulations.:  96%|█████████▌| 9559/10000 [00:39<00:01, 223.81it/s]Running 10000 simulations.:  96%|█████████▌| 9582/10000 [00:40<00:01, 223.83it/s]Running 10000 simulations.:  96%|█████████▌| 9605/10000 [00:40<00:01, 223.44it/s]Running 10000 simulations.:  96%|█████████▋| 9628/10000 [00:40<00:01, 223.38it/s]Running 10000 simulations.:  97%|█████████▋| 9651/10000 [00:40<00:01, 223.37it/s]Running 10000 simulations.:  97%|█████████▋| 9674/10000 [00:40<00:01, 223.55it/s]Running 10000 simulations.:  97%|█████████▋| 9697/10000 [00:40<00:01, 223.69it/s]Running 10000 simulations.:  97%|█████████▋| 9720/10000 [00:40<00:01, 223.29it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [00:40<00:01, 222.79it/s]Running 10000 simulations.:  98%|█████████▊| 9766/10000 [00:40<00:01, 223.23it/s]Running 10000 simulations.:  98%|█████████▊| 9789/10000 [00:40<00:00, 224.21it/s]Running 10000 simulations.:  98%|█████████▊| 9812/10000 [00:41<00:00, 223.80it/s]Running 10000 simulations.:  98%|█████████▊| 9835/10000 [00:41<00:00, 223.62it/s]Running 10000 simulations.:  99%|█████████▊| 9858/10000 [00:41<00:00, 224.19it/s]Running 10000 simulations.:  99%|█████████▉| 9881/10000 [00:41<00:00, 224.92it/s]Running 10000 simulations.:  99%|█████████▉| 9904/10000 [00:41<00:00, 225.77it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [00:41<00:00, 227.51it/s]Running 10000 simulations.: 100%|█████████▉| 9951/10000 [00:41<00:00, 227.89it/s]Running 10000 simulations.: 100%|█████████▉| 9974/10000 [00:41<00:00, 227.02it/s]Running 10000 simulations.: 100%|█████████▉| 9997/10000 [00:41<00:00, 226.93it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 238.87it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163397.68it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164555.72it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165954.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19920/50000 [00:00<00:00, 168569.65it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39838/50000 [00:00<00:00, 168966.01it/s]Drawing 50000 posterior samples: 59776it [00:00, 168941.76it/s]                           Drawing 50000 posterior samples: 59776it [00:00, 168892.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168070.65it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168562.45it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168969.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169578.85it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169822.94it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169953.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 18034/50000 [00:00<00:00, 152799.29it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36075/50000 [00:00<00:00, 152755.25it/s]Drawing 50000 posterior samples: 54077it [00:00, 152256.34it/s]                           Drawing 50000 posterior samples: 54077it [00:00, 151987.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 19030/50000 [00:00<00:00, 160386.46it/s]Drawing 50000 posterior samples:  76%|███████▋  | 38127/50000 [00:00<00:00, 160885.16it/s]Drawing 50000 posterior samples: 57224it [00:00, 160808.43it/s]                           Drawing 50000 posterior samples: 57224it [00:00, 160823.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168231.43it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168228.90it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167954.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169208.74it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169305.56it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169158.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169551.78it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169819.61it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169765.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 162006.98it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163943.75it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165902.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19999/50000 [00:00<00:00, 169082.62it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39999/50000 [00:00<00:00, 168955.81it/s]Drawing 50000 posterior samples: 59999it [00:00, 168942.04it/s]                           Drawing 50000 posterior samples: 59999it [00:00, 168666.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 171602.67it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 171538.04it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 171802.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170128.09it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170281.95it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169858.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167923.29it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167963.54it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168195.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169388.81it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169806.23it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 170068.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19967/50000 [00:00<00:00, 147942.64it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39919/50000 [00:00<00:00, 153417.42it/s]Drawing 50000 posterior samples: 59886it [00:00, 157779.15it/s]                           Drawing 50000 posterior samples: 59886it [00:00, 160810.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19999/50000 [00:00<00:00, 168841.66it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39999/50000 [00:00<00:00, 169015.03it/s]Drawing 50000 posterior samples: 59998it [00:00, 169335.76it/s]                           Drawing 50000 posterior samples: 59998it [00:00, 169217.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 159361.38it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 159854.44it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 160141.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19983/50000 [00:00<00:00, 161580.93it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39965/50000 [00:00<00:00, 161528.99it/s]Drawing 50000 posterior samples: 59940it [00:00, 161543.67it/s]                           Drawing 50000 posterior samples: 59940it [00:00, 161316.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 160107.80it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 160209.35it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 159786.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 160395.26it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 160294.12it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 160179.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161834.45it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 162007.07it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161903.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165034.57it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164753.45it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164110.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161215.52it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161480.03it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161576.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163772.83it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163678.21it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163071.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161516.62it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165201.36it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168592.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 173314.77it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165212.59it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 153050.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 134612.52it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 135073.10it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 134790.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 136290.43it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 137213.64it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 137872.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18305/50000 [00:00<00:00, 147590.52it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36634/50000 [00:00<00:00, 147557.38it/s]Drawing 50000 posterior samples: 54994it [00:00, 147323.32it/s]                           Drawing 50000 posterior samples: 54994it [00:00, 147087.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18462/50000 [00:00<00:00, 148659.77it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36854/50000 [00:00<00:00, 148608.83it/s]Drawing 50000 posterior samples: 55317it [00:00, 148741.97it/s]                           Drawing 50000 posterior samples: 55317it [00:00, 148537.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18385/50000 [00:00<00:00, 148411.57it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36726/50000 [00:00<00:00, 147932.32it/s]Drawing 50000 posterior samples: 55194it [00:00, 148016.07it/s]                           Drawing 50000 posterior samples: 55194it [00:00, 147622.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18425/50000 [00:00<00:00, 148468.73it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36795/50000 [00:00<00:00, 148577.65it/s]Drawing 50000 posterior samples: 55130it [00:00, 148536.91it/s]                           Drawing 50000 posterior samples: 55130it [00:00, 148361.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18372/50000 [00:00<00:00, 147168.00it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36752/50000 [00:00<00:00, 147657.79it/s]Drawing 50000 posterior samples: 55188it [00:00, 147653.07it/s]                           Drawing 50000 posterior samples: 55188it [00:00, 147681.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  30%|███       | 15204/50000 [00:00<00:00, 121993.36it/s]Drawing 50000 posterior samples:  61%|██████    | 30541/50000 [00:00<00:00, 122637.19it/s]Drawing 50000 posterior samples:  92%|█████████▏| 45896/50000 [00:00<00:00, 123796.08it/s]Drawing 50000 posterior samples: 53606it [00:00, 124510.32it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18368/50000 [00:00<00:00, 153807.87it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36736/50000 [00:00<00:00, 153819.57it/s]Drawing 50000 posterior samples: 55076it [00:00, 153584.85it/s]                           Drawing 50000 posterior samples: 55076it [00:00, 153360.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18355/50000 [00:00<00:00, 151819.49it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36733/50000 [00:00<00:00, 151754.16it/s]Drawing 50000 posterior samples: 55157it [00:00, 151749.91it/s]                           Drawing 50000 posterior samples: 55157it [00:00, 151528.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18314/50000 [00:00<00:00, 151613.12it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36703/50000 [00:00<00:00, 151976.88it/s]Drawing 50000 posterior samples: 55046it [00:00, 152334.88it/s]                           Drawing 50000 posterior samples: 55046it [00:00, 152348.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18357/50000 [00:00<00:00, 161296.07it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36717/50000 [00:00<00:00, 161864.12it/s]Drawing 50000 posterior samples: 55188it [00:00, 162119.35it/s]                           Drawing 50000 posterior samples: 55188it [00:00, 162181.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18338/50000 [00:00<00:00, 149388.09it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36709/50000 [00:00<00:00, 149589.55it/s]Drawing 50000 posterior samples: 55172it [00:00, 150441.01it/s]                           Drawing 50000 posterior samples: 55172it [00:00, 150429.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18314/50000 [00:00<00:00, 149285.07it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36733/50000 [00:00<00:00, 149778.96it/s]Drawing 50000 posterior samples: 55063it [00:00, 149769.18it/s]                           Drawing 50000 posterior samples: 55063it [00:00, 149793.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18380/50000 [00:00<00:00, 150379.22it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36730/50000 [00:00<00:00, 150277.24it/s]Drawing 50000 posterior samples: 55124it [00:00, 150379.59it/s]                           Drawing 50000 posterior samples: 55124it [00:00, 150149.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18319/50000 [00:00<00:00, 150427.39it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36752/50000 [00:00<00:00, 150797.75it/s]Drawing 50000 posterior samples: 55131it [00:00, 151104.70it/s]                           Drawing 50000 posterior samples: 55131it [00:00, 151103.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18391/50000 [00:00<00:00, 152163.47it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36831/50000 [00:00<00:00, 152232.17it/s]Drawing 50000 posterior samples: 55238it [00:00, 152242.35it/s]                           Drawing 50000 posterior samples: 55238it [00:00, 152064.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18365/50000 [00:00<00:00, 150675.04it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36793/50000 [00:00<00:00, 150488.17it/s]Drawing 50000 posterior samples: 55192it [00:00, 150412.09it/s]                           Drawing 50000 posterior samples: 55192it [00:00, 150127.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18379/50000 [00:00<00:00, 149454.74it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36764/50000 [00:00<00:00, 149986.66it/s]Drawing 50000 posterior samples: 55149it [00:00, 150393.99it/s]                           Drawing 50000 posterior samples: 55149it [00:00, 150485.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18419/50000 [00:00<00:00, 159774.67it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36806/50000 [00:00<00:00, 157320.52it/s]Drawing 50000 posterior samples: 55191it [00:00, 156403.59it/s]                           Drawing 50000 posterior samples: 55191it [00:00, 155036.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18393/50000 [00:00<00:00, 153186.88it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36814/50000 [00:00<00:00, 148773.75it/s]Drawing 50000 posterior samples: 55183it [00:00, 144376.13it/s]                           Drawing 50000 posterior samples: 55183it [00:00, 141951.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18463/50000 [00:00<00:00, 136660.64it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36863/50000 [00:00<00:00, 136734.69it/s]Drawing 50000 posterior samples: 55290it [00:00, 135577.61it/s]                           Drawing 50000 posterior samples: 55290it [00:00, 135299.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18352/50000 [00:00<00:00, 132330.03it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36730/50000 [00:00<00:00, 132865.01it/s]Drawing 50000 posterior samples: 55152it [00:00, 133255.92it/s]                           Drawing 50000 posterior samples: 55152it [00:00, 133381.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18451/50000 [00:00<00:00, 148209.84it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36822/50000 [00:00<00:00, 148691.36it/s]Drawing 50000 posterior samples: 55207it [00:00, 148980.27it/s]                           Drawing 50000 posterior samples: 55207it [00:00, 149033.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18349/50000 [00:00<00:00, 147408.87it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36740/50000 [00:00<00:00, 147750.65it/s]Drawing 50000 posterior samples: 55104it [00:00, 147670.44it/s]                           Drawing 50000 posterior samples: 55104it [00:00, 147610.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18393/50000 [00:00<00:00, 148648.67it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36758/50000 [00:00<00:00, 148755.02it/s]Drawing 50000 posterior samples: 55183it [00:00, 148854.23it/s]                           Drawing 50000 posterior samples: 55183it [00:00, 148717.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18368/50000 [00:00<00:00, 147707.20it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36727/50000 [00:00<00:00, 147751.45it/s]Drawing 50000 posterior samples: 55155it [00:00, 147767.14it/s]                           Drawing 50000 posterior samples: 55155it [00:00, 147592.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18410/50000 [00:00<00:00, 149316.02it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36739/50000 [00:00<00:00, 149183.08it/s]Drawing 50000 posterior samples: 55195it [00:00, 149294.87it/s]                           Drawing 50000 posterior samples: 55195it [00:00, 149051.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18372/50000 [00:00<00:00, 147192.74it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36689/50000 [00:00<00:00, 147749.46it/s]Drawing 50000 posterior samples: 55100it [00:00, 149068.58it/s]                           Drawing 50000 posterior samples: 55100it [00:00, 149275.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18411/50000 [00:00<00:00, 149232.94it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36802/50000 [00:00<00:00, 147311.36it/s]Drawing 50000 posterior samples: 55198it [00:00, 142417.47it/s]                           Drawing 50000 posterior samples: 55198it [00:00, 140914.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18324/50000 [00:00<00:00, 132297.12it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36709/50000 [00:00<00:00, 132041.59it/s]Drawing 50000 posterior samples: 55127it [00:00, 132084.88it/s]                           Drawing 50000 posterior samples: 55127it [00:00, 131804.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18368/50000 [00:00<00:00, 131230.30it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36714/50000 [00:00<00:00, 130958.99it/s]Drawing 50000 posterior samples: 55101it [00:00, 130969.85it/s]                           Drawing 50000 posterior samples: 55101it [00:00, 130664.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18398/50000 [00:00<00:00, 161414.54it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36806/50000 [00:00<00:00, 160916.36it/s]Drawing 50000 posterior samples: 55186it [00:00, 160466.38it/s]                           Drawing 50000 posterior samples: 55186it [00:00, 159986.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18369/50000 [00:00<00:00, 134513.98it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36658/50000 [00:00<00:00, 137476.08it/s]Drawing 50000 posterior samples: 54988it [00:00, 141658.94it/s]                           Drawing 50000 posterior samples: 54988it [00:00, 143409.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18373/50000 [00:00<00:00, 150702.05it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36704/50000 [00:00<00:00, 150565.36it/s]Drawing 50000 posterior samples: 55033it [00:00, 150398.48it/s]                           Drawing 50000 posterior samples: 55033it [00:00, 150127.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18308/50000 [00:00<00:00, 128825.36it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36668/50000 [00:00<00:00, 129140.02it/s]Drawing 50000 posterior samples: 55026it [00:00, 129115.69it/s]                           Drawing 50000 posterior samples: 55026it [00:00, 129084.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18385/50000 [00:00<00:00, 156728.45it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36811/50000 [00:00<00:00, 157186.06it/s]Drawing 50000 posterior samples: 55185it [00:00, 155541.00it/s]                           Drawing 50000 posterior samples: 55185it [00:00, 155358.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▌      | 17688/50000 [00:00<00:00, 154724.17it/s]Drawing 50000 posterior samples:  71%|███████   | 35434/50000 [00:00<00:00, 154122.43it/s]Drawing 50000 posterior samples: 53072it [00:00, 153425.63it/s]                           Drawing 50000 posterior samples: 53072it [00:00, 152876.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18317/50000 [00:00<00:00, 149818.77it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36663/50000 [00:00<00:00, 149356.83it/s]Drawing 50000 posterior samples: 55084it [00:00, 149684.40it/s]                           Drawing 50000 posterior samples: 55084it [00:00, 149317.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18378/50000 [00:00<00:00, 147394.25it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36720/50000 [00:00<00:00, 147202.92it/s]Drawing 50000 posterior samples: 55105it [00:00, 147210.94it/s]                           Drawing 50000 posterior samples: 55105it [00:00, 146916.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18309/50000 [00:00<00:00, 147442.22it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36672/50000 [00:00<00:00, 147364.63it/s]Drawing 50000 posterior samples: 55015it [00:00, 148201.66it/s]                           Drawing 50000 posterior samples: 55015it [00:00, 148071.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18416/50000 [00:00<00:00, 150094.93it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36743/50000 [00:00<00:00, 149875.79it/s]Drawing 50000 posterior samples: 55144it [00:00, 149632.29it/s]                           Drawing 50000 posterior samples: 55144it [00:00, 149280.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18407/50000 [00:00<00:00, 125347.53it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36791/50000 [00:00<00:00, 125240.00it/s]Drawing 50000 posterior samples: 55232it [00:00, 124895.37it/s]                           Drawing 50000 posterior samples: 55232it [00:00, 124644.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18429/50000 [00:00<00:00, 154830.24it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36768/50000 [00:00<00:00, 154515.88it/s]Drawing 50000 posterior samples: 55182it [00:00, 154795.11it/s]                           Drawing 50000 posterior samples: 55182it [00:00, 154470.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18380/50000 [00:00<00:00, 155428.53it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36753/50000 [00:00<00:00, 155630.06it/s]Drawing 50000 posterior samples: 55093it [00:00, 155016.95it/s]                           Drawing 50000 posterior samples: 55093it [00:00, 154837.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18374/50000 [00:00<00:00, 153838.76it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36735/50000 [00:00<00:00, 153887.23it/s]Drawing 50000 posterior samples: 55059it [00:00, 154004.20it/s]                           Drawing 50000 posterior samples: 55059it [00:00, 153837.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18372/50000 [00:00<00:00, 156803.11it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36718/50000 [00:00<00:00, 156867.51it/s]Drawing 50000 posterior samples: 55077it [00:00, 156276.48it/s]                           Drawing 50000 posterior samples: 55077it [00:00, 156014.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18322/50000 [00:00<00:00, 147451.50it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36730/50000 [00:00<00:00, 147739.92it/s]Drawing 50000 posterior samples: 55080it [00:00, 147634.71it/s]                           Drawing 50000 posterior samples: 55080it [00:00, 147564.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18369/50000 [00:00<00:00, 146927.62it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36728/50000 [00:00<00:00, 147237.23it/s]Drawing 50000 posterior samples: 55055it [00:00, 147394.17it/s]                           Drawing 50000 posterior samples: 55055it [00:00, 147360.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18315/50000 [00:00<00:00, 158881.07it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36622/50000 [00:00<00:00, 152614.40it/s]Drawing 50000 posterior samples: 55007it [00:00, 140742.97it/s]                           Drawing 50000 posterior samples: 55007it [00:00, 137109.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18350/50000 [00:00<00:00, 133360.15it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36752/50000 [00:00<00:00, 133129.77it/s]Drawing 50000 posterior samples: 55107it [00:00, 132914.58it/s]                           Drawing 50000 posterior samples: 55107it [00:00, 132610.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18372/50000 [00:00<00:00, 150865.86it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36791/50000 [00:00<00:00, 151020.57it/s]Drawing 50000 posterior samples: 55152it [00:00, 150740.62it/s]                           Drawing 50000 posterior samples: 55152it [00:00, 150562.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18355/50000 [00:00<00:00, 149438.92it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36716/50000 [00:00<00:00, 149317.26it/s]Drawing 50000 posterior samples: 55016it [00:00, 149255.05it/s]                           Drawing 50000 posterior samples: 55016it [00:00, 149002.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18344/50000 [00:00<00:00, 147779.97it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36733/50000 [00:00<00:00, 148202.52it/s]Drawing 50000 posterior samples: 55059it [00:00, 148535.72it/s]                           Drawing 50000 posterior samples: 55059it [00:00, 148566.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18287/50000 [00:00<00:00, 148050.45it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36632/50000 [00:00<00:00, 148207.88it/s]Drawing 50000 posterior samples: 55009it [00:00, 148541.94it/s]                           Drawing 50000 posterior samples: 55009it [00:00, 148455.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18344/50000 [00:00<00:00, 148720.61it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36722/50000 [00:00<00:00, 149156.85it/s]Drawing 50000 posterior samples: 55122it [00:00, 149412.99it/s]                           Drawing 50000 posterior samples: 55122it [00:00, 149433.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18388/50000 [00:00<00:00, 147427.66it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36779/50000 [00:00<00:00, 147086.38it/s]Drawing 50000 posterior samples: 55140it [00:00, 146891.02it/s]                           Drawing 50000 posterior samples: 55140it [00:00, 146511.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18390/50000 [00:00<00:00, 147109.62it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36750/50000 [00:00<00:00, 146698.05it/s]Drawing 50000 posterior samples: 55044it [00:00, 146240.19it/s]                           Drawing 50000 posterior samples: 55044it [00:00, 145806.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18321/50000 [00:00<00:00, 145058.18it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36627/50000 [00:00<00:00, 145039.54it/s]Drawing 50000 posterior samples: 54939it [00:00, 145144.20it/s]                           Drawing 50000 posterior samples: 54939it [00:00, 144920.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18358/50000 [00:00<00:00, 147718.55it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36714/50000 [00:00<00:00, 147606.84it/s]Drawing 50000 posterior samples: 55022it [00:00, 147527.87it/s]                           Drawing 50000 posterior samples: 55022it [00:00, 147260.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18368/50000 [00:00<00:00, 146191.69it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36750/50000 [00:00<00:00, 146078.24it/s]Drawing 50000 posterior samples: 55094it [00:00, 146160.42it/s]                           Drawing 50000 posterior samples: 55094it [00:00, 145921.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18373/50000 [00:00<00:00, 146535.41it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36751/50000 [00:00<00:00, 146170.13it/s]Drawing 50000 posterior samples: 55171it [00:00, 146357.53it/s]                           Drawing 50000 posterior samples: 55171it [00:00, 145992.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18302/50000 [00:00<00:00, 148132.43it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36741/50000 [00:00<00:00, 148843.86it/s]Drawing 50000 posterior samples: 55152it [00:00, 148756.26it/s]                           Drawing 50000 posterior samples: 55152it [00:00, 148867.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163998.23it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163617.26it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163153.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 18865/50000 [00:00<00:00, 152412.18it/s]Drawing 50000 posterior samples:  76%|███████▌  | 37811/50000 [00:00<00:00, 153104.70it/s]Drawing 50000 posterior samples: 56784it [00:00, 153572.58it/s]                           Drawing 50000 posterior samples: 56784it [00:00, 153737.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161697.82it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161963.16it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161979.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164436.08it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164301.68it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164004.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▍      | 17364/50000 [00:00<00:00, 116301.00it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34797/50000 [00:00<00:00, 117278.17it/s]Drawing 50000 posterior samples: 52191it [00:00, 116919.57it/s]                           Drawing 50000 posterior samples: 52191it [00:00, 117166.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▌      | 17568/50000 [00:00<00:00, 136639.66it/s]Drawing 50000 posterior samples:  70%|███████   | 35189/50000 [00:00<00:00, 133733.39it/s]Drawing 50000 posterior samples: 52828it [00:00, 129599.95it/s]                           Drawing 50000 posterior samples: 52828it [00:00, 127789.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 137244.13it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 136883.47it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 136724.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166655.90it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166916.15it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167084.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168454.74it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168556.39it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168627.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169421.65it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169567.54it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169514.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19975/50000 [00:00<00:00, 170079.97it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39955/50000 [00:00<00:00, 170254.15it/s]Drawing 50000 posterior samples: 59939it [00:00, 170469.78it/s]                           Drawing 50000 posterior samples: 59939it [00:00, 170341.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168498.05it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169069.40it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169657.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170273.82it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169929.24it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169283.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170487.34it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170720.61it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 170811.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 171621.28it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 171272.60it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 170789.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▉      | 19711/50000 [00:00<00:00, 169081.16it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39414/50000 [00:00<00:00, 169154.21it/s]Drawing 50000 posterior samples: 59122it [00:00, 169116.99it/s]                           Drawing 50000 posterior samples: 59122it [00:00, 168869.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19959/50000 [00:00<00:00, 171464.15it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39919/50000 [00:00<00:00, 171068.77it/s]Drawing 50000 posterior samples: 59870it [00:00, 170191.72it/s]                           Drawing 50000 posterior samples: 59870it [00:00, 169698.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 171082.96it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 171064.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 171082.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▉      | 19578/50000 [00:00<00:00, 165296.68it/s]Drawing 50000 posterior samples:  78%|███████▊  | 39153/50000 [00:00<00:00, 165539.42it/s]Drawing 50000 posterior samples: 58757it [00:00, 165771.33it/s]                           Drawing 50000 posterior samples: 58757it [00:00, 165654.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 171594.60it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 171656.12it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 171498.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170810.19it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170781.61it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 170828.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169581.94it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169813.45it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 170119.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169590.85it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169703.66it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169655.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 171221.59it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 171165.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 171203.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170279.70it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170090.77it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169594.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170077.04it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170230.08it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 170088.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19986/50000 [00:00<00:00, 171320.99it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39970/50000 [00:00<00:00, 171313.43it/s]Drawing 50000 posterior samples: 59957it [00:00, 171152.06it/s]                           Drawing 50000 posterior samples: 59957it [00:00, 170903.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170653.82it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 170962.67it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 171073.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169568.91it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169817.20it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169590.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  34%|███▍      | 17102/50000 [00:00<00:00, 136563.34it/s]Drawing 50000 posterior samples:  68%|██████▊   | 34143/50000 [00:00<00:00, 136616.86it/s]Drawing 50000 posterior samples: 51276it [00:00, 136708.47it/s]                           Drawing 50000 posterior samples: 51276it [00:00, 136566.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18309/50000 [00:00<00:00, 145400.40it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36647/50000 [00:00<00:00, 145754.23it/s]Drawing 50000 posterior samples: 54975it [00:00, 145734.72it/s]                           Drawing 50000 posterior samples: 54975it [00:00, 145673.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 17763/50000 [00:00<00:00, 142859.87it/s]Drawing 50000 posterior samples:  71%|███████   | 35440/50000 [00:00<00:00, 142288.57it/s]Drawing 50000 posterior samples: 53198it [00:00, 141922.27it/s]                           Drawing 50000 posterior samples: 53198it [00:00, 141444.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18375/50000 [00:00<00:00, 150042.71it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36661/50000 [00:00<00:00, 149424.63it/s]Drawing 50000 posterior samples: 54987it [00:00, 148991.41it/s]                           Drawing 50000 posterior samples: 54987it [00:00, 148460.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18334/50000 [00:00<00:00, 148770.96it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36668/50000 [00:00<00:00, 148366.32it/s]Drawing 50000 posterior samples: 54941it [00:00, 148095.17it/s]                           Drawing 50000 posterior samples: 54941it [00:00, 147691.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 18009/50000 [00:00<00:00, 146208.99it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36005/50000 [00:00<00:00, 146131.72it/s]Drawing 50000 posterior samples: 53978it [00:00, 143988.16it/s]                           Drawing 50000 posterior samples: 53978it [00:00, 143513.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18338/50000 [00:00<00:00, 149171.37it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36643/50000 [00:00<00:00, 149884.19it/s]Drawing 50000 posterior samples: 54929it [00:00, 150360.53it/s]                           Drawing 50000 posterior samples: 54929it [00:00, 150507.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18293/50000 [00:00<00:00, 150817.42it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36612/50000 [00:00<00:00, 151033.46it/s]Drawing 50000 posterior samples: 54946it [00:00, 150823.19it/s]                           Drawing 50000 posterior samples: 54946it [00:00, 150659.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18311/50000 [00:00<00:00, 156522.00it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36657/50000 [00:00<00:00, 157701.83it/s]Drawing 50000 posterior samples: 54949it [00:00, 158591.73it/s]                           Drawing 50000 posterior samples: 54949it [00:00, 159008.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18253/50000 [00:00<00:00, 120632.02it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36595/50000 [00:00<00:00, 121079.73it/s]Drawing 50000 posterior samples: 54952it [00:00, 118292.13it/s]                           Drawing 50000 posterior samples: 54952it [00:00, 118013.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18268/50000 [00:00<00:00, 126313.34it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36561/50000 [00:00<00:00, 126476.69it/s]Drawing 50000 posterior samples: 54893it [00:00, 131582.64it/s]                           Drawing 50000 posterior samples: 54893it [00:00, 132115.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18331/50000 [00:00<00:00, 153166.26it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36678/50000 [00:00<00:00, 153089.30it/s]Drawing 50000 posterior samples: 54994it [00:00, 152459.44it/s]                           Drawing 50000 posterior samples: 54994it [00:00, 152138.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18359/50000 [00:00<00:00, 153234.15it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36666/50000 [00:00<00:00, 153147.39it/s]Drawing 50000 posterior samples: 54949it [00:00, 153103.75it/s]                           Drawing 50000 posterior samples: 54949it [00:00, 152851.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18333/50000 [00:00<00:00, 150143.76it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36625/50000 [00:00<00:00, 150384.50it/s]Drawing 50000 posterior samples: 54980it [00:00, 150615.64it/s]                           Drawing 50000 posterior samples: 54980it [00:00, 150537.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18327/50000 [00:00<00:00, 151219.90it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36695/50000 [00:00<00:00, 151794.67it/s]Drawing 50000 posterior samples: 55096it [00:00, 152277.87it/s]                           Drawing 50000 posterior samples: 55096it [00:00, 152391.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18329/50000 [00:00<00:00, 149983.32it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36590/50000 [00:00<00:00, 150399.41it/s]Drawing 50000 posterior samples: 54870it [00:00, 150866.88it/s]                           Drawing 50000 posterior samples: 54870it [00:00, 150898.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18310/50000 [00:00<00:00, 150922.28it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36612/50000 [00:00<00:00, 151378.23it/s]Drawing 50000 posterior samples: 54968it [00:00, 151963.18it/s]                           Drawing 50000 posterior samples: 54968it [00:00, 152044.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18356/50000 [00:00<00:00, 154220.95it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36673/50000 [00:00<00:00, 153873.67it/s]Drawing 50000 posterior samples: 55049it [00:00, 153437.60it/s]                           Drawing 50000 posterior samples: 55049it [00:00, 153035.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18341/50000 [00:00<00:00, 151543.21it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36614/50000 [00:00<00:00, 151511.21it/s]Drawing 50000 posterior samples: 54935it [00:00, 151890.13it/s]                           Drawing 50000 posterior samples: 54935it [00:00, 151708.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18359/50000 [00:00<00:00, 152363.67it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36659/50000 [00:00<00:00, 152274.70it/s]Drawing 50000 posterior samples: 54955it [00:00, 152398.35it/s]                           Drawing 50000 posterior samples: 54955it [00:00, 152175.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▋      | 18241/50000 [00:00<00:00, 153398.25it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36500/50000 [00:00<00:00, 153016.78it/s]Drawing 50000 posterior samples: 54860it [00:00, 153040.34it/s]                           Drawing 50000 posterior samples: 54860it [00:00, 152666.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18329/50000 [00:00<00:00, 153264.04it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36576/50000 [00:00<00:00, 152863.45it/s]Drawing 50000 posterior samples: 54898it [00:00, 153092.71it/s]                           Drawing 50000 posterior samples: 54898it [00:00, 152732.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18367/50000 [00:00<00:00, 152946.65it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36718/50000 [00:00<00:00, 152796.65it/s]Drawing 50000 posterior samples: 55009it [00:00, 152761.72it/s]                           Drawing 50000 posterior samples: 55009it [00:00, 152489.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18315/50000 [00:00<00:00, 149335.01it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36641/50000 [00:00<00:00, 149460.98it/s]Drawing 50000 posterior samples: 55006it [00:00, 149630.96it/s]                           Drawing 50000 posterior samples: 55006it [00:00, 149496.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18348/50000 [00:00<00:00, 151390.20it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36611/50000 [00:00<00:00, 151191.47it/s]Drawing 50000 posterior samples: 54914it [00:00, 151227.46it/s]                           Drawing 50000 posterior samples: 54914it [00:00, 150945.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18420/50000 [00:00<00:00, 150720.90it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36749/50000 [00:00<00:00, 151017.00it/s]Drawing 50000 posterior samples: 55032it [00:00, 150957.33it/s]                           Drawing 50000 posterior samples: 55032it [00:00, 150874.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18360/50000 [00:00<00:00, 149921.39it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36696/50000 [00:00<00:00, 150099.28it/s]Drawing 50000 posterior samples: 55048it [00:00, 150544.97it/s]                           Drawing 50000 posterior samples: 55048it [00:00, 150479.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18320/50000 [00:00<00:00, 150158.09it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36641/50000 [00:00<00:00, 150342.28it/s]Drawing 50000 posterior samples: 54949it [00:00, 150721.20it/s]                           Drawing 50000 posterior samples: 54949it [00:00, 150646.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18410/50000 [00:00<00:00, 152340.51it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36687/50000 [00:00<00:00, 152016.62it/s]Drawing 50000 posterior samples: 54993it [00:00, 151334.87it/s]                           Drawing 50000 posterior samples: 54993it [00:00, 150917.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18355/50000 [00:00<00:00, 151904.87it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36666/50000 [00:00<00:00, 151691.20it/s]Drawing 50000 posterior samples: 55006it [00:00, 151736.90it/s]                           Drawing 50000 posterior samples: 55006it [00:00, 151453.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18408/50000 [00:00<00:00, 156898.69it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36697/50000 [00:00<00:00, 156080.78it/s]Drawing 50000 posterior samples: 54994it [00:00, 155631.71it/s]                           Drawing 50000 posterior samples: 54994it [00:00, 155020.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168529.53it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168619.88it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168324.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▊      | 19340/50000 [00:00<00:00, 140276.27it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38743/50000 [00:00<00:00, 141355.35it/s]Drawing 50000 posterior samples: 58092it [00:00, 141565.93it/s]                           Drawing 50000 posterior samples: 58092it [00:00, 141895.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166595.66it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166855.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166998.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 158892.00it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 159737.70it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 157801.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 19046/50000 [00:00<00:00, 150265.72it/s]Drawing 50000 posterior samples:  76%|███████▋  | 38128/50000 [00:00<00:00, 151706.88it/s]Drawing 50000 posterior samples: 57131it [00:00, 152486.16it/s]                           Drawing 50000 posterior samples: 57131it [00:00, 153022.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 19098/50000 [00:00<00:00, 154208.47it/s]Drawing 50000 posterior samples:  76%|███████▋  | 38185/50000 [00:00<00:00, 154195.00it/s]Drawing 50000 posterior samples: 57289it [00:00, 153889.52it/s]                           Drawing 50000 posterior samples: 57289it [00:00, 153654.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161651.70it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161168.78it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 153301.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161552.39it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161820.90it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161750.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 162436.76it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 162681.81it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163036.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164433.18it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163715.17it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 162844.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19999/50000 [00:00<00:00, 162706.53it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39998/50000 [00:00<00:00, 162501.99it/s]Drawing 50000 posterior samples: 59996it [00:00, 162858.75it/s]                           Drawing 50000 posterior samples: 59996it [00:00, 162596.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 141396.13it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 141824.20it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 141887.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 143895.32it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 143669.38it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 142575.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 143492.88it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 142706.14it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 140987.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 141114.26it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 141758.27it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 142168.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19915/50000 [00:00<00:00, 173042.60it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39842/50000 [00:00<00:00, 173477.57it/s]Drawing 50000 posterior samples: 59754it [00:00, 171343.42it/s]                           Drawing 50000 posterior samples: 59754it [00:00, 171070.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19998/50000 [00:00<00:00, 164664.95it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39990/50000 [00:00<00:00, 164445.44it/s]Drawing 50000 posterior samples: 59988it [00:00, 164445.34it/s]                           Drawing 50000 posterior samples: 59988it [00:00, 164143.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163045.15it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163287.56it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163163.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19845/50000 [00:00<00:00, 139784.78it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39702/50000 [00:00<00:00, 140815.34it/s]Drawing 50000 posterior samples: 59515it [00:00, 140221.21it/s]                           Drawing 50000 posterior samples: 59515it [00:00, 140436.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164133.65it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166513.05it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168811.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 174869.41it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 174880.46it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 174389.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161315.35it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161814.69it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 162126.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163363.63it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 157992.43it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 152021.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 162670.80it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 162833.26it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 162759.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 162349.68it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 162875.09it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 156835.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 140378.43it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 148188.30it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 156715.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167173.68it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167237.07it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167621.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169705.44it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169987.09it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169913.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168720.71it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168746.37it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168340.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 18068/50000 [00:00<00:00, 153557.94it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36170/50000 [00:00<00:00, 153483.59it/s]Drawing 50000 posterior samples: 54271it [00:00, 153486.84it/s]                           Drawing 50000 posterior samples: 54271it [00:00, 153248.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161269.45it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161041.99it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 160654.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19953/50000 [00:00<00:00, 160152.76it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39899/50000 [00:00<00:00, 160125.24it/s]Drawing 50000 posterior samples: 59855it [00:00, 159947.92it/s]                           Drawing 50000 posterior samples: 59855it [00:00, 159708.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 171978.41it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168089.28it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163086.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 130991.15it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 135868.72it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 140899.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▊      | 19324/50000 [00:00<00:00, 155371.10it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38685/50000 [00:00<00:00, 154952.70it/s]Drawing 50000 posterior samples: 58035it [00:00, 154407.23it/s]                           Drawing 50000 posterior samples: 58035it [00:00, 153954.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 18779/50000 [00:00<00:00, 161370.94it/s]Drawing 50000 posterior samples:  75%|███████▍  | 37478/50000 [00:00<00:00, 159437.36it/s]Drawing 50000 posterior samples: 56266it [00:00, 157677.63it/s]                           Drawing 50000 posterior samples: 56266it [00:00, 156455.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163493.22it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163647.36it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161665.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 140742.08it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 140905.41it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 140820.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 145209.00it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 145356.73it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 145511.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167737.27it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167790.92it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167581.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167385.50it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167580.62it/s]Drawing 50000 posterior samples: 59999it [00:00, 167480.18it/s]                           Drawing 50000 posterior samples: 59999it [00:00, 167339.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164569.31it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 165152.90it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165481.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166512.00it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166445.59it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166312.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 165491.68it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166187.96it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166697.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166913.56it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166811.29it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166479.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19765/50000 [00:00<00:00, 164440.91it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39547/50000 [00:00<00:00, 162943.58it/s]Drawing 50000 posterior samples: 59340it [00:00, 156523.93it/s]                           Drawing 50000 posterior samples: 59340it [00:00, 155019.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161465.32it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161589.89it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161566.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 160458.77it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 160668.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 160811.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▉      | 19730/50000 [00:00<00:00, 160475.37it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39447/50000 [00:00<00:00, 160715.74it/s]Drawing 50000 posterior samples: 59190it [00:00, 161148.20it/s]                           Drawing 50000 posterior samples: 59190it [00:00, 161094.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161485.84it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161558.90it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 161545.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161485.84it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 161715.77it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 162095.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 141208.57it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 138962.65it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 138011.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 136928.70it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 137421.23it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 137999.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 134150.12it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 134137.25it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 133846.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168857.58it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168977.07it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168920.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168350.27it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 168186.64it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167536.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169564.11it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169831.78it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 170165.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169764.52it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169930.41it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169716.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169313.25it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169565.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169449.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  34%|███▎      | 16771/50000 [00:00<00:00, 140572.32it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33654/50000 [00:00<00:00, 141338.45it/s]Drawing 50000 posterior samples: 50476it [00:00, 141604.04it/s]                           Drawing 50000 posterior samples: 50476it [00:00, 141807.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169206.69it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169216.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 168856.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▉      | 19736/50000 [00:00<00:00, 166276.21it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39479/50000 [00:00<00:00, 166351.73it/s]Drawing 50000 posterior samples: 59225it [00:00, 166398.07it/s]                           Drawing 50000 posterior samples: 59225it [00:00, 166208.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 167129.05it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167403.80it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167545.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 166777.50it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 167429.20it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 167928.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 18977/50000 [00:00<00:00, 160070.68it/s]Drawing 50000 posterior samples:  76%|███████▌  | 38006/50000 [00:00<00:00, 160045.31it/s]Drawing 50000 posterior samples: 57009it [00:00, 159593.19it/s]                           Drawing 50000 posterior samples: 57009it [00:00, 159305.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  35%|███▌      | 17727/50000 [00:00<00:00, 149578.99it/s]Drawing 50000 posterior samples:  71%|███████   | 35437/50000 [00:00<00:00, 149487.45it/s]Drawing 50000 posterior samples: 53102it [00:00, 143992.15it/s]                           Drawing 50000 posterior samples: 53102it [00:00, 143198.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 168763.14it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169176.77it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169440.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169962.29it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169820.67it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169218.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169914.44it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169932.93it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169860.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169768.64it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169716.71it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169234.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19987/50000 [00:00<00:00, 168355.39it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39972/50000 [00:00<00:00, 167913.47it/s]Drawing 50000 posterior samples: 59960it [00:00, 167889.71it/s]                           Drawing 50000 posterior samples: 59960it [00:00, 167479.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 170165.37it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 169906.25it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 169499.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 169202.60it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 166661.49it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163900.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 159071.28it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 158875.33it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 158586.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 159205.02it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 159143.95it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 158960.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19843/50000 [00:00<00:00, 157117.65it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39677/50000 [00:00<00:00, 157479.62it/s]Drawing 50000 posterior samples: 59518it [00:00, 157709.20it/s]                           Drawing 50000 posterior samples: 59518it [00:00, 157696.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164279.25it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164094.25it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163620.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164482.51it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164032.00it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163621.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|███▉      | 19872/50000 [00:00<00:00, 161188.98it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39727/50000 [00:00<00:00, 161178.46it/s]Drawing 50000 posterior samples: 59605it [00:00, 161234.18it/s]                           Drawing 50000 posterior samples: 59605it [00:00, 161017.97it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 161994.15it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 162584.45it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 162659.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 162224.41it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163712.45it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166480.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 174881.08it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 175344.41it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 166610.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 133252.13it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 133993.03it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 134640.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 135094.00it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 134746.95it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 134831.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164129.79it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164768.69it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 165156.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163004.28it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163608.87it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164063.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163319.42it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163414.68it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163401.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 164162.55it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 164487.32it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 164231.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20000/50000 [00:00<00:00, 163399.91it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 163438.11it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 163410.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▋      | 18133/50000 [00:00<00:00, 149459.81it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36314/50000 [00:00<00:00, 149410.18it/s]Drawing 50000 posterior samples: 54496it [00:00, 149322.90it/s]                           Drawing 50000 posterior samples: 54496it [00:00, 149094.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18387/50000 [00:00<00:00, 151845.52it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36839/50000 [00:00<00:00, 152505.51it/s]Drawing 50000 posterior samples: 55155it [00:00, 152430.46it/s]                           Drawing 50000 posterior samples: 55155it [00:00, 152511.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18331/50000 [00:00<00:00, 152263.86it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36698/50000 [00:00<00:00, 152088.24it/s]Drawing 50000 posterior samples: 55060it [00:00, 152330.91it/s]                           Drawing 50000 posterior samples: 55060it [00:00, 152051.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18355/50000 [00:00<00:00, 154600.89it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36686/50000 [00:00<00:00, 152723.03it/s]Drawing 50000 posterior samples: 55101it [00:00, 153420.03it/s]                           Drawing 50000 posterior samples: 55101it [00:00, 152431.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18388/50000 [00:00<00:00, 153348.95it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36702/50000 [00:00<00:00, 152478.12it/s]Drawing 50000 posterior samples: 54988it [00:00, 152312.48it/s]                           Drawing 50000 posterior samples: 54988it [00:00, 151715.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  23%|██▎       | 11671/50000 [00:00<00:00, 95543.89it/s]Drawing 50000 posterior samples:  46%|████▋     | 23245/50000 [00:00<00:00, 95544.16it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34757/50000 [00:00<00:00, 95142.23it/s]Drawing 50000 posterior samples:  93%|█████████▎| 46372/50000 [00:00<00:00, 94998.87it/s]Drawing 50000 posterior samples: 52092it [00:00, 94666.49it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18374/50000 [00:00<00:00, 153795.47it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36766/50000 [00:00<00:00, 153762.17it/s]Drawing 50000 posterior samples: 55113it [00:00, 153200.70it/s]                           Drawing 50000 posterior samples: 55113it [00:00, 152918.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18430/50000 [00:00<00:00, 161784.64it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36811/50000 [00:00<00:00, 161412.89it/s]Drawing 50000 posterior samples: 55206it [00:00, 160921.42it/s]                           Drawing 50000 posterior samples: 55206it [00:00, 160460.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18422/50000 [00:00<00:00, 164195.55it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36792/50000 [00:00<00:00, 162008.54it/s]Drawing 50000 posterior samples: 55154it [00:00, 160262.93it/s]                           Drawing 50000 posterior samples: 55154it [00:00, 158905.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18297/50000 [00:00<00:00, 153072.76it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36748/50000 [00:00<00:00, 153791.57it/s]Drawing 50000 posterior samples: 55143it [00:00, 154133.56it/s]                           Drawing 50000 posterior samples: 55143it [00:00, 154287.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18439/50000 [00:00<00:00, 134631.93it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36827/50000 [00:00<00:00, 134839.40it/s]Drawing 50000 posterior samples: 55218it [00:00, 134428.27it/s]                           Drawing 50000 posterior samples: 55218it [00:00, 134297.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18386/50000 [00:00<00:00, 166058.65it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36702/50000 [00:00<00:00, 164688.24it/s]Drawing 50000 posterior samples: 55015it [00:00, 161852.15it/s]                           Drawing 50000 posterior samples: 55015it [00:00, 160750.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18438/50000 [00:00<00:00, 136658.16it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36839/50000 [00:00<00:00, 136021.91it/s]Drawing 50000 posterior samples: 55167it [00:00, 135795.72it/s]                           Drawing 50000 posterior samples: 55167it [00:00, 135309.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18364/50000 [00:00<00:00, 151150.84it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36708/50000 [00:00<00:00, 151325.19it/s]Drawing 50000 posterior samples: 55030it [00:00, 151174.42it/s]                           Drawing 50000 posterior samples: 55030it [00:00, 151037.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18399/50000 [00:00<00:00, 150906.17it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36786/50000 [00:00<00:00, 151120.45it/s]Drawing 50000 posterior samples: 55065it [00:00, 151428.69it/s]                           Drawing 50000 posterior samples: 55065it [00:00, 151356.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18343/50000 [00:00<00:00, 149633.71it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36672/50000 [00:00<00:00, 149821.85it/s]Drawing 50000 posterior samples: 55047it [00:00, 150307.84it/s]                           Drawing 50000 posterior samples: 55047it [00:00, 150236.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18365/50000 [00:00<00:00, 151889.03it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36754/50000 [00:00<00:00, 152435.74it/s]Drawing 50000 posterior samples: 55085it [00:00, 152693.18it/s]                           Drawing 50000 posterior samples: 55085it [00:00, 152768.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18345/50000 [00:00<00:00, 150074.42it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36717/50000 [00:00<00:00, 150287.41it/s]Drawing 50000 posterior samples: 55018it [00:00, 150214.21it/s]                           Drawing 50000 posterior samples: 55018it [00:00, 150105.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18374/50000 [00:00<00:00, 152941.48it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36693/50000 [00:00<00:00, 152818.62it/s]Drawing 50000 posterior samples: 55012it [00:00, 152775.65it/s]                           Drawing 50000 posterior samples: 55012it [00:00, 152517.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18344/50000 [00:00<00:00, 150743.35it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36724/50000 [00:00<00:00, 151651.26it/s]Drawing 50000 posterior samples: 55113it [00:00, 153234.10it/s]                           Drawing 50000 posterior samples: 55113it [00:00, 153626.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18413/50000 [00:00<00:00, 135801.17it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36790/50000 [00:00<00:00, 136036.88it/s]Drawing 50000 posterior samples: 55229it [00:00, 136047.02it/s]                           Drawing 50000 posterior samples: 55229it [00:00, 135957.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18375/50000 [00:00<00:00, 138576.58it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36756/50000 [00:00<00:00, 138017.40it/s]Drawing 50000 posterior samples: 55212it [00:00, 136313.81it/s]                           Drawing 50000 posterior samples: 55212it [00:00, 135696.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18371/50000 [00:00<00:00, 132001.83it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36762/50000 [00:00<00:00, 132378.09it/s]Drawing 50000 posterior samples: 55082it [00:00, 132960.82it/s]                           Drawing 50000 posterior samples: 55082it [00:00, 133006.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18324/50000 [00:00<00:00, 149149.48it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36659/50000 [00:00<00:00, 149333.19it/s]Drawing 50000 posterior samples: 55082it [00:00, 149887.50it/s]                           Drawing 50000 posterior samples: 55082it [00:00, 149842.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18377/50000 [00:00<00:00, 149617.46it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36757/50000 [00:00<00:00, 149638.81it/s]Drawing 50000 posterior samples: 55156it [00:00, 149390.54it/s]                           Drawing 50000 posterior samples: 55156it [00:00, 149145.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18403/50000 [00:00<00:00, 148020.44it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36723/50000 [00:00<00:00, 148148.79it/s]Drawing 50000 posterior samples: 55049it [00:00, 148120.04it/s]                           Drawing 50000 posterior samples: 55049it [00:00, 147983.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18353/50000 [00:00<00:00, 147658.49it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36746/50000 [00:00<00:00, 147990.00it/s]Drawing 50000 posterior samples: 55127it [00:00, 147896.55it/s]                           Drawing 50000 posterior samples: 55127it [00:00, 147838.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18343/50000 [00:00<00:00, 148611.97it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36766/50000 [00:00<00:00, 149110.77it/s]Drawing 50000 posterior samples: 55096it [00:00, 148956.63it/s]                           Drawing 50000 posterior samples: 55096it [00:00, 148936.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18375/50000 [00:00<00:00, 149426.85it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36802/50000 [00:00<00:00, 150738.53it/s]Drawing 50000 posterior samples: 55067it [00:00, 150358.23it/s]                           Drawing 50000 posterior samples: 55067it [00:00, 150713.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18386/50000 [00:00<00:00, 150629.59it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36729/50000 [00:00<00:00, 148618.95it/s]Drawing 50000 posterior samples: 55125it [00:00, 141146.38it/s]                           Drawing 50000 posterior samples: 55125it [00:00, 139375.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18316/50000 [00:00<00:00, 143065.21it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36714/50000 [00:00<00:00, 143654.31it/s]Drawing 50000 posterior samples: 55070it [00:00, 144254.42it/s]                           Drawing 50000 posterior samples: 55070it [00:00, 144407.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18372/50000 [00:00<00:00, 131267.59it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36672/50000 [00:00<00:00, 131154.64it/s]Drawing 50000 posterior samples: 55011it [00:00, 129746.97it/s]                           Drawing 50000 posterior samples: 55011it [00:00, 129363.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▋      | 18224/50000 [00:00<00:00, 129403.55it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36599/50000 [00:00<00:00, 129721.26it/s]Drawing 50000 posterior samples: 54997it [00:00, 129800.42it/s]                           Drawing 50000 posterior samples: 54997it [00:00, 129756.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18397/50000 [00:00<00:00, 156634.32it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36754/50000 [00:00<00:00, 157185.82it/s]Drawing 50000 posterior samples: 55091it [00:00, 157943.54it/s]                           Drawing 50000 posterior samples: 55091it [00:00, 158065.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18403/50000 [00:00<00:00, 149043.95it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36736/50000 [00:00<00:00, 149058.18it/s]Drawing 50000 posterior samples: 55088it [00:00, 149154.66it/s]                           Drawing 50000 posterior samples: 55088it [00:00, 148951.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  32%|███▏      | 15990/50000 [00:00<00:00, 129902.90it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32006/50000 [00:00<00:00, 129919.67it/s]Drawing 50000 posterior samples:  96%|█████████▌| 48025/50000 [00:00<00:00, 129967.14it/s]Drawing 50000 posterior samples: 56087it [00:00, 129933.80it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18360/50000 [00:00<00:00, 150824.90it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36749/50000 [00:00<00:00, 150924.72it/s]Drawing 50000 posterior samples: 55123it [00:00, 151187.23it/s]                           Drawing 50000 posterior samples: 55123it [00:00, 151062.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18379/50000 [00:00<00:00, 152447.60it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36760/50000 [00:00<00:00, 152510.03it/s]Drawing 50000 posterior samples: 55151it [00:00, 152435.53it/s]                           Drawing 50000 posterior samples: 55151it [00:00, 152248.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18336/50000 [00:00<00:00, 149628.99it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36712/50000 [00:00<00:00, 151890.28it/s]Drawing 50000 posterior samples: 55049it [00:00, 153663.53it/s]                           Drawing 50000 posterior samples: 55049it [00:00, 154716.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18314/50000 [00:00<00:00, 157926.14it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36664/50000 [00:00<00:00, 157212.52it/s]Drawing 50000 posterior samples: 54975it [00:00, 157394.31it/s]                           Drawing 50000 posterior samples: 54975it [00:00, 156757.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18421/50000 [00:00<00:00, 149071.72it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36750/50000 [00:00<00:00, 148662.10it/s]Drawing 50000 posterior samples: 55074it [00:00, 148436.97it/s]                           Drawing 50000 posterior samples: 55074it [00:00, 148039.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18318/50000 [00:00<00:00, 130806.89it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36743/50000 [00:00<00:00, 130513.96it/s]Drawing 50000 posterior samples: 55094it [00:00, 130083.82it/s]                           Drawing 50000 posterior samples: 55094it [00:00, 129709.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18318/50000 [00:00<00:00, 148246.77it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36708/50000 [00:00<00:00, 148628.13it/s]Drawing 50000 posterior samples: 55071it [00:00, 148650.69it/s]                           Drawing 50000 posterior samples: 55071it [00:00, 148624.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18379/50000 [00:00<00:00, 128966.45it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36763/50000 [00:00<00:00, 127342.64it/s]Drawing 50000 posterior samples: 55070it [00:00, 125919.54it/s]                           Drawing 50000 posterior samples: 55070it [00:00, 124912.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18361/50000 [00:00<00:00, 156133.22it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36739/50000 [00:00<00:00, 156002.75it/s]Drawing 50000 posterior samples: 55125it [00:00, 155882.47it/s]                           Drawing 50000 posterior samples: 55125it [00:00, 155613.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18340/50000 [00:00<00:00, 152987.89it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36663/50000 [00:00<00:00, 153162.50it/s]Drawing 50000 posterior samples: 54943it [00:00, 153032.98it/s]                           Drawing 50000 posterior samples: 54943it [00:00, 152901.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18304/50000 [00:00<00:00, 154364.76it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36657/50000 [00:00<00:00, 153953.30it/s]Drawing 50000 posterior samples: 55044it [00:00, 153672.19it/s]                           Drawing 50000 posterior samples: 55044it [00:00, 153231.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18353/50000 [00:00<00:00, 155183.94it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36776/50000 [00:00<00:00, 155425.06it/s]Drawing 50000 posterior samples: 55092it [00:00, 154881.05it/s]                           Drawing 50000 posterior samples: 55092it [00:00, 154721.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18348/50000 [00:00<00:00, 146658.40it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36768/50000 [00:00<00:00, 146952.66it/s]Drawing 50000 posterior samples: 55105it [00:00, 146730.89it/s]                           Drawing 50000 posterior samples: 55105it [00:00, 146649.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18310/50000 [00:00<00:00, 145300.50it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36660/50000 [00:00<00:00, 145500.88it/s]Drawing 50000 posterior samples: 55027it [00:00, 146004.72it/s]                           Drawing 50000 posterior samples: 55027it [00:00, 145949.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18327/50000 [00:00<00:00, 147410.00it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36662/50000 [00:00<00:00, 138149.07it/s]Drawing 50000 posterior samples: 55039it [00:00, 131610.14it/s]                           Drawing 50000 posterior samples: 55039it [00:00, 127356.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18439/50000 [00:00<00:00, 130923.34it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36841/50000 [00:00<00:00, 131259.09it/s]Drawing 50000 posterior samples: 55176it [00:00, 131735.03it/s]                           Drawing 50000 posterior samples: 55176it [00:00, 131757.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18432/50000 [00:00<00:00, 149625.52it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36772/50000 [00:00<00:00, 149479.51it/s]Drawing 50000 posterior samples: 55106it [00:00, 149728.26it/s]                           Drawing 50000 posterior samples: 55106it [00:00, 149489.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18379/50000 [00:00<00:00, 149395.95it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36788/50000 [00:00<00:00, 149079.94it/s]Drawing 50000 posterior samples: 55181it [00:00, 149249.93it/s]                           Drawing 50000 posterior samples: 55181it [00:00, 148933.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18362/50000 [00:00<00:00, 148132.97it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36765/50000 [00:00<00:00, 148178.85it/s]Drawing 50000 posterior samples: 55229it [00:00, 148575.53it/s]                           Drawing 50000 posterior samples: 55229it [00:00, 148427.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18374/50000 [00:00<00:00, 148554.94it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36740/50000 [00:00<00:00, 148826.17it/s]Drawing 50000 posterior samples: 55138it [00:00, 148863.20it/s]                           Drawing 50000 posterior samples: 55138it [00:00, 148795.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18358/50000 [00:00<00:00, 147714.87it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36647/50000 [00:00<00:00, 147425.96it/s]Drawing 50000 posterior samples: 54996it [00:00, 147361.72it/s]                           Drawing 50000 posterior samples: 54996it [00:00, 147034.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18384/50000 [00:00<00:00, 145751.78it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36747/50000 [00:00<00:00, 145141.92it/s]Drawing 50000 posterior samples: 55092it [00:00, 145174.11it/s]                           Drawing 50000 posterior samples: 55092it [00:00, 144710.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18336/50000 [00:00<00:00, 145391.84it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36686/50000 [00:00<00:00, 145237.75it/s]Drawing 50000 posterior samples: 55049it [00:00, 144877.69it/s]                           Drawing 50000 posterior samples: 55049it [00:00, 144554.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18379/50000 [00:00<00:00, 145310.02it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36717/50000 [00:00<00:00, 145262.73it/s]Drawing 50000 posterior samples: 55035it [00:00, 145235.83it/s]                           Drawing 50000 posterior samples: 55035it [00:00, 144986.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18350/50000 [00:00<00:00, 145876.53it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36711/50000 [00:00<00:00, 145826.91it/s]Drawing 50000 posterior samples: 55116it [00:00, 145675.79it/s]                           Drawing 50000 posterior samples: 55116it [00:00, 145449.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
30
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Neural network successfully converged after 278 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Neural network successfully converged after 301 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Neural network successfully converged after 358 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Neural network successfully converged after 224 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Neural network successfully converged after 126 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Neural network successfully converged after 261 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Neural network successfully converged after 284 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Neural network successfully converged after 200 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Neural network successfully converged after 243 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Neural network successfully converged after 135 epochs.
log prob true 7.433692
log prob true 7.101277
log prob true 7.249572
log prob true 6.708023
log prob true 6.655765
log prob true 6.750798
log prob true 6.861409
log prob true 7.346216
log prob true 6.920866
log prob true 6.976018
log prob true 6.7874546
log prob true 7.2361045
log prob true 7.572289
log prob true 6.9715075
log prob true 6.517999
log prob true 6.598233
log prob true 6.740939
log prob true 7.025241
log prob true 6.80321
log prob true 7.35855
log prob true 7.2737956
log prob true 7.086892
log prob true 7.562076
log prob true 6.935027
log prob true 7.240061
log prob true 7.126357
log prob true 6.5495477
log prob true 6.8761578
log prob true 7.3834176
log prob true 6.3765306
log prob true 4.47763
log prob true 4.0165806
log prob true 4.255573
log prob true 3.2229035
log prob true 3.3656986
log prob true 3.2184436
log prob true 3.6422603
log prob true 4.0469704
log prob true 3.7772977
log prob true 3.8903036
log prob true 3.2437613
log prob true 4.173976
log prob true 4.44063
log prob true 4.154299
log prob true 3.273326
log prob true 3.0109346
log prob true 3.795008
log prob true 4.177094
log prob true 2.4987595
log prob true 4.187876
log prob true 4.0506577
log prob true 3.8650644
log prob true 4.421442
log prob true 3.9016073
log prob true 4.301827
log prob true 4.0344
log prob true 3.171875
log prob true 3.5359354
log prob true 4.42333
log prob true 2.1147158
log prob true 4.420683
log prob true 4.158526
log prob true 4.349821
log prob true 3.2197075
log prob true 3.2806242
log prob true 3.195474
log prob true 3.7504053
log prob true 4.314106
log prob true 3.877859
log prob true 3.844139
log prob true 3.2775235
log prob true 4.2280464
log prob true 4.5485926
log prob true 4.113346
log prob true 3.1636384
log prob true 3.2366652
log prob true 3.8534517
log prob true 4.211188
log prob true 2.8381608
log prob true 4.390581
log prob true 3.9600549
log prob true 3.9330099
log prob true 4.348902
log prob true 3.989305
log prob true 4.4054513
log prob true 4.165105
log prob true 3.3504612
log prob true 3.752151
log prob true 4.227255
log prob true 2.3399262
log prob true 7.214997
log prob true 6.6996436
log prob true 7.0291324
log prob true 6.696064
log prob true 6.257683
log prob true 6.68479
log prob true 6.545316
log prob true 7.042041
log prob true 6.690616
log prob true 6.8977437
log prob true 6.684924
log prob true 6.8160334
log prob true 7.3546643
log prob true 6.872714
log prob true 6.5119805
log prob true 6.302938
log prob true 6.5216117
log prob true 6.753585
log prob true 6.388875
log prob true 6.9110494
log prob true 7.1149464
log prob true 6.874601
log prob true 7.2180734
log prob true 6.454598
log prob true 7.1154284
log prob true 6.7325044
log prob true 5.839536
log prob true 6.5633965
log prob true 7.0760117
log prob true 6.5238833
log prob true 4.2034607
log prob true 3.635833
log prob true 4.01732
log prob true 2.7993152
log prob true 2.8082006
log prob true 2.7115612
log prob true 3.3975272
log prob true 4.072663
log prob true 3.5365767
log prob true 3.8449233
log prob true 3.1396978
log prob true 3.90192
log prob true 4.117557
log prob true 3.8453233
log prob true 3.1343513
log prob true 2.7143912
log prob true 3.4926271
log prob true 3.7957735
log prob true 2.6010566
log prob true 4.108649
log prob true 3.880188
log prob true 3.424222
log prob true 4.17301
log prob true 3.659007
log prob true 3.9501917
log prob true 3.888227
log prob true 2.9734015
log prob true 3.5482605
log prob true 4.0161724
log prob true 1.8173665
log prob true 7.343223
log prob true 6.857379
log prob true 6.932823
log prob true 6.8154063
log prob true 5.9491696
log prob true 6.665971
log prob true 6.5444956
log prob true 7.135183
log prob true 6.659452
log prob true 7.052574
log prob true 6.824629
log prob true 7.0275674
log prob true 7.546132
log prob true 6.9497066
log prob true 6.575045
log prob true 6.3774853
log prob true 6.625342
log prob true 6.7656703
log prob true 6.5830455
log prob true 7.103899
log prob true 7.1661644
log prob true 7.110817
log prob true 7.420688
log prob true 6.726877
log prob true 7.1322
log prob true 6.8303022
log prob true 6.3401074
log prob true 6.658109
log prob true 7.3655176
log prob true 6.4670897
log prob true 7.482587
log prob true 7.1027746
log prob true 7.334225
log prob true 7.116483
log prob true 6.339223
log prob true 6.806319
log prob true 6.825536
log prob true 7.297421
log prob true 6.966016
log prob true 7.0317364
log prob true 6.8384805
log prob true 7.210238
log prob true 7.6376767
log prob true 7.2121634
log prob true 6.8273664
log prob true 6.4772387
log prob true 6.860792
log prob true 7.107239
log prob true 6.810925
log prob true 7.1599193
log prob true 7.429757
log prob true 7.128922
log prob true 7.530004
log prob true 6.9487057
log prob true 7.3457665
log prob true 7.147342
log prob true 6.5466933
log prob true 6.8651614
log prob true 7.375656
log prob true 6.8559613
log prob true 7.4088283
log prob true 6.8847322
log prob true 7.0866156
log prob true 6.689029
log prob true 6.073507
log prob true 6.761577
log prob true 6.631651
log prob true 7.1938725
log prob true 6.6820326
log prob true 6.988
log prob true 6.678655
log prob true 7.082223
log prob true 7.3814664
log prob true 7.0587945
log prob true 6.4770117
log prob true 6.1985755
log prob true 6.5754457
log prob true 6.9080954
log prob true 6.5099826
log prob true 7.198486
log prob true 7.0937614
log prob true 6.8638406
log prob true 7.357873
log prob true 6.7589083
log prob true 7.212123
log prob true 6.9382477
log prob true 6.2422857
log prob true 6.7554154
log prob true 7.231173
log prob true 6.463064
log prob true 4.505471
log prob true 3.8440676
log prob true 4.2614803
log prob true 3.1213412
log prob true 3.7083848
log prob true 3.1264384
log prob true 3.6945992
log prob true 4.2836857
log prob true 3.884755
log prob true 3.5472772
log prob true 3.081015
log prob true 4.131486
log prob true 4.4998927
log prob true 4.113192
log prob true 3.393497
log prob true 3.097657
log prob true 3.8047836
log prob true 4.19551
log prob true 2.7116394
log prob true 4.3228893
log prob true 3.9373617
log prob true 3.8360732
log prob true 4.4412317
log prob true 3.8082457
log prob true 4.3272734
log prob true 4.115528
log prob true 3.102405
log prob true 3.6272502
log prob true 4.2093186
log prob true 2.2085104
log prob true 4.3949866
log prob true 3.9202216
log prob true 4.097398
log prob true 2.7753208
log prob true 3.2931614
log prob true 2.8367329
log prob true 3.628292
log prob true 4.1807046
log prob true 3.7222612
log prob true 3.746976
log prob true 2.9804182
log prob true 4.09677
log prob true 4.1007404
log prob true 4.0375547
log prob true 3.1388485
log prob true 2.9647164
log prob true 3.7300897
log prob true 4.0256853
log prob true 2.5908952
log prob true 4.2474546
log prob true 3.9073029
log prob true 3.5290487
log prob true 4.2789207
log prob true 3.7848432
log prob true 4.208562
log prob true 4.031056
log prob true 3.086665
log prob true 3.5865958
log prob true 4.064304
log prob true 2.2879972
script complete
