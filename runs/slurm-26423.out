Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 274.83it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<00:36, 274.68it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<00:36, 274.81it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<00:35, 274.98it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:35, 275.23it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:35, 275.67it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:00<00:35, 276.12it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:00<00:35, 276.29it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:00<00:35, 275.87it/s]Running 10000 simulations.:   3%|▎         | 280/10000 [00:01<00:35, 276.27it/s]Running 10000 simulations.:   3%|▎         | 308/10000 [00:01<00:35, 275.67it/s]Running 10000 simulations.:   3%|▎         | 336/10000 [00:01<00:35, 274.97it/s]Running 10000 simulations.:   4%|▎         | 364/10000 [00:01<00:35, 274.85it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:01<00:35, 274.41it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:34, 273.86it/s]Running 10000 simulations.:   4%|▍         | 448/10000 [00:01<00:34, 274.53it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:01<00:34, 274.64it/s]Running 10000 simulations.:   5%|▌         | 504/10000 [00:01<00:35, 269.24it/s]Running 10000 simulations.:   5%|▌         | 532/10000 [00:01<00:35, 269.95it/s]Running 10000 simulations.:   6%|▌         | 560/10000 [00:02<00:34, 270.37it/s]Running 10000 simulations.:   6%|▌         | 588/10000 [00:02<00:34, 270.59it/s]Running 10000 simulations.:   6%|▌         | 616/10000 [00:02<00:34, 270.78it/s]Running 10000 simulations.:   6%|▋         | 644/10000 [00:02<00:34, 270.76it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:02<00:34, 270.45it/s]Running 10000 simulations.:   7%|▋         | 700/10000 [00:02<00:34, 271.65it/s]Running 10000 simulations.:   7%|▋         | 728/10000 [00:02<00:34, 271.92it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:02<00:33, 272.02it/s]Running 10000 simulations.:   8%|▊         | 784/10000 [00:02<00:33, 272.76it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:02<00:33, 271.42it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:03<00:33, 272.14it/s]Running 10000 simulations.:   9%|▊         | 868/10000 [00:03<00:33, 270.53it/s]Running 10000 simulations.:   9%|▉         | 896/10000 [00:03<00:37, 240.73it/s]Running 10000 simulations.:   9%|▉         | 921/10000 [00:03<00:42, 211.91it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:03<00:46, 193.92it/s]Running 10000 simulations.:  10%|▉         | 965/10000 [00:03<00:49, 183.36it/s]Running 10000 simulations.:  10%|▉         | 985/10000 [00:03<00:50, 177.20it/s]Running 10000 simulations.:  10%|█         | 1004/10000 [00:03<00:52, 171.96it/s]Running 10000 simulations.:  10%|█         | 1022/10000 [00:04<00:53, 167.87it/s]Running 10000 simulations.:  10%|█         | 1040/10000 [00:04<00:53, 167.26it/s]Running 10000 simulations.:  11%|█         | 1057/10000 [00:04<00:53, 165.73it/s]Running 10000 simulations.:  11%|█         | 1075/10000 [00:04<00:53, 168.38it/s]Running 10000 simulations.:  11%|█         | 1092/10000 [00:04<00:53, 166.50it/s]Running 10000 simulations.:  11%|█         | 1109/10000 [00:04<00:53, 166.14it/s]Running 10000 simulations.:  11%|█▏        | 1126/10000 [00:04<00:53, 164.37it/s]Running 10000 simulations.:  11%|█▏        | 1143/10000 [00:04<00:54, 163.41it/s]Running 10000 simulations.:  12%|█▏        | 1160/10000 [00:04<00:54, 163.22it/s]Running 10000 simulations.:  12%|█▏        | 1177/10000 [00:05<00:55, 159.83it/s]Running 10000 simulations.:  12%|█▏        | 1194/10000 [00:05<00:55, 159.09it/s]Running 10000 simulations.:  12%|█▏        | 1211/10000 [00:05<00:54, 161.92it/s]Running 10000 simulations.:  12%|█▏        | 1228/10000 [00:05<00:54, 161.98it/s]Running 10000 simulations.:  12%|█▏        | 1245/10000 [00:05<00:54, 162.02it/s]Running 10000 simulations.:  13%|█▎        | 1262/10000 [00:05<00:53, 162.96it/s]Running 10000 simulations.:  13%|█▎        | 1280/10000 [00:05<00:52, 165.55it/s]Running 10000 simulations.:  13%|█▎        | 1297/10000 [00:05<00:53, 163.76it/s]Running 10000 simulations.:  13%|█▎        | 1314/10000 [00:05<00:53, 162.63it/s]Running 10000 simulations.:  13%|█▎        | 1331/10000 [00:05<00:53, 162.00it/s]Running 10000 simulations.:  13%|█▎        | 1348/10000 [00:06<00:53, 162.57it/s]Running 10000 simulations.:  14%|█▎        | 1365/10000 [00:06<00:53, 162.81it/s]Running 10000 simulations.:  14%|█▍        | 1382/10000 [00:06<00:52, 162.77it/s]Running 10000 simulations.:  14%|█▍        | 1399/10000 [00:06<00:52, 163.38it/s]Running 10000 simulations.:  14%|█▍        | 1417/10000 [00:06<00:51, 167.13it/s]Running 10000 simulations.:  14%|█▍        | 1434/10000 [00:06<00:51, 165.59it/s]Running 10000 simulations.:  15%|█▍        | 1451/10000 [00:06<00:52, 164.17it/s]Running 10000 simulations.:  15%|█▍        | 1468/10000 [00:06<00:52, 164.04it/s]Running 10000 simulations.:  15%|█▍        | 1485/10000 [00:06<00:52, 163.26it/s]Running 10000 simulations.:  15%|█▌        | 1502/10000 [00:07<00:52, 161.99it/s]Running 10000 simulations.:  15%|█▌        | 1519/10000 [00:07<00:52, 161.11it/s]Running 10000 simulations.:  15%|█▌        | 1536/10000 [00:07<00:52, 160.70it/s]Running 10000 simulations.:  16%|█▌        | 1553/10000 [00:07<00:52, 160.89it/s]Running 10000 simulations.:  16%|█▌        | 1570/10000 [00:07<00:52, 160.58it/s]Running 10000 simulations.:  16%|█▌        | 1587/10000 [00:07<00:52, 160.16it/s]Running 10000 simulations.:  16%|█▌        | 1604/10000 [00:07<00:52, 160.12it/s]Running 10000 simulations.:  16%|█▌        | 1621/10000 [00:07<00:52, 159.74it/s]Running 10000 simulations.:  16%|█▋        | 1638/10000 [00:07<00:52, 160.25it/s]Running 10000 simulations.:  17%|█▋        | 1655/10000 [00:07<00:52, 160.17it/s]Running 10000 simulations.:  17%|█▋        | 1672/10000 [00:08<00:52, 158.81it/s]Running 10000 simulations.:  17%|█▋        | 1688/10000 [00:08<00:52, 158.90it/s]Running 10000 simulations.:  17%|█▋        | 1704/10000 [00:08<00:52, 159.03it/s]Running 10000 simulations.:  17%|█▋        | 1720/10000 [00:08<00:52, 158.91it/s]Running 10000 simulations.:  17%|█▋        | 1736/10000 [00:08<00:51, 158.96it/s]Running 10000 simulations.:  18%|█▊        | 1753/10000 [00:08<00:51, 159.51it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:08<00:51, 159.37it/s]Running 10000 simulations.:  18%|█▊        | 1785/10000 [00:08<00:51, 159.15it/s]Running 10000 simulations.:  18%|█▊        | 1801/10000 [00:08<00:51, 159.22it/s]Running 10000 simulations.:  18%|█▊        | 1817/10000 [00:09<00:51, 159.14it/s]Running 10000 simulations.:  18%|█▊        | 1833/10000 [00:09<00:51, 157.65it/s]Running 10000 simulations.:  18%|█▊        | 1849/10000 [00:09<00:51, 157.74it/s]Running 10000 simulations.:  19%|█▊        | 1865/10000 [00:09<00:51, 157.55it/s]Running 10000 simulations.:  19%|█▉        | 1881/10000 [00:09<00:51, 157.80it/s]Running 10000 simulations.:  19%|█▉        | 1897/10000 [00:09<00:51, 157.93it/s]Running 10000 simulations.:  19%|█▉        | 1913/10000 [00:09<00:51, 157.95it/s]Running 10000 simulations.:  19%|█▉        | 1930/10000 [00:09<00:50, 159.02it/s]Running 10000 simulations.:  19%|█▉        | 1946/10000 [00:09<00:53, 150.62it/s]Running 10000 simulations.:  20%|█▉        | 1963/10000 [00:09<00:52, 153.76it/s]Running 10000 simulations.:  20%|█▉        | 1979/10000 [00:10<00:51, 154.98it/s]Running 10000 simulations.:  20%|█▉        | 1995/10000 [00:10<00:51, 155.94it/s]Running 10000 simulations.:  20%|██        | 2011/10000 [00:10<00:51, 156.52it/s]Running 10000 simulations.:  20%|██        | 2027/10000 [00:10<00:50, 157.09it/s]Running 10000 simulations.:  20%|██        | 2044/10000 [00:10<00:50, 158.22it/s]Running 10000 simulations.:  21%|██        | 2060/10000 [00:10<00:50, 158.34it/s]Running 10000 simulations.:  21%|██        | 2076/10000 [00:10<00:49, 158.71it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:10<00:49, 159.08it/s]Running 10000 simulations.:  21%|██        | 2108/10000 [00:10<00:49, 159.09it/s]Running 10000 simulations.:  21%|██        | 2124/10000 [00:10<00:49, 159.33it/s]Running 10000 simulations.:  21%|██▏       | 2141/10000 [00:11<00:49, 159.54it/s]Running 10000 simulations.:  22%|██▏       | 2157/10000 [00:11<00:49, 159.37it/s]Running 10000 simulations.:  22%|██▏       | 2173/10000 [00:11<00:49, 158.54it/s]Running 10000 simulations.:  22%|██▏       | 2189/10000 [00:11<00:49, 158.26it/s]Running 10000 simulations.:  22%|██▏       | 2205/10000 [00:11<00:49, 158.33it/s]Running 10000 simulations.:  22%|██▏       | 2221/10000 [00:11<00:49, 158.27it/s]Running 10000 simulations.:  22%|██▏       | 2237/10000 [00:11<00:49, 157.70it/s]Running 10000 simulations.:  23%|██▎       | 2253/10000 [00:11<00:49, 157.94it/s]Running 10000 simulations.:  23%|██▎       | 2269/10000 [00:11<00:48, 158.12it/s]Running 10000 simulations.:  23%|██▎       | 2285/10000 [00:11<00:48, 158.39it/s]Running 10000 simulations.:  23%|██▎       | 2301/10000 [00:12<00:48, 158.72it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:12<00:48, 157.94it/s]Running 10000 simulations.:  23%|██▎       | 2333/10000 [00:12<00:48, 158.14it/s]Running 10000 simulations.:  23%|██▎       | 2349/10000 [00:12<00:48, 158.12it/s]Running 10000 simulations.:  24%|██▎       | 2365/10000 [00:12<00:48, 157.75it/s]Running 10000 simulations.:  24%|██▍       | 2381/10000 [00:12<00:48, 158.24it/s]Running 10000 simulations.:  24%|██▍       | 2397/10000 [00:12<00:48, 158.16it/s]Running 10000 simulations.:  24%|██▍       | 2413/10000 [00:12<00:47, 158.16it/s]Running 10000 simulations.:  24%|██▍       | 2429/10000 [00:12<00:47, 158.17it/s]Running 10000 simulations.:  24%|██▍       | 2445/10000 [00:12<00:47, 157.93it/s]Running 10000 simulations.:  25%|██▍       | 2461/10000 [00:13<00:48, 156.70it/s]Running 10000 simulations.:  25%|██▍       | 2477/10000 [00:13<00:48, 155.42it/s]Running 10000 simulations.:  25%|██▍       | 2493/10000 [00:13<00:48, 154.14it/s]Running 10000 simulations.:  25%|██▌       | 2509/10000 [00:13<00:49, 152.77it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:13<00:48, 152.98it/s]Running 10000 simulations.:  25%|██▌       | 2541/10000 [00:13<00:48, 153.02it/s]Running 10000 simulations.:  26%|██▌       | 2557/10000 [00:13<00:48, 153.94it/s]Running 10000 simulations.:  26%|██▌       | 2573/10000 [00:13<00:48, 153.85it/s]Running 10000 simulations.:  26%|██▌       | 2589/10000 [00:13<00:48, 153.54it/s]Running 10000 simulations.:  26%|██▌       | 2605/10000 [00:14<00:48, 154.00it/s]Running 10000 simulations.:  26%|██▌       | 2621/10000 [00:14<00:47, 154.10it/s]Running 10000 simulations.:  26%|██▋       | 2637/10000 [00:14<00:47, 153.85it/s]Running 10000 simulations.:  27%|██▋       | 2653/10000 [00:14<00:47, 153.95it/s]Running 10000 simulations.:  27%|██▋       | 2669/10000 [00:14<00:47, 154.12it/s]Running 10000 simulations.:  27%|██▋       | 2685/10000 [00:14<00:47, 153.77it/s]Running 10000 simulations.:  27%|██▋       | 2701/10000 [00:14<00:47, 153.52it/s]Running 10000 simulations.:  27%|██▋       | 2717/10000 [00:14<00:47, 153.77it/s]Running 10000 simulations.:  27%|██▋       | 2733/10000 [00:14<00:47, 153.94it/s]Running 10000 simulations.:  27%|██▋       | 2749/10000 [00:14<00:47, 154.07it/s]Running 10000 simulations.:  28%|██▊       | 2765/10000 [00:15<00:46, 153.95it/s]Running 10000 simulations.:  28%|██▊       | 2781/10000 [00:15<00:46, 153.95it/s]Running 10000 simulations.:  28%|██▊       | 2797/10000 [00:15<00:47, 152.61it/s]Running 10000 simulations.:  28%|██▊       | 2813/10000 [00:15<00:47, 151.45it/s]Running 10000 simulations.:  28%|██▊       | 2829/10000 [00:15<00:47, 150.33it/s]Running 10000 simulations.:  28%|██▊       | 2845/10000 [00:15<00:47, 149.63it/s]Running 10000 simulations.:  29%|██▊       | 2860/10000 [00:15<00:47, 148.85it/s]Running 10000 simulations.:  29%|██▉       | 2875/10000 [00:15<00:47, 148.58it/s]Running 10000 simulations.:  29%|██▉       | 2890/10000 [00:15<00:47, 148.87it/s]Running 10000 simulations.:  29%|██▉       | 2905/10000 [00:16<00:47, 149.20it/s]Running 10000 simulations.:  29%|██▉       | 2920/10000 [00:16<00:47, 149.13it/s]Running 10000 simulations.:  29%|██▉       | 2935/10000 [00:16<00:47, 148.58it/s]Running 10000 simulations.:  30%|██▉       | 2950/10000 [00:16<00:47, 148.64it/s]Running 10000 simulations.:  30%|██▉       | 2965/10000 [00:16<00:47, 148.93it/s]Running 10000 simulations.:  30%|██▉       | 2980/10000 [00:16<00:47, 149.23it/s]Running 10000 simulations.:  30%|██▉       | 2996/10000 [00:16<00:46, 149.68it/s]Running 10000 simulations.:  30%|███       | 3011/10000 [00:16<00:46, 149.36it/s]Running 10000 simulations.:  30%|███       | 3026/10000 [00:16<00:46, 148.53it/s]Running 10000 simulations.:  30%|███       | 3041/10000 [00:16<00:46, 148.94it/s]Running 10000 simulations.:  31%|███       | 3056/10000 [00:17<00:46, 148.50it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:17<00:47, 146.27it/s]Running 10000 simulations.:  31%|███       | 3086/10000 [00:17<00:47, 146.04it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:17<00:47, 146.70it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:17<00:47, 146.11it/s]Running 10000 simulations.:  31%|███▏      | 3131/10000 [00:17<00:47, 145.29it/s]Running 10000 simulations.:  31%|███▏      | 3146/10000 [00:17<00:47, 144.53it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:17<00:47, 144.01it/s]Running 10000 simulations.:  32%|███▏      | 3176/10000 [00:17<00:46, 145.33it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:17<00:46, 146.41it/s]Running 10000 simulations.:  32%|███▏      | 3206/10000 [00:18<00:46, 147.19it/s]Running 10000 simulations.:  32%|███▏      | 3221/10000 [00:18<00:45, 147.46it/s]Running 10000 simulations.:  32%|███▏      | 3236/10000 [00:18<00:45, 147.79it/s]Running 10000 simulations.:  33%|███▎      | 3251/10000 [00:18<00:45, 147.87it/s]Running 10000 simulations.:  33%|███▎      | 3266/10000 [00:18<00:45, 147.92it/s]Running 10000 simulations.:  33%|███▎      | 3281/10000 [00:18<00:45, 148.01it/s]Running 10000 simulations.:  33%|███▎      | 3296/10000 [00:18<00:45, 148.44it/s]Running 10000 simulations.:  33%|███▎      | 3311/10000 [00:18<00:45, 148.44it/s]Running 10000 simulations.:  33%|███▎      | 3326/10000 [00:18<00:44, 148.80it/s]Running 10000 simulations.:  33%|███▎      | 3341/10000 [00:18<00:44, 148.93it/s]Running 10000 simulations.:  34%|███▎      | 3356/10000 [00:19<00:44, 149.17it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:19<00:44, 149.20it/s]Running 10000 simulations.:  34%|███▍      | 3387/10000 [00:19<00:44, 149.66it/s]Running 10000 simulations.:  34%|███▍      | 3402/10000 [00:19<00:44, 149.46it/s]Running 10000 simulations.:  34%|███▍      | 3417/10000 [00:19<00:44, 149.39it/s]Running 10000 simulations.:  34%|███▍      | 3432/10000 [00:19<00:44, 148.93it/s]Running 10000 simulations.:  34%|███▍      | 3447/10000 [00:19<00:44, 148.56it/s]Running 10000 simulations.:  35%|███▍      | 3462/10000 [00:19<00:44, 148.48it/s]Running 10000 simulations.:  35%|███▍      | 3477/10000 [00:19<00:43, 148.41it/s]Running 10000 simulations.:  35%|███▍      | 3492/10000 [00:19<00:43, 148.87it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:20<00:43, 148.63it/s]Running 10000 simulations.:  35%|███▌      | 3522/10000 [00:20<00:43, 148.64it/s]Running 10000 simulations.:  35%|███▌      | 3537/10000 [00:20<00:43, 148.72it/s]Running 10000 simulations.:  36%|███▌      | 3552/10000 [00:20<00:43, 148.28it/s]Running 10000 simulations.:  36%|███▌      | 3567/10000 [00:20<00:43, 148.13it/s]Running 10000 simulations.:  36%|███▌      | 3582/10000 [00:20<00:43, 148.27it/s]Running 10000 simulations.:  36%|███▌      | 3597/10000 [00:20<00:43, 148.42it/s]Running 10000 simulations.:  36%|███▌      | 3612/10000 [00:20<00:42, 148.69it/s]Running 10000 simulations.:  36%|███▋      | 3627/10000 [00:20<00:42, 148.80it/s]Running 10000 simulations.:  36%|███▋      | 3642/10000 [00:20<00:42, 148.99it/s]Running 10000 simulations.:  37%|███▋      | 3657/10000 [00:21<00:42, 149.05it/s]Running 10000 simulations.:  37%|███▋      | 3672/10000 [00:21<00:42, 148.56it/s]Running 10000 simulations.:  37%|███▋      | 3687/10000 [00:21<00:42, 147.94it/s]Running 10000 simulations.:  37%|███▋      | 3702/10000 [00:21<00:42, 147.62it/s]Running 10000 simulations.:  37%|███▋      | 3717/10000 [00:21<00:42, 147.08it/s]Running 10000 simulations.:  37%|███▋      | 3732/10000 [00:21<00:42, 147.06it/s]Running 10000 simulations.:  37%|███▋      | 3747/10000 [00:21<00:42, 147.04it/s]Running 10000 simulations.:  38%|███▊      | 3762/10000 [00:21<00:42, 146.74it/s]Running 10000 simulations.:  38%|███▊      | 3777/10000 [00:21<00:42, 146.89it/s]Running 10000 simulations.:  38%|███▊      | 3792/10000 [00:22<00:42, 146.55it/s]Running 10000 simulations.:  38%|███▊      | 3807/10000 [00:22<00:42, 146.66it/s]Running 10000 simulations.:  38%|███▊      | 3822/10000 [00:22<00:42, 146.56it/s]Running 10000 simulations.:  38%|███▊      | 3837/10000 [00:22<00:41, 147.07it/s]Running 10000 simulations.:  39%|███▊      | 3852/10000 [00:22<00:41, 147.32it/s]Running 10000 simulations.:  39%|███▊      | 3867/10000 [00:22<00:41, 146.83it/s]Running 10000 simulations.:  39%|███▉      | 3882/10000 [00:22<00:41, 146.27it/s]Running 10000 simulations.:  39%|███▉      | 3897/10000 [00:22<00:41, 146.31it/s]Running 10000 simulations.:  39%|███▉      | 3912/10000 [00:22<00:41, 146.75it/s]Running 10000 simulations.:  39%|███▉      | 3927/10000 [00:22<00:41, 147.13it/s]Running 10000 simulations.:  39%|███▉      | 3942/10000 [00:23<00:41, 146.91it/s]Running 10000 simulations.:  40%|███▉      | 3957/10000 [00:23<00:41, 146.84it/s]Running 10000 simulations.:  40%|███▉      | 3972/10000 [00:23<00:41, 146.91it/s]Running 10000 simulations.:  40%|███▉      | 3987/10000 [00:23<00:41, 146.27it/s]Running 10000 simulations.:  40%|████      | 4002/10000 [00:23<00:41, 146.28it/s]Running 10000 simulations.:  40%|████      | 4017/10000 [00:23<00:40, 146.46it/s]Running 10000 simulations.:  40%|████      | 4032/10000 [00:23<00:40, 146.57it/s]Running 10000 simulations.:  40%|████      | 4047/10000 [00:23<00:40, 146.32it/s]Running 10000 simulations.:  41%|████      | 4062/10000 [00:23<00:40, 145.97it/s]Running 10000 simulations.:  41%|████      | 4077/10000 [00:23<00:40, 146.01it/s]Running 10000 simulations.:  41%|████      | 4092/10000 [00:24<00:40, 146.51it/s]Running 10000 simulations.:  41%|████      | 4108/10000 [00:24<00:39, 149.09it/s]Running 10000 simulations.:  41%|████▏     | 4125/10000 [00:24<00:38, 152.68it/s]Running 10000 simulations.:  41%|████▏     | 4141/10000 [00:24<00:38, 151.28it/s]Running 10000 simulations.:  42%|████▏     | 4157/10000 [00:24<00:39, 148.54it/s]Running 10000 simulations.:  42%|████▏     | 4172/10000 [00:24<00:39, 146.25it/s]Running 10000 simulations.:  42%|████▏     | 4187/10000 [00:24<00:39, 145.75it/s]Running 10000 simulations.:  42%|████▏     | 4202/10000 [00:24<00:39, 146.10it/s]Running 10000 simulations.:  42%|████▏     | 4217/10000 [00:24<00:39, 146.27it/s]Running 10000 simulations.:  42%|████▏     | 4232/10000 [00:25<00:39, 146.02it/s]Running 10000 simulations.:  42%|████▏     | 4247/10000 [00:25<00:39, 146.52it/s]Running 10000 simulations.:  43%|████▎     | 4262/10000 [00:25<00:39, 146.97it/s]Running 10000 simulations.:  43%|████▎     | 4277/10000 [00:25<00:39, 146.67it/s]Running 10000 simulations.:  43%|████▎     | 4292/10000 [00:25<00:38, 146.93it/s]Running 10000 simulations.:  43%|████▎     | 4307/10000 [00:25<00:38, 146.97it/s]Running 10000 simulations.:  43%|████▎     | 4322/10000 [00:25<00:38, 146.94it/s]Running 10000 simulations.:  43%|████▎     | 4337/10000 [00:25<00:38, 147.41it/s]Running 10000 simulations.:  44%|████▎     | 4352/10000 [00:25<00:38, 147.27it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:25<00:38, 146.90it/s]Running 10000 simulations.:  44%|████▍     | 4382/10000 [00:26<00:38, 147.20it/s]Running 10000 simulations.:  44%|████▍     | 4397/10000 [00:26<00:38, 147.06it/s]Running 10000 simulations.:  44%|████▍     | 4412/10000 [00:26<00:38, 146.99it/s]Running 10000 simulations.:  44%|████▍     | 4427/10000 [00:26<00:37, 146.83it/s]Running 10000 simulations.:  44%|████▍     | 4442/10000 [00:26<00:37, 146.79it/s]Running 10000 simulations.:  45%|████▍     | 4457/10000 [00:26<00:37, 146.44it/s]Running 10000 simulations.:  45%|████▍     | 4472/10000 [00:26<00:37, 147.07it/s]Running 10000 simulations.:  45%|████▍     | 4487/10000 [00:26<00:37, 147.22it/s]Running 10000 simulations.:  45%|████▌     | 4502/10000 [00:26<00:37, 147.15it/s]Running 10000 simulations.:  45%|████▌     | 4517/10000 [00:26<00:37, 147.34it/s]Running 10000 simulations.:  45%|████▌     | 4532/10000 [00:27<00:37, 147.23it/s]Running 10000 simulations.:  45%|████▌     | 4547/10000 [00:27<00:37, 147.02it/s]Running 10000 simulations.:  46%|████▌     | 4562/10000 [00:27<00:38, 139.59it/s]Running 10000 simulations.:  46%|████▌     | 4577/10000 [00:27<00:38, 141.52it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:27<00:37, 142.93it/s]Running 10000 simulations.:  46%|████▌     | 4607/10000 [00:27<00:37, 143.83it/s]Running 10000 simulations.:  46%|████▌     | 4622/10000 [00:27<00:37, 144.66it/s]Running 10000 simulations.:  46%|████▋     | 4637/10000 [00:27<00:36, 145.61it/s]Running 10000 simulations.:  47%|████▋     | 4652/10000 [00:27<00:36, 145.73it/s]Running 10000 simulations.:  47%|████▋     | 4667/10000 [00:27<00:36, 145.82it/s]Running 10000 simulations.:  47%|████▋     | 4682/10000 [00:28<00:36, 145.64it/s]Running 10000 simulations.:  47%|████▋     | 4697/10000 [00:28<00:36, 145.15it/s]Running 10000 simulations.:  47%|████▋     | 4712/10000 [00:28<00:36, 145.43it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:28<00:36, 145.19it/s]Running 10000 simulations.:  47%|████▋     | 4742/10000 [00:28<00:36, 145.20it/s]Running 10000 simulations.:  48%|████▊     | 4757/10000 [00:28<00:36, 145.48it/s]Running 10000 simulations.:  48%|████▊     | 4772/10000 [00:28<00:35, 145.39it/s]Running 10000 simulations.:  48%|████▊     | 4787/10000 [00:28<00:35, 144.98it/s]Running 10000 simulations.:  48%|████▊     | 4802/10000 [00:28<00:35, 145.34it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:29<00:35, 145.19it/s]Running 10000 simulations.:  48%|████▊     | 4832/10000 [00:29<00:35, 145.09it/s]Running 10000 simulations.:  48%|████▊     | 4847/10000 [00:29<00:35, 145.51it/s]Running 10000 simulations.:  49%|████▊     | 4862/10000 [00:29<00:35, 145.66it/s]Running 10000 simulations.:  49%|████▉     | 4877/10000 [00:29<00:35, 145.56it/s]Running 10000 simulations.:  49%|████▉     | 4892/10000 [00:29<00:35, 145.29it/s]Running 10000 simulations.:  49%|████▉     | 4907/10000 [00:29<00:35, 144.83it/s]Running 10000 simulations.:  49%|████▉     | 4922/10000 [00:29<00:35, 144.79it/s]Running 10000 simulations.:  49%|████▉     | 4937/10000 [00:29<00:34, 144.68it/s]Running 10000 simulations.:  50%|████▉     | 4952/10000 [00:29<00:34, 144.72it/s]Running 10000 simulations.:  50%|████▉     | 4967/10000 [00:30<00:34, 144.58it/s]Running 10000 simulations.:  50%|████▉     | 4982/10000 [00:30<00:34, 144.71it/s]Running 10000 simulations.:  50%|████▉     | 4997/10000 [00:30<00:34, 144.26it/s]Running 10000 simulations.:  50%|█████     | 5012/10000 [00:30<00:34, 143.74it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:30<00:34, 143.60it/s]Running 10000 simulations.:  50%|█████     | 5042/10000 [00:30<00:34, 143.92it/s]Running 10000 simulations.:  51%|█████     | 5057/10000 [00:30<00:34, 145.17it/s]Running 10000 simulations.:  51%|█████     | 5072/10000 [00:30<00:33, 145.56it/s]Running 10000 simulations.:  51%|█████     | 5087/10000 [00:30<00:33, 145.98it/s]Running 10000 simulations.:  51%|█████     | 5102/10000 [00:30<00:33, 146.26it/s]Running 10000 simulations.:  51%|█████     | 5117/10000 [00:31<00:33, 146.28it/s]Running 10000 simulations.:  51%|█████▏    | 5132/10000 [00:31<00:33, 146.60it/s]Running 10000 simulations.:  51%|█████▏    | 5147/10000 [00:31<00:32, 147.18it/s]Running 10000 simulations.:  52%|█████▏    | 5162/10000 [00:31<00:32, 147.18it/s]Running 10000 simulations.:  52%|█████▏    | 5177/10000 [00:31<00:32, 146.90it/s]Running 10000 simulations.:  52%|█████▏    | 5192/10000 [00:31<00:32, 146.56it/s]Running 10000 simulations.:  52%|█████▏    | 5207/10000 [00:31<00:32, 146.54it/s]Running 10000 simulations.:  52%|█████▏    | 5222/10000 [00:31<00:32, 146.24it/s]Running 10000 simulations.:  52%|█████▏    | 5237/10000 [00:31<00:32, 146.29it/s]Running 10000 simulations.:  53%|█████▎    | 5252/10000 [00:32<00:32, 146.25it/s]Running 10000 simulations.:  53%|█████▎    | 5267/10000 [00:32<00:32, 146.25it/s]Running 10000 simulations.:  53%|█████▎    | 5282/10000 [00:32<00:32, 146.22it/s]Running 10000 simulations.:  53%|█████▎    | 5297/10000 [00:32<00:32, 146.06it/s]Running 10000 simulations.:  53%|█████▎    | 5312/10000 [00:32<00:32, 145.75it/s]Running 10000 simulations.:  53%|█████▎    | 5327/10000 [00:32<00:32, 145.69it/s]Running 10000 simulations.:  53%|█████▎    | 5342/10000 [00:32<00:32, 145.44it/s]Running 10000 simulations.:  54%|█████▎    | 5357/10000 [00:32<00:31, 145.50it/s]Running 10000 simulations.:  54%|█████▎    | 5372/10000 [00:32<00:31, 145.66it/s]Running 10000 simulations.:  54%|█████▍    | 5387/10000 [00:32<00:31, 145.74it/s]Running 10000 simulations.:  54%|█████▍    | 5402/10000 [00:33<00:31, 145.70it/s]Running 10000 simulations.:  54%|█████▍    | 5417/10000 [00:33<00:31, 145.19it/s]Running 10000 simulations.:  54%|█████▍    | 5432/10000 [00:33<00:31, 146.08it/s]Running 10000 simulations.:  54%|█████▍    | 5447/10000 [00:33<00:31, 143.05it/s]Running 10000 simulations.:  55%|█████▍    | 5462/10000 [00:33<00:31, 143.57it/s]Running 10000 simulations.:  55%|█████▍    | 5477/10000 [00:33<00:31, 144.20it/s]Running 10000 simulations.:  55%|█████▍    | 5492/10000 [00:33<00:31, 144.48it/s]Running 10000 simulations.:  55%|█████▌    | 5507/10000 [00:33<00:30, 144.98it/s]Running 10000 simulations.:  55%|█████▌    | 5522/10000 [00:33<00:30, 145.30it/s]Running 10000 simulations.:  55%|█████▌    | 5537/10000 [00:33<00:30, 145.65it/s]Running 10000 simulations.:  56%|█████▌    | 5552/10000 [00:34<00:30, 145.86it/s]Running 10000 simulations.:  56%|█████▌    | 5567/10000 [00:34<00:30, 146.13it/s]Running 10000 simulations.:  56%|█████▌    | 5582/10000 [00:34<00:30, 146.34it/s]Running 10000 simulations.:  56%|█████▌    | 5597/10000 [00:34<00:30, 145.32it/s]Running 10000 simulations.:  56%|█████▌    | 5612/10000 [00:34<00:30, 144.60it/s]Running 10000 simulations.:  56%|█████▋    | 5627/10000 [00:34<00:30, 144.67it/s]Running 10000 simulations.:  56%|█████▋    | 5642/10000 [00:34<00:30, 144.03it/s]Running 10000 simulations.:  57%|█████▋    | 5657/10000 [00:34<00:30, 144.52it/s]Running 10000 simulations.:  57%|█████▋    | 5672/10000 [00:34<00:29, 144.62it/s]Running 10000 simulations.:  57%|█████▋    | 5687/10000 [00:35<00:29, 144.25it/s]Running 10000 simulations.:  57%|█████▋    | 5702/10000 [00:35<00:29, 143.60it/s]Running 10000 simulations.:  57%|█████▋    | 5717/10000 [00:35<00:29, 142.86it/s]Running 10000 simulations.:  57%|█████▋    | 5732/10000 [00:35<00:29, 143.49it/s]Running 10000 simulations.:  57%|█████▋    | 5747/10000 [00:35<00:29, 143.75it/s]Running 10000 simulations.:  58%|█████▊    | 5762/10000 [00:35<00:29, 143.72it/s]Running 10000 simulations.:  58%|█████▊    | 5777/10000 [00:35<00:29, 144.36it/s]Running 10000 simulations.:  58%|█████▊    | 5792/10000 [00:35<00:29, 144.57it/s]Running 10000 simulations.:  58%|█████▊    | 5807/10000 [00:35<00:28, 144.70it/s]Running 10000 simulations.:  58%|█████▊    | 5822/10000 [00:35<00:28, 144.38it/s]Running 10000 simulations.:  58%|█████▊    | 5837/10000 [00:36<00:28, 144.65it/s]Running 10000 simulations.:  59%|█████▊    | 5852/10000 [00:36<00:28, 144.78it/s]Running 10000 simulations.:  59%|█████▊    | 5867/10000 [00:36<00:28, 145.41it/s]Running 10000 simulations.:  59%|█████▉    | 5882/10000 [00:36<00:28, 145.06it/s]Running 10000 simulations.:  59%|█████▉    | 5897/10000 [00:36<00:28, 145.23it/s]Running 10000 simulations.:  59%|█████▉    | 5912/10000 [00:36<00:28, 145.43it/s]Running 10000 simulations.:  59%|█████▉    | 5927/10000 [00:36<00:28, 145.08it/s]Running 10000 simulations.:  59%|█████▉    | 5942/10000 [00:36<00:27, 145.07it/s]Running 10000 simulations.:  60%|█████▉    | 5957/10000 [00:36<00:27, 145.31it/s]Running 10000 simulations.:  60%|█████▉    | 5972/10000 [00:36<00:27, 144.88it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:37<00:27, 144.28it/s]Running 10000 simulations.:  60%|██████    | 6002/10000 [00:37<00:27, 144.36it/s]Running 10000 simulations.:  60%|██████    | 6017/10000 [00:37<00:27, 144.72it/s]Running 10000 simulations.:  60%|██████    | 6032/10000 [00:37<00:27, 144.94it/s]Running 10000 simulations.:  60%|██████    | 6047/10000 [00:37<00:27, 145.08it/s]Running 10000 simulations.:  61%|██████    | 6062/10000 [00:37<00:27, 145.21it/s]Running 10000 simulations.:  61%|██████    | 6077/10000 [00:37<00:27, 145.24it/s]Running 10000 simulations.:  61%|██████    | 6092/10000 [00:37<00:26, 145.22it/s]Running 10000 simulations.:  61%|██████    | 6107/10000 [00:37<00:26, 145.31it/s]Running 10000 simulations.:  61%|██████    | 6122/10000 [00:38<00:26, 144.99it/s]Running 10000 simulations.:  61%|██████▏   | 6137/10000 [00:38<00:26, 144.58it/s]Running 10000 simulations.:  62%|██████▏   | 6152/10000 [00:38<00:26, 144.06it/s]Running 10000 simulations.:  62%|██████▏   | 6167/10000 [00:38<00:26, 144.12it/s]Running 10000 simulations.:  62%|██████▏   | 6182/10000 [00:38<00:26, 144.12it/s]Running 10000 simulations.:  62%|██████▏   | 6197/10000 [00:38<00:26, 144.58it/s]Running 10000 simulations.:  62%|██████▏   | 6212/10000 [00:38<00:26, 145.01it/s]Running 10000 simulations.:  62%|██████▏   | 6227/10000 [00:38<00:26, 144.90it/s]Running 10000 simulations.:  62%|██████▏   | 6242/10000 [00:38<00:25, 144.74it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:38<00:25, 145.02it/s]Running 10000 simulations.:  63%|██████▎   | 6272/10000 [00:39<00:25, 145.34it/s]Running 10000 simulations.:  63%|██████▎   | 6287/10000 [00:39<00:25, 145.27it/s]Running 10000 simulations.:  63%|██████▎   | 6302/10000 [00:39<00:25, 145.57it/s]Running 10000 simulations.:  63%|██████▎   | 6317/10000 [00:39<00:25, 145.53it/s]Running 10000 simulations.:  63%|██████▎   | 6332/10000 [00:39<00:25, 145.39it/s]Running 10000 simulations.:  63%|██████▎   | 6347/10000 [00:39<00:25, 145.24it/s]Running 10000 simulations.:  64%|██████▎   | 6362/10000 [00:39<00:25, 145.13it/s]Running 10000 simulations.:  64%|██████▍   | 6377/10000 [00:39<00:24, 145.34it/s]Running 10000 simulations.:  64%|██████▍   | 6392/10000 [00:39<00:24, 145.41it/s]Running 10000 simulations.:  64%|██████▍   | 6407/10000 [00:39<00:24, 145.16it/s]Running 10000 simulations.:  64%|██████▍   | 6422/10000 [00:40<00:24, 145.09it/s]Running 10000 simulations.:  64%|██████▍   | 6437/10000 [00:40<00:25, 142.31it/s]Running 10000 simulations.:  65%|██████▍   | 6452/10000 [00:40<00:25, 138.36it/s]Running 10000 simulations.:  65%|██████▍   | 6466/10000 [00:40<00:26, 135.64it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:40<00:26, 133.67it/s]Running 10000 simulations.:  65%|██████▍   | 6494/10000 [00:40<00:26, 132.50it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:40<00:26, 131.94it/s]Running 10000 simulations.:  65%|██████▌   | 6522/10000 [00:40<00:26, 131.37it/s]Running 10000 simulations.:  65%|██████▌   | 6536/10000 [00:40<00:26, 130.78it/s]Running 10000 simulations.:  66%|██████▌   | 6550/10000 [00:41<00:26, 131.01it/s]Running 10000 simulations.:  66%|██████▌   | 6564/10000 [00:41<00:26, 130.78it/s]Running 10000 simulations.:  66%|██████▌   | 6578/10000 [00:41<00:26, 131.33it/s]Running 10000 simulations.:  66%|██████▌   | 6592/10000 [00:41<00:25, 131.41it/s]Running 10000 simulations.:  66%|██████▌   | 6606/10000 [00:41<00:25, 131.03it/s]Running 10000 simulations.:  66%|██████▌   | 6620/10000 [00:41<00:25, 130.87it/s]Running 10000 simulations.:  66%|██████▋   | 6634/10000 [00:41<00:25, 130.85it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:41<00:25, 131.16it/s]Running 10000 simulations.:  67%|██████▋   | 6662/10000 [00:41<00:25, 131.28it/s]Running 10000 simulations.:  67%|██████▋   | 6676/10000 [00:42<00:25, 130.93it/s]Running 10000 simulations.:  67%|██████▋   | 6690/10000 [00:42<00:25, 131.60it/s]Running 10000 simulations.:  67%|██████▋   | 6704/10000 [00:42<00:24, 132.01it/s]Running 10000 simulations.:  67%|██████▋   | 6718/10000 [00:42<00:24, 131.70it/s]Running 10000 simulations.:  67%|██████▋   | 6732/10000 [00:42<00:24, 131.33it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:42<00:24, 131.39it/s]Running 10000 simulations.:  68%|██████▊   | 6760/10000 [00:42<00:24, 131.56it/s]Running 10000 simulations.:  68%|██████▊   | 6774/10000 [00:42<00:24, 130.63it/s]Running 10000 simulations.:  68%|██████▊   | 6788/10000 [00:42<00:24, 130.65it/s]Running 10000 simulations.:  68%|██████▊   | 6802/10000 [00:42<00:24, 131.00it/s]Running 10000 simulations.:  68%|██████▊   | 6816/10000 [00:43<00:24, 130.75it/s]Running 10000 simulations.:  68%|██████▊   | 6830/10000 [00:43<00:24, 130.43it/s]Running 10000 simulations.:  68%|██████▊   | 6844/10000 [00:43<00:24, 131.46it/s]Running 10000 simulations.:  69%|██████▊   | 6859/10000 [00:43<00:23, 134.35it/s]Running 10000 simulations.:  69%|██████▊   | 6874/10000 [00:43<00:22, 136.81it/s]Running 10000 simulations.:  69%|██████▉   | 6889/10000 [00:43<00:22, 138.27it/s]Running 10000 simulations.:  69%|██████▉   | 6904/10000 [00:43<00:22, 139.56it/s]Running 10000 simulations.:  69%|██████▉   | 6919/10000 [00:43<00:21, 140.54it/s]Running 10000 simulations.:  69%|██████▉   | 6934/10000 [00:43<00:21, 141.07it/s]Running 10000 simulations.:  69%|██████▉   | 6949/10000 [00:44<00:21, 141.14it/s]Running 10000 simulations.:  70%|██████▉   | 6964/10000 [00:44<00:21, 141.39it/s]Running 10000 simulations.:  70%|██████▉   | 6979/10000 [00:44<00:21, 141.76it/s]Running 10000 simulations.:  70%|██████▉   | 6994/10000 [00:44<00:21, 141.78it/s]Running 10000 simulations.:  70%|███████   | 7009/10000 [00:44<00:21, 141.79it/s]Running 10000 simulations.:  70%|███████   | 7024/10000 [00:44<00:20, 142.26it/s]Running 10000 simulations.:  70%|███████   | 7039/10000 [00:44<00:20, 142.54it/s]Running 10000 simulations.:  71%|███████   | 7054/10000 [00:44<00:20, 141.59it/s]Running 10000 simulations.:  71%|███████   | 7069/10000 [00:44<00:20, 141.53it/s]Running 10000 simulations.:  71%|███████   | 7084/10000 [00:44<00:20, 141.78it/s]Running 10000 simulations.:  71%|███████   | 7099/10000 [00:45<00:20, 141.85it/s]Running 10000 simulations.:  71%|███████   | 7114/10000 [00:45<00:20, 141.93it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:45<00:20, 142.11it/s]Running 10000 simulations.:  71%|███████▏  | 7144/10000 [00:45<00:20, 142.54it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:45<00:19, 142.51it/s]Running 10000 simulations.:  72%|███████▏  | 7174/10000 [00:45<00:19, 142.42it/s]Running 10000 simulations.:  72%|███████▏  | 7189/10000 [00:45<00:19, 142.71it/s]Running 10000 simulations.:  72%|███████▏  | 7204/10000 [00:45<00:19, 142.94it/s]Running 10000 simulations.:  72%|███████▏  | 7219/10000 [00:45<00:19, 143.03it/s]Running 10000 simulations.:  72%|███████▏  | 7234/10000 [00:46<00:19, 142.93it/s]Running 10000 simulations.:  72%|███████▏  | 7249/10000 [00:46<00:19, 142.65it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:46<00:19, 142.14it/s]Running 10000 simulations.:  73%|███████▎  | 7279/10000 [00:46<00:19, 141.86it/s]Running 10000 simulations.:  73%|███████▎  | 7294/10000 [00:46<00:18, 142.47it/s]Running 10000 simulations.:  73%|███████▎  | 7309/10000 [00:46<00:18, 142.44it/s]Running 10000 simulations.:  73%|███████▎  | 7324/10000 [00:46<00:18, 141.91it/s]Running 10000 simulations.:  73%|███████▎  | 7339/10000 [00:46<00:18, 141.70it/s]Running 10000 simulations.:  74%|███████▎  | 7354/10000 [00:46<00:18, 139.27it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:47<00:18, 140.41it/s]Running 10000 simulations.:  74%|███████▍  | 7384/10000 [00:47<00:18, 141.34it/s]Running 10000 simulations.:  74%|███████▍  | 7399/10000 [00:47<00:18, 141.80it/s]Running 10000 simulations.:  74%|███████▍  | 7414/10000 [00:47<00:18, 141.73it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:47<00:18, 142.02it/s]Running 10000 simulations.:  74%|███████▍  | 7444/10000 [00:47<00:17, 142.48it/s]Running 10000 simulations.:  75%|███████▍  | 7459/10000 [00:47<00:17, 142.30it/s]Running 10000 simulations.:  75%|███████▍  | 7474/10000 [00:47<00:17, 141.64it/s]Running 10000 simulations.:  75%|███████▍  | 7489/10000 [00:47<00:17, 141.36it/s]Running 10000 simulations.:  75%|███████▌  | 7504/10000 [00:47<00:17, 140.56it/s]Running 10000 simulations.:  75%|███████▌  | 7519/10000 [00:48<00:17, 140.05it/s]Running 10000 simulations.:  75%|███████▌  | 7534/10000 [00:48<00:17, 140.46it/s]Running 10000 simulations.:  75%|███████▌  | 7549/10000 [00:48<00:17, 140.43it/s]Running 10000 simulations.:  76%|███████▌  | 7564/10000 [00:48<00:17, 138.75it/s]Running 10000 simulations.:  76%|███████▌  | 7578/10000 [00:48<00:17, 137.35it/s]Running 10000 simulations.:  76%|███████▌  | 7592/10000 [00:48<00:17, 137.21it/s]Running 10000 simulations.:  76%|███████▌  | 7606/10000 [00:48<00:17, 137.31it/s]Running 10000 simulations.:  76%|███████▌  | 7620/10000 [00:48<00:17, 137.09it/s]Running 10000 simulations.:  76%|███████▋  | 7634/10000 [00:48<00:17, 136.83it/s]Running 10000 simulations.:  76%|███████▋  | 7648/10000 [00:49<00:17, 137.62it/s]Running 10000 simulations.:  77%|███████▋  | 7662/10000 [00:49<00:16, 138.08it/s]Running 10000 simulations.:  77%|███████▋  | 7676/10000 [00:49<00:16, 137.67it/s]Running 10000 simulations.:  77%|███████▋  | 7690/10000 [00:49<00:16, 136.33it/s]Running 10000 simulations.:  77%|███████▋  | 7704/10000 [00:49<00:16, 135.18it/s]Running 10000 simulations.:  77%|███████▋  | 7719/10000 [00:49<00:16, 137.12it/s]Running 10000 simulations.:  77%|███████▋  | 7734/10000 [00:49<00:16, 138.51it/s]Running 10000 simulations.:  77%|███████▋  | 7749/10000 [00:49<00:16, 139.76it/s]Running 10000 simulations.:  78%|███████▊  | 7763/10000 [00:49<00:16, 138.25it/s]Running 10000 simulations.:  78%|███████▊  | 7777/10000 [00:49<00:16, 138.74it/s]Running 10000 simulations.:  78%|███████▊  | 7791/10000 [00:50<00:15, 138.93it/s]Running 10000 simulations.:  78%|███████▊  | 7806/10000 [00:50<00:15, 139.78it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:50<00:15, 140.09it/s]Running 10000 simulations.:  78%|███████▊  | 7836/10000 [00:50<00:15, 139.99it/s]Running 10000 simulations.:  79%|███████▊  | 7851/10000 [00:50<00:15, 140.35it/s]Running 10000 simulations.:  79%|███████▊  | 7866/10000 [00:50<00:15, 139.58it/s]Running 10000 simulations.:  79%|███████▉  | 7880/10000 [00:50<00:15, 138.56it/s]Running 10000 simulations.:  79%|███████▉  | 7894/10000 [00:50<00:15, 137.15it/s]Running 10000 simulations.:  79%|███████▉  | 7908/10000 [00:50<00:15, 132.12it/s]Running 10000 simulations.:  79%|███████▉  | 7922/10000 [00:51<00:16, 128.70it/s]Running 10000 simulations.:  79%|███████▉  | 7935/10000 [00:51<00:16, 126.61it/s]Running 10000 simulations.:  79%|███████▉  | 7948/10000 [00:51<00:16, 126.20it/s]Running 10000 simulations.:  80%|███████▉  | 7962/10000 [00:51<00:15, 129.33it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:51<00:15, 130.87it/s]Running 10000 simulations.:  80%|███████▉  | 7990/10000 [00:51<00:15, 132.59it/s]Running 10000 simulations.:  80%|████████  | 8004/10000 [00:51<00:14, 133.40it/s]Running 10000 simulations.:  80%|████████  | 8018/10000 [00:51<00:14, 134.83it/s]Running 10000 simulations.:  80%|████████  | 8032/10000 [00:51<00:14, 135.85it/s]Running 10000 simulations.:  80%|████████  | 8046/10000 [00:52<00:25, 77.47it/s] Running 10000 simulations.:  81%|████████  | 8060/10000 [00:52<00:21, 89.33it/s]Running 10000 simulations.:  81%|████████  | 8074/10000 [00:52<00:19, 99.64it/s]Running 10000 simulations.:  81%|████████  | 8088/10000 [00:52<00:17, 108.60it/s]Running 10000 simulations.:  81%|████████  | 8102/10000 [00:52<00:16, 115.75it/s]Running 10000 simulations.:  81%|████████  | 8116/10000 [00:52<00:15, 121.36it/s]Running 10000 simulations.:  81%|████████▏ | 8130/10000 [00:52<00:14, 125.58it/s]Running 10000 simulations.:  81%|████████▏ | 8144/10000 [00:52<00:14, 128.49it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:53<00:14, 130.84it/s]Running 10000 simulations.:  82%|████████▏ | 8172/10000 [00:53<00:13, 132.70it/s]Running 10000 simulations.:  82%|████████▏ | 8186/10000 [00:53<00:13, 133.86it/s]Running 10000 simulations.:  82%|████████▏ | 8200/10000 [00:53<00:13, 134.17it/s]Running 10000 simulations.:  82%|████████▏ | 8214/10000 [00:53<00:13, 133.69it/s]Running 10000 simulations.:  82%|████████▏ | 8228/10000 [00:53<00:13, 133.96it/s]Running 10000 simulations.:  82%|████████▏ | 8242/10000 [00:53<00:13, 133.88it/s]Running 10000 simulations.:  83%|████████▎ | 8256/10000 [00:53<00:13, 134.14it/s]Running 10000 simulations.:  83%|████████▎ | 8270/10000 [00:53<00:12, 134.33it/s]Running 10000 simulations.:  83%|████████▎ | 8284/10000 [00:53<00:12, 134.10it/s]Running 10000 simulations.:  83%|████████▎ | 8298/10000 [00:54<00:12, 134.14it/s]Running 10000 simulations.:  83%|████████▎ | 8312/10000 [00:54<00:12, 133.75it/s]Running 10000 simulations.:  83%|████████▎ | 8326/10000 [00:54<00:12, 133.14it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:54<00:12, 133.29it/s]Running 10000 simulations.:  84%|████████▎ | 8354/10000 [00:54<00:12, 133.98it/s]Running 10000 simulations.:  84%|████████▎ | 8368/10000 [00:54<00:12, 134.00it/s]Running 10000 simulations.:  84%|████████▍ | 8382/10000 [00:54<00:12, 133.70it/s]Running 10000 simulations.:  84%|████████▍ | 8396/10000 [00:54<00:11, 133.78it/s]Running 10000 simulations.:  84%|████████▍ | 8410/10000 [00:54<00:11, 132.51it/s]Running 10000 simulations.:  84%|████████▍ | 8424/10000 [00:55<00:11, 133.03it/s]Running 10000 simulations.:  84%|████████▍ | 8438/10000 [00:55<00:11, 133.39it/s]Running 10000 simulations.:  85%|████████▍ | 8452/10000 [00:55<00:11, 134.19it/s]Running 10000 simulations.:  85%|████████▍ | 8466/10000 [00:55<00:11, 134.27it/s]Running 10000 simulations.:  85%|████████▍ | 8480/10000 [00:55<00:11, 134.17it/s]Running 10000 simulations.:  85%|████████▍ | 8494/10000 [00:55<00:11, 133.83it/s]Running 10000 simulations.:  85%|████████▌ | 8508/10000 [00:55<00:11, 133.70it/s]Running 10000 simulations.:  85%|████████▌ | 8522/10000 [00:55<00:11, 133.14it/s]Running 10000 simulations.:  85%|████████▌ | 8536/10000 [00:55<00:11, 133.03it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:55<00:10, 132.04it/s]Running 10000 simulations.:  86%|████████▌ | 8564/10000 [00:56<00:10, 131.93it/s]Running 10000 simulations.:  86%|████████▌ | 8578/10000 [00:56<00:10, 132.62it/s]Running 10000 simulations.:  86%|████████▌ | 8592/10000 [00:56<00:10, 132.44it/s]Running 10000 simulations.:  86%|████████▌ | 8606/10000 [00:56<00:10, 132.71it/s]Running 10000 simulations.:  86%|████████▌ | 8620/10000 [00:56<00:10, 133.25it/s]Running 10000 simulations.:  86%|████████▋ | 8634/10000 [00:56<00:10, 133.88it/s]Running 10000 simulations.:  86%|████████▋ | 8648/10000 [00:56<00:10, 133.44it/s]Running 10000 simulations.:  87%|████████▋ | 8662/10000 [00:56<00:10, 132.30it/s]Running 10000 simulations.:  87%|████████▋ | 8676/10000 [00:56<00:10, 128.28it/s]Running 10000 simulations.:  87%|████████▋ | 8689/10000 [00:57<00:10, 128.27it/s]Running 10000 simulations.:  87%|████████▋ | 8703/10000 [00:57<00:09, 129.84it/s]Running 10000 simulations.:  87%|████████▋ | 8717/10000 [00:57<00:10, 124.37it/s]Running 10000 simulations.:  87%|████████▋ | 8731/10000 [00:57<00:09, 128.25it/s]Running 10000 simulations.:  87%|████████▋ | 8745/10000 [00:57<00:09, 131.41it/s]Running 10000 simulations.:  88%|████████▊ | 8760/10000 [00:57<00:09, 134.27it/s]Running 10000 simulations.:  88%|████████▊ | 8775/10000 [00:57<00:08, 136.33it/s]Running 10000 simulations.:  88%|████████▊ | 8790/10000 [00:57<00:08, 137.83it/s]Running 10000 simulations.:  88%|████████▊ | 8804/10000 [00:57<00:08, 138.03it/s]Running 10000 simulations.:  88%|████████▊ | 8819/10000 [00:57<00:08, 139.06it/s]Running 10000 simulations.:  88%|████████▊ | 8834/10000 [00:58<00:08, 139.47it/s]Running 10000 simulations.:  88%|████████▊ | 8848/10000 [00:58<00:08, 138.12it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [00:58<00:08, 138.45it/s]Running 10000 simulations.:  89%|████████▉ | 8876/10000 [00:58<00:08, 137.69it/s]Running 10000 simulations.:  89%|████████▉ | 8890/10000 [00:58<00:08, 136.61it/s]Running 10000 simulations.:  89%|████████▉ | 8904/10000 [00:58<00:08, 136.12it/s]Running 10000 simulations.:  89%|████████▉ | 8918/10000 [00:58<00:07, 136.44it/s]Running 10000 simulations.:  89%|████████▉ | 8932/10000 [00:58<00:07, 135.92it/s]Running 10000 simulations.:  89%|████████▉ | 8946/10000 [00:58<00:07, 136.19it/s]Running 10000 simulations.:  90%|████████▉ | 8960/10000 [00:58<00:07, 136.11it/s]Running 10000 simulations.:  90%|████████▉ | 8974/10000 [00:59<00:07, 135.57it/s]Running 10000 simulations.:  90%|████████▉ | 8988/10000 [00:59<00:07, 135.37it/s]Running 10000 simulations.:  90%|█████████ | 9002/10000 [00:59<00:07, 134.40it/s]Running 10000 simulations.:  90%|█████████ | 9016/10000 [00:59<00:07, 133.06it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:59<00:07, 134.87it/s]Running 10000 simulations.:  90%|█████████ | 9045/10000 [00:59<00:07, 136.27it/s]Running 10000 simulations.:  91%|█████████ | 9059/10000 [00:59<00:06, 137.25it/s]Running 10000 simulations.:  91%|█████████ | 9073/10000 [00:59<00:06, 137.11it/s]Running 10000 simulations.:  91%|█████████ | 9087/10000 [00:59<00:06, 136.42it/s]Running 10000 simulations.:  91%|█████████ | 9101/10000 [01:00<00:06, 136.47it/s]Running 10000 simulations.:  91%|█████████ | 9115/10000 [01:00<00:06, 136.99it/s]Running 10000 simulations.:  91%|█████████▏| 9129/10000 [01:00<00:06, 137.62it/s]Running 10000 simulations.:  91%|█████████▏| 9143/10000 [01:00<00:06, 137.72it/s]Running 10000 simulations.:  92%|█████████▏| 9157/10000 [01:00<00:06, 138.09it/s]Running 10000 simulations.:  92%|█████████▏| 9171/10000 [01:00<00:05, 138.21it/s]Running 10000 simulations.:  92%|█████████▏| 9185/10000 [01:00<00:05, 138.43it/s]Running 10000 simulations.:  92%|█████████▏| 9199/10000 [01:00<00:05, 137.60it/s]Running 10000 simulations.:  92%|█████████▏| 9213/10000 [01:00<00:05, 138.00it/s]Running 10000 simulations.:  92%|█████████▏| 9227/10000 [01:00<00:05, 137.55it/s]Running 10000 simulations.:  92%|█████████▏| 9241/10000 [01:01<00:05, 137.59it/s]Running 10000 simulations.:  93%|█████████▎| 9255/10000 [01:01<00:05, 137.56it/s]Running 10000 simulations.:  93%|█████████▎| 9269/10000 [01:01<00:05, 137.84it/s]Running 10000 simulations.:  93%|█████████▎| 9283/10000 [01:01<00:05, 137.29it/s]Running 10000 simulations.:  93%|█████████▎| 9297/10000 [01:01<00:05, 137.44it/s]Running 10000 simulations.:  93%|█████████▎| 9311/10000 [01:01<00:05, 137.38it/s]Running 10000 simulations.:  93%|█████████▎| 9325/10000 [01:01<00:04, 137.08it/s]Running 10000 simulations.:  93%|█████████▎| 9339/10000 [01:01<00:04, 137.20it/s]Running 10000 simulations.:  94%|█████████▎| 9353/10000 [01:01<00:04, 138.01it/s]Running 10000 simulations.:  94%|█████████▎| 9368/10000 [01:01<00:04, 138.92it/s]Running 10000 simulations.:  94%|█████████▍| 9382/10000 [01:02<00:04, 138.96it/s]Running 10000 simulations.:  94%|█████████▍| 9396/10000 [01:02<00:04, 138.55it/s]Running 10000 simulations.:  94%|█████████▍| 9410/10000 [01:02<00:04, 138.73it/s]Running 10000 simulations.:  94%|█████████▍| 9424/10000 [01:02<00:04, 138.45it/s]Running 10000 simulations.:  94%|█████████▍| 9438/10000 [01:02<00:04, 137.67it/s]Running 10000 simulations.:  95%|█████████▍| 9452/10000 [01:02<00:03, 137.23it/s]Running 10000 simulations.:  95%|█████████▍| 9466/10000 [01:02<00:03, 136.77it/s]Running 10000 simulations.:  95%|█████████▍| 9480/10000 [01:02<00:03, 137.29it/s]Running 10000 simulations.:  95%|█████████▍| 9494/10000 [01:02<00:03, 137.44it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [01:02<00:03, 137.16it/s]Running 10000 simulations.:  95%|█████████▌| 9522/10000 [01:03<00:03, 137.52it/s]Running 10000 simulations.:  95%|█████████▌| 9536/10000 [01:03<00:03, 137.60it/s]Running 10000 simulations.:  96%|█████████▌| 9551/10000 [01:03<00:03, 138.60it/s]Running 10000 simulations.:  96%|█████████▌| 9565/10000 [01:03<00:03, 138.72it/s]Running 10000 simulations.:  96%|█████████▌| 9580/10000 [01:03<00:03, 139.16it/s]Running 10000 simulations.:  96%|█████████▌| 9594/10000 [01:03<00:02, 139.03it/s]Running 10000 simulations.:  96%|█████████▌| 9608/10000 [01:03<00:02, 133.81it/s]Running 10000 simulations.:  96%|█████████▌| 9622/10000 [01:03<00:02, 134.05it/s]Running 10000 simulations.:  96%|█████████▋| 9636/10000 [01:03<00:02, 134.62it/s]Running 10000 simulations.:  96%|█████████▋| 9650/10000 [01:04<00:02, 135.47it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [01:04<00:02, 135.63it/s]Running 10000 simulations.:  97%|█████████▋| 9678/10000 [01:04<00:02, 136.71it/s]Running 10000 simulations.:  97%|█████████▋| 9692/10000 [01:04<00:02, 136.63it/s]Running 10000 simulations.:  97%|█████████▋| 9706/10000 [01:04<00:02, 136.73it/s]Running 10000 simulations.:  97%|█████████▋| 9720/10000 [01:04<00:02, 136.92it/s]Running 10000 simulations.:  97%|█████████▋| 9734/10000 [01:04<00:01, 136.47it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [01:04<00:01, 137.22it/s]Running 10000 simulations.:  98%|█████████▊| 9762/10000 [01:04<00:01, 137.46it/s]Running 10000 simulations.:  98%|█████████▊| 9776/10000 [01:04<00:01, 136.17it/s]Running 10000 simulations.:  98%|█████████▊| 9790/10000 [01:05<00:01, 137.00it/s]Running 10000 simulations.:  98%|█████████▊| 9804/10000 [01:05<00:01, 137.79it/s]Running 10000 simulations.:  98%|█████████▊| 9818/10000 [01:05<00:01, 138.28it/s]Running 10000 simulations.:  98%|█████████▊| 9832/10000 [01:05<00:01, 138.01it/s]Running 10000 simulations.:  98%|█████████▊| 9846/10000 [01:05<00:01, 138.21it/s]Running 10000 simulations.:  99%|█████████▊| 9860/10000 [01:05<00:01, 138.22it/s]Running 10000 simulations.:  99%|█████████▊| 9874/10000 [01:05<00:00, 137.86it/s]Running 10000 simulations.:  99%|█████████▉| 9888/10000 [01:05<00:00, 137.92it/s]Running 10000 simulations.:  99%|█████████▉| 9902/10000 [01:05<00:00, 138.20it/s]Running 10000 simulations.:  99%|█████████▉| 9916/10000 [01:05<00:00, 138.47it/s]Running 10000 simulations.:  99%|█████████▉| 9930/10000 [01:06<00:00, 138.72it/s]Running 10000 simulations.:  99%|█████████▉| 9944/10000 [01:06<00:00, 138.73it/s]Running 10000 simulations.: 100%|█████████▉| 9958/10000 [01:06<00:00, 138.90it/s]Running 10000 simulations.: 100%|█████████▉| 9972/10000 [01:06<00:00, 138.93it/s]Running 10000 simulations.: 100%|█████████▉| 9987/10000 [01:06<00:00, 139.41it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:06<00:00, 150.24it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:06, 149.37it/s]Running 10000 simulations.:   0%|          | 31/10000 [00:00<01:06, 149.60it/s]Running 10000 simulations.:   0%|          | 46/10000 [00:00<01:06, 149.71it/s]Running 10000 simulations.:   1%|          | 62/10000 [00:00<01:06, 149.89it/s]Running 10000 simulations.:   1%|          | 77/10000 [00:00<01:06, 149.43it/s]Running 10000 simulations.:   1%|          | 92/10000 [00:00<01:06, 149.25it/s]Running 10000 simulations.:   1%|          | 107/10000 [00:00<01:06, 148.88it/s]Running 10000 simulations.:   1%|          | 122/10000 [00:00<01:06, 148.44it/s]Running 10000 simulations.:   1%|▏         | 137/10000 [00:00<01:06, 148.39it/s]Running 10000 simulations.:   2%|▏         | 152/10000 [00:01<01:06, 148.70it/s]Running 10000 simulations.:   2%|▏         | 167/10000 [00:01<01:06, 148.50it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:01<01:06, 147.91it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:01<01:06, 147.48it/s]Running 10000 simulations.:   2%|▏         | 212/10000 [00:01<01:06, 147.21it/s]Running 10000 simulations.:   2%|▏         | 227/10000 [00:01<01:06, 146.96it/s]Running 10000 simulations.:   2%|▏         | 242/10000 [00:01<01:06, 147.15it/s]Running 10000 simulations.:   3%|▎         | 257/10000 [00:01<01:06, 146.92it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<01:06, 146.53it/s]Running 10000 simulations.:   3%|▎         | 287/10000 [00:01<01:06, 146.42it/s]Running 10000 simulations.:   3%|▎         | 302/10000 [00:02<01:06, 146.35it/s]Running 10000 simulations.:   3%|▎         | 317/10000 [00:02<01:06, 146.02it/s]Running 10000 simulations.:   3%|▎         | 332/10000 [00:02<01:06, 145.95it/s]Running 10000 simulations.:   3%|▎         | 347/10000 [00:02<01:06, 145.85it/s]Running 10000 simulations.:   4%|▎         | 362/10000 [00:02<01:06, 145.81it/s]Running 10000 simulations.:   4%|▍         | 377/10000 [00:02<01:06, 145.70it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:02<01:06, 145.39it/s]Running 10000 simulations.:   4%|▍         | 407/10000 [00:02<01:05, 145.52it/s]Running 10000 simulations.:   4%|▍         | 422/10000 [00:02<01:05, 145.68it/s]Running 10000 simulations.:   4%|▍         | 437/10000 [00:02<01:05, 146.11it/s]Running 10000 simulations.:   5%|▍         | 452/10000 [00:03<01:05, 146.30it/s]Running 10000 simulations.:   5%|▍         | 467/10000 [00:03<01:05, 146.59it/s]Running 10000 simulations.:   5%|▍         | 482/10000 [00:03<01:04, 146.44it/s]Running 10000 simulations.:   5%|▍         | 497/10000 [00:03<01:04, 146.35it/s]Running 10000 simulations.:   5%|▌         | 512/10000 [00:03<01:05, 145.77it/s]Running 10000 simulations.:   5%|▌         | 527/10000 [00:03<01:05, 145.39it/s]Running 10000 simulations.:   5%|▌         | 542/10000 [00:03<01:04, 145.55it/s]Running 10000 simulations.:   6%|▌         | 557/10000 [00:03<01:04, 145.62it/s]Running 10000 simulations.:   6%|▌         | 572/10000 [00:03<01:04, 145.41it/s]Running 10000 simulations.:   6%|▌         | 587/10000 [00:03<01:04, 145.71it/s]Running 10000 simulations.:   6%|▌         | 602/10000 [00:04<01:04, 145.77it/s]Running 10000 simulations.:   6%|▌         | 617/10000 [00:04<01:04, 146.24it/s]Running 10000 simulations.:   6%|▋         | 632/10000 [00:04<01:03, 146.42it/s]Running 10000 simulations.:   6%|▋         | 647/10000 [00:04<01:04, 146.07it/s]Running 10000 simulations.:   7%|▋         | 662/10000 [00:04<01:04, 145.88it/s]Running 10000 simulations.:   7%|▋         | 677/10000 [00:04<01:03, 145.86it/s]Running 10000 simulations.:   7%|▋         | 692/10000 [00:04<01:03, 145.69it/s]Running 10000 simulations.:   7%|▋         | 707/10000 [00:04<01:04, 145.09it/s]Running 10000 simulations.:   7%|▋         | 722/10000 [00:04<01:04, 144.79it/s]Running 10000 simulations.:   7%|▋         | 737/10000 [00:05<01:03, 144.76it/s]Running 10000 simulations.:   8%|▊         | 752/10000 [00:05<01:03, 144.76it/s]Running 10000 simulations.:   8%|▊         | 767/10000 [00:05<01:03, 144.56it/s]Running 10000 simulations.:   8%|▊         | 782/10000 [00:05<01:03, 144.35it/s]Running 10000 simulations.:   8%|▊         | 797/10000 [00:05<01:03, 144.88it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:05<01:03, 145.27it/s]Running 10000 simulations.:   8%|▊         | 827/10000 [00:05<01:03, 143.73it/s]Running 10000 simulations.:   8%|▊         | 842/10000 [00:05<01:03, 144.40it/s]Running 10000 simulations.:   9%|▊         | 857/10000 [00:05<01:03, 144.68it/s]Running 10000 simulations.:   9%|▊         | 872/10000 [00:05<01:03, 144.59it/s]Running 10000 simulations.:   9%|▉         | 887/10000 [00:06<01:02, 144.80it/s]Running 10000 simulations.:   9%|▉         | 902/10000 [00:06<01:02, 144.57it/s]Running 10000 simulations.:   9%|▉         | 917/10000 [00:06<01:02, 144.38it/s]Running 10000 simulations.:   9%|▉         | 932/10000 [00:06<01:02, 144.35it/s]Running 10000 simulations.:   9%|▉         | 947/10000 [00:06<01:02, 144.38it/s]Running 10000 simulations.:  10%|▉         | 962/10000 [00:06<01:06, 135.39it/s]Running 10000 simulations.:  10%|▉         | 976/10000 [00:06<01:08, 132.54it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:06<01:08, 130.75it/s]Running 10000 simulations.:  10%|█         | 1004/10000 [00:06<01:09, 128.66it/s]Running 10000 simulations.:  10%|█         | 1017/10000 [00:07<01:10, 127.32it/s]Running 10000 simulations.:  10%|█         | 1030/10000 [00:07<01:10, 127.75it/s]Running 10000 simulations.:  10%|█         | 1044/10000 [00:07<01:09, 128.96it/s]Running 10000 simulations.:  11%|█         | 1058/10000 [00:07<01:09, 129.55it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:07<01:08, 130.32it/s]Running 10000 simulations.:  11%|█         | 1086/10000 [00:07<01:07, 131.15it/s]Running 10000 simulations.:  11%|█         | 1100/10000 [00:07<01:07, 131.30it/s]Running 10000 simulations.:  11%|█         | 1114/10000 [00:07<01:07, 131.59it/s]Running 10000 simulations.:  11%|█▏        | 1128/10000 [00:07<01:07, 132.06it/s]Running 10000 simulations.:  11%|█▏        | 1142/10000 [00:07<01:06, 132.34it/s]Running 10000 simulations.:  12%|█▏        | 1156/10000 [00:08<01:07, 131.78it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:08<01:07, 131.22it/s]Running 10000 simulations.:  12%|█▏        | 1184/10000 [00:08<01:07, 131.27it/s]Running 10000 simulations.:  12%|█▏        | 1198/10000 [00:08<01:06, 131.49it/s]Running 10000 simulations.:  12%|█▏        | 1212/10000 [00:08<01:06, 131.54it/s]Running 10000 simulations.:  12%|█▏        | 1226/10000 [00:08<01:06, 132.20it/s]Running 10000 simulations.:  12%|█▏        | 1240/10000 [00:08<01:06, 132.07it/s]Running 10000 simulations.:  13%|█▎        | 1254/10000 [00:08<01:06, 132.40it/s]Running 10000 simulations.:  13%|█▎        | 1268/10000 [00:08<01:06, 131.69it/s]Running 10000 simulations.:  13%|█▎        | 1282/10000 [00:09<01:06, 130.85it/s]Running 10000 simulations.:  13%|█▎        | 1296/10000 [00:09<01:06, 131.20it/s]Running 10000 simulations.:  13%|█▎        | 1310/10000 [00:09<01:06, 131.37it/s]Running 10000 simulations.:  13%|█▎        | 1324/10000 [00:09<01:06, 130.56it/s]Running 10000 simulations.:  13%|█▎        | 1338/10000 [00:09<01:06, 130.02it/s]Running 10000 simulations.:  14%|█▎        | 1352/10000 [00:09<01:06, 130.07it/s]Running 10000 simulations.:  14%|█▎        | 1366/10000 [00:09<01:05, 131.10it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:09<01:04, 133.02it/s]Running 10000 simulations.:  14%|█▍        | 1394/10000 [00:09<01:04, 134.16it/s]Running 10000 simulations.:  14%|█▍        | 1408/10000 [00:10<01:03, 135.63it/s]Running 10000 simulations.:  14%|█▍        | 1422/10000 [00:10<01:02, 136.51it/s]Running 10000 simulations.:  14%|█▍        | 1436/10000 [00:10<01:02, 137.26it/s]Running 10000 simulations.:  14%|█▍        | 1450/10000 [00:10<01:02, 137.47it/s]Running 10000 simulations.:  15%|█▍        | 1464/10000 [00:10<01:02, 137.40it/s]Running 10000 simulations.:  15%|█▍        | 1478/10000 [00:10<01:02, 137.11it/s]Running 10000 simulations.:  15%|█▍        | 1492/10000 [00:10<01:01, 137.46it/s]Running 10000 simulations.:  15%|█▌        | 1506/10000 [00:10<01:01, 137.40it/s]Running 10000 simulations.:  15%|█▌        | 1520/10000 [00:10<01:01, 137.68it/s]Running 10000 simulations.:  15%|█▌        | 1534/10000 [00:10<01:01, 137.43it/s]Running 10000 simulations.:  15%|█▌        | 1548/10000 [00:11<01:01, 137.06it/s]Running 10000 simulations.:  16%|█▌        | 1562/10000 [00:11<01:01, 137.34it/s]Running 10000 simulations.:  16%|█▌        | 1576/10000 [00:11<01:01, 138.08it/s]Running 10000 simulations.:  16%|█▌        | 1590/10000 [00:11<01:00, 138.07it/s]Running 10000 simulations.:  16%|█▌        | 1604/10000 [00:11<01:00, 138.10it/s]Running 10000 simulations.:  16%|█▌        | 1618/10000 [00:11<01:00, 138.66it/s]Running 10000 simulations.:  16%|█▋        | 1633/10000 [00:11<01:00, 139.21it/s]Running 10000 simulations.:  16%|█▋        | 1647/10000 [00:11<01:00, 138.94it/s]Running 10000 simulations.:  17%|█▋        | 1661/10000 [00:11<01:00, 138.48it/s]Running 10000 simulations.:  17%|█▋        | 1675/10000 [00:11<01:00, 138.74it/s]Running 10000 simulations.:  17%|█▋        | 1689/10000 [00:12<00:59, 138.73it/s]Running 10000 simulations.:  17%|█▋        | 1703/10000 [00:12<00:59, 138.28it/s]Running 10000 simulations.:  17%|█▋        | 1717/10000 [00:12<00:59, 138.58it/s]Running 10000 simulations.:  17%|█▋        | 1731/10000 [00:12<00:59, 138.99it/s]Running 10000 simulations.:  17%|█▋        | 1745/10000 [00:12<00:59, 138.50it/s]Running 10000 simulations.:  18%|█▊        | 1759/10000 [00:12<00:59, 138.20it/s]Running 10000 simulations.:  18%|█▊        | 1774/10000 [00:12<00:59, 139.37it/s]Running 10000 simulations.:  18%|█▊        | 1788/10000 [00:12<00:59, 138.88it/s]Running 10000 simulations.:  18%|█▊        | 1802/10000 [00:12<00:59, 138.79it/s]Running 10000 simulations.:  18%|█▊        | 1816/10000 [00:12<00:59, 138.63it/s]Running 10000 simulations.:  18%|█▊        | 1830/10000 [00:13<00:58, 138.81it/s]Running 10000 simulations.:  18%|█▊        | 1845/10000 [00:13<00:58, 139.16it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:13<00:58, 139.52it/s]Running 10000 simulations.:  19%|█▊        | 1874/10000 [00:13<00:58, 139.46it/s]Running 10000 simulations.:  19%|█▉        | 1888/10000 [00:13<00:58, 138.83it/s]Running 10000 simulations.:  19%|█▉        | 1902/10000 [00:13<00:58, 138.98it/s]Running 10000 simulations.:  19%|█▉        | 1916/10000 [00:13<00:58, 138.87it/s]Running 10000 simulations.:  19%|█▉        | 1930/10000 [00:13<00:58, 138.73it/s]Running 10000 simulations.:  19%|█▉        | 1944/10000 [00:13<00:58, 138.80it/s]Running 10000 simulations.:  20%|█▉        | 1959/10000 [00:13<00:57, 139.13it/s]Running 10000 simulations.:  20%|█▉        | 1973/10000 [00:14<00:57, 138.84it/s]Running 10000 simulations.:  20%|█▉        | 1988/10000 [00:14<00:57, 139.21it/s]Running 10000 simulations.:  20%|██        | 2003/10000 [00:14<00:57, 139.78it/s]Running 10000 simulations.:  20%|██        | 2017/10000 [00:14<00:57, 139.67it/s]Running 10000 simulations.:  20%|██        | 2032/10000 [00:14<00:56, 139.91it/s]Running 10000 simulations.:  20%|██        | 2046/10000 [00:14<00:57, 139.17it/s]Running 10000 simulations.:  21%|██        | 2060/10000 [00:14<00:57, 138.78it/s]Running 10000 simulations.:  21%|██        | 2074/10000 [00:14<00:57, 138.79it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:14<00:57, 138.40it/s]Running 10000 simulations.:  21%|██        | 2103/10000 [00:15<00:56, 139.26it/s]Running 10000 simulations.:  21%|██        | 2118/10000 [00:15<00:56, 139.77it/s]Running 10000 simulations.:  21%|██▏       | 2132/10000 [00:15<00:56, 139.40it/s]Running 10000 simulations.:  21%|██▏       | 2147/10000 [00:15<00:56, 139.70it/s]Running 10000 simulations.:  22%|██▏       | 2162/10000 [00:15<00:56, 139.81it/s]Running 10000 simulations.:  22%|██▏       | 2177/10000 [00:15<00:55, 140.98it/s]Running 10000 simulations.:  22%|██▏       | 2192/10000 [00:15<00:55, 141.77it/s]Running 10000 simulations.:  22%|██▏       | 2207/10000 [00:15<00:54, 141.94it/s]Running 10000 simulations.:  22%|██▏       | 2222/10000 [00:15<00:54, 141.72it/s]Running 10000 simulations.:  22%|██▏       | 2237/10000 [00:15<00:54, 141.87it/s]Running 10000 simulations.:  23%|██▎       | 2252/10000 [00:16<00:54, 141.35it/s]Running 10000 simulations.:  23%|██▎       | 2267/10000 [00:16<00:55, 140.30it/s]Running 10000 simulations.:  23%|██▎       | 2282/10000 [00:16<00:54, 140.65it/s]Running 10000 simulations.:  23%|██▎       | 2297/10000 [00:16<00:54, 140.35it/s]Running 10000 simulations.:  23%|██▎       | 2312/10000 [00:16<00:54, 140.48it/s]Running 10000 simulations.:  23%|██▎       | 2327/10000 [00:16<00:54, 140.49it/s]Running 10000 simulations.:  23%|██▎       | 2342/10000 [00:16<00:54, 140.18it/s]Running 10000 simulations.:  24%|██▎       | 2357/10000 [00:16<00:54, 139.54it/s]Running 10000 simulations.:  24%|██▎       | 2371/10000 [00:16<00:54, 139.23it/s]Running 10000 simulations.:  24%|██▍       | 2386/10000 [00:17<00:54, 139.81it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:17<00:54, 139.33it/s]Running 10000 simulations.:  24%|██▍       | 2414/10000 [00:17<00:54, 139.10it/s]Running 10000 simulations.:  24%|██▍       | 2429/10000 [00:17<00:54, 139.56it/s]Running 10000 simulations.:  24%|██▍       | 2443/10000 [00:17<00:54, 139.60it/s]Running 10000 simulations.:  25%|██▍       | 2457/10000 [00:17<00:54, 139.19it/s]Running 10000 simulations.:  25%|██▍       | 2471/10000 [00:17<00:54, 139.31it/s]Running 10000 simulations.:  25%|██▍       | 2485/10000 [00:17<00:53, 139.30it/s]Running 10000 simulations.:  25%|██▍       | 2499/10000 [00:17<00:53, 139.17it/s]Running 10000 simulations.:  25%|██▌       | 2513/10000 [00:17<00:53, 138.77it/s]Running 10000 simulations.:  25%|██▌       | 2527/10000 [00:18<00:53, 138.65it/s]Running 10000 simulations.:  25%|██▌       | 2541/10000 [00:18<00:53, 138.73it/s]Running 10000 simulations.:  26%|██▌       | 2555/10000 [00:18<00:53, 139.05it/s]Running 10000 simulations.:  26%|██▌       | 2569/10000 [00:18<00:53, 138.90it/s]Running 10000 simulations.:  26%|██▌       | 2584/10000 [00:18<00:53, 139.43it/s]Running 10000 simulations.:  26%|██▌       | 2598/10000 [00:18<00:53, 139.32it/s]Running 10000 simulations.:  26%|██▌       | 2612/10000 [00:18<00:52, 139.47it/s]Running 10000 simulations.:  26%|██▋       | 2627/10000 [00:18<00:52, 139.89it/s]Running 10000 simulations.:  26%|██▋       | 2641/10000 [00:18<00:52, 139.53it/s]Running 10000 simulations.:  27%|██▋       | 2655/10000 [00:18<00:52, 139.33it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:19<00:52, 139.70it/s]Running 10000 simulations.:  27%|██▋       | 2685/10000 [00:19<00:52, 139.98it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:19<00:52, 140.04it/s]Running 10000 simulations.:  27%|██▋       | 2715/10000 [00:19<00:52, 139.57it/s]Running 10000 simulations.:  27%|██▋       | 2729/10000 [00:19<00:52, 139.35it/s]Running 10000 simulations.:  27%|██▋       | 2743/10000 [00:19<00:52, 139.23it/s]Running 10000 simulations.:  28%|██▊       | 2757/10000 [00:19<00:52, 138.61it/s]Running 10000 simulations.:  28%|██▊       | 2771/10000 [00:19<00:52, 138.14it/s]Running 10000 simulations.:  28%|██▊       | 2785/10000 [00:19<00:52, 138.33it/s]Running 10000 simulations.:  28%|██▊       | 2799/10000 [00:20<00:52, 137.96it/s]Running 10000 simulations.:  28%|██▊       | 2813/10000 [00:20<00:52, 138.19it/s]Running 10000 simulations.:  28%|██▊       | 2827/10000 [00:20<00:51, 138.13it/s]Running 10000 simulations.:  28%|██▊       | 2841/10000 [00:20<00:51, 138.64it/s]Running 10000 simulations.:  29%|██▊       | 2856/10000 [00:20<00:51, 139.03it/s]Running 10000 simulations.:  29%|██▊       | 2870/10000 [00:20<00:51, 139.06it/s]Running 10000 simulations.:  29%|██▉       | 2884/10000 [00:20<00:51, 139.17it/s]Running 10000 simulations.:  29%|██▉       | 2898/10000 [00:20<00:51, 138.92it/s]Running 10000 simulations.:  29%|██▉       | 2912/10000 [00:20<00:51, 138.76it/s]Running 10000 simulations.:  29%|██▉       | 2927/10000 [00:20<00:50, 139.30it/s]Running 10000 simulations.:  29%|██▉       | 2942/10000 [00:21<00:50, 139.93it/s]Running 10000 simulations.:  30%|██▉       | 2957/10000 [00:21<00:50, 140.11it/s]Running 10000 simulations.:  30%|██▉       | 2972/10000 [00:21<00:50, 139.68it/s]Running 10000 simulations.:  30%|██▉       | 2986/10000 [00:21<00:50, 139.25it/s]Running 10000 simulations.:  30%|███       | 3001/10000 [00:21<00:50, 139.79it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:21<00:50, 139.47it/s]Running 10000 simulations.:  30%|███       | 3029/10000 [00:21<00:50, 138.95it/s]Running 10000 simulations.:  30%|███       | 3043/10000 [00:21<00:50, 138.29it/s]Running 10000 simulations.:  31%|███       | 3057/10000 [00:21<00:50, 138.55it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:21<00:50, 138.25it/s]Running 10000 simulations.:  31%|███       | 3085/10000 [00:22<00:50, 137.75it/s]Running 10000 simulations.:  31%|███       | 3099/10000 [00:22<00:49, 138.06it/s]Running 10000 simulations.:  31%|███       | 3113/10000 [00:22<00:49, 137.81it/s]Running 10000 simulations.:  31%|███▏      | 3128/10000 [00:22<00:49, 138.84it/s]Running 10000 simulations.:  31%|███▏      | 3143/10000 [00:22<00:48, 140.11it/s]Running 10000 simulations.:  32%|███▏      | 3158/10000 [00:22<00:48, 141.71it/s]Running 10000 simulations.:  32%|███▏      | 3173/10000 [00:22<00:47, 142.43it/s]Running 10000 simulations.:  32%|███▏      | 3188/10000 [00:22<00:47, 142.89it/s]Running 10000 simulations.:  32%|███▏      | 3203/10000 [00:22<00:47, 142.75it/s]Running 10000 simulations.:  32%|███▏      | 3218/10000 [00:22<00:47, 142.80it/s]Running 10000 simulations.:  32%|███▏      | 3233/10000 [00:23<00:47, 143.12it/s]Running 10000 simulations.:  32%|███▏      | 3248/10000 [00:23<00:47, 143.16it/s]Running 10000 simulations.:  33%|███▎      | 3263/10000 [00:23<00:47, 142.95it/s]Running 10000 simulations.:  33%|███▎      | 3278/10000 [00:23<00:46, 143.38it/s]Running 10000 simulations.:  33%|███▎      | 3293/10000 [00:23<00:46, 143.07it/s]Running 10000 simulations.:  33%|███▎      | 3308/10000 [00:23<00:46, 143.12it/s]Running 10000 simulations.:  33%|███▎      | 3323/10000 [00:23<00:46, 143.30it/s]Running 10000 simulations.:  33%|███▎      | 3338/10000 [00:23<00:46, 143.18it/s]Running 10000 simulations.:  34%|███▎      | 3353/10000 [00:23<00:46, 143.02it/s]Running 10000 simulations.:  34%|███▎      | 3368/10000 [00:24<00:46, 143.11it/s]Running 10000 simulations.:  34%|███▍      | 3383/10000 [00:24<00:46, 142.58it/s]Running 10000 simulations.:  34%|███▍      | 3398/10000 [00:24<00:46, 142.68it/s]Running 10000 simulations.:  34%|███▍      | 3413/10000 [00:24<00:45, 143.27it/s]Running 10000 simulations.:  34%|███▍      | 3428/10000 [00:24<00:45, 143.60it/s]Running 10000 simulations.:  34%|███▍      | 3443/10000 [00:24<00:45, 143.88it/s]Running 10000 simulations.:  35%|███▍      | 3458/10000 [00:24<00:45, 144.03it/s]Running 10000 simulations.:  35%|███▍      | 3473/10000 [00:24<00:45, 143.44it/s]Running 10000 simulations.:  35%|███▍      | 3488/10000 [00:24<00:45, 143.17it/s]Running 10000 simulations.:  35%|███▌      | 3503/10000 [00:24<00:45, 142.98it/s]Running 10000 simulations.:  35%|███▌      | 3518/10000 [00:25<00:45, 142.92it/s]Running 10000 simulations.:  35%|███▌      | 3533/10000 [00:25<00:45, 142.69it/s]Running 10000 simulations.:  35%|███▌      | 3548/10000 [00:25<00:45, 143.02it/s]Running 10000 simulations.:  36%|███▌      | 3563/10000 [00:25<00:45, 142.88it/s]Running 10000 simulations.:  36%|███▌      | 3578/10000 [00:25<00:44, 142.74it/s]Running 10000 simulations.:  36%|███▌      | 3593/10000 [00:25<00:44, 142.68it/s]Running 10000 simulations.:  36%|███▌      | 3608/10000 [00:25<00:44, 142.63it/s]Running 10000 simulations.:  36%|███▌      | 3623/10000 [00:25<00:44, 142.64it/s]Running 10000 simulations.:  36%|███▋      | 3638/10000 [00:25<00:44, 142.67it/s]Running 10000 simulations.:  37%|███▋      | 3653/10000 [00:26<00:44, 142.89it/s]Running 10000 simulations.:  37%|███▋      | 3668/10000 [00:26<00:44, 142.71it/s]Running 10000 simulations.:  37%|███▋      | 3683/10000 [00:26<00:44, 142.77it/s]Running 10000 simulations.:  37%|███▋      | 3698/10000 [00:26<00:44, 142.52it/s]Running 10000 simulations.:  37%|███▋      | 3713/10000 [00:26<00:44, 142.55it/s]Running 10000 simulations.:  37%|███▋      | 3728/10000 [00:26<00:44, 142.40it/s]Running 10000 simulations.:  37%|███▋      | 3743/10000 [00:26<00:44, 141.73it/s]Running 10000 simulations.:  38%|███▊      | 3758/10000 [00:26<00:44, 141.38it/s]Running 10000 simulations.:  38%|███▊      | 3773/10000 [00:26<00:44, 141.36it/s]Running 10000 simulations.:  38%|███▊      | 3788/10000 [00:26<00:44, 140.47it/s]Running 10000 simulations.:  38%|███▊      | 3803/10000 [00:27<00:44, 140.14it/s]Running 10000 simulations.:  38%|███▊      | 3818/10000 [00:27<00:43, 140.74it/s]Running 10000 simulations.:  38%|███▊      | 3833/10000 [00:27<00:44, 139.87it/s]Running 10000 simulations.:  38%|███▊      | 3848/10000 [00:27<00:43, 140.94it/s]Running 10000 simulations.:  39%|███▊      | 3863/10000 [00:27<00:43, 141.25it/s]Running 10000 simulations.:  39%|███▉      | 3878/10000 [00:27<00:43, 141.49it/s]Running 10000 simulations.:  39%|███▉      | 3893/10000 [00:27<00:43, 141.78it/s]Running 10000 simulations.:  39%|███▉      | 3908/10000 [00:27<00:42, 141.95it/s]Running 10000 simulations.:  39%|███▉      | 3923/10000 [00:27<00:42, 141.93it/s]Running 10000 simulations.:  39%|███▉      | 3938/10000 [00:28<00:42, 142.07it/s]Running 10000 simulations.:  40%|███▉      | 3953/10000 [00:28<00:42, 142.18it/s]Running 10000 simulations.:  40%|███▉      | 3968/10000 [00:28<00:42, 142.28it/s]Running 10000 simulations.:  40%|███▉      | 3983/10000 [00:28<00:42, 142.65it/s]Running 10000 simulations.:  40%|███▉      | 3998/10000 [00:28<00:42, 139.63it/s]Running 10000 simulations.:  40%|████      | 4013/10000 [00:28<00:42, 139.98it/s]Running 10000 simulations.:  40%|████      | 4028/10000 [00:28<00:42, 140.50it/s]Running 10000 simulations.:  40%|████      | 4043/10000 [00:28<00:42, 141.01it/s]Running 10000 simulations.:  41%|████      | 4058/10000 [00:28<00:41, 141.70it/s]Running 10000 simulations.:  41%|████      | 4073/10000 [00:29<00:41, 142.28it/s]Running 10000 simulations.:  41%|████      | 4088/10000 [00:29<00:41, 142.28it/s]Running 10000 simulations.:  41%|████      | 4103/10000 [00:29<00:41, 142.09it/s]Running 10000 simulations.:  41%|████      | 4118/10000 [00:29<00:41, 142.26it/s]Running 10000 simulations.:  41%|████▏     | 4133/10000 [00:29<00:41, 142.13it/s]Running 10000 simulations.:  41%|████▏     | 4148/10000 [00:29<00:41, 141.89it/s]Running 10000 simulations.:  42%|████▏     | 4163/10000 [00:29<00:41, 141.71it/s]Running 10000 simulations.:  42%|████▏     | 4178/10000 [00:29<00:41, 141.67it/s]Running 10000 simulations.:  42%|████▏     | 4193/10000 [00:29<00:40, 141.75it/s]Running 10000 simulations.:  42%|████▏     | 4208/10000 [00:29<00:40, 141.86it/s]Running 10000 simulations.:  42%|████▏     | 4223/10000 [00:30<00:40, 141.81it/s]Running 10000 simulations.:  42%|████▏     | 4238/10000 [00:30<00:40, 141.81it/s]Running 10000 simulations.:  43%|████▎     | 4253/10000 [00:30<00:40, 141.92it/s]Running 10000 simulations.:  43%|████▎     | 4268/10000 [00:30<00:40, 142.08it/s]Running 10000 simulations.:  43%|████▎     | 4283/10000 [00:30<00:40, 142.73it/s]Running 10000 simulations.:  43%|████▎     | 4298/10000 [00:30<00:40, 141.88it/s]Running 10000 simulations.:  43%|████▎     | 4313/10000 [00:30<00:40, 141.70it/s]Running 10000 simulations.:  43%|████▎     | 4328/10000 [00:30<00:39, 141.87it/s]Running 10000 simulations.:  43%|████▎     | 4343/10000 [00:30<00:39, 141.73it/s]Running 10000 simulations.:  44%|████▎     | 4358/10000 [00:31<00:39, 141.59it/s]Running 10000 simulations.:  44%|████▎     | 4373/10000 [00:31<00:39, 141.33it/s]Running 10000 simulations.:  44%|████▍     | 4388/10000 [00:31<00:39, 141.47it/s]Running 10000 simulations.:  44%|████▍     | 4403/10000 [00:31<00:39, 141.09it/s]Running 10000 simulations.:  44%|████▍     | 4418/10000 [00:31<00:39, 141.41it/s]Running 10000 simulations.:  44%|████▍     | 4433/10000 [00:31<00:39, 141.65it/s]Running 10000 simulations.:  44%|████▍     | 4448/10000 [00:31<00:39, 141.77it/s]Running 10000 simulations.:  45%|████▍     | 4463/10000 [00:31<00:38, 142.25it/s]Running 10000 simulations.:  45%|████▍     | 4478/10000 [00:31<00:38, 142.10it/s]Running 10000 simulations.:  45%|████▍     | 4493/10000 [00:31<00:38, 141.32it/s]Running 10000 simulations.:  45%|████▌     | 4508/10000 [00:32<00:38, 141.10it/s]Running 10000 simulations.:  45%|████▌     | 4523/10000 [00:32<00:38, 141.28it/s]Running 10000 simulations.:  45%|████▌     | 4538/10000 [00:32<00:38, 141.72it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:32<00:38, 142.12it/s]Running 10000 simulations.:  46%|████▌     | 4568/10000 [00:32<00:38, 141.84it/s]Running 10000 simulations.:  46%|████▌     | 4583/10000 [00:32<00:38, 141.89it/s]Running 10000 simulations.:  46%|████▌     | 4598/10000 [00:32<00:38, 141.68it/s]Running 10000 simulations.:  46%|████▌     | 4613/10000 [00:32<00:38, 141.34it/s]Running 10000 simulations.:  46%|████▋     | 4628/10000 [00:32<00:37, 141.61it/s]Running 10000 simulations.:  46%|████▋     | 4643/10000 [00:33<00:37, 141.69it/s]Running 10000 simulations.:  47%|████▋     | 4658/10000 [00:33<00:37, 142.04it/s]Running 10000 simulations.:  47%|████▋     | 4673/10000 [00:33<00:37, 141.87it/s]Running 10000 simulations.:  47%|████▋     | 4688/10000 [00:33<00:37, 141.14it/s]Running 10000 simulations.:  47%|████▋     | 4703/10000 [00:33<00:37, 141.15it/s]Running 10000 simulations.:  47%|████▋     | 4718/10000 [00:33<00:37, 141.22it/s]Running 10000 simulations.:  47%|████▋     | 4733/10000 [00:33<00:37, 141.36it/s]Running 10000 simulations.:  47%|████▋     | 4748/10000 [00:33<00:37, 141.34it/s]Running 10000 simulations.:  48%|████▊     | 4763/10000 [00:33<00:37, 140.89it/s]Running 10000 simulations.:  48%|████▊     | 4778/10000 [00:33<00:36, 141.24it/s]Running 10000 simulations.:  48%|████▊     | 4793/10000 [00:34<00:37, 140.54it/s]Running 10000 simulations.:  48%|████▊     | 4808/10000 [00:34<00:37, 139.94it/s]Running 10000 simulations.:  48%|████▊     | 4823/10000 [00:34<00:36, 140.71it/s]Running 10000 simulations.:  48%|████▊     | 4838/10000 [00:34<00:36, 141.85it/s]Running 10000 simulations.:  49%|████▊     | 4853/10000 [00:34<00:36, 142.20it/s]Running 10000 simulations.:  49%|████▊     | 4868/10000 [00:34<00:36, 142.33it/s]Running 10000 simulations.:  49%|████▉     | 4883/10000 [00:34<00:35, 142.50it/s]Running 10000 simulations.:  49%|████▉     | 4898/10000 [00:34<00:35, 142.38it/s]Running 10000 simulations.:  49%|████▉     | 4913/10000 [00:34<00:35, 142.24it/s]Running 10000 simulations.:  49%|████▉     | 4928/10000 [00:35<00:35, 142.16it/s]Running 10000 simulations.:  49%|████▉     | 4943/10000 [00:35<00:35, 141.99it/s]Running 10000 simulations.:  50%|████▉     | 4958/10000 [00:35<00:35, 142.29it/s]Running 10000 simulations.:  50%|████▉     | 4973/10000 [00:35<00:35, 142.16it/s]Running 10000 simulations.:  50%|████▉     | 4988/10000 [00:35<00:35, 142.19it/s]Running 10000 simulations.:  50%|█████     | 5003/10000 [00:35<00:35, 142.02it/s]Running 10000 simulations.:  50%|█████     | 5018/10000 [00:35<00:35, 142.19it/s]Running 10000 simulations.:  50%|█████     | 5033/10000 [00:35<00:34, 142.09it/s]Running 10000 simulations.:  50%|█████     | 5048/10000 [00:35<00:34, 142.15it/s]Running 10000 simulations.:  51%|█████     | 5063/10000 [00:35<00:34, 142.01it/s]Running 10000 simulations.:  51%|█████     | 5078/10000 [00:36<00:34, 141.63it/s]Running 10000 simulations.:  51%|█████     | 5093/10000 [00:36<00:34, 141.75it/s]Running 10000 simulations.:  51%|█████     | 5108/10000 [00:36<00:34, 142.30it/s]Running 10000 simulations.:  51%|█████     | 5123/10000 [00:36<00:34, 142.49it/s]Running 10000 simulations.:  51%|█████▏    | 5138/10000 [00:36<00:34, 141.79it/s]Running 10000 simulations.:  52%|█████▏    | 5153/10000 [00:36<00:36, 132.95it/s]Running 10000 simulations.:  52%|█████▏    | 5168/10000 [00:36<00:35, 136.05it/s]Running 10000 simulations.:  52%|█████▏    | 5183/10000 [00:36<00:34, 138.13it/s]Running 10000 simulations.:  52%|█████▏    | 5198/10000 [00:36<00:34, 139.46it/s]Running 10000 simulations.:  52%|█████▏    | 5213/10000 [00:37<00:34, 140.18it/s]Running 10000 simulations.:  52%|█████▏    | 5228/10000 [00:37<00:33, 140.95it/s]Running 10000 simulations.:  52%|█████▏    | 5243/10000 [00:37<00:33, 141.23it/s]Running 10000 simulations.:  53%|█████▎    | 5258/10000 [00:37<00:33, 141.30it/s]Running 10000 simulations.:  53%|█████▎    | 5273/10000 [00:37<00:33, 140.97it/s]Running 10000 simulations.:  53%|█████▎    | 5288/10000 [00:37<00:33, 141.49it/s]Running 10000 simulations.:  53%|█████▎    | 5303/10000 [00:37<00:33, 141.98it/s]Running 10000 simulations.:  53%|█████▎    | 5318/10000 [00:37<00:32, 142.04it/s]Running 10000 simulations.:  53%|█████▎    | 5333/10000 [00:37<00:32, 141.93it/s]Running 10000 simulations.:  53%|█████▎    | 5348/10000 [00:38<00:32, 141.88it/s]Running 10000 simulations.:  54%|█████▎    | 5363/10000 [00:38<00:32, 142.04it/s]Running 10000 simulations.:  54%|█████▍    | 5378/10000 [00:38<00:32, 142.36it/s]Running 10000 simulations.:  54%|█████▍    | 5393/10000 [00:38<00:32, 142.35it/s]Running 10000 simulations.:  54%|█████▍    | 5408/10000 [00:38<00:32, 141.99it/s]Running 10000 simulations.:  54%|█████▍    | 5423/10000 [00:38<00:32, 141.66it/s]Running 10000 simulations.:  54%|█████▍    | 5438/10000 [00:38<00:32, 140.35it/s]Running 10000 simulations.:  55%|█████▍    | 5453/10000 [00:38<00:32, 140.53it/s]Running 10000 simulations.:  55%|█████▍    | 5468/10000 [00:38<00:32, 141.45it/s]Running 10000 simulations.:  55%|█████▍    | 5483/10000 [00:38<00:31, 141.98it/s]Running 10000 simulations.:  55%|█████▍    | 5498/10000 [00:39<00:31, 141.92it/s]Running 10000 simulations.:  55%|█████▌    | 5513/10000 [00:39<00:31, 142.19it/s]Running 10000 simulations.:  55%|█████▌    | 5528/10000 [00:39<00:31, 142.92it/s]Running 10000 simulations.:  55%|█████▌    | 5543/10000 [00:39<00:31, 143.45it/s]Running 10000 simulations.:  56%|█████▌    | 5558/10000 [00:39<00:30, 144.10it/s]Running 10000 simulations.:  56%|█████▌    | 5573/10000 [00:39<00:30, 144.30it/s]Running 10000 simulations.:  56%|█████▌    | 5588/10000 [00:39<00:30, 143.80it/s]Running 10000 simulations.:  56%|█████▌    | 5603/10000 [00:39<00:30, 144.25it/s]Running 10000 simulations.:  56%|█████▌    | 5618/10000 [00:39<00:30, 144.45it/s]Running 10000 simulations.:  56%|█████▋    | 5633/10000 [00:40<00:30, 144.56it/s]Running 10000 simulations.:  56%|█████▋    | 5648/10000 [00:40<00:30, 143.24it/s]Running 10000 simulations.:  57%|█████▋    | 5663/10000 [00:40<00:31, 139.72it/s]Running 10000 simulations.:  57%|█████▋    | 5677/10000 [00:40<00:31, 137.45it/s]Running 10000 simulations.:  57%|█████▋    | 5691/10000 [00:40<00:31, 135.77it/s]Running 10000 simulations.:  57%|█████▋    | 5705/10000 [00:40<00:31, 134.37it/s]Running 10000 simulations.:  57%|█████▋    | 5719/10000 [00:40<00:32, 132.95it/s]Running 10000 simulations.:  57%|█████▋    | 5733/10000 [00:40<00:32, 132.65it/s]Running 10000 simulations.:  57%|█████▋    | 5747/10000 [00:40<00:32, 132.12it/s]Running 10000 simulations.:  58%|█████▊    | 5761/10000 [00:40<00:32, 131.40it/s]Running 10000 simulations.:  58%|█████▊    | 5775/10000 [00:41<00:32, 131.55it/s]Running 10000 simulations.:  58%|█████▊    | 5789/10000 [00:41<00:32, 131.54it/s]Running 10000 simulations.:  58%|█████▊    | 5803/10000 [00:41<00:31, 131.26it/s]Running 10000 simulations.:  58%|█████▊    | 5817/10000 [00:41<00:31, 131.58it/s]Running 10000 simulations.:  58%|█████▊    | 5831/10000 [00:41<00:31, 131.67it/s]Running 10000 simulations.:  58%|█████▊    | 5845/10000 [00:41<00:31, 131.49it/s]Running 10000 simulations.:  59%|█████▊    | 5859/10000 [00:41<00:31, 131.16it/s]Running 10000 simulations.:  59%|█████▊    | 5873/10000 [00:41<00:31, 131.01it/s]Running 10000 simulations.:  59%|█████▉    | 5887/10000 [00:41<00:31, 130.83it/s]Running 10000 simulations.:  59%|█████▉    | 5901/10000 [00:42<00:31, 132.08it/s]Running 10000 simulations.:  59%|█████▉    | 5916/10000 [00:42<00:30, 135.01it/s]Running 10000 simulations.:  59%|█████▉    | 5931/10000 [00:42<00:29, 137.47it/s]Running 10000 simulations.:  59%|█████▉    | 5946/10000 [00:42<00:29, 138.99it/s]Running 10000 simulations.:  60%|█████▉    | 5961/10000 [00:42<00:28, 139.83it/s]Running 10000 simulations.:  60%|█████▉    | 5976/10000 [00:42<00:28, 140.27it/s]Running 10000 simulations.:  60%|█████▉    | 5991/10000 [00:42<00:28, 141.32it/s]Running 10000 simulations.:  60%|██████    | 6006/10000 [00:42<00:28, 141.51it/s]Running 10000 simulations.:  60%|██████    | 6021/10000 [00:42<00:28, 141.43it/s]Running 10000 simulations.:  60%|██████    | 6036/10000 [00:42<00:28, 141.31it/s]Running 10000 simulations.:  61%|██████    | 6051/10000 [00:43<00:28, 140.96it/s]Running 10000 simulations.:  61%|██████    | 6066/10000 [00:43<00:27, 141.03it/s]Running 10000 simulations.:  61%|██████    | 6081/10000 [00:43<00:27, 141.07it/s]Running 10000 simulations.:  61%|██████    | 6096/10000 [00:43<00:27, 141.17it/s]Running 10000 simulations.:  61%|██████    | 6111/10000 [00:43<00:27, 141.29it/s]Running 10000 simulations.:  61%|██████▏   | 6126/10000 [00:43<00:27, 141.37it/s]Running 10000 simulations.:  61%|██████▏   | 6141/10000 [00:43<00:27, 141.04it/s]Running 10000 simulations.:  62%|██████▏   | 6156/10000 [00:43<00:27, 141.10it/s]Running 10000 simulations.:  62%|██████▏   | 6171/10000 [00:43<00:27, 141.52it/s]Running 10000 simulations.:  62%|██████▏   | 6186/10000 [00:44<00:26, 141.46it/s]Running 10000 simulations.:  62%|██████▏   | 6201/10000 [00:44<00:26, 141.61it/s]Running 10000 simulations.:  62%|██████▏   | 6216/10000 [00:44<00:26, 141.90it/s]Running 10000 simulations.:  62%|██████▏   | 6231/10000 [00:44<00:26, 141.82it/s]Running 10000 simulations.:  62%|██████▏   | 6246/10000 [00:44<00:26, 141.19it/s]Running 10000 simulations.:  63%|██████▎   | 6261/10000 [00:44<00:26, 141.01it/s]Running 10000 simulations.:  63%|██████▎   | 6276/10000 [00:44<00:26, 141.16it/s]Running 10000 simulations.:  63%|██████▎   | 6291/10000 [00:44<00:26, 141.07it/s]Running 10000 simulations.:  63%|██████▎   | 6306/10000 [00:44<00:26, 140.79it/s]Running 10000 simulations.:  63%|██████▎   | 6321/10000 [00:45<00:26, 141.04it/s]Running 10000 simulations.:  63%|██████▎   | 6336/10000 [00:45<00:25, 141.53it/s]Running 10000 simulations.:  64%|██████▎   | 6351/10000 [00:45<00:25, 141.45it/s]Running 10000 simulations.:  64%|██████▎   | 6366/10000 [00:45<00:25, 142.08it/s]Running 10000 simulations.:  64%|██████▍   | 6381/10000 [00:45<00:25, 141.83it/s]Running 10000 simulations.:  64%|██████▍   | 6396/10000 [00:45<00:25, 141.87it/s]Running 10000 simulations.:  64%|██████▍   | 6411/10000 [00:45<00:25, 141.99it/s]Running 10000 simulations.:  64%|██████▍   | 6426/10000 [00:45<00:25, 142.59it/s]Running 10000 simulations.:  64%|██████▍   | 6441/10000 [00:45<00:24, 143.10it/s]Running 10000 simulations.:  65%|██████▍   | 6456/10000 [00:45<00:24, 142.65it/s]Running 10000 simulations.:  65%|██████▍   | 6471/10000 [00:46<00:24, 142.27it/s]Running 10000 simulations.:  65%|██████▍   | 6486/10000 [00:46<00:24, 142.00it/s]Running 10000 simulations.:  65%|██████▌   | 6501/10000 [00:46<00:24, 142.49it/s]Running 10000 simulations.:  65%|██████▌   | 6516/10000 [00:46<00:24, 142.54it/s]Running 10000 simulations.:  65%|██████▌   | 6531/10000 [00:46<00:24, 142.06it/s]Running 10000 simulations.:  65%|██████▌   | 6546/10000 [00:46<00:24, 141.75it/s]Running 10000 simulations.:  66%|██████▌   | 6561/10000 [00:46<00:24, 141.47it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:46<00:24, 141.80it/s]Running 10000 simulations.:  66%|██████▌   | 6591/10000 [00:46<00:24, 141.48it/s]Running 10000 simulations.:  66%|██████▌   | 6606/10000 [00:47<00:24, 141.25it/s]Running 10000 simulations.:  66%|██████▌   | 6621/10000 [00:47<00:23, 140.90it/s]Running 10000 simulations.:  66%|██████▋   | 6636/10000 [00:47<00:23, 140.69it/s]Running 10000 simulations.:  67%|██████▋   | 6651/10000 [00:47<00:23, 140.75it/s]Running 10000 simulations.:  67%|██████▋   | 6666/10000 [00:47<00:23, 140.87it/s]Running 10000 simulations.:  67%|██████▋   | 6681/10000 [00:47<00:23, 140.51it/s]Running 10000 simulations.:  67%|██████▋   | 6696/10000 [00:47<00:23, 140.46it/s]Running 10000 simulations.:  67%|██████▋   | 6711/10000 [00:47<00:23, 140.80it/s]Running 10000 simulations.:  67%|██████▋   | 6726/10000 [00:47<00:23, 141.45it/s]Running 10000 simulations.:  67%|██████▋   | 6741/10000 [00:47<00:23, 141.41it/s]Running 10000 simulations.:  68%|██████▊   | 6756/10000 [00:48<00:22, 141.82it/s]Running 10000 simulations.:  68%|██████▊   | 6771/10000 [00:48<00:22, 141.88it/s]Running 10000 simulations.:  68%|██████▊   | 6786/10000 [00:48<00:22, 141.86it/s]Running 10000 simulations.:  68%|██████▊   | 6801/10000 [00:48<00:22, 141.94it/s]Running 10000 simulations.:  68%|██████▊   | 6816/10000 [00:48<00:22, 142.00it/s]Running 10000 simulations.:  68%|██████▊   | 6831/10000 [00:48<00:22, 141.81it/s]Running 10000 simulations.:  68%|██████▊   | 6846/10000 [00:48<00:22, 141.43it/s]Running 10000 simulations.:  69%|██████▊   | 6861/10000 [00:48<00:22, 140.39it/s]Running 10000 simulations.:  69%|██████▉   | 6876/10000 [00:48<00:22, 140.21it/s]Running 10000 simulations.:  69%|██████▉   | 6891/10000 [00:49<00:22, 140.82it/s]Running 10000 simulations.:  69%|██████▉   | 6906/10000 [00:49<00:21, 141.28it/s]Running 10000 simulations.:  69%|██████▉   | 6921/10000 [00:49<00:21, 141.38it/s]Running 10000 simulations.:  69%|██████▉   | 6936/10000 [00:49<00:21, 141.46it/s]Running 10000 simulations.:  70%|██████▉   | 6951/10000 [00:49<00:21, 141.69it/s]Running 10000 simulations.:  70%|██████▉   | 6966/10000 [00:49<00:21, 141.82it/s]Running 10000 simulations.:  70%|██████▉   | 6981/10000 [00:49<00:21, 141.76it/s]Running 10000 simulations.:  70%|██████▉   | 6996/10000 [00:49<00:21, 141.82it/s]Running 10000 simulations.:  70%|███████   | 7011/10000 [00:49<00:21, 141.79it/s]Running 10000 simulations.:  70%|███████   | 7026/10000 [00:49<00:20, 141.72it/s]Running 10000 simulations.:  70%|███████   | 7041/10000 [00:50<00:20, 142.02it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:50<00:20, 142.21it/s]Running 10000 simulations.:  71%|███████   | 7071/10000 [00:50<00:20, 142.24it/s]Running 10000 simulations.:  71%|███████   | 7086/10000 [00:50<00:20, 142.40it/s]Running 10000 simulations.:  71%|███████   | 7101/10000 [00:50<00:20, 142.08it/s]Running 10000 simulations.:  71%|███████   | 7116/10000 [00:50<00:20, 142.07it/s]Running 10000 simulations.:  71%|███████▏  | 7131/10000 [00:50<00:20, 142.03it/s]Running 10000 simulations.:  71%|███████▏  | 7146/10000 [00:50<00:20, 142.06it/s]Running 10000 simulations.:  72%|███████▏  | 7161/10000 [00:50<00:20, 141.82it/s]Running 10000 simulations.:  72%|███████▏  | 7176/10000 [00:51<00:19, 141.49it/s]Running 10000 simulations.:  72%|███████▏  | 7191/10000 [00:51<00:19, 141.63it/s]Running 10000 simulations.:  72%|███████▏  | 7206/10000 [00:51<00:19, 141.85it/s]Running 10000 simulations.:  72%|███████▏  | 7221/10000 [00:51<00:19, 142.00it/s]Running 10000 simulations.:  72%|███████▏  | 7236/10000 [00:51<00:19, 141.91it/s]Running 10000 simulations.:  73%|███████▎  | 7251/10000 [00:51<00:19, 141.57it/s]Running 10000 simulations.:  73%|███████▎  | 7266/10000 [00:51<00:19, 138.92it/s]Running 10000 simulations.:  73%|███████▎  | 7280/10000 [00:51<00:20, 135.98it/s]Running 10000 simulations.:  73%|███████▎  | 7294/10000 [00:51<00:20, 133.67it/s]Running 10000 simulations.:  73%|███████▎  | 7308/10000 [00:52<00:20, 132.55it/s]Running 10000 simulations.:  73%|███████▎  | 7322/10000 [00:52<00:20, 131.86it/s]Running 10000 simulations.:  73%|███████▎  | 7336/10000 [00:52<00:20, 130.99it/s]Running 10000 simulations.:  74%|███████▎  | 7350/10000 [00:52<00:20, 130.80it/s]Running 10000 simulations.:  74%|███████▎  | 7364/10000 [00:52<00:20, 131.10it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:52<00:20, 130.82it/s]Running 10000 simulations.:  74%|███████▍  | 7392/10000 [00:52<00:19, 130.51it/s]Running 10000 simulations.:  74%|███████▍  | 7406/10000 [00:52<00:19, 130.33it/s]Running 10000 simulations.:  74%|███████▍  | 7420/10000 [00:52<00:19, 130.04it/s]Running 10000 simulations.:  74%|███████▍  | 7434/10000 [00:52<00:19, 130.37it/s]Running 10000 simulations.:  74%|███████▍  | 7448/10000 [00:53<00:19, 131.18it/s]Running 10000 simulations.:  75%|███████▍  | 7462/10000 [00:53<00:19, 130.69it/s]Running 10000 simulations.:  75%|███████▍  | 7476/10000 [00:53<00:19, 130.47it/s]Running 10000 simulations.:  75%|███████▍  | 7490/10000 [00:53<00:19, 130.21it/s]Running 10000 simulations.:  75%|███████▌  | 7504/10000 [00:53<00:19, 129.89it/s]Running 10000 simulations.:  75%|███████▌  | 7517/10000 [00:53<00:19, 129.79it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:53<00:19, 129.69it/s]Running 10000 simulations.:  75%|███████▌  | 7543/10000 [00:53<00:18, 129.59it/s]Running 10000 simulations.:  76%|███████▌  | 7557/10000 [00:53<00:18, 129.95it/s]Running 10000 simulations.:  76%|███████▌  | 7570/10000 [00:54<00:18, 129.86it/s]Running 10000 simulations.:  76%|███████▌  | 7584/10000 [00:54<00:18, 130.10it/s]Running 10000 simulations.:  76%|███████▌  | 7598/10000 [00:54<00:18, 130.01it/s]Running 10000 simulations.:  76%|███████▌  | 7612/10000 [00:54<00:18, 130.31it/s]Running 10000 simulations.:  76%|███████▋  | 7626/10000 [00:54<00:18, 130.34it/s]Running 10000 simulations.:  76%|███████▋  | 7640/10000 [00:54<00:18, 130.12it/s]Running 10000 simulations.:  77%|███████▋  | 7654/10000 [00:54<00:18, 129.86it/s]Running 10000 simulations.:  77%|███████▋  | 7668/10000 [00:54<00:17, 130.63it/s]Running 10000 simulations.:  77%|███████▋  | 7682/10000 [00:54<00:17, 130.90it/s]Running 10000 simulations.:  77%|███████▋  | 7696/10000 [00:54<00:17, 130.40it/s]Running 10000 simulations.:  77%|███████▋  | 7710/10000 [00:55<00:17, 130.55it/s]Running 10000 simulations.:  77%|███████▋  | 7724/10000 [00:55<00:17, 130.80it/s]Running 10000 simulations.:  77%|███████▋  | 7738/10000 [00:55<00:17, 130.74it/s]Running 10000 simulations.:  78%|███████▊  | 7752/10000 [00:55<00:17, 130.51it/s]Running 10000 simulations.:  78%|███████▊  | 7766/10000 [00:55<00:17, 130.36it/s]Running 10000 simulations.:  78%|███████▊  | 7780/10000 [00:55<00:17, 130.21it/s]Running 10000 simulations.:  78%|███████▊  | 7794/10000 [00:55<00:16, 130.06it/s]Running 10000 simulations.:  78%|███████▊  | 7808/10000 [00:55<00:16, 129.81it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:55<00:16, 128.94it/s]Running 10000 simulations.:  78%|███████▊  | 7834/10000 [00:56<00:16, 128.06it/s]Running 10000 simulations.:  78%|███████▊  | 7847/10000 [00:56<00:16, 128.41it/s]Running 10000 simulations.:  79%|███████▊  | 7860/10000 [00:56<00:16, 128.47it/s]Running 10000 simulations.:  79%|███████▊  | 7874/10000 [00:56<00:16, 130.90it/s]Running 10000 simulations.:  79%|███████▉  | 7889/10000 [00:56<00:15, 134.58it/s]Running 10000 simulations.:  79%|███████▉  | 7904/10000 [00:56<00:15, 137.38it/s]Running 10000 simulations.:  79%|███████▉  | 7919/10000 [00:56<00:14, 139.35it/s]Running 10000 simulations.:  79%|███████▉  | 7934/10000 [00:56<00:14, 140.29it/s]Running 10000 simulations.:  79%|███████▉  | 7949/10000 [00:56<00:14, 140.96it/s]Running 10000 simulations.:  80%|███████▉  | 7964/10000 [00:56<00:14, 141.65it/s]Running 10000 simulations.:  80%|███████▉  | 7979/10000 [00:57<00:14, 142.38it/s]Running 10000 simulations.:  80%|███████▉  | 7994/10000 [00:57<00:14, 142.31it/s]Running 10000 simulations.:  80%|████████  | 8009/10000 [00:57<00:14, 142.18it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:57<00:13, 142.26it/s]Running 10000 simulations.:  80%|████████  | 8039/10000 [00:57<00:13, 142.21it/s]Running 10000 simulations.:  81%|████████  | 8054/10000 [00:57<00:13, 140.74it/s]Running 10000 simulations.:  81%|████████  | 8069/10000 [00:57<00:13, 138.57it/s]Running 10000 simulations.:  81%|████████  | 8083/10000 [00:57<00:14, 136.77it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:57<00:14, 135.75it/s]Running 10000 simulations.:  81%|████████  | 8112/10000 [00:58<00:13, 137.32it/s]Running 10000 simulations.:  81%|████████▏ | 8127/10000 [00:58<00:13, 138.38it/s]Running 10000 simulations.:  81%|████████▏ | 8142/10000 [00:58<00:13, 139.30it/s]Running 10000 simulations.:  82%|████████▏ | 8157/10000 [00:58<00:13, 140.04it/s]Running 10000 simulations.:  82%|████████▏ | 8172/10000 [00:58<00:13, 140.15it/s]Running 10000 simulations.:  82%|████████▏ | 8187/10000 [00:58<00:12, 140.63it/s]Running 10000 simulations.:  82%|████████▏ | 8202/10000 [00:58<00:12, 140.56it/s]Running 10000 simulations.:  82%|████████▏ | 8217/10000 [00:58<00:12, 140.49it/s]Running 10000 simulations.:  82%|████████▏ | 8232/10000 [00:58<00:12, 140.68it/s]Running 10000 simulations.:  82%|████████▏ | 8247/10000 [00:59<00:12, 140.89it/s]Running 10000 simulations.:  83%|████████▎ | 8262/10000 [00:59<00:12, 141.07it/s]Running 10000 simulations.:  83%|████████▎ | 8277/10000 [00:59<00:12, 141.50it/s]Running 10000 simulations.:  83%|████████▎ | 8292/10000 [00:59<00:12, 141.76it/s]Running 10000 simulations.:  83%|████████▎ | 8307/10000 [00:59<00:11, 141.92it/s]Running 10000 simulations.:  83%|████████▎ | 8322/10000 [00:59<00:11, 141.73it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:59<00:11, 141.80it/s]Running 10000 simulations.:  84%|████████▎ | 8352/10000 [00:59<00:11, 141.64it/s]Running 10000 simulations.:  84%|████████▎ | 8367/10000 [00:59<00:11, 141.73it/s]Running 10000 simulations.:  84%|████████▍ | 8382/10000 [00:59<00:11, 141.53it/s]Running 10000 simulations.:  84%|████████▍ | 8397/10000 [01:00<00:11, 141.12it/s]Running 10000 simulations.:  84%|████████▍ | 8412/10000 [01:00<00:11, 141.14it/s]Running 10000 simulations.:  84%|████████▍ | 8427/10000 [01:00<00:11, 141.49it/s]Running 10000 simulations.:  84%|████████▍ | 8442/10000 [01:00<00:10, 141.79it/s]Running 10000 simulations.:  85%|████████▍ | 8457/10000 [01:00<00:10, 142.13it/s]Running 10000 simulations.:  85%|████████▍ | 8472/10000 [01:00<00:10, 141.81it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [01:00<00:10, 141.37it/s]Running 10000 simulations.:  85%|████████▌ | 8502/10000 [01:00<00:10, 141.47it/s]Running 10000 simulations.:  85%|████████▌ | 8517/10000 [01:00<00:10, 142.05it/s]Running 10000 simulations.:  85%|████████▌ | 8532/10000 [01:01<00:10, 141.44it/s]Running 10000 simulations.:  85%|████████▌ | 8547/10000 [01:01<00:10, 137.22it/s]Running 10000 simulations.:  86%|████████▌ | 8561/10000 [01:01<00:10, 134.21it/s]Running 10000 simulations.:  86%|████████▌ | 8575/10000 [01:01<00:10, 132.44it/s]Running 10000 simulations.:  86%|████████▌ | 8589/10000 [01:01<00:10, 131.38it/s]Running 10000 simulations.:  86%|████████▌ | 8603/10000 [01:01<00:10, 130.86it/s]Running 10000 simulations.:  86%|████████▌ | 8617/10000 [01:01<00:10, 130.45it/s]Running 10000 simulations.:  86%|████████▋ | 8631/10000 [01:01<00:10, 130.06it/s]Running 10000 simulations.:  86%|████████▋ | 8645/10000 [01:01<00:10, 130.10it/s]Running 10000 simulations.:  87%|████████▋ | 8659/10000 [01:02<00:10, 129.77it/s]Running 10000 simulations.:  87%|████████▋ | 8673/10000 [01:02<00:10, 129.82it/s]Running 10000 simulations.:  87%|████████▋ | 8687/10000 [01:02<00:10, 130.21it/s]Running 10000 simulations.:  87%|████████▋ | 8702/10000 [01:02<00:09, 133.25it/s]Running 10000 simulations.:  87%|████████▋ | 8717/10000 [01:02<00:09, 135.49it/s]Running 10000 simulations.:  87%|████████▋ | 8732/10000 [01:02<00:09, 137.50it/s]Running 10000 simulations.:  87%|████████▋ | 8747/10000 [01:02<00:09, 138.39it/s]Running 10000 simulations.:  88%|████████▊ | 8762/10000 [01:02<00:08, 139.39it/s]Running 10000 simulations.:  88%|████████▊ | 8776/10000 [01:02<00:08, 139.09it/s]Running 10000 simulations.:  88%|████████▊ | 8791/10000 [01:02<00:08, 139.66it/s]Running 10000 simulations.:  88%|████████▊ | 8806/10000 [01:03<00:08, 140.72it/s]Running 10000 simulations.:  88%|████████▊ | 8821/10000 [01:03<00:08, 141.24it/s]Running 10000 simulations.:  88%|████████▊ | 8836/10000 [01:03<00:08, 140.72it/s]Running 10000 simulations.:  89%|████████▊ | 8851/10000 [01:03<00:08, 140.53it/s]Running 10000 simulations.:  89%|████████▊ | 8866/10000 [01:03<00:08, 140.35it/s]Running 10000 simulations.:  89%|████████▉ | 8881/10000 [01:03<00:07, 140.22it/s]Running 10000 simulations.:  89%|████████▉ | 8896/10000 [01:03<00:07, 140.33it/s]Running 10000 simulations.:  89%|████████▉ | 8911/10000 [01:03<00:07, 140.55it/s]Running 10000 simulations.:  89%|████████▉ | 8926/10000 [01:03<00:07, 140.31it/s]Running 10000 simulations.:  89%|████████▉ | 8941/10000 [01:04<00:07, 139.87it/s]Running 10000 simulations.:  90%|████████▉ | 8956/10000 [01:04<00:07, 140.33it/s]Running 10000 simulations.:  90%|████████▉ | 8971/10000 [01:04<00:07, 140.82it/s]Running 10000 simulations.:  90%|████████▉ | 8986/10000 [01:04<00:07, 141.27it/s]Running 10000 simulations.:  90%|█████████ | 9001/10000 [01:04<00:07, 140.96it/s]Running 10000 simulations.:  90%|█████████ | 9016/10000 [01:04<00:06, 141.58it/s]Running 10000 simulations.:  90%|█████████ | 9031/10000 [01:04<00:06, 141.14it/s]Running 10000 simulations.:  90%|█████████ | 9046/10000 [01:04<00:06, 141.16it/s]Running 10000 simulations.:  91%|█████████ | 9061/10000 [01:04<00:06, 141.29it/s]Running 10000 simulations.:  91%|█████████ | 9076/10000 [01:04<00:06, 140.05it/s]Running 10000 simulations.:  91%|█████████ | 9091/10000 [01:05<00:06, 139.85it/s]Running 10000 simulations.:  91%|█████████ | 9106/10000 [01:05<00:06, 139.96it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [01:05<00:06, 139.67it/s]Running 10000 simulations.:  91%|█████████▏| 9134/10000 [01:05<00:06, 139.45it/s]Running 10000 simulations.:  91%|█████████▏| 9148/10000 [01:05<00:06, 138.81it/s]Running 10000 simulations.:  92%|█████████▏| 9162/10000 [01:05<00:06, 139.08it/s]Running 10000 simulations.:  92%|█████████▏| 9176/10000 [01:05<00:05, 139.32it/s]Running 10000 simulations.:  92%|█████████▏| 9191/10000 [01:05<00:05, 140.08it/s]Running 10000 simulations.:  92%|█████████▏| 9206/10000 [01:05<00:05, 139.73it/s]Running 10000 simulations.:  92%|█████████▏| 9220/10000 [01:06<00:05, 139.18it/s]Running 10000 simulations.:  92%|█████████▏| 9235/10000 [01:06<00:05, 139.62it/s]Running 10000 simulations.:  92%|█████████▏| 9249/10000 [01:06<00:05, 139.56it/s]Running 10000 simulations.:  93%|█████████▎| 9264/10000 [01:06<00:05, 140.46it/s]Running 10000 simulations.:  93%|█████████▎| 9279/10000 [01:06<00:05, 139.86it/s]Running 10000 simulations.:  93%|█████████▎| 9293/10000 [01:06<00:05, 137.60it/s]Running 10000 simulations.:  93%|█████████▎| 9307/10000 [01:06<00:05, 126.42it/s]Running 10000 simulations.:  93%|█████████▎| 9320/10000 [01:06<00:05, 127.47it/s]Running 10000 simulations.:  93%|█████████▎| 9334/10000 [01:06<00:05, 128.57it/s]Running 10000 simulations.:  93%|█████████▎| 9349/10000 [01:06<00:04, 133.93it/s]Running 10000 simulations.:  94%|█████████▎| 9364/10000 [01:07<00:04, 137.01it/s]Running 10000 simulations.:  94%|█████████▍| 9379/10000 [01:07<00:04, 140.16it/s]Running 10000 simulations.:  94%|█████████▍| 9394/10000 [01:07<00:04, 140.05it/s]Running 10000 simulations.:  94%|█████████▍| 9409/10000 [01:07<00:04, 138.27it/s]Running 10000 simulations.:  94%|█████████▍| 9423/10000 [01:07<00:04, 137.32it/s]Running 10000 simulations.:  94%|█████████▍| 9437/10000 [01:07<00:04, 136.26it/s]Running 10000 simulations.:  95%|█████████▍| 9451/10000 [01:07<00:04, 135.64it/s]Running 10000 simulations.:  95%|█████████▍| 9465/10000 [01:07<00:03, 135.37it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [01:07<00:03, 135.32it/s]Running 10000 simulations.:  95%|█████████▍| 9493/10000 [01:08<00:03, 135.60it/s]Running 10000 simulations.:  95%|█████████▌| 9507/10000 [01:08<00:03, 134.82it/s]Running 10000 simulations.:  95%|█████████▌| 9521/10000 [01:08<00:03, 134.31it/s]Running 10000 simulations.:  95%|█████████▌| 9535/10000 [01:08<00:03, 134.03it/s]Running 10000 simulations.:  95%|█████████▌| 9549/10000 [01:08<00:03, 134.50it/s]Running 10000 simulations.:  96%|█████████▌| 9563/10000 [01:08<00:03, 134.01it/s]Running 10000 simulations.:  96%|█████████▌| 9577/10000 [01:08<00:03, 135.24it/s]Running 10000 simulations.:  96%|█████████▌| 9591/10000 [01:08<00:03, 135.65it/s]Running 10000 simulations.:  96%|█████████▌| 9605/10000 [01:08<00:02, 136.47it/s]Running 10000 simulations.:  96%|█████████▌| 9619/10000 [01:08<00:02, 136.59it/s]Running 10000 simulations.:  96%|█████████▋| 9633/10000 [01:09<00:02, 136.81it/s]Running 10000 simulations.:  96%|█████████▋| 9647/10000 [01:09<00:02, 137.13it/s]Running 10000 simulations.:  97%|█████████▋| 9661/10000 [01:09<00:02, 137.33it/s]Running 10000 simulations.:  97%|█████████▋| 9675/10000 [01:09<00:02, 137.77it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [01:09<00:02, 138.87it/s]Running 10000 simulations.:  97%|█████████▋| 9705/10000 [01:09<00:02, 139.45it/s]Running 10000 simulations.:  97%|█████████▋| 9720/10000 [01:09<00:01, 140.41it/s]Running 10000 simulations.:  97%|█████████▋| 9735/10000 [01:09<00:01, 140.53it/s]Running 10000 simulations.:  98%|█████████▊| 9750/10000 [01:09<00:01, 140.98it/s]Running 10000 simulations.:  98%|█████████▊| 9765/10000 [01:10<00:01, 141.36it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [01:10<00:01, 141.09it/s]Running 10000 simulations.:  98%|█████████▊| 9795/10000 [01:10<00:01, 141.76it/s]Running 10000 simulations.:  98%|█████████▊| 9810/10000 [01:10<00:01, 140.09it/s]Running 10000 simulations.:  98%|█████████▊| 9825/10000 [01:10<00:01, 137.74it/s]Running 10000 simulations.:  98%|█████████▊| 9839/10000 [01:10<00:01, 136.59it/s]Running 10000 simulations.:  99%|█████████▊| 9853/10000 [01:10<00:01, 135.76it/s]Running 10000 simulations.:  99%|█████████▊| 9867/10000 [01:10<00:00, 134.44it/s]Running 10000 simulations.:  99%|█████████▉| 9881/10000 [01:10<00:00, 133.97it/s]Running 10000 simulations.:  99%|█████████▉| 9895/10000 [01:10<00:00, 133.18it/s]Running 10000 simulations.:  99%|█████████▉| 9909/10000 [01:11<00:00, 133.00it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [01:11<00:00, 132.53it/s]Running 10000 simulations.:  99%|█████████▉| 9937/10000 [01:11<00:00, 132.82it/s]Running 10000 simulations.: 100%|█████████▉| 9951/10000 [01:11<00:00, 132.82it/s]Running 10000 simulations.: 100%|█████████▉| 9965/10000 [01:11<00:00, 133.33it/s]Running 10000 simulations.: 100%|█████████▉| 9979/10000 [01:11<00:00, 135.19it/s]Running 10000 simulations.: 100%|█████████▉| 9994/10000 [01:11<00:00, 138.04it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:11<00:00, 139.40it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:08, 146.11it/s]Running 10000 simulations.:   0%|          | 29/10000 [00:00<01:09, 143.65it/s]Running 10000 simulations.:   0%|          | 44/10000 [00:00<01:09, 143.53it/s]Running 10000 simulations.:   1%|          | 59/10000 [00:00<01:08, 144.42it/s]Running 10000 simulations.:   1%|          | 74/10000 [00:00<01:09, 143.75it/s]Running 10000 simulations.:   1%|          | 89/10000 [00:00<01:08, 143.84it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<01:08, 144.89it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<01:07, 146.17it/s]Running 10000 simulations.:   1%|▏         | 134/10000 [00:00<01:07, 145.51it/s]Running 10000 simulations.:   1%|▏         | 149/10000 [00:01<01:07, 146.76it/s]Running 10000 simulations.:   2%|▏         | 164/10000 [00:01<01:07, 145.44it/s]Running 10000 simulations.:   2%|▏         | 179/10000 [00:01<01:07, 145.56it/s]Running 10000 simulations.:   2%|▏         | 194/10000 [00:01<01:07, 144.89it/s]Running 10000 simulations.:   2%|▏         | 209/10000 [00:01<01:08, 143.70it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:01<01:08, 142.60it/s]Running 10000 simulations.:   2%|▏         | 239/10000 [00:01<01:08, 142.19it/s]Running 10000 simulations.:   3%|▎         | 254/10000 [00:01<01:08, 142.83it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:01<01:08, 142.20it/s]Running 10000 simulations.:   3%|▎         | 285/10000 [00:01<01:06, 145.31it/s]Running 10000 simulations.:   3%|▎         | 301/10000 [00:02<01:05, 148.59it/s]Running 10000 simulations.:   3%|▎         | 317/10000 [00:02<01:04, 151.25it/s]Running 10000 simulations.:   3%|▎         | 334/10000 [00:02<01:02, 154.66it/s]Running 10000 simulations.:   4%|▎         | 350/10000 [00:02<01:02, 153.18it/s]Running 10000 simulations.:   4%|▎         | 366/10000 [00:02<01:07, 142.04it/s]Running 10000 simulations.:   4%|▍         | 381/10000 [00:02<01:07, 142.54it/s]Running 10000 simulations.:   4%|▍         | 396/10000 [00:02<01:06, 144.58it/s]Running 10000 simulations.:   4%|▍         | 411/10000 [00:02<01:05, 145.47it/s]Running 10000 simulations.:   4%|▍         | 426/10000 [00:02<01:05, 145.48it/s]Running 10000 simulations.:   4%|▍         | 441/10000 [00:03<01:06, 144.64it/s]Running 10000 simulations.:   5%|▍         | 456/10000 [00:03<01:05, 145.14it/s]Running 10000 simulations.:   5%|▍         | 471/10000 [00:03<01:05, 145.01it/s]Running 10000 simulations.:   5%|▍         | 486/10000 [00:03<01:05, 145.95it/s]Running 10000 simulations.:   5%|▌         | 501/10000 [00:03<01:04, 146.70it/s]Running 10000 simulations.:   5%|▌         | 516/10000 [00:03<01:05, 145.76it/s]Running 10000 simulations.:   5%|▌         | 531/10000 [00:03<01:05, 145.40it/s]Running 10000 simulations.:   5%|▌         | 546/10000 [00:03<01:05, 145.35it/s]Running 10000 simulations.:   6%|▌         | 561/10000 [00:03<01:04, 145.27it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:03<01:05, 144.89it/s]Running 10000 simulations.:   6%|▌         | 591/10000 [00:04<01:04, 145.33it/s]Running 10000 simulations.:   6%|▌         | 606/10000 [00:04<01:04, 144.84it/s]Running 10000 simulations.:   6%|▌         | 621/10000 [00:04<01:04, 145.30it/s]Running 10000 simulations.:   6%|▋         | 636/10000 [00:04<01:04, 145.77it/s]Running 10000 simulations.:   7%|▋         | 651/10000 [00:04<01:04, 144.47it/s]Running 10000 simulations.:   7%|▋         | 666/10000 [00:04<01:04, 144.10it/s]Running 10000 simulations.:   7%|▋         | 681/10000 [00:04<01:04, 143.71it/s]Running 10000 simulations.:   7%|▋         | 696/10000 [00:04<01:05, 142.64it/s]Running 10000 simulations.:   7%|▋         | 711/10000 [00:04<01:04, 143.26it/s]Running 10000 simulations.:   7%|▋         | 726/10000 [00:05<01:04, 144.09it/s]Running 10000 simulations.:   7%|▋         | 741/10000 [00:05<01:04, 144.54it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:05<01:03, 145.31it/s]Running 10000 simulations.:   8%|▊         | 771/10000 [00:05<01:03, 145.85it/s]Running 10000 simulations.:   8%|▊         | 786/10000 [00:05<01:03, 144.54it/s]Running 10000 simulations.:   8%|▊         | 801/10000 [00:05<01:03, 144.65it/s]Running 10000 simulations.:   8%|▊         | 816/10000 [00:05<01:03, 144.83it/s]Running 10000 simulations.:   8%|▊         | 831/10000 [00:05<01:03, 144.30it/s]Running 10000 simulations.:   8%|▊         | 846/10000 [00:05<01:03, 144.25it/s]Running 10000 simulations.:   9%|▊         | 861/10000 [00:05<01:03, 144.15it/s]Running 10000 simulations.:   9%|▉         | 876/10000 [00:06<01:03, 144.20it/s]Running 10000 simulations.:   9%|▉         | 891/10000 [00:06<01:02, 145.05it/s]Running 10000 simulations.:   9%|▉         | 906/10000 [00:06<01:02, 145.59it/s]Running 10000 simulations.:   9%|▉         | 921/10000 [00:06<01:02, 145.58it/s]Running 10000 simulations.:   9%|▉         | 936/10000 [00:06<01:02, 144.78it/s]Running 10000 simulations.:  10%|▉         | 951/10000 [00:06<01:02, 143.66it/s]Running 10000 simulations.:  10%|▉         | 966/10000 [00:06<01:03, 143.39it/s]Running 10000 simulations.:  10%|▉         | 981/10000 [00:06<01:02, 143.33it/s]Running 10000 simulations.:  10%|▉         | 996/10000 [00:06<01:02, 143.78it/s]Running 10000 simulations.:  10%|█         | 1011/10000 [00:06<01:02, 144.12it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:07<01:01, 144.96it/s]Running 10000 simulations.:  10%|█         | 1041/10000 [00:07<01:01, 145.68it/s]Running 10000 simulations.:  11%|█         | 1056/10000 [00:07<01:01, 145.83it/s]Running 10000 simulations.:  11%|█         | 1071/10000 [00:07<01:01, 144.74it/s]Running 10000 simulations.:  11%|█         | 1086/10000 [00:07<01:02, 143.68it/s]Running 10000 simulations.:  11%|█         | 1101/10000 [00:07<01:01, 143.72it/s]Running 10000 simulations.:  11%|█         | 1116/10000 [00:07<01:01, 143.36it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:07<01:01, 143.91it/s]Running 10000 simulations.:  11%|█▏        | 1146/10000 [00:07<01:01, 144.00it/s]Running 10000 simulations.:  12%|█▏        | 1161/10000 [00:08<01:00, 144.98it/s]Running 10000 simulations.:  12%|█▏        | 1176/10000 [00:08<01:02, 140.58it/s]Running 10000 simulations.:  12%|█▏        | 1191/10000 [00:08<01:03, 138.50it/s]Running 10000 simulations.:  12%|█▏        | 1205/10000 [00:08<01:04, 135.57it/s]Running 10000 simulations.:  12%|█▏        | 1219/10000 [00:08<01:05, 133.40it/s]Running 10000 simulations.:  12%|█▏        | 1233/10000 [00:08<01:06, 132.83it/s]Running 10000 simulations.:  12%|█▏        | 1247/10000 [00:08<01:06, 132.32it/s]Running 10000 simulations.:  13%|█▎        | 1261/10000 [00:08<01:06, 132.05it/s]Running 10000 simulations.:  13%|█▎        | 1275/10000 [00:08<01:06, 130.57it/s]Running 10000 simulations.:  13%|█▎        | 1289/10000 [00:08<01:06, 131.64it/s]Running 10000 simulations.:  13%|█▎        | 1304/10000 [00:09<01:05, 133.71it/s]Running 10000 simulations.:  13%|█▎        | 1318/10000 [00:09<01:04, 134.03it/s]Running 10000 simulations.:  13%|█▎        | 1332/10000 [00:09<01:04, 134.20it/s]Running 10000 simulations.:  13%|█▎        | 1346/10000 [00:09<01:04, 134.42it/s]Running 10000 simulations.:  14%|█▎        | 1360/10000 [00:09<01:04, 134.05it/s]Running 10000 simulations.:  14%|█▎        | 1374/10000 [00:09<01:04, 133.71it/s]Running 10000 simulations.:  14%|█▍        | 1388/10000 [00:09<01:04, 133.85it/s]Running 10000 simulations.:  14%|█▍        | 1402/10000 [00:09<01:05, 132.09it/s]Running 10000 simulations.:  14%|█▍        | 1416/10000 [00:09<01:04, 133.08it/s]Running 10000 simulations.:  14%|█▍        | 1431/10000 [00:10<01:02, 137.64it/s]Running 10000 simulations.:  14%|█▍        | 1446/10000 [00:10<01:00, 140.86it/s]Running 10000 simulations.:  15%|█▍        | 1462/10000 [00:10<00:59, 144.07it/s]Running 10000 simulations.:  15%|█▍        | 1477/10000 [00:10<00:58, 144.71it/s]Running 10000 simulations.:  15%|█▍        | 1492/10000 [00:10<01:00, 141.46it/s]Running 10000 simulations.:  15%|█▌        | 1507/10000 [00:10<01:01, 138.12it/s]Running 10000 simulations.:  15%|█▌        | 1521/10000 [00:10<01:02, 136.70it/s]Running 10000 simulations.:  15%|█▌        | 1535/10000 [00:10<01:02, 135.54it/s]Running 10000 simulations.:  15%|█▌        | 1549/10000 [00:10<01:03, 133.63it/s]Running 10000 simulations.:  16%|█▌        | 1563/10000 [00:10<01:03, 132.06it/s]Running 10000 simulations.:  16%|█▌        | 1577/10000 [00:11<01:03, 131.78it/s]Running 10000 simulations.:  16%|█▌        | 1591/10000 [00:11<01:03, 131.43it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:11<01:04, 130.31it/s]Running 10000 simulations.:  16%|█▌        | 1619/10000 [00:11<01:03, 132.02it/s]Running 10000 simulations.:  16%|█▋        | 1633/10000 [00:11<01:02, 133.37it/s]Running 10000 simulations.:  16%|█▋        | 1647/10000 [00:11<01:02, 133.37it/s]Running 10000 simulations.:  17%|█▋        | 1661/10000 [00:11<01:02, 132.64it/s]Running 10000 simulations.:  17%|█▋        | 1675/10000 [00:11<01:03, 130.67it/s]Running 10000 simulations.:  17%|█▋        | 1689/10000 [00:11<01:04, 128.83it/s]Running 10000 simulations.:  17%|█▋        | 1703/10000 [00:12<01:04, 129.35it/s]Running 10000 simulations.:  17%|█▋        | 1716/10000 [00:12<01:04, 129.31it/s]Running 10000 simulations.:  17%|█▋        | 1729/10000 [00:12<01:04, 128.34it/s]Running 10000 simulations.:  17%|█▋        | 1742/10000 [00:12<01:04, 128.69it/s]Running 10000 simulations.:  18%|█▊        | 1756/10000 [00:12<01:03, 130.68it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:12<01:03, 129.59it/s]Running 10000 simulations.:  18%|█▊        | 1784/10000 [00:12<01:02, 130.78it/s]Running 10000 simulations.:  18%|█▊        | 1798/10000 [00:12<01:02, 132.00it/s]Running 10000 simulations.:  18%|█▊        | 1812/10000 [00:12<01:01, 133.02it/s]Running 10000 simulations.:  18%|█▊        | 1827/10000 [00:13<01:00, 135.95it/s]Running 10000 simulations.:  18%|█▊        | 1842/10000 [00:13<00:59, 137.64it/s]Running 10000 simulations.:  19%|█▊        | 1856/10000 [00:13<00:59, 137.97it/s]Running 10000 simulations.:  19%|█▊        | 1871/10000 [00:13<00:58, 139.13it/s]Running 10000 simulations.:  19%|█▉        | 1886/10000 [00:13<00:57, 140.61it/s]Running 10000 simulations.:  19%|█▉        | 1901/10000 [00:13<00:57, 141.66it/s]Running 10000 simulations.:  19%|█▉        | 1916/10000 [00:13<00:56, 143.31it/s]Running 10000 simulations.:  19%|█▉        | 1931/10000 [00:13<00:55, 144.34it/s]Running 10000 simulations.:  19%|█▉        | 1946/10000 [00:13<00:55, 144.37it/s]Running 10000 simulations.:  20%|█▉        | 1961/10000 [00:13<00:55, 143.76it/s]Running 10000 simulations.:  20%|█▉        | 1976/10000 [00:14<00:56, 142.32it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:14<00:56, 140.93it/s]Running 10000 simulations.:  20%|██        | 2006/10000 [00:14<00:56, 140.89it/s]Running 10000 simulations.:  20%|██        | 2021/10000 [00:14<00:56, 142.22it/s]Running 10000 simulations.:  20%|██        | 2036/10000 [00:14<00:55, 142.49it/s]Running 10000 simulations.:  21%|██        | 2051/10000 [00:14<00:55, 143.35it/s]Running 10000 simulations.:  21%|██        | 2066/10000 [00:14<00:55, 143.78it/s]Running 10000 simulations.:  21%|██        | 2081/10000 [00:14<00:54, 144.09it/s]Running 10000 simulations.:  21%|██        | 2096/10000 [00:14<00:55, 143.40it/s]Running 10000 simulations.:  21%|██        | 2111/10000 [00:14<00:55, 143.19it/s]Running 10000 simulations.:  21%|██▏       | 2126/10000 [00:15<00:55, 142.27it/s]Running 10000 simulations.:  21%|██▏       | 2141/10000 [00:15<00:55, 142.42it/s]Running 10000 simulations.:  22%|██▏       | 2156/10000 [00:15<00:54, 143.26it/s]Running 10000 simulations.:  22%|██▏       | 2171/10000 [00:15<00:54, 143.55it/s]Running 10000 simulations.:  22%|██▏       | 2186/10000 [00:15<00:54, 144.46it/s]Running 10000 simulations.:  22%|██▏       | 2201/10000 [00:15<00:53, 144.78it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:15<00:53, 144.82it/s]Running 10000 simulations.:  22%|██▏       | 2231/10000 [00:15<00:53, 144.59it/s]Running 10000 simulations.:  22%|██▏       | 2246/10000 [00:15<00:53, 143.81it/s]Running 10000 simulations.:  23%|██▎       | 2261/10000 [00:16<00:54, 142.18it/s]Running 10000 simulations.:  23%|██▎       | 2276/10000 [00:16<00:54, 142.28it/s]Running 10000 simulations.:  23%|██▎       | 2291/10000 [00:16<00:54, 142.70it/s]Running 10000 simulations.:  23%|██▎       | 2306/10000 [00:16<00:53, 143.37it/s]Running 10000 simulations.:  23%|██▎       | 2321/10000 [00:16<00:53, 144.75it/s]Running 10000 simulations.:  23%|██▎       | 2336/10000 [00:16<00:52, 145.15it/s]Running 10000 simulations.:  24%|██▎       | 2351/10000 [00:16<00:52, 145.07it/s]Running 10000 simulations.:  24%|██▎       | 2366/10000 [00:16<00:52, 144.82it/s]Running 10000 simulations.:  24%|██▍       | 2381/10000 [00:16<00:52, 143.81it/s]Running 10000 simulations.:  24%|██▍       | 2396/10000 [00:16<00:53, 142.01it/s]Running 10000 simulations.:  24%|██▍       | 2411/10000 [00:17<00:53, 142.07it/s]Running 10000 simulations.:  24%|██▍       | 2426/10000 [00:17<00:53, 142.04it/s]Running 10000 simulations.:  24%|██▍       | 2441/10000 [00:17<00:52, 143.08it/s]Running 10000 simulations.:  25%|██▍       | 2456/10000 [00:17<00:52, 143.58it/s]Running 10000 simulations.:  25%|██▍       | 2471/10000 [00:17<00:52, 143.33it/s]Running 10000 simulations.:  25%|██▍       | 2486/10000 [00:17<00:52, 143.67it/s]Running 10000 simulations.:  25%|██▌       | 2501/10000 [00:17<00:52, 143.66it/s]Running 10000 simulations.:  25%|██▌       | 2516/10000 [00:17<00:52, 143.72it/s]Running 10000 simulations.:  25%|██▌       | 2531/10000 [00:17<00:51, 143.69it/s]Running 10000 simulations.:  25%|██▌       | 2548/10000 [00:18<00:50, 148.93it/s]Running 10000 simulations.:  26%|██▌       | 2565/10000 [00:18<00:48, 153.26it/s]Running 10000 simulations.:  26%|██▌       | 2581/10000 [00:18<00:48, 154.36it/s]Running 10000 simulations.:  26%|██▌       | 2597/10000 [00:18<00:49, 150.44it/s]Running 10000 simulations.:  26%|██▌       | 2613/10000 [00:18<00:49, 148.53it/s]Running 10000 simulations.:  26%|██▋       | 2628/10000 [00:18<00:49, 147.69it/s]Running 10000 simulations.:  26%|██▋       | 2643/10000 [00:18<00:50, 146.76it/s]Running 10000 simulations.:  27%|██▋       | 2658/10000 [00:18<00:50, 146.41it/s]Running 10000 simulations.:  27%|██▋       | 2673/10000 [00:18<00:50, 146.09it/s]Running 10000 simulations.:  27%|██▋       | 2688/10000 [00:18<00:50, 145.69it/s]Running 10000 simulations.:  27%|██▋       | 2703/10000 [00:19<00:50, 145.03it/s]Running 10000 simulations.:  27%|██▋       | 2718/10000 [00:19<00:50, 143.44it/s]Running 10000 simulations.:  27%|██▋       | 2733/10000 [00:19<00:50, 143.15it/s]Running 10000 simulations.:  27%|██▋       | 2748/10000 [00:19<00:51, 142.06it/s]Running 10000 simulations.:  28%|██▊       | 2763/10000 [00:19<00:50, 142.10it/s]Running 10000 simulations.:  28%|██▊       | 2778/10000 [00:19<00:50, 143.22it/s]Running 10000 simulations.:  28%|██▊       | 2793/10000 [00:19<00:50, 143.63it/s]Running 10000 simulations.:  28%|██▊       | 2808/10000 [00:19<00:50, 143.50it/s]Running 10000 simulations.:  28%|██▊       | 2823/10000 [00:19<00:49, 143.85it/s]Running 10000 simulations.:  28%|██▊       | 2838/10000 [00:20<00:50, 142.76it/s]Running 10000 simulations.:  29%|██▊       | 2853/10000 [00:20<00:50, 141.41it/s]Running 10000 simulations.:  29%|██▊       | 2868/10000 [00:20<00:50, 141.80it/s]Running 10000 simulations.:  29%|██▉       | 2883/10000 [00:20<00:50, 141.27it/s]Running 10000 simulations.:  29%|██▉       | 2898/10000 [00:20<00:50, 141.93it/s]Running 10000 simulations.:  29%|██▉       | 2913/10000 [00:20<00:49, 142.38it/s]Running 10000 simulations.:  29%|██▉       | 2928/10000 [00:20<00:49, 143.05it/s]Running 10000 simulations.:  29%|██▉       | 2943/10000 [00:20<00:49, 143.34it/s]Running 10000 simulations.:  30%|██▉       | 2958/10000 [00:20<00:49, 143.37it/s]Running 10000 simulations.:  30%|██▉       | 2973/10000 [00:20<00:49, 142.87it/s]Running 10000 simulations.:  30%|██▉       | 2988/10000 [00:21<00:49, 141.95it/s]Running 10000 simulations.:  30%|███       | 3003/10000 [00:21<00:48, 143.24it/s]Running 10000 simulations.:  30%|███       | 3018/10000 [00:21<00:48, 142.92it/s]Running 10000 simulations.:  30%|███       | 3033/10000 [00:21<00:48, 143.02it/s]Running 10000 simulations.:  30%|███       | 3048/10000 [00:21<00:48, 142.59it/s]Running 10000 simulations.:  31%|███       | 3063/10000 [00:21<00:48, 142.52it/s]Running 10000 simulations.:  31%|███       | 3078/10000 [00:21<00:48, 142.46it/s]Running 10000 simulations.:  31%|███       | 3093/10000 [00:21<00:48, 141.21it/s]Running 10000 simulations.:  31%|███       | 3108/10000 [00:21<00:48, 141.14it/s]Running 10000 simulations.:  31%|███       | 3123/10000 [00:22<00:48, 141.25it/s]Running 10000 simulations.:  31%|███▏      | 3138/10000 [00:22<00:48, 141.36it/s]Running 10000 simulations.:  32%|███▏      | 3153/10000 [00:22<00:48, 142.54it/s]Running 10000 simulations.:  32%|███▏      | 3168/10000 [00:22<00:47, 143.66it/s]Running 10000 simulations.:  32%|███▏      | 3183/10000 [00:22<00:47, 142.67it/s]Running 10000 simulations.:  32%|███▏      | 3198/10000 [00:22<00:47, 143.06it/s]Running 10000 simulations.:  32%|███▏      | 3213/10000 [00:22<00:47, 142.88it/s]Running 10000 simulations.:  32%|███▏      | 3228/10000 [00:22<00:47, 141.32it/s]Running 10000 simulations.:  32%|███▏      | 3243/10000 [00:22<00:47, 141.70it/s]Running 10000 simulations.:  33%|███▎      | 3258/10000 [00:22<00:47, 141.91it/s]Running 10000 simulations.:  33%|███▎      | 3273/10000 [00:23<00:47, 141.32it/s]Running 10000 simulations.:  33%|███▎      | 3288/10000 [00:23<00:47, 142.56it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:23<00:46, 143.53it/s]Running 10000 simulations.:  33%|███▎      | 3318/10000 [00:23<00:46, 143.06it/s]Running 10000 simulations.:  33%|███▎      | 3333/10000 [00:23<00:46, 142.38it/s]Running 10000 simulations.:  33%|███▎      | 3348/10000 [00:23<00:46, 142.09it/s]Running 10000 simulations.:  34%|███▎      | 3363/10000 [00:23<00:47, 140.71it/s]Running 10000 simulations.:  34%|███▍      | 3378/10000 [00:23<00:46, 141.08it/s]Running 10000 simulations.:  34%|███▍      | 3393/10000 [00:23<00:46, 141.27it/s]Running 10000 simulations.:  34%|███▍      | 3408/10000 [00:24<00:46, 141.73it/s]Running 10000 simulations.:  34%|███▍      | 3423/10000 [00:24<00:45, 143.25it/s]Running 10000 simulations.:  34%|███▍      | 3438/10000 [00:24<00:45, 144.09it/s]Running 10000 simulations.:  35%|███▍      | 3453/10000 [00:24<00:45, 143.82it/s]Running 10000 simulations.:  35%|███▍      | 3468/10000 [00:24<00:45, 143.25it/s]Running 10000 simulations.:  35%|███▍      | 3483/10000 [00:24<00:45, 143.04it/s]Running 10000 simulations.:  35%|███▍      | 3498/10000 [00:24<00:45, 141.97it/s]Running 10000 simulations.:  35%|███▌      | 3513/10000 [00:24<00:45, 141.25it/s]Running 10000 simulations.:  35%|███▌      | 3528/10000 [00:24<00:45, 141.52it/s]Running 10000 simulations.:  35%|███▌      | 3543/10000 [00:24<00:45, 141.88it/s]Running 10000 simulations.:  36%|███▌      | 3558/10000 [00:25<00:45, 141.76it/s]Running 10000 simulations.:  36%|███▌      | 3573/10000 [00:25<00:45, 141.81it/s]Running 10000 simulations.:  36%|███▌      | 3588/10000 [00:25<00:45, 141.37it/s]Running 10000 simulations.:  36%|███▌      | 3603/10000 [00:25<00:45, 140.55it/s]Running 10000 simulations.:  36%|███▌      | 3619/10000 [00:25<00:44, 143.49it/s]Running 10000 simulations.:  36%|███▋      | 3636/10000 [00:25<00:42, 148.18it/s]Running 10000 simulations.:  37%|███▋      | 3652/10000 [00:25<00:42, 150.82it/s]Running 10000 simulations.:  37%|███▋      | 3668/10000 [00:25<00:41, 151.15it/s]Running 10000 simulations.:  37%|███▋      | 3684/10000 [00:25<00:42, 146.99it/s]Running 10000 simulations.:  37%|███▋      | 3699/10000 [00:26<00:43, 145.65it/s]Running 10000 simulations.:  37%|███▋      | 3714/10000 [00:26<00:43, 145.45it/s]Running 10000 simulations.:  37%|███▋      | 3729/10000 [00:26<00:43, 143.45it/s]Running 10000 simulations.:  37%|███▋      | 3744/10000 [00:26<00:43, 143.69it/s]Running 10000 simulations.:  38%|███▊      | 3759/10000 [00:26<00:43, 143.01it/s]Running 10000 simulations.:  38%|███▊      | 3774/10000 [00:26<00:43, 143.11it/s]Running 10000 simulations.:  38%|███▊      | 3789/10000 [00:26<00:43, 143.26it/s]Running 10000 simulations.:  38%|███▊      | 3804/10000 [00:26<00:43, 142.58it/s]Running 10000 simulations.:  38%|███▊      | 3819/10000 [00:26<00:43, 142.59it/s]Running 10000 simulations.:  38%|███▊      | 3834/10000 [00:26<00:43, 142.50it/s]Running 10000 simulations.:  38%|███▊      | 3849/10000 [00:27<00:43, 142.66it/s]Running 10000 simulations.:  39%|███▊      | 3864/10000 [00:27<00:42, 142.78it/s]Running 10000 simulations.:  39%|███▉      | 3879/10000 [00:27<00:42, 142.59it/s]Running 10000 simulations.:  39%|███▉      | 3894/10000 [00:27<00:42, 142.37it/s]Running 10000 simulations.:  39%|███▉      | 3909/10000 [00:27<00:42, 142.86it/s]Running 10000 simulations.:  39%|███▉      | 3924/10000 [00:27<00:42, 142.02it/s]Running 10000 simulations.:  39%|███▉      | 3939/10000 [00:27<00:42, 142.50it/s]Running 10000 simulations.:  40%|███▉      | 3954/10000 [00:27<00:42, 142.36it/s]Running 10000 simulations.:  40%|███▉      | 3969/10000 [00:27<00:42, 142.12it/s]Running 10000 simulations.:  40%|███▉      | 3984/10000 [00:28<00:41, 143.25it/s]Running 10000 simulations.:  40%|███▉      | 3999/10000 [00:28<00:41, 143.34it/s]Running 10000 simulations.:  40%|████      | 4014/10000 [00:28<00:42, 142.34it/s]Running 10000 simulations.:  40%|████      | 4029/10000 [00:28<00:42, 140.97it/s]Running 10000 simulations.:  40%|████      | 4044/10000 [00:28<00:42, 141.04it/s]Running 10000 simulations.:  41%|████      | 4059/10000 [00:28<00:42, 140.75it/s]Running 10000 simulations.:  41%|████      | 4074/10000 [00:28<00:41, 141.31it/s]Running 10000 simulations.:  41%|████      | 4089/10000 [00:28<00:41, 141.73it/s]Running 10000 simulations.:  41%|████      | 4104/10000 [00:28<00:41, 143.18it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:28<00:40, 144.56it/s]Running 10000 simulations.:  41%|████▏     | 4134/10000 [00:29<00:40, 144.67it/s]Running 10000 simulations.:  41%|████▏     | 4149/10000 [00:29<00:40, 143.87it/s]Running 10000 simulations.:  42%|████▏     | 4164/10000 [00:29<00:40, 143.01it/s]Running 10000 simulations.:  42%|████▏     | 4179/10000 [00:29<00:40, 142.47it/s]Running 10000 simulations.:  42%|████▏     | 4194/10000 [00:29<00:40, 141.90it/s]Running 10000 simulations.:  42%|████▏     | 4209/10000 [00:29<00:40, 141.30it/s]Running 10000 simulations.:  42%|████▏     | 4224/10000 [00:29<00:40, 141.84it/s]Running 10000 simulations.:  42%|████▏     | 4239/10000 [00:29<00:40, 142.81it/s]Running 10000 simulations.:  43%|████▎     | 4254/10000 [00:29<00:40, 143.10it/s]Running 10000 simulations.:  43%|████▎     | 4269/10000 [00:30<00:39, 143.42it/s]Running 10000 simulations.:  43%|████▎     | 4284/10000 [00:30<00:40, 142.57it/s]Running 10000 simulations.:  43%|████▎     | 4299/10000 [00:30<00:40, 142.02it/s]Running 10000 simulations.:  43%|████▎     | 4314/10000 [00:30<00:40, 141.13it/s]Running 10000 simulations.:  43%|████▎     | 4329/10000 [00:30<00:40, 141.48it/s]Running 10000 simulations.:  43%|████▎     | 4344/10000 [00:30<00:39, 142.07it/s]Running 10000 simulations.:  44%|████▎     | 4359/10000 [00:30<00:39, 142.08it/s]Running 10000 simulations.:  44%|████▎     | 4374/10000 [00:30<00:39, 142.59it/s]Running 10000 simulations.:  44%|████▍     | 4389/10000 [00:30<00:39, 142.51it/s]Running 10000 simulations.:  44%|████▍     | 4404/10000 [00:30<00:39, 142.40it/s]Running 10000 simulations.:  44%|████▍     | 4419/10000 [00:31<00:39, 142.22it/s]Running 10000 simulations.:  44%|████▍     | 4434/10000 [00:31<00:39, 140.19it/s]Running 10000 simulations.:  44%|████▍     | 4449/10000 [00:31<00:39, 140.47it/s]Running 10000 simulations.:  45%|████▍     | 4464/10000 [00:31<00:39, 140.68it/s]Running 10000 simulations.:  45%|████▍     | 4479/10000 [00:31<00:39, 140.62it/s]Running 10000 simulations.:  45%|████▍     | 4494/10000 [00:31<00:38, 142.26it/s]Running 10000 simulations.:  45%|████▌     | 4509/10000 [00:31<00:38, 142.82it/s]Running 10000 simulations.:  45%|████▌     | 4524/10000 [00:31<00:38, 142.77it/s]Running 10000 simulations.:  45%|████▌     | 4539/10000 [00:31<00:38, 143.21it/s]Running 10000 simulations.:  46%|████▌     | 4554/10000 [00:32<00:38, 141.96it/s]Running 10000 simulations.:  46%|████▌     | 4569/10000 [00:32<00:38, 141.45it/s]Running 10000 simulations.:  46%|████▌     | 4585/10000 [00:32<00:37, 146.34it/s]Running 10000 simulations.:  46%|████▌     | 4601/10000 [00:32<00:36, 149.27it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:32<00:37, 142.91it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:32<00:37, 143.18it/s]Running 10000 simulations.:  46%|████▋     | 4646/10000 [00:32<00:37, 143.46it/s]Running 10000 simulations.:  47%|████▋     | 4661/10000 [00:32<00:37, 142.91it/s]Running 10000 simulations.:  47%|████▋     | 4676/10000 [00:32<00:36, 144.04it/s]Running 10000 simulations.:  47%|████▋     | 4691/10000 [00:32<00:36, 144.61it/s]Running 10000 simulations.:  47%|████▋     | 4706/10000 [00:33<00:36, 144.56it/s]Running 10000 simulations.:  47%|████▋     | 4721/10000 [00:33<00:36, 144.33it/s]Running 10000 simulations.:  47%|████▋     | 4736/10000 [00:33<00:36, 143.98it/s]Running 10000 simulations.:  48%|████▊     | 4751/10000 [00:33<00:36, 142.04it/s]Running 10000 simulations.:  48%|████▊     | 4766/10000 [00:33<00:37, 141.08it/s]Running 10000 simulations.:  48%|████▊     | 4781/10000 [00:33<00:36, 141.75it/s]Running 10000 simulations.:  48%|████▊     | 4796/10000 [00:33<00:36, 141.50it/s]Running 10000 simulations.:  48%|████▊     | 4811/10000 [00:33<00:36, 141.46it/s]Running 10000 simulations.:  48%|████▊     | 4826/10000 [00:33<00:36, 142.27it/s]Running 10000 simulations.:  48%|████▊     | 4841/10000 [00:34<00:36, 142.64it/s]Running 10000 simulations.:  49%|████▊     | 4856/10000 [00:34<00:35, 143.36it/s]Running 10000 simulations.:  49%|████▊     | 4871/10000 [00:34<00:35, 142.87it/s]Running 10000 simulations.:  49%|████▉     | 4886/10000 [00:34<00:35, 142.55it/s]Running 10000 simulations.:  49%|████▉     | 4901/10000 [00:34<00:35, 142.44it/s]Running 10000 simulations.:  49%|████▉     | 4916/10000 [00:34<00:35, 143.51it/s]Running 10000 simulations.:  49%|████▉     | 4931/10000 [00:34<00:35, 143.32it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:34<00:35, 144.02it/s]Running 10000 simulations.:  50%|████▉     | 4961/10000 [00:34<00:34, 144.20it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:34<00:34, 144.90it/s]Running 10000 simulations.:  50%|████▉     | 4991/10000 [00:35<00:34, 144.95it/s]Running 10000 simulations.:  50%|█████     | 5006/10000 [00:35<00:34, 143.45it/s]Running 10000 simulations.:  50%|█████     | 5021/10000 [00:35<00:34, 142.96it/s]Running 10000 simulations.:  50%|█████     | 5036/10000 [00:35<00:34, 143.21it/s]Running 10000 simulations.:  51%|█████     | 5051/10000 [00:35<00:34, 143.88it/s]Running 10000 simulations.:  51%|█████     | 5066/10000 [00:35<00:34, 143.01it/s]Running 10000 simulations.:  51%|█████     | 5081/10000 [00:35<00:34, 143.46it/s]Running 10000 simulations.:  51%|█████     | 5096/10000 [00:35<00:34, 143.16it/s]Running 10000 simulations.:  51%|█████     | 5111/10000 [00:35<00:34, 142.46it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:36<00:34, 142.67it/s]Running 10000 simulations.:  51%|█████▏    | 5141/10000 [00:36<00:34, 142.91it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:36<00:33, 143.07it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:36<00:33, 143.50it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:36<00:33, 143.85it/s]Running 10000 simulations.:  52%|█████▏    | 5201/10000 [00:36<00:33, 144.74it/s]Running 10000 simulations.:  52%|█████▏    | 5216/10000 [00:36<00:33, 144.94it/s]Running 10000 simulations.:  52%|█████▏    | 5231/10000 [00:36<00:32, 144.98it/s]Running 10000 simulations.:  52%|█████▏    | 5246/10000 [00:36<00:32, 145.06it/s]Running 10000 simulations.:  53%|█████▎    | 5261/10000 [00:36<00:32, 144.70it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:37<00:32, 144.63it/s]Running 10000 simulations.:  53%|█████▎    | 5291/10000 [00:37<00:32, 144.77it/s]Running 10000 simulations.:  53%|█████▎    | 5306/10000 [00:37<00:32, 143.73it/s]Running 10000 simulations.:  53%|█████▎    | 5321/10000 [00:37<00:32, 143.71it/s]Running 10000 simulations.:  53%|█████▎    | 5336/10000 [00:37<00:32, 144.89it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:37<00:31, 145.63it/s]Running 10000 simulations.:  54%|█████▎    | 5366/10000 [00:37<00:31, 145.53it/s]Running 10000 simulations.:  54%|█████▍    | 5381/10000 [00:37<00:31, 145.78it/s]Running 10000 simulations.:  54%|█████▍    | 5396/10000 [00:37<00:31, 144.72it/s]Running 10000 simulations.:  54%|█████▍    | 5411/10000 [00:38<00:32, 143.28it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:38<00:32, 142.71it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:38<00:31, 142.55it/s]Running 10000 simulations.:  55%|█████▍    | 5456/10000 [00:38<00:31, 143.79it/s]Running 10000 simulations.:  55%|█████▍    | 5471/10000 [00:38<00:31, 144.39it/s]Running 10000 simulations.:  55%|█████▍    | 5486/10000 [00:38<00:31, 145.21it/s]Running 10000 simulations.:  55%|█████▌    | 5501/10000 [00:38<00:30, 145.43it/s]Running 10000 simulations.:  55%|█████▌    | 5516/10000 [00:38<00:30, 145.28it/s]Running 10000 simulations.:  55%|█████▌    | 5531/10000 [00:38<00:31, 143.80it/s]Running 10000 simulations.:  55%|█████▌    | 5546/10000 [00:38<00:30, 144.13it/s]Running 10000 simulations.:  56%|█████▌    | 5561/10000 [00:39<00:30, 144.43it/s]Running 10000 simulations.:  56%|█████▌    | 5576/10000 [00:39<00:30, 144.80it/s]Running 10000 simulations.:  56%|█████▌    | 5591/10000 [00:39<00:30, 145.58it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:39<00:30, 145.73it/s]Running 10000 simulations.:  56%|█████▌    | 5621/10000 [00:39<00:30, 145.14it/s]Running 10000 simulations.:  56%|█████▋    | 5636/10000 [00:39<00:30, 144.64it/s]Running 10000 simulations.:  57%|█████▋    | 5651/10000 [00:39<00:30, 143.70it/s]Running 10000 simulations.:  57%|█████▋    | 5666/10000 [00:39<00:29, 144.47it/s]Running 10000 simulations.:  57%|█████▋    | 5683/10000 [00:39<00:28, 149.39it/s]Running 10000 simulations.:  57%|█████▋    | 5700/10000 [00:39<00:27, 153.60it/s]Running 10000 simulations.:  57%|█████▋    | 5716/10000 [00:40<00:27, 154.89it/s]Running 10000 simulations.:  57%|█████▋    | 5732/10000 [00:40<00:28, 151.43it/s]Running 10000 simulations.:  57%|█████▋    | 5748/10000 [00:40<00:28, 149.44it/s]Running 10000 simulations.:  58%|█████▊    | 5763/10000 [00:40<00:28, 147.35it/s]Running 10000 simulations.:  58%|█████▊    | 5778/10000 [00:40<00:28, 145.87it/s]Running 10000 simulations.:  58%|█████▊    | 5793/10000 [00:40<00:29, 144.18it/s]Running 10000 simulations.:  58%|█████▊    | 5808/10000 [00:40<00:29, 142.28it/s]Running 10000 simulations.:  58%|█████▊    | 5823/10000 [00:40<00:29, 142.24it/s]Running 10000 simulations.:  58%|█████▊    | 5838/10000 [00:40<00:29, 142.27it/s]Running 10000 simulations.:  59%|█████▊    | 5853/10000 [00:41<00:29, 142.82it/s]Running 10000 simulations.:  59%|█████▊    | 5868/10000 [00:41<00:28, 143.95it/s]Running 10000 simulations.:  59%|█████▉    | 5883/10000 [00:41<00:28, 144.55it/s]Running 10000 simulations.:  59%|█████▉    | 5898/10000 [00:41<00:28, 144.63it/s]Running 10000 simulations.:  59%|█████▉    | 5913/10000 [00:41<00:28, 143.97it/s]Running 10000 simulations.:  59%|█████▉    | 5928/10000 [00:41<00:28, 144.09it/s]Running 10000 simulations.:  59%|█████▉    | 5943/10000 [00:41<00:28, 143.34it/s]Running 10000 simulations.:  60%|█████▉    | 5958/10000 [00:41<00:28, 143.04it/s]Running 10000 simulations.:  60%|█████▉    | 5973/10000 [00:41<00:28, 142.63it/s]Running 10000 simulations.:  60%|█████▉    | 5988/10000 [00:41<00:28, 143.01it/s]Running 10000 simulations.:  60%|██████    | 6003/10000 [00:42<00:27, 143.58it/s]Running 10000 simulations.:  60%|██████    | 6018/10000 [00:42<00:27, 145.18it/s]Running 10000 simulations.:  60%|██████    | 6033/10000 [00:42<00:27, 143.63it/s]Running 10000 simulations.:  60%|██████    | 6048/10000 [00:42<00:27, 143.90it/s]Running 10000 simulations.:  61%|██████    | 6063/10000 [00:42<00:27, 143.58it/s]Running 10000 simulations.:  61%|██████    | 6078/10000 [00:42<00:27, 143.09it/s]Running 10000 simulations.:  61%|██████    | 6093/10000 [00:42<00:27, 142.39it/s]Running 10000 simulations.:  61%|██████    | 6108/10000 [00:42<00:27, 142.85it/s]Running 10000 simulations.:  61%|██████    | 6123/10000 [00:42<00:27, 143.13it/s]Running 10000 simulations.:  61%|██████▏   | 6138/10000 [00:43<00:26, 143.62it/s]Running 10000 simulations.:  62%|██████▏   | 6153/10000 [00:43<00:26, 143.74it/s]Running 10000 simulations.:  62%|██████▏   | 6168/10000 [00:43<00:26, 143.72it/s]Running 10000 simulations.:  62%|██████▏   | 6183/10000 [00:43<00:26, 143.05it/s]Running 10000 simulations.:  62%|██████▏   | 6198/10000 [00:43<00:26, 143.30it/s]Running 10000 simulations.:  62%|██████▏   | 6213/10000 [00:43<00:26, 142.67it/s]Running 10000 simulations.:  62%|██████▏   | 6228/10000 [00:43<00:26, 142.90it/s]Running 10000 simulations.:  62%|██████▏   | 6243/10000 [00:43<00:26, 143.97it/s]Running 10000 simulations.:  63%|██████▎   | 6258/10000 [00:43<00:25, 144.42it/s]Running 10000 simulations.:  63%|██████▎   | 6273/10000 [00:43<00:25, 145.16it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:44<00:25, 145.57it/s]Running 10000 simulations.:  63%|██████▎   | 6303/10000 [00:44<00:25, 143.96it/s]Running 10000 simulations.:  63%|██████▎   | 6318/10000 [00:44<00:25, 143.17it/s]Running 10000 simulations.:  63%|██████▎   | 6333/10000 [00:44<00:25, 143.25it/s]Running 10000 simulations.:  63%|██████▎   | 6348/10000 [00:44<00:25, 142.34it/s]Running 10000 simulations.:  64%|██████▎   | 6363/10000 [00:44<00:25, 142.52it/s]Running 10000 simulations.:  64%|██████▍   | 6378/10000 [00:44<00:25, 143.85it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:44<00:25, 143.87it/s]Running 10000 simulations.:  64%|██████▍   | 6408/10000 [00:44<00:24, 145.07it/s]Running 10000 simulations.:  64%|██████▍   | 6423/10000 [00:45<00:24, 145.68it/s]Running 10000 simulations.:  64%|██████▍   | 6438/10000 [00:45<00:24, 144.19it/s]Running 10000 simulations.:  65%|██████▍   | 6453/10000 [00:45<00:24, 142.80it/s]Running 10000 simulations.:  65%|██████▍   | 6468/10000 [00:45<00:24, 142.64it/s]Running 10000 simulations.:  65%|██████▍   | 6483/10000 [00:45<00:24, 141.55it/s]Running 10000 simulations.:  65%|██████▍   | 6498/10000 [00:45<00:24, 142.39it/s]Running 10000 simulations.:  65%|██████▌   | 6513/10000 [00:45<00:24, 143.47it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:45<00:24, 143.33it/s]Running 10000 simulations.:  65%|██████▌   | 6543/10000 [00:45<00:23, 144.62it/s]Running 10000 simulations.:  66%|██████▌   | 6558/10000 [00:45<00:23, 145.20it/s]Running 10000 simulations.:  66%|██████▌   | 6573/10000 [00:46<00:23, 145.74it/s]Running 10000 simulations.:  66%|██████▌   | 6588/10000 [00:46<00:23, 144.53it/s]Running 10000 simulations.:  66%|██████▌   | 6603/10000 [00:46<00:23, 143.06it/s]Running 10000 simulations.:  66%|██████▌   | 6618/10000 [00:46<00:23, 142.61it/s]Running 10000 simulations.:  66%|██████▋   | 6633/10000 [00:46<00:23, 143.10it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:46<00:23, 142.75it/s]Running 10000 simulations.:  67%|██████▋   | 6663/10000 [00:46<00:23, 144.39it/s]Running 10000 simulations.:  67%|██████▋   | 6678/10000 [00:46<00:22, 144.53it/s]Running 10000 simulations.:  67%|██████▋   | 6693/10000 [00:46<00:22, 145.05it/s]Running 10000 simulations.:  67%|██████▋   | 6708/10000 [00:46<00:22, 145.49it/s]Running 10000 simulations.:  67%|██████▋   | 6723/10000 [00:47<00:22, 144.52it/s]Running 10000 simulations.:  67%|██████▋   | 6738/10000 [00:47<00:22, 143.16it/s]Running 10000 simulations.:  68%|██████▊   | 6754/10000 [00:47<00:21, 147.58it/s]Running 10000 simulations.:  68%|██████▊   | 6770/10000 [00:47<00:21, 151.03it/s]Running 10000 simulations.:  68%|██████▊   | 6787/10000 [00:47<00:20, 153.95it/s]Running 10000 simulations.:  68%|██████▊   | 6803/10000 [00:47<00:20, 153.11it/s]Running 10000 simulations.:  68%|██████▊   | 6819/10000 [00:47<00:21, 150.03it/s]Running 10000 simulations.:  68%|██████▊   | 6835/10000 [00:47<00:21, 148.57it/s]Running 10000 simulations.:  69%|██████▊   | 6851/10000 [00:47<00:20, 151.26it/s]Running 10000 simulations.:  69%|██████▊   | 6868/10000 [00:48<00:20, 154.41it/s]Running 10000 simulations.:  69%|██████▉   | 6885/10000 [00:48<00:19, 156.79it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:48<00:19, 158.62it/s]Running 10000 simulations.:  69%|██████▉   | 6919/10000 [00:48<00:19, 159.85it/s]Running 10000 simulations.:  69%|██████▉   | 6936/10000 [00:48<00:19, 158.67it/s]Running 10000 simulations.:  70%|██████▉   | 6952/10000 [00:48<00:19, 157.39it/s]Running 10000 simulations.:  70%|██████▉   | 6969/10000 [00:48<00:19, 159.29it/s]Running 10000 simulations.:  70%|██████▉   | 6986/10000 [00:48<00:18, 159.49it/s]Running 10000 simulations.:  70%|███████   | 7002/10000 [00:48<00:18, 158.35it/s]Running 10000 simulations.:  70%|███████   | 7022/10000 [00:48<00:17, 167.57it/s]Running 10000 simulations.:  70%|███████   | 7045/10000 [00:49<00:16, 180.99it/s]Running 10000 simulations.:  71%|███████   | 7068/10000 [00:49<00:15, 192.62it/s]Running 10000 simulations.:  71%|███████   | 7092/10000 [00:49<00:14, 202.75it/s]Running 10000 simulations.:  71%|███████   | 7115/10000 [00:49<00:13, 207.50it/s]Running 10000 simulations.:  71%|███████▏  | 7138/10000 [00:49<00:13, 213.09it/s]Running 10000 simulations.:  72%|███████▏  | 7161/10000 [00:49<00:13, 217.47it/s]Running 10000 simulations.:  72%|███████▏  | 7184/10000 [00:49<00:12, 220.73it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:49<00:12, 223.28it/s]Running 10000 simulations.:  72%|███████▏  | 7231/10000 [00:49<00:12, 225.60it/s]Running 10000 simulations.:  73%|███████▎  | 7254/10000 [00:50<00:12, 226.04it/s]Running 10000 simulations.:  73%|███████▎  | 7277/10000 [00:50<00:12, 226.60it/s]Running 10000 simulations.:  73%|███████▎  | 7300/10000 [00:50<00:11, 226.96it/s]Running 10000 simulations.:  73%|███████▎  | 7323/10000 [00:50<00:11, 224.78it/s]Running 10000 simulations.:  73%|███████▎  | 7346/10000 [00:50<00:11, 223.23it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:50<00:11, 223.85it/s]Running 10000 simulations.:  74%|███████▍  | 7392/10000 [00:50<00:11, 225.21it/s]Running 10000 simulations.:  74%|███████▍  | 7415/10000 [00:50<00:11, 225.40it/s]Running 10000 simulations.:  74%|███████▍  | 7439/10000 [00:50<00:11, 227.06it/s]Running 10000 simulations.:  75%|███████▍  | 7462/10000 [00:50<00:11, 227.32it/s]Running 10000 simulations.:  75%|███████▍  | 7486/10000 [00:51<00:11, 228.32it/s]Running 10000 simulations.:  75%|███████▌  | 7509/10000 [00:51<00:10, 228.54it/s]Running 10000 simulations.:  75%|███████▌  | 7532/10000 [00:51<00:11, 223.32it/s]Running 10000 simulations.:  76%|███████▌  | 7555/10000 [00:51<00:10, 223.68it/s]Running 10000 simulations.:  76%|███████▌  | 7578/10000 [00:51<00:10, 224.30it/s]Running 10000 simulations.:  76%|███████▌  | 7601/10000 [00:51<00:10, 225.17it/s]Running 10000 simulations.:  76%|███████▌  | 7624/10000 [00:51<00:10, 226.18it/s]Running 10000 simulations.:  76%|███████▋  | 7648/10000 [00:51<00:10, 227.81it/s]Running 10000 simulations.:  77%|███████▋  | 7672/10000 [00:51<00:10, 228.57it/s]Running 10000 simulations.:  77%|███████▋  | 7696/10000 [00:51<00:10, 229.12it/s]Running 10000 simulations.:  77%|███████▋  | 7720/10000 [00:52<00:09, 229.80it/s]Running 10000 simulations.:  77%|███████▋  | 7743/10000 [00:52<00:09, 227.15it/s]Running 10000 simulations.:  78%|███████▊  | 7766/10000 [00:52<00:09, 225.32it/s]Running 10000 simulations.:  78%|███████▊  | 7789/10000 [00:52<00:09, 223.71it/s]Running 10000 simulations.:  78%|███████▊  | 7812/10000 [00:52<00:09, 224.35it/s]Running 10000 simulations.:  78%|███████▊  | 7835/10000 [00:52<00:09, 224.49it/s]Running 10000 simulations.:  79%|███████▊  | 7858/10000 [00:52<00:09, 225.19it/s]Running 10000 simulations.:  79%|███████▉  | 7881/10000 [00:52<00:09, 226.33it/s]Running 10000 simulations.:  79%|███████▉  | 7904/10000 [00:52<00:09, 226.55it/s]Running 10000 simulations.:  79%|███████▉  | 7927/10000 [00:52<00:09, 226.96it/s]Running 10000 simulations.:  80%|███████▉  | 7950/10000 [00:53<00:09, 225.95it/s]Running 10000 simulations.:  80%|███████▉  | 7973/10000 [00:53<00:09, 222.46it/s]Running 10000 simulations.:  80%|███████▉  | 7996/10000 [00:53<00:08, 223.84it/s]Running 10000 simulations.:  80%|████████  | 8019/10000 [00:53<00:08, 224.34it/s]Running 10000 simulations.:  80%|████████  | 8042/10000 [00:53<00:08, 224.86it/s]Running 10000 simulations.:  81%|████████  | 8065/10000 [00:53<00:08, 224.71it/s]Running 10000 simulations.:  81%|████████  | 8088/10000 [00:53<00:08, 225.03it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:53<00:08, 225.64it/s]Running 10000 simulations.:  81%|████████▏ | 8134/10000 [00:53<00:08, 226.54it/s]Running 10000 simulations.:  82%|████████▏ | 8157/10000 [00:54<00:08, 224.70it/s]Running 10000 simulations.:  82%|████████▏ | 8180/10000 [00:54<00:08, 220.81it/s]Running 10000 simulations.:  82%|████████▏ | 8203/10000 [00:54<00:08, 220.49it/s]Running 10000 simulations.:  82%|████████▏ | 8226/10000 [00:54<00:08, 220.27it/s]Running 10000 simulations.:  82%|████████▏ | 8249/10000 [00:54<00:07, 220.18it/s]Running 10000 simulations.:  83%|████████▎ | 8272/10000 [00:54<00:07, 220.71it/s]Running 10000 simulations.:  83%|████████▎ | 8295/10000 [00:54<00:07, 222.80it/s]Running 10000 simulations.:  83%|████████▎ | 8318/10000 [00:54<00:07, 224.03it/s]Running 10000 simulations.:  83%|████████▎ | 8341/10000 [00:54<00:07, 224.87it/s]Running 10000 simulations.:  84%|████████▎ | 8364/10000 [00:54<00:07, 226.22it/s]Running 10000 simulations.:  84%|████████▍ | 8387/10000 [00:55<00:07, 225.12it/s]Running 10000 simulations.:  84%|████████▍ | 8410/10000 [00:55<00:07, 223.30it/s]Running 10000 simulations.:  84%|████████▍ | 8433/10000 [00:55<00:07, 223.34it/s]Running 10000 simulations.:  85%|████████▍ | 8456/10000 [00:55<00:06, 223.35it/s]Running 10000 simulations.:  85%|████████▍ | 8479/10000 [00:55<00:06, 223.43it/s]Running 10000 simulations.:  85%|████████▌ | 8502/10000 [00:55<00:06, 224.73it/s]Running 10000 simulations.:  85%|████████▌ | 8525/10000 [00:55<00:06, 225.09it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:55<00:06, 225.03it/s]Running 10000 simulations.:  86%|████████▌ | 8571/10000 [00:55<00:06, 221.76it/s]Running 10000 simulations.:  86%|████████▌ | 8594/10000 [00:55<00:06, 221.54it/s]Running 10000 simulations.:  86%|████████▌ | 8617/10000 [00:56<00:06, 221.73it/s]Running 10000 simulations.:  86%|████████▋ | 8640/10000 [00:56<00:06, 221.25it/s]Running 10000 simulations.:  87%|████████▋ | 8663/10000 [00:56<00:06, 221.17it/s]Running 10000 simulations.:  87%|████████▋ | 8686/10000 [00:56<00:05, 221.80it/s]Running 10000 simulations.:  87%|████████▋ | 8709/10000 [00:56<00:05, 219.47it/s]Running 10000 simulations.:  87%|████████▋ | 8731/10000 [00:56<00:05, 216.70it/s]Running 10000 simulations.:  88%|████████▊ | 8754/10000 [00:56<00:05, 219.10it/s]Running 10000 simulations.:  88%|████████▊ | 8777/10000 [00:56<00:05, 221.84it/s]Running 10000 simulations.:  88%|████████▊ | 8800/10000 [00:56<00:05, 223.45it/s]Running 10000 simulations.:  88%|████████▊ | 8824/10000 [00:57<00:05, 225.72it/s]Running 10000 simulations.:  88%|████████▊ | 8847/10000 [00:57<00:05, 226.95it/s]Running 10000 simulations.:  89%|████████▊ | 8871/10000 [00:57<00:04, 228.21it/s]Running 10000 simulations.:  89%|████████▉ | 8895/10000 [00:57<00:04, 229.83it/s]Running 10000 simulations.:  89%|████████▉ | 8918/10000 [00:57<00:04, 228.29it/s]Running 10000 simulations.:  89%|████████▉ | 8941/10000 [00:57<00:04, 227.63it/s]Running 10000 simulations.:  90%|████████▉ | 8964/10000 [00:57<00:04, 227.39it/s]Running 10000 simulations.:  90%|████████▉ | 8987/10000 [00:57<00:04, 227.31it/s]Running 10000 simulations.:  90%|█████████ | 9010/10000 [00:57<00:04, 227.65it/s]Running 10000 simulations.:  90%|█████████ | 9033/10000 [00:57<00:04, 228.29it/s]Running 10000 simulations.:  91%|█████████ | 9057/10000 [00:58<00:04, 228.93it/s]Running 10000 simulations.:  91%|█████████ | 9081/10000 [00:58<00:03, 230.21it/s]Running 10000 simulations.:  91%|█████████ | 9105/10000 [00:58<00:03, 232.12it/s]Running 10000 simulations.:  91%|█████████▏| 9129/10000 [00:58<00:03, 229.24it/s]Running 10000 simulations.:  92%|█████████▏| 9152/10000 [00:58<00:03, 226.76it/s]Running 10000 simulations.:  92%|█████████▏| 9175/10000 [00:58<00:03, 226.55it/s]Running 10000 simulations.:  92%|█████████▏| 9198/10000 [00:58<00:03, 226.85it/s]Running 10000 simulations.:  92%|█████████▏| 9221/10000 [00:58<00:03, 227.47it/s]Running 10000 simulations.:  92%|█████████▏| 9245/10000 [00:58<00:03, 228.27it/s]Running 10000 simulations.:  93%|█████████▎| 9268/10000 [00:58<00:03, 227.88it/s]Running 10000 simulations.:  93%|█████████▎| 9291/10000 [00:59<00:03, 227.57it/s]Running 10000 simulations.:  93%|█████████▎| 9315/10000 [00:59<00:02, 229.77it/s]Running 10000 simulations.:  93%|█████████▎| 9338/10000 [00:59<00:02, 227.94it/s]Running 10000 simulations.:  94%|█████████▎| 9361/10000 [00:59<00:02, 226.72it/s]Running 10000 simulations.:  94%|█████████▍| 9384/10000 [00:59<00:02, 225.15it/s]Running 10000 simulations.:  94%|█████████▍| 9407/10000 [00:59<00:02, 224.96it/s]Running 10000 simulations.:  94%|█████████▍| 9430/10000 [00:59<00:02, 225.91it/s]Running 10000 simulations.:  95%|█████████▍| 9454/10000 [00:59<00:02, 228.13it/s]Running 10000 simulations.:  95%|█████████▍| 9478/10000 [00:59<00:02, 229.40it/s]Running 10000 simulations.:  95%|█████████▌| 9502/10000 [00:59<00:02, 230.32it/s]Running 10000 simulations.:  95%|█████████▌| 9526/10000 [01:00<00:02, 231.82it/s]Running 10000 simulations.:  96%|█████████▌| 9550/10000 [01:00<00:01, 229.98it/s]Running 10000 simulations.:  96%|█████████▌| 9574/10000 [01:00<00:01, 228.14it/s]Running 10000 simulations.:  96%|█████████▌| 9597/10000 [01:00<00:01, 228.32it/s]Running 10000 simulations.:  96%|█████████▌| 9621/10000 [01:00<00:01, 229.73it/s]Running 10000 simulations.:  96%|█████████▋| 9645/10000 [01:00<00:01, 230.06it/s]Running 10000 simulations.:  97%|█████████▋| 9669/10000 [01:00<00:01, 230.84it/s]Running 10000 simulations.:  97%|█████████▋| 9693/10000 [01:00<00:01, 231.42it/s]Running 10000 simulations.:  97%|█████████▋| 9717/10000 [01:00<00:01, 232.28it/s]Running 10000 simulations.:  97%|█████████▋| 9741/10000 [01:01<00:01, 232.27it/s]Running 10000 simulations.:  98%|█████████▊| 9765/10000 [01:01<00:01, 231.06it/s]Running 10000 simulations.:  98%|█████████▊| 9789/10000 [01:01<00:00, 230.50it/s]Running 10000 simulations.:  98%|█████████▊| 9813/10000 [01:01<00:00, 231.09it/s]Running 10000 simulations.:  98%|█████████▊| 9837/10000 [01:01<00:00, 231.74it/s]Running 10000 simulations.:  99%|█████████▊| 9861/10000 [01:01<00:00, 232.86it/s]Running 10000 simulations.:  99%|█████████▉| 9885/10000 [01:01<00:00, 233.03it/s]Running 10000 simulations.:  99%|█████████▉| 9909/10000 [01:01<00:00, 233.52it/s]Running 10000 simulations.:  99%|█████████▉| 9933/10000 [01:01<00:00, 233.76it/s]Running 10000 simulations.: 100%|█████████▉| 9957/10000 [01:01<00:00, 234.66it/s]Running 10000 simulations.: 100%|█████████▉| 9981/10000 [01:02<00:00, 233.57it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:02<00:00, 160.97it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 25/10000 [00:00<00:41, 241.26it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<00:41, 242.43it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<00:40, 243.25it/s]Running 10000 simulations.:   1%|          | 100/10000 [00:00<00:40, 244.03it/s]Running 10000 simulations.:   1%|▏         | 125/10000 [00:00<00:40, 244.15it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:40, 244.03it/s]Running 10000 simulations.:   2%|▏         | 175/10000 [00:00<00:40, 244.14it/s]Running 10000 simulations.:   2%|▏         | 200/10000 [00:00<00:40, 243.65it/s]Running 10000 simulations.:   2%|▏         | 225/10000 [00:00<00:40, 243.04it/s]Running 10000 simulations.:   2%|▎         | 250/10000 [00:01<00:40, 242.38it/s]Running 10000 simulations.:   3%|▎         | 274/10000 [00:01<00:40, 241.60it/s]Running 10000 simulations.:   3%|▎         | 299/10000 [00:01<00:40, 241.96it/s]Running 10000 simulations.:   3%|▎         | 324/10000 [00:01<00:39, 242.18it/s]Running 10000 simulations.:   3%|▎         | 349/10000 [00:01<00:39, 242.20it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:01<00:39, 241.33it/s]Running 10000 simulations.:   4%|▍         | 399/10000 [00:01<00:39, 240.39it/s]Running 10000 simulations.:   4%|▍         | 423/10000 [00:01<00:39, 240.14it/s]Running 10000 simulations.:   4%|▍         | 447/10000 [00:01<00:39, 239.53it/s]Running 10000 simulations.:   5%|▍         | 471/10000 [00:01<00:39, 239.17it/s]Running 10000 simulations.:   5%|▍         | 495/10000 [00:02<00:39, 238.82it/s]Running 10000 simulations.:   5%|▌         | 519/10000 [00:02<00:39, 238.82it/s]Running 10000 simulations.:   5%|▌         | 543/10000 [00:02<00:39, 238.92it/s]Running 10000 simulations.:   6%|▌         | 567/10000 [00:02<00:39, 238.57it/s]Running 10000 simulations.:   6%|▌         | 591/10000 [00:02<00:39, 238.53it/s]Running 10000 simulations.:   6%|▌         | 615/10000 [00:02<00:39, 238.44it/s]Running 10000 simulations.:   6%|▋         | 639/10000 [00:02<00:39, 238.30it/s]Running 10000 simulations.:   7%|▋         | 663/10000 [00:02<00:39, 238.56it/s]Running 10000 simulations.:   7%|▋         | 687/10000 [00:02<00:39, 238.55it/s]Running 10000 simulations.:   7%|▋         | 711/10000 [00:02<00:38, 238.47it/s]Running 10000 simulations.:   7%|▋         | 735/10000 [00:03<00:38, 238.78it/s]Running 10000 simulations.:   8%|▊         | 759/10000 [00:03<00:38, 238.97it/s]Running 10000 simulations.:   8%|▊         | 784/10000 [00:03<00:38, 239.64it/s]Running 10000 simulations.:   8%|▊         | 808/10000 [00:03<00:38, 239.42it/s]Running 10000 simulations.:   8%|▊         | 832/10000 [00:03<00:38, 238.59it/s]Running 10000 simulations.:   9%|▊         | 856/10000 [00:03<00:38, 237.56it/s]Running 10000 simulations.:   9%|▉         | 880/10000 [00:03<00:38, 237.33it/s]Running 10000 simulations.:   9%|▉         | 904/10000 [00:03<00:38, 236.58it/s]Running 10000 simulations.:   9%|▉         | 928/10000 [00:03<00:38, 236.41it/s]Running 10000 simulations.:  10%|▉         | 952/10000 [00:03<00:38, 236.84it/s]Running 10000 simulations.:  10%|▉         | 976/10000 [00:04<00:38, 236.72it/s]Running 10000 simulations.:  10%|█         | 1000/10000 [00:04<00:38, 236.43it/s]Running 10000 simulations.:  10%|█         | 1024/10000 [00:04<00:38, 235.13it/s]Running 10000 simulations.:  10%|█         | 1048/10000 [00:04<00:38, 232.14it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:04<00:38, 233.26it/s]Running 10000 simulations.:  11%|█         | 1096/10000 [00:04<00:37, 234.35it/s]Running 10000 simulations.:  11%|█         | 1121/10000 [00:04<00:37, 236.26it/s]Running 10000 simulations.:  11%|█▏        | 1145/10000 [00:04<00:37, 236.68it/s]Running 10000 simulations.:  12%|█▏        | 1169/10000 [00:04<00:37, 237.24it/s]Running 10000 simulations.:  12%|█▏        | 1193/10000 [00:04<00:37, 236.77it/s]Running 10000 simulations.:  12%|█▏        | 1217/10000 [00:05<00:37, 237.17it/s]Running 10000 simulations.:  12%|█▏        | 1241/10000 [00:05<00:36, 237.55it/s]Running 10000 simulations.:  13%|█▎        | 1265/10000 [00:05<00:36, 237.06it/s]Running 10000 simulations.:  13%|█▎        | 1289/10000 [00:05<00:36, 236.77it/s]Running 10000 simulations.:  13%|█▎        | 1313/10000 [00:05<00:36, 236.46it/s]Running 10000 simulations.:  13%|█▎        | 1337/10000 [00:05<00:36, 236.41it/s]Running 10000 simulations.:  14%|█▎        | 1361/10000 [00:05<00:36, 237.09it/s]Running 10000 simulations.:  14%|█▍        | 1385/10000 [00:05<00:36, 237.85it/s]Running 10000 simulations.:  14%|█▍        | 1409/10000 [00:05<00:36, 235.88it/s]Running 10000 simulations.:  14%|█▍        | 1433/10000 [00:06<00:36, 231.80it/s]Running 10000 simulations.:  15%|█▍        | 1457/10000 [00:06<00:36, 231.38it/s]Running 10000 simulations.:  15%|█▍        | 1481/10000 [00:06<00:36, 232.19it/s]Running 10000 simulations.:  15%|█▌        | 1505/10000 [00:06<00:36, 233.03it/s]Running 10000 simulations.:  15%|█▌        | 1529/10000 [00:06<00:36, 232.73it/s]Running 10000 simulations.:  16%|█▌        | 1553/10000 [00:06<00:36, 232.71it/s]Running 10000 simulations.:  16%|█▌        | 1577/10000 [00:06<00:36, 233.49it/s]Running 10000 simulations.:  16%|█▌        | 1601/10000 [00:06<00:36, 233.24it/s]Running 10000 simulations.:  16%|█▋        | 1625/10000 [00:06<00:35, 233.22it/s]Running 10000 simulations.:  16%|█▋        | 1649/10000 [00:06<00:35, 232.91it/s]Running 10000 simulations.:  17%|█▋        | 1673/10000 [00:07<00:37, 221.07it/s]Running 10000 simulations.:  17%|█▋        | 1696/10000 [00:07<00:37, 222.24it/s]Running 10000 simulations.:  17%|█▋        | 1720/10000 [00:07<00:36, 225.65it/s]Running 10000 simulations.:  17%|█▋        | 1744/10000 [00:07<00:36, 227.38it/s]Running 10000 simulations.:  18%|█▊        | 1768/10000 [00:07<00:36, 228.17it/s]Running 10000 simulations.:  18%|█▊        | 1792/10000 [00:07<00:35, 229.26it/s]Running 10000 simulations.:  18%|█▊        | 1816/10000 [00:07<00:35, 229.79it/s]Running 10000 simulations.:  18%|█▊        | 1840/10000 [00:07<00:35, 230.29it/s]Running 10000 simulations.:  19%|█▊        | 1864/10000 [00:07<00:35, 231.22it/s]Running 10000 simulations.:  19%|█▉        | 1888/10000 [00:07<00:35, 230.82it/s]Running 10000 simulations.:  19%|█▉        | 1912/10000 [00:08<00:35, 230.92it/s]Running 10000 simulations.:  19%|█▉        | 1936/10000 [00:08<00:34, 231.17it/s]Running 10000 simulations.:  20%|█▉        | 1960/10000 [00:08<00:34, 231.41it/s]Running 10000 simulations.:  20%|█▉        | 1984/10000 [00:08<00:34, 231.24it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:08<00:34, 231.54it/s]Running 10000 simulations.:  20%|██        | 2032/10000 [00:08<00:34, 231.00it/s]Running 10000 simulations.:  21%|██        | 2056/10000 [00:08<00:34, 231.13it/s]Running 10000 simulations.:  21%|██        | 2080/10000 [00:08<00:34, 231.13it/s]Running 10000 simulations.:  21%|██        | 2104/10000 [00:08<00:34, 231.16it/s]Running 10000 simulations.:  21%|██▏       | 2128/10000 [00:09<00:34, 231.27it/s]Running 10000 simulations.:  22%|██▏       | 2152/10000 [00:09<00:33, 231.81it/s]Running 10000 simulations.:  22%|██▏       | 2176/10000 [00:09<00:33, 231.97it/s]Running 10000 simulations.:  22%|██▏       | 2200/10000 [00:09<00:33, 231.12it/s]Running 10000 simulations.:  22%|██▏       | 2224/10000 [00:09<00:33, 230.35it/s]Running 10000 simulations.:  22%|██▏       | 2248/10000 [00:09<00:33, 230.78it/s]Running 10000 simulations.:  23%|██▎       | 2272/10000 [00:09<00:33, 231.08it/s]Running 10000 simulations.:  23%|██▎       | 2296/10000 [00:09<00:33, 231.17it/s]Running 10000 simulations.:  23%|██▎       | 2320/10000 [00:09<00:33, 231.35it/s]Running 10000 simulations.:  23%|██▎       | 2344/10000 [00:09<00:33, 231.08it/s]Running 10000 simulations.:  24%|██▎       | 2368/10000 [00:10<00:33, 230.81it/s]Running 10000 simulations.:  24%|██▍       | 2392/10000 [00:10<00:32, 231.10it/s]Running 10000 simulations.:  24%|██▍       | 2416/10000 [00:10<00:32, 232.35it/s]Running 10000 simulations.:  24%|██▍       | 2440/10000 [00:10<00:32, 233.23it/s]Running 10000 simulations.:  25%|██▍       | 2464/10000 [00:10<00:32, 232.68it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:10<00:32, 232.69it/s]Running 10000 simulations.:  25%|██▌       | 2512/10000 [00:10<00:32, 233.39it/s]Running 10000 simulations.:  25%|██▌       | 2536/10000 [00:10<00:31, 233.77it/s]Running 10000 simulations.:  26%|██▌       | 2560/10000 [00:10<00:31, 233.47it/s]Running 10000 simulations.:  26%|██▌       | 2584/10000 [00:10<00:31, 233.57it/s]Running 10000 simulations.:  26%|██▌       | 2608/10000 [00:11<00:31, 234.39it/s]Running 10000 simulations.:  26%|██▋       | 2632/10000 [00:11<00:31, 234.13it/s]Running 10000 simulations.:  27%|██▋       | 2656/10000 [00:11<00:31, 234.02it/s]Running 10000 simulations.:  27%|██▋       | 2680/10000 [00:11<00:31, 234.18it/s]Running 10000 simulations.:  27%|██▋       | 2704/10000 [00:11<00:31, 234.03it/s]Running 10000 simulations.:  27%|██▋       | 2728/10000 [00:11<00:31, 233.50it/s]Running 10000 simulations.:  28%|██▊       | 2752/10000 [00:11<00:31, 233.07it/s]Running 10000 simulations.:  28%|██▊       | 2776/10000 [00:11<00:31, 232.88it/s]Running 10000 simulations.:  28%|██▊       | 2800/10000 [00:11<00:30, 232.57it/s]Running 10000 simulations.:  28%|██▊       | 2824/10000 [00:12<00:30, 232.26it/s]Running 10000 simulations.:  28%|██▊       | 2848/10000 [00:12<00:30, 232.01it/s]Running 10000 simulations.:  29%|██▊       | 2872/10000 [00:12<00:30, 232.25it/s]Running 10000 simulations.:  29%|██▉       | 2896/10000 [00:12<00:30, 232.25it/s]Running 10000 simulations.:  29%|██▉       | 2920/10000 [00:12<00:30, 232.25it/s]Running 10000 simulations.:  29%|██▉       | 2944/10000 [00:12<00:30, 232.28it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:12<00:30, 231.82it/s]Running 10000 simulations.:  30%|██▉       | 2992/10000 [00:12<00:30, 231.34it/s]Running 10000 simulations.:  30%|███       | 3016/10000 [00:12<00:30, 231.23it/s]Running 10000 simulations.:  30%|███       | 3040/10000 [00:12<00:30, 231.16it/s]Running 10000 simulations.:  31%|███       | 3064/10000 [00:13<00:30, 230.98it/s]Running 10000 simulations.:  31%|███       | 3088/10000 [00:13<00:29, 230.66it/s]Running 10000 simulations.:  31%|███       | 3112/10000 [00:13<00:29, 230.99it/s]Running 10000 simulations.:  31%|███▏      | 3136/10000 [00:13<00:29, 230.81it/s]Running 10000 simulations.:  32%|███▏      | 3160/10000 [00:13<00:29, 230.82it/s]Running 10000 simulations.:  32%|███▏      | 3184/10000 [00:13<00:29, 230.89it/s]Running 10000 simulations.:  32%|███▏      | 3208/10000 [00:13<00:29, 230.84it/s]Running 10000 simulations.:  32%|███▏      | 3232/10000 [00:13<00:29, 231.10it/s]Running 10000 simulations.:  33%|███▎      | 3256/10000 [00:13<00:29, 231.04it/s]Running 10000 simulations.:  33%|███▎      | 3280/10000 [00:13<00:29, 230.48it/s]Running 10000 simulations.:  33%|███▎      | 3304/10000 [00:14<00:29, 230.24it/s]Running 10000 simulations.:  33%|███▎      | 3328/10000 [00:14<00:28, 230.18it/s]Running 10000 simulations.:  34%|███▎      | 3352/10000 [00:14<00:28, 230.28it/s]Running 10000 simulations.:  34%|███▍      | 3376/10000 [00:14<00:28, 230.42it/s]Running 10000 simulations.:  34%|███▍      | 3400/10000 [00:14<00:28, 230.28it/s]Running 10000 simulations.:  34%|███▍      | 3424/10000 [00:14<00:28, 230.73it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:14<00:28, 231.07it/s]Running 10000 simulations.:  35%|███▍      | 3472/10000 [00:14<00:28, 231.42it/s]Running 10000 simulations.:  35%|███▍      | 3496/10000 [00:14<00:28, 230.90it/s]Running 10000 simulations.:  35%|███▌      | 3520/10000 [00:15<00:28, 230.61it/s]Running 10000 simulations.:  35%|███▌      | 3544/10000 [00:15<00:27, 231.42it/s]Running 10000 simulations.:  36%|███▌      | 3568/10000 [00:15<00:27, 232.16it/s]Running 10000 simulations.:  36%|███▌      | 3592/10000 [00:15<00:27, 231.94it/s]Running 10000 simulations.:  36%|███▌      | 3616/10000 [00:15<00:27, 231.84it/s]Running 10000 simulations.:  36%|███▋      | 3640/10000 [00:15<00:27, 232.04it/s]Running 10000 simulations.:  37%|███▋      | 3664/10000 [00:15<00:27, 231.65it/s]Running 10000 simulations.:  37%|███▋      | 3688/10000 [00:15<00:27, 231.51it/s]Running 10000 simulations.:  37%|███▋      | 3712/10000 [00:15<00:27, 231.73it/s]Running 10000 simulations.:  37%|███▋      | 3736/10000 [00:15<00:26, 232.50it/s]Running 10000 simulations.:  38%|███▊      | 3760/10000 [00:16<00:26, 231.84it/s]Running 10000 simulations.:  38%|███▊      | 3784/10000 [00:16<00:26, 232.08it/s]Running 10000 simulations.:  38%|███▊      | 3808/10000 [00:16<00:26, 232.49it/s]Running 10000 simulations.:  38%|███▊      | 3832/10000 [00:16<00:26, 231.53it/s]Running 10000 simulations.:  39%|███▊      | 3856/10000 [00:16<00:26, 231.66it/s]Running 10000 simulations.:  39%|███▉      | 3880/10000 [00:16<00:26, 231.97it/s]Running 10000 simulations.:  39%|███▉      | 3904/10000 [00:16<00:26, 231.74it/s]Running 10000 simulations.:  39%|███▉      | 3928/10000 [00:16<00:26, 231.76it/s]Running 10000 simulations.:  40%|███▉      | 3952/10000 [00:16<00:26, 231.31it/s]Running 10000 simulations.:  40%|███▉      | 3976/10000 [00:17<00:26, 231.03it/s]Running 10000 simulations.:  40%|████      | 4000/10000 [00:17<00:26, 230.70it/s]Running 10000 simulations.:  40%|████      | 4024/10000 [00:17<00:25, 231.80it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:17<00:25, 232.77it/s]Running 10000 simulations.:  41%|████      | 4072/10000 [00:17<00:25, 233.35it/s]Running 10000 simulations.:  41%|████      | 4096/10000 [00:17<00:25, 233.75it/s]Running 10000 simulations.:  41%|████      | 4120/10000 [00:17<00:25, 233.73it/s]Running 10000 simulations.:  41%|████▏     | 4144/10000 [00:17<00:25, 233.85it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:17<00:25, 233.15it/s]Running 10000 simulations.:  42%|████▏     | 4192/10000 [00:17<00:24, 232.94it/s]Running 10000 simulations.:  42%|████▏     | 4216/10000 [00:18<00:24, 233.03it/s]Running 10000 simulations.:  42%|████▏     | 4240/10000 [00:18<00:24, 233.17it/s]Running 10000 simulations.:  43%|████▎     | 4264/10000 [00:18<00:24, 232.21it/s]Running 10000 simulations.:  43%|████▎     | 4288/10000 [00:18<00:24, 231.81it/s]Running 10000 simulations.:  43%|████▎     | 4312/10000 [00:18<00:24, 231.39it/s]Running 10000 simulations.:  43%|████▎     | 4336/10000 [00:18<00:24, 231.51it/s]Running 10000 simulations.:  44%|████▎     | 4360/10000 [00:18<00:24, 231.94it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:18<00:24, 231.89it/s]Running 10000 simulations.:  44%|████▍     | 4408/10000 [00:18<00:24, 231.82it/s]Running 10000 simulations.:  44%|████▍     | 4432/10000 [00:18<00:23, 232.20it/s]Running 10000 simulations.:  45%|████▍     | 4456/10000 [00:19<00:23, 232.74it/s]Running 10000 simulations.:  45%|████▍     | 4480/10000 [00:19<00:23, 233.10it/s]Running 10000 simulations.:  45%|████▌     | 4504/10000 [00:19<00:23, 232.46it/s]Running 10000 simulations.:  45%|████▌     | 4528/10000 [00:19<00:23, 231.48it/s]Running 10000 simulations.:  46%|████▌     | 4552/10000 [00:19<00:23, 230.95it/s]Running 10000 simulations.:  46%|████▌     | 4576/10000 [00:19<00:23, 230.65it/s]Running 10000 simulations.:  46%|████▌     | 4600/10000 [00:19<00:23, 230.40it/s]Running 10000 simulations.:  46%|████▌     | 4624/10000 [00:19<00:23, 230.26it/s]Running 10000 simulations.:  46%|████▋     | 4648/10000 [00:19<00:23, 230.19it/s]Running 10000 simulations.:  47%|████▋     | 4672/10000 [00:20<00:23, 229.90it/s]Running 10000 simulations.:  47%|████▋     | 4695/10000 [00:20<00:23, 229.75it/s]Running 10000 simulations.:  47%|████▋     | 4719/10000 [00:20<00:22, 230.24it/s]Running 10000 simulations.:  47%|████▋     | 4743/10000 [00:20<00:22, 230.54it/s]Running 10000 simulations.:  48%|████▊     | 4767/10000 [00:20<00:22, 230.19it/s]Running 10000 simulations.:  48%|████▊     | 4791/10000 [00:20<00:22, 228.32it/s]Running 10000 simulations.:  48%|████▊     | 4814/10000 [00:20<00:22, 227.99it/s]Running 10000 simulations.:  48%|████▊     | 4837/10000 [00:20<00:22, 228.54it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:20<00:22, 228.94it/s]Running 10000 simulations.:  49%|████▉     | 4884/10000 [00:20<00:22, 229.26it/s]Running 10000 simulations.:  49%|████▉     | 4908/10000 [00:21<00:22, 229.51it/s]Running 10000 simulations.:  49%|████▉     | 4932/10000 [00:21<00:22, 229.82it/s]Running 10000 simulations.:  50%|████▉     | 4956/10000 [00:21<00:21, 230.32it/s]Running 10000 simulations.:  50%|████▉     | 4980/10000 [00:21<00:21, 230.09it/s]Running 10000 simulations.:  50%|█████     | 5004/10000 [00:21<00:21, 229.72it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:21<00:21, 229.35it/s]Running 10000 simulations.:  50%|█████     | 5050/10000 [00:21<00:21, 229.41it/s]Running 10000 simulations.:  51%|█████     | 5073/10000 [00:21<00:21, 229.58it/s]Running 10000 simulations.:  51%|█████     | 5097/10000 [00:21<00:21, 229.97it/s]Running 10000 simulations.:  51%|█████     | 5121/10000 [00:21<00:21, 230.05it/s]Running 10000 simulations.:  51%|█████▏    | 5145/10000 [00:22<00:21, 230.23it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:22<00:20, 230.77it/s]Running 10000 simulations.:  52%|█████▏    | 5193/10000 [00:22<00:20, 230.47it/s]Running 10000 simulations.:  52%|█████▏    | 5217/10000 [00:22<00:20, 229.68it/s]Running 10000 simulations.:  52%|█████▏    | 5241/10000 [00:22<00:20, 229.93it/s]Running 10000 simulations.:  53%|█████▎    | 5265/10000 [00:22<00:20, 230.45it/s]Running 10000 simulations.:  53%|█████▎    | 5289/10000 [00:22<00:20, 230.14it/s]Running 10000 simulations.:  53%|█████▎    | 5313/10000 [00:22<00:20, 229.95it/s]Running 10000 simulations.:  53%|█████▎    | 5336/10000 [00:22<00:20, 229.63it/s]Running 10000 simulations.:  54%|█████▎    | 5359/10000 [00:22<00:20, 229.07it/s]Running 10000 simulations.:  54%|█████▍    | 5382/10000 [00:23<00:20, 228.87it/s]Running 10000 simulations.:  54%|█████▍    | 5405/10000 [00:23<00:20, 228.19it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:23<00:20, 228.45it/s]Running 10000 simulations.:  55%|█████▍    | 5452/10000 [00:23<00:19, 229.02it/s]Running 10000 simulations.:  55%|█████▍    | 5476/10000 [00:23<00:19, 229.49it/s]Running 10000 simulations.:  55%|█████▍    | 5499/10000 [00:23<00:19, 229.64it/s]Running 10000 simulations.:  55%|█████▌    | 5522/10000 [00:23<00:19, 229.22it/s]Running 10000 simulations.:  55%|█████▌    | 5546/10000 [00:23<00:19, 229.64it/s]Running 10000 simulations.:  56%|█████▌    | 5569/10000 [00:23<00:19, 229.73it/s]Running 10000 simulations.:  56%|█████▌    | 5593/10000 [00:24<00:19, 229.93it/s]Running 10000 simulations.:  56%|█████▌    | 5616/10000 [00:24<00:19, 229.78it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:24<00:19, 229.34it/s]Running 10000 simulations.:  57%|█████▋    | 5662/10000 [00:24<00:18, 229.07it/s]Running 10000 simulations.:  57%|█████▋    | 5685/10000 [00:24<00:18, 229.21it/s]Running 10000 simulations.:  57%|█████▋    | 5708/10000 [00:24<00:18, 228.60it/s]Running 10000 simulations.:  57%|█████▋    | 5731/10000 [00:24<00:18, 228.60it/s]Running 10000 simulations.:  58%|█████▊    | 5754/10000 [00:24<00:18, 228.55it/s]Running 10000 simulations.:  58%|█████▊    | 5777/10000 [00:24<00:18, 228.82it/s]Running 10000 simulations.:  58%|█████▊    | 5800/10000 [00:24<00:18, 228.96it/s]Running 10000 simulations.:  58%|█████▊    | 5823/10000 [00:25<00:18, 228.40it/s]Running 10000 simulations.:  58%|█████▊    | 5846/10000 [00:25<00:18, 228.46it/s]Running 10000 simulations.:  59%|█████▊    | 5870/10000 [00:25<00:18, 229.16it/s]Running 10000 simulations.:  59%|█████▉    | 5893/10000 [00:25<00:17, 229.11it/s]Running 10000 simulations.:  59%|█████▉    | 5917/10000 [00:25<00:17, 229.49it/s]Running 10000 simulations.:  59%|█████▉    | 5941/10000 [00:25<00:17, 229.86it/s]Running 10000 simulations.:  60%|█████▉    | 5964/10000 [00:25<00:17, 229.86it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:25<00:17, 229.63it/s]Running 10000 simulations.:  60%|██████    | 6010/10000 [00:25<00:17, 228.95it/s]Running 10000 simulations.:  60%|██████    | 6033/10000 [00:25<00:17, 228.21it/s]Running 10000 simulations.:  61%|██████    | 6056/10000 [00:26<00:17, 227.93it/s]Running 10000 simulations.:  61%|██████    | 6079/10000 [00:26<00:17, 227.33it/s]Running 10000 simulations.:  61%|██████    | 6102/10000 [00:26<00:17, 227.08it/s]Running 10000 simulations.:  61%|██████▏   | 6125/10000 [00:26<00:17, 227.26it/s]Running 10000 simulations.:  61%|██████▏   | 6148/10000 [00:26<00:16, 227.37it/s]Running 10000 simulations.:  62%|██████▏   | 6171/10000 [00:26<00:16, 227.35it/s]Running 10000 simulations.:  62%|██████▏   | 6194/10000 [00:26<00:16, 227.17it/s]Running 10000 simulations.:  62%|██████▏   | 6217/10000 [00:26<00:16, 227.42it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:26<00:16, 228.16it/s]Running 10000 simulations.:  63%|██████▎   | 6263/10000 [00:26<00:16, 228.12it/s]Running 10000 simulations.:  63%|██████▎   | 6286/10000 [00:27<00:16, 228.01it/s]Running 10000 simulations.:  63%|██████▎   | 6309/10000 [00:27<00:16, 228.36it/s]Running 10000 simulations.:  63%|██████▎   | 6332/10000 [00:27<00:16, 228.70it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:27<00:15, 229.28it/s]Running 10000 simulations.:  64%|██████▍   | 6379/10000 [00:27<00:15, 229.26it/s]Running 10000 simulations.:  64%|██████▍   | 6402/10000 [00:27<00:15, 228.68it/s]Running 10000 simulations.:  64%|██████▍   | 6425/10000 [00:27<00:15, 228.79it/s]Running 10000 simulations.:  64%|██████▍   | 6448/10000 [00:27<00:15, 228.36it/s]Running 10000 simulations.:  65%|██████▍   | 6471/10000 [00:27<00:15, 227.84it/s]Running 10000 simulations.:  65%|██████▍   | 6494/10000 [00:27<00:15, 228.06it/s]Running 10000 simulations.:  65%|██████▌   | 6517/10000 [00:28<00:15, 228.20it/s]Running 10000 simulations.:  65%|██████▌   | 6540/10000 [00:28<00:15, 228.11it/s]Running 10000 simulations.:  66%|██████▌   | 6563/10000 [00:28<00:15, 227.77it/s]Running 10000 simulations.:  66%|██████▌   | 6586/10000 [00:28<00:14, 227.62it/s]Running 10000 simulations.:  66%|██████▌   | 6609/10000 [00:28<00:14, 227.99it/s]Running 10000 simulations.:  66%|██████▋   | 6632/10000 [00:28<00:14, 228.16it/s]Running 10000 simulations.:  67%|██████▋   | 6655/10000 [00:28<00:14, 228.25it/s]Running 10000 simulations.:  67%|██████▋   | 6678/10000 [00:28<00:14, 228.40it/s]Running 10000 simulations.:  67%|██████▋   | 6701/10000 [00:28<00:14, 228.77it/s]Running 10000 simulations.:  67%|██████▋   | 6724/10000 [00:28<00:14, 228.87it/s]Running 10000 simulations.:  67%|██████▋   | 6747/10000 [00:29<00:14, 228.83it/s]Running 10000 simulations.:  68%|██████▊   | 6770/10000 [00:29<00:14, 228.52it/s]Running 10000 simulations.:  68%|██████▊   | 6793/10000 [00:29<00:14, 226.21it/s]Running 10000 simulations.:  68%|██████▊   | 6816/10000 [00:29<00:14, 226.42it/s]Running 10000 simulations.:  68%|██████▊   | 6839/10000 [00:29<00:13, 227.45it/s]Running 10000 simulations.:  69%|██████▊   | 6862/10000 [00:29<00:13, 228.06it/s]Running 10000 simulations.:  69%|██████▉   | 6885/10000 [00:29<00:13, 227.89it/s]Running 10000 simulations.:  69%|██████▉   | 6908/10000 [00:29<00:13, 223.32it/s]Running 10000 simulations.:  69%|██████▉   | 6931/10000 [00:29<00:13, 224.50it/s]Running 10000 simulations.:  70%|██████▉   | 6954/10000 [00:29<00:13, 225.48it/s]Running 10000 simulations.:  70%|██████▉   | 6977/10000 [00:30<00:13, 226.21it/s]Running 10000 simulations.:  70%|███████   | 7000/10000 [00:30<00:13, 226.79it/s]Running 10000 simulations.:  70%|███████   | 7023/10000 [00:30<00:13, 227.57it/s]Running 10000 simulations.:  70%|███████   | 7046/10000 [00:30<00:12, 227.93it/s]Running 10000 simulations.:  71%|███████   | 7069/10000 [00:30<00:12, 228.07it/s]Running 10000 simulations.:  71%|███████   | 7092/10000 [00:30<00:12, 226.27it/s]Running 10000 simulations.:  71%|███████   | 7115/10000 [00:30<00:12, 226.12it/s]Running 10000 simulations.:  71%|███████▏  | 7138/10000 [00:30<00:12, 227.27it/s]Running 10000 simulations.:  72%|███████▏  | 7162/10000 [00:30<00:12, 228.15it/s]Running 10000 simulations.:  72%|███████▏  | 7185/10000 [00:30<00:12, 227.87it/s]Running 10000 simulations.:  72%|███████▏  | 7208/10000 [00:31<00:12, 228.01it/s]Running 10000 simulations.:  72%|███████▏  | 7231/10000 [00:31<00:12, 228.00it/s]Running 10000 simulations.:  73%|███████▎  | 7254/10000 [00:31<00:12, 227.98it/s]Running 10000 simulations.:  73%|███████▎  | 7277/10000 [00:31<00:11, 227.61it/s]Running 10000 simulations.:  73%|███████▎  | 7300/10000 [00:31<00:11, 228.04it/s]Running 10000 simulations.:  73%|███████▎  | 7323/10000 [00:31<00:11, 228.56it/s]Running 10000 simulations.:  73%|███████▎  | 7346/10000 [00:31<00:11, 228.22it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:31<00:11, 226.01it/s]Running 10000 simulations.:  74%|███████▍  | 7392/10000 [00:31<00:11, 225.87it/s]Running 10000 simulations.:  74%|███████▍  | 7415/10000 [00:32<00:11, 226.44it/s]Running 10000 simulations.:  74%|███████▍  | 7438/10000 [00:32<00:11, 226.68it/s]Running 10000 simulations.:  75%|███████▍  | 7461/10000 [00:32<00:11, 227.11it/s]Running 10000 simulations.:  75%|███████▍  | 7484/10000 [00:32<00:11, 227.45it/s]Running 10000 simulations.:  75%|███████▌  | 7507/10000 [00:32<00:10, 227.78it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:32<00:10, 227.74it/s]Running 10000 simulations.:  76%|███████▌  | 7553/10000 [00:32<00:10, 227.96it/s]Running 10000 simulations.:  76%|███████▌  | 7576/10000 [00:32<00:10, 227.68it/s]Running 10000 simulations.:  76%|███████▌  | 7600/10000 [00:32<00:10, 228.78it/s]Running 10000 simulations.:  76%|███████▌  | 7623/10000 [00:32<00:10, 228.61it/s]Running 10000 simulations.:  76%|███████▋  | 7646/10000 [00:33<00:10, 228.10it/s]Running 10000 simulations.:  77%|███████▋  | 7669/10000 [00:33<00:10, 228.44it/s]Running 10000 simulations.:  77%|███████▋  | 7692/10000 [00:33<00:10, 228.28it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:33<00:10, 228.30it/s]Running 10000 simulations.:  77%|███████▋  | 7738/10000 [00:33<00:09, 228.62it/s]Running 10000 simulations.:  78%|███████▊  | 7761/10000 [00:33<00:09, 228.31it/s]Running 10000 simulations.:  78%|███████▊  | 7784/10000 [00:33<00:09, 228.26it/s]Running 10000 simulations.:  78%|███████▊  | 7807/10000 [00:33<00:09, 227.76it/s]Running 10000 simulations.:  78%|███████▊  | 7830/10000 [00:33<00:09, 227.77it/s]Running 10000 simulations.:  79%|███████▊  | 7853/10000 [00:33<00:09, 228.09it/s]Running 10000 simulations.:  79%|███████▉  | 7876/10000 [00:34<00:09, 228.03it/s]Running 10000 simulations.:  79%|███████▉  | 7899/10000 [00:34<00:09, 228.47it/s]Running 10000 simulations.:  79%|███████▉  | 7922/10000 [00:34<00:09, 228.34it/s]Running 10000 simulations.:  79%|███████▉  | 7946/10000 [00:34<00:08, 228.99it/s]Running 10000 simulations.:  80%|███████▉  | 7969/10000 [00:34<00:08, 228.68it/s]Running 10000 simulations.:  80%|███████▉  | 7992/10000 [00:34<00:08, 228.25it/s]Running 10000 simulations.:  80%|████████  | 8015/10000 [00:34<00:08, 228.01it/s]Running 10000 simulations.:  80%|████████  | 8039/10000 [00:34<00:08, 228.80it/s]Running 10000 simulations.:  81%|████████  | 8063/10000 [00:34<00:08, 229.42it/s]Running 10000 simulations.:  81%|████████  | 8087/10000 [00:34<00:08, 229.78it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:35<00:08, 230.09it/s]Running 10000 simulations.:  81%|████████▏ | 8135/10000 [00:35<00:08, 229.74it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:35<00:08, 228.87it/s]Running 10000 simulations.:  82%|████████▏ | 8181/10000 [00:35<00:07, 228.87it/s]Running 10000 simulations.:  82%|████████▏ | 8204/10000 [00:35<00:07, 228.88it/s]Running 10000 simulations.:  82%|████████▏ | 8227/10000 [00:35<00:07, 228.96it/s]Running 10000 simulations.:  82%|████████▎ | 8250/10000 [00:35<00:07, 228.98it/s]Running 10000 simulations.:  83%|████████▎ | 8273/10000 [00:35<00:07, 229.11it/s]Running 10000 simulations.:  83%|████████▎ | 8297/10000 [00:35<00:07, 229.40it/s]Running 10000 simulations.:  83%|████████▎ | 8320/10000 [00:35<00:07, 229.45it/s]Running 10000 simulations.:  83%|████████▎ | 8343/10000 [00:36<00:07, 229.51it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [00:36<00:07, 229.10it/s]Running 10000 simulations.:  84%|████████▍ | 8389/10000 [00:36<00:07, 228.56it/s]Running 10000 simulations.:  84%|████████▍ | 8412/10000 [00:36<00:06, 228.33it/s]Running 10000 simulations.:  84%|████████▍ | 8436/10000 [00:36<00:06, 228.93it/s]Running 10000 simulations.:  85%|████████▍ | 8459/10000 [00:36<00:06, 228.69it/s]Running 10000 simulations.:  85%|████████▍ | 8483/10000 [00:36<00:06, 229.16it/s]Running 10000 simulations.:  85%|████████▌ | 8506/10000 [00:36<00:06, 228.97it/s]Running 10000 simulations.:  85%|████████▌ | 8529/10000 [00:36<00:06, 228.96it/s]Running 10000 simulations.:  86%|████████▌ | 8552/10000 [00:36<00:06, 218.89it/s]Running 10000 simulations.:  86%|████████▌ | 8575/10000 [00:37<00:06, 220.10it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [00:37<00:06, 222.58it/s]Running 10000 simulations.:  86%|████████▌ | 8622/10000 [00:37<00:06, 224.98it/s]Running 10000 simulations.:  86%|████████▋ | 8646/10000 [00:37<00:05, 226.57it/s]Running 10000 simulations.:  87%|████████▋ | 8669/10000 [00:37<00:05, 227.57it/s]Running 10000 simulations.:  87%|████████▋ | 8693/10000 [00:37<00:05, 228.40it/s]Running 10000 simulations.:  87%|████████▋ | 8716/10000 [00:37<00:05, 228.78it/s]Running 10000 simulations.:  87%|████████▋ | 8739/10000 [00:37<00:05, 229.00it/s]Running 10000 simulations.:  88%|████████▊ | 8762/10000 [00:37<00:05, 228.66it/s]Running 10000 simulations.:  88%|████████▊ | 8785/10000 [00:38<00:05, 229.02it/s]Running 10000 simulations.:  88%|████████▊ | 8809/10000 [00:38<00:05, 229.41it/s]Running 10000 simulations.:  88%|████████▊ | 8832/10000 [00:38<00:05, 228.53it/s]Running 10000 simulations.:  89%|████████▊ | 8855/10000 [00:38<00:05, 228.29it/s]Running 10000 simulations.:  89%|████████▉ | 8879/10000 [00:38<00:04, 229.17it/s]Running 10000 simulations.:  89%|████████▉ | 8903/10000 [00:38<00:04, 229.81it/s]Running 10000 simulations.:  89%|████████▉ | 8927/10000 [00:38<00:04, 230.06it/s]Running 10000 simulations.:  90%|████████▉ | 8951/10000 [00:38<00:04, 230.94it/s]Running 10000 simulations.:  90%|████████▉ | 8975/10000 [00:38<00:04, 231.19it/s]Running 10000 simulations.:  90%|████████▉ | 8999/10000 [00:38<00:04, 231.05it/s]Running 10000 simulations.:  90%|█████████ | 9023/10000 [00:39<00:04, 231.06it/s]Running 10000 simulations.:  90%|█████████ | 9047/10000 [00:39<00:04, 230.58it/s]Running 10000 simulations.:  91%|█████████ | 9071/10000 [00:39<00:04, 230.63it/s]Running 10000 simulations.:  91%|█████████ | 9095/10000 [00:39<00:03, 230.37it/s]Running 10000 simulations.:  91%|█████████ | 9119/10000 [00:39<00:03, 230.20it/s]Running 10000 simulations.:  91%|█████████▏| 9143/10000 [00:39<00:03, 230.47it/s]Running 10000 simulations.:  92%|█████████▏| 9167/10000 [00:39<00:03, 230.44it/s]Running 10000 simulations.:  92%|█████████▏| 9191/10000 [00:39<00:03, 230.82it/s]Running 10000 simulations.:  92%|█████████▏| 9215/10000 [00:39<00:03, 230.87it/s]Running 10000 simulations.:  92%|█████████▏| 9239/10000 [00:39<00:03, 231.29it/s]Running 10000 simulations.:  93%|█████████▎| 9263/10000 [00:40<00:03, 230.77it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [00:40<00:03, 229.72it/s]Running 10000 simulations.:  93%|█████████▎| 9310/10000 [00:40<00:03, 229.10it/s]Running 10000 simulations.:  93%|█████████▎| 9334/10000 [00:40<00:02, 229.46it/s]Running 10000 simulations.:  94%|█████████▎| 9358/10000 [00:40<00:02, 229.67it/s]Running 10000 simulations.:  94%|█████████▍| 9381/10000 [00:40<00:02, 229.15it/s]Running 10000 simulations.:  94%|█████████▍| 9404/10000 [00:40<00:02, 228.95it/s]Running 10000 simulations.:  94%|█████████▍| 9427/10000 [00:40<00:02, 228.83it/s]Running 10000 simulations.:  94%|█████████▍| 9450/10000 [00:40<00:02, 228.82it/s]Running 10000 simulations.:  95%|█████████▍| 9473/10000 [00:41<00:02, 229.00it/s]Running 10000 simulations.:  95%|█████████▍| 9497/10000 [00:41<00:02, 229.57it/s]Running 10000 simulations.:  95%|█████████▌| 9521/10000 [00:41<00:02, 230.09it/s]Running 10000 simulations.:  95%|█████████▌| 9545/10000 [00:41<00:01, 230.23it/s]Running 10000 simulations.:  96%|█████████▌| 9569/10000 [00:41<00:01, 230.50it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:41<00:01, 231.00it/s]Running 10000 simulations.:  96%|█████████▌| 9617/10000 [00:41<00:01, 231.68it/s]Running 10000 simulations.:  96%|█████████▋| 9641/10000 [00:41<00:01, 232.54it/s]Running 10000 simulations.:  97%|█████████▋| 9665/10000 [00:41<00:01, 232.91it/s]Running 10000 simulations.:  97%|█████████▋| 9689/10000 [00:41<00:01, 233.33it/s]Running 10000 simulations.:  97%|█████████▋| 9713/10000 [00:42<00:01, 233.91it/s]Running 10000 simulations.:  97%|█████████▋| 9737/10000 [00:42<00:01, 234.86it/s]Running 10000 simulations.:  98%|█████████▊| 9761/10000 [00:42<00:01, 235.23it/s]Running 10000 simulations.:  98%|█████████▊| 9785/10000 [00:42<00:00, 235.33it/s]Running 10000 simulations.:  98%|█████████▊| 9809/10000 [00:42<00:00, 235.06it/s]Running 10000 simulations.:  98%|█████████▊| 9833/10000 [00:42<00:00, 234.88it/s]Running 10000 simulations.:  99%|█████████▊| 9857/10000 [00:42<00:00, 234.10it/s]Running 10000 simulations.:  99%|█████████▉| 9881/10000 [00:42<00:00, 234.23it/s]Running 10000 simulations.:  99%|█████████▉| 9905/10000 [00:42<00:00, 234.39it/s]Running 10000 simulations.:  99%|█████████▉| 9929/10000 [00:42<00:00, 234.15it/s]Running 10000 simulations.: 100%|█████████▉| 9953/10000 [00:43<00:00, 231.48it/s]Running 10000 simulations.: 100%|█████████▉| 9977/10000 [00:43<00:00, 231.87it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:43<00:00, 231.13it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:38, 256.20it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:38, 255.37it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:39, 254.35it/s]Running 10000 simulations.:   1%|          | 103/10000 [00:00<00:39, 252.55it/s]Running 10000 simulations.:   1%|▏         | 128/10000 [00:00<00:39, 251.73it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:39, 250.49it/s]Running 10000 simulations.:   2%|▏         | 178/10000 [00:00<00:39, 249.27it/s]Running 10000 simulations.:   2%|▏         | 203/10000 [00:00<00:39, 248.47it/s]Running 10000 simulations.:   2%|▏         | 228/10000 [00:00<00:39, 248.25it/s]Running 10000 simulations.:   3%|▎         | 253/10000 [00:01<00:39, 247.91it/s]Running 10000 simulations.:   3%|▎         | 278/10000 [00:01<00:39, 248.13it/s]Running 10000 simulations.:   3%|▎         | 303/10000 [00:01<00:39, 247.60it/s]Running 10000 simulations.:   3%|▎         | 328/10000 [00:01<00:39, 247.14it/s]Running 10000 simulations.:   4%|▎         | 353/10000 [00:01<00:39, 246.58it/s]Running 10000 simulations.:   4%|▍         | 378/10000 [00:01<00:39, 246.49it/s]Running 10000 simulations.:   4%|▍         | 403/10000 [00:01<00:39, 245.88it/s]Running 10000 simulations.:   4%|▍         | 428/10000 [00:01<00:39, 245.24it/s]Running 10000 simulations.:   5%|▍         | 453/10000 [00:01<00:38, 244.96it/s]Running 10000 simulations.:   5%|▍         | 478/10000 [00:01<00:38, 244.73it/s]Running 10000 simulations.:   5%|▌         | 503/10000 [00:02<00:38, 244.59it/s]Running 10000 simulations.:   5%|▌         | 528/10000 [00:02<00:38, 245.51it/s]Running 10000 simulations.:   6%|▌         | 553/10000 [00:02<00:38, 245.73it/s]Running 10000 simulations.:   6%|▌         | 578/10000 [00:02<00:38, 245.79it/s]Running 10000 simulations.:   6%|▌         | 603/10000 [00:02<00:38, 245.84it/s]Running 10000 simulations.:   6%|▋         | 628/10000 [00:02<00:38, 246.21it/s]Running 10000 simulations.:   7%|▋         | 653/10000 [00:02<00:38, 245.64it/s]Running 10000 simulations.:   7%|▋         | 678/10000 [00:02<00:37, 246.13it/s]Running 10000 simulations.:   7%|▋         | 703/10000 [00:02<00:37, 245.61it/s]Running 10000 simulations.:   7%|▋         | 728/10000 [00:02<00:37, 245.03it/s]Running 10000 simulations.:   8%|▊         | 753/10000 [00:03<00:37, 244.37it/s]Running 10000 simulations.:   8%|▊         | 778/10000 [00:03<00:37, 244.04it/s]Running 10000 simulations.:   8%|▊         | 803/10000 [00:03<00:37, 243.79it/s]Running 10000 simulations.:   8%|▊         | 828/10000 [00:03<00:37, 244.60it/s]Running 10000 simulations.:   9%|▊         | 853/10000 [00:03<00:37, 245.29it/s]Running 10000 simulations.:   9%|▉         | 878/10000 [00:03<00:37, 245.90it/s]Running 10000 simulations.:   9%|▉         | 903/10000 [00:03<00:37, 244.09it/s]Running 10000 simulations.:   9%|▉         | 928/10000 [00:03<00:37, 241.34it/s]Running 10000 simulations.:  10%|▉         | 953/10000 [00:03<00:37, 241.39it/s]Running 10000 simulations.:  10%|▉         | 978/10000 [00:03<00:37, 241.35it/s]Running 10000 simulations.:  10%|█         | 1003/10000 [00:04<00:37, 241.33it/s]Running 10000 simulations.:  10%|█         | 1028/10000 [00:04<00:37, 241.18it/s]Running 10000 simulations.:  11%|█         | 1053/10000 [00:04<00:37, 241.21it/s]Running 10000 simulations.:  11%|█         | 1078/10000 [00:04<00:36, 241.43it/s]Running 10000 simulations.:  11%|█         | 1103/10000 [00:04<00:36, 241.57it/s]Running 10000 simulations.:  11%|█▏        | 1128/10000 [00:04<00:36, 241.52it/s]Running 10000 simulations.:  12%|█▏        | 1153/10000 [00:04<00:36, 241.23it/s]Running 10000 simulations.:  12%|█▏        | 1178/10000 [00:04<00:36, 239.02it/s]Running 10000 simulations.:  12%|█▏        | 1202/10000 [00:04<00:36, 239.08it/s]Running 10000 simulations.:  12%|█▏        | 1227/10000 [00:05<00:36, 239.80it/s]Running 10000 simulations.:  13%|█▎        | 1251/10000 [00:05<00:36, 239.12it/s]Running 10000 simulations.:  13%|█▎        | 1275/10000 [00:05<00:36, 237.84it/s]Running 10000 simulations.:  13%|█▎        | 1300/10000 [00:05<00:36, 239.31it/s]Running 10000 simulations.:  13%|█▎        | 1325/10000 [00:05<00:36, 240.20it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:05<00:35, 240.63it/s]Running 10000 simulations.:  14%|█▍        | 1375/10000 [00:05<00:35, 240.83it/s]Running 10000 simulations.:  14%|█▍        | 1400/10000 [00:05<00:35, 241.13it/s]Running 10000 simulations.:  14%|█▍        | 1425/10000 [00:05<00:35, 241.48it/s]Running 10000 simulations.:  14%|█▍        | 1450/10000 [00:05<00:35, 241.98it/s]Running 10000 simulations.:  15%|█▍        | 1475/10000 [00:06<00:35, 241.78it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:06<00:35, 241.68it/s]Running 10000 simulations.:  15%|█▌        | 1525/10000 [00:06<00:35, 241.59it/s]Running 10000 simulations.:  16%|█▌        | 1550/10000 [00:06<00:34, 241.50it/s]Running 10000 simulations.:  16%|█▌        | 1575/10000 [00:06<00:34, 241.68it/s]Running 10000 simulations.:  16%|█▌        | 1600/10000 [00:06<00:34, 241.67it/s]Running 10000 simulations.:  16%|█▋        | 1625/10000 [00:06<00:34, 241.73it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:06<00:35, 233.91it/s]Running 10000 simulations.:  17%|█▋        | 1675/10000 [00:06<00:35, 236.70it/s]Running 10000 simulations.:  17%|█▋        | 1700/10000 [00:06<00:34, 238.06it/s]Running 10000 simulations.:  17%|█▋        | 1725/10000 [00:07<00:34, 239.41it/s]Running 10000 simulations.:  18%|█▊        | 1750/10000 [00:07<00:34, 240.81it/s]Running 10000 simulations.:  18%|█▊        | 1775/10000 [00:07<00:34, 241.79it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:07<00:33, 241.30it/s]Running 10000 simulations.:  18%|█▊        | 1825/10000 [00:07<00:33, 241.53it/s]Running 10000 simulations.:  18%|█▊        | 1850/10000 [00:07<00:33, 242.15it/s]Running 10000 simulations.:  19%|█▉        | 1875/10000 [00:07<00:33, 241.82it/s]Running 10000 simulations.:  19%|█▉        | 1900/10000 [00:07<00:33, 242.18it/s]Running 10000 simulations.:  19%|█▉        | 1925/10000 [00:07<00:33, 241.79it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:08<00:33, 241.07it/s]Running 10000 simulations.:  20%|█▉        | 1975/10000 [00:08<00:33, 240.82it/s]Running 10000 simulations.:  20%|██        | 2000/10000 [00:08<00:33, 240.66it/s]Running 10000 simulations.:  20%|██        | 2025/10000 [00:08<00:33, 241.22it/s]Running 10000 simulations.:  20%|██        | 2050/10000 [00:08<00:32, 241.28it/s]Running 10000 simulations.:  21%|██        | 2075/10000 [00:08<00:32, 241.55it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:08<00:32, 241.37it/s]Running 10000 simulations.:  21%|██▏       | 2125/10000 [00:08<00:32, 240.99it/s]Running 10000 simulations.:  22%|██▏       | 2150/10000 [00:08<00:32, 241.38it/s]Running 10000 simulations.:  22%|██▏       | 2175/10000 [00:08<00:32, 241.85it/s]Running 10000 simulations.:  22%|██▏       | 2200/10000 [00:09<00:32, 242.53it/s]Running 10000 simulations.:  22%|██▏       | 2225/10000 [00:09<00:31, 243.00it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:09<00:31, 243.22it/s]Running 10000 simulations.:  23%|██▎       | 2275/10000 [00:09<00:31, 242.26it/s]Running 10000 simulations.:  23%|██▎       | 2300/10000 [00:09<00:31, 241.20it/s]Running 10000 simulations.:  23%|██▎       | 2325/10000 [00:09<00:31, 240.80it/s]Running 10000 simulations.:  24%|██▎       | 2350/10000 [00:09<00:31, 240.82it/s]Running 10000 simulations.:  24%|██▍       | 2375/10000 [00:09<00:31, 240.63it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:09<00:31, 241.54it/s]Running 10000 simulations.:  24%|██▍       | 2425/10000 [00:09<00:31, 241.40it/s]Running 10000 simulations.:  24%|██▍       | 2450/10000 [00:10<00:31, 241.40it/s]Running 10000 simulations.:  25%|██▍       | 2475/10000 [00:10<00:31, 242.04it/s]Running 10000 simulations.:  25%|██▌       | 2500/10000 [00:10<00:30, 242.28it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:10<00:30, 242.09it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:10<00:30, 241.87it/s]Running 10000 simulations.:  26%|██▌       | 2575/10000 [00:10<00:30, 241.97it/s]Running 10000 simulations.:  26%|██▌       | 2600/10000 [00:10<00:30, 241.66it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:10<00:30, 241.11it/s]Running 10000 simulations.:  26%|██▋       | 2650/10000 [00:10<00:30, 240.99it/s]Running 10000 simulations.:  27%|██▋       | 2675/10000 [00:11<00:30, 241.78it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:11<00:30, 241.22it/s]Running 10000 simulations.:  27%|██▋       | 2725/10000 [00:11<00:30, 241.39it/s]Running 10000 simulations.:  28%|██▊       | 2750/10000 [00:11<00:30, 240.96it/s]Running 10000 simulations.:  28%|██▊       | 2775/10000 [00:11<00:29, 241.20it/s]Running 10000 simulations.:  28%|██▊       | 2800/10000 [00:11<00:29, 241.71it/s]Running 10000 simulations.:  28%|██▊       | 2825/10000 [00:11<00:29, 242.22it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:11<00:29, 239.49it/s]Running 10000 simulations.:  29%|██▊       | 2874/10000 [00:11<00:29, 239.26it/s]Running 10000 simulations.:  29%|██▉       | 2898/10000 [00:11<00:29, 238.92it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:12<00:29, 239.72it/s]Running 10000 simulations.:  29%|██▉       | 2947/10000 [00:12<00:29, 239.58it/s]Running 10000 simulations.:  30%|██▉       | 2971/10000 [00:12<00:29, 239.25it/s]Running 10000 simulations.:  30%|██▉       | 2995/10000 [00:12<00:29, 238.61it/s]Running 10000 simulations.:  30%|███       | 3019/10000 [00:12<00:29, 238.27it/s]Running 10000 simulations.:  30%|███       | 3043/10000 [00:12<00:29, 238.74it/s]Running 10000 simulations.:  31%|███       | 3068/10000 [00:12<00:28, 239.26it/s]Running 10000 simulations.:  31%|███       | 3093/10000 [00:12<00:28, 239.66it/s]Running 10000 simulations.:  31%|███       | 3117/10000 [00:12<00:28, 238.68it/s]Running 10000 simulations.:  31%|███▏      | 3141/10000 [00:12<00:28, 239.01it/s]Running 10000 simulations.:  32%|███▏      | 3165/10000 [00:13<00:28, 239.21it/s]Running 10000 simulations.:  32%|███▏      | 3189/10000 [00:13<00:28, 238.79it/s]Running 10000 simulations.:  32%|███▏      | 3213/10000 [00:13<00:28, 238.36it/s]Running 10000 simulations.:  32%|███▏      | 3237/10000 [00:13<00:28, 237.96it/s]Running 10000 simulations.:  33%|███▎      | 3261/10000 [00:13<00:28, 237.88it/s]Running 10000 simulations.:  33%|███▎      | 3285/10000 [00:13<00:28, 237.92it/s]Running 10000 simulations.:  33%|███▎      | 3309/10000 [00:13<00:28, 237.58it/s]Running 10000 simulations.:  33%|███▎      | 3334/10000 [00:13<00:27, 238.39it/s]Running 10000 simulations.:  34%|███▎      | 3358/10000 [00:13<00:27, 238.44it/s]Running 10000 simulations.:  34%|███▍      | 3382/10000 [00:13<00:27, 238.20it/s]Running 10000 simulations.:  34%|███▍      | 3406/10000 [00:14<00:27, 237.78it/s]Running 10000 simulations.:  34%|███▍      | 3430/10000 [00:14<00:27, 237.91it/s]Running 10000 simulations.:  35%|███▍      | 3454/10000 [00:14<00:27, 237.94it/s]Running 10000 simulations.:  35%|███▍      | 3478/10000 [00:14<00:27, 238.19it/s]Running 10000 simulations.:  35%|███▌      | 3502/10000 [00:14<00:27, 238.37it/s]Running 10000 simulations.:  35%|███▌      | 3526/10000 [00:14<00:27, 238.36it/s]Running 10000 simulations.:  36%|███▌      | 3550/10000 [00:14<00:27, 238.73it/s]Running 10000 simulations.:  36%|███▌      | 3574/10000 [00:14<00:27, 237.55it/s]Running 10000 simulations.:  36%|███▌      | 3598/10000 [00:14<00:27, 237.00it/s]Running 10000 simulations.:  36%|███▌      | 3622/10000 [00:14<00:26, 237.88it/s]Running 10000 simulations.:  36%|███▋      | 3646/10000 [00:15<00:26, 237.81it/s]Running 10000 simulations.:  37%|███▋      | 3670/10000 [00:15<00:26, 237.45it/s]Running 10000 simulations.:  37%|███▋      | 3694/10000 [00:15<00:26, 237.39it/s]Running 10000 simulations.:  37%|███▋      | 3718/10000 [00:15<00:26, 237.34it/s]Running 10000 simulations.:  37%|███▋      | 3742/10000 [00:15<00:26, 236.95it/s]Running 10000 simulations.:  38%|███▊      | 3766/10000 [00:15<00:26, 236.53it/s]Running 10000 simulations.:  38%|███▊      | 3790/10000 [00:15<00:26, 236.52it/s]Running 10000 simulations.:  38%|███▊      | 3814/10000 [00:15<00:26, 236.73it/s]Running 10000 simulations.:  38%|███▊      | 3838/10000 [00:15<00:26, 236.94it/s]Running 10000 simulations.:  39%|███▊      | 3862/10000 [00:15<00:25, 237.71it/s]Running 10000 simulations.:  39%|███▉      | 3886/10000 [00:16<00:25, 237.79it/s]Running 10000 simulations.:  39%|███▉      | 3910/10000 [00:16<00:25, 237.90it/s]Running 10000 simulations.:  39%|███▉      | 3934/10000 [00:16<00:25, 237.32it/s]Running 10000 simulations.:  40%|███▉      | 3958/10000 [00:16<00:25, 236.03it/s]Running 10000 simulations.:  40%|███▉      | 3982/10000 [00:16<00:25, 235.83it/s]Running 10000 simulations.:  40%|████      | 4006/10000 [00:16<00:25, 236.76it/s]Running 10000 simulations.:  40%|████      | 4030/10000 [00:16<00:25, 237.27it/s]Running 10000 simulations.:  41%|████      | 4054/10000 [00:16<00:25, 237.17it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:16<00:24, 237.35it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:17<00:24, 237.37it/s]Running 10000 simulations.:  41%|████▏     | 4126/10000 [00:17<00:24, 237.47it/s]Running 10000 simulations.:  42%|████▏     | 4150/10000 [00:17<00:24, 236.75it/s]Running 10000 simulations.:  42%|████▏     | 4174/10000 [00:17<00:24, 236.47it/s]Running 10000 simulations.:  42%|████▏     | 4198/10000 [00:17<00:24, 236.56it/s]Running 10000 simulations.:  42%|████▏     | 4222/10000 [00:17<00:24, 237.01it/s]Running 10000 simulations.:  42%|████▏     | 4246/10000 [00:17<00:24, 236.98it/s]Running 10000 simulations.:  43%|████▎     | 4270/10000 [00:17<00:24, 237.29it/s]Running 10000 simulations.:  43%|████▎     | 4294/10000 [00:17<00:23, 237.82it/s]Running 10000 simulations.:  43%|████▎     | 4318/10000 [00:17<00:23, 237.91it/s]Running 10000 simulations.:  43%|████▎     | 4342/10000 [00:18<00:23, 237.42it/s]Running 10000 simulations.:  44%|████▎     | 4366/10000 [00:18<00:23, 237.03it/s]Running 10000 simulations.:  44%|████▍     | 4390/10000 [00:18<00:23, 237.30it/s]Running 10000 simulations.:  44%|████▍     | 4414/10000 [00:18<00:23, 237.44it/s]Running 10000 simulations.:  44%|████▍     | 4438/10000 [00:18<00:23, 237.56it/s]Running 10000 simulations.:  45%|████▍     | 4462/10000 [00:18<00:23, 238.15it/s]Running 10000 simulations.:  45%|████▍     | 4487/10000 [00:18<00:23, 238.87it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:18<00:23, 238.40it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:18<00:23, 236.55it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:18<00:22, 236.82it/s]Running 10000 simulations.:  46%|████▌     | 4584/10000 [00:19<00:22, 237.85it/s]Running 10000 simulations.:  46%|████▌     | 4609/10000 [00:19<00:22, 238.83it/s]Running 10000 simulations.:  46%|████▋     | 4633/10000 [00:19<00:22, 239.15it/s]Running 10000 simulations.:  47%|████▋     | 4658/10000 [00:19<00:22, 239.43it/s]Running 10000 simulations.:  47%|████▋     | 4682/10000 [00:19<00:22, 239.21it/s]Running 10000 simulations.:  47%|████▋     | 4706/10000 [00:19<00:22, 239.27it/s]Running 10000 simulations.:  47%|████▋     | 4731/10000 [00:19<00:21, 239.81it/s]Running 10000 simulations.:  48%|████▊     | 4756/10000 [00:19<00:21, 239.91it/s]Running 10000 simulations.:  48%|████▊     | 4780/10000 [00:19<00:21, 239.12it/s]Running 10000 simulations.:  48%|████▊     | 4804/10000 [00:19<00:21, 238.49it/s]Running 10000 simulations.:  48%|████▊     | 4828/10000 [00:20<00:21, 237.84it/s]Running 10000 simulations.:  49%|████▊     | 4852/10000 [00:20<00:21, 237.82it/s]Running 10000 simulations.:  49%|████▉     | 4876/10000 [00:20<00:21, 237.55it/s]Running 10000 simulations.:  49%|████▉     | 4900/10000 [00:20<00:21, 236.04it/s]Running 10000 simulations.:  49%|████▉     | 4924/10000 [00:20<00:21, 235.25it/s]Running 10000 simulations.:  49%|████▉     | 4948/10000 [00:20<00:21, 236.08it/s]Running 10000 simulations.:  50%|████▉     | 4972/10000 [00:20<00:21, 236.93it/s]Running 10000 simulations.:  50%|████▉     | 4996/10000 [00:20<00:21, 237.12it/s]Running 10000 simulations.:  50%|█████     | 5020/10000 [00:20<00:20, 237.43it/s]Running 10000 simulations.:  50%|█████     | 5044/10000 [00:20<00:20, 237.23it/s]Running 10000 simulations.:  51%|█████     | 5068/10000 [00:21<00:20, 237.33it/s]Running 10000 simulations.:  51%|█████     | 5092/10000 [00:21<00:20, 237.07it/s]Running 10000 simulations.:  51%|█████     | 5116/10000 [00:21<00:20, 237.19it/s]Running 10000 simulations.:  51%|█████▏    | 5140/10000 [00:21<00:20, 237.51it/s]Running 10000 simulations.:  52%|█████▏    | 5164/10000 [00:21<00:20, 237.51it/s]Running 10000 simulations.:  52%|█████▏    | 5188/10000 [00:21<00:20, 238.03it/s]Running 10000 simulations.:  52%|█████▏    | 5212/10000 [00:21<00:20, 238.33it/s]Running 10000 simulations.:  52%|█████▏    | 5237/10000 [00:21<00:19, 238.88it/s]Running 10000 simulations.:  53%|█████▎    | 5261/10000 [00:21<00:19, 239.19it/s]Running 10000 simulations.:  53%|█████▎    | 5285/10000 [00:21<00:19, 238.56it/s]Running 10000 simulations.:  53%|█████▎    | 5309/10000 [00:22<00:19, 238.41it/s]Running 10000 simulations.:  53%|█████▎    | 5334/10000 [00:22<00:19, 239.01it/s]Running 10000 simulations.:  54%|█████▎    | 5359/10000 [00:22<00:19, 239.74it/s]Running 10000 simulations.:  54%|█████▍    | 5383/10000 [00:22<00:19, 239.23it/s]Running 10000 simulations.:  54%|█████▍    | 5407/10000 [00:22<00:19, 238.96it/s]Running 10000 simulations.:  54%|█████▍    | 5431/10000 [00:22<00:19, 238.91it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:22<00:19, 238.56it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:22<00:18, 238.20it/s]Running 10000 simulations.:  55%|█████▌    | 5504/10000 [00:22<00:18, 238.74it/s]Running 10000 simulations.:  55%|█████▌    | 5529/10000 [00:23<00:18, 239.36it/s]Running 10000 simulations.:  56%|█████▌    | 5553/10000 [00:23<00:18, 238.88it/s]Running 10000 simulations.:  56%|█████▌    | 5577/10000 [00:23<00:18, 238.60it/s]Running 10000 simulations.:  56%|█████▌    | 5601/10000 [00:23<00:18, 238.73it/s]Running 10000 simulations.:  56%|█████▋    | 5625/10000 [00:23<00:18, 238.66it/s]Running 10000 simulations.:  56%|█████▋    | 5649/10000 [00:23<00:18, 239.01it/s]Running 10000 simulations.:  57%|█████▋    | 5673/10000 [00:23<00:18, 238.74it/s]Running 10000 simulations.:  57%|█████▋    | 5697/10000 [00:23<00:18, 239.03it/s]Running 10000 simulations.:  57%|█████▋    | 5721/10000 [00:23<00:17, 238.80it/s]Running 10000 simulations.:  57%|█████▋    | 5745/10000 [00:23<00:17, 238.82it/s]Running 10000 simulations.:  58%|█████▊    | 5769/10000 [00:24<00:17, 238.73it/s]Running 10000 simulations.:  58%|█████▊    | 5793/10000 [00:24<00:17, 238.86it/s]Running 10000 simulations.:  58%|█████▊    | 5818/10000 [00:24<00:17, 239.45it/s]Running 10000 simulations.:  58%|█████▊    | 5842/10000 [00:24<00:17, 239.30it/s]Running 10000 simulations.:  59%|█████▊    | 5866/10000 [00:24<00:17, 239.10it/s]Running 10000 simulations.:  59%|█████▉    | 5890/10000 [00:24<00:17, 238.91it/s]Running 10000 simulations.:  59%|█████▉    | 5914/10000 [00:24<00:17, 239.16it/s]Running 10000 simulations.:  59%|█████▉    | 5938/10000 [00:24<00:17, 238.85it/s]Running 10000 simulations.:  60%|█████▉    | 5962/10000 [00:24<00:16, 238.61it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:24<00:16, 239.12it/s]Running 10000 simulations.:  60%|██████    | 6011/10000 [00:25<00:16, 238.95it/s]Running 10000 simulations.:  60%|██████    | 6035/10000 [00:25<00:16, 238.90it/s]Running 10000 simulations.:  61%|██████    | 6059/10000 [00:25<00:16, 238.78it/s]Running 10000 simulations.:  61%|██████    | 6083/10000 [00:25<00:16, 238.73it/s]Running 10000 simulations.:  61%|██████    | 6108/10000 [00:25<00:16, 239.18it/s]Running 10000 simulations.:  61%|██████▏   | 6132/10000 [00:25<00:16, 239.22it/s]Running 10000 simulations.:  62%|██████▏   | 6156/10000 [00:25<00:16, 239.10it/s]Running 10000 simulations.:  62%|██████▏   | 6180/10000 [00:25<00:15, 238.88it/s]Running 10000 simulations.:  62%|██████▏   | 6204/10000 [00:25<00:15, 238.91it/s]Running 10000 simulations.:  62%|██████▏   | 6228/10000 [00:25<00:15, 238.54it/s]Running 10000 simulations.:  63%|██████▎   | 6252/10000 [00:26<00:15, 238.35it/s]Running 10000 simulations.:  63%|██████▎   | 6276/10000 [00:26<00:15, 238.28it/s]Running 10000 simulations.:  63%|██████▎   | 6300/10000 [00:26<00:15, 238.09it/s]Running 10000 simulations.:  63%|██████▎   | 6324/10000 [00:26<00:15, 238.20it/s]Running 10000 simulations.:  63%|██████▎   | 6348/10000 [00:26<00:15, 238.44it/s]Running 10000 simulations.:  64%|██████▎   | 6372/10000 [00:26<00:15, 238.72it/s]Running 10000 simulations.:  64%|██████▍   | 6396/10000 [00:26<00:15, 239.09it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:26<00:14, 238.77it/s]Running 10000 simulations.:  64%|██████▍   | 6444/10000 [00:26<00:14, 238.52it/s]Running 10000 simulations.:  65%|██████▍   | 6468/10000 [00:26<00:14, 238.08it/s]Running 10000 simulations.:  65%|██████▍   | 6492/10000 [00:27<00:14, 237.03it/s]Running 10000 simulations.:  65%|██████▌   | 6516/10000 [00:27<00:14, 235.83it/s]Running 10000 simulations.:  65%|██████▌   | 6540/10000 [00:27<00:14, 236.41it/s]Running 10000 simulations.:  66%|██████▌   | 6564/10000 [00:27<00:14, 237.15it/s]Running 10000 simulations.:  66%|██████▌   | 6588/10000 [00:27<00:14, 237.84it/s]Running 10000 simulations.:  66%|██████▌   | 6613/10000 [00:27<00:14, 238.58it/s]Running 10000 simulations.:  66%|██████▋   | 6637/10000 [00:27<00:14, 238.54it/s]Running 10000 simulations.:  67%|██████▋   | 6661/10000 [00:27<00:13, 238.52it/s]Running 10000 simulations.:  67%|██████▋   | 6685/10000 [00:27<00:13, 237.20it/s]Running 10000 simulations.:  67%|██████▋   | 6709/10000 [00:27<00:13, 235.87it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:28<00:13, 236.01it/s]Running 10000 simulations.:  68%|██████▊   | 6758/10000 [00:28<00:13, 237.52it/s]Running 10000 simulations.:  68%|██████▊   | 6782/10000 [00:28<00:13, 237.90it/s]Running 10000 simulations.:  68%|██████▊   | 6806/10000 [00:28<00:13, 238.16it/s]Running 10000 simulations.:  68%|██████▊   | 6830/10000 [00:28<00:13, 237.86it/s]Running 10000 simulations.:  69%|██████▊   | 6854/10000 [00:28<00:13, 238.45it/s]Running 10000 simulations.:  69%|██████▉   | 6878/10000 [00:28<00:13, 238.57it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:28<00:13, 237.43it/s]Running 10000 simulations.:  69%|██████▉   | 6926/10000 [00:28<00:12, 236.81it/s]Running 10000 simulations.:  70%|██████▉   | 6950/10000 [00:28<00:12, 236.71it/s]Running 10000 simulations.:  70%|██████▉   | 6974/10000 [00:29<00:12, 236.71it/s]Running 10000 simulations.:  70%|██████▉   | 6998/10000 [00:29<00:12, 236.92it/s]Running 10000 simulations.:  70%|███████   | 7022/10000 [00:29<00:12, 237.41it/s]Running 10000 simulations.:  70%|███████   | 7046/10000 [00:29<00:12, 237.71it/s]Running 10000 simulations.:  71%|███████   | 7070/10000 [00:29<00:12, 237.41it/s]Running 10000 simulations.:  71%|███████   | 7094/10000 [00:29<00:12, 237.94it/s]Running 10000 simulations.:  71%|███████   | 7118/10000 [00:29<00:12, 237.86it/s]Running 10000 simulations.:  71%|███████▏  | 7142/10000 [00:29<00:12, 237.97it/s]Running 10000 simulations.:  72%|███████▏  | 7166/10000 [00:29<00:11, 238.32it/s]Running 10000 simulations.:  72%|███████▏  | 7190/10000 [00:29<00:11, 238.41it/s]Running 10000 simulations.:  72%|███████▏  | 7214/10000 [00:30<00:11, 237.79it/s]Running 10000 simulations.:  72%|███████▏  | 7238/10000 [00:30<00:11, 237.52it/s]Running 10000 simulations.:  73%|███████▎  | 7262/10000 [00:30<00:11, 237.47it/s]Running 10000 simulations.:  73%|███████▎  | 7286/10000 [00:30<00:11, 238.03it/s]Running 10000 simulations.:  73%|███████▎  | 7311/10000 [00:30<00:11, 238.74it/s]Running 10000 simulations.:  73%|███████▎  | 7335/10000 [00:30<00:11, 238.57it/s]Running 10000 simulations.:  74%|███████▎  | 7359/10000 [00:30<00:11, 238.25it/s]Running 10000 simulations.:  74%|███████▍  | 7383/10000 [00:30<00:10, 238.33it/s]Running 10000 simulations.:  74%|███████▍  | 7407/10000 [00:30<00:10, 237.98it/s]Running 10000 simulations.:  74%|███████▍  | 7431/10000 [00:30<00:10, 237.33it/s]Running 10000 simulations.:  75%|███████▍  | 7455/10000 [00:31<00:10, 236.90it/s]Running 10000 simulations.:  75%|███████▍  | 7479/10000 [00:31<00:10, 237.45it/s]Running 10000 simulations.:  75%|███████▌  | 7504/10000 [00:31<00:10, 238.69it/s]Running 10000 simulations.:  75%|███████▌  | 7528/10000 [00:31<00:10, 238.74it/s]Running 10000 simulations.:  76%|███████▌  | 7552/10000 [00:31<00:10, 238.43it/s]Running 10000 simulations.:  76%|███████▌  | 7576/10000 [00:31<00:10, 238.81it/s]Running 10000 simulations.:  76%|███████▌  | 7600/10000 [00:31<00:10, 238.70it/s]Running 10000 simulations.:  76%|███████▌  | 7624/10000 [00:31<00:09, 238.62it/s]Running 10000 simulations.:  76%|███████▋  | 7648/10000 [00:31<00:09, 238.41it/s]Running 10000 simulations.:  77%|███████▋  | 7672/10000 [00:32<00:09, 238.50it/s]Running 10000 simulations.:  77%|███████▋  | 7696/10000 [00:32<00:09, 238.29it/s]Running 10000 simulations.:  77%|███████▋  | 7720/10000 [00:32<00:09, 238.65it/s]Running 10000 simulations.:  77%|███████▋  | 7744/10000 [00:32<00:09, 238.64it/s]Running 10000 simulations.:  78%|███████▊  | 7769/10000 [00:32<00:09, 239.49it/s]Running 10000 simulations.:  78%|███████▊  | 7793/10000 [00:32<00:09, 239.50it/s]Running 10000 simulations.:  78%|███████▊  | 7818/10000 [00:32<00:09, 239.86it/s]Running 10000 simulations.:  78%|███████▊  | 7842/10000 [00:32<00:09, 239.67it/s]Running 10000 simulations.:  79%|███████▊  | 7866/10000 [00:32<00:08, 239.36it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:32<00:08, 239.04it/s]Running 10000 simulations.:  79%|███████▉  | 7914/10000 [00:33<00:08, 238.81it/s]Running 10000 simulations.:  79%|███████▉  | 7938/10000 [00:33<00:08, 238.77it/s]Running 10000 simulations.:  80%|███████▉  | 7962/10000 [00:33<00:08, 238.69it/s]Running 10000 simulations.:  80%|███████▉  | 7986/10000 [00:33<00:08, 238.45it/s]Running 10000 simulations.:  80%|████████  | 8010/10000 [00:33<00:08, 238.31it/s]Running 10000 simulations.:  80%|████████  | 8034/10000 [00:33<00:08, 238.62it/s]Running 10000 simulations.:  81%|████████  | 8058/10000 [00:33<00:08, 238.45it/s]Running 10000 simulations.:  81%|████████  | 8082/10000 [00:33<00:08, 238.32it/s]Running 10000 simulations.:  81%|████████  | 8106/10000 [00:33<00:07, 237.84it/s]Running 10000 simulations.:  81%|████████▏ | 8131/10000 [00:33<00:07, 238.56it/s]Running 10000 simulations.:  82%|████████▏ | 8155/10000 [00:34<00:07, 238.42it/s]Running 10000 simulations.:  82%|████████▏ | 8179/10000 [00:34<00:07, 237.91it/s]Running 10000 simulations.:  82%|████████▏ | 8203/10000 [00:34<00:07, 237.33it/s]Running 10000 simulations.:  82%|████████▏ | 8227/10000 [00:34<00:07, 237.06it/s]Running 10000 simulations.:  83%|████████▎ | 8251/10000 [00:34<00:07, 237.76it/s]Running 10000 simulations.:  83%|████████▎ | 8275/10000 [00:34<00:07, 238.18it/s]Running 10000 simulations.:  83%|████████▎ | 8299/10000 [00:34<00:07, 237.77it/s]Running 10000 simulations.:  83%|████████▎ | 8323/10000 [00:34<00:07, 236.83it/s]Running 10000 simulations.:  83%|████████▎ | 8347/10000 [00:34<00:06, 237.43it/s]Running 10000 simulations.:  84%|████████▎ | 8372/10000 [00:34<00:06, 238.52it/s]Running 10000 simulations.:  84%|████████▍ | 8396/10000 [00:35<00:06, 238.83it/s]Running 10000 simulations.:  84%|████████▍ | 8420/10000 [00:35<00:06, 239.15it/s]Running 10000 simulations.:  84%|████████▍ | 8444/10000 [00:35<00:06, 238.61it/s]Running 10000 simulations.:  85%|████████▍ | 8468/10000 [00:35<00:06, 238.39it/s]Running 10000 simulations.:  85%|████████▍ | 8492/10000 [00:35<00:06, 238.04it/s]Running 10000 simulations.:  85%|████████▌ | 8516/10000 [00:35<00:06, 238.18it/s]Running 10000 simulations.:  85%|████████▌ | 8541/10000 [00:35<00:06, 238.88it/s]Running 10000 simulations.:  86%|████████▌ | 8565/10000 [00:35<00:06, 238.76it/s]Running 10000 simulations.:  86%|████████▌ | 8589/10000 [00:35<00:05, 238.58it/s]Running 10000 simulations.:  86%|████████▌ | 8613/10000 [00:35<00:05, 238.77it/s]Running 10000 simulations.:  86%|████████▋ | 8637/10000 [00:36<00:05, 238.74it/s]Running 10000 simulations.:  87%|████████▋ | 8662/10000 [00:36<00:05, 239.26it/s]Running 10000 simulations.:  87%|████████▋ | 8687/10000 [00:36<00:05, 239.52it/s]Running 10000 simulations.:  87%|████████▋ | 8712/10000 [00:36<00:05, 240.13it/s]Running 10000 simulations.:  87%|████████▋ | 8737/10000 [00:36<00:05, 240.71it/s]Running 10000 simulations.:  88%|████████▊ | 8762/10000 [00:36<00:05, 239.82it/s]Running 10000 simulations.:  88%|████████▊ | 8786/10000 [00:36<00:05, 238.57it/s]Running 10000 simulations.:  88%|████████▊ | 8810/10000 [00:36<00:05, 231.19it/s]Running 10000 simulations.:  88%|████████▊ | 8835/10000 [00:36<00:04, 234.07it/s]Running 10000 simulations.:  89%|████████▊ | 8859/10000 [00:36<00:04, 235.09it/s]Running 10000 simulations.:  89%|████████▉ | 8883/10000 [00:37<00:04, 233.85it/s]Running 10000 simulations.:  89%|████████▉ | 8907/10000 [00:37<00:04, 235.24it/s]Running 10000 simulations.:  89%|████████▉ | 8932/10000 [00:37<00:04, 236.69it/s]Running 10000 simulations.:  90%|████████▉ | 8956/10000 [00:37<00:04, 237.64it/s]Running 10000 simulations.:  90%|████████▉ | 8980/10000 [00:37<00:04, 238.15it/s]Running 10000 simulations.:  90%|█████████ | 9004/10000 [00:37<00:04, 238.21it/s]Running 10000 simulations.:  90%|█████████ | 9028/10000 [00:37<00:04, 238.51it/s]Running 10000 simulations.:  91%|█████████ | 9053/10000 [00:37<00:03, 239.24it/s]Running 10000 simulations.:  91%|█████████ | 9078/10000 [00:37<00:03, 239.83it/s]Running 10000 simulations.:  91%|█████████ | 9103/10000 [00:38<00:03, 239.96it/s]Running 10000 simulations.:  91%|█████████▏| 9128/10000 [00:38<00:03, 240.30it/s]Running 10000 simulations.:  92%|█████████▏| 9153/10000 [00:38<00:03, 240.07it/s]Running 10000 simulations.:  92%|█████████▏| 9178/10000 [00:38<00:03, 237.35it/s]Running 10000 simulations.:  92%|█████████▏| 9202/10000 [00:38<00:03, 237.97it/s]Running 10000 simulations.:  92%|█████████▏| 9226/10000 [00:38<00:03, 238.57it/s]Running 10000 simulations.:  93%|█████████▎| 9251/10000 [00:38<00:03, 239.41it/s]Running 10000 simulations.:  93%|█████████▎| 9275/10000 [00:38<00:03, 239.26it/s]Running 10000 simulations.:  93%|█████████▎| 9299/10000 [00:38<00:02, 238.85it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [00:38<00:02, 238.83it/s]Running 10000 simulations.:  93%|█████████▎| 9347/10000 [00:39<00:02, 238.76it/s]Running 10000 simulations.:  94%|█████████▎| 9371/10000 [00:39<00:02, 238.75it/s]Running 10000 simulations.:  94%|█████████▍| 9395/10000 [00:39<00:02, 238.92it/s]Running 10000 simulations.:  94%|█████████▍| 9419/10000 [00:39<00:02, 238.65it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [00:39<00:02, 235.29it/s]Running 10000 simulations.:  95%|█████████▍| 9467/10000 [00:39<00:02, 232.20it/s]Running 10000 simulations.:  95%|█████████▍| 9491/10000 [00:39<00:02, 230.62it/s]Running 10000 simulations.:  95%|█████████▌| 9515/10000 [00:39<00:02, 229.53it/s]Running 10000 simulations.:  95%|█████████▌| 9538/10000 [00:39<00:02, 229.17it/s]Running 10000 simulations.:  96%|█████████▌| 9562/10000 [00:39<00:01, 230.84it/s]Running 10000 simulations.:  96%|█████████▌| 9586/10000 [00:40<00:01, 232.71it/s]Running 10000 simulations.:  96%|█████████▌| 9610/10000 [00:40<00:01, 233.67it/s]Running 10000 simulations.:  96%|█████████▋| 9634/10000 [00:40<00:01, 234.13it/s]Running 10000 simulations.:  97%|█████████▋| 9658/10000 [00:40<00:01, 234.88it/s]Running 10000 simulations.:  97%|█████████▋| 9682/10000 [00:40<00:01, 234.69it/s]Running 10000 simulations.:  97%|█████████▋| 9706/10000 [00:40<00:01, 235.01it/s]Running 10000 simulations.:  97%|█████████▋| 9730/10000 [00:40<00:01, 234.53it/s]Running 10000 simulations.:  98%|█████████▊| 9754/10000 [00:40<00:01, 235.13it/s]Running 10000 simulations.:  98%|█████████▊| 9778/10000 [00:40<00:00, 236.29it/s]Running 10000 simulations.:  98%|█████████▊| 9802/10000 [00:40<00:00, 236.96it/s]Running 10000 simulations.:  98%|█████████▊| 9826/10000 [00:41<00:00, 237.46it/s]Running 10000 simulations.:  98%|█████████▊| 9850/10000 [00:41<00:00, 237.90it/s]Running 10000 simulations.:  99%|█████████▉| 9875/10000 [00:41<00:00, 238.71it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:41<00:00, 238.59it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [00:41<00:00, 237.98it/s]Running 10000 simulations.:  99%|█████████▉| 9947/10000 [00:41<00:00, 235.98it/s]Running 10000 simulations.: 100%|█████████▉| 9971/10000 [00:41<00:00, 235.36it/s]Running 10000 simulations.: 100%|█████████▉| 9995/10000 [00:41<00:00, 235.92it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 239.18it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 255.38it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 254.77it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:38, 254.63it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:38, 254.77it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:38, 254.59it/s]Running 10000 simulations.:   2%|▏         | 156/10000 [00:00<00:38, 254.18it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:00<00:38, 253.71it/s]Running 10000 simulations.:   2%|▏         | 207/10000 [00:00<00:38, 252.16it/s]Running 10000 simulations.:   2%|▏         | 232/10000 [00:00<00:39, 248.81it/s]Running 10000 simulations.:   3%|▎         | 257/10000 [00:01<00:39, 248.82it/s]Running 10000 simulations.:   3%|▎         | 283/10000 [00:01<00:38, 249.58it/s]Running 10000 simulations.:   3%|▎         | 309/10000 [00:01<00:38, 249.76it/s]Running 10000 simulations.:   3%|▎         | 334/10000 [00:01<00:38, 249.67it/s]Running 10000 simulations.:   4%|▎         | 359/10000 [00:01<00:38, 249.23it/s]Running 10000 simulations.:   4%|▍         | 384/10000 [00:01<00:38, 247.89it/s]Running 10000 simulations.:   4%|▍         | 409/10000 [00:01<00:38, 247.70it/s]Running 10000 simulations.:   4%|▍         | 434/10000 [00:01<00:39, 245.19it/s]Running 10000 simulations.:   5%|▍         | 459/10000 [00:01<00:39, 242.79it/s]Running 10000 simulations.:   5%|▍         | 484/10000 [00:01<00:39, 241.25it/s]Running 10000 simulations.:   5%|▌         | 509/10000 [00:02<00:40, 233.21it/s]Running 10000 simulations.:   5%|▌         | 534/10000 [00:02<00:40, 235.22it/s]Running 10000 simulations.:   6%|▌         | 559/10000 [00:02<00:39, 237.79it/s]Running 10000 simulations.:   6%|▌         | 584/10000 [00:02<00:39, 239.53it/s]Running 10000 simulations.:   6%|▌         | 609/10000 [00:02<00:39, 240.48it/s]Running 10000 simulations.:   6%|▋         | 634/10000 [00:02<00:38, 242.00it/s]Running 10000 simulations.:   7%|▋         | 659/10000 [00:02<00:38, 243.11it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:02<00:38, 243.39it/s]Running 10000 simulations.:   7%|▋         | 709/10000 [00:02<00:38, 244.04it/s]Running 10000 simulations.:   7%|▋         | 734/10000 [00:02<00:37, 244.35it/s]Running 10000 simulations.:   8%|▊         | 759/10000 [00:03<00:37, 244.01it/s]Running 10000 simulations.:   8%|▊         | 784/10000 [00:03<00:37, 244.87it/s]Running 10000 simulations.:   8%|▊         | 809/10000 [00:03<00:37, 245.16it/s]Running 10000 simulations.:   8%|▊         | 834/10000 [00:03<00:37, 245.46it/s]Running 10000 simulations.:   9%|▊         | 859/10000 [00:03<00:37, 245.91it/s]Running 10000 simulations.:   9%|▉         | 884/10000 [00:03<00:37, 245.77it/s]Running 10000 simulations.:   9%|▉         | 909/10000 [00:03<00:37, 245.00it/s]Running 10000 simulations.:   9%|▉         | 934/10000 [00:03<00:37, 243.99it/s]Running 10000 simulations.:  10%|▉         | 959/10000 [00:03<00:37, 243.68it/s]Running 10000 simulations.:  10%|▉         | 984/10000 [00:04<00:36, 244.26it/s]Running 10000 simulations.:  10%|█         | 1009/10000 [00:04<00:36, 244.54it/s]Running 10000 simulations.:  10%|█         | 1034/10000 [00:04<00:36, 243.78it/s]Running 10000 simulations.:  11%|█         | 1059/10000 [00:04<00:36, 241.90it/s]Running 10000 simulations.:  11%|█         | 1084/10000 [00:04<00:49, 178.52it/s]Running 10000 simulations.:  11%|█         | 1109/10000 [00:04<00:45, 194.49it/s]Running 10000 simulations.:  11%|█▏        | 1134/10000 [00:04<00:42, 207.29it/s]Running 10000 simulations.:  12%|█▏        | 1159/10000 [00:04<00:40, 216.39it/s]Running 10000 simulations.:  12%|█▏        | 1184/10000 [00:04<00:39, 223.60it/s]Running 10000 simulations.:  12%|█▏        | 1209/10000 [00:05<00:38, 229.18it/s]Running 10000 simulations.:  12%|█▏        | 1234/10000 [00:05<00:37, 233.59it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:05<00:36, 236.29it/s]Running 10000 simulations.:  13%|█▎        | 1284/10000 [00:05<00:36, 238.11it/s]Running 10000 simulations.:  13%|█▎        | 1309/10000 [00:05<00:36, 239.10it/s]Running 10000 simulations.:  13%|█▎        | 1334/10000 [00:05<00:36, 239.28it/s]Running 10000 simulations.:  14%|█▎        | 1359/10000 [00:05<00:36, 239.23it/s]Running 10000 simulations.:  14%|█▍        | 1384/10000 [00:05<00:35, 239.94it/s]Running 10000 simulations.:  14%|█▍        | 1409/10000 [00:05<00:35, 240.34it/s]Running 10000 simulations.:  14%|█▍        | 1434/10000 [00:05<00:35, 240.56it/s]Running 10000 simulations.:  15%|█▍        | 1459/10000 [00:06<00:35, 241.01it/s]Running 10000 simulations.:  15%|█▍        | 1484/10000 [00:06<00:35, 241.27it/s]Running 10000 simulations.:  15%|█▌        | 1509/10000 [00:06<00:35, 241.57it/s]Running 10000 simulations.:  15%|█▌        | 1534/10000 [00:06<00:35, 241.15it/s]Running 10000 simulations.:  16%|█▌        | 1559/10000 [00:06<00:34, 241.74it/s]Running 10000 simulations.:  16%|█▌        | 1584/10000 [00:06<00:34, 242.05it/s]Running 10000 simulations.:  16%|█▌        | 1609/10000 [00:06<00:34, 242.70it/s]Running 10000 simulations.:  16%|█▋        | 1634/10000 [00:06<00:34, 242.33it/s]Running 10000 simulations.:  17%|█▋        | 1659/10000 [00:06<00:34, 241.22it/s]Running 10000 simulations.:  17%|█▋        | 1684/10000 [00:07<00:34, 240.39it/s]Running 10000 simulations.:  17%|█▋        | 1709/10000 [00:07<00:34, 239.46it/s]Running 10000 simulations.:  17%|█▋        | 1733/10000 [00:07<00:34, 239.57it/s]Running 10000 simulations.:  18%|█▊        | 1758/10000 [00:07<00:34, 239.80it/s]Running 10000 simulations.:  18%|█▊        | 1783/10000 [00:07<00:34, 240.34it/s]Running 10000 simulations.:  18%|█▊        | 1808/10000 [00:07<00:34, 240.71it/s]Running 10000 simulations.:  18%|█▊        | 1833/10000 [00:07<00:33, 240.61it/s]Running 10000 simulations.:  19%|█▊        | 1858/10000 [00:07<00:33, 240.78it/s]Running 10000 simulations.:  19%|█▉        | 1883/10000 [00:07<00:33, 240.62it/s]Running 10000 simulations.:  19%|█▉        | 1908/10000 [00:07<00:33, 240.08it/s]Running 10000 simulations.:  19%|█▉        | 1933/10000 [00:08<00:33, 240.36it/s]Running 10000 simulations.:  20%|█▉        | 1958/10000 [00:08<00:33, 240.48it/s]Running 10000 simulations.:  20%|█▉        | 1983/10000 [00:08<00:33, 240.85it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:08<00:33, 240.17it/s]Running 10000 simulations.:  20%|██        | 2033/10000 [00:08<00:33, 240.19it/s]Running 10000 simulations.:  21%|██        | 2058/10000 [00:08<00:32, 241.03it/s]Running 10000 simulations.:  21%|██        | 2083/10000 [00:08<00:32, 240.85it/s]Running 10000 simulations.:  21%|██        | 2108/10000 [00:08<00:32, 240.21it/s]Running 10000 simulations.:  21%|██▏       | 2133/10000 [00:08<00:32, 239.34it/s]Running 10000 simulations.:  22%|██▏       | 2158/10000 [00:08<00:32, 239.44it/s]Running 10000 simulations.:  22%|██▏       | 2182/10000 [00:09<00:32, 239.42it/s]Running 10000 simulations.:  22%|██▏       | 2206/10000 [00:09<00:32, 239.33it/s]Running 10000 simulations.:  22%|██▏       | 2231/10000 [00:09<00:32, 239.61it/s]Running 10000 simulations.:  23%|██▎       | 2255/10000 [00:09<00:32, 239.65it/s]Running 10000 simulations.:  23%|██▎       | 2279/10000 [00:09<00:32, 239.33it/s]Running 10000 simulations.:  23%|██▎       | 2303/10000 [00:09<00:32, 238.19it/s]Running 10000 simulations.:  23%|██▎       | 2327/10000 [00:09<00:32, 237.77it/s]Running 10000 simulations.:  24%|██▎       | 2351/10000 [00:09<00:32, 237.65it/s]Running 10000 simulations.:  24%|██▍       | 2375/10000 [00:09<00:32, 237.67it/s]Running 10000 simulations.:  24%|██▍       | 2399/10000 [00:10<00:31, 237.87it/s]Running 10000 simulations.:  24%|██▍       | 2423/10000 [00:10<00:31, 238.13it/s]Running 10000 simulations.:  24%|██▍       | 2447/10000 [00:10<00:31, 238.14it/s]Running 10000 simulations.:  25%|██▍       | 2471/10000 [00:10<00:31, 238.18it/s]Running 10000 simulations.:  25%|██▍       | 2495/10000 [00:10<00:31, 237.26it/s]Running 10000 simulations.:  25%|██▌       | 2519/10000 [00:10<00:31, 237.71it/s]Running 10000 simulations.:  25%|██▌       | 2543/10000 [00:10<00:31, 238.26it/s]Running 10000 simulations.:  26%|██▌       | 2567/10000 [00:10<00:31, 238.28it/s]Running 10000 simulations.:  26%|██▌       | 2591/10000 [00:10<00:31, 238.51it/s]Running 10000 simulations.:  26%|██▌       | 2615/10000 [00:10<00:30, 238.61it/s]Running 10000 simulations.:  26%|██▋       | 2639/10000 [00:11<00:30, 238.73it/s]Running 10000 simulations.:  27%|██▋       | 2663/10000 [00:11<00:30, 238.80it/s]Running 10000 simulations.:  27%|██▋       | 2687/10000 [00:11<00:30, 238.46it/s]Running 10000 simulations.:  27%|██▋       | 2711/10000 [00:11<00:30, 238.34it/s]Running 10000 simulations.:  27%|██▋       | 2735/10000 [00:11<00:30, 238.46it/s]Running 10000 simulations.:  28%|██▊       | 2759/10000 [00:11<00:30, 238.56it/s]Running 10000 simulations.:  28%|██▊       | 2784/10000 [00:11<00:30, 239.38it/s]Running 10000 simulations.:  28%|██▊       | 2809/10000 [00:11<00:29, 240.32it/s]Running 10000 simulations.:  28%|██▊       | 2834/10000 [00:11<00:29, 240.63it/s]Running 10000 simulations.:  29%|██▊       | 2859/10000 [00:11<00:29, 241.12it/s]Running 10000 simulations.:  29%|██▉       | 2884/10000 [00:12<00:29, 239.39it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:12<00:30, 234.68it/s]Running 10000 simulations.:  29%|██▉       | 2932/10000 [00:12<00:30, 230.89it/s]Running 10000 simulations.:  30%|██▉       | 2956/10000 [00:12<00:30, 228.97it/s]Running 10000 simulations.:  30%|██▉       | 2979/10000 [00:12<00:30, 228.45it/s]Running 10000 simulations.:  30%|███       | 3002/10000 [00:12<00:30, 227.71it/s]Running 10000 simulations.:  30%|███       | 3025/10000 [00:12<00:30, 227.42it/s]Running 10000 simulations.:  30%|███       | 3048/10000 [00:12<00:30, 227.48it/s]Running 10000 simulations.:  31%|███       | 3072/10000 [00:12<00:30, 230.78it/s]Running 10000 simulations.:  31%|███       | 3096/10000 [00:12<00:29, 232.77it/s]Running 10000 simulations.:  31%|███       | 3120/10000 [00:13<00:29, 234.36it/s]Running 10000 simulations.:  31%|███▏      | 3145/10000 [00:13<00:28, 236.71it/s]Running 10000 simulations.:  32%|███▏      | 3170/10000 [00:13<00:28, 238.11it/s]Running 10000 simulations.:  32%|███▏      | 3194/10000 [00:13<00:28, 238.58it/s]Running 10000 simulations.:  32%|███▏      | 3218/10000 [00:13<00:28, 238.50it/s]Running 10000 simulations.:  32%|███▏      | 3242/10000 [00:13<00:28, 238.11it/s]Running 10000 simulations.:  33%|███▎      | 3266/10000 [00:13<00:28, 238.17it/s]Running 10000 simulations.:  33%|███▎      | 3291/10000 [00:13<00:28, 238.81it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:13<00:28, 238.52it/s]Running 10000 simulations.:  33%|███▎      | 3339/10000 [00:13<00:27, 238.57it/s]Running 10000 simulations.:  34%|███▎      | 3363/10000 [00:14<00:27, 238.09it/s]Running 10000 simulations.:  34%|███▍      | 3387/10000 [00:14<00:27, 237.75it/s]Running 10000 simulations.:  34%|███▍      | 3411/10000 [00:14<00:27, 236.58it/s]Running 10000 simulations.:  34%|███▍      | 3435/10000 [00:14<00:27, 235.47it/s]Running 10000 simulations.:  35%|███▍      | 3459/10000 [00:14<00:27, 236.24it/s]Running 10000 simulations.:  35%|███▍      | 3483/10000 [00:14<00:27, 237.25it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:14<00:27, 237.98it/s]Running 10000 simulations.:  35%|███▌      | 3531/10000 [00:14<00:27, 238.39it/s]Running 10000 simulations.:  36%|███▌      | 3556/10000 [00:14<00:26, 239.07it/s]Running 10000 simulations.:  36%|███▌      | 3581/10000 [00:14<00:26, 239.87it/s]Running 10000 simulations.:  36%|███▌      | 3605/10000 [00:15<00:26, 239.71it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:15<00:26, 240.15it/s]Running 10000 simulations.:  37%|███▋      | 3655/10000 [00:15<00:26, 239.67it/s]Running 10000 simulations.:  37%|███▋      | 3680/10000 [00:15<00:26, 239.81it/s]Running 10000 simulations.:  37%|███▋      | 3704/10000 [00:15<00:26, 239.84it/s]Running 10000 simulations.:  37%|███▋      | 3728/10000 [00:15<00:26, 239.69it/s]Running 10000 simulations.:  38%|███▊      | 3752/10000 [00:15<00:26, 239.48it/s]Running 10000 simulations.:  38%|███▊      | 3776/10000 [00:15<00:26, 239.23it/s]Running 10000 simulations.:  38%|███▊      | 3801/10000 [00:15<00:25, 240.05it/s]Running 10000 simulations.:  38%|███▊      | 3826/10000 [00:16<00:25, 238.92it/s]Running 10000 simulations.:  38%|███▊      | 3850/10000 [00:16<00:25, 236.95it/s]Running 10000 simulations.:  39%|███▉      | 3875/10000 [00:16<00:25, 238.41it/s]Running 10000 simulations.:  39%|███▉      | 3900/10000 [00:16<00:25, 239.18it/s]Running 10000 simulations.:  39%|███▉      | 3924/10000 [00:16<00:25, 239.08it/s]Running 10000 simulations.:  39%|███▉      | 3949/10000 [00:16<00:25, 239.35it/s]Running 10000 simulations.:  40%|███▉      | 3974/10000 [00:16<00:25, 240.08it/s]Running 10000 simulations.:  40%|███▉      | 3999/10000 [00:16<00:24, 240.31it/s]Running 10000 simulations.:  40%|████      | 4024/10000 [00:16<00:24, 240.68it/s]Running 10000 simulations.:  40%|████      | 4049/10000 [00:16<00:24, 240.84it/s]Running 10000 simulations.:  41%|████      | 4074/10000 [00:17<00:24, 240.82it/s]Running 10000 simulations.:  41%|████      | 4099/10000 [00:17<00:24, 240.50it/s]Running 10000 simulations.:  41%|████      | 4124/10000 [00:17<00:24, 240.99it/s]Running 10000 simulations.:  41%|████▏     | 4149/10000 [00:17<00:24, 239.78it/s]Running 10000 simulations.:  42%|████▏     | 4173/10000 [00:17<00:24, 239.68it/s]Running 10000 simulations.:  42%|████▏     | 4197/10000 [00:17<00:24, 239.64it/s]Running 10000 simulations.:  42%|████▏     | 4221/10000 [00:17<00:24, 239.05it/s]Running 10000 simulations.:  42%|████▏     | 4245/10000 [00:17<00:24, 238.98it/s]Running 10000 simulations.:  43%|████▎     | 4270/10000 [00:17<00:23, 239.29it/s]Running 10000 simulations.:  43%|████▎     | 4295/10000 [00:17<00:23, 240.01it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:18<00:23, 239.65it/s]Running 10000 simulations.:  43%|████▎     | 4344/10000 [00:18<00:23, 239.46it/s]Running 10000 simulations.:  44%|████▎     | 4368/10000 [00:18<00:23, 239.48it/s]Running 10000 simulations.:  44%|████▍     | 4392/10000 [00:18<00:23, 239.13it/s]Running 10000 simulations.:  44%|████▍     | 4417/10000 [00:18<00:23, 239.43it/s]Running 10000 simulations.:  44%|████▍     | 4442/10000 [00:18<00:23, 239.95it/s]Running 10000 simulations.:  45%|████▍     | 4467/10000 [00:18<00:23, 240.20it/s]Running 10000 simulations.:  45%|████▍     | 4492/10000 [00:18<00:22, 239.82it/s]Running 10000 simulations.:  45%|████▌     | 4517/10000 [00:18<00:22, 240.16it/s]Running 10000 simulations.:  45%|████▌     | 4542/10000 [00:19<00:22, 240.39it/s]Running 10000 simulations.:  46%|████▌     | 4567/10000 [00:19<00:22, 240.75it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:19<00:22, 240.50it/s]Running 10000 simulations.:  46%|████▌     | 4617/10000 [00:19<00:22, 240.07it/s]Running 10000 simulations.:  46%|████▋     | 4642/10000 [00:19<00:22, 239.25it/s]Running 10000 simulations.:  47%|████▋     | 4666/10000 [00:19<00:22, 238.87it/s]Running 10000 simulations.:  47%|████▋     | 4690/10000 [00:19<00:22, 238.64it/s]Running 10000 simulations.:  47%|████▋     | 4715/10000 [00:19<00:22, 239.21it/s]Running 10000 simulations.:  47%|████▋     | 4739/10000 [00:19<00:22, 238.82it/s]Running 10000 simulations.:  48%|████▊     | 4764/10000 [00:19<00:21, 239.32it/s]Running 10000 simulations.:  48%|████▊     | 4788/10000 [00:20<00:21, 239.01it/s]Running 10000 simulations.:  48%|████▊     | 4813/10000 [00:20<00:21, 239.48it/s]Running 10000 simulations.:  48%|████▊     | 4837/10000 [00:20<00:21, 239.63it/s]Running 10000 simulations.:  49%|████▊     | 4861/10000 [00:20<00:21, 239.72it/s]Running 10000 simulations.:  49%|████▉     | 4886/10000 [00:20<00:21, 240.38it/s]Running 10000 simulations.:  49%|████▉     | 4911/10000 [00:20<00:21, 241.11it/s]Running 10000 simulations.:  49%|████▉     | 4936/10000 [00:20<00:21, 241.02it/s]Running 10000 simulations.:  50%|████▉     | 4961/10000 [00:20<00:20, 240.38it/s]Running 10000 simulations.:  50%|████▉     | 4986/10000 [00:20<00:20, 241.22it/s]Running 10000 simulations.:  50%|█████     | 5011/10000 [00:20<00:20, 241.85it/s]Running 10000 simulations.:  50%|█████     | 5036/10000 [00:21<00:20, 240.90it/s]Running 10000 simulations.:  51%|█████     | 5061/10000 [00:21<00:20, 240.50it/s]Running 10000 simulations.:  51%|█████     | 5086/10000 [00:21<00:20, 240.53it/s]Running 10000 simulations.:  51%|█████     | 5111/10000 [00:21<00:20, 239.85it/s]Running 10000 simulations.:  51%|█████▏    | 5135/10000 [00:21<00:20, 239.55it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:21<00:20, 239.87it/s]Running 10000 simulations.:  52%|█████▏    | 5185/10000 [00:21<00:19, 241.01it/s]Running 10000 simulations.:  52%|█████▏    | 5210/10000 [00:21<00:19, 241.15it/s]Running 10000 simulations.:  52%|█████▏    | 5235/10000 [00:21<00:19, 240.78it/s]Running 10000 simulations.:  53%|█████▎    | 5260/10000 [00:21<00:19, 240.65it/s]Running 10000 simulations.:  53%|█████▎    | 5285/10000 [00:22<00:19, 240.39it/s]Running 10000 simulations.:  53%|█████▎    | 5310/10000 [00:22<00:19, 239.35it/s]Running 10000 simulations.:  53%|█████▎    | 5335/10000 [00:22<00:19, 239.79it/s]Running 10000 simulations.:  54%|█████▎    | 5360/10000 [00:22<00:19, 240.50it/s]Running 10000 simulations.:  54%|█████▍    | 5385/10000 [00:22<00:19, 240.71it/s]Running 10000 simulations.:  54%|█████▍    | 5410/10000 [00:22<00:19, 240.18it/s]Running 10000 simulations.:  54%|█████▍    | 5435/10000 [00:22<00:19, 239.77it/s]Running 10000 simulations.:  55%|█████▍    | 5459/10000 [00:22<00:18, 239.56it/s]Running 10000 simulations.:  55%|█████▍    | 5484/10000 [00:22<00:18, 239.95it/s]Running 10000 simulations.:  55%|█████▌    | 5508/10000 [00:23<00:18, 239.91it/s]Running 10000 simulations.:  55%|█████▌    | 5533/10000 [00:23<00:18, 240.75it/s]Running 10000 simulations.:  56%|█████▌    | 5558/10000 [00:23<00:18, 240.32it/s]Running 10000 simulations.:  56%|█████▌    | 5583/10000 [00:23<00:18, 240.96it/s]Running 10000 simulations.:  56%|█████▌    | 5608/10000 [00:23<00:18, 241.60it/s]Running 10000 simulations.:  56%|█████▋    | 5633/10000 [00:23<00:18, 241.17it/s]Running 10000 simulations.:  57%|█████▋    | 5658/10000 [00:23<00:18, 240.19it/s]Running 10000 simulations.:  57%|█████▋    | 5683/10000 [00:23<00:18, 239.67it/s]Running 10000 simulations.:  57%|█████▋    | 5707/10000 [00:23<00:17, 239.46it/s]Running 10000 simulations.:  57%|█████▋    | 5732/10000 [00:23<00:17, 239.72it/s]Running 10000 simulations.:  58%|█████▊    | 5757/10000 [00:24<00:17, 240.21it/s]Running 10000 simulations.:  58%|█████▊    | 5782/10000 [00:24<00:17, 239.58it/s]Running 10000 simulations.:  58%|█████▊    | 5806/10000 [00:24<00:17, 239.13it/s]Running 10000 simulations.:  58%|█████▊    | 5830/10000 [00:24<00:17, 239.14it/s]Running 10000 simulations.:  59%|█████▊    | 5854/10000 [00:24<00:17, 239.16it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:24<00:17, 239.33it/s]Running 10000 simulations.:  59%|█████▉    | 5903/10000 [00:24<00:17, 239.62it/s]Running 10000 simulations.:  59%|█████▉    | 5927/10000 [00:24<00:16, 239.64it/s]Running 10000 simulations.:  60%|█████▉    | 5951/10000 [00:24<00:16, 239.61it/s]Running 10000 simulations.:  60%|█████▉    | 5975/10000 [00:24<00:16, 239.70it/s]Running 10000 simulations.:  60%|█████▉    | 5999/10000 [00:25<00:16, 239.60it/s]Running 10000 simulations.:  60%|██████    | 6024/10000 [00:25<00:16, 240.10it/s]Running 10000 simulations.:  60%|██████    | 6049/10000 [00:25<00:16, 240.91it/s]Running 10000 simulations.:  61%|██████    | 6074/10000 [00:25<00:16, 240.66it/s]Running 10000 simulations.:  61%|██████    | 6099/10000 [00:25<00:16, 238.77it/s]Running 10000 simulations.:  61%|██████    | 6124/10000 [00:25<00:16, 239.71it/s]Running 10000 simulations.:  61%|██████▏   | 6149/10000 [00:25<00:16, 240.60it/s]Running 10000 simulations.:  62%|██████▏   | 6174/10000 [00:25<00:15, 240.39it/s]Running 10000 simulations.:  62%|██████▏   | 6199/10000 [00:25<00:15, 240.69it/s]Running 10000 simulations.:  62%|██████▏   | 6224/10000 [00:26<00:15, 241.29it/s]Running 10000 simulations.:  62%|██████▏   | 6249/10000 [00:26<00:15, 241.49it/s]Running 10000 simulations.:  63%|██████▎   | 6274/10000 [00:26<00:15, 242.12it/s]Running 10000 simulations.:  63%|██████▎   | 6299/10000 [00:26<00:15, 241.78it/s]Running 10000 simulations.:  63%|██████▎   | 6324/10000 [00:26<00:15, 242.16it/s]Running 10000 simulations.:  63%|██████▎   | 6349/10000 [00:26<00:15, 242.29it/s]Running 10000 simulations.:  64%|██████▎   | 6374/10000 [00:26<00:15, 241.07it/s]Running 10000 simulations.:  64%|██████▍   | 6399/10000 [00:26<00:14, 240.07it/s]Running 10000 simulations.:  64%|██████▍   | 6424/10000 [00:26<00:14, 239.94it/s]Running 10000 simulations.:  64%|██████▍   | 6449/10000 [00:26<00:14, 240.88it/s]Running 10000 simulations.:  65%|██████▍   | 6474/10000 [00:27<00:14, 241.40it/s]Running 10000 simulations.:  65%|██████▍   | 6499/10000 [00:27<00:14, 240.86it/s]Running 10000 simulations.:  65%|██████▌   | 6524/10000 [00:27<00:14, 240.92it/s]Running 10000 simulations.:  65%|██████▌   | 6549/10000 [00:27<00:14, 241.46it/s]Running 10000 simulations.:  66%|██████▌   | 6574/10000 [00:27<00:14, 242.02it/s]Running 10000 simulations.:  66%|██████▌   | 6599/10000 [00:27<00:14, 242.31it/s]Running 10000 simulations.:  66%|██████▌   | 6624/10000 [00:27<00:13, 242.31it/s]Running 10000 simulations.:  66%|██████▋   | 6649/10000 [00:27<00:13, 241.19it/s]Running 10000 simulations.:  67%|██████▋   | 6674/10000 [00:27<00:13, 241.01it/s]Running 10000 simulations.:  67%|██████▋   | 6699/10000 [00:27<00:13, 240.34it/s]Running 10000 simulations.:  67%|██████▋   | 6724/10000 [00:28<00:13, 240.07it/s]Running 10000 simulations.:  67%|██████▋   | 6749/10000 [00:28<00:13, 240.50it/s]Running 10000 simulations.:  68%|██████▊   | 6774/10000 [00:28<00:13, 240.74it/s]Running 10000 simulations.:  68%|██████▊   | 6799/10000 [00:28<00:13, 240.63it/s]Running 10000 simulations.:  68%|██████▊   | 6824/10000 [00:28<00:13, 241.36it/s]Running 10000 simulations.:  68%|██████▊   | 6849/10000 [00:28<00:13, 241.32it/s]Running 10000 simulations.:  69%|██████▊   | 6874/10000 [00:28<00:12, 241.29it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:28<00:12, 242.04it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:28<00:12, 242.28it/s]Running 10000 simulations.:  69%|██████▉   | 6949/10000 [00:29<00:12, 241.97it/s]Running 10000 simulations.:  70%|██████▉   | 6974/10000 [00:29<00:12, 240.33it/s]Running 10000 simulations.:  70%|██████▉   | 6999/10000 [00:29<00:12, 238.62it/s]Running 10000 simulations.:  70%|███████   | 7023/10000 [00:29<00:12, 238.79it/s]Running 10000 simulations.:  70%|███████   | 7048/10000 [00:29<00:12, 239.31it/s]Running 10000 simulations.:  71%|███████   | 7073/10000 [00:29<00:12, 239.99it/s]Running 10000 simulations.:  71%|███████   | 7098/10000 [00:29<00:12, 240.92it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:29<00:11, 240.80it/s]Running 10000 simulations.:  71%|███████▏  | 7148/10000 [00:29<00:11, 240.66it/s]Running 10000 simulations.:  72%|███████▏  | 7173/10000 [00:29<00:11, 241.04it/s]Running 10000 simulations.:  72%|███████▏  | 7198/10000 [00:30<00:11, 240.05it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:30<00:11, 238.81it/s]Running 10000 simulations.:  72%|███████▏  | 7247/10000 [00:30<00:11, 238.65it/s]Running 10000 simulations.:  73%|███████▎  | 7272/10000 [00:30<00:11, 239.19it/s]Running 10000 simulations.:  73%|███████▎  | 7297/10000 [00:30<00:11, 239.79it/s]Running 10000 simulations.:  73%|███████▎  | 7322/10000 [00:30<00:11, 240.56it/s]Running 10000 simulations.:  73%|███████▎  | 7347/10000 [00:30<00:11, 240.67it/s]Running 10000 simulations.:  74%|███████▎  | 7372/10000 [00:30<00:10, 240.73it/s]Running 10000 simulations.:  74%|███████▍  | 7397/10000 [00:30<00:10, 239.69it/s]Running 10000 simulations.:  74%|███████▍  | 7421/10000 [00:30<00:10, 239.12it/s]Running 10000 simulations.:  74%|███████▍  | 7445/10000 [00:31<00:10, 239.00it/s]Running 10000 simulations.:  75%|███████▍  | 7469/10000 [00:31<00:10, 238.82it/s]Running 10000 simulations.:  75%|███████▍  | 7493/10000 [00:31<00:10, 238.23it/s]Running 10000 simulations.:  75%|███████▌  | 7517/10000 [00:31<00:10, 238.10it/s]Running 10000 simulations.:  75%|███████▌  | 7541/10000 [00:31<00:10, 238.00it/s]Running 10000 simulations.:  76%|███████▌  | 7566/10000 [00:31<00:10, 238.88it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:31<00:10, 240.18it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:31<00:09, 240.76it/s]Running 10000 simulations.:  76%|███████▋  | 7641/10000 [00:31<00:09, 241.10it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:32<00:09, 241.08it/s]Running 10000 simulations.:  77%|███████▋  | 7691/10000 [00:32<00:09, 233.02it/s]Running 10000 simulations.:  77%|███████▋  | 7716/10000 [00:32<00:09, 235.63it/s]Running 10000 simulations.:  77%|███████▋  | 7741/10000 [00:32<00:09, 237.29it/s]Running 10000 simulations.:  78%|███████▊  | 7766/10000 [00:32<00:09, 238.69it/s]Running 10000 simulations.:  78%|███████▊  | 7790/10000 [00:32<00:09, 238.32it/s]Running 10000 simulations.:  78%|███████▊  | 7814/10000 [00:32<00:09, 237.95it/s]Running 10000 simulations.:  78%|███████▊  | 7838/10000 [00:32<00:09, 237.59it/s]Running 10000 simulations.:  79%|███████▊  | 7862/10000 [00:32<00:09, 237.47it/s]Running 10000 simulations.:  79%|███████▉  | 7887/10000 [00:32<00:08, 238.69it/s]Running 10000 simulations.:  79%|███████▉  | 7912/10000 [00:33<00:08, 239.41it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:33<00:08, 239.44it/s]Running 10000 simulations.:  80%|███████▉  | 7960/10000 [00:33<00:08, 239.56it/s]Running 10000 simulations.:  80%|███████▉  | 7985/10000 [00:33<00:08, 239.86it/s]Running 10000 simulations.:  80%|████████  | 8010/10000 [00:33<00:08, 240.31it/s]Running 10000 simulations.:  80%|████████  | 8035/10000 [00:33<00:08, 240.62it/s]Running 10000 simulations.:  81%|████████  | 8060/10000 [00:33<00:08, 240.70it/s]Running 10000 simulations.:  81%|████████  | 8085/10000 [00:33<00:07, 240.82it/s]Running 10000 simulations.:  81%|████████  | 8110/10000 [00:33<00:07, 240.82it/s]Running 10000 simulations.:  81%|████████▏ | 8135/10000 [00:33<00:07, 240.26it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:34<00:07, 239.34it/s]Running 10000 simulations.:  82%|████████▏ | 8185/10000 [00:34<00:07, 239.56it/s]Running 10000 simulations.:  82%|████████▏ | 8210/10000 [00:34<00:07, 239.93it/s]Running 10000 simulations.:  82%|████████▏ | 8234/10000 [00:34<00:07, 239.42it/s]Running 10000 simulations.:  83%|████████▎ | 8259/10000 [00:34<00:07, 239.96it/s]Running 10000 simulations.:  83%|████████▎ | 8284/10000 [00:34<00:07, 240.22it/s]Running 10000 simulations.:  83%|████████▎ | 8309/10000 [00:34<00:07, 240.03it/s]Running 10000 simulations.:  83%|████████▎ | 8334/10000 [00:34<00:06, 239.46it/s]Running 10000 simulations.:  84%|████████▎ | 8358/10000 [00:34<00:06, 237.96it/s]Running 10000 simulations.:  84%|████████▍ | 8382/10000 [00:35<00:06, 235.85it/s]Running 10000 simulations.:  84%|████████▍ | 8406/10000 [00:35<00:06, 234.68it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:35<00:06, 234.52it/s]Running 10000 simulations.:  85%|████████▍ | 8454/10000 [00:35<00:06, 234.63it/s]Running 10000 simulations.:  85%|████████▍ | 8478/10000 [00:35<00:06, 234.37it/s]Running 10000 simulations.:  85%|████████▌ | 8502/10000 [00:35<00:06, 232.93it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [00:35<00:06, 232.16it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:35<00:06, 232.22it/s]Running 10000 simulations.:  86%|████████▌ | 8574/10000 [00:35<00:06, 232.64it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [00:35<00:06, 232.89it/s]Running 10000 simulations.:  86%|████████▌ | 8622/10000 [00:36<00:05, 233.15it/s]Running 10000 simulations.:  86%|████████▋ | 8646/10000 [00:36<00:05, 233.45it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [00:36<00:05, 234.14it/s]Running 10000 simulations.:  87%|████████▋ | 8694/10000 [00:36<00:05, 234.49it/s]Running 10000 simulations.:  87%|████████▋ | 8718/10000 [00:36<00:05, 234.45it/s]Running 10000 simulations.:  87%|████████▋ | 8742/10000 [00:36<00:05, 233.69it/s]Running 10000 simulations.:  88%|████████▊ | 8766/10000 [00:36<00:05, 233.41it/s]Running 10000 simulations.:  88%|████████▊ | 8790/10000 [00:36<00:05, 233.62it/s]Running 10000 simulations.:  88%|████████▊ | 8814/10000 [00:36<00:05, 234.63it/s]Running 10000 simulations.:  88%|████████▊ | 8838/10000 [00:36<00:04, 235.08it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [00:37<00:04, 234.89it/s]Running 10000 simulations.:  89%|████████▉ | 8886/10000 [00:37<00:04, 231.91it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [00:37<00:04, 231.51it/s]Running 10000 simulations.:  89%|████████▉ | 8934/10000 [00:37<00:04, 230.76it/s]Running 10000 simulations.:  90%|████████▉ | 8958/10000 [00:37<00:04, 230.74it/s]Running 10000 simulations.:  90%|████████▉ | 8982/10000 [00:37<00:04, 231.66it/s]Running 10000 simulations.:  90%|█████████ | 9006/10000 [00:37<00:04, 231.39it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:37<00:04, 230.69it/s]Running 10000 simulations.:  91%|█████████ | 9054/10000 [00:37<00:04, 230.89it/s]Running 10000 simulations.:  91%|█████████ | 9078/10000 [00:38<00:03, 231.96it/s]Running 10000 simulations.:  91%|█████████ | 9102/10000 [00:38<00:03, 231.92it/s]Running 10000 simulations.:  91%|█████████▏| 9126/10000 [00:38<00:03, 232.44it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [00:38<00:03, 233.30it/s]Running 10000 simulations.:  92%|█████████▏| 9174/10000 [00:38<00:03, 231.79it/s]Running 10000 simulations.:  92%|█████████▏| 9198/10000 [00:38<00:03, 232.65it/s]Running 10000 simulations.:  92%|█████████▏| 9222/10000 [00:38<00:03, 233.38it/s]Running 10000 simulations.:  92%|█████████▏| 9246/10000 [00:38<00:03, 232.81it/s]Running 10000 simulations.:  93%|█████████▎| 9270/10000 [00:38<00:03, 233.21it/s]Running 10000 simulations.:  93%|█████████▎| 9294/10000 [00:38<00:03, 233.03it/s]Running 10000 simulations.:  93%|█████████▎| 9318/10000 [00:39<00:02, 232.94it/s]Running 10000 simulations.:  93%|█████████▎| 9342/10000 [00:39<00:02, 233.27it/s]Running 10000 simulations.:  94%|█████████▎| 9366/10000 [00:39<00:02, 234.42it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:39<00:02, 235.44it/s]Running 10000 simulations.:  94%|█████████▍| 9414/10000 [00:39<00:02, 236.25it/s]Running 10000 simulations.:  94%|█████████▍| 9438/10000 [00:39<00:02, 237.05it/s]Running 10000 simulations.:  95%|█████████▍| 9463/10000 [00:39<00:02, 238.10it/s]Running 10000 simulations.:  95%|█████████▍| 9488/10000 [00:39<00:02, 238.96it/s]Running 10000 simulations.:  95%|█████████▌| 9513/10000 [00:39<00:02, 239.63it/s]Running 10000 simulations.:  95%|█████████▌| 9537/10000 [00:39<00:01, 239.63it/s]Running 10000 simulations.:  96%|█████████▌| 9562/10000 [00:40<00:01, 239.80it/s]Running 10000 simulations.:  96%|█████████▌| 9586/10000 [00:40<00:01, 239.80it/s]Running 10000 simulations.:  96%|█████████▌| 9610/10000 [00:40<00:01, 239.78it/s]Running 10000 simulations.:  96%|█████████▋| 9635/10000 [00:40<00:01, 240.40it/s]Running 10000 simulations.:  97%|█████████▋| 9660/10000 [00:40<00:01, 240.82it/s]Running 10000 simulations.:  97%|█████████▋| 9685/10000 [00:40<00:01, 241.40it/s]Running 10000 simulations.:  97%|█████████▋| 9710/10000 [00:40<00:01, 242.62it/s]Running 10000 simulations.:  97%|█████████▋| 9735/10000 [00:40<00:01, 241.76it/s]Running 10000 simulations.:  98%|█████████▊| 9760/10000 [00:40<00:00, 241.33it/s]Running 10000 simulations.:  98%|█████████▊| 9785/10000 [00:40<00:00, 241.08it/s]Running 10000 simulations.:  98%|█████████▊| 9810/10000 [00:41<00:00, 242.19it/s]Running 10000 simulations.:  98%|█████████▊| 9835/10000 [00:41<00:00, 242.03it/s]Running 10000 simulations.:  99%|█████████▊| 9860/10000 [00:41<00:00, 240.30it/s]Running 10000 simulations.:  99%|█████████▉| 9885/10000 [00:41<00:00, 240.07it/s]Running 10000 simulations.:  99%|█████████▉| 9910/10000 [00:41<00:00, 240.02it/s]Running 10000 simulations.:  99%|█████████▉| 9935/10000 [00:41<00:00, 240.12it/s]Running 10000 simulations.: 100%|█████████▉| 9960/10000 [00:41<00:00, 241.28it/s]Running 10000 simulations.: 100%|█████████▉| 9985/10000 [00:41<00:00, 242.48it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 238.85it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 255.73it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:39, 254.19it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:39, 253.45it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:39, 252.67it/s]Running 10000 simulations.:   1%|▏         | 129/10000 [00:00<00:39, 251.81it/s]Running 10000 simulations.:   2%|▏         | 155/10000 [00:00<00:39, 251.68it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:00<00:39, 251.14it/s]Running 10000 simulations.:   2%|▏         | 206/10000 [00:00<00:39, 250.82it/s]Running 10000 simulations.:   2%|▏         | 231/10000 [00:00<00:39, 249.62it/s]Running 10000 simulations.:   3%|▎         | 256/10000 [00:01<00:39, 249.03it/s]Running 10000 simulations.:   3%|▎         | 281/10000 [00:01<00:39, 248.43it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:39, 247.73it/s]Running 10000 simulations.:   3%|▎         | 331/10000 [00:01<00:39, 247.65it/s]Running 10000 simulations.:   4%|▎         | 356/10000 [00:01<00:39, 247.19it/s]Running 10000 simulations.:   4%|▍         | 381/10000 [00:01<00:38, 246.92it/s]Running 10000 simulations.:   4%|▍         | 406/10000 [00:01<00:38, 246.93it/s]Running 10000 simulations.:   4%|▍         | 431/10000 [00:01<00:38, 246.43it/s]Running 10000 simulations.:   5%|▍         | 456/10000 [00:01<00:38, 246.07it/s]Running 10000 simulations.:   5%|▍         | 481/10000 [00:01<00:38, 245.81it/s]Running 10000 simulations.:   5%|▌         | 506/10000 [00:02<00:38, 245.38it/s]Running 10000 simulations.:   5%|▌         | 531/10000 [00:02<00:38, 244.97it/s]Running 10000 simulations.:   6%|▌         | 556/10000 [00:02<00:38, 244.60it/s]Running 10000 simulations.:   6%|▌         | 581/10000 [00:02<00:38, 244.50it/s]Running 10000 simulations.:   6%|▌         | 606/10000 [00:02<00:38, 244.60it/s]Running 10000 simulations.:   6%|▋         | 631/10000 [00:02<00:38, 244.52it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:02<00:38, 244.47it/s]Running 10000 simulations.:   7%|▋         | 681/10000 [00:02<00:38, 244.16it/s]Running 10000 simulations.:   7%|▋         | 706/10000 [00:02<00:38, 244.17it/s]Running 10000 simulations.:   7%|▋         | 731/10000 [00:02<00:37, 244.10it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:03<00:37, 244.08it/s]Running 10000 simulations.:   8%|▊         | 781/10000 [00:03<00:37, 244.43it/s]Running 10000 simulations.:   8%|▊         | 806/10000 [00:03<00:37, 243.97it/s]Running 10000 simulations.:   8%|▊         | 831/10000 [00:03<00:37, 243.45it/s]Running 10000 simulations.:   9%|▊         | 856/10000 [00:03<00:37, 243.16it/s]Running 10000 simulations.:   9%|▉         | 881/10000 [00:03<00:37, 242.18it/s]Running 10000 simulations.:   9%|▉         | 906/10000 [00:03<00:37, 242.07it/s]Running 10000 simulations.:   9%|▉         | 931/10000 [00:03<00:37, 242.11it/s]Running 10000 simulations.:  10%|▉         | 956/10000 [00:03<00:37, 241.37it/s]Running 10000 simulations.:  10%|▉         | 981/10000 [00:03<00:37, 241.76it/s]Running 10000 simulations.:  10%|█         | 1006/10000 [00:04<00:37, 242.08it/s]Running 10000 simulations.:  10%|█         | 1031/10000 [00:04<00:37, 242.14it/s]Running 10000 simulations.:  11%|█         | 1056/10000 [00:04<00:36, 242.38it/s]Running 10000 simulations.:  11%|█         | 1081/10000 [00:04<00:36, 242.15it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:04<00:36, 241.84it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:04<00:36, 241.93it/s]Running 10000 simulations.:  12%|█▏        | 1156/10000 [00:04<00:36, 242.40it/s]Running 10000 simulations.:  12%|█▏        | 1181/10000 [00:04<00:36, 242.27it/s]Running 10000 simulations.:  12%|█▏        | 1206/10000 [00:04<00:36, 242.02it/s]Running 10000 simulations.:  12%|█▏        | 1231/10000 [00:05<00:36, 242.02it/s]Running 10000 simulations.:  13%|█▎        | 1256/10000 [00:05<00:36, 242.06it/s]Running 10000 simulations.:  13%|█▎        | 1281/10000 [00:05<00:36, 241.87it/s]Running 10000 simulations.:  13%|█▎        | 1306/10000 [00:05<00:35, 241.85it/s]Running 10000 simulations.:  13%|█▎        | 1331/10000 [00:05<00:35, 241.36it/s]Running 10000 simulations.:  14%|█▎        | 1356/10000 [00:05<00:35, 241.30it/s]Running 10000 simulations.:  14%|█▍        | 1381/10000 [00:05<00:35, 241.57it/s]Running 10000 simulations.:  14%|█▍        | 1406/10000 [00:05<00:35, 242.03it/s]Running 10000 simulations.:  14%|█▍        | 1431/10000 [00:05<00:35, 242.71it/s]Running 10000 simulations.:  15%|█▍        | 1456/10000 [00:05<00:35, 242.30it/s]Running 10000 simulations.:  15%|█▍        | 1481/10000 [00:06<00:35, 242.16it/s]Running 10000 simulations.:  15%|█▌        | 1506/10000 [00:06<00:35, 241.90it/s]Running 10000 simulations.:  15%|█▌        | 1531/10000 [00:06<00:36, 234.84it/s]Running 10000 simulations.:  16%|█▌        | 1556/10000 [00:06<00:35, 237.48it/s]Running 10000 simulations.:  16%|█▌        | 1581/10000 [00:06<00:35, 238.55it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:06<00:35, 236.70it/s]Running 10000 simulations.:  16%|█▋        | 1629/10000 [00:06<00:35, 237.07it/s]Running 10000 simulations.:  17%|█▋        | 1654/10000 [00:06<00:35, 238.38it/s]Running 10000 simulations.:  17%|█▋        | 1679/10000 [00:06<00:34, 239.27it/s]Running 10000 simulations.:  17%|█▋        | 1704/10000 [00:06<00:34, 240.57it/s]Running 10000 simulations.:  17%|█▋        | 1729/10000 [00:07<00:34, 241.56it/s]Running 10000 simulations.:  18%|█▊        | 1754/10000 [00:07<00:34, 237.48it/s]Running 10000 simulations.:  18%|█▊        | 1778/10000 [00:07<00:34, 236.77it/s]Running 10000 simulations.:  18%|█▊        | 1802/10000 [00:07<00:34, 237.25it/s]Running 10000 simulations.:  18%|█▊        | 1827/10000 [00:07<00:34, 238.43it/s]Running 10000 simulations.:  19%|█▊        | 1851/10000 [00:07<00:34, 238.86it/s]Running 10000 simulations.:  19%|█▉        | 1875/10000 [00:07<00:33, 239.10it/s]Running 10000 simulations.:  19%|█▉        | 1899/10000 [00:07<00:33, 238.97it/s]Running 10000 simulations.:  19%|█▉        | 1923/10000 [00:07<00:34, 233.81it/s]Running 10000 simulations.:  19%|█▉        | 1947/10000 [00:08<00:34, 234.56it/s]Running 10000 simulations.:  20%|█▉        | 1971/10000 [00:08<00:34, 236.00it/s]Running 10000 simulations.:  20%|█▉        | 1996/10000 [00:08<00:33, 237.70it/s]Running 10000 simulations.:  20%|██        | 2021/10000 [00:08<00:33, 239.41it/s]Running 10000 simulations.:  20%|██        | 2046/10000 [00:08<00:33, 240.28it/s]Running 10000 simulations.:  21%|██        | 2071/10000 [00:08<00:33, 237.16it/s]Running 10000 simulations.:  21%|██        | 2095/10000 [00:08<00:33, 234.77it/s]Running 10000 simulations.:  21%|██        | 2119/10000 [00:08<00:33, 236.26it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:08<00:33, 235.91it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:08<00:33, 236.33it/s]Running 10000 simulations.:  22%|██▏       | 2192/10000 [00:09<00:32, 238.21it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:09<00:32, 238.74it/s]Running 10000 simulations.:  22%|██▏       | 2240/10000 [00:09<00:32, 236.57it/s]Running 10000 simulations.:  23%|██▎       | 2264/10000 [00:09<00:32, 237.33it/s]Running 10000 simulations.:  23%|██▎       | 2289/10000 [00:09<00:32, 238.30it/s]Running 10000 simulations.:  23%|██▎       | 2314/10000 [00:09<00:32, 238.94it/s]Running 10000 simulations.:  23%|██▎       | 2339/10000 [00:09<00:31, 239.64it/s]Running 10000 simulations.:  24%|██▎       | 2364/10000 [00:09<00:31, 240.36it/s]Running 10000 simulations.:  24%|██▍       | 2389/10000 [00:09<00:31, 238.39it/s]Running 10000 simulations.:  24%|██▍       | 2413/10000 [00:09<00:31, 237.51it/s]Running 10000 simulations.:  24%|██▍       | 2437/10000 [00:10<00:31, 237.27it/s]Running 10000 simulations.:  25%|██▍       | 2461/10000 [00:10<00:31, 236.34it/s]Running 10000 simulations.:  25%|██▍       | 2485/10000 [00:10<00:32, 234.25it/s]Running 10000 simulations.:  25%|██▌       | 2509/10000 [00:10<00:32, 233.19it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:10<00:31, 233.99it/s]Running 10000 simulations.:  26%|██▌       | 2557/10000 [00:10<00:31, 235.26it/s]Running 10000 simulations.:  26%|██▌       | 2581/10000 [00:10<00:31, 236.27it/s]Running 10000 simulations.:  26%|██▌       | 2605/10000 [00:10<00:31, 236.78it/s]Running 10000 simulations.:  26%|██▋       | 2629/10000 [00:10<00:31, 232.12it/s]Running 10000 simulations.:  27%|██▋       | 2653/10000 [00:11<00:31, 231.45it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:11<00:31, 231.02it/s]Running 10000 simulations.:  27%|██▋       | 2701/10000 [00:11<00:31, 231.31it/s]Running 10000 simulations.:  27%|██▋       | 2725/10000 [00:11<00:31, 232.35it/s]Running 10000 simulations.:  28%|██▊       | 2750/10000 [00:11<00:30, 235.71it/s]Running 10000 simulations.:  28%|██▊       | 2774/10000 [00:11<00:30, 236.76it/s]Running 10000 simulations.:  28%|██▊       | 2798/10000 [00:11<00:30, 235.26it/s]Running 10000 simulations.:  28%|██▊       | 2822/10000 [00:11<00:30, 235.90it/s]Running 10000 simulations.:  28%|██▊       | 2846/10000 [00:11<00:30, 236.99it/s]Running 10000 simulations.:  29%|██▊       | 2871/10000 [00:11<00:29, 237.96it/s]Running 10000 simulations.:  29%|██▉       | 2895/10000 [00:12<00:29, 238.51it/s]Running 10000 simulations.:  29%|██▉       | 2919/10000 [00:12<00:29, 238.81it/s]Running 10000 simulations.:  29%|██▉       | 2943/10000 [00:12<00:29, 236.83it/s]Running 10000 simulations.:  30%|██▉       | 2967/10000 [00:12<00:29, 237.41it/s]Running 10000 simulations.:  30%|██▉       | 2991/10000 [00:12<00:29, 238.02it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:12<00:29, 237.94it/s]Running 10000 simulations.:  30%|███       | 3039/10000 [00:12<00:29, 238.45it/s]Running 10000 simulations.:  31%|███       | 3064/10000 [00:12<00:28, 239.73it/s]Running 10000 simulations.:  31%|███       | 3088/10000 [00:12<00:28, 239.51it/s]Running 10000 simulations.:  31%|███       | 3112/10000 [00:12<00:29, 236.57it/s]Running 10000 simulations.:  31%|███▏      | 3136/10000 [00:13<00:28, 236.97it/s]Running 10000 simulations.:  32%|███▏      | 3160/10000 [00:13<00:28, 237.63it/s]Running 10000 simulations.:  32%|███▏      | 3184/10000 [00:13<00:28, 238.24it/s]Running 10000 simulations.:  32%|███▏      | 3208/10000 [00:13<00:28, 238.26it/s]Running 10000 simulations.:  32%|███▏      | 3233/10000 [00:13<00:28, 238.86it/s]Running 10000 simulations.:  33%|███▎      | 3257/10000 [00:13<00:28, 236.83it/s]Running 10000 simulations.:  33%|███▎      | 3281/10000 [00:13<00:28, 237.64it/s]Running 10000 simulations.:  33%|███▎      | 3305/10000 [00:13<00:28, 238.11it/s]Running 10000 simulations.:  33%|███▎      | 3329/10000 [00:13<00:28, 237.90it/s]Running 10000 simulations.:  34%|███▎      | 3353/10000 [00:13<00:27, 238.52it/s]Running 10000 simulations.:  34%|███▍      | 3378/10000 [00:14<00:27, 239.28it/s]Running 10000 simulations.:  34%|███▍      | 3402/10000 [00:14<00:27, 238.13it/s]Running 10000 simulations.:  34%|███▍      | 3426/10000 [00:14<00:27, 236.70it/s]Running 10000 simulations.:  34%|███▍      | 3450/10000 [00:14<00:27, 237.37it/s]Running 10000 simulations.:  35%|███▍      | 3474/10000 [00:14<00:27, 237.81it/s]Running 10000 simulations.:  35%|███▍      | 3498/10000 [00:14<00:27, 238.08it/s]Running 10000 simulations.:  35%|███▌      | 3522/10000 [00:14<00:27, 238.62it/s]Running 10000 simulations.:  35%|███▌      | 3547/10000 [00:14<00:26, 239.20it/s]Running 10000 simulations.:  36%|███▌      | 3571/10000 [00:14<00:27, 236.10it/s]Running 10000 simulations.:  36%|███▌      | 3595/10000 [00:14<00:27, 235.16it/s]Running 10000 simulations.:  36%|███▌      | 3619/10000 [00:15<00:27, 235.22it/s]Running 10000 simulations.:  36%|███▋      | 3643/10000 [00:15<00:27, 234.30it/s]Running 10000 simulations.:  37%|███▋      | 3667/10000 [00:15<00:26, 235.19it/s]Running 10000 simulations.:  37%|███▋      | 3692/10000 [00:15<00:26, 236.82it/s]Running 10000 simulations.:  37%|███▋      | 3716/10000 [00:15<00:26, 234.93it/s]Running 10000 simulations.:  37%|███▋      | 3740/10000 [00:15<00:26, 235.26it/s]Running 10000 simulations.:  38%|███▊      | 3764/10000 [00:15<00:26, 235.04it/s]Running 10000 simulations.:  38%|███▊      | 3788/10000 [00:15<00:26, 234.63it/s]Running 10000 simulations.:  38%|███▊      | 3812/10000 [00:15<00:26, 235.51it/s]Running 10000 simulations.:  38%|███▊      | 3836/10000 [00:16<00:26, 234.97it/s]Running 10000 simulations.:  39%|███▊      | 3860/10000 [00:16<00:26, 235.90it/s]Running 10000 simulations.:  39%|███▉      | 3884/10000 [00:16<00:25, 236.97it/s]Running 10000 simulations.:  39%|███▉      | 3908/10000 [00:16<00:25, 237.50it/s]Running 10000 simulations.:  39%|███▉      | 3932/10000 [00:16<00:25, 236.19it/s]Running 10000 simulations.:  40%|███▉      | 3956/10000 [00:16<00:25, 236.50it/s]Running 10000 simulations.:  40%|███▉      | 3980/10000 [00:16<00:25, 237.15it/s]Running 10000 simulations.:  40%|████      | 4004/10000 [00:16<00:25, 237.89it/s]Running 10000 simulations.:  40%|████      | 4029/10000 [00:16<00:25, 238.62it/s]Running 10000 simulations.:  41%|████      | 4054/10000 [00:16<00:24, 239.67it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:17<00:24, 238.90it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:17<00:24, 237.02it/s]Running 10000 simulations.:  41%|████▏     | 4126/10000 [00:17<00:24, 237.51it/s]Running 10000 simulations.:  42%|████▏     | 4150/10000 [00:17<00:24, 237.68it/s]Running 10000 simulations.:  42%|████▏     | 4174/10000 [00:17<00:24, 238.10it/s]Running 10000 simulations.:  42%|████▏     | 4199/10000 [00:17<00:24, 238.92it/s]Running 10000 simulations.:  42%|████▏     | 4223/10000 [00:17<00:24, 239.05it/s]Running 10000 simulations.:  42%|████▏     | 4247/10000 [00:17<00:24, 237.15it/s]Running 10000 simulations.:  43%|████▎     | 4271/10000 [00:17<00:24, 237.36it/s]Running 10000 simulations.:  43%|████▎     | 4295/10000 [00:17<00:23, 237.77it/s]Running 10000 simulations.:  43%|████▎     | 4319/10000 [00:18<00:23, 238.36it/s]Running 10000 simulations.:  43%|████▎     | 4343/10000 [00:18<00:23, 238.78it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:18<00:23, 238.98it/s]Running 10000 simulations.:  44%|████▍     | 4391/10000 [00:18<00:23, 237.41it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:18<00:23, 236.51it/s]Running 10000 simulations.:  44%|████▍     | 4439/10000 [00:18<00:23, 236.92it/s]Running 10000 simulations.:  45%|████▍     | 4463/10000 [00:18<00:23, 237.45it/s]Running 10000 simulations.:  45%|████▍     | 4487/10000 [00:18<00:23, 237.00it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:18<00:23, 236.16it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:18<00:23, 236.51it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:19<00:23, 235.03it/s]Running 10000 simulations.:  46%|████▌     | 4583/10000 [00:19<00:22, 235.97it/s]Running 10000 simulations.:  46%|████▌     | 4607/10000 [00:19<00:22, 236.98it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:19<00:22, 237.67it/s]Running 10000 simulations.:  47%|████▋     | 4655/10000 [00:19<00:22, 237.62it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:19<00:22, 238.26it/s]Running 10000 simulations.:  47%|████▋     | 4703/10000 [00:19<00:22, 236.29it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:19<00:22, 235.97it/s]Running 10000 simulations.:  48%|████▊     | 4751/10000 [00:19<00:22, 236.98it/s]Running 10000 simulations.:  48%|████▊     | 4775/10000 [00:19<00:22, 236.97it/s]Running 10000 simulations.:  48%|████▊     | 4799/10000 [00:20<00:21, 237.75it/s]Running 10000 simulations.:  48%|████▊     | 4824/10000 [00:20<00:21, 238.71it/s]Running 10000 simulations.:  48%|████▊     | 4848/10000 [00:20<00:21, 238.01it/s]Running 10000 simulations.:  49%|████▊     | 4872/10000 [00:20<00:22, 233.08it/s]Running 10000 simulations.:  49%|████▉     | 4896/10000 [00:20<00:21, 233.72it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:20<00:21, 234.41it/s]Running 10000 simulations.:  49%|████▉     | 4944/10000 [00:20<00:21, 234.51it/s]Running 10000 simulations.:  50%|████▉     | 4968/10000 [00:20<00:21, 233.24it/s]Running 10000 simulations.:  50%|████▉     | 4992/10000 [00:20<00:21, 232.94it/s]Running 10000 simulations.:  50%|█████     | 5016/10000 [00:20<00:21, 230.66it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:21<00:21, 232.93it/s]Running 10000 simulations.:  51%|█████     | 5064/10000 [00:21<00:21, 234.87it/s]Running 10000 simulations.:  51%|█████     | 5088/10000 [00:21<00:20, 236.17it/s]Running 10000 simulations.:  51%|█████     | 5112/10000 [00:21<00:21, 232.26it/s]Running 10000 simulations.:  51%|█████▏    | 5136/10000 [00:21<00:20, 231.97it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:21<00:20, 233.52it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:21<00:20, 234.98it/s]Running 10000 simulations.:  52%|█████▏    | 5208/10000 [00:21<00:20, 236.22it/s]Running 10000 simulations.:  52%|█████▏    | 5233/10000 [00:21<00:20, 237.72it/s]Running 10000 simulations.:  53%|█████▎    | 5257/10000 [00:22<00:20, 236.96it/s]Running 10000 simulations.:  53%|█████▎    | 5281/10000 [00:22<00:20, 231.54it/s]Running 10000 simulations.:  53%|█████▎    | 5305/10000 [00:22<00:20, 231.85it/s]Running 10000 simulations.:  53%|█████▎    | 5329/10000 [00:22<00:19, 233.82it/s]Running 10000 simulations.:  54%|█████▎    | 5353/10000 [00:22<00:19, 235.24it/s]Running 10000 simulations.:  54%|█████▍    | 5377/10000 [00:22<00:19, 236.42it/s]Running 10000 simulations.:  54%|█████▍    | 5402/10000 [00:22<00:19, 238.05it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:22<00:19, 233.47it/s]Running 10000 simulations.:  55%|█████▍    | 5450/10000 [00:22<00:19, 232.15it/s]Running 10000 simulations.:  55%|█████▍    | 5474/10000 [00:22<00:19, 233.20it/s]Running 10000 simulations.:  55%|█████▍    | 5498/10000 [00:23<00:19, 234.77it/s]Running 10000 simulations.:  55%|█████▌    | 5522/10000 [00:23<00:18, 236.27it/s]Running 10000 simulations.:  55%|█████▌    | 5546/10000 [00:23<00:18, 236.85it/s]Running 10000 simulations.:  56%|█████▌    | 5570/10000 [00:23<00:18, 237.26it/s]Running 10000 simulations.:  56%|█████▌    | 5594/10000 [00:23<00:18, 232.43it/s]Running 10000 simulations.:  56%|█████▌    | 5618/10000 [00:23<00:18, 233.08it/s]Running 10000 simulations.:  56%|█████▋    | 5642/10000 [00:23<00:18, 234.49it/s]Running 10000 simulations.:  57%|█████▋    | 5666/10000 [00:23<00:18, 235.30it/s]Running 10000 simulations.:  57%|█████▋    | 5690/10000 [00:23<00:18, 236.62it/s]Running 10000 simulations.:  57%|█████▋    | 5715/10000 [00:23<00:17, 238.36it/s]Running 10000 simulations.:  57%|█████▋    | 5739/10000 [00:24<00:18, 234.51it/s]Running 10000 simulations.:  58%|█████▊    | 5763/10000 [00:24<00:18, 234.32it/s]Running 10000 simulations.:  58%|█████▊    | 5787/10000 [00:24<00:17, 235.81it/s]Running 10000 simulations.:  58%|█████▊    | 5811/10000 [00:24<00:17, 236.98it/s]Running 10000 simulations.:  58%|█████▊    | 5836/10000 [00:24<00:17, 238.15it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:24<00:17, 239.83it/s]Running 10000 simulations.:  59%|█████▉    | 5886/10000 [00:24<00:17, 240.39it/s]Running 10000 simulations.:  59%|█████▉    | 5911/10000 [00:24<00:17, 239.10it/s]Running 10000 simulations.:  59%|█████▉    | 5936/10000 [00:24<00:16, 239.67it/s]Running 10000 simulations.:  60%|█████▉    | 5961/10000 [00:24<00:16, 240.09it/s]Running 10000 simulations.:  60%|█████▉    | 5986/10000 [00:25<00:16, 240.39it/s]Running 10000 simulations.:  60%|██████    | 6011/10000 [00:25<00:16, 240.40it/s]Running 10000 simulations.:  60%|██████    | 6036/10000 [00:25<00:16, 241.04it/s]Running 10000 simulations.:  61%|██████    | 6061/10000 [00:25<00:16, 239.80it/s]Running 10000 simulations.:  61%|██████    | 6085/10000 [00:25<00:16, 239.72it/s]Running 10000 simulations.:  61%|██████    | 6110/10000 [00:25<00:16, 240.06it/s]Running 10000 simulations.:  61%|██████▏   | 6135/10000 [00:25<00:16, 240.01it/s]Running 10000 simulations.:  62%|██████▏   | 6160/10000 [00:25<00:15, 240.44it/s]Running 10000 simulations.:  62%|██████▏   | 6185/10000 [00:25<00:15, 241.45it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:26<00:15, 239.97it/s]Running 10000 simulations.:  62%|██████▏   | 6235/10000 [00:26<00:15, 240.18it/s]Running 10000 simulations.:  63%|██████▎   | 6260/10000 [00:26<00:15, 239.36it/s]Running 10000 simulations.:  63%|██████▎   | 6284/10000 [00:26<00:15, 238.72it/s]Running 10000 simulations.:  63%|██████▎   | 6309/10000 [00:26<00:15, 239.39it/s]Running 10000 simulations.:  63%|██████▎   | 6334/10000 [00:26<00:15, 240.35it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:26<00:15, 240.63it/s]Running 10000 simulations.:  64%|██████▍   | 6384/10000 [00:26<00:14, 241.13it/s]Running 10000 simulations.:  64%|██████▍   | 6409/10000 [00:26<00:14, 242.15it/s]Running 10000 simulations.:  64%|██████▍   | 6434/10000 [00:26<00:14, 240.42it/s]Running 10000 simulations.:  65%|██████▍   | 6459/10000 [00:27<00:14, 240.09it/s]Running 10000 simulations.:  65%|██████▍   | 6484/10000 [00:27<00:14, 238.93it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:27<00:14, 238.46it/s]Running 10000 simulations.:  65%|██████▌   | 6532/10000 [00:27<00:14, 238.72it/s]Running 10000 simulations.:  66%|██████▌   | 6557/10000 [00:27<00:14, 239.19it/s]Running 10000 simulations.:  66%|██████▌   | 6581/10000 [00:27<00:14, 237.02it/s]Running 10000 simulations.:  66%|██████▌   | 6605/10000 [00:27<00:14, 237.12it/s]Running 10000 simulations.:  66%|██████▋   | 6629/10000 [00:27<00:14, 237.35it/s]Running 10000 simulations.:  67%|██████▋   | 6653/10000 [00:27<00:14, 237.54it/s]Running 10000 simulations.:  67%|██████▋   | 6677/10000 [00:27<00:13, 237.69it/s]Running 10000 simulations.:  67%|██████▋   | 6702/10000 [00:28<00:13, 238.39it/s]Running 10000 simulations.:  67%|██████▋   | 6726/10000 [00:28<00:13, 237.49it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:28<00:13, 236.61it/s]Running 10000 simulations.:  68%|██████▊   | 6774/10000 [00:28<00:13, 237.42it/s]Running 10000 simulations.:  68%|██████▊   | 6798/10000 [00:28<00:13, 237.36it/s]Running 10000 simulations.:  68%|██████▊   | 6822/10000 [00:28<00:13, 237.73it/s]Running 10000 simulations.:  68%|██████▊   | 6847/10000 [00:28<00:13, 238.73it/s]Running 10000 simulations.:  69%|██████▊   | 6871/10000 [00:28<00:13, 238.95it/s]Running 10000 simulations.:  69%|██████▉   | 6895/10000 [00:28<00:13, 236.69it/s]Running 10000 simulations.:  69%|██████▉   | 6919/10000 [00:28<00:12, 237.56it/s]Running 10000 simulations.:  69%|██████▉   | 6944/10000 [00:29<00:12, 238.34it/s]Running 10000 simulations.:  70%|██████▉   | 6969/10000 [00:29<00:12, 238.97it/s]Running 10000 simulations.:  70%|██████▉   | 6994/10000 [00:29<00:12, 240.05it/s]Running 10000 simulations.:  70%|███████   | 7019/10000 [00:29<00:12, 239.55it/s]Running 10000 simulations.:  70%|███████   | 7043/10000 [00:29<00:12, 237.80it/s]Running 10000 simulations.:  71%|███████   | 7067/10000 [00:29<00:12, 237.88it/s]Running 10000 simulations.:  71%|███████   | 7091/10000 [00:29<00:12, 237.80it/s]Running 10000 simulations.:  71%|███████   | 7115/10000 [00:29<00:12, 237.84it/s]Running 10000 simulations.:  71%|███████▏  | 7139/10000 [00:29<00:12, 238.39it/s]Running 10000 simulations.:  72%|███████▏  | 7163/10000 [00:30<00:11, 238.65it/s]Running 10000 simulations.:  72%|███████▏  | 7187/10000 [00:30<00:11, 237.05it/s]Running 10000 simulations.:  72%|███████▏  | 7211/10000 [00:30<00:11, 235.56it/s]Running 10000 simulations.:  72%|███████▏  | 7235/10000 [00:30<00:11, 235.92it/s]Running 10000 simulations.:  73%|███████▎  | 7259/10000 [00:30<00:11, 236.68it/s]Running 10000 simulations.:  73%|███████▎  | 7283/10000 [00:30<00:11, 236.66it/s]Running 10000 simulations.:  73%|███████▎  | 7307/10000 [00:30<00:11, 235.04it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:30<00:11, 230.44it/s]Running 10000 simulations.:  74%|███████▎  | 7355/10000 [00:30<00:11, 229.04it/s]Running 10000 simulations.:  74%|███████▍  | 7379/10000 [00:30<00:11, 230.99it/s]Running 10000 simulations.:  74%|███████▍  | 7403/10000 [00:31<00:11, 232.34it/s]Running 10000 simulations.:  74%|███████▍  | 7427/10000 [00:31<00:11, 232.39it/s]Running 10000 simulations.:  75%|███████▍  | 7451/10000 [00:31<00:11, 231.68it/s]Running 10000 simulations.:  75%|███████▍  | 7475/10000 [00:31<00:10, 232.82it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:31<00:10, 235.20it/s]Running 10000 simulations.:  75%|███████▌  | 7525/10000 [00:31<00:10, 237.06it/s]Running 10000 simulations.:  76%|███████▌  | 7550/10000 [00:31<00:10, 238.50it/s]Running 10000 simulations.:  76%|███████▌  | 7574/10000 [00:31<00:10, 237.78it/s]Running 10000 simulations.:  76%|███████▌  | 7598/10000 [00:31<00:10, 236.94it/s]Running 10000 simulations.:  76%|███████▌  | 7622/10000 [00:31<00:10, 237.64it/s]Running 10000 simulations.:  76%|███████▋  | 7646/10000 [00:32<00:09, 237.85it/s]Running 10000 simulations.:  77%|███████▋  | 7670/10000 [00:32<00:09, 237.71it/s]Running 10000 simulations.:  77%|███████▋  | 7695/10000 [00:32<00:09, 238.59it/s]Running 10000 simulations.:  77%|███████▋  | 7719/10000 [00:32<00:09, 237.82it/s]Running 10000 simulations.:  77%|███████▋  | 7743/10000 [00:32<00:09, 238.40it/s]Running 10000 simulations.:  78%|███████▊  | 7767/10000 [00:32<00:09, 238.34it/s]Running 10000 simulations.:  78%|███████▊  | 7791/10000 [00:32<00:09, 238.70it/s]Running 10000 simulations.:  78%|███████▊  | 7816/10000 [00:32<00:09, 239.37it/s]Running 10000 simulations.:  78%|███████▊  | 7841/10000 [00:32<00:08, 240.58it/s]Running 10000 simulations.:  79%|███████▊  | 7866/10000 [00:32<00:08, 239.17it/s]Running 10000 simulations.:  79%|███████▉  | 7891/10000 [00:33<00:08, 239.84it/s]Running 10000 simulations.:  79%|███████▉  | 7915/10000 [00:33<00:08, 239.67it/s]Running 10000 simulations.:  79%|███████▉  | 7940/10000 [00:33<00:08, 240.19it/s]Running 10000 simulations.:  80%|███████▉  | 7965/10000 [00:33<00:08, 240.57it/s]Running 10000 simulations.:  80%|███████▉  | 7990/10000 [00:33<00:08, 241.08it/s]Running 10000 simulations.:  80%|████████  | 8015/10000 [00:33<00:08, 240.02it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:33<00:08, 240.40it/s]Running 10000 simulations.:  81%|████████  | 8065/10000 [00:33<00:08, 240.81it/s]Running 10000 simulations.:  81%|████████  | 8090/10000 [00:33<00:07, 241.28it/s]Running 10000 simulations.:  81%|████████  | 8115/10000 [00:34<00:07, 242.38it/s]Running 10000 simulations.:  81%|████████▏ | 8140/10000 [00:34<00:07, 241.93it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:34<00:07, 239.54it/s]Running 10000 simulations.:  82%|████████▏ | 8190/10000 [00:34<00:07, 239.93it/s]Running 10000 simulations.:  82%|████████▏ | 8215/10000 [00:34<00:07, 240.34it/s]Running 10000 simulations.:  82%|████████▏ | 8240/10000 [00:34<00:07, 240.14it/s]Running 10000 simulations.:  83%|████████▎ | 8265/10000 [00:34<00:07, 240.38it/s]Running 10000 simulations.:  83%|████████▎ | 8290/10000 [00:34<00:07, 241.22it/s]Running 10000 simulations.:  83%|████████▎ | 8315/10000 [00:34<00:07, 239.44it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:34<00:06, 239.94it/s]Running 10000 simulations.:  84%|████████▎ | 8365/10000 [00:35<00:06, 240.27it/s]Running 10000 simulations.:  84%|████████▍ | 8390/10000 [00:35<00:06, 239.84it/s]Running 10000 simulations.:  84%|████████▍ | 8415/10000 [00:35<00:06, 240.52it/s]Running 10000 simulations.:  84%|████████▍ | 8440/10000 [00:35<00:06, 239.81it/s]Running 10000 simulations.:  85%|████████▍ | 8464/10000 [00:35<00:06, 237.77it/s]Running 10000 simulations.:  85%|████████▍ | 8488/10000 [00:35<00:06, 237.81it/s]Running 10000 simulations.:  85%|████████▌ | 8512/10000 [00:35<00:06, 238.29it/s]Running 10000 simulations.:  85%|████████▌ | 8537/10000 [00:35<00:06, 239.07it/s]Running 10000 simulations.:  86%|████████▌ | 8562/10000 [00:35<00:05, 240.40it/s]Running 10000 simulations.:  86%|████████▌ | 8587/10000 [00:36<00:05, 238.88it/s]Running 10000 simulations.:  86%|████████▌ | 8611/10000 [00:36<00:05, 234.91it/s]Running 10000 simulations.:  86%|████████▋ | 8635/10000 [00:36<00:06, 226.95it/s]Running 10000 simulations.:  87%|████████▋ | 8659/10000 [00:36<00:05, 228.16it/s]Running 10000 simulations.:  87%|████████▋ | 8683/10000 [00:36<00:05, 230.52it/s]Running 10000 simulations.:  87%|████████▋ | 8708/10000 [00:36<00:05, 233.33it/s]Running 10000 simulations.:  87%|████████▋ | 8733/10000 [00:36<00:05, 236.08it/s]Running 10000 simulations.:  88%|████████▊ | 8758/10000 [00:36<00:05, 237.85it/s]Running 10000 simulations.:  88%|████████▊ | 8783/10000 [00:36<00:05, 238.68it/s]Running 10000 simulations.:  88%|████████▊ | 8808/10000 [00:36<00:04, 239.69it/s]Running 10000 simulations.:  88%|████████▊ | 8832/10000 [00:37<00:04, 237.76it/s]Running 10000 simulations.:  89%|████████▊ | 8856/10000 [00:37<00:04, 238.18it/s]Running 10000 simulations.:  89%|████████▉ | 8880/10000 [00:37<00:04, 238.54it/s]Running 10000 simulations.:  89%|████████▉ | 8905/10000 [00:37<00:04, 239.26it/s]Running 10000 simulations.:  89%|████████▉ | 8930/10000 [00:37<00:04, 239.88it/s]Running 10000 simulations.:  90%|████████▉ | 8955/10000 [00:37<00:04, 240.92it/s]Running 10000 simulations.:  90%|████████▉ | 8980/10000 [00:37<00:04, 240.38it/s]Running 10000 simulations.:  90%|█████████ | 9005/10000 [00:37<00:04, 238.29it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:37<00:04, 239.16it/s]Running 10000 simulations.:  91%|█████████ | 9055/10000 [00:37<00:03, 239.40it/s]Running 10000 simulations.:  91%|█████████ | 9080/10000 [00:38<00:03, 239.80it/s]Running 10000 simulations.:  91%|█████████ | 9105/10000 [00:38<00:03, 241.11it/s]Running 10000 simulations.:  91%|█████████▏| 9130/10000 [00:38<00:03, 240.95it/s]Running 10000 simulations.:  92%|█████████▏| 9155/10000 [00:38<00:03, 238.69it/s]Running 10000 simulations.:  92%|█████████▏| 9179/10000 [00:38<00:03, 237.74it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [00:38<00:03, 237.53it/s]Running 10000 simulations.:  92%|█████████▏| 9228/10000 [00:38<00:03, 238.34it/s]Running 10000 simulations.:  93%|█████████▎| 9253/10000 [00:38<00:03, 239.30it/s]Running 10000 simulations.:  93%|█████████▎| 9278/10000 [00:38<00:03, 239.83it/s]Running 10000 simulations.:  93%|█████████▎| 9302/10000 [00:39<00:02, 233.89it/s]Running 10000 simulations.:  93%|█████████▎| 9326/10000 [00:39<00:02, 234.36it/s]Running 10000 simulations.:  94%|█████████▎| 9350/10000 [00:39<00:02, 235.81it/s]Running 10000 simulations.:  94%|█████████▎| 9374/10000 [00:39<00:02, 236.72it/s]Running 10000 simulations.:  94%|█████████▍| 9398/10000 [00:39<00:02, 237.04it/s]Running 10000 simulations.:  94%|█████████▍| 9423/10000 [00:39<00:02, 238.94it/s]Running 10000 simulations.:  94%|█████████▍| 9447/10000 [00:39<00:02, 238.71it/s]Running 10000 simulations.:  95%|█████████▍| 9471/10000 [00:39<00:02, 238.82it/s]Running 10000 simulations.:  95%|█████████▍| 9496/10000 [00:39<00:02, 239.44it/s]Running 10000 simulations.:  95%|█████████▌| 9520/10000 [00:39<00:02, 239.57it/s]Running 10000 simulations.:  95%|█████████▌| 9545/10000 [00:40<00:01, 240.02it/s]Running 10000 simulations.:  96%|█████████▌| 9570/10000 [00:40<00:01, 240.97it/s]Running 10000 simulations.:  96%|█████████▌| 9595/10000 [00:40<00:01, 240.10it/s]Running 10000 simulations.:  96%|█████████▌| 9620/10000 [00:40<00:01, 240.15it/s]Running 10000 simulations.:  96%|█████████▋| 9645/10000 [00:40<00:01, 241.03it/s]Running 10000 simulations.:  97%|█████████▋| 9670/10000 [00:40<00:01, 241.46it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:40<00:01, 241.83it/s]Running 10000 simulations.:  97%|█████████▋| 9720/10000 [00:40<00:01, 243.12it/s]Running 10000 simulations.:  97%|█████████▋| 9745/10000 [00:40<00:01, 241.89it/s]Running 10000 simulations.:  98%|█████████▊| 9770/10000 [00:40<00:00, 241.46it/s]Running 10000 simulations.:  98%|█████████▊| 9795/10000 [00:41<00:00, 241.38it/s]Running 10000 simulations.:  98%|█████████▊| 9820/10000 [00:41<00:00, 240.74it/s]Running 10000 simulations.:  98%|█████████▊| 9845/10000 [00:41<00:00, 240.43it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [00:41<00:00, 240.66it/s]Running 10000 simulations.:  99%|█████████▉| 9895/10000 [00:41<00:00, 241.11it/s]Running 10000 simulations.:  99%|█████████▉| 9920/10000 [00:41<00:00, 242.44it/s]Running 10000 simulations.:  99%|█████████▉| 9945/10000 [00:41<00:00, 241.19it/s]Running 10000 simulations.: 100%|█████████▉| 9970/10000 [00:41<00:00, 241.99it/s]Running 10000 simulations.: 100%|█████████▉| 9995/10000 [00:41<00:00, 242.23it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 238.57it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 26/10000 [00:00<00:39, 254.91it/s]Running 10000 simulations.:   1%|          | 52/10000 [00:00<00:38, 255.81it/s]Running 10000 simulations.:   1%|          | 78/10000 [00:00<00:38, 256.85it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:38, 256.19it/s]Running 10000 simulations.:   1%|▏         | 130/10000 [00:00<00:38, 256.11it/s]Running 10000 simulations.:   2%|▏         | 156/10000 [00:00<00:38, 256.05it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:00<00:38, 256.26it/s]Running 10000 simulations.:   2%|▏         | 208/10000 [00:00<00:38, 255.27it/s]Running 10000 simulations.:   2%|▏         | 234/10000 [00:00<00:38, 254.38it/s]Running 10000 simulations.:   3%|▎         | 259/10000 [00:01<00:38, 252.88it/s]Running 10000 simulations.:   3%|▎         | 284/10000 [00:01<00:38, 251.50it/s]Running 10000 simulations.:   3%|▎         | 309/10000 [00:01<00:38, 250.67it/s]Running 10000 simulations.:   3%|▎         | 334/10000 [00:01<00:38, 250.22it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:01<00:38, 250.59it/s]Running 10000 simulations.:   4%|▍         | 385/10000 [00:01<00:38, 250.35it/s]Running 10000 simulations.:   4%|▍         | 410/10000 [00:01<00:38, 250.15it/s]Running 10000 simulations.:   4%|▍         | 436/10000 [00:01<00:38, 250.40it/s]Running 10000 simulations.:   5%|▍         | 462/10000 [00:01<00:38, 250.79it/s]Running 10000 simulations.:   5%|▍         | 488/10000 [00:01<00:37, 250.93it/s]Running 10000 simulations.:   5%|▌         | 514/10000 [00:02<00:37, 250.92it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:02<00:37, 250.99it/s]Running 10000 simulations.:   6%|▌         | 566/10000 [00:02<00:37, 250.53it/s]Running 10000 simulations.:   6%|▌         | 592/10000 [00:02<00:37, 249.15it/s]Running 10000 simulations.:   6%|▌         | 617/10000 [00:02<00:37, 249.24it/s]Running 10000 simulations.:   6%|▋         | 643/10000 [00:02<00:37, 249.48it/s]Running 10000 simulations.:   7%|▋         | 669/10000 [00:02<00:37, 250.24it/s]Running 10000 simulations.:   7%|▋         | 695/10000 [00:02<00:37, 249.43it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:02<00:37, 248.68it/s]Running 10000 simulations.:   7%|▋         | 745/10000 [00:02<00:37, 247.66it/s]Running 10000 simulations.:   8%|▊         | 770/10000 [00:03<00:37, 244.80it/s]Running 10000 simulations.:   8%|▊         | 795/10000 [00:03<00:37, 243.58it/s]Running 10000 simulations.:   8%|▊         | 820/10000 [00:03<00:37, 244.58it/s]Running 10000 simulations.:   8%|▊         | 845/10000 [00:03<00:37, 245.84it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:03<00:37, 246.26it/s]Running 10000 simulations.:   9%|▉         | 895/10000 [00:03<00:36, 246.42it/s]Running 10000 simulations.:   9%|▉         | 920/10000 [00:03<00:36, 245.79it/s]Running 10000 simulations.:   9%|▉         | 945/10000 [00:03<00:36, 245.84it/s]Running 10000 simulations.:  10%|▉         | 970/10000 [00:03<00:36, 245.87it/s]Running 10000 simulations.:  10%|▉         | 995/10000 [00:03<00:36, 245.89it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:04<00:37, 238.00it/s]Running 10000 simulations.:  10%|█         | 1045/10000 [00:04<00:37, 241.26it/s]Running 10000 simulations.:  11%|█         | 1070/10000 [00:04<00:36, 242.84it/s]Running 10000 simulations.:  11%|█         | 1095/10000 [00:04<00:36, 241.16it/s]Running 10000 simulations.:  11%|█         | 1120/10000 [00:04<00:36, 240.95it/s]Running 10000 simulations.:  11%|█▏        | 1145/10000 [00:04<00:36, 241.92it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:04<00:36, 242.63it/s]Running 10000 simulations.:  12%|█▏        | 1195/10000 [00:04<00:36, 243.36it/s]Running 10000 simulations.:  12%|█▏        | 1220/10000 [00:04<00:35, 245.03it/s]Running 10000 simulations.:  12%|█▏        | 1245/10000 [00:05<00:35, 246.13it/s]Running 10000 simulations.:  13%|█▎        | 1270/10000 [00:05<00:35, 247.16it/s]Running 10000 simulations.:  13%|█▎        | 1295/10000 [00:05<00:35, 246.94it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:05<00:35, 246.81it/s]Running 10000 simulations.:  13%|█▎        | 1345/10000 [00:05<00:35, 245.63it/s]Running 10000 simulations.:  14%|█▎        | 1370/10000 [00:05<00:35, 244.63it/s]Running 10000 simulations.:  14%|█▍        | 1395/10000 [00:05<00:35, 244.36it/s]Running 10000 simulations.:  14%|█▍        | 1420/10000 [00:05<00:34, 245.21it/s]Running 10000 simulations.:  14%|█▍        | 1445/10000 [00:05<00:34, 246.10it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:05<00:34, 247.02it/s]Running 10000 simulations.:  15%|█▍        | 1496/10000 [00:06<00:34, 248.04it/s]Running 10000 simulations.:  15%|█▌        | 1521/10000 [00:06<00:34, 243.05it/s]Running 10000 simulations.:  15%|█▌        | 1546/10000 [00:06<00:34, 242.98it/s]Running 10000 simulations.:  16%|█▌        | 1571/10000 [00:06<00:35, 237.58it/s]Running 10000 simulations.:  16%|█▌        | 1595/10000 [00:06<00:35, 237.68it/s]Running 10000 simulations.:  16%|█▌        | 1620/10000 [00:06<00:34, 239.70it/s]Running 10000 simulations.:  16%|█▋        | 1645/10000 [00:06<00:34, 241.51it/s]Running 10000 simulations.:  17%|█▋        | 1670/10000 [00:06<00:34, 241.25it/s]Running 10000 simulations.:  17%|█▋        | 1695/10000 [00:06<00:34, 242.64it/s]Running 10000 simulations.:  17%|█▋        | 1721/10000 [00:06<00:33, 245.14it/s]Running 10000 simulations.:  17%|█▋        | 1747/10000 [00:07<00:33, 247.35it/s]Running 10000 simulations.:  18%|█▊        | 1772/10000 [00:07<00:33, 248.03it/s]Running 10000 simulations.:  18%|█▊        | 1798/10000 [00:07<00:32, 248.78it/s]Running 10000 simulations.:  18%|█▊        | 1823/10000 [00:07<00:32, 248.85it/s]Running 10000 simulations.:  18%|█▊        | 1849/10000 [00:07<00:32, 249.70it/s]Running 10000 simulations.:  19%|█▉        | 1875/10000 [00:07<00:32, 250.94it/s]Running 10000 simulations.:  19%|█▉        | 1901/10000 [00:07<00:32, 251.72it/s]Running 10000 simulations.:  19%|█▉        | 1927/10000 [00:07<00:32, 252.26it/s]Running 10000 simulations.:  20%|█▉        | 1953/10000 [00:07<00:31, 252.66it/s]Running 10000 simulations.:  20%|█▉        | 1979/10000 [00:07<00:31, 252.71it/s]Running 10000 simulations.:  20%|██        | 2005/10000 [00:08<00:31, 252.20it/s]Running 10000 simulations.:  20%|██        | 2031/10000 [00:08<00:31, 251.61it/s]Running 10000 simulations.:  21%|██        | 2057/10000 [00:08<00:31, 250.50it/s]Running 10000 simulations.:  21%|██        | 2083/10000 [00:08<00:31, 249.35it/s]Running 10000 simulations.:  21%|██        | 2108/10000 [00:08<00:31, 249.32it/s]Running 10000 simulations.:  21%|██▏       | 2133/10000 [00:08<00:31, 248.72it/s]Running 10000 simulations.:  22%|██▏       | 2158/10000 [00:08<00:31, 247.96it/s]Running 10000 simulations.:  22%|██▏       | 2183/10000 [00:08<00:31, 247.65it/s]Running 10000 simulations.:  22%|██▏       | 2208/10000 [00:08<00:31, 247.59it/s]Running 10000 simulations.:  22%|██▏       | 2234/10000 [00:09<00:31, 248.41it/s]Running 10000 simulations.:  23%|██▎       | 2260/10000 [00:09<00:31, 248.92it/s]Running 10000 simulations.:  23%|██▎       | 2285/10000 [00:09<00:31, 247.65it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:09<00:31, 246.36it/s]Running 10000 simulations.:  23%|██▎       | 2335/10000 [00:09<00:31, 245.63it/s]Running 10000 simulations.:  24%|██▎       | 2360/10000 [00:09<00:31, 245.85it/s]Running 10000 simulations.:  24%|██▍       | 2386/10000 [00:09<00:30, 247.18it/s]Running 10000 simulations.:  24%|██▍       | 2411/10000 [00:09<00:30, 247.41it/s]Running 10000 simulations.:  24%|██▍       | 2436/10000 [00:09<00:30, 247.11it/s]Running 10000 simulations.:  25%|██▍       | 2461/10000 [00:09<00:30, 247.38it/s]Running 10000 simulations.:  25%|██▍       | 2486/10000 [00:10<00:30, 247.46it/s]Running 10000 simulations.:  25%|██▌       | 2512/10000 [00:10<00:30, 248.46it/s]Running 10000 simulations.:  25%|██▌       | 2537/10000 [00:10<00:29, 248.79it/s]Running 10000 simulations.:  26%|██▌       | 2562/10000 [00:10<00:30, 247.50it/s]Running 10000 simulations.:  26%|██▌       | 2587/10000 [00:10<00:30, 247.05it/s]Running 10000 simulations.:  26%|██▌       | 2612/10000 [00:10<00:30, 246.22it/s]Running 10000 simulations.:  26%|██▋       | 2637/10000 [00:10<00:30, 245.33it/s]Running 10000 simulations.:  27%|██▋       | 2662/10000 [00:10<00:29, 245.16it/s]Running 10000 simulations.:  27%|██▋       | 2687/10000 [00:10<00:29, 245.70it/s]Running 10000 simulations.:  27%|██▋       | 2712/10000 [00:10<00:29, 245.85it/s]Running 10000 simulations.:  27%|██▋       | 2738/10000 [00:11<00:29, 247.45it/s]Running 10000 simulations.:  28%|██▊       | 2764/10000 [00:11<00:29, 249.01it/s]Running 10000 simulations.:  28%|██▊       | 2789/10000 [00:11<00:28, 248.80it/s]Running 10000 simulations.:  28%|██▊       | 2814/10000 [00:11<00:29, 245.44it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:11<00:29, 244.79it/s]Running 10000 simulations.:  29%|██▊       | 2864/10000 [00:11<00:29, 245.25it/s]Running 10000 simulations.:  29%|██▉       | 2889/10000 [00:11<00:28, 245.46it/s]Running 10000 simulations.:  29%|██▉       | 2914/10000 [00:11<00:28, 246.06it/s]Running 10000 simulations.:  29%|██▉       | 2939/10000 [00:11<00:28, 245.16it/s]Running 10000 simulations.:  30%|██▉       | 2964/10000 [00:11<00:28, 245.74it/s]Running 10000 simulations.:  30%|██▉       | 2989/10000 [00:12<00:28, 246.08it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:12<00:28, 247.84it/s]Running 10000 simulations.:  30%|███       | 3040/10000 [00:12<00:28, 245.55it/s]Running 10000 simulations.:  31%|███       | 3065/10000 [00:12<00:28, 244.90it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:12<00:28, 244.17it/s]Running 10000 simulations.:  31%|███       | 3115/10000 [00:12<00:28, 243.71it/s]Running 10000 simulations.:  31%|███▏      | 3140/10000 [00:12<00:28, 242.80it/s]Running 10000 simulations.:  32%|███▏      | 3165/10000 [00:12<00:28, 243.19it/s]Running 10000 simulations.:  32%|███▏      | 3190/10000 [00:12<00:28, 242.84it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:13<00:27, 242.73it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:13<00:27, 244.32it/s]Running 10000 simulations.:  33%|███▎      | 3265/10000 [00:13<00:27, 243.21it/s]Running 10000 simulations.:  33%|███▎      | 3290/10000 [00:13<00:27, 242.05it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:13<00:27, 242.39it/s]Running 10000 simulations.:  33%|███▎      | 3340/10000 [00:13<00:27, 243.00it/s]Running 10000 simulations.:  34%|███▎      | 3365/10000 [00:13<00:27, 244.75it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:13<00:26, 245.99it/s]Running 10000 simulations.:  34%|███▍      | 3415/10000 [00:13<00:26, 245.64it/s]Running 10000 simulations.:  34%|███▍      | 3440/10000 [00:13<00:26, 245.61it/s]Running 10000 simulations.:  35%|███▍      | 3465/10000 [00:14<00:26, 246.10it/s]Running 10000 simulations.:  35%|███▍      | 3490/10000 [00:14<00:26, 243.21it/s]Running 10000 simulations.:  35%|███▌      | 3515/10000 [00:14<00:26, 243.40it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:14<00:26, 244.32it/s]Running 10000 simulations.:  36%|███▌      | 3565/10000 [00:14<00:26, 244.63it/s]Running 10000 simulations.:  36%|███▌      | 3590/10000 [00:14<00:26, 244.39it/s]Running 10000 simulations.:  36%|███▌      | 3615/10000 [00:14<00:26, 241.77it/s]Running 10000 simulations.:  36%|███▋      | 3640/10000 [00:14<00:26, 242.73it/s]Running 10000 simulations.:  37%|███▋      | 3665/10000 [00:14<00:25, 243.80it/s]Running 10000 simulations.:  37%|███▋      | 3690/10000 [00:14<00:25, 244.65it/s]Running 10000 simulations.:  37%|███▋      | 3715/10000 [00:15<00:25, 242.16it/s]Running 10000 simulations.:  37%|███▋      | 3740/10000 [00:15<00:25, 242.11it/s]Running 10000 simulations.:  38%|███▊      | 3765/10000 [00:15<00:25, 242.31it/s]Running 10000 simulations.:  38%|███▊      | 3790/10000 [00:15<00:25, 243.22it/s]Running 10000 simulations.:  38%|███▊      | 3815/10000 [00:15<00:25, 243.65it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:15<00:25, 245.00it/s]Running 10000 simulations.:  39%|███▊      | 3865/10000 [00:15<00:25, 245.21it/s]Running 10000 simulations.:  39%|███▉      | 3890/10000 [00:15<00:24, 245.51it/s]Running 10000 simulations.:  39%|███▉      | 3916/10000 [00:15<00:24, 246.88it/s]Running 10000 simulations.:  39%|███▉      | 3941/10000 [00:15<00:24, 246.43it/s]Running 10000 simulations.:  40%|███▉      | 3966/10000 [00:16<00:24, 242.62it/s]Running 10000 simulations.:  40%|███▉      | 3991/10000 [00:16<00:24, 243.20it/s]Running 10000 simulations.:  40%|████      | 4016/10000 [00:16<00:24, 242.91it/s]Running 10000 simulations.:  40%|████      | 4041/10000 [00:16<00:24, 243.44it/s]Running 10000 simulations.:  41%|████      | 4066/10000 [00:16<00:24, 243.77it/s]Running 10000 simulations.:  41%|████      | 4091/10000 [00:16<00:24, 244.66it/s]Running 10000 simulations.:  41%|████      | 4116/10000 [00:16<00:24, 243.62it/s]Running 10000 simulations.:  41%|████▏     | 4141/10000 [00:16<00:24, 243.40it/s]Running 10000 simulations.:  42%|████▏     | 4166/10000 [00:16<00:23, 243.59it/s]Running 10000 simulations.:  42%|████▏     | 4191/10000 [00:17<00:23, 244.94it/s]Running 10000 simulations.:  42%|████▏     | 4216/10000 [00:17<00:23, 246.27it/s]Running 10000 simulations.:  42%|████▏     | 4241/10000 [00:17<00:23, 245.36it/s]Running 10000 simulations.:  43%|████▎     | 4266/10000 [00:17<00:23, 243.27it/s]Running 10000 simulations.:  43%|████▎     | 4291/10000 [00:17<00:23, 244.16it/s]Running 10000 simulations.:  43%|████▎     | 4316/10000 [00:17<00:23, 243.86it/s]Running 10000 simulations.:  43%|████▎     | 4341/10000 [00:17<00:23, 243.87it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:17<00:22, 245.78it/s]Running 10000 simulations.:  44%|████▍     | 4392/10000 [00:17<00:22, 246.94it/s]Running 10000 simulations.:  44%|████▍     | 4417/10000 [00:17<00:22, 247.08it/s]Running 10000 simulations.:  44%|████▍     | 4442/10000 [00:18<00:22, 247.52it/s]Running 10000 simulations.:  45%|████▍     | 4467/10000 [00:18<00:22, 244.03it/s]Running 10000 simulations.:  45%|████▍     | 4492/10000 [00:18<00:22, 243.58it/s]Running 10000 simulations.:  45%|████▌     | 4517/10000 [00:18<00:22, 243.34it/s]Running 10000 simulations.:  45%|████▌     | 4542/10000 [00:18<00:22, 243.55it/s]Running 10000 simulations.:  46%|████▌     | 4567/10000 [00:18<00:22, 243.50it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:18<00:22, 244.09it/s]Running 10000 simulations.:  46%|████▌     | 4617/10000 [00:18<00:22, 244.38it/s]Running 10000 simulations.:  46%|████▋     | 4642/10000 [00:18<00:21, 244.78it/s]Running 10000 simulations.:  47%|████▋     | 4667/10000 [00:18<00:21, 245.80it/s]Running 10000 simulations.:  47%|████▋     | 4692/10000 [00:19<00:21, 242.51it/s]Running 10000 simulations.:  47%|████▋     | 4717/10000 [00:19<00:21, 243.14it/s]Running 10000 simulations.:  47%|████▋     | 4742/10000 [00:19<00:21, 243.51it/s]Running 10000 simulations.:  48%|████▊     | 4767/10000 [00:19<00:21, 243.74it/s]Running 10000 simulations.:  48%|████▊     | 4792/10000 [00:19<00:21, 244.19it/s]Running 10000 simulations.:  48%|████▊     | 4817/10000 [00:19<00:21, 244.28it/s]Running 10000 simulations.:  48%|████▊     | 4842/10000 [00:19<00:21, 245.01it/s]Running 10000 simulations.:  49%|████▊     | 4867/10000 [00:19<00:20, 245.52it/s]Running 10000 simulations.:  49%|████▉     | 4892/10000 [00:19<00:20, 245.99it/s]Running 10000 simulations.:  49%|████▉     | 4917/10000 [00:19<00:20, 242.58it/s]Running 10000 simulations.:  49%|████▉     | 4942/10000 [00:20<00:20, 243.94it/s]Running 10000 simulations.:  50%|████▉     | 4967/10000 [00:20<00:20, 245.46it/s]Running 10000 simulations.:  50%|████▉     | 4992/10000 [00:20<00:20, 246.78it/s]Running 10000 simulations.:  50%|█████     | 5018/10000 [00:20<00:20, 248.65it/s]Running 10000 simulations.:  50%|█████     | 5043/10000 [00:20<00:19, 248.58it/s]Running 10000 simulations.:  51%|█████     | 5069/10000 [00:20<00:19, 249.02it/s]Running 10000 simulations.:  51%|█████     | 5094/10000 [00:20<00:19, 249.27it/s]Running 10000 simulations.:  51%|█████     | 5119/10000 [00:20<00:19, 247.65it/s]Running 10000 simulations.:  51%|█████▏    | 5144/10000 [00:20<00:19, 243.42it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:21<00:19, 243.26it/s]Running 10000 simulations.:  52%|█████▏    | 5194/10000 [00:21<00:19, 242.33it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:21<00:19, 242.59it/s]Running 10000 simulations.:  52%|█████▏    | 5244/10000 [00:21<00:19, 243.19it/s]Running 10000 simulations.:  53%|█████▎    | 5269/10000 [00:21<00:19, 243.54it/s]Running 10000 simulations.:  53%|█████▎    | 5294/10000 [00:21<00:19, 244.29it/s]Running 10000 simulations.:  53%|█████▎    | 5319/10000 [00:21<00:19, 244.37it/s]Running 10000 simulations.:  53%|█████▎    | 5344/10000 [00:21<00:18, 245.18it/s]Running 10000 simulations.:  54%|█████▎    | 5369/10000 [00:21<00:19, 241.78it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:21<00:19, 241.55it/s]Running 10000 simulations.:  54%|█████▍    | 5419/10000 [00:22<00:18, 241.94it/s]Running 10000 simulations.:  54%|█████▍    | 5444/10000 [00:22<00:18, 242.10it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:22<00:18, 244.15it/s]Running 10000 simulations.:  55%|█████▍    | 5494/10000 [00:22<00:18, 243.36it/s]Running 10000 simulations.:  55%|█████▌    | 5519/10000 [00:22<00:18, 243.64it/s]Running 10000 simulations.:  55%|█████▌    | 5544/10000 [00:22<00:18, 244.08it/s]Running 10000 simulations.:  56%|█████▌    | 5569/10000 [00:22<00:18, 242.55it/s]Running 10000 simulations.:  56%|█████▌    | 5594/10000 [00:22<00:18, 240.58it/s]Running 10000 simulations.:  56%|█████▌    | 5619/10000 [00:22<00:18, 240.55it/s]Running 10000 simulations.:  56%|█████▋    | 5644/10000 [00:22<00:18, 240.14it/s]Running 10000 simulations.:  57%|█████▋    | 5669/10000 [00:23<00:18, 240.04it/s]Running 10000 simulations.:  57%|█████▋    | 5694/10000 [00:23<00:17, 240.20it/s]Running 10000 simulations.:  57%|█████▋    | 5719/10000 [00:23<00:17, 240.18it/s]Running 10000 simulations.:  57%|█████▋    | 5744/10000 [00:23<00:17, 240.01it/s]Running 10000 simulations.:  58%|█████▊    | 5769/10000 [00:23<00:17, 240.65it/s]Running 10000 simulations.:  58%|█████▊    | 5794/10000 [00:23<00:17, 238.43it/s]Running 10000 simulations.:  58%|█████▊    | 5819/10000 [00:23<00:17, 239.05it/s]Running 10000 simulations.:  58%|█████▊    | 5843/10000 [00:23<00:17, 239.03it/s]Running 10000 simulations.:  59%|█████▊    | 5868/10000 [00:23<00:17, 239.57it/s]Running 10000 simulations.:  59%|█████▉    | 5893/10000 [00:23<00:17, 240.62it/s]Running 10000 simulations.:  59%|█████▉    | 5918/10000 [00:24<00:16, 240.25it/s]Running 10000 simulations.:  59%|█████▉    | 5943/10000 [00:24<00:16, 238.79it/s]Running 10000 simulations.:  60%|█████▉    | 5967/10000 [00:24<00:16, 238.89it/s]Running 10000 simulations.:  60%|█████▉    | 5991/10000 [00:24<00:16, 239.04it/s]Running 10000 simulations.:  60%|██████    | 6015/10000 [00:24<00:16, 239.25it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:24<00:16, 239.22it/s]Running 10000 simulations.:  61%|██████    | 6064/10000 [00:24<00:16, 240.07it/s]Running 10000 simulations.:  61%|██████    | 6089/10000 [00:24<00:16, 238.53it/s]Running 10000 simulations.:  61%|██████    | 6114/10000 [00:24<00:16, 239.32it/s]Running 10000 simulations.:  61%|██████▏   | 6139/10000 [00:25<00:16, 240.08it/s]Running 10000 simulations.:  62%|██████▏   | 6164/10000 [00:25<00:15, 240.19it/s]Running 10000 simulations.:  62%|██████▏   | 6189/10000 [00:25<00:15, 239.05it/s]Running 10000 simulations.:  62%|██████▏   | 6213/10000 [00:25<00:15, 238.74it/s]Running 10000 simulations.:  62%|██████▏   | 6238/10000 [00:25<00:15, 239.30it/s]Running 10000 simulations.:  63%|██████▎   | 6263/10000 [00:25<00:15, 240.13it/s]Running 10000 simulations.:  63%|██████▎   | 6288/10000 [00:25<00:15, 240.82it/s]Running 10000 simulations.:  63%|██████▎   | 6313/10000 [00:25<00:15, 237.86it/s]Running 10000 simulations.:  63%|██████▎   | 6338/10000 [00:25<00:15, 238.96it/s]Running 10000 simulations.:  64%|██████▎   | 6362/10000 [00:25<00:15, 239.00it/s]Running 10000 simulations.:  64%|██████▍   | 6386/10000 [00:26<00:15, 238.87it/s]Running 10000 simulations.:  64%|██████▍   | 6411/10000 [00:26<00:14, 239.37it/s]Running 10000 simulations.:  64%|██████▍   | 6435/10000 [00:26<00:14, 239.39it/s]Running 10000 simulations.:  65%|██████▍   | 6459/10000 [00:26<00:14, 239.32it/s]Running 10000 simulations.:  65%|██████▍   | 6483/10000 [00:26<00:14, 239.17it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:26<00:14, 239.79it/s]Running 10000 simulations.:  65%|██████▌   | 6532/10000 [00:26<00:14, 239.14it/s]Running 10000 simulations.:  66%|██████▌   | 6556/10000 [00:26<00:14, 238.13it/s]Running 10000 simulations.:  66%|██████▌   | 6580/10000 [00:26<00:14, 237.25it/s]Running 10000 simulations.:  66%|██████▌   | 6605/10000 [00:26<00:14, 239.62it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:27<00:14, 240.06it/s]Running 10000 simulations.:  67%|██████▋   | 6655/10000 [00:27<00:13, 240.35it/s]Running 10000 simulations.:  67%|██████▋   | 6680/10000 [00:27<00:13, 240.99it/s]Running 10000 simulations.:  67%|██████▋   | 6705/10000 [00:27<00:13, 240.57it/s]Running 10000 simulations.:  67%|██████▋   | 6730/10000 [00:27<00:13, 241.01it/s]Running 10000 simulations.:  68%|██████▊   | 6755/10000 [00:27<00:13, 240.76it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:27<00:13, 238.65it/s]Running 10000 simulations.:  68%|██████▊   | 6805/10000 [00:27<00:13, 240.39it/s]Running 10000 simulations.:  68%|██████▊   | 6830/10000 [00:27<00:13, 240.15it/s]Running 10000 simulations.:  69%|██████▊   | 6855/10000 [00:28<00:13, 239.89it/s]Running 10000 simulations.:  69%|██████▉   | 6879/10000 [00:28<00:13, 239.71it/s]Running 10000 simulations.:  69%|██████▉   | 6903/10000 [00:28<00:12, 239.67it/s]Running 10000 simulations.:  69%|██████▉   | 6927/10000 [00:28<00:12, 239.60it/s]Running 10000 simulations.:  70%|██████▉   | 6952/10000 [00:28<00:12, 240.33it/s]Running 10000 simulations.:  70%|██████▉   | 6977/10000 [00:28<00:12, 241.42it/s]Running 10000 simulations.:  70%|███████   | 7002/10000 [00:28<00:12, 238.29it/s]Running 10000 simulations.:  70%|███████   | 7026/10000 [00:28<00:12, 238.14it/s]Running 10000 simulations.:  70%|███████   | 7050/10000 [00:28<00:12, 238.45it/s]Running 10000 simulations.:  71%|███████   | 7074/10000 [00:28<00:12, 238.29it/s]Running 10000 simulations.:  71%|███████   | 7098/10000 [00:29<00:12, 237.80it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:29<00:12, 238.50it/s]Running 10000 simulations.:  71%|███████▏  | 7148/10000 [00:29<00:11, 239.05it/s]Running 10000 simulations.:  72%|███████▏  | 7173/10000 [00:29<00:11, 240.29it/s]Running 10000 simulations.:  72%|███████▏  | 7198/10000 [00:29<00:11, 241.89it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:29<00:11, 240.43it/s]Running 10000 simulations.:  72%|███████▏  | 7248/10000 [00:29<00:11, 237.65it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:29<00:11, 238.46it/s]Running 10000 simulations.:  73%|███████▎  | 7297/10000 [00:29<00:11, 237.19it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:29<00:11, 235.53it/s]Running 10000 simulations.:  73%|███████▎  | 7346/10000 [00:30<00:11, 237.33it/s]Running 10000 simulations.:  74%|███████▎  | 7370/10000 [00:30<00:11, 237.74it/s]Running 10000 simulations.:  74%|███████▍  | 7395/10000 [00:30<00:10, 239.27it/s]Running 10000 simulations.:  74%|███████▍  | 7420/10000 [00:30<00:10, 241.95it/s]Running 10000 simulations.:  74%|███████▍  | 7445/10000 [00:30<00:10, 238.82it/s]Running 10000 simulations.:  75%|███████▍  | 7469/10000 [00:30<00:10, 232.39it/s]Running 10000 simulations.:  75%|███████▍  | 7493/10000 [00:30<00:10, 231.75it/s]Running 10000 simulations.:  75%|███████▌  | 7517/10000 [00:30<00:10, 231.28it/s]Running 10000 simulations.:  75%|███████▌  | 7541/10000 [00:30<00:10, 230.95it/s]Running 10000 simulations.:  76%|███████▌  | 7566/10000 [00:31<00:10, 233.79it/s]Running 10000 simulations.:  76%|███████▌  | 7590/10000 [00:31<00:10, 234.98it/s]Running 10000 simulations.:  76%|███████▌  | 7614/10000 [00:31<00:10, 233.15it/s]Running 10000 simulations.:  76%|███████▋  | 7638/10000 [00:31<00:10, 231.99it/s]Running 10000 simulations.:  77%|███████▋  | 7662/10000 [00:31<00:10, 233.09it/s]Running 10000 simulations.:  77%|███████▋  | 7686/10000 [00:31<00:09, 234.65it/s]Running 10000 simulations.:  77%|███████▋  | 7710/10000 [00:31<00:09, 235.72it/s]Running 10000 simulations.:  77%|███████▋  | 7735/10000 [00:31<00:09, 237.66it/s]Running 10000 simulations.:  78%|███████▊  | 7759/10000 [00:31<00:09, 238.01it/s]Running 10000 simulations.:  78%|███████▊  | 7783/10000 [00:31<00:09, 232.68it/s]Running 10000 simulations.:  78%|███████▊  | 7807/10000 [00:32<00:09, 231.73it/s]Running 10000 simulations.:  78%|███████▊  | 7831/10000 [00:32<00:09, 230.93it/s]Running 10000 simulations.:  79%|███████▊  | 7855/10000 [00:32<00:09, 230.87it/s]Running 10000 simulations.:  79%|███████▉  | 7879/10000 [00:32<00:09, 233.20it/s]Running 10000 simulations.:  79%|███████▉  | 7903/10000 [00:32<00:08, 234.80it/s]Running 10000 simulations.:  79%|███████▉  | 7928/10000 [00:32<00:08, 236.78it/s]Running 10000 simulations.:  80%|███████▉  | 7953/10000 [00:32<00:08, 238.63it/s]Running 10000 simulations.:  80%|███████▉  | 7978/10000 [00:32<00:08, 239.18it/s]Running 10000 simulations.:  80%|████████  | 8002/10000 [00:32<00:08, 233.95it/s]Running 10000 simulations.:  80%|████████  | 8026/10000 [00:32<00:08, 232.87it/s]Running 10000 simulations.:  81%|████████  | 8051/10000 [00:33<00:08, 235.26it/s]Running 10000 simulations.:  81%|████████  | 8076/10000 [00:33<00:08, 237.42it/s]Running 10000 simulations.:  81%|████████  | 8100/10000 [00:33<00:07, 238.07it/s]Running 10000 simulations.:  81%|████████  | 8124/10000 [00:33<00:07, 238.41it/s]Running 10000 simulations.:  81%|████████▏ | 8149/10000 [00:33<00:07, 239.25it/s]Running 10000 simulations.:  82%|████████▏ | 8174/10000 [00:33<00:07, 240.14it/s]Running 10000 simulations.:  82%|████████▏ | 8199/10000 [00:33<00:07, 241.38it/s]Running 10000 simulations.:  82%|████████▏ | 8224/10000 [00:33<00:07, 240.02it/s]Running 10000 simulations.:  82%|████████▏ | 8249/10000 [00:33<00:07, 241.10it/s]Running 10000 simulations.:  83%|████████▎ | 8274/10000 [00:34<00:07, 240.94it/s]Running 10000 simulations.:  83%|████████▎ | 8299/10000 [00:34<00:07, 233.02it/s]Running 10000 simulations.:  83%|████████▎ | 8324/10000 [00:34<00:07, 236.57it/s]Running 10000 simulations.:  83%|████████▎ | 8348/10000 [00:34<00:06, 237.57it/s]Running 10000 simulations.:  84%|████████▎ | 8373/10000 [00:34<00:06, 239.40it/s]Running 10000 simulations.:  84%|████████▍ | 8397/10000 [00:34<00:06, 239.53it/s]Running 10000 simulations.:  84%|████████▍ | 8421/10000 [00:34<00:06, 239.32it/s]Running 10000 simulations.:  84%|████████▍ | 8445/10000 [00:34<00:06, 237.86it/s]Running 10000 simulations.:  85%|████████▍ | 8470/10000 [00:34<00:06, 239.00it/s]Running 10000 simulations.:  85%|████████▍ | 8495/10000 [00:34<00:06, 239.65it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:35<00:06, 240.98it/s]Running 10000 simulations.:  85%|████████▌ | 8545/10000 [00:35<00:06, 242.50it/s]Running 10000 simulations.:  86%|████████▌ | 8570/10000 [00:35<00:05, 243.52it/s]Running 10000 simulations.:  86%|████████▌ | 8595/10000 [00:35<00:05, 244.27it/s]Running 10000 simulations.:  86%|████████▌ | 8620/10000 [00:35<00:05, 245.03it/s]Running 10000 simulations.:  86%|████████▋ | 8645/10000 [00:35<00:05, 244.07it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [00:35<00:05, 242.25it/s]Running 10000 simulations.:  87%|████████▋ | 8695/10000 [00:35<00:05, 242.55it/s]Running 10000 simulations.:  87%|████████▋ | 8720/10000 [00:35<00:05, 241.97it/s]Running 10000 simulations.:  87%|████████▋ | 8745/10000 [00:35<00:05, 242.80it/s]Running 10000 simulations.:  88%|████████▊ | 8770/10000 [00:36<00:05, 244.43it/s]Running 10000 simulations.:  88%|████████▊ | 8795/10000 [00:36<00:04, 243.69it/s]Running 10000 simulations.:  88%|████████▊ | 8820/10000 [00:36<00:04, 244.46it/s]Running 10000 simulations.:  88%|████████▊ | 8845/10000 [00:36<00:04, 244.99it/s]Running 10000 simulations.:  89%|████████▊ | 8870/10000 [00:36<00:04, 243.23it/s]Running 10000 simulations.:  89%|████████▉ | 8895/10000 [00:36<00:04, 242.05it/s]Running 10000 simulations.:  89%|████████▉ | 8920/10000 [00:36<00:04, 243.41it/s]Running 10000 simulations.:  89%|████████▉ | 8945/10000 [00:36<00:04, 244.71it/s]Running 10000 simulations.:  90%|████████▉ | 8970/10000 [00:36<00:04, 245.48it/s]Running 10000 simulations.:  90%|████████▉ | 8995/10000 [00:36<00:04, 246.56it/s]Running 10000 simulations.:  90%|█████████ | 9020/10000 [00:37<00:03, 245.22it/s]Running 10000 simulations.:  90%|█████████ | 9045/10000 [00:37<00:03, 242.36it/s]Running 10000 simulations.:  91%|█████████ | 9070/10000 [00:37<00:03, 242.50it/s]Running 10000 simulations.:  91%|█████████ | 9095/10000 [00:37<00:03, 243.58it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:37<00:03, 243.46it/s]Running 10000 simulations.:  91%|█████████▏| 9145/10000 [00:37<00:03, 243.78it/s]Running 10000 simulations.:  92%|█████████▏| 9170/10000 [00:37<00:03, 243.88it/s]Running 10000 simulations.:  92%|█████████▏| 9195/10000 [00:37<00:03, 243.56it/s]Running 10000 simulations.:  92%|█████████▏| 9220/10000 [00:37<00:03, 244.13it/s]Running 10000 simulations.:  92%|█████████▏| 9245/10000 [00:38<00:03, 243.44it/s]Running 10000 simulations.:  93%|█████████▎| 9270/10000 [00:38<00:03, 242.84it/s]Running 10000 simulations.:  93%|█████████▎| 9295/10000 [00:38<00:02, 244.11it/s]Running 10000 simulations.:  93%|█████████▎| 9320/10000 [00:38<00:02, 242.66it/s]Running 10000 simulations.:  93%|█████████▎| 9345/10000 [00:38<00:02, 241.69it/s]Running 10000 simulations.:  94%|█████████▎| 9370/10000 [00:38<00:02, 242.87it/s]Running 10000 simulations.:  94%|█████████▍| 9395/10000 [00:38<00:02, 244.17it/s]Running 10000 simulations.:  94%|█████████▍| 9420/10000 [00:38<00:02, 245.34it/s]Running 10000 simulations.:  94%|█████████▍| 9445/10000 [00:38<00:02, 243.34it/s]Running 10000 simulations.:  95%|█████████▍| 9470/10000 [00:38<00:02, 241.59it/s]Running 10000 simulations.:  95%|█████████▍| 9495/10000 [00:39<00:02, 242.79it/s]Running 10000 simulations.:  95%|█████████▌| 9520/10000 [00:39<00:01, 242.90it/s]Running 10000 simulations.:  95%|█████████▌| 9545/10000 [00:39<00:01, 242.71it/s]Running 10000 simulations.:  96%|█████████▌| 9570/10000 [00:39<00:01, 244.52it/s]Running 10000 simulations.:  96%|█████████▌| 9595/10000 [00:39<00:01, 243.18it/s]Running 10000 simulations.:  96%|█████████▌| 9620/10000 [00:39<00:01, 241.49it/s]Running 10000 simulations.:  96%|█████████▋| 9645/10000 [00:39<00:01, 243.71it/s]Running 10000 simulations.:  97%|█████████▋| 9670/10000 [00:39<00:01, 244.46it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:39<00:01, 245.38it/s]Running 10000 simulations.:  97%|█████████▋| 9720/10000 [00:39<00:01, 245.69it/s]Running 10000 simulations.:  97%|█████████▋| 9745/10000 [00:40<00:01, 245.75it/s]Running 10000 simulations.:  98%|█████████▊| 9771/10000 [00:40<00:00, 247.28it/s]Running 10000 simulations.:  98%|█████████▊| 9797/10000 [00:40<00:00, 248.52it/s]Running 10000 simulations.:  98%|█████████▊| 9822/10000 [00:40<00:00, 247.34it/s]Running 10000 simulations.:  98%|█████████▊| 9847/10000 [00:40<00:00, 245.39it/s]Running 10000 simulations.:  99%|█████████▊| 9872/10000 [00:40<00:00, 245.87it/s]Running 10000 simulations.:  99%|█████████▉| 9897/10000 [00:40<00:00, 246.10it/s]Running 10000 simulations.:  99%|█████████▉| 9922/10000 [00:40<00:00, 246.22it/s]Running 10000 simulations.:  99%|█████████▉| 9947/10000 [00:40<00:00, 246.74it/s]Running 10000 simulations.: 100%|█████████▉| 9972/10000 [00:40<00:00, 246.53it/s]Running 10000 simulations.: 100%|█████████▉| 9997/10000 [00:41<00:00, 246.35it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:41<00:00, 243.35it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 270.70it/s]Running 10000 simulations.:   1%|          | 54/10000 [00:00<00:37, 265.69it/s]Running 10000 simulations.:   1%|          | 80/10000 [00:00<00:37, 261.35it/s]Running 10000 simulations.:   1%|          | 107/10000 [00:00<00:37, 261.09it/s]Running 10000 simulations.:   1%|▏         | 134/10000 [00:00<00:37, 261.49it/s]Running 10000 simulations.:   2%|▏         | 161/10000 [00:00<00:37, 261.95it/s]Running 10000 simulations.:   2%|▏         | 188/10000 [00:00<00:37, 263.56it/s]Running 10000 simulations.:   2%|▏         | 214/10000 [00:00<00:37, 260.68it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:00<00:37, 259.98it/s]Running 10000 simulations.:   3%|▎         | 266/10000 [00:01<00:37, 259.94it/s]Running 10000 simulations.:   3%|▎         | 293/10000 [00:01<00:37, 260.43it/s]Running 10000 simulations.:   3%|▎         | 319/10000 [00:01<00:37, 259.91it/s]Running 10000 simulations.:   3%|▎         | 345/10000 [00:01<00:37, 256.70it/s]Running 10000 simulations.:   4%|▎         | 371/10000 [00:01<00:37, 254.73it/s]Running 10000 simulations.:   4%|▍         | 397/10000 [00:01<00:37, 255.12it/s]Running 10000 simulations.:   4%|▍         | 423/10000 [00:01<00:37, 255.82it/s]Running 10000 simulations.:   4%|▍         | 449/10000 [00:01<00:37, 256.07it/s]Running 10000 simulations.:   5%|▍         | 475/10000 [00:01<00:37, 257.12it/s]Running 10000 simulations.:   5%|▌         | 501/10000 [00:01<00:36, 257.40it/s]Running 10000 simulations.:   5%|▌         | 527/10000 [00:02<00:37, 255.91it/s]Running 10000 simulations.:   6%|▌         | 553/10000 [00:02<00:36, 256.97it/s]Running 10000 simulations.:   6%|▌         | 579/10000 [00:02<00:36, 257.03it/s]Running 10000 simulations.:   6%|▌         | 605/10000 [00:02<00:36, 257.08it/s]Running 10000 simulations.:   6%|▋         | 631/10000 [00:02<00:36, 253.72it/s]Running 10000 simulations.:   7%|▋         | 657/10000 [00:02<00:36, 254.62it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:02<00:36, 256.63it/s]Running 10000 simulations.:   7%|▋         | 710/10000 [00:02<00:36, 254.01it/s]Running 10000 simulations.:   7%|▋         | 736/10000 [00:02<00:36, 254.05it/s]Running 10000 simulations.:   8%|▊         | 762/10000 [00:02<00:36, 254.22it/s]Running 10000 simulations.:   8%|▊         | 788/10000 [00:03<00:36, 255.59it/s]Running 10000 simulations.:   8%|▊         | 814/10000 [00:03<00:35, 255.73it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:03<00:35, 256.38it/s]Running 10000 simulations.:   9%|▊         | 866/10000 [00:03<00:36, 252.97it/s]Running 10000 simulations.:   9%|▉         | 892/10000 [00:03<00:36, 252.52it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:03<00:35, 252.66it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:03<00:35, 252.34it/s]Running 10000 simulations.:  10%|▉         | 970/10000 [00:03<00:35, 252.88it/s]Running 10000 simulations.:  10%|▉         | 996/10000 [00:03<00:35, 254.25it/s]Running 10000 simulations.:  10%|█         | 1022/10000 [00:03<00:35, 251.75it/s]Running 10000 simulations.:  10%|█         | 1048/10000 [00:04<00:35, 251.68it/s]Running 10000 simulations.:  11%|█         | 1074/10000 [00:04<00:35, 252.09it/s]Running 10000 simulations.:  11%|█         | 1100/10000 [00:04<00:35, 253.17it/s]Running 10000 simulations.:  11%|█▏        | 1126/10000 [00:04<00:35, 253.05it/s]Running 10000 simulations.:  12%|█▏        | 1152/10000 [00:04<00:34, 253.89it/s]Running 10000 simulations.:  12%|█▏        | 1178/10000 [00:04<00:35, 251.26it/s]Running 10000 simulations.:  12%|█▏        | 1204/10000 [00:04<00:34, 251.46it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:04<00:34, 252.02it/s]Running 10000 simulations.:  13%|█▎        | 1256/10000 [00:04<00:34, 253.02it/s]Running 10000 simulations.:  13%|█▎        | 1282/10000 [00:05<00:34, 254.57it/s]Running 10000 simulations.:  13%|█▎        | 1309/10000 [00:05<00:33, 256.15it/s]Running 10000 simulations.:  13%|█▎        | 1335/10000 [00:05<00:34, 253.52it/s]Running 10000 simulations.:  14%|█▎        | 1361/10000 [00:05<00:34, 253.53it/s]Running 10000 simulations.:  14%|█▍        | 1387/10000 [00:05<00:33, 253.87it/s]Running 10000 simulations.:  14%|█▍        | 1413/10000 [00:05<00:33, 254.24it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:05<00:33, 254.72it/s]Running 10000 simulations.:  15%|█▍        | 1465/10000 [00:05<00:33, 255.01it/s]Running 10000 simulations.:  15%|█▍        | 1491/10000 [00:05<00:33, 252.88it/s]Running 10000 simulations.:  15%|█▌        | 1517/10000 [00:05<00:34, 245.45it/s]Running 10000 simulations.:  15%|█▌        | 1543/10000 [00:06<00:34, 247.75it/s]Running 10000 simulations.:  16%|█▌        | 1569/10000 [00:06<00:33, 249.42it/s]Running 10000 simulations.:  16%|█▌        | 1595/10000 [00:06<00:33, 252.12it/s]Running 10000 simulations.:  16%|█▌        | 1621/10000 [00:06<00:33, 253.85it/s]Running 10000 simulations.:  16%|█▋        | 1647/10000 [00:06<00:33, 251.67it/s]Running 10000 simulations.:  17%|█▋        | 1673/10000 [00:06<00:33, 251.89it/s]Running 10000 simulations.:  17%|█▋        | 1699/10000 [00:06<00:32, 253.63it/s]Running 10000 simulations.:  17%|█▋        | 1725/10000 [00:06<00:32, 254.05it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:06<00:32, 254.96it/s]Running 10000 simulations.:  18%|█▊        | 1777/10000 [00:06<00:32, 253.55it/s]Running 10000 simulations.:  18%|█▊        | 1803/10000 [00:07<00:32, 253.48it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:07<00:32, 253.37it/s]Running 10000 simulations.:  19%|█▊        | 1855/10000 [00:07<00:32, 253.40it/s]Running 10000 simulations.:  19%|█▉        | 1881/10000 [00:07<00:32, 250.51it/s]Running 10000 simulations.:  19%|█▉        | 1907/10000 [00:07<00:32, 250.97it/s]Running 10000 simulations.:  19%|█▉        | 1933/10000 [00:07<00:31, 252.48it/s]Running 10000 simulations.:  20%|█▉        | 1959/10000 [00:07<00:31, 254.07it/s]Running 10000 simulations.:  20%|█▉        | 1985/10000 [00:07<00:31, 253.26it/s]Running 10000 simulations.:  20%|██        | 2011/10000 [00:07<00:31, 253.03it/s]Running 10000 simulations.:  20%|██        | 2037/10000 [00:08<00:31, 252.14it/s]Running 10000 simulations.:  21%|██        | 2063/10000 [00:08<00:31, 252.26it/s]Running 10000 simulations.:  21%|██        | 2089/10000 [00:08<00:31, 253.47it/s]Running 10000 simulations.:  21%|██        | 2115/10000 [00:08<00:31, 253.78it/s]Running 10000 simulations.:  21%|██▏       | 2141/10000 [00:08<00:31, 252.74it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:08<00:30, 253.23it/s]Running 10000 simulations.:  22%|██▏       | 2193/10000 [00:08<00:30, 253.76it/s]Running 10000 simulations.:  22%|██▏       | 2219/10000 [00:08<00:30, 254.59it/s]Running 10000 simulations.:  22%|██▏       | 2245/10000 [00:08<00:30, 255.06it/s]Running 10000 simulations.:  23%|██▎       | 2271/10000 [00:08<00:30, 255.46it/s]Running 10000 simulations.:  23%|██▎       | 2297/10000 [00:09<00:30, 253.85it/s]Running 10000 simulations.:  23%|██▎       | 2323/10000 [00:09<00:30, 254.24it/s]Running 10000 simulations.:  23%|██▎       | 2349/10000 [00:09<00:30, 254.19it/s]Running 10000 simulations.:  24%|██▍       | 2375/10000 [00:09<00:30, 253.92it/s]Running 10000 simulations.:  24%|██▍       | 2401/10000 [00:09<00:30, 252.36it/s]Running 10000 simulations.:  24%|██▍       | 2427/10000 [00:09<00:30, 250.46it/s]Running 10000 simulations.:  25%|██▍       | 2453/10000 [00:09<00:30, 249.02it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:09<00:29, 251.07it/s]Running 10000 simulations.:  25%|██▌       | 2505/10000 [00:09<00:29, 252.14it/s]Running 10000 simulations.:  25%|██▌       | 2531/10000 [00:09<00:29, 252.79it/s]Running 10000 simulations.:  26%|██▌       | 2557/10000 [00:10<00:29, 253.65it/s]Running 10000 simulations.:  26%|██▌       | 2583/10000 [00:10<00:29, 252.46it/s]Running 10000 simulations.:  26%|██▌       | 2609/10000 [00:10<00:29, 252.53it/s]Running 10000 simulations.:  26%|██▋       | 2635/10000 [00:10<00:29, 253.26it/s]Running 10000 simulations.:  27%|██▋       | 2661/10000 [00:10<00:28, 254.46it/s]Running 10000 simulations.:  27%|██▋       | 2687/10000 [00:10<00:28, 255.11it/s]Running 10000 simulations.:  27%|██▋       | 2713/10000 [00:10<00:28, 256.13it/s]Running 10000 simulations.:  27%|██▋       | 2739/10000 [00:10<00:28, 253.27it/s]Running 10000 simulations.:  28%|██▊       | 2765/10000 [00:10<00:28, 253.11it/s]Running 10000 simulations.:  28%|██▊       | 2791/10000 [00:10<00:28, 252.13it/s]Running 10000 simulations.:  28%|██▊       | 2817/10000 [00:11<00:28, 252.47it/s]Running 10000 simulations.:  28%|██▊       | 2843/10000 [00:11<00:28, 254.29it/s]Running 10000 simulations.:  29%|██▊       | 2869/10000 [00:11<00:27, 255.32it/s]Running 10000 simulations.:  29%|██▉       | 2895/10000 [00:11<00:28, 253.28it/s]Running 10000 simulations.:  29%|██▉       | 2921/10000 [00:11<00:28, 246.83it/s]Running 10000 simulations.:  29%|██▉       | 2946/10000 [00:11<00:28, 245.04it/s]Running 10000 simulations.:  30%|██▉       | 2972/10000 [00:11<00:28, 246.95it/s]Running 10000 simulations.:  30%|██▉       | 2998/10000 [00:11<00:28, 249.01it/s]Running 10000 simulations.:  30%|███       | 3023/10000 [00:11<00:28, 247.79it/s]Running 10000 simulations.:  30%|███       | 3049/10000 [00:12<00:27, 249.69it/s]Running 10000 simulations.:  31%|███       | 3075/10000 [00:12<00:27, 251.88it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:12<00:27, 252.10it/s]Running 10000 simulations.:  31%|███▏      | 3127/10000 [00:12<00:27, 250.55it/s]Running 10000 simulations.:  32%|███▏      | 3153/10000 [00:12<00:27, 251.08it/s]Running 10000 simulations.:  32%|███▏      | 3179/10000 [00:12<00:27, 251.11it/s]Running 10000 simulations.:  32%|███▏      | 3205/10000 [00:12<00:27, 251.52it/s]Running 10000 simulations.:  32%|███▏      | 3231/10000 [00:12<00:26, 252.06it/s]Running 10000 simulations.:  33%|███▎      | 3257/10000 [00:12<00:26, 252.69it/s]Running 10000 simulations.:  33%|███▎      | 3283/10000 [00:12<00:26, 251.55it/s]Running 10000 simulations.:  33%|███▎      | 3309/10000 [00:13<00:26, 251.28it/s]Running 10000 simulations.:  33%|███▎      | 3335/10000 [00:13<00:26, 252.33it/s]Running 10000 simulations.:  34%|███▎      | 3361/10000 [00:13<00:26, 253.06it/s]Running 10000 simulations.:  34%|███▍      | 3387/10000 [00:13<00:26, 253.17it/s]Running 10000 simulations.:  34%|███▍      | 3413/10000 [00:13<00:26, 252.91it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:13<00:26, 247.19it/s]Running 10000 simulations.:  35%|███▍      | 3464/10000 [00:13<00:26, 245.94it/s]Running 10000 simulations.:  35%|███▍      | 3489/10000 [00:13<00:26, 245.65it/s]Running 10000 simulations.:  35%|███▌      | 3515/10000 [00:13<00:26, 248.39it/s]Running 10000 simulations.:  35%|███▌      | 3541/10000 [00:13<00:25, 250.44it/s]Running 10000 simulations.:  36%|███▌      | 3567/10000 [00:14<00:25, 250.68it/s]Running 10000 simulations.:  36%|███▌      | 3593/10000 [00:14<00:26, 245.24it/s]Running 10000 simulations.:  36%|███▌      | 3618/10000 [00:14<00:25, 246.27it/s]Running 10000 simulations.:  36%|███▋      | 3644/10000 [00:14<00:25, 248.26it/s]Running 10000 simulations.:  37%|███▋      | 3670/10000 [00:14<00:25, 249.92it/s]Running 10000 simulations.:  37%|███▋      | 3696/10000 [00:14<00:25, 250.06it/s]Running 10000 simulations.:  37%|███▋      | 3722/10000 [00:14<00:25, 250.52it/s]Running 10000 simulations.:  37%|███▋      | 3748/10000 [00:14<00:25, 249.02it/s]Running 10000 simulations.:  38%|███▊      | 3774/10000 [00:14<00:24, 249.80it/s]Running 10000 simulations.:  38%|███▊      | 3800/10000 [00:15<00:24, 250.76it/s]Running 10000 simulations.:  38%|███▊      | 3826/10000 [00:15<00:24, 251.67it/s]Running 10000 simulations.:  39%|███▊      | 3852/10000 [00:15<00:24, 251.37it/s]Running 10000 simulations.:  39%|███▉      | 3878/10000 [00:15<00:24, 251.67it/s]Running 10000 simulations.:  39%|███▉      | 3904/10000 [00:15<00:24, 249.53it/s]Running 10000 simulations.:  39%|███▉      | 3929/10000 [00:15<00:24, 249.61it/s]Running 10000 simulations.:  40%|███▉      | 3955/10000 [00:15<00:24, 250.50it/s]Running 10000 simulations.:  40%|███▉      | 3981/10000 [00:15<00:24, 250.48it/s]Running 10000 simulations.:  40%|████      | 4007/10000 [00:15<00:23, 250.82it/s]Running 10000 simulations.:  40%|████      | 4033/10000 [00:15<00:23, 251.19it/s]Running 10000 simulations.:  41%|████      | 4059/10000 [00:16<00:23, 250.81it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:16<00:23, 252.04it/s]Running 10000 simulations.:  41%|████      | 4111/10000 [00:16<00:23, 252.19it/s]Running 10000 simulations.:  41%|████▏     | 4137/10000 [00:16<00:23, 253.24it/s]Running 10000 simulations.:  42%|████▏     | 4163/10000 [00:16<00:22, 254.01it/s]Running 10000 simulations.:  42%|████▏     | 4189/10000 [00:16<00:22, 253.01it/s]Running 10000 simulations.:  42%|████▏     | 4215/10000 [00:16<00:23, 251.31it/s]Running 10000 simulations.:  42%|████▏     | 4241/10000 [00:16<00:22, 251.64it/s]Running 10000 simulations.:  43%|████▎     | 4267/10000 [00:16<00:22, 252.52it/s]Running 10000 simulations.:  43%|████▎     | 4293/10000 [00:16<00:22, 249.43it/s]Running 10000 simulations.:  43%|████▎     | 4318/10000 [00:17<00:22, 248.83it/s]Running 10000 simulations.:  43%|████▎     | 4344/10000 [00:17<00:22, 250.23it/s]Running 10000 simulations.:  44%|████▎     | 4370/10000 [00:17<00:22, 252.17it/s]Running 10000 simulations.:  44%|████▍     | 4396/10000 [00:17<00:22, 250.15it/s]Running 10000 simulations.:  44%|████▍     | 4422/10000 [00:17<00:22, 250.46it/s]Running 10000 simulations.:  44%|████▍     | 4448/10000 [00:17<00:22, 250.78it/s]Running 10000 simulations.:  45%|████▍     | 4474/10000 [00:17<00:21, 251.30it/s]Running 10000 simulations.:  45%|████▌     | 4500/10000 [00:17<00:21, 252.03it/s]Running 10000 simulations.:  45%|████▌     | 4526/10000 [00:17<00:21, 253.22it/s]Running 10000 simulations.:  46%|████▌     | 4552/10000 [00:18<00:21, 252.12it/s]Running 10000 simulations.:  46%|████▌     | 4578/10000 [00:18<00:21, 251.07it/s]Running 10000 simulations.:  46%|████▌     | 4604/10000 [00:18<00:21, 251.90it/s]Running 10000 simulations.:  46%|████▋     | 4630/10000 [00:18<00:21, 252.52it/s]Running 10000 simulations.:  47%|████▋     | 4656/10000 [00:18<00:21, 253.10it/s]Running 10000 simulations.:  47%|████▋     | 4682/10000 [00:18<00:20, 253.31it/s]Running 10000 simulations.:  47%|████▋     | 4708/10000 [00:18<00:21, 251.32it/s]Running 10000 simulations.:  47%|████▋     | 4734/10000 [00:18<00:20, 250.93it/s]Running 10000 simulations.:  48%|████▊     | 4760/10000 [00:18<00:20, 251.44it/s]Running 10000 simulations.:  48%|████▊     | 4786/10000 [00:18<00:20, 251.47it/s]Running 10000 simulations.:  48%|████▊     | 4812/10000 [00:19<00:20, 252.41it/s]Running 10000 simulations.:  48%|████▊     | 4838/10000 [00:19<00:20, 251.58it/s]Running 10000 simulations.:  49%|████▊     | 4864/10000 [00:19<00:20, 249.32it/s]Running 10000 simulations.:  49%|████▉     | 4889/10000 [00:19<00:20, 249.47it/s]Running 10000 simulations.:  49%|████▉     | 4915/10000 [00:19<00:20, 250.41it/s]Running 10000 simulations.:  49%|████▉     | 4941/10000 [00:19<00:20, 251.38it/s]Running 10000 simulations.:  50%|████▉     | 4967/10000 [00:19<00:20, 251.07it/s]Running 10000 simulations.:  50%|████▉     | 4993/10000 [00:19<00:20, 247.19it/s]Running 10000 simulations.:  50%|█████     | 5018/10000 [00:19<00:20, 245.31it/s]Running 10000 simulations.:  50%|█████     | 5043/10000 [00:19<00:20, 246.06it/s]Running 10000 simulations.:  51%|█████     | 5069/10000 [00:20<00:19, 247.93it/s]Running 10000 simulations.:  51%|█████     | 5095/10000 [00:20<00:19, 249.12it/s]Running 10000 simulations.:  51%|█████     | 5121/10000 [00:20<00:19, 249.51it/s]Running 10000 simulations.:  51%|█████▏    | 5146/10000 [00:20<00:19, 249.57it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:20<00:19, 245.63it/s]Running 10000 simulations.:  52%|█████▏    | 5196/10000 [00:20<00:19, 246.77it/s]Running 10000 simulations.:  52%|█████▏    | 5222/10000 [00:20<00:19, 248.32it/s]Running 10000 simulations.:  52%|█████▏    | 5247/10000 [00:20<00:19, 248.22it/s]Running 10000 simulations.:  53%|█████▎    | 5273/10000 [00:20<00:18, 250.15it/s]Running 10000 simulations.:  53%|█████▎    | 5299/10000 [00:21<00:18, 250.80it/s]Running 10000 simulations.:  53%|█████▎    | 5325/10000 [00:21<00:18, 249.61it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:21<00:18, 250.32it/s]Running 10000 simulations.:  54%|█████▍    | 5377/10000 [00:21<00:18, 250.66it/s]Running 10000 simulations.:  54%|█████▍    | 5403/10000 [00:21<00:18, 247.30it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:21<00:18, 246.26it/s]Running 10000 simulations.:  55%|█████▍    | 5453/10000 [00:21<00:18, 247.20it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:21<00:18, 248.52it/s]Running 10000 simulations.:  55%|█████▌    | 5504/10000 [00:21<00:18, 248.60it/s]Running 10000 simulations.:  55%|█████▌    | 5529/10000 [00:21<00:18, 247.26it/s]Running 10000 simulations.:  56%|█████▌    | 5554/10000 [00:22<00:18, 246.73it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:22<00:17, 248.07it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:22<00:17, 250.13it/s]Running 10000 simulations.:  56%|█████▋    | 5632/10000 [00:22<00:17, 251.28it/s]Running 10000 simulations.:  57%|█████▋    | 5658/10000 [00:22<00:17, 252.17it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:22<00:17, 251.41it/s]Running 10000 simulations.:  57%|█████▋    | 5710/10000 [00:22<00:17, 248.43it/s]Running 10000 simulations.:  57%|█████▋    | 5735/10000 [00:22<00:17, 248.58it/s]Running 10000 simulations.:  58%|█████▊    | 5760/10000 [00:22<00:17, 246.73it/s]Running 10000 simulations.:  58%|█████▊    | 5785/10000 [00:22<00:17, 246.75it/s]Running 10000 simulations.:  58%|█████▊    | 5811/10000 [00:23<00:16, 248.59it/s]Running 10000 simulations.:  58%|█████▊    | 5836/10000 [00:23<00:16, 246.48it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:23<00:16, 247.32it/s]Running 10000 simulations.:  59%|█████▉    | 5887/10000 [00:23<00:16, 248.75it/s]Running 10000 simulations.:  59%|█████▉    | 5913/10000 [00:23<00:16, 250.22it/s]Running 10000 simulations.:  59%|█████▉    | 5939/10000 [00:23<00:16, 251.17it/s]Running 10000 simulations.:  60%|█████▉    | 5965/10000 [00:23<00:16, 251.73it/s]Running 10000 simulations.:  60%|█████▉    | 5991/10000 [00:23<00:16, 247.35it/s]Running 10000 simulations.:  60%|██████    | 6016/10000 [00:23<00:16, 248.09it/s]Running 10000 simulations.:  60%|██████    | 6041/10000 [00:23<00:15, 248.34it/s]Running 10000 simulations.:  61%|██████    | 6067/10000 [00:24<00:15, 249.78it/s]Running 10000 simulations.:  61%|██████    | 6093/10000 [00:24<00:15, 251.70it/s]Running 10000 simulations.:  61%|██████    | 6119/10000 [00:24<00:15, 252.32it/s]Running 10000 simulations.:  61%|██████▏   | 6145/10000 [00:24<00:15, 250.92it/s]Running 10000 simulations.:  62%|██████▏   | 6171/10000 [00:24<00:15, 250.97it/s]Running 10000 simulations.:  62%|██████▏   | 6197/10000 [00:24<00:15, 250.78it/s]Running 10000 simulations.:  62%|██████▏   | 6223/10000 [00:24<00:15, 251.16it/s]Running 10000 simulations.:  62%|██████▏   | 6249/10000 [00:24<00:14, 251.86it/s]Running 10000 simulations.:  63%|██████▎   | 6275/10000 [00:24<00:14, 251.44it/s]Running 10000 simulations.:  63%|██████▎   | 6301/10000 [00:25<00:14, 249.99it/s]Running 10000 simulations.:  63%|██████▎   | 6327/10000 [00:25<00:14, 251.43it/s]Running 10000 simulations.:  64%|██████▎   | 6353/10000 [00:25<00:14, 252.63it/s]Running 10000 simulations.:  64%|██████▍   | 6379/10000 [00:25<00:14, 252.65it/s]Running 10000 simulations.:  64%|██████▍   | 6405/10000 [00:25<00:14, 253.66it/s]Running 10000 simulations.:  64%|██████▍   | 6431/10000 [00:25<00:14, 251.44it/s]Running 10000 simulations.:  65%|██████▍   | 6457/10000 [00:25<00:14, 252.30it/s]Running 10000 simulations.:  65%|██████▍   | 6483/10000 [00:25<00:13, 252.16it/s]Running 10000 simulations.:  65%|██████▌   | 6509/10000 [00:25<00:13, 252.28it/s]Running 10000 simulations.:  65%|██████▌   | 6535/10000 [00:25<00:13, 250.08it/s]Running 10000 simulations.:  66%|██████▌   | 6561/10000 [00:26<00:13, 249.25it/s]Running 10000 simulations.:  66%|██████▌   | 6587/10000 [00:26<00:13, 250.05it/s]Running 10000 simulations.:  66%|██████▌   | 6613/10000 [00:26<00:13, 250.44it/s]Running 10000 simulations.:  66%|██████▋   | 6639/10000 [00:26<00:13, 248.76it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:26<00:13, 250.02it/s]Running 10000 simulations.:  67%|██████▋   | 6691/10000 [00:26<00:13, 250.86it/s]Running 10000 simulations.:  67%|██████▋   | 6717/10000 [00:26<00:13, 251.05it/s]Running 10000 simulations.:  67%|██████▋   | 6743/10000 [00:26<00:12, 251.58it/s]Running 10000 simulations.:  68%|██████▊   | 6769/10000 [00:26<00:12, 250.76it/s]Running 10000 simulations.:  68%|██████▊   | 6795/10000 [00:26<00:12, 248.45it/s]Running 10000 simulations.:  68%|██████▊   | 6821/10000 [00:27<00:12, 249.25it/s]Running 10000 simulations.:  68%|██████▊   | 6847/10000 [00:27<00:12, 250.21it/s]Running 10000 simulations.:  69%|██████▊   | 6873/10000 [00:27<00:12, 251.04it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:27<00:12, 252.06it/s]Running 10000 simulations.:  69%|██████▉   | 6925/10000 [00:27<00:12, 249.04it/s]Running 10000 simulations.:  70%|██████▉   | 6951/10000 [00:27<00:12, 249.67it/s]Running 10000 simulations.:  70%|██████▉   | 6977/10000 [00:27<00:12, 251.14it/s]Running 10000 simulations.:  70%|███████   | 7003/10000 [00:27<00:11, 252.04it/s]Running 10000 simulations.:  70%|███████   | 7029/10000 [00:27<00:11, 252.44it/s]Running 10000 simulations.:  71%|███████   | 7055/10000 [00:28<00:11, 253.19it/s]Running 10000 simulations.:  71%|███████   | 7081/10000 [00:28<00:11, 250.29it/s]Running 10000 simulations.:  71%|███████   | 7107/10000 [00:28<00:11, 251.00it/s]Running 10000 simulations.:  71%|███████▏  | 7133/10000 [00:28<00:11, 250.91it/s]Running 10000 simulations.:  72%|███████▏  | 7159/10000 [00:28<00:11, 251.45it/s]Running 10000 simulations.:  72%|███████▏  | 7185/10000 [00:28<00:11, 251.89it/s]Running 10000 simulations.:  72%|███████▏  | 7211/10000 [00:28<00:11, 252.67it/s]Running 10000 simulations.:  72%|███████▏  | 7237/10000 [00:28<00:11, 251.17it/s]Running 10000 simulations.:  73%|███████▎  | 7263/10000 [00:28<00:10, 250.82it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:28<00:10, 251.61it/s]Running 10000 simulations.:  73%|███████▎  | 7315/10000 [00:29<00:10, 251.45it/s]Running 10000 simulations.:  73%|███████▎  | 7341/10000 [00:29<00:10, 251.48it/s]Running 10000 simulations.:  74%|███████▎  | 7367/10000 [00:29<00:10, 253.01it/s]Running 10000 simulations.:  74%|███████▍  | 7393/10000 [00:29<00:10, 249.53it/s]Running 10000 simulations.:  74%|███████▍  | 7419/10000 [00:29<00:10, 250.16it/s]Running 10000 simulations.:  74%|███████▍  | 7445/10000 [00:29<00:10, 251.20it/s]Running 10000 simulations.:  75%|███████▍  | 7471/10000 [00:29<00:10, 251.72it/s]Running 10000 simulations.:  75%|███████▍  | 7497/10000 [00:29<00:09, 253.33it/s]Running 10000 simulations.:  75%|███████▌  | 7523/10000 [00:29<00:09, 252.11it/s]Running 10000 simulations.:  75%|███████▌  | 7549/10000 [00:29<00:09, 245.19it/s]Running 10000 simulations.:  76%|███████▌  | 7574/10000 [00:30<00:09, 243.90it/s]Running 10000 simulations.:  76%|███████▌  | 7599/10000 [00:30<00:09, 245.16it/s]Running 10000 simulations.:  76%|███████▋  | 7625/10000 [00:30<00:09, 248.44it/s]Running 10000 simulations.:  77%|███████▋  | 7651/10000 [00:30<00:09, 250.79it/s]Running 10000 simulations.:  77%|███████▋  | 7677/10000 [00:30<00:09, 250.36it/s]Running 10000 simulations.:  77%|███████▋  | 7703/10000 [00:30<00:09, 246.18it/s]Running 10000 simulations.:  77%|███████▋  | 7728/10000 [00:30<00:09, 246.52it/s]Running 10000 simulations.:  78%|███████▊  | 7753/10000 [00:30<00:09, 246.48it/s]Running 10000 simulations.:  78%|███████▊  | 7778/10000 [00:30<00:09, 246.83it/s]Running 10000 simulations.:  78%|███████▊  | 7803/10000 [00:31<00:08, 246.84it/s]Running 10000 simulations.:  78%|███████▊  | 7829/10000 [00:31<00:08, 248.48it/s]Running 10000 simulations.:  79%|███████▊  | 7855/10000 [00:31<00:08, 250.10it/s]Running 10000 simulations.:  79%|███████▉  | 7882/10000 [00:31<00:08, 253.28it/s]Running 10000 simulations.:  79%|███████▉  | 7908/10000 [00:31<00:08, 252.96it/s]Running 10000 simulations.:  79%|███████▉  | 7934/10000 [00:31<00:08, 247.77it/s]Running 10000 simulations.:  80%|███████▉  | 7959/10000 [00:31<00:08, 247.90it/s]Running 10000 simulations.:  80%|███████▉  | 7985/10000 [00:31<00:08, 250.35it/s]Running 10000 simulations.:  80%|████████  | 8011/10000 [00:31<00:07, 252.98it/s]Running 10000 simulations.:  80%|████████  | 8037/10000 [00:31<00:07, 254.05it/s]Running 10000 simulations.:  81%|████████  | 8063/10000 [00:32<00:07, 249.35it/s]Running 10000 simulations.:  81%|████████  | 8088/10000 [00:32<00:07, 246.40it/s]Running 10000 simulations.:  81%|████████  | 8113/10000 [00:32<00:07, 246.43it/s]Running 10000 simulations.:  81%|████████▏ | 8139/10000 [00:32<00:07, 248.90it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:32<00:07, 251.48it/s]Running 10000 simulations.:  82%|████████▏ | 8191/10000 [00:32<00:07, 253.93it/s]Running 10000 simulations.:  82%|████████▏ | 8217/10000 [00:32<00:07, 248.49it/s]Running 10000 simulations.:  82%|████████▏ | 8242/10000 [00:32<00:07, 247.98it/s]Running 10000 simulations.:  83%|████████▎ | 8267/10000 [00:32<00:07, 247.00it/s]Running 10000 simulations.:  83%|████████▎ | 8293/10000 [00:32<00:06, 248.47it/s]Running 10000 simulations.:  83%|████████▎ | 8319/10000 [00:33<00:06, 249.71it/s]Running 10000 simulations.:  83%|████████▎ | 8344/10000 [00:33<00:06, 248.64it/s]Running 10000 simulations.:  84%|████████▎ | 8369/10000 [00:33<00:06, 242.18it/s]Running 10000 simulations.:  84%|████████▍ | 8394/10000 [00:33<00:06, 243.59it/s]Running 10000 simulations.:  84%|████████▍ | 8420/10000 [00:33<00:06, 245.96it/s]Running 10000 simulations.:  84%|████████▍ | 8446/10000 [00:33<00:06, 248.10it/s]Running 10000 simulations.:  85%|████████▍ | 8472/10000 [00:33<00:06, 249.71it/s]Running 10000 simulations.:  85%|████████▍ | 8498/10000 [00:33<00:05, 250.50it/s]Running 10000 simulations.:  85%|████████▌ | 8524/10000 [00:33<00:05, 249.12it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:34<00:05, 249.79it/s]Running 10000 simulations.:  86%|████████▌ | 8576/10000 [00:34<00:05, 250.71it/s]Running 10000 simulations.:  86%|████████▌ | 8602/10000 [00:34<00:05, 250.59it/s]Running 10000 simulations.:  86%|████████▋ | 8628/10000 [00:34<00:05, 252.24it/s]Running 10000 simulations.:  87%|████████▋ | 8654/10000 [00:34<00:05, 248.60it/s]Running 10000 simulations.:  87%|████████▋ | 8679/10000 [00:34<00:05, 244.47it/s]Running 10000 simulations.:  87%|████████▋ | 8705/10000 [00:34<00:05, 247.32it/s]Running 10000 simulations.:  87%|████████▋ | 8731/10000 [00:34<00:05, 248.64it/s]Running 10000 simulations.:  88%|████████▊ | 8757/10000 [00:34<00:04, 250.14it/s]Running 10000 simulations.:  88%|████████▊ | 8783/10000 [00:34<00:04, 252.91it/s]Running 10000 simulations.:  88%|████████▊ | 8809/10000 [00:35<00:04, 250.82it/s]Running 10000 simulations.:  88%|████████▊ | 8835/10000 [00:35<00:04, 251.06it/s]Running 10000 simulations.:  89%|████████▊ | 8861/10000 [00:35<00:04, 252.20it/s]Running 10000 simulations.:  89%|████████▉ | 8887/10000 [00:35<00:04, 252.46it/s]Running 10000 simulations.:  89%|████████▉ | 8913/10000 [00:35<00:04, 251.16it/s]Running 10000 simulations.:  89%|████████▉ | 8939/10000 [00:35<00:04, 250.66it/s]Running 10000 simulations.:  90%|████████▉ | 8965/10000 [00:35<00:04, 252.05it/s]Running 10000 simulations.:  90%|████████▉ | 8991/10000 [00:35<00:03, 252.77it/s]Running 10000 simulations.:  90%|█████████ | 9017/10000 [00:35<00:04, 241.91it/s]Running 10000 simulations.:  90%|█████████ | 9042/10000 [00:35<00:03, 244.11it/s]Running 10000 simulations.:  91%|█████████ | 9068/10000 [00:36<00:03, 246.22it/s]Running 10000 simulations.:  91%|█████████ | 9094/10000 [00:36<00:03, 248.45it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:36<00:03, 250.89it/s]Running 10000 simulations.:  91%|█████████▏| 9146/10000 [00:36<00:03, 251.21it/s]Running 10000 simulations.:  92%|█████████▏| 9172/10000 [00:36<00:03, 249.38it/s]Running 10000 simulations.:  92%|█████████▏| 9198/10000 [00:36<00:03, 250.43it/s]Running 10000 simulations.:  92%|█████████▏| 9224/10000 [00:36<00:03, 251.22it/s]Running 10000 simulations.:  92%|█████████▎| 9250/10000 [00:36<00:02, 252.39it/s]Running 10000 simulations.:  93%|█████████▎| 9276/10000 [00:36<00:02, 253.85it/s]Running 10000 simulations.:  93%|█████████▎| 9302/10000 [00:37<00:02, 250.40it/s]Running 10000 simulations.:  93%|█████████▎| 9328/10000 [00:37<00:02, 251.99it/s]Running 10000 simulations.:  94%|█████████▎| 9354/10000 [00:37<00:02, 252.86it/s]Running 10000 simulations.:  94%|█████████▍| 9380/10000 [00:37<00:02, 254.16it/s]Running 10000 simulations.:  94%|█████████▍| 9406/10000 [00:37<00:02, 254.27it/s]Running 10000 simulations.:  94%|█████████▍| 9432/10000 [00:37<00:02, 255.27it/s]Running 10000 simulations.:  95%|█████████▍| 9458/10000 [00:37<00:02, 251.59it/s]Running 10000 simulations.:  95%|█████████▍| 9484/10000 [00:37<00:02, 252.36it/s]Running 10000 simulations.:  95%|█████████▌| 9510/10000 [00:37<00:01, 252.40it/s]Running 10000 simulations.:  95%|█████████▌| 9536/10000 [00:37<00:01, 253.60it/s]Running 10000 simulations.:  96%|█████████▌| 9562/10000 [00:38<00:01, 254.19it/s]Running 10000 simulations.:  96%|█████████▌| 9588/10000 [00:38<00:01, 255.44it/s]Running 10000 simulations.:  96%|█████████▌| 9614/10000 [00:38<00:01, 253.29it/s]Running 10000 simulations.:  96%|█████████▋| 9640/10000 [00:38<00:01, 252.77it/s]Running 10000 simulations.:  97%|█████████▋| 9666/10000 [00:38<00:01, 253.96it/s]Running 10000 simulations.:  97%|█████████▋| 9692/10000 [00:38<00:01, 254.55it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [00:38<00:01, 255.92it/s]Running 10000 simulations.:  97%|█████████▋| 9744/10000 [00:38<00:00, 256.81it/s]Running 10000 simulations.:  98%|█████████▊| 9770/10000 [00:38<00:00, 254.96it/s]Running 10000 simulations.:  98%|█████████▊| 9796/10000 [00:38<00:00, 256.42it/s]Running 10000 simulations.:  98%|█████████▊| 9822/10000 [00:39<00:00, 257.06it/s]Running 10000 simulations.:  98%|█████████▊| 9848/10000 [00:39<00:00, 256.74it/s]Running 10000 simulations.:  99%|█████████▊| 9874/10000 [00:39<00:00, 257.32it/s]Running 10000 simulations.:  99%|█████████▉| 9900/10000 [00:39<00:00, 256.98it/s]Running 10000 simulations.:  99%|█████████▉| 9926/10000 [00:39<00:00, 255.37it/s]Running 10000 simulations.: 100%|█████████▉| 9952/10000 [00:39<00:00, 254.91it/s]Running 10000 simulations.: 100%|█████████▉| 9978/10000 [00:39<00:00, 253.02it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:39<00:00, 251.49it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 28/10000 [00:00<00:36, 275.89it/s]Running 10000 simulations.:   1%|          | 56/10000 [00:00<00:35, 276.74it/s]Running 10000 simulations.:   1%|          | 84/10000 [00:00<00:35, 276.84it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<00:35, 276.70it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:35, 276.36it/s]Running 10000 simulations.:   2%|▏         | 168/10000 [00:00<00:35, 276.14it/s]Running 10000 simulations.:   2%|▏         | 196/10000 [00:00<00:35, 275.96it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:00<00:35, 275.35it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:00<00:35, 275.07it/s]Running 10000 simulations.:   3%|▎         | 280/10000 [00:01<00:35, 274.98it/s]Running 10000 simulations.:   3%|▎         | 308/10000 [00:01<00:35, 275.09it/s]Running 10000 simulations.:   3%|▎         | 336/10000 [00:01<00:35, 275.62it/s]Running 10000 simulations.:   4%|▎         | 364/10000 [00:01<00:35, 275.12it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:01<00:35, 274.28it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:34, 274.21it/s]Running 10000 simulations.:   4%|▍         | 448/10000 [00:01<00:34, 273.93it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:01<00:34, 274.12it/s]Running 10000 simulations.:   5%|▌         | 504/10000 [00:01<00:34, 273.21it/s]Running 10000 simulations.:   5%|▌         | 532/10000 [00:01<00:34, 273.53it/s]Running 10000 simulations.:   6%|▌         | 560/10000 [00:02<00:34, 273.36it/s]Running 10000 simulations.:   6%|▌         | 588/10000 [00:02<00:34, 272.97it/s]Running 10000 simulations.:   6%|▌         | 616/10000 [00:02<00:34, 273.32it/s]Running 10000 simulations.:   6%|▋         | 644/10000 [00:02<00:34, 273.05it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:02<00:34, 272.44it/s]Running 10000 simulations.:   7%|▋         | 700/10000 [00:02<00:34, 271.68it/s]Running 10000 simulations.:   7%|▋         | 728/10000 [00:02<00:34, 271.88it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:02<00:34, 271.06it/s]Running 10000 simulations.:   8%|▊         | 784/10000 [00:02<00:33, 271.60it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:02<00:33, 271.69it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:03<00:33, 271.70it/s]Running 10000 simulations.:   9%|▊         | 868/10000 [00:03<00:33, 272.25it/s]Running 10000 simulations.:   9%|▉         | 896/10000 [00:03<00:33, 272.12it/s]Running 10000 simulations.:   9%|▉         | 924/10000 [00:03<00:33, 272.18it/s]Running 10000 simulations.:  10%|▉         | 952/10000 [00:03<00:33, 272.30it/s]Running 10000 simulations.:  10%|▉         | 980/10000 [00:03<00:33, 268.21it/s]Running 10000 simulations.:  10%|█         | 1007/10000 [00:03<00:33, 267.66it/s]Running 10000 simulations.:  10%|█         | 1035/10000 [00:03<00:33, 268.91it/s]Running 10000 simulations.:  11%|█         | 1063/10000 [00:03<00:33, 269.91it/s]Running 10000 simulations.:  11%|█         | 1091/10000 [00:03<00:32, 270.46it/s]Running 10000 simulations.:  11%|█         | 1119/10000 [00:04<00:32, 270.45it/s]Running 10000 simulations.:  11%|█▏        | 1147/10000 [00:04<00:32, 270.93it/s]Running 10000 simulations.:  12%|█▏        | 1175/10000 [00:04<00:32, 270.47it/s]Running 10000 simulations.:  12%|█▏        | 1203/10000 [00:04<00:32, 270.77it/s]Running 10000 simulations.:  12%|█▏        | 1231/10000 [00:04<00:32, 271.23it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:04<00:32, 271.33it/s]Running 10000 simulations.:  13%|█▎        | 1287/10000 [00:04<00:32, 271.75it/s]Running 10000 simulations.:  13%|█▎        | 1315/10000 [00:04<00:31, 272.07it/s]Running 10000 simulations.:  13%|█▎        | 1343/10000 [00:04<00:31, 271.81it/s]Running 10000 simulations.:  14%|█▎        | 1371/10000 [00:05<00:31, 271.65it/s]Running 10000 simulations.:  14%|█▍        | 1399/10000 [00:05<00:31, 271.35it/s]Running 10000 simulations.:  14%|█▍        | 1427/10000 [00:05<00:31, 271.80it/s]Running 10000 simulations.:  15%|█▍        | 1455/10000 [00:05<00:31, 272.03it/s]Running 10000 simulations.:  15%|█▍        | 1483/10000 [00:05<00:31, 272.03it/s]Running 10000 simulations.:  15%|█▌        | 1511/10000 [00:05<00:31, 271.68it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:05<00:31, 271.50it/s]Running 10000 simulations.:  16%|█▌        | 1567/10000 [00:05<00:31, 271.76it/s]Running 10000 simulations.:  16%|█▌        | 1595/10000 [00:05<00:30, 271.44it/s]Running 10000 simulations.:  16%|█▌        | 1623/10000 [00:05<00:30, 271.62it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:06<00:30, 271.35it/s]Running 10000 simulations.:  17%|█▋        | 1679/10000 [00:06<00:30, 271.04it/s]Running 10000 simulations.:  17%|█▋        | 1707/10000 [00:06<00:30, 270.89it/s]Running 10000 simulations.:  17%|█▋        | 1735/10000 [00:06<00:30, 270.81it/s]Running 10000 simulations.:  18%|█▊        | 1763/10000 [00:06<00:30, 270.24it/s]Running 10000 simulations.:  18%|█▊        | 1791/10000 [00:06<00:30, 270.17it/s]Running 10000 simulations.:  18%|█▊        | 1819/10000 [00:06<00:30, 269.28it/s]Running 10000 simulations.:  18%|█▊        | 1847/10000 [00:06<00:30, 269.59it/s]Running 10000 simulations.:  19%|█▉        | 1875/10000 [00:06<00:30, 270.00it/s]Running 10000 simulations.:  19%|█▉        | 1903/10000 [00:06<00:29, 270.46it/s]Running 10000 simulations.:  19%|█▉        | 1931/10000 [00:07<00:29, 270.30it/s]Running 10000 simulations.:  20%|█▉        | 1959/10000 [00:07<00:29, 270.38it/s]Running 10000 simulations.:  20%|█▉        | 1987/10000 [00:07<00:29, 270.67it/s]Running 10000 simulations.:  20%|██        | 2015/10000 [00:07<00:30, 265.95it/s]Running 10000 simulations.:  20%|██        | 2042/10000 [00:07<00:29, 266.40it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:07<00:29, 267.70it/s]Running 10000 simulations.:  21%|██        | 2097/10000 [00:07<00:29, 268.24it/s]Running 10000 simulations.:  21%|██▏       | 2125/10000 [00:07<00:29, 268.77it/s]Running 10000 simulations.:  22%|██▏       | 2152/10000 [00:07<00:29, 268.73it/s]Running 10000 simulations.:  22%|██▏       | 2180/10000 [00:08<00:29, 269.11it/s]Running 10000 simulations.:  22%|██▏       | 2207/10000 [00:08<00:28, 269.22it/s]Running 10000 simulations.:  22%|██▏       | 2234/10000 [00:08<00:28, 269.23it/s]Running 10000 simulations.:  23%|██▎       | 2261/10000 [00:08<00:28, 268.89it/s]Running 10000 simulations.:  23%|██▎       | 2288/10000 [00:08<00:28, 268.26it/s]Running 10000 simulations.:  23%|██▎       | 2315/10000 [00:08<00:28, 268.35it/s]Running 10000 simulations.:  23%|██▎       | 2342/10000 [00:08<00:28, 267.28it/s]Running 10000 simulations.:  24%|██▎       | 2369/10000 [00:08<00:28, 267.76it/s]Running 10000 simulations.:  24%|██▍       | 2397/10000 [00:08<00:28, 268.67it/s]Running 10000 simulations.:  24%|██▍       | 2424/10000 [00:08<00:28, 268.10it/s]Running 10000 simulations.:  25%|██▍       | 2451/10000 [00:09<00:28, 266.03it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:09<00:28, 267.19it/s]Running 10000 simulations.:  25%|██▌       | 2506/10000 [00:09<00:28, 267.50it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:09<00:27, 266.99it/s]Running 10000 simulations.:  26%|██▌       | 2561/10000 [00:09<00:27, 267.98it/s]Running 10000 simulations.:  26%|██▌       | 2589/10000 [00:09<00:27, 268.91it/s]Running 10000 simulations.:  26%|██▌       | 2616/10000 [00:09<00:27, 269.13it/s]Running 10000 simulations.:  26%|██▋       | 2643/10000 [00:09<00:27, 268.87it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:09<00:27, 268.61it/s]Running 10000 simulations.:  27%|██▋       | 2697/10000 [00:09<00:27, 268.88it/s]Running 10000 simulations.:  27%|██▋       | 2724/10000 [00:10<00:27, 268.77it/s]Running 10000 simulations.:  28%|██▊       | 2751/10000 [00:10<00:26, 268.85it/s]Running 10000 simulations.:  28%|██▊       | 2778/10000 [00:10<00:26, 268.83it/s]Running 10000 simulations.:  28%|██▊       | 2805/10000 [00:10<00:26, 268.62it/s]Running 10000 simulations.:  28%|██▊       | 2833/10000 [00:10<00:26, 269.12it/s]Running 10000 simulations.:  29%|██▊       | 2860/10000 [00:10<00:26, 269.03it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:10<00:26, 268.87it/s]Running 10000 simulations.:  29%|██▉       | 2914/10000 [00:10<00:26, 267.86it/s]Running 10000 simulations.:  29%|██▉       | 2941/10000 [00:10<00:26, 267.87it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:10<00:26, 268.08it/s]Running 10000 simulations.:  30%|██▉       | 2995/10000 [00:11<00:26, 267.75it/s]Running 10000 simulations.:  30%|███       | 3022/10000 [00:11<00:26, 267.29it/s]Running 10000 simulations.:  30%|███       | 3049/10000 [00:11<00:26, 267.17it/s]Running 10000 simulations.:  31%|███       | 3076/10000 [00:11<00:25, 267.38it/s]Running 10000 simulations.:  31%|███       | 3103/10000 [00:11<00:25, 266.85it/s]Running 10000 simulations.:  31%|███▏      | 3130/10000 [00:11<00:25, 267.11it/s]Running 10000 simulations.:  32%|███▏      | 3157/10000 [00:11<00:25, 267.09it/s]Running 10000 simulations.:  32%|███▏      | 3184/10000 [00:11<00:25, 266.91it/s]Running 10000 simulations.:  32%|███▏      | 3211/10000 [00:11<00:25, 267.31it/s]Running 10000 simulations.:  32%|███▏      | 3238/10000 [00:11<00:25, 267.40it/s]Running 10000 simulations.:  33%|███▎      | 3265/10000 [00:12<00:25, 267.03it/s]Running 10000 simulations.:  33%|███▎      | 3292/10000 [00:12<00:25, 266.59it/s]Running 10000 simulations.:  33%|███▎      | 3319/10000 [00:12<00:25, 267.20it/s]Running 10000 simulations.:  33%|███▎      | 3346/10000 [00:12<00:24, 266.99it/s]Running 10000 simulations.:  34%|███▎      | 3373/10000 [00:12<00:24, 267.20it/s]Running 10000 simulations.:  34%|███▍      | 3400/10000 [00:12<00:24, 266.86it/s]Running 10000 simulations.:  34%|███▍      | 3427/10000 [00:12<00:24, 266.61it/s]Running 10000 simulations.:  35%|███▍      | 3454/10000 [00:12<00:24, 266.81it/s]Running 10000 simulations.:  35%|███▍      | 3481/10000 [00:12<00:24, 266.56it/s]Running 10000 simulations.:  35%|███▌      | 3508/10000 [00:12<00:24, 266.49it/s]Running 10000 simulations.:  35%|███▌      | 3535/10000 [00:13<00:24, 266.67it/s]Running 10000 simulations.:  36%|███▌      | 3562/10000 [00:13<00:24, 266.92it/s]Running 10000 simulations.:  36%|███▌      | 3589/10000 [00:13<00:24, 266.85it/s]Running 10000 simulations.:  36%|███▌      | 3616/10000 [00:13<00:23, 266.82it/s]Running 10000 simulations.:  36%|███▋      | 3643/10000 [00:13<00:23, 267.29it/s]Running 10000 simulations.:  37%|███▋      | 3670/10000 [00:13<00:23, 266.83it/s]Running 10000 simulations.:  37%|███▋      | 3697/10000 [00:13<00:23, 267.64it/s]Running 10000 simulations.:  37%|███▋      | 3724/10000 [00:13<00:23, 267.48it/s]Running 10000 simulations.:  38%|███▊      | 3751/10000 [00:13<00:23, 266.93it/s]Running 10000 simulations.:  38%|███▊      | 3778/10000 [00:14<00:23, 262.36it/s]Running 10000 simulations.:  38%|███▊      | 3805/10000 [00:14<00:23, 263.21it/s]Running 10000 simulations.:  38%|███▊      | 3832/10000 [00:14<00:23, 264.23it/s]Running 10000 simulations.:  39%|███▊      | 3859/10000 [00:14<00:23, 265.45it/s]Running 10000 simulations.:  39%|███▉      | 3886/10000 [00:14<00:22, 266.12it/s]Running 10000 simulations.:  39%|███▉      | 3913/10000 [00:14<00:22, 266.26it/s]Running 10000 simulations.:  39%|███▉      | 3940/10000 [00:14<00:22, 266.17it/s]Running 10000 simulations.:  40%|███▉      | 3967/10000 [00:14<00:22, 266.76it/s]Running 10000 simulations.:  40%|███▉      | 3994/10000 [00:14<00:22, 266.58it/s]Running 10000 simulations.:  40%|████      | 4021/10000 [00:14<00:22, 266.21it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:15<00:22, 265.91it/s]Running 10000 simulations.:  41%|████      | 4075/10000 [00:15<00:22, 265.90it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:15<00:22, 265.63it/s]Running 10000 simulations.:  41%|████▏     | 4129/10000 [00:15<00:22, 265.77it/s]Running 10000 simulations.:  42%|████▏     | 4156/10000 [00:15<00:22, 265.54it/s]Running 10000 simulations.:  42%|████▏     | 4183/10000 [00:15<00:21, 265.83it/s]Running 10000 simulations.:  42%|████▏     | 4210/10000 [00:15<00:21, 265.85it/s]Running 10000 simulations.:  42%|████▏     | 4237/10000 [00:15<00:21, 266.36it/s]Running 10000 simulations.:  43%|████▎     | 4264/10000 [00:15<00:21, 266.35it/s]Running 10000 simulations.:  43%|████▎     | 4291/10000 [00:15<00:21, 265.05it/s]Running 10000 simulations.:  43%|████▎     | 4318/10000 [00:16<00:21, 266.04it/s]Running 10000 simulations.:  43%|████▎     | 4345/10000 [00:16<00:21, 266.67it/s]Running 10000 simulations.:  44%|████▎     | 4372/10000 [00:16<00:21, 267.03it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:16<00:20, 267.56it/s]Running 10000 simulations.:  44%|████▍     | 4426/10000 [00:16<00:20, 267.85it/s]Running 10000 simulations.:  45%|████▍     | 4453/10000 [00:16<00:20, 268.21it/s]Running 10000 simulations.:  45%|████▍     | 4480/10000 [00:16<00:20, 267.85it/s]Running 10000 simulations.:  45%|████▌     | 4507/10000 [00:16<00:20, 267.61it/s]Running 10000 simulations.:  45%|████▌     | 4534/10000 [00:16<00:20, 266.79it/s]Running 10000 simulations.:  46%|████▌     | 4561/10000 [00:16<00:20, 267.40it/s]Running 10000 simulations.:  46%|████▌     | 4588/10000 [00:17<00:20, 267.67it/s]Running 10000 simulations.:  46%|████▌     | 4615/10000 [00:17<00:20, 267.98it/s]Running 10000 simulations.:  46%|████▋     | 4642/10000 [00:17<00:19, 268.00it/s]Running 10000 simulations.:  47%|████▋     | 4669/10000 [00:17<00:19, 268.02it/s]Running 10000 simulations.:  47%|████▋     | 4696/10000 [00:17<00:19, 267.87it/s]Running 10000 simulations.:  47%|████▋     | 4723/10000 [00:17<00:19, 267.82it/s]Running 10000 simulations.:  48%|████▊     | 4750/10000 [00:17<00:19, 268.30it/s]Running 10000 simulations.:  48%|████▊     | 4777/10000 [00:17<00:19, 267.92it/s]Running 10000 simulations.:  48%|████▊     | 4804/10000 [00:17<00:19, 263.43it/s]Running 10000 simulations.:  48%|████▊     | 4831/10000 [00:17<00:19, 263.60it/s]Running 10000 simulations.:  49%|████▊     | 4858/10000 [00:18<00:19, 265.33it/s]Running 10000 simulations.:  49%|████▉     | 4885/10000 [00:18<00:19, 266.64it/s]Running 10000 simulations.:  49%|████▉     | 4912/10000 [00:18<00:19, 267.35it/s]Running 10000 simulations.:  49%|████▉     | 4939/10000 [00:18<00:18, 267.68it/s]Running 10000 simulations.:  50%|████▉     | 4966/10000 [00:18<00:18, 267.65it/s]Running 10000 simulations.:  50%|████▉     | 4993/10000 [00:18<00:18, 267.77it/s]Running 10000 simulations.:  50%|█████     | 5020/10000 [00:18<00:18, 267.69it/s]Running 10000 simulations.:  50%|█████     | 5047/10000 [00:18<00:18, 266.87it/s]Running 10000 simulations.:  51%|█████     | 5074/10000 [00:18<00:18, 267.74it/s]Running 10000 simulations.:  51%|█████     | 5101/10000 [00:18<00:18, 267.70it/s]Running 10000 simulations.:  51%|█████▏    | 5128/10000 [00:19<00:18, 267.64it/s]Running 10000 simulations.:  52%|█████▏    | 5155/10000 [00:19<00:18, 267.40it/s]Running 10000 simulations.:  52%|█████▏    | 5182/10000 [00:19<00:18, 266.02it/s]Running 10000 simulations.:  52%|█████▏    | 5209/10000 [00:19<00:18, 265.21it/s]Running 10000 simulations.:  52%|█████▏    | 5236/10000 [00:19<00:17, 264.94it/s]Running 10000 simulations.:  53%|█████▎    | 5263/10000 [00:19<00:17, 264.71it/s]Running 10000 simulations.:  53%|█████▎    | 5290/10000 [00:19<00:17, 264.73it/s]Running 10000 simulations.:  53%|█████▎    | 5317/10000 [00:19<00:17, 264.94it/s]Running 10000 simulations.:  53%|█████▎    | 5344/10000 [00:19<00:17, 264.79it/s]Running 10000 simulations.:  54%|█████▎    | 5371/10000 [00:19<00:17, 264.78it/s]Running 10000 simulations.:  54%|█████▍    | 5398/10000 [00:20<00:17, 264.03it/s]Running 10000 simulations.:  54%|█████▍    | 5425/10000 [00:20<00:17, 264.29it/s]Running 10000 simulations.:  55%|█████▍    | 5452/10000 [00:20<00:17, 264.76it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:20<00:17, 264.82it/s]Running 10000 simulations.:  55%|█████▌    | 5506/10000 [00:20<00:16, 264.97it/s]Running 10000 simulations.:  55%|█████▌    | 5533/10000 [00:20<00:16, 264.47it/s]Running 10000 simulations.:  56%|█████▌    | 5560/10000 [00:20<00:16, 265.10it/s]Running 10000 simulations.:  56%|█████▌    | 5587/10000 [00:20<00:16, 264.78it/s]Running 10000 simulations.:  56%|█████▌    | 5614/10000 [00:20<00:16, 264.48it/s]Running 10000 simulations.:  56%|█████▋    | 5641/10000 [00:20<00:16, 264.90it/s]Running 10000 simulations.:  57%|█████▋    | 5668/10000 [00:21<00:16, 265.36it/s]Running 10000 simulations.:  57%|█████▋    | 5695/10000 [00:21<00:16, 265.21it/s]Running 10000 simulations.:  57%|█████▋    | 5722/10000 [00:21<00:16, 265.05it/s]Running 10000 simulations.:  57%|█████▋    | 5749/10000 [00:21<00:16, 265.10it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:21<00:15, 264.91it/s]Running 10000 simulations.:  58%|█████▊    | 5803/10000 [00:21<00:15, 264.56it/s]Running 10000 simulations.:  58%|█████▊    | 5830/10000 [00:21<00:15, 264.44it/s]Running 10000 simulations.:  59%|█████▊    | 5857/10000 [00:21<00:15, 264.42it/s]Running 10000 simulations.:  59%|█████▉    | 5884/10000 [00:21<00:15, 264.58it/s]Running 10000 simulations.:  59%|█████▉    | 5911/10000 [00:22<00:15, 263.11it/s]Running 10000 simulations.:  59%|█████▉    | 5938/10000 [00:22<00:15, 263.81it/s]Running 10000 simulations.:  60%|█████▉    | 5965/10000 [00:22<00:15, 264.57it/s]Running 10000 simulations.:  60%|█████▉    | 5992/10000 [00:22<00:15, 255.93it/s]Running 10000 simulations.:  60%|██████    | 6019/10000 [00:22<00:15, 258.47it/s]Running 10000 simulations.:  60%|██████    | 6046/10000 [00:22<00:15, 260.05it/s]Running 10000 simulations.:  61%|██████    | 6073/10000 [00:22<00:15, 261.41it/s]Running 10000 simulations.:  61%|██████    | 6100/10000 [00:22<00:14, 262.24it/s]Running 10000 simulations.:  61%|██████▏   | 6127/10000 [00:22<00:14, 263.18it/s]Running 10000 simulations.:  62%|██████▏   | 6154/10000 [00:22<00:14, 263.98it/s]Running 10000 simulations.:  62%|██████▏   | 6181/10000 [00:23<00:14, 264.43it/s]Running 10000 simulations.:  62%|██████▏   | 6208/10000 [00:23<00:14, 264.76it/s]Running 10000 simulations.:  62%|██████▏   | 6235/10000 [00:23<00:14, 265.33it/s]Running 10000 simulations.:  63%|██████▎   | 6262/10000 [00:23<00:14, 265.27it/s]Running 10000 simulations.:  63%|██████▎   | 6289/10000 [00:23<00:14, 259.40it/s]Running 10000 simulations.:  63%|██████▎   | 6316/10000 [00:23<00:14, 261.06it/s]Running 10000 simulations.:  63%|██████▎   | 6343/10000 [00:23<00:13, 261.38it/s]Running 10000 simulations.:  64%|██████▎   | 6370/10000 [00:23<00:13, 262.72it/s]Running 10000 simulations.:  64%|██████▍   | 6397/10000 [00:23<00:13, 263.21it/s]Running 10000 simulations.:  64%|██████▍   | 6424/10000 [00:23<00:13, 263.42it/s]Running 10000 simulations.:  65%|██████▍   | 6451/10000 [00:24<00:13, 264.17it/s]Running 10000 simulations.:  65%|██████▍   | 6478/10000 [00:24<00:13, 263.75it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:24<00:13, 263.82it/s]Running 10000 simulations.:  65%|██████▌   | 6532/10000 [00:24<00:13, 264.04it/s]Running 10000 simulations.:  66%|██████▌   | 6559/10000 [00:24<00:13, 264.13it/s]Running 10000 simulations.:  66%|██████▌   | 6586/10000 [00:24<00:12, 263.91it/s]Running 10000 simulations.:  66%|██████▌   | 6613/10000 [00:24<00:12, 264.53it/s]Running 10000 simulations.:  66%|██████▋   | 6640/10000 [00:24<00:12, 264.87it/s]Running 10000 simulations.:  67%|██████▋   | 6667/10000 [00:24<00:12, 265.18it/s]Running 10000 simulations.:  67%|██████▋   | 6694/10000 [00:24<00:12, 265.08it/s]Running 10000 simulations.:  67%|██████▋   | 6721/10000 [00:25<00:12, 266.11it/s]Running 10000 simulations.:  67%|██████▋   | 6748/10000 [00:25<00:12, 266.11it/s]Running 10000 simulations.:  68%|██████▊   | 6775/10000 [00:25<00:12, 265.44it/s]Running 10000 simulations.:  68%|██████▊   | 6802/10000 [00:25<00:12, 265.13it/s]Running 10000 simulations.:  68%|██████▊   | 6829/10000 [00:25<00:11, 264.62it/s]Running 10000 simulations.:  69%|██████▊   | 6856/10000 [00:25<00:11, 264.98it/s]Running 10000 simulations.:  69%|██████▉   | 6883/10000 [00:25<00:11, 265.40it/s]Running 10000 simulations.:  69%|██████▉   | 6910/10000 [00:25<00:11, 265.68it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:25<00:11, 265.59it/s]Running 10000 simulations.:  70%|██████▉   | 6964/10000 [00:26<00:11, 265.40it/s]Running 10000 simulations.:  70%|██████▉   | 6991/10000 [00:26<00:11, 265.50it/s]Running 10000 simulations.:  70%|███████   | 7018/10000 [00:26<00:11, 265.26it/s]Running 10000 simulations.:  70%|███████   | 7045/10000 [00:26<00:11, 264.64it/s]Running 10000 simulations.:  71%|███████   | 7072/10000 [00:26<00:11, 264.71it/s]Running 10000 simulations.:  71%|███████   | 7099/10000 [00:26<00:10, 265.18it/s]Running 10000 simulations.:  71%|███████▏  | 7126/10000 [00:26<00:10, 265.18it/s]Running 10000 simulations.:  72%|███████▏  | 7153/10000 [00:26<00:10, 265.12it/s]Running 10000 simulations.:  72%|███████▏  | 7180/10000 [00:26<00:10, 265.13it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:26<00:10, 265.16it/s]Running 10000 simulations.:  72%|███████▏  | 7234/10000 [00:27<00:10, 265.31it/s]Running 10000 simulations.:  73%|███████▎  | 7261/10000 [00:27<00:10, 265.23it/s]Running 10000 simulations.:  73%|███████▎  | 7288/10000 [00:27<00:10, 265.06it/s]Running 10000 simulations.:  73%|███████▎  | 7315/10000 [00:27<00:10, 264.77it/s]Running 10000 simulations.:  73%|███████▎  | 7342/10000 [00:27<00:10, 264.67it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:27<00:09, 264.72it/s]Running 10000 simulations.:  74%|███████▍  | 7396/10000 [00:27<00:09, 264.76it/s]Running 10000 simulations.:  74%|███████▍  | 7423/10000 [00:27<00:09, 265.03it/s]Running 10000 simulations.:  74%|███████▍  | 7450/10000 [00:27<00:09, 265.29it/s]Running 10000 simulations.:  75%|███████▍  | 7477/10000 [00:27<00:09, 265.38it/s]Running 10000 simulations.:  75%|███████▌  | 7504/10000 [00:28<00:09, 266.02it/s]Running 10000 simulations.:  75%|███████▌  | 7531/10000 [00:28<00:09, 265.82it/s]Running 10000 simulations.:  76%|███████▌  | 7558/10000 [00:28<00:09, 265.73it/s]Running 10000 simulations.:  76%|███████▌  | 7585/10000 [00:28<00:09, 265.43it/s]Running 10000 simulations.:  76%|███████▌  | 7612/10000 [00:28<00:08, 265.74it/s]Running 10000 simulations.:  76%|███████▋  | 7639/10000 [00:28<00:08, 265.44it/s]Running 10000 simulations.:  77%|███████▋  | 7666/10000 [00:28<00:08, 265.98it/s]Running 10000 simulations.:  77%|███████▋  | 7693/10000 [00:28<00:08, 266.17it/s]Running 10000 simulations.:  77%|███████▋  | 7720/10000 [00:28<00:08, 265.65it/s]Running 10000 simulations.:  77%|███████▋  | 7747/10000 [00:28<00:08, 265.26it/s]Running 10000 simulations.:  78%|███████▊  | 7774/10000 [00:29<00:08, 265.43it/s]Running 10000 simulations.:  78%|███████▊  | 7801/10000 [00:29<00:08, 265.31it/s]Running 10000 simulations.:  78%|███████▊  | 7828/10000 [00:29<00:08, 262.34it/s]Running 10000 simulations.:  79%|███████▊  | 7855/10000 [00:29<00:08, 260.24it/s]Running 10000 simulations.:  79%|███████▉  | 7882/10000 [00:29<00:08, 262.02it/s]Running 10000 simulations.:  79%|███████▉  | 7909/10000 [00:29<00:07, 262.82it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:29<00:07, 263.44it/s]Running 10000 simulations.:  80%|███████▉  | 7963/10000 [00:29<00:07, 264.30it/s]Running 10000 simulations.:  80%|███████▉  | 7990/10000 [00:29<00:07, 264.23it/s]Running 10000 simulations.:  80%|████████  | 8017/10000 [00:29<00:07, 264.79it/s]Running 10000 simulations.:  80%|████████  | 8044/10000 [00:30<00:07, 264.69it/s]Running 10000 simulations.:  81%|████████  | 8071/10000 [00:30<00:07, 264.76it/s]Running 10000 simulations.:  81%|████████  | 8098/10000 [00:30<00:07, 264.39it/s]Running 10000 simulations.:  81%|████████▏ | 8125/10000 [00:30<00:07, 264.76it/s]Running 10000 simulations.:  82%|████████▏ | 8152/10000 [00:30<00:06, 264.91it/s]Running 10000 simulations.:  82%|████████▏ | 8179/10000 [00:30<00:06, 265.16it/s]Running 10000 simulations.:  82%|████████▏ | 8206/10000 [00:30<00:06, 265.20it/s]Running 10000 simulations.:  82%|████████▏ | 8233/10000 [00:30<00:06, 265.11it/s]Running 10000 simulations.:  83%|████████▎ | 8260/10000 [00:30<00:06, 265.07it/s]Running 10000 simulations.:  83%|████████▎ | 8287/10000 [00:31<00:06, 264.63it/s]Running 10000 simulations.:  83%|████████▎ | 8314/10000 [00:31<00:06, 264.54it/s]Running 10000 simulations.:  83%|████████▎ | 8341/10000 [00:31<00:06, 264.54it/s]Running 10000 simulations.:  84%|████████▎ | 8368/10000 [00:31<00:06, 264.55it/s]Running 10000 simulations.:  84%|████████▍ | 8395/10000 [00:31<00:06, 264.90it/s]Running 10000 simulations.:  84%|████████▍ | 8422/10000 [00:31<00:05, 264.63it/s]Running 10000 simulations.:  84%|████████▍ | 8449/10000 [00:31<00:05, 264.94it/s]Running 10000 simulations.:  85%|████████▍ | 8476/10000 [00:31<00:05, 264.35it/s]Running 10000 simulations.:  85%|████████▌ | 8503/10000 [00:31<00:05, 263.87it/s]Running 10000 simulations.:  85%|████████▌ | 8530/10000 [00:31<00:05, 263.61it/s]Running 10000 simulations.:  86%|████████▌ | 8557/10000 [00:32<00:05, 263.05it/s]Running 10000 simulations.:  86%|████████▌ | 8584/10000 [00:32<00:05, 263.40it/s]Running 10000 simulations.:  86%|████████▌ | 8611/10000 [00:32<00:05, 263.67it/s]Running 10000 simulations.:  86%|████████▋ | 8638/10000 [00:32<00:05, 263.80it/s]Running 10000 simulations.:  87%|████████▋ | 8665/10000 [00:32<00:05, 263.03it/s]Running 10000 simulations.:  87%|████████▋ | 8692/10000 [00:32<00:04, 263.52it/s]Running 10000 simulations.:  87%|████████▋ | 8719/10000 [00:32<00:04, 264.33it/s]Running 10000 simulations.:  87%|████████▋ | 8746/10000 [00:32<00:04, 264.93it/s]Running 10000 simulations.:  88%|████████▊ | 8773/10000 [00:32<00:04, 264.98it/s]Running 10000 simulations.:  88%|████████▊ | 8800/10000 [00:32<00:04, 265.40it/s]Running 10000 simulations.:  88%|████████▊ | 8827/10000 [00:33<00:04, 265.26it/s]Running 10000 simulations.:  89%|████████▊ | 8854/10000 [00:33<00:04, 264.93it/s]Running 10000 simulations.:  89%|████████▉ | 8881/10000 [00:33<00:04, 265.67it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:33<00:04, 266.08it/s]Running 10000 simulations.:  89%|████████▉ | 8935/10000 [00:33<00:03, 266.30it/s]Running 10000 simulations.:  90%|████████▉ | 8962/10000 [00:33<00:03, 266.57it/s]Running 10000 simulations.:  90%|████████▉ | 8989/10000 [00:33<00:03, 266.55it/s]Running 10000 simulations.:  90%|█████████ | 9016/10000 [00:33<00:03, 266.02it/s]Running 10000 simulations.:  90%|█████████ | 9043/10000 [00:33<00:03, 264.45it/s]Running 10000 simulations.:  91%|█████████ | 9070/10000 [00:33<00:03, 259.93it/s]Running 10000 simulations.:  91%|█████████ | 9097/10000 [00:34<00:03, 261.69it/s]Running 10000 simulations.:  91%|█████████ | 9124/10000 [00:34<00:03, 263.01it/s]Running 10000 simulations.:  92%|█████████▏| 9151/10000 [00:34<00:03, 264.08it/s]Running 10000 simulations.:  92%|█████████▏| 9178/10000 [00:34<00:03, 264.78it/s]Running 10000 simulations.:  92%|█████████▏| 9205/10000 [00:34<00:03, 264.95it/s]Running 10000 simulations.:  92%|█████████▏| 9232/10000 [00:34<00:02, 265.37it/s]Running 10000 simulations.:  93%|█████████▎| 9259/10000 [00:34<00:02, 265.85it/s]Running 10000 simulations.:  93%|█████████▎| 9286/10000 [00:34<00:02, 266.32it/s]Running 10000 simulations.:  93%|█████████▎| 9313/10000 [00:34<00:02, 266.19it/s]Running 10000 simulations.:  93%|█████████▎| 9340/10000 [00:34<00:02, 265.58it/s]Running 10000 simulations.:  94%|█████████▎| 9367/10000 [00:35<00:02, 265.56it/s]Running 10000 simulations.:  94%|█████████▍| 9394/10000 [00:35<00:02, 265.74it/s]Running 10000 simulations.:  94%|█████████▍| 9421/10000 [00:35<00:02, 266.40it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [00:35<00:02, 266.86it/s]Running 10000 simulations.:  95%|█████████▍| 9475/10000 [00:35<00:01, 266.82it/s]Running 10000 simulations.:  95%|█████████▌| 9502/10000 [00:35<00:01, 267.10it/s]Running 10000 simulations.:  95%|█████████▌| 9529/10000 [00:35<00:01, 266.96it/s]Running 10000 simulations.:  96%|█████████▌| 9556/10000 [00:35<00:01, 267.01it/s]Running 10000 simulations.:  96%|█████████▌| 9583/10000 [00:35<00:01, 266.74it/s]Running 10000 simulations.:  96%|█████████▌| 9610/10000 [00:36<00:01, 267.02it/s]Running 10000 simulations.:  96%|█████████▋| 9637/10000 [00:36<00:01, 266.57it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [00:36<00:01, 267.11it/s]Running 10000 simulations.:  97%|█████████▋| 9691/10000 [00:36<00:01, 266.70it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [00:36<00:01, 267.48it/s]Running 10000 simulations.:  97%|█████████▋| 9745/10000 [00:36<00:00, 267.60it/s]Running 10000 simulations.:  98%|█████████▊| 9772/10000 [00:36<00:00, 267.42it/s]Running 10000 simulations.:  98%|█████████▊| 9799/10000 [00:36<00:00, 267.41it/s]Running 10000 simulations.:  98%|█████████▊| 9826/10000 [00:36<00:00, 267.08it/s]Running 10000 simulations.:  99%|█████████▊| 9853/10000 [00:36<00:00, 267.66it/s]Running 10000 simulations.:  99%|█████████▉| 9880/10000 [00:37<00:00, 266.99it/s]Running 10000 simulations.:  99%|█████████▉| 9908/10000 [00:37<00:00, 267.95it/s]Running 10000 simulations.:  99%|█████████▉| 9935/10000 [00:37<00:00, 268.34it/s]Running 10000 simulations.: 100%|█████████▉| 9962/10000 [00:37<00:00, 268.14it/s]Running 10000 simulations.: 100%|█████████▉| 9989/10000 [00:37<00:00, 267.95it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:37<00:00, 266.97it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55022it [00:00, 498532.12it/s]           Drawing 50000 posterior samples: 55022it [00:00, 496319.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54967it [00:00, 543326.98it/s]           Drawing 50000 posterior samples: 54967it [00:00, 541028.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55009it [00:00, 565661.97it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55040it [00:00, 477324.17it/s]           Drawing 50000 posterior samples: 55040it [00:00, 474668.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50123it [00:00, 450317.34it/s]           Drawing 50000 posterior samples: 50123it [00:00, 448026.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55029it [00:00, 490327.34it/s]           Drawing 50000 posterior samples: 55029it [00:00, 487723.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54975it [00:00, 539387.92it/s]           Drawing 50000 posterior samples: 54975it [00:00, 536924.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54977it [00:00, 541324.71it/s]           Drawing 50000 posterior samples: 54977it [00:00, 538676.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55102it [00:00, 551990.45it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55076it [00:00, 513200.69it/s]           Drawing 50000 posterior samples: 55076it [00:00, 510787.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55092it [00:00, 527207.92it/s]           Drawing 50000 posterior samples: 55092it [00:00, 524595.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55027it [00:00, 525040.59it/s]           Drawing 50000 posterior samples: 55027it [00:00, 522758.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54952it [00:00, 548077.90it/s]           Drawing 50000 posterior samples: 54952it [00:00, 545827.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55025it [00:00, 488327.90it/s]           Drawing 50000 posterior samples: 55025it [00:00, 484594.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54953it [00:00, 527328.73it/s]           Drawing 50000 posterior samples: 54953it [00:00, 524412.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54906it [00:00, 548479.91it/s]           Drawing 50000 posterior samples: 54906it [00:00, 545412.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55113it [00:00, 539965.09it/s]           Drawing 50000 posterior samples: 55113it [00:00, 536767.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55019it [00:00, 534017.10it/s]           Drawing 50000 posterior samples: 55019it [00:00, 531691.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55010it [00:00, 527358.10it/s]           Drawing 50000 posterior samples: 55010it [00:00, 524541.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54945it [00:00, 523343.85it/s]           Drawing 50000 posterior samples: 54945it [00:00, 521033.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55069it [00:00, 529833.46it/s]           Drawing 50000 posterior samples: 55069it [00:00, 527455.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55088it [00:00, 516535.93it/s]           Drawing 50000 posterior samples: 55088it [00:00, 513967.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54946it [00:00, 529755.87it/s]           Drawing 50000 posterior samples: 54946it [00:00, 527174.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55019it [00:00, 548361.48it/s]           Drawing 50000 posterior samples: 55019it [00:00, 545903.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55019it [00:00, 571687.94it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55031it [00:00, 555399.33it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55030it [00:00, 559802.06it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55002it [00:00, 555478.23it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55097it [00:00, 579131.07it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55073it [00:00, 571231.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609587.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59946it [00:00, 614660.38it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614051.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59991it [00:00, 601028.28it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59070it [00:00, 595530.92it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53002it [00:00, 533527.49it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597172.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612625.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608522.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 605189.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57881it [00:00, 593164.85it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612928.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615009.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603771.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59997it [00:00, 606056.71it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58580it [00:00, 592347.84it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601665.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 604154.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58145it [00:00, 582852.69it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 599054.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 607275.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615956.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601920.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597218.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603813.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 599037.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595976.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 610574.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 607997.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55865it [00:00, 482363.44it/s]           Drawing 50000 posterior samples: 55865it [00:00, 480339.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612196.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59983it [00:00, 604904.25it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614427.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602690.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54089it [00:00, 534562.63it/s]           Drawing 50000 posterior samples: 54089it [00:00, 532212.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56290it [00:00, 562117.86it/s]           Drawing 50000 posterior samples: 56290it [00:00, 559227.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601390.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598753.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 604906.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 600043.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59996it [00:00, 608279.22it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609722.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 605514.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603186.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 610750.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59710it [00:00, 599507.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 597782.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601420.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59899it [00:00, 611034.10it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602252.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 605509.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609196.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 599923.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591800.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 586911.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 599877.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603371.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 585819.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 569216.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52670it [00:00, 502371.83it/s]           Drawing 50000 posterior samples: 52670it [00:00, 499912.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 536734.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59692it [00:00, 566514.15it/s]           Drawing 50000 posterior samples: 59692it [00:00, 562653.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 584704.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 605903.27it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51846it [00:00, 525473.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53420it [00:00, 546389.84it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612176.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 596707.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 600777.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 600803.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59972it [00:00, 613948.40it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618921.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 599602.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602237.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 592099.30it/s]           Drawing 50000 posterior samples: 59999it [00:00, 589555.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58912it [00:00, 604578.44it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 613846.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 604772.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57713it [00:00, 597838.16it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612478.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611095.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609318.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 577087.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608621.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 613188.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 603444.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608582.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595566.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 608245.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55048it [00:00, 479191.84it/s]           Drawing 50000 posterior samples: 55048it [00:00, 477471.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 595516.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59340it [00:00, 605085.94it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611992.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602997.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  84%|████████▍ | 42031/50000 [00:00<00:00, 417626.99it/s]Drawing 50000 posterior samples: 55978it [00:00, 418884.14it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53467it [00:00, 540555.10it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 610729.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614305.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 585574.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612287.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59622it [00:00, 598668.45it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601052.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 600775.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602143.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612194.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57615it [00:00, 585580.03it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59913it [00:00, 594001.06it/s]           Drawing 50000 posterior samples: 59913it [00:00, 591286.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 613344.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59108it [00:00, 599193.53it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 610201.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 605490.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 594889.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 591385.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 598063.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614218.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 586369.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 580704.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 561187.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 564735.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52882it [00:00, 501704.79it/s]           Drawing 50000 posterior samples: 52882it [00:00, 499485.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54993it [00:00, 559132.76it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54934it [00:00, 564618.04it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54967it [00:00, 543298.81it/s]           Drawing 50000 posterior samples: 54967it [00:00, 540695.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55017it [00:00, 525917.84it/s]           Drawing 50000 posterior samples: 55017it [00:00, 522568.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  99%|█████████▊| 49290/50000 [00:00<00:00, 472993.10it/s]Drawing 50000 posterior samples: 57467it [00:00, 470091.15it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55090it [00:00, 536489.01it/s]           Drawing 50000 posterior samples: 55090it [00:00, 534238.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54952it [00:00, 527659.57it/s]           Drawing 50000 posterior samples: 54952it [00:00, 525284.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54975it [00:00, 532829.26it/s]           Drawing 50000 posterior samples: 54975it [00:00, 530409.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55009it [00:00, 557920.00it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55041it [00:00, 547206.32it/s]           Drawing 50000 posterior samples: 55041it [00:00, 544695.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54974it [00:00, 520713.51it/s]           Drawing 50000 posterior samples: 54974it [00:00, 518393.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54981it [00:00, 531244.88it/s]           Drawing 50000 posterior samples: 54981it [00:00, 528855.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55049it [00:00, 525689.39it/s]           Drawing 50000 posterior samples: 55049it [00:00, 523320.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54908it [00:00, 528910.48it/s]           Drawing 50000 posterior samples: 54908it [00:00, 526771.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54967it [00:00, 536649.33it/s]           Drawing 50000 posterior samples: 54967it [00:00, 534191.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54937it [00:00, 565273.60it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55029it [00:00, 558001.41it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55063it [00:00, 564695.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54954it [00:00, 541382.93it/s]           Drawing 50000 posterior samples: 54954it [00:00, 538612.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54942it [00:00, 530353.69it/s]           Drawing 50000 posterior samples: 54942it [00:00, 527969.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54933it [00:00, 537428.25it/s]           Drawing 50000 posterior samples: 54933it [00:00, 534992.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55017it [00:00, 524351.14it/s]           Drawing 50000 posterior samples: 55017it [00:00, 521742.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54987it [00:00, 543136.83it/s]           Drawing 50000 posterior samples: 54987it [00:00, 540901.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54936it [00:00, 569397.99it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54925it [00:00, 568366.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54906it [00:00, 572011.63it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54852it [00:00, 564230.13it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54993it [00:00, 575924.93it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55005it [00:00, 572741.42it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55020it [00:00, 570353.19it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 613003.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59997it [00:00, 619763.46it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615500.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59962it [00:00, 606171.79it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55970it [00:00, 562813.63it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57589it [00:00, 583274.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 609759.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602837.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612071.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 610457.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59850it [00:00, 612564.90it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 592997.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601711.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611464.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59954it [00:00, 606495.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59371it [00:00, 598086.81it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 602046.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629423.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56686it [00:00, 588602.47it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623426.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616348.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618552.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 601299.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612469.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618554.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615305.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614928.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633760.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622073.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50889it [00:00, 452515.64it/s]           Drawing 50000 posterior samples: 50889it [00:00, 451307.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54967it [00:00, 568771.98it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51775it [00:00, 545322.82it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54929it [00:00, 576491.15it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54923it [00:00, 560731.79it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53620it [00:00, 566141.50it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54757it [00:00, 570286.53it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54829it [00:00, 569031.41it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54943it [00:00, 577513.81it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54866it [00:00, 566816.55it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54767it [00:00, 567517.32it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54919it [00:00, 567596.16it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55010it [00:00, 575581.28it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54941it [00:00, 565514.54it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54869it [00:00, 575564.76it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54858it [00:00, 569938.79it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54859it [00:00, 571069.50it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54560it [00:00, 567140.59it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54913it [00:00, 576871.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54865it [00:00, 567689.92it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54855it [00:00, 556434.78it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54947it [00:00, 574228.77it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54828it [00:00, 575834.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55060it [00:00, 568592.46it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54810it [00:00, 561087.28it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54934it [00:00, 568685.85it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54957it [00:00, 577462.70it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54867it [00:00, 567926.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54867it [00:00, 562765.49it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54833it [00:00, 564210.42it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54803it [00:00, 571361.49it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616325.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59998it [00:00, 621680.01it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633607.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611006.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56862it [00:00, 598302.44it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53522it [00:00, 555131.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620029.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617779.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622499.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623968.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59937it [00:00, 617540.63it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620596.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627996.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616865.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627463.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59512it [00:00, 617652.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616780.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 625233.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59949it [00:00, 629727.02it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 619149.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 611254.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620444.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623801.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623959.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622557.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629803.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 615390.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622376.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632984.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52795it [00:00, 551745.97it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 637447.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59997it [00:00, 620186.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624622.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59997it [00:00, 614801.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|█████████▉| 49982/50000 [00:00<00:00, 442541.14it/s]Drawing 50000 posterior samples: 57102it [00:00, 440613.85it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53713it [00:00, 547862.31it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616833.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618264.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614681.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 613641.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59839it [00:00, 620859.21it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621282.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632827.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623575.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623202.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57438it [00:00, 591154.09it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621249.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620600.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58902it [00:00, 620081.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620736.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628292.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629922.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 619132.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630025.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620977.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623099.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629306.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 612310.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628782.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54008it [00:00, 473569.83it/s]           Drawing 50000 posterior samples: 54008it [00:00, 472115.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
30
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Neural network successfully converged after 232 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Neural network successfully converged after 277 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Neural network successfully converged after 350 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Neural network successfully converged after 241 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Neural network successfully converged after 193 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Neural network successfully converged after 328 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Training neural network. Epochs trained:  372Training neural network. Epochs trained:  373Training neural network. Epochs trained:  374Training neural network. Epochs trained:  375Training neural network. Epochs trained:  376Training neural network. Epochs trained:  377Training neural network. Epochs trained:  378Training neural network. Epochs trained:  379Training neural network. Epochs trained:  380Training neural network. Epochs trained:  381Training neural network. Epochs trained:  382Training neural network. Epochs trained:  383Training neural network. Epochs trained:  384Training neural network. Epochs trained:  385Training neural network. Epochs trained:  386Training neural network. Epochs trained:  387Training neural network. Epochs trained:  388Training neural network. Epochs trained:  389Training neural network. Epochs trained:  390Training neural network. Epochs trained:  391Training neural network. Epochs trained:  392Training neural network. Epochs trained:  393Training neural network. Epochs trained:  394Training neural network. Epochs trained:  395Training neural network. Epochs trained:  396Training neural network. Epochs trained:  397Training neural network. Epochs trained:  398Training neural network. Epochs trained:  399Training neural network. Epochs trained:  400Training neural network. Epochs trained:  401Training neural network. Epochs trained:  402Training neural network. Epochs trained:  403Training neural network. Epochs trained:  404Training neural network. Epochs trained:  405Training neural network. Epochs trained:  406Training neural network. Epochs trained:  407Training neural network. Epochs trained:  408Training neural network. Epochs trained:  409Training neural network. Epochs trained:  410Training neural network. Epochs trained:  411Training neural network. Epochs trained:  412Training neural network. Epochs trained:  413Training neural network. Epochs trained:  414Training neural network. Epochs trained:  415Training neural network. Epochs trained:  416Training neural network. Epochs trained:  417Training neural network. Epochs trained:  418Training neural network. Epochs trained:  419Training neural network. Epochs trained:  420Training neural network. Epochs trained:  421Training neural network. Epochs trained:  422Training neural network. Epochs trained:  423Training neural network. Epochs trained:  424Training neural network. Epochs trained:  425Neural network successfully converged after 425 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Neural network successfully converged after 340 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Neural network successfully converged after 348 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Neural network successfully converged after 316 epochs.
log prob true 4.3190427
log prob true 4.0544057
log prob true 4.355808
log prob true 3.0980966
log prob true 3.3404157
log prob true 3.0681033
log prob true 3.6532726
log prob true 4.4209795
log prob true 3.9943554
log prob true 3.6020174
log prob true 3.1592023
log prob true 4.2165666
log prob true 4.4355636
log prob true 3.8213725
log prob true 3.6035554
log prob true 3.2885566
log prob true 3.8702066
log prob true 4.22427
log prob true 3.3390636
log prob true 4.318612
log prob true 4.0431547
log prob true 3.7665706
log prob true 4.4850063
log prob true 3.9260414
log prob true 4.4525046
log prob true 4.0901003
log prob true 3.3018823
log prob true 3.7960715
log prob true 4.354685
log prob true 3.0001023
log prob true 7.23194
log prob true 6.8653207
log prob true 7.085119
log prob true 6.608395
log prob true 6.1975455
log prob true 6.445865
log prob true 6.6162686
log prob true 7.131931
log prob true 6.7491584
log prob true 6.9639087
log prob true 6.3041883
log prob true 7.07701
log prob true 7.5317254
log prob true 7.0415215
log prob true 6.5319653
log prob true 6.343996
log prob true 6.6344876
log prob true 6.908789
log prob true 6.468379
log prob true 7.2031703
log prob true 7.1397667
log prob true 6.8207674
log prob true 7.031714
log prob true 6.7431684
log prob true 6.5054483
log prob true 6.918465
log prob true 6.2996335
log prob true 6.6589937
log prob true 6.9350734
log prob true 6.697933
log prob true 7.507573
log prob true 7.006101
log prob true 7.408487
log prob true 7.068738
log prob true 6.8447623
log prob true 6.770508
log prob true 6.8783717
log prob true 7.3006797
log prob true 7.045971
log prob true 7.0441628
log prob true 6.862983
log prob true 7.286119
log prob true 7.7399263
log prob true 7.267042
log prob true 6.7942524
log prob true 6.5361767
log prob true 6.8079667
log prob true 6.91135
log prob true 6.785764
log prob true 7.4345326
log prob true 7.48514
log prob true 7.0770454
log prob true 7.4121046
log prob true 6.8883724
log prob true 7.4481597
log prob true 7.160198
log prob true 6.394029
log prob true 6.837191
log prob true 7.3015165
log prob true 6.8620114
log prob true 7.360449
log prob true 6.8869267
log prob true 7.242489
log prob true 6.7351394
log prob true 6.231858
log prob true 6.748397
log prob true 6.6171584
log prob true 7.114079
log prob true 6.697693
log prob true 7.0294514
log prob true 6.805871
log prob true 7.078146
log prob true 7.447011
log prob true 6.838905
log prob true 6.527522
log prob true 6.4688916
log prob true 6.7480016
log prob true 6.9634013
log prob true 6.636364
log prob true 7.2211213
log prob true 6.9517922
log prob true 6.9096484
log prob true 7.363717
log prob true 6.7179313
log prob true 7.263631
log prob true 6.9707775
log prob true 6.2403345
log prob true 6.7012005
log prob true 6.9869413
log prob true 6.731559
log prob true 7.0551543
log prob true 6.479796
log prob true 6.7954283
log prob true 6.491416
log prob true 6.5063243
log prob true 6.408283
log prob true 6.5287795
log prob true 6.7726207
log prob true 6.573395
log prob true 6.666671
log prob true 6.374064
log prob true 6.665295
log prob true 7.1396546
log prob true 6.8260474
log prob true 6.272517
log prob true 6.050351
log prob true 6.2431
log prob true 6.691966
log prob true 6.292795
log prob true 7.0052834
log prob true 6.938665
log prob true 6.6793942
log prob true 6.882594
log prob true 6.311177
log prob true 6.860357
log prob true 6.8353076
log prob true 5.7416353
log prob true 6.2953362
log prob true 6.881673
log prob true 6.092125
log prob true 4.4601135
log prob true 3.8190813
log prob true 4.3200946
log prob true 3.3350427
log prob true 3.6940203
log prob true 3.0500298
log prob true 3.6866994
log prob true 4.2538157
log prob true 3.9125206
log prob true 3.6843889
log prob true 3.153159
log prob true 4.2042665
log prob true 4.2537417
log prob true 4.0826283
log prob true 3.556248
log prob true 3.1912708
log prob true 3.9590883
log prob true 4.2371993
log prob true 3.3568907
log prob true 4.270253
log prob true 3.9521394
log prob true 3.615722
log prob true 4.5544267
log prob true 3.9086192
log prob true 4.385831
log prob true 4.0521083
log prob true 3.2935777
log prob true 3.6498542
log prob true 4.2451563
log prob true 3.0881214
log prob true 7.149326
log prob true 6.709027
log prob true 6.822931
log prob true 6.5242734
log prob true 6.1795387
log prob true 6.2430673
log prob true 6.539173
log prob true 7.001363
log prob true 6.5526953
log prob true 6.646495
log prob true 6.609356
log prob true 6.945199
log prob true 7.0223637
log prob true 6.899631
log prob true 6.2925534
log prob true 6.2438645
log prob true 6.565075
log prob true 6.750737
log prob true 6.305069
log prob true 7.0801
log prob true 6.8313036
log prob true 6.560691
log prob true 6.93301
log prob true 6.5415487
log prob true 6.951069
log prob true 6.7588387
log prob true 6.27099
log prob true 6.5436897
log prob true 6.6531286
log prob true 6.667438
log prob true 4.185958
log prob true 3.6663196
log prob true 4.114001
log prob true 2.8589365
log prob true 3.2181258
log prob true 2.6907089
log prob true 2.8767512
log prob true 4.0186954
log prob true 3.6293015
log prob true 3.696004
log prob true 3.131777
log prob true 3.7937992
log prob true 4.514065
log prob true 3.853258
log prob true 3.2315307
log prob true 2.9292953
log prob true 3.6439931
log prob true 3.9236293
log prob true 2.8921165
log prob true 4.022285
log prob true 3.6590726
log prob true 3.8679774
log prob true 4.1715474
log prob true 3.5566888
log prob true 4.164166
log prob true 3.8133028
log prob true 2.9028258
log prob true 3.4178994
log prob true 3.7533853
log prob true 1.9213086
log prob true 7.51482
log prob true 6.918764
log prob true 7.3474154
log prob true 7.063238
log prob true 6.596264
log prob true 6.9344735
log prob true 6.876965
log prob true 7.3155327
log prob true 6.9996343
log prob true 7.2348742
log prob true 6.939599
log prob true 7.278424
log prob true 7.8228006
log prob true 7.293271
log prob true 6.8926477
log prob true 6.568105
log prob true 6.9257326
log prob true 7.203106
log prob true 6.7679486
log prob true 7.3759446
log prob true 7.446856
log prob true 7.249918
log prob true 7.47374
log prob true 6.9982615
log prob true 7.3384504
log prob true 7.1547313
log prob true 6.5797043
log prob true 6.8435874
log prob true 7.3892183
log prob true 6.8487754
log prob true 7.5193615
log prob true 7.044343
log prob true 7.1087847
log prob true 6.930137
log prob true 6.786285
log prob true 6.6455884
log prob true 6.6569424
log prob true 7.1884637
log prob true 6.725928
log prob true 6.9479485
log prob true 6.715533
log prob true 7.1954412
log prob true 7.484128
log prob true 7.091673
log prob true 6.6597853
log prob true 6.443673
log prob true 6.772786
log prob true 6.9837794
log prob true 6.5589557
log prob true 7.165892
log prob true 7.222085
log prob true 6.96303
log prob true 7.3314767
log prob true 6.857296
log prob true 7.140933
log prob true 6.953163
log prob true 6.4835963
log prob true 6.756342
log prob true 7.1146846
log prob true 6.7009773
script complete
