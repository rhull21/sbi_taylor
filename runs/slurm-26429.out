Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 29/10000 [00:00<00:35, 284.38it/s]Running 10000 simulations.:   1%|          | 58/10000 [00:00<00:34, 285.57it/s]Running 10000 simulations.:   1%|          | 87/10000 [00:00<00:34, 285.86it/s]Running 10000 simulations.:   1%|          | 116/10000 [00:00<00:34, 284.57it/s]Running 10000 simulations.:   1%|▏         | 145/10000 [00:00<00:34, 284.40it/s]Running 10000 simulations.:   2%|▏         | 174/10000 [00:00<00:34, 283.98it/s]Running 10000 simulations.:   2%|▏         | 203/10000 [00:00<00:34, 284.19it/s]Running 10000 simulations.:   2%|▏         | 232/10000 [00:00<00:34, 283.60it/s]Running 10000 simulations.:   3%|▎         | 261/10000 [00:00<00:34, 283.35it/s]Running 10000 simulations.:   3%|▎         | 290/10000 [00:01<00:34, 283.07it/s]Running 10000 simulations.:   3%|▎         | 319/10000 [00:01<00:34, 283.14it/s]Running 10000 simulations.:   3%|▎         | 348/10000 [00:01<00:34, 283.48it/s]Running 10000 simulations.:   4%|▍         | 377/10000 [00:01<00:34, 282.98it/s]Running 10000 simulations.:   4%|▍         | 406/10000 [00:01<00:33, 282.85it/s]Running 10000 simulations.:   4%|▍         | 435/10000 [00:01<00:33, 282.75it/s]Running 10000 simulations.:   5%|▍         | 464/10000 [00:01<00:33, 283.17it/s]Running 10000 simulations.:   5%|▍         | 493/10000 [00:01<00:33, 283.31it/s]Running 10000 simulations.:   5%|▌         | 522/10000 [00:01<00:34, 277.70it/s]Running 10000 simulations.:   6%|▌         | 551/10000 [00:01<00:33, 279.55it/s]Running 10000 simulations.:   6%|▌         | 580/10000 [00:02<00:33, 281.07it/s]Running 10000 simulations.:   6%|▌         | 609/10000 [00:02<00:33, 282.89it/s]Running 10000 simulations.:   6%|▋         | 638/10000 [00:02<00:32, 284.14it/s]Running 10000 simulations.:   7%|▋         | 667/10000 [00:02<00:32, 284.07it/s]Running 10000 simulations.:   7%|▋         | 696/10000 [00:02<00:32, 284.26it/s]Running 10000 simulations.:   7%|▋         | 725/10000 [00:02<00:32, 283.76it/s]Running 10000 simulations.:   8%|▊         | 754/10000 [00:02<00:32, 283.67it/s]Running 10000 simulations.:   8%|▊         | 783/10000 [00:02<00:32, 283.13it/s]Running 10000 simulations.:   8%|▊         | 812/10000 [00:02<00:32, 283.04it/s]Running 10000 simulations.:   8%|▊         | 841/10000 [00:02<00:32, 281.87it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:03<00:32, 282.92it/s]Running 10000 simulations.:   9%|▉         | 899/10000 [00:03<00:31, 284.59it/s]Running 10000 simulations.:   9%|▉         | 928/10000 [00:03<00:31, 284.10it/s]Running 10000 simulations.:  10%|▉         | 957/10000 [00:03<00:31, 283.70it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:03<00:31, 283.98it/s]Running 10000 simulations.:  10%|█         | 1015/10000 [00:03<00:31, 283.64it/s]Running 10000 simulations.:  10%|█         | 1044/10000 [00:03<00:31, 283.01it/s]Running 10000 simulations.:  11%|█         | 1073/10000 [00:03<00:31, 282.84it/s]Running 10000 simulations.:  11%|█         | 1102/10000 [00:03<00:31, 282.96it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:03<00:31, 284.64it/s]Running 10000 simulations.:  12%|█▏        | 1160/10000 [00:04<00:30, 285.42it/s]Running 10000 simulations.:  12%|█▏        | 1189/10000 [00:04<00:30, 285.89it/s]Running 10000 simulations.:  12%|█▏        | 1218/10000 [00:04<00:30, 286.21it/s]Running 10000 simulations.:  12%|█▏        | 1247/10000 [00:04<00:30, 285.55it/s]Running 10000 simulations.:  13%|█▎        | 1276/10000 [00:04<00:30, 286.36it/s]Running 10000 simulations.:  13%|█▎        | 1305/10000 [00:04<00:30, 286.18it/s]Running 10000 simulations.:  13%|█▎        | 1334/10000 [00:04<00:30, 285.82it/s]Running 10000 simulations.:  14%|█▎        | 1363/10000 [00:04<00:30, 285.70it/s]Running 10000 simulations.:  14%|█▍        | 1392/10000 [00:04<00:30, 285.51it/s]Running 10000 simulations.:  14%|█▍        | 1421/10000 [00:05<00:30, 283.20it/s]Running 10000 simulations.:  14%|█▍        | 1450/10000 [00:05<00:30, 282.97it/s]Running 10000 simulations.:  15%|█▍        | 1479/10000 [00:05<00:30, 282.65it/s]Running 10000 simulations.:  15%|█▌        | 1508/10000 [00:05<00:30, 282.52it/s]Running 10000 simulations.:  15%|█▌        | 1537/10000 [00:05<00:29, 282.10it/s]Running 10000 simulations.:  16%|█▌        | 1566/10000 [00:05<00:29, 282.44it/s]Running 10000 simulations.:  16%|█▌        | 1595/10000 [00:05<00:29, 282.27it/s]Running 10000 simulations.:  16%|█▌        | 1624/10000 [00:05<00:29, 282.47it/s]Running 10000 simulations.:  17%|█▋        | 1653/10000 [00:05<00:29, 283.90it/s]Running 10000 simulations.:  17%|█▋        | 1682/10000 [00:05<00:29, 284.62it/s]Running 10000 simulations.:  17%|█▋        | 1711/10000 [00:06<00:29, 283.93it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:06<00:29, 283.43it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:06<00:29, 283.41it/s]Running 10000 simulations.:  18%|█▊        | 1798/10000 [00:06<00:28, 284.17it/s]Running 10000 simulations.:  18%|█▊        | 1827/10000 [00:06<00:28, 284.88it/s]Running 10000 simulations.:  19%|█▊        | 1856/10000 [00:06<00:28, 285.60it/s]Running 10000 simulations.:  19%|█▉        | 1885/10000 [00:06<00:28, 286.74it/s]Running 10000 simulations.:  19%|█▉        | 1914/10000 [00:06<00:28, 287.55it/s]Running 10000 simulations.:  19%|█▉        | 1943/10000 [00:06<00:27, 287.95it/s]Running 10000 simulations.:  20%|█▉        | 1972/10000 [00:06<00:27, 286.89it/s]Running 10000 simulations.:  20%|██        | 2001/10000 [00:07<00:27, 285.92it/s]Running 10000 simulations.:  20%|██        | 2030/10000 [00:07<00:27, 284.89it/s]Running 10000 simulations.:  21%|██        | 2059/10000 [00:07<00:27, 284.20it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:07<00:27, 283.97it/s]Running 10000 simulations.:  21%|██        | 2117/10000 [00:07<00:27, 283.73it/s]Running 10000 simulations.:  21%|██▏       | 2146/10000 [00:07<00:27, 283.43it/s]Running 10000 simulations.:  22%|██▏       | 2175/10000 [00:07<00:27, 282.83it/s]Running 10000 simulations.:  22%|██▏       | 2204/10000 [00:07<00:27, 283.41it/s]Running 10000 simulations.:  22%|██▏       | 2233/10000 [00:07<00:27, 285.27it/s]Running 10000 simulations.:  23%|██▎       | 2262/10000 [00:07<00:27, 284.54it/s]Running 10000 simulations.:  23%|██▎       | 2291/10000 [00:08<00:27, 284.20it/s]Running 10000 simulations.:  23%|██▎       | 2320/10000 [00:08<00:27, 283.50it/s]Running 10000 simulations.:  23%|██▎       | 2349/10000 [00:08<00:26, 284.27it/s]Running 10000 simulations.:  24%|██▍       | 2378/10000 [00:08<00:26, 285.69it/s]Running 10000 simulations.:  24%|██▍       | 2407/10000 [00:08<00:26, 286.67it/s]Running 10000 simulations.:  24%|██▍       | 2436/10000 [00:08<00:26, 287.08it/s]Running 10000 simulations.:  25%|██▍       | 2465/10000 [00:08<00:26, 287.57it/s]Running 10000 simulations.:  25%|██▍       | 2494/10000 [00:08<00:26, 287.85it/s]Running 10000 simulations.:  25%|██▌       | 2523/10000 [00:08<00:26, 286.47it/s]Running 10000 simulations.:  26%|██▌       | 2552/10000 [00:08<00:26, 285.64it/s]Running 10000 simulations.:  26%|██▌       | 2581/10000 [00:09<00:26, 285.12it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:09<00:26, 284.20it/s]Running 10000 simulations.:  26%|██▋       | 2639/10000 [00:09<00:25, 284.49it/s]Running 10000 simulations.:  27%|██▋       | 2668/10000 [00:09<00:25, 284.87it/s]Running 10000 simulations.:  27%|██▋       | 2697/10000 [00:09<00:25, 284.24it/s]Running 10000 simulations.:  27%|██▋       | 2726/10000 [00:09<00:25, 283.76it/s]Running 10000 simulations.:  28%|██▊       | 2755/10000 [00:09<00:25, 283.11it/s]Running 10000 simulations.:  28%|██▊       | 2784/10000 [00:09<00:25, 283.95it/s]Running 10000 simulations.:  28%|██▊       | 2813/10000 [00:09<00:25, 284.69it/s]Running 10000 simulations.:  28%|██▊       | 2842/10000 [00:10<00:25, 284.59it/s]Running 10000 simulations.:  29%|██▊       | 2871/10000 [00:10<00:25, 283.97it/s]Running 10000 simulations.:  29%|██▉       | 2900/10000 [00:10<00:25, 283.52it/s]Running 10000 simulations.:  29%|██▉       | 2929/10000 [00:10<00:24, 283.08it/s]Running 10000 simulations.:  30%|██▉       | 2958/10000 [00:10<00:24, 283.32it/s]Running 10000 simulations.:  30%|██▉       | 2987/10000 [00:10<00:24, 282.87it/s]Running 10000 simulations.:  30%|███       | 3016/10000 [00:10<00:24, 282.77it/s]Running 10000 simulations.:  30%|███       | 3045/10000 [00:10<00:24, 283.11it/s]Running 10000 simulations.:  31%|███       | 3074/10000 [00:10<00:24, 283.07it/s]Running 10000 simulations.:  31%|███       | 3103/10000 [00:10<00:24, 283.40it/s]Running 10000 simulations.:  31%|███▏      | 3132/10000 [00:11<00:24, 283.30it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:11<00:24, 283.72it/s]Running 10000 simulations.:  32%|███▏      | 3190/10000 [00:11<00:23, 283.88it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:11<00:23, 283.81it/s]Running 10000 simulations.:  32%|███▏      | 3248/10000 [00:11<00:23, 283.26it/s]Running 10000 simulations.:  33%|███▎      | 3277/10000 [00:11<00:23, 283.15it/s]Running 10000 simulations.:  33%|███▎      | 3306/10000 [00:11<00:23, 283.17it/s]Running 10000 simulations.:  33%|███▎      | 3335/10000 [00:11<00:23, 283.54it/s]Running 10000 simulations.:  34%|███▎      | 3364/10000 [00:11<00:23, 283.12it/s]Running 10000 simulations.:  34%|███▍      | 3393/10000 [00:11<00:23, 283.09it/s]Running 10000 simulations.:  34%|███▍      | 3422/10000 [00:12<00:23, 283.29it/s]Running 10000 simulations.:  35%|███▍      | 3451/10000 [00:12<00:23, 283.39it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:12<00:23, 282.88it/s]Running 10000 simulations.:  35%|███▌      | 3509/10000 [00:12<00:22, 282.78it/s]Running 10000 simulations.:  35%|███▌      | 3538/10000 [00:12<00:22, 282.72it/s]Running 10000 simulations.:  36%|███▌      | 3567/10000 [00:12<00:22, 282.51it/s]Running 10000 simulations.:  36%|███▌      | 3596/10000 [00:12<00:22, 282.63it/s]Running 10000 simulations.:  36%|███▋      | 3625/10000 [00:12<00:22, 282.60it/s]Running 10000 simulations.:  37%|███▋      | 3654/10000 [00:12<00:22, 283.05it/s]Running 10000 simulations.:  37%|███▋      | 3683/10000 [00:12<00:22, 282.98it/s]Running 10000 simulations.:  37%|███▋      | 3712/10000 [00:13<00:22, 280.33it/s]Running 10000 simulations.:  37%|███▋      | 3741/10000 [00:13<00:22, 280.55it/s]Running 10000 simulations.:  38%|███▊      | 3770/10000 [00:13<00:22, 281.01it/s]Running 10000 simulations.:  38%|███▊      | 3799/10000 [00:13<00:22, 281.38it/s]Running 10000 simulations.:  38%|███▊      | 3828/10000 [00:13<00:21, 281.95it/s]Running 10000 simulations.:  39%|███▊      | 3857/10000 [00:13<00:21, 281.74it/s]Running 10000 simulations.:  39%|███▉      | 3886/10000 [00:13<00:21, 282.06it/s]Running 10000 simulations.:  39%|███▉      | 3915/10000 [00:13<00:21, 282.24it/s]Running 10000 simulations.:  39%|███▉      | 3944/10000 [00:13<00:21, 282.02it/s]Running 10000 simulations.:  40%|███▉      | 3973/10000 [00:14<00:21, 283.54it/s]Running 10000 simulations.:  40%|████      | 4002/10000 [00:14<00:21, 284.04it/s]Running 10000 simulations.:  40%|████      | 4031/10000 [00:14<00:20, 284.33it/s]Running 10000 simulations.:  41%|████      | 4060/10000 [00:14<00:20, 284.53it/s]Running 10000 simulations.:  41%|████      | 4089/10000 [00:14<00:20, 284.07it/s]Running 10000 simulations.:  41%|████      | 4118/10000 [00:14<00:20, 283.23it/s]Running 10000 simulations.:  41%|████▏     | 4147/10000 [00:14<00:20, 282.74it/s]Running 10000 simulations.:  42%|████▏     | 4176/10000 [00:14<00:20, 282.54it/s]Running 10000 simulations.:  42%|████▏     | 4205/10000 [00:14<00:20, 282.85it/s]Running 10000 simulations.:  42%|████▏     | 4234/10000 [00:14<00:20, 283.40it/s]Running 10000 simulations.:  43%|████▎     | 4263/10000 [00:15<00:20, 284.21it/s]Running 10000 simulations.:  43%|████▎     | 4292/10000 [00:15<00:20, 284.12it/s]Running 10000 simulations.:  43%|████▎     | 4321/10000 [00:15<00:20, 283.21it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:15<00:19, 283.03it/s]Running 10000 simulations.:  44%|████▍     | 4379/10000 [00:15<00:19, 284.44it/s]Running 10000 simulations.:  44%|████▍     | 4408/10000 [00:15<00:19, 283.99it/s]Running 10000 simulations.:  44%|████▍     | 4437/10000 [00:15<00:19, 283.37it/s]Running 10000 simulations.:  45%|████▍     | 4466/10000 [00:15<00:19, 283.29it/s]Running 10000 simulations.:  45%|████▍     | 4495/10000 [00:15<00:19, 283.64it/s]Running 10000 simulations.:  45%|████▌     | 4524/10000 [00:15<00:19, 283.73it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:16<00:19, 283.57it/s]Running 10000 simulations.:  46%|████▌     | 4582/10000 [00:16<00:19, 282.96it/s]Running 10000 simulations.:  46%|████▌     | 4611/10000 [00:16<00:19, 282.40it/s]Running 10000 simulations.:  46%|████▋     | 4640/10000 [00:16<00:18, 282.42it/s]Running 10000 simulations.:  47%|████▋     | 4669/10000 [00:16<00:18, 282.00it/s]Running 10000 simulations.:  47%|████▋     | 4698/10000 [00:16<00:18, 281.60it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:16<00:18, 281.59it/s]Running 10000 simulations.:  48%|████▊     | 4756/10000 [00:16<00:18, 281.53it/s]Running 10000 simulations.:  48%|████▊     | 4785/10000 [00:16<00:18, 281.61it/s]Running 10000 simulations.:  48%|████▊     | 4814/10000 [00:16<00:18, 281.46it/s]Running 10000 simulations.:  48%|████▊     | 4843/10000 [00:17<00:18, 281.32it/s]Running 10000 simulations.:  49%|████▊     | 4872/10000 [00:17<00:18, 281.20it/s]Running 10000 simulations.:  49%|████▉     | 4901/10000 [00:17<00:18, 281.16it/s]Running 10000 simulations.:  49%|████▉     | 4930/10000 [00:17<00:18, 281.08it/s]Running 10000 simulations.:  50%|████▉     | 4959/10000 [00:17<00:17, 281.45it/s]Running 10000 simulations.:  50%|████▉     | 4988/10000 [00:17<00:17, 281.27it/s]Running 10000 simulations.:  50%|█████     | 5017/10000 [00:17<00:17, 281.01it/s]Running 10000 simulations.:  50%|█████     | 5046/10000 [00:17<00:17, 281.13it/s]Running 10000 simulations.:  51%|█████     | 5075/10000 [00:17<00:17, 281.42it/s]Running 10000 simulations.:  51%|█████     | 5104/10000 [00:18<00:17, 281.60it/s]Running 10000 simulations.:  51%|█████▏    | 5133/10000 [00:18<00:17, 281.35it/s]Running 10000 simulations.:  52%|█████▏    | 5162/10000 [00:18<00:17, 282.58it/s]Running 10000 simulations.:  52%|█████▏    | 5191/10000 [00:18<00:17, 282.68it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:18<00:16, 282.01it/s]Running 10000 simulations.:  52%|█████▏    | 5249/10000 [00:18<00:16, 283.15it/s]Running 10000 simulations.:  53%|█████▎    | 5278/10000 [00:18<00:16, 284.37it/s]Running 10000 simulations.:  53%|█████▎    | 5307/10000 [00:18<00:16, 284.35it/s]Running 10000 simulations.:  53%|█████▎    | 5336/10000 [00:18<00:16, 283.41it/s]Running 10000 simulations.:  54%|█████▎    | 5365/10000 [00:18<00:16, 283.82it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:19<00:16, 283.39it/s]Running 10000 simulations.:  54%|█████▍    | 5423/10000 [00:19<00:16, 282.98it/s]Running 10000 simulations.:  55%|█████▍    | 5452/10000 [00:19<00:16, 282.58it/s]Running 10000 simulations.:  55%|█████▍    | 5481/10000 [00:19<00:15, 282.58it/s]Running 10000 simulations.:  55%|█████▌    | 5510/10000 [00:19<00:15, 281.83it/s]Running 10000 simulations.:  55%|█████▌    | 5539/10000 [00:19<00:15, 281.89it/s]Running 10000 simulations.:  56%|█████▌    | 5568/10000 [00:19<00:15, 283.43it/s]Running 10000 simulations.:  56%|█████▌    | 5597/10000 [00:19<00:15, 283.38it/s]Running 10000 simulations.:  56%|█████▋    | 5626/10000 [00:19<00:15, 283.09it/s]Running 10000 simulations.:  57%|█████▋    | 5655/10000 [00:19<00:15, 282.62it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:20<00:15, 282.07it/s]Running 10000 simulations.:  57%|█████▋    | 5713/10000 [00:20<00:15, 281.85it/s]Running 10000 simulations.:  57%|█████▋    | 5742/10000 [00:20<00:15, 281.83it/s]Running 10000 simulations.:  58%|█████▊    | 5771/10000 [00:20<00:14, 282.09it/s]Running 10000 simulations.:  58%|█████▊    | 5800/10000 [00:20<00:14, 282.03it/s]Running 10000 simulations.:  58%|█████▊    | 5829/10000 [00:20<00:14, 282.15it/s]Running 10000 simulations.:  59%|█████▊    | 5858/10000 [00:20<00:14, 282.24it/s]Running 10000 simulations.:  59%|█████▉    | 5887/10000 [00:20<00:14, 282.33it/s]Running 10000 simulations.:  59%|█████▉    | 5916/10000 [00:20<00:14, 282.29it/s]Running 10000 simulations.:  59%|█████▉    | 5945/10000 [00:20<00:14, 281.80it/s]Running 10000 simulations.:  60%|█████▉    | 5974/10000 [00:21<00:14, 281.70it/s]Running 10000 simulations.:  60%|██████    | 6003/10000 [00:21<00:14, 282.48it/s]Running 10000 simulations.:  60%|██████    | 6032/10000 [00:21<00:13, 283.73it/s]Running 10000 simulations.:  61%|██████    | 6061/10000 [00:21<00:13, 284.23it/s]Running 10000 simulations.:  61%|██████    | 6090/10000 [00:21<00:13, 283.67it/s]Running 10000 simulations.:  61%|██████    | 6119/10000 [00:21<00:13, 283.19it/s]Running 10000 simulations.:  61%|██████▏   | 6148/10000 [00:21<00:13, 282.89it/s]Running 10000 simulations.:  62%|██████▏   | 6177/10000 [00:21<00:13, 283.62it/s]Running 10000 simulations.:  62%|██████▏   | 6206/10000 [00:21<00:13, 283.73it/s]Running 10000 simulations.:  62%|██████▏   | 6235/10000 [00:22<00:13, 284.72it/s]Running 10000 simulations.:  63%|██████▎   | 6264/10000 [00:22<00:13, 284.20it/s]Running 10000 simulations.:  63%|██████▎   | 6293/10000 [00:22<00:13, 284.57it/s]Running 10000 simulations.:  63%|██████▎   | 6322/10000 [00:22<00:12, 283.64it/s]Running 10000 simulations.:  64%|██████▎   | 6351/10000 [00:22<00:12, 282.54it/s]Running 10000 simulations.:  64%|██████▍   | 6380/10000 [00:22<00:12, 283.07it/s]Running 10000 simulations.:  64%|██████▍   | 6409/10000 [00:22<00:12, 282.62it/s]Running 10000 simulations.:  64%|██████▍   | 6438/10000 [00:22<00:12, 282.50it/s]Running 10000 simulations.:  65%|██████▍   | 6467/10000 [00:22<00:12, 282.06it/s]Running 10000 simulations.:  65%|██████▍   | 6496/10000 [00:22<00:12, 281.98it/s]Running 10000 simulations.:  65%|██████▌   | 6525/10000 [00:23<00:12, 282.64it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:23<00:12, 282.18it/s]Running 10000 simulations.:  66%|██████▌   | 6583/10000 [00:23<00:12, 281.71it/s]Running 10000 simulations.:  66%|██████▌   | 6612/10000 [00:23<00:12, 281.86it/s]Running 10000 simulations.:  66%|██████▋   | 6641/10000 [00:23<00:11, 283.41it/s]Running 10000 simulations.:  67%|██████▋   | 6670/10000 [00:23<00:11, 282.97it/s]Running 10000 simulations.:  67%|██████▋   | 6699/10000 [00:23<00:11, 281.93it/s]Running 10000 simulations.:  67%|██████▋   | 6728/10000 [00:23<00:11, 282.28it/s]Running 10000 simulations.:  68%|██████▊   | 6757/10000 [00:23<00:11, 281.53it/s]Running 10000 simulations.:  68%|██████▊   | 6786/10000 [00:23<00:11, 282.34it/s]Running 10000 simulations.:  68%|██████▊   | 6815/10000 [00:24<00:11, 281.95it/s]Running 10000 simulations.:  68%|██████▊   | 6844/10000 [00:24<00:11, 281.48it/s]Running 10000 simulations.:  69%|██████▊   | 6873/10000 [00:24<00:11, 281.15it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:24<00:11, 281.22it/s]Running 10000 simulations.:  69%|██████▉   | 6931/10000 [00:24<00:10, 282.65it/s]Running 10000 simulations.:  70%|██████▉   | 6960/10000 [00:24<00:10, 282.92it/s]Running 10000 simulations.:  70%|██████▉   | 6989/10000 [00:24<00:10, 282.59it/s]Running 10000 simulations.:  70%|███████   | 7018/10000 [00:24<00:10, 282.17it/s]Running 10000 simulations.:  70%|███████   | 7047/10000 [00:24<00:10, 281.72it/s]Running 10000 simulations.:  71%|███████   | 7076/10000 [00:24<00:10, 282.64it/s]Running 10000 simulations.:  71%|███████   | 7105/10000 [00:25<00:10, 282.45it/s]Running 10000 simulations.:  71%|███████▏  | 7134/10000 [00:25<00:10, 283.66it/s]Running 10000 simulations.:  72%|███████▏  | 7163/10000 [00:25<00:09, 284.40it/s]Running 10000 simulations.:  72%|███████▏  | 7192/10000 [00:25<00:09, 284.36it/s]Running 10000 simulations.:  72%|███████▏  | 7221/10000 [00:25<00:09, 284.84it/s]Running 10000 simulations.:  72%|███████▎  | 7250/10000 [00:25<00:09, 283.61it/s]Running 10000 simulations.:  73%|███████▎  | 7279/10000 [00:25<00:09, 282.68it/s]Running 10000 simulations.:  73%|███████▎  | 7308/10000 [00:25<00:09, 282.29it/s]Running 10000 simulations.:  73%|███████▎  | 7337/10000 [00:25<00:09, 281.76it/s]Running 10000 simulations.:  74%|███████▎  | 7366/10000 [00:26<00:09, 280.30it/s]Running 10000 simulations.:  74%|███████▍  | 7395/10000 [00:26<00:09, 281.03it/s]Running 10000 simulations.:  74%|███████▍  | 7424/10000 [00:26<00:09, 280.86it/s]Running 10000 simulations.:  75%|███████▍  | 7453/10000 [00:26<00:09, 280.75it/s]Running 10000 simulations.:  75%|███████▍  | 7482/10000 [00:26<00:08, 281.62it/s]Running 10000 simulations.:  75%|███████▌  | 7511/10000 [00:26<00:08, 281.22it/s]Running 10000 simulations.:  75%|███████▌  | 7540/10000 [00:26<00:08, 281.46it/s]Running 10000 simulations.:  76%|███████▌  | 7569/10000 [00:26<00:08, 281.31it/s]Running 10000 simulations.:  76%|███████▌  | 7598/10000 [00:26<00:08, 280.78it/s]Running 10000 simulations.:  76%|███████▋  | 7627/10000 [00:26<00:08, 280.22it/s]Running 10000 simulations.:  77%|███████▋  | 7656/10000 [00:27<00:08, 280.17it/s]Running 10000 simulations.:  77%|███████▋  | 7685/10000 [00:27<00:08, 279.69it/s]Running 10000 simulations.:  77%|███████▋  | 7713/10000 [00:27<00:08, 266.97it/s]Running 10000 simulations.:  77%|███████▋  | 7742/10000 [00:27<00:08, 270.93it/s]Running 10000 simulations.:  78%|███████▊  | 7771/10000 [00:27<00:08, 273.72it/s]Running 10000 simulations.:  78%|███████▊  | 7800/10000 [00:27<00:07, 275.85it/s]Running 10000 simulations.:  78%|███████▊  | 7829/10000 [00:27<00:07, 277.38it/s]Running 10000 simulations.:  79%|███████▊  | 7857/10000 [00:27<00:07, 277.81it/s]Running 10000 simulations.:  79%|███████▉  | 7885/10000 [00:27<00:07, 277.98it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:27<00:07, 278.45it/s]Running 10000 simulations.:  79%|███████▉  | 7941/10000 [00:28<00:07, 278.87it/s]Running 10000 simulations.:  80%|███████▉  | 7969/10000 [00:28<00:07, 278.94it/s]Running 10000 simulations.:  80%|███████▉  | 7997/10000 [00:28<00:07, 278.74it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:28<00:07, 279.00it/s]Running 10000 simulations.:  81%|████████  | 8053/10000 [00:28<00:10, 186.16it/s]Running 10000 simulations.:  81%|████████  | 8082/10000 [00:28<00:09, 207.10it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:28<00:08, 224.97it/s]Running 10000 simulations.:  81%|████████▏ | 8140/10000 [00:28<00:07, 239.39it/s]Running 10000 simulations.:  82%|████████▏ | 8169/10000 [00:29<00:07, 250.86it/s]Running 10000 simulations.:  82%|████████▏ | 8196/10000 [00:29<00:07, 254.29it/s]Running 10000 simulations.:  82%|████████▏ | 8224/10000 [00:29<00:06, 261.02it/s]Running 10000 simulations.:  83%|████████▎ | 8253/10000 [00:29<00:06, 267.58it/s]Running 10000 simulations.:  83%|████████▎ | 8281/10000 [00:29<00:06, 270.74it/s]Running 10000 simulations.:  83%|████████▎ | 8309/10000 [00:29<00:06, 272.97it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:29<00:06, 274.97it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [00:29<00:05, 277.11it/s]Running 10000 simulations.:  84%|████████▍ | 8395/10000 [00:29<00:05, 278.59it/s]Running 10000 simulations.:  84%|████████▍ | 8424/10000 [00:29<00:05, 279.70it/s]Running 10000 simulations.:  85%|████████▍ | 8453/10000 [00:30<00:05, 279.54it/s]Running 10000 simulations.:  85%|████████▍ | 8482/10000 [00:30<00:05, 279.65it/s]Running 10000 simulations.:  85%|████████▌ | 8511/10000 [00:30<00:05, 279.89it/s]Running 10000 simulations.:  85%|████████▌ | 8540/10000 [00:30<00:05, 280.76it/s]Running 10000 simulations.:  86%|████████▌ | 8569/10000 [00:30<00:05, 280.81it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [00:30<00:04, 280.49it/s]Running 10000 simulations.:  86%|████████▋ | 8627/10000 [00:30<00:04, 280.05it/s]Running 10000 simulations.:  87%|████████▋ | 8656/10000 [00:30<00:04, 280.97it/s]Running 10000 simulations.:  87%|████████▋ | 8685/10000 [00:30<00:04, 281.22it/s]Running 10000 simulations.:  87%|████████▋ | 8714/10000 [00:31<00:04, 281.57it/s]Running 10000 simulations.:  87%|████████▋ | 8743/10000 [00:31<00:04, 281.82it/s]Running 10000 simulations.:  88%|████████▊ | 8772/10000 [00:31<00:04, 281.74it/s]Running 10000 simulations.:  88%|████████▊ | 8801/10000 [00:31<00:04, 281.39it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [00:31<00:04, 281.38it/s]Running 10000 simulations.:  89%|████████▊ | 8859/10000 [00:31<00:04, 281.94it/s]Running 10000 simulations.:  89%|████████▉ | 8888/10000 [00:31<00:03, 281.70it/s]Running 10000 simulations.:  89%|████████▉ | 8917/10000 [00:31<00:03, 281.63it/s]Running 10000 simulations.:  89%|████████▉ | 8946/10000 [00:31<00:03, 281.97it/s]Running 10000 simulations.:  90%|████████▉ | 8975/10000 [00:31<00:03, 281.51it/s]Running 10000 simulations.:  90%|█████████ | 9004/10000 [00:32<00:03, 281.63it/s]Running 10000 simulations.:  90%|█████████ | 9033/10000 [00:32<00:03, 281.61it/s]Running 10000 simulations.:  91%|█████████ | 9062/10000 [00:32<00:03, 281.59it/s]Running 10000 simulations.:  91%|█████████ | 9091/10000 [00:32<00:03, 281.82it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:32<00:03, 281.70it/s]Running 10000 simulations.:  91%|█████████▏| 9149/10000 [00:32<00:03, 282.34it/s]Running 10000 simulations.:  92%|█████████▏| 9178/10000 [00:32<00:02, 282.16it/s]Running 10000 simulations.:  92%|█████████▏| 9207/10000 [00:32<00:02, 281.90it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [00:32<00:02, 281.89it/s]Running 10000 simulations.:  93%|█████████▎| 9265/10000 [00:32<00:02, 282.84it/s]Running 10000 simulations.:  93%|█████████▎| 9294/10000 [00:33<00:02, 282.71it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [00:33<00:02, 282.28it/s]Running 10000 simulations.:  94%|█████████▎| 9352/10000 [00:33<00:02, 282.07it/s]Running 10000 simulations.:  94%|█████████▍| 9381/10000 [00:33<00:02, 281.52it/s]Running 10000 simulations.:  94%|█████████▍| 9410/10000 [00:33<00:02, 282.11it/s]Running 10000 simulations.:  94%|█████████▍| 9439/10000 [00:33<00:01, 281.72it/s]Running 10000 simulations.:  95%|█████████▍| 9468/10000 [00:33<00:01, 281.65it/s]Running 10000 simulations.:  95%|█████████▍| 9497/10000 [00:33<00:01, 281.97it/s]Running 10000 simulations.:  95%|█████████▌| 9526/10000 [00:33<00:01, 282.48it/s]Running 10000 simulations.:  96%|█████████▌| 9555/10000 [00:33<00:01, 282.58it/s]Running 10000 simulations.:  96%|█████████▌| 9584/10000 [00:34<00:01, 282.10it/s]Running 10000 simulations.:  96%|█████████▌| 9613/10000 [00:34<00:01, 282.48it/s]Running 10000 simulations.:  96%|█████████▋| 9642/10000 [00:34<00:01, 281.83it/s]Running 10000 simulations.:  97%|█████████▋| 9671/10000 [00:34<00:01, 281.76it/s]Running 10000 simulations.:  97%|█████████▋| 9700/10000 [00:34<00:01, 281.84it/s]Running 10000 simulations.:  97%|█████████▋| 9729/10000 [00:34<00:00, 281.48it/s]Running 10000 simulations.:  98%|█████████▊| 9758/10000 [00:34<00:00, 281.47it/s]Running 10000 simulations.:  98%|█████████▊| 9787/10000 [00:34<00:00, 282.41it/s]Running 10000 simulations.:  98%|█████████▊| 9816/10000 [00:34<00:00, 282.70it/s]Running 10000 simulations.:  98%|█████████▊| 9845/10000 [00:35<00:00, 282.50it/s]Running 10000 simulations.:  99%|█████████▊| 9874/10000 [00:35<00:00, 282.51it/s]Running 10000 simulations.:  99%|█████████▉| 9903/10000 [00:35<00:00, 282.02it/s]Running 10000 simulations.:  99%|█████████▉| 9932/10000 [00:35<00:00, 282.02it/s]Running 10000 simulations.: 100%|█████████▉| 9961/10000 [00:35<00:00, 281.62it/s]Running 10000 simulations.: 100%|█████████▉| 9990/10000 [00:35<00:00, 281.45it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:35<00:00, 281.19it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 16/10000 [00:00<01:03, 156.33it/s]Running 10000 simulations.:   0%|          | 32/10000 [00:00<01:03, 156.17it/s]Running 10000 simulations.:   0%|          | 48/10000 [00:00<01:04, 155.19it/s]Running 10000 simulations.:   1%|          | 64/10000 [00:00<01:04, 154.38it/s]Running 10000 simulations.:   1%|          | 80/10000 [00:00<01:04, 153.61it/s]Running 10000 simulations.:   1%|          | 96/10000 [00:00<01:04, 153.25it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<01:04, 152.86it/s]Running 10000 simulations.:   1%|▏         | 128/10000 [00:00<01:04, 152.66it/s]Running 10000 simulations.:   1%|▏         | 144/10000 [00:00<01:04, 152.59it/s]Running 10000 simulations.:   2%|▏         | 160/10000 [00:01<01:04, 152.36it/s]Running 10000 simulations.:   2%|▏         | 176/10000 [00:01<01:04, 152.11it/s]Running 10000 simulations.:   2%|▏         | 192/10000 [00:01<01:04, 151.92it/s]Running 10000 simulations.:   2%|▏         | 208/10000 [00:01<01:04, 152.29it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:01<01:04, 152.18it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:01<01:04, 151.45it/s]Running 10000 simulations.:   3%|▎         | 256/10000 [00:01<01:04, 151.42it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<01:04, 150.81it/s]Running 10000 simulations.:   3%|▎         | 288/10000 [00:01<01:04, 150.71it/s]Running 10000 simulations.:   3%|▎         | 304/10000 [00:01<01:04, 150.76it/s]Running 10000 simulations.:   3%|▎         | 320/10000 [00:02<01:04, 150.46it/s]Running 10000 simulations.:   3%|▎         | 336/10000 [00:02<01:04, 149.01it/s]Running 10000 simulations.:   4%|▎         | 351/10000 [00:02<01:04, 148.69it/s]Running 10000 simulations.:   4%|▎         | 366/10000 [00:02<01:04, 148.65it/s]Running 10000 simulations.:   4%|▍         | 381/10000 [00:02<01:04, 148.88it/s]Running 10000 simulations.:   4%|▍         | 396/10000 [00:02<01:04, 149.20it/s]Running 10000 simulations.:   4%|▍         | 411/10000 [00:02<01:04, 148.60it/s]Running 10000 simulations.:   4%|▍         | 426/10000 [00:02<01:04, 148.66it/s]Running 10000 simulations.:   4%|▍         | 441/10000 [00:02<01:04, 148.85it/s]Running 10000 simulations.:   5%|▍         | 457/10000 [00:03<01:03, 149.30it/s]Running 10000 simulations.:   5%|▍         | 472/10000 [00:03<01:03, 149.51it/s]Running 10000 simulations.:   5%|▍         | 487/10000 [00:03<01:03, 149.27it/s]Running 10000 simulations.:   5%|▌         | 502/10000 [00:03<01:03, 149.23it/s]Running 10000 simulations.:   5%|▌         | 517/10000 [00:03<01:03, 148.83it/s]Running 10000 simulations.:   5%|▌         | 532/10000 [00:03<01:03, 148.87it/s]Running 10000 simulations.:   5%|▌         | 547/10000 [00:03<01:03, 148.44it/s]Running 10000 simulations.:   6%|▌         | 562/10000 [00:03<01:03, 148.70it/s]Running 10000 simulations.:   6%|▌         | 577/10000 [00:03<01:03, 148.43it/s]Running 10000 simulations.:   6%|▌         | 593/10000 [00:03<01:03, 149.32it/s]Running 10000 simulations.:   6%|▌         | 608/10000 [00:04<01:02, 149.08it/s]Running 10000 simulations.:   6%|▌         | 624/10000 [00:04<01:02, 149.54it/s]Running 10000 simulations.:   6%|▋         | 639/10000 [00:04<01:02, 149.34it/s]Running 10000 simulations.:   7%|▋         | 654/10000 [00:04<01:02, 149.31it/s]Running 10000 simulations.:   7%|▋         | 669/10000 [00:04<01:02, 148.87it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:04<01:02, 148.44it/s]Running 10000 simulations.:   7%|▋         | 699/10000 [00:04<01:02, 148.14it/s]Running 10000 simulations.:   7%|▋         | 714/10000 [00:04<01:02, 147.56it/s]Running 10000 simulations.:   7%|▋         | 729/10000 [00:04<01:02, 147.62it/s]Running 10000 simulations.:   7%|▋         | 744/10000 [00:04<01:02, 147.82it/s]Running 10000 simulations.:   8%|▊         | 759/10000 [00:05<01:02, 148.06it/s]Running 10000 simulations.:   8%|▊         | 775/10000 [00:05<01:02, 148.66it/s]Running 10000 simulations.:   8%|▊         | 791/10000 [00:05<01:01, 149.09it/s]Running 10000 simulations.:   8%|▊         | 806/10000 [00:05<01:01, 148.96it/s]Running 10000 simulations.:   8%|▊         | 821/10000 [00:05<01:01, 148.75it/s]Running 10000 simulations.:   8%|▊         | 836/10000 [00:05<01:01, 148.48it/s]Running 10000 simulations.:   9%|▊         | 851/10000 [00:05<01:01, 148.24it/s]Running 10000 simulations.:   9%|▊         | 866/10000 [00:05<01:01, 148.13it/s]Running 10000 simulations.:   9%|▉         | 881/10000 [00:05<01:01, 147.94it/s]Running 10000 simulations.:   9%|▉         | 896/10000 [00:05<01:01, 148.00it/s]Running 10000 simulations.:   9%|▉         | 911/10000 [00:06<01:01, 148.02it/s]Running 10000 simulations.:   9%|▉         | 926/10000 [00:06<01:01, 147.90it/s]Running 10000 simulations.:   9%|▉         | 941/10000 [00:06<01:01, 147.25it/s]Running 10000 simulations.:  10%|▉         | 956/10000 [00:06<01:01, 147.68it/s]Running 10000 simulations.:  10%|▉         | 971/10000 [00:06<01:00, 148.17it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:06<01:01, 147.77it/s]Running 10000 simulations.:  10%|█         | 1001/10000 [00:06<01:00, 147.71it/s]Running 10000 simulations.:  10%|█         | 1016/10000 [00:06<01:00, 147.55it/s]Running 10000 simulations.:  10%|█         | 1031/10000 [00:06<01:00, 147.32it/s]Running 10000 simulations.:  10%|█         | 1046/10000 [00:07<01:00, 146.95it/s]Running 10000 simulations.:  11%|█         | 1061/10000 [00:07<01:00, 146.73it/s]Running 10000 simulations.:  11%|█         | 1076/10000 [00:07<01:00, 146.31it/s]Running 10000 simulations.:  11%|█         | 1091/10000 [00:07<01:00, 146.48it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:07<01:00, 146.46it/s]Running 10000 simulations.:  11%|█         | 1121/10000 [00:07<01:00, 146.19it/s]Running 10000 simulations.:  11%|█▏        | 1136/10000 [00:07<01:01, 145.29it/s]Running 10000 simulations.:  12%|█▏        | 1151/10000 [00:07<01:01, 144.18it/s]Running 10000 simulations.:  12%|█▏        | 1166/10000 [00:07<01:01, 143.68it/s]Running 10000 simulations.:  12%|█▏        | 1181/10000 [00:07<01:01, 143.07it/s]Running 10000 simulations.:  12%|█▏        | 1196/10000 [00:08<01:01, 143.22it/s]Running 10000 simulations.:  12%|█▏        | 1211/10000 [00:08<01:00, 144.11it/s]Running 10000 simulations.:  12%|█▏        | 1226/10000 [00:08<01:00, 145.01it/s]Running 10000 simulations.:  12%|█▏        | 1241/10000 [00:08<01:00, 145.26it/s]Running 10000 simulations.:  13%|█▎        | 1256/10000 [00:08<00:59, 146.12it/s]Running 10000 simulations.:  13%|█▎        | 1271/10000 [00:08<00:59, 146.43it/s]Running 10000 simulations.:  13%|█▎        | 1286/10000 [00:08<00:59, 146.73it/s]Running 10000 simulations.:  13%|█▎        | 1301/10000 [00:08<00:59, 146.51it/s]Running 10000 simulations.:  13%|█▎        | 1316/10000 [00:08<00:59, 146.18it/s]Running 10000 simulations.:  13%|█▎        | 1331/10000 [00:08<00:59, 145.74it/s]Running 10000 simulations.:  13%|█▎        | 1346/10000 [00:09<00:59, 144.71it/s]Running 10000 simulations.:  14%|█▎        | 1361/10000 [00:09<01:00, 143.90it/s]Running 10000 simulations.:  14%|█▍        | 1376/10000 [00:09<00:59, 144.20it/s]Running 10000 simulations.:  14%|█▍        | 1391/10000 [00:09<00:59, 144.70it/s]Running 10000 simulations.:  14%|█▍        | 1406/10000 [00:09<00:59, 144.38it/s]Running 10000 simulations.:  14%|█▍        | 1421/10000 [00:09<00:59, 144.57it/s]Running 10000 simulations.:  14%|█▍        | 1436/10000 [00:09<00:59, 144.89it/s]Running 10000 simulations.:  15%|█▍        | 1451/10000 [00:09<00:59, 144.87it/s]Running 10000 simulations.:  15%|█▍        | 1466/10000 [00:09<00:59, 144.43it/s]Running 10000 simulations.:  15%|█▍        | 1481/10000 [00:10<00:59, 144.17it/s]Running 10000 simulations.:  15%|█▍        | 1496/10000 [00:10<00:58, 144.21it/s]Running 10000 simulations.:  15%|█▌        | 1511/10000 [00:10<00:58, 144.31it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:10<00:58, 143.83it/s]Running 10000 simulations.:  15%|█▌        | 1541/10000 [00:10<00:59, 143.08it/s]Running 10000 simulations.:  16%|█▌        | 1556/10000 [00:10<00:58, 143.60it/s]Running 10000 simulations.:  16%|█▌        | 1571/10000 [00:10<00:58, 143.70it/s]Running 10000 simulations.:  16%|█▌        | 1586/10000 [00:10<00:58, 143.53it/s]Running 10000 simulations.:  16%|█▌        | 1601/10000 [00:10<00:58, 143.47it/s]Running 10000 simulations.:  16%|█▌        | 1616/10000 [00:10<00:58, 143.51it/s]Running 10000 simulations.:  16%|█▋        | 1631/10000 [00:11<00:58, 143.81it/s]Running 10000 simulations.:  16%|█▋        | 1646/10000 [00:11<00:58, 143.71it/s]Running 10000 simulations.:  17%|█▋        | 1661/10000 [00:11<00:58, 143.73it/s]Running 10000 simulations.:  17%|█▋        | 1676/10000 [00:11<00:58, 143.49it/s]Running 10000 simulations.:  17%|█▋        | 1691/10000 [00:11<00:57, 143.33it/s]Running 10000 simulations.:  17%|█▋        | 1706/10000 [00:11<00:57, 143.46it/s]Running 10000 simulations.:  17%|█▋        | 1721/10000 [00:11<00:57, 143.32it/s]Running 10000 simulations.:  17%|█▋        | 1736/10000 [00:11<00:57, 143.06it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:11<00:57, 142.77it/s]Running 10000 simulations.:  18%|█▊        | 1766/10000 [00:11<00:57, 142.36it/s]Running 10000 simulations.:  18%|█▊        | 1781/10000 [00:12<00:57, 142.54it/s]Running 10000 simulations.:  18%|█▊        | 1796/10000 [00:12<00:57, 142.70it/s]Running 10000 simulations.:  18%|█▊        | 1811/10000 [00:12<00:57, 142.84it/s]Running 10000 simulations.:  18%|█▊        | 1826/10000 [00:12<00:57, 143.09it/s]Running 10000 simulations.:  18%|█▊        | 1841/10000 [00:12<00:56, 143.67it/s]Running 10000 simulations.:  19%|█▊        | 1856/10000 [00:12<00:56, 144.26it/s]Running 10000 simulations.:  19%|█▊        | 1871/10000 [00:12<00:56, 143.52it/s]Running 10000 simulations.:  19%|█▉        | 1886/10000 [00:12<00:56, 143.35it/s]Running 10000 simulations.:  19%|█▉        | 1901/10000 [00:12<00:56, 143.33it/s]Running 10000 simulations.:  19%|█▉        | 1916/10000 [00:13<00:56, 143.30it/s]Running 10000 simulations.:  19%|█▉        | 1931/10000 [00:13<00:56, 143.42it/s]Running 10000 simulations.:  19%|█▉        | 1946/10000 [00:13<00:55, 143.98it/s]Running 10000 simulations.:  20%|█▉        | 1961/10000 [00:13<00:55, 144.04it/s]Running 10000 simulations.:  20%|█▉        | 1976/10000 [00:13<00:55, 143.67it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:13<00:55, 143.73it/s]Running 10000 simulations.:  20%|██        | 2006/10000 [00:13<00:55, 143.62it/s]Running 10000 simulations.:  20%|██        | 2021/10000 [00:13<00:55, 143.64it/s]Running 10000 simulations.:  20%|██        | 2036/10000 [00:13<00:55, 143.42it/s]Running 10000 simulations.:  21%|██        | 2051/10000 [00:13<00:55, 143.36it/s]Running 10000 simulations.:  21%|██        | 2066/10000 [00:14<00:55, 143.64it/s]Running 10000 simulations.:  21%|██        | 2081/10000 [00:14<00:55, 143.59it/s]Running 10000 simulations.:  21%|██        | 2096/10000 [00:14<00:55, 143.38it/s]Running 10000 simulations.:  21%|██        | 2111/10000 [00:14<00:55, 143.43it/s]Running 10000 simulations.:  21%|██▏       | 2126/10000 [00:14<00:54, 143.72it/s]Running 10000 simulations.:  21%|██▏       | 2141/10000 [00:14<00:54, 143.84it/s]Running 10000 simulations.:  22%|██▏       | 2156/10000 [00:14<00:54, 143.92it/s]Running 10000 simulations.:  22%|██▏       | 2171/10000 [00:14<00:54, 143.83it/s]Running 10000 simulations.:  22%|██▏       | 2186/10000 [00:14<00:54, 144.06it/s]Running 10000 simulations.:  22%|██▏       | 2201/10000 [00:15<00:54, 143.68it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:15<00:54, 144.11it/s]Running 10000 simulations.:  22%|██▏       | 2231/10000 [00:15<00:53, 143.89it/s]Running 10000 simulations.:  22%|██▏       | 2246/10000 [00:15<00:54, 143.59it/s]Running 10000 simulations.:  23%|██▎       | 2261/10000 [00:15<00:53, 143.32it/s]Running 10000 simulations.:  23%|██▎       | 2276/10000 [00:15<00:53, 143.11it/s]Running 10000 simulations.:  23%|██▎       | 2291/10000 [00:15<00:53, 142.98it/s]Running 10000 simulations.:  23%|██▎       | 2306/10000 [00:15<00:53, 142.59it/s]Running 10000 simulations.:  23%|██▎       | 2321/10000 [00:15<00:53, 142.99it/s]Running 10000 simulations.:  23%|██▎       | 2336/10000 [00:15<00:53, 142.91it/s]Running 10000 simulations.:  24%|██▎       | 2351/10000 [00:16<00:53, 142.98it/s]Running 10000 simulations.:  24%|██▎       | 2366/10000 [00:16<00:52, 144.14it/s]Running 10000 simulations.:  24%|██▍       | 2381/10000 [00:16<00:52, 145.18it/s]Running 10000 simulations.:  24%|██▍       | 2396/10000 [00:16<00:52, 146.05it/s]Running 10000 simulations.:  24%|██▍       | 2411/10000 [00:16<00:51, 146.14it/s]Running 10000 simulations.:  24%|██▍       | 2426/10000 [00:16<00:51, 146.11it/s]Running 10000 simulations.:  24%|██▍       | 2441/10000 [00:16<00:51, 146.30it/s]Running 10000 simulations.:  25%|██▍       | 2456/10000 [00:16<00:51, 145.80it/s]Running 10000 simulations.:  25%|██▍       | 2471/10000 [00:16<00:51, 145.84it/s]Running 10000 simulations.:  25%|██▍       | 2486/10000 [00:16<00:51, 145.99it/s]Running 10000 simulations.:  25%|██▌       | 2501/10000 [00:17<00:51, 146.01it/s]Running 10000 simulations.:  25%|██▌       | 2516/10000 [00:17<00:51, 146.27it/s]Running 10000 simulations.:  25%|██▌       | 2531/10000 [00:17<00:50, 146.78it/s]Running 10000 simulations.:  25%|██▌       | 2546/10000 [00:17<00:50, 146.74it/s]Running 10000 simulations.:  26%|██▌       | 2561/10000 [00:17<00:50, 146.95it/s]Running 10000 simulations.:  26%|██▌       | 2576/10000 [00:17<00:50, 146.64it/s]Running 10000 simulations.:  26%|██▌       | 2591/10000 [00:17<00:50, 146.32it/s]Running 10000 simulations.:  26%|██▌       | 2606/10000 [00:17<00:50, 146.34it/s]Running 10000 simulations.:  26%|██▌       | 2621/10000 [00:17<00:50, 146.12it/s]Running 10000 simulations.:  26%|██▋       | 2636/10000 [00:18<00:50, 145.89it/s]Running 10000 simulations.:  27%|██▋       | 2651/10000 [00:18<00:50, 145.68it/s]Running 10000 simulations.:  27%|██▋       | 2666/10000 [00:18<00:50, 145.71it/s]Running 10000 simulations.:  27%|██▋       | 2681/10000 [00:18<00:50, 145.57it/s]Running 10000 simulations.:  27%|██▋       | 2696/10000 [00:18<00:50, 145.49it/s]Running 10000 simulations.:  27%|██▋       | 2711/10000 [00:18<00:49, 145.84it/s]Running 10000 simulations.:  27%|██▋       | 2726/10000 [00:18<00:49, 145.86it/s]Running 10000 simulations.:  27%|██▋       | 2741/10000 [00:18<00:49, 146.05it/s]Running 10000 simulations.:  28%|██▊       | 2756/10000 [00:18<00:49, 146.04it/s]Running 10000 simulations.:  28%|██▊       | 2771/10000 [00:18<00:49, 146.12it/s]Running 10000 simulations.:  28%|██▊       | 2786/10000 [00:19<00:49, 146.19it/s]Running 10000 simulations.:  28%|██▊       | 2801/10000 [00:19<00:49, 146.09it/s]Running 10000 simulations.:  28%|██▊       | 2816/10000 [00:19<00:49, 146.22it/s]Running 10000 simulations.:  28%|██▊       | 2831/10000 [00:19<00:49, 146.29it/s]Running 10000 simulations.:  28%|██▊       | 2846/10000 [00:19<00:48, 146.07it/s]Running 10000 simulations.:  29%|██▊       | 2861/10000 [00:19<00:48, 146.00it/s]Running 10000 simulations.:  29%|██▉       | 2876/10000 [00:19<00:48, 146.30it/s]Running 10000 simulations.:  29%|██▉       | 2891/10000 [00:19<00:48, 146.61it/s]Running 10000 simulations.:  29%|██▉       | 2906/10000 [00:19<00:48, 146.55it/s]Running 10000 simulations.:  29%|██▉       | 2921/10000 [00:19<00:48, 146.30it/s]Running 10000 simulations.:  29%|██▉       | 2936/10000 [00:20<00:48, 146.84it/s]Running 10000 simulations.:  30%|██▉       | 2951/10000 [00:20<00:47, 147.13it/s]Running 10000 simulations.:  30%|██▉       | 2966/10000 [00:20<00:47, 146.64it/s]Running 10000 simulations.:  30%|██▉       | 2981/10000 [00:20<00:47, 146.81it/s]Running 10000 simulations.:  30%|██▉       | 2996/10000 [00:20<00:47, 146.62it/s]Running 10000 simulations.:  30%|███       | 3011/10000 [00:20<00:47, 146.41it/s]Running 10000 simulations.:  30%|███       | 3026/10000 [00:20<00:47, 146.69it/s]Running 10000 simulations.:  30%|███       | 3041/10000 [00:20<00:47, 146.61it/s]Running 10000 simulations.:  31%|███       | 3056/10000 [00:20<00:47, 145.88it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:20<00:47, 145.86it/s]Running 10000 simulations.:  31%|███       | 3086/10000 [00:21<00:47, 146.12it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:21<00:47, 145.86it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:21<00:47, 146.17it/s]Running 10000 simulations.:  31%|███▏      | 3131/10000 [00:21<00:46, 146.62it/s]Running 10000 simulations.:  31%|███▏      | 3146/10000 [00:21<00:46, 146.25it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:21<00:46, 146.55it/s]Running 10000 simulations.:  32%|███▏      | 3176/10000 [00:21<00:46, 146.31it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:21<00:46, 145.86it/s]Running 10000 simulations.:  32%|███▏      | 3206/10000 [00:21<00:46, 146.16it/s]Running 10000 simulations.:  32%|███▏      | 3221/10000 [00:22<00:46, 146.67it/s]Running 10000 simulations.:  32%|███▏      | 3236/10000 [00:22<00:46, 146.30it/s]Running 10000 simulations.:  33%|███▎      | 3251/10000 [00:22<00:46, 145.99it/s]Running 10000 simulations.:  33%|███▎      | 3266/10000 [00:22<00:46, 145.98it/s]Running 10000 simulations.:  33%|███▎      | 3281/10000 [00:22<00:45, 146.40it/s]Running 10000 simulations.:  33%|███▎      | 3296/10000 [00:22<00:45, 146.68it/s]Running 10000 simulations.:  33%|███▎      | 3311/10000 [00:22<00:45, 146.14it/s]Running 10000 simulations.:  33%|███▎      | 3326/10000 [00:22<00:45, 146.01it/s]Running 10000 simulations.:  33%|███▎      | 3341/10000 [00:22<00:45, 145.92it/s]Running 10000 simulations.:  34%|███▎      | 3356/10000 [00:22<00:45, 146.24it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:23<00:45, 145.86it/s]Running 10000 simulations.:  34%|███▍      | 3386/10000 [00:23<00:45, 145.88it/s]Running 10000 simulations.:  34%|███▍      | 3401/10000 [00:23<00:45, 146.01it/s]Running 10000 simulations.:  34%|███▍      | 3416/10000 [00:23<00:45, 146.28it/s]Running 10000 simulations.:  34%|███▍      | 3431/10000 [00:23<00:44, 146.30it/s]Running 10000 simulations.:  34%|███▍      | 3446/10000 [00:23<00:44, 146.60it/s]Running 10000 simulations.:  35%|███▍      | 3461/10000 [00:23<00:44, 146.23it/s]Running 10000 simulations.:  35%|███▍      | 3476/10000 [00:23<00:44, 145.89it/s]Running 10000 simulations.:  35%|███▍      | 3491/10000 [00:23<00:44, 144.80it/s]Running 10000 simulations.:  35%|███▌      | 3506/10000 [00:23<00:44, 144.38it/s]Running 10000 simulations.:  35%|███▌      | 3521/10000 [00:24<00:44, 144.93it/s]Running 10000 simulations.:  35%|███▌      | 3536/10000 [00:24<00:44, 145.13it/s]Running 10000 simulations.:  36%|███▌      | 3551/10000 [00:24<00:44, 145.35it/s]Running 10000 simulations.:  36%|███▌      | 3566/10000 [00:24<00:44, 145.70it/s]Running 10000 simulations.:  36%|███▌      | 3581/10000 [00:24<00:44, 145.57it/s]Running 10000 simulations.:  36%|███▌      | 3596/10000 [00:24<00:44, 145.39it/s]Running 10000 simulations.:  36%|███▌      | 3611/10000 [00:24<00:43, 146.29it/s]Running 10000 simulations.:  36%|███▋      | 3626/10000 [00:24<00:43, 146.34it/s]Running 10000 simulations.:  36%|███▋      | 3641/10000 [00:24<00:43, 146.32it/s]Running 10000 simulations.:  37%|███▋      | 3656/10000 [00:25<00:43, 144.42it/s]Running 10000 simulations.:  37%|███▋      | 3672/10000 [00:25<00:43, 146.42it/s]Running 10000 simulations.:  37%|███▋      | 3688/10000 [00:25<00:42, 147.81it/s]Running 10000 simulations.:  37%|███▋      | 3703/10000 [00:25<00:42, 147.54it/s]Running 10000 simulations.:  37%|███▋      | 3718/10000 [00:25<00:42, 147.36it/s]Running 10000 simulations.:  37%|███▋      | 3733/10000 [00:25<00:42, 147.17it/s]Running 10000 simulations.:  37%|███▋      | 3748/10000 [00:25<00:42, 147.42it/s]Running 10000 simulations.:  38%|███▊      | 3763/10000 [00:25<00:42, 146.63it/s]Running 10000 simulations.:  38%|███▊      | 3778/10000 [00:25<00:42, 146.17it/s]Running 10000 simulations.:  38%|███▊      | 3793/10000 [00:25<00:42, 145.94it/s]Running 10000 simulations.:  38%|███▊      | 3808/10000 [00:26<00:42, 146.15it/s]Running 10000 simulations.:  38%|███▊      | 3823/10000 [00:26<00:42, 146.35it/s]Running 10000 simulations.:  38%|███▊      | 3838/10000 [00:26<00:42, 146.41it/s]Running 10000 simulations.:  39%|███▊      | 3853/10000 [00:26<00:41, 146.39it/s]Running 10000 simulations.:  39%|███▊      | 3868/10000 [00:26<00:41, 146.03it/s]Running 10000 simulations.:  39%|███▉      | 3883/10000 [00:26<00:41, 145.94it/s]Running 10000 simulations.:  39%|███▉      | 3898/10000 [00:26<00:41, 145.58it/s]Running 10000 simulations.:  39%|███▉      | 3913/10000 [00:26<00:41, 145.69it/s]Running 10000 simulations.:  39%|███▉      | 3928/10000 [00:26<00:41, 145.64it/s]Running 10000 simulations.:  39%|███▉      | 3943/10000 [00:26<00:41, 146.03it/s]Running 10000 simulations.:  40%|███▉      | 3958/10000 [00:27<00:41, 145.59it/s]Running 10000 simulations.:  40%|███▉      | 3973/10000 [00:27<00:41, 145.62it/s]Running 10000 simulations.:  40%|███▉      | 3988/10000 [00:27<00:41, 145.71it/s]Running 10000 simulations.:  40%|████      | 4003/10000 [00:27<00:41, 145.49it/s]Running 10000 simulations.:  40%|████      | 4018/10000 [00:27<00:41, 145.23it/s]Running 10000 simulations.:  40%|████      | 4033/10000 [00:27<00:41, 144.86it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:27<00:41, 144.86it/s]Running 10000 simulations.:  41%|████      | 4063/10000 [00:27<00:40, 145.03it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:27<00:40, 144.89it/s]Running 10000 simulations.:  41%|████      | 4093/10000 [00:27<00:40, 144.91it/s]Running 10000 simulations.:  41%|████      | 4108/10000 [00:28<00:40, 144.96it/s]Running 10000 simulations.:  41%|████      | 4123/10000 [00:28<00:40, 145.22it/s]Running 10000 simulations.:  41%|████▏     | 4138/10000 [00:28<00:40, 145.43it/s]Running 10000 simulations.:  42%|████▏     | 4153/10000 [00:28<00:40, 145.57it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:28<00:40, 145.49it/s]Running 10000 simulations.:  42%|████▏     | 4183/10000 [00:28<00:40, 145.34it/s]Running 10000 simulations.:  42%|████▏     | 4198/10000 [00:28<00:42, 137.59it/s]Running 10000 simulations.:  42%|████▏     | 4213/10000 [00:28<00:41, 139.97it/s]Running 10000 simulations.:  42%|████▏     | 4228/10000 [00:28<00:40, 141.48it/s]Running 10000 simulations.:  42%|████▏     | 4243/10000 [00:29<00:40, 143.13it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:29<00:39, 145.10it/s]Running 10000 simulations.:  43%|████▎     | 4274/10000 [00:29<00:39, 145.66it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:29<00:38, 147.78it/s]Running 10000 simulations.:  43%|████▎     | 4306/10000 [00:29<00:38, 149.33it/s]Running 10000 simulations.:  43%|████▎     | 4322/10000 [00:29<00:37, 149.84it/s]Running 10000 simulations.:  43%|████▎     | 4338/10000 [00:29<00:37, 150.13it/s]Running 10000 simulations.:  44%|████▎     | 4354/10000 [00:29<00:37, 150.80it/s]Running 10000 simulations.:  44%|████▎     | 4370/10000 [00:29<00:37, 151.98it/s]Running 10000 simulations.:  44%|████▍     | 4386/10000 [00:29<00:36, 152.41it/s]Running 10000 simulations.:  44%|████▍     | 4402/10000 [00:30<00:36, 151.90it/s]Running 10000 simulations.:  44%|████▍     | 4418/10000 [00:30<00:36, 151.22it/s]Running 10000 simulations.:  44%|████▍     | 4434/10000 [00:30<00:36, 151.08it/s]Running 10000 simulations.:  44%|████▍     | 4450/10000 [00:30<00:36, 151.04it/s]Running 10000 simulations.:  45%|████▍     | 4466/10000 [00:30<00:36, 150.84it/s]Running 10000 simulations.:  45%|████▍     | 4482/10000 [00:30<00:36, 149.97it/s]Running 10000 simulations.:  45%|████▍     | 4498/10000 [00:30<00:36, 150.09it/s]Running 10000 simulations.:  45%|████▌     | 4514/10000 [00:30<00:36, 150.20it/s]Running 10000 simulations.:  45%|████▌     | 4530/10000 [00:30<00:36, 150.57it/s]Running 10000 simulations.:  45%|████▌     | 4546/10000 [00:31<00:36, 150.52it/s]Running 10000 simulations.:  46%|████▌     | 4562/10000 [00:31<00:36, 150.24it/s]Running 10000 simulations.:  46%|████▌     | 4578/10000 [00:31<00:35, 150.62it/s]Running 10000 simulations.:  46%|████▌     | 4594/10000 [00:31<00:35, 151.57it/s]Running 10000 simulations.:  46%|████▌     | 4610/10000 [00:31<00:35, 152.16it/s]Running 10000 simulations.:  46%|████▋     | 4626/10000 [00:31<00:35, 151.54it/s]Running 10000 simulations.:  46%|████▋     | 4642/10000 [00:31<00:35, 151.47it/s]Running 10000 simulations.:  47%|████▋     | 4658/10000 [00:31<00:35, 151.90it/s]Running 10000 simulations.:  47%|████▋     | 4674/10000 [00:31<00:35, 151.46it/s]Running 10000 simulations.:  47%|████▋     | 4690/10000 [00:31<00:35, 151.25it/s]Running 10000 simulations.:  47%|████▋     | 4706/10000 [00:32<00:35, 150.91it/s]Running 10000 simulations.:  47%|████▋     | 4722/10000 [00:32<00:34, 151.13it/s]Running 10000 simulations.:  47%|████▋     | 4738/10000 [00:32<00:34, 151.14it/s]Running 10000 simulations.:  48%|████▊     | 4754/10000 [00:32<00:34, 151.44it/s]Running 10000 simulations.:  48%|████▊     | 4770/10000 [00:32<00:34, 151.44it/s]Running 10000 simulations.:  48%|████▊     | 4786/10000 [00:32<00:34, 151.51it/s]Running 10000 simulations.:  48%|████▊     | 4802/10000 [00:32<00:34, 151.66it/s]Running 10000 simulations.:  48%|████▊     | 4818/10000 [00:32<00:34, 151.34it/s]Running 10000 simulations.:  48%|████▊     | 4834/10000 [00:32<00:34, 150.58it/s]Running 10000 simulations.:  48%|████▊     | 4850/10000 [00:33<00:34, 150.60it/s]Running 10000 simulations.:  49%|████▊     | 4866/10000 [00:33<00:34, 150.84it/s]Running 10000 simulations.:  49%|████▉     | 4882/10000 [00:33<00:33, 150.88it/s]Running 10000 simulations.:  49%|████▉     | 4898/10000 [00:33<00:33, 151.38it/s]Running 10000 simulations.:  49%|████▉     | 4914/10000 [00:33<00:33, 150.83it/s]Running 10000 simulations.:  49%|████▉     | 4930/10000 [00:33<00:33, 150.89it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:33<00:33, 150.87it/s]Running 10000 simulations.:  50%|████▉     | 4962/10000 [00:33<00:33, 150.84it/s]Running 10000 simulations.:  50%|████▉     | 4978/10000 [00:33<00:33, 150.54it/s]Running 10000 simulations.:  50%|████▉     | 4994/10000 [00:34<00:33, 150.76it/s]Running 10000 simulations.:  50%|█████     | 5010/10000 [00:34<00:32, 151.28it/s]Running 10000 simulations.:  50%|█████     | 5026/10000 [00:34<00:32, 150.87it/s]Running 10000 simulations.:  50%|█████     | 5042/10000 [00:34<00:32, 150.85it/s]Running 10000 simulations.:  51%|█████     | 5058/10000 [00:34<00:32, 150.20it/s]Running 10000 simulations.:  51%|█████     | 5074/10000 [00:34<00:32, 150.15it/s]Running 10000 simulations.:  51%|█████     | 5090/10000 [00:34<00:32, 150.65it/s]Running 10000 simulations.:  51%|█████     | 5106/10000 [00:34<00:32, 150.78it/s]Running 10000 simulations.:  51%|█████     | 5122/10000 [00:34<00:32, 150.86it/s]Running 10000 simulations.:  51%|█████▏    | 5138/10000 [00:34<00:32, 150.65it/s]Running 10000 simulations.:  52%|█████▏    | 5154/10000 [00:35<00:32, 150.78it/s]Running 10000 simulations.:  52%|█████▏    | 5170/10000 [00:35<00:31, 151.29it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:35<00:31, 151.61it/s]Running 10000 simulations.:  52%|█████▏    | 5202/10000 [00:35<00:31, 150.54it/s]Running 10000 simulations.:  52%|█████▏    | 5218/10000 [00:35<00:31, 151.08it/s]Running 10000 simulations.:  52%|█████▏    | 5234/10000 [00:35<00:31, 151.72it/s]Running 10000 simulations.:  52%|█████▎    | 5250/10000 [00:35<00:31, 151.89it/s]Running 10000 simulations.:  53%|█████▎    | 5266/10000 [00:35<00:31, 152.56it/s]Running 10000 simulations.:  53%|█████▎    | 5282/10000 [00:35<00:30, 152.35it/s]Running 10000 simulations.:  53%|█████▎    | 5298/10000 [00:36<00:31, 151.54it/s]Running 10000 simulations.:  53%|█████▎    | 5314/10000 [00:36<00:30, 151.49it/s]Running 10000 simulations.:  53%|█████▎    | 5330/10000 [00:36<00:30, 151.72it/s]Running 10000 simulations.:  53%|█████▎    | 5346/10000 [00:36<00:30, 151.78it/s]Running 10000 simulations.:  54%|█████▎    | 5362/10000 [00:36<00:30, 151.59it/s]Running 10000 simulations.:  54%|█████▍    | 5378/10000 [00:36<00:30, 151.74it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:36<00:30, 152.28it/s]Running 10000 simulations.:  54%|█████▍    | 5410/10000 [00:36<00:30, 152.59it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:36<00:29, 152.78it/s]Running 10000 simulations.:  54%|█████▍    | 5442/10000 [00:36<00:29, 152.33it/s]Running 10000 simulations.:  55%|█████▍    | 5458/10000 [00:37<00:29, 151.67it/s]Running 10000 simulations.:  55%|█████▍    | 5474/10000 [00:37<00:29, 151.67it/s]Running 10000 simulations.:  55%|█████▍    | 5490/10000 [00:37<00:29, 151.73it/s]Running 10000 simulations.:  55%|█████▌    | 5506/10000 [00:37<00:29, 151.52it/s]Running 10000 simulations.:  55%|█████▌    | 5522/10000 [00:37<00:29, 151.36it/s]Running 10000 simulations.:  55%|█████▌    | 5538/10000 [00:37<00:29, 151.10it/s]Running 10000 simulations.:  56%|█████▌    | 5554/10000 [00:37<00:29, 151.13it/s]Running 10000 simulations.:  56%|█████▌    | 5570/10000 [00:37<00:29, 151.18it/s]Running 10000 simulations.:  56%|█████▌    | 5586/10000 [00:37<00:29, 151.27it/s]Running 10000 simulations.:  56%|█████▌    | 5602/10000 [00:38<00:29, 151.04it/s]Running 10000 simulations.:  56%|█████▌    | 5618/10000 [00:38<00:29, 150.89it/s]Running 10000 simulations.:  56%|█████▋    | 5634/10000 [00:38<00:28, 150.60it/s]Running 10000 simulations.:  56%|█████▋    | 5650/10000 [00:38<00:28, 150.67it/s]Running 10000 simulations.:  57%|█████▋    | 5666/10000 [00:38<00:28, 150.86it/s]Running 10000 simulations.:  57%|█████▋    | 5682/10000 [00:38<00:28, 151.01it/s]Running 10000 simulations.:  57%|█████▋    | 5698/10000 [00:38<00:28, 150.94it/s]Running 10000 simulations.:  57%|█████▋    | 5714/10000 [00:38<00:28, 150.82it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:38<00:28, 150.49it/s]Running 10000 simulations.:  57%|█████▋    | 5746/10000 [00:38<00:28, 149.97it/s]Running 10000 simulations.:  58%|█████▊    | 5762/10000 [00:39<00:28, 150.07it/s]Running 10000 simulations.:  58%|█████▊    | 5778/10000 [00:39<00:28, 150.28it/s]Running 10000 simulations.:  58%|█████▊    | 5794/10000 [00:39<00:27, 150.42it/s]Running 10000 simulations.:  58%|█████▊    | 5810/10000 [00:39<00:27, 150.45it/s]Running 10000 simulations.:  58%|█████▊    | 5826/10000 [00:39<00:27, 150.52it/s]Running 10000 simulations.:  58%|█████▊    | 5842/10000 [00:39<00:27, 149.95it/s]Running 10000 simulations.:  59%|█████▊    | 5857/10000 [00:39<00:27, 149.19it/s]Running 10000 simulations.:  59%|█████▊    | 5873/10000 [00:39<00:27, 150.17it/s]Running 10000 simulations.:  59%|█████▉    | 5889/10000 [00:39<00:27, 150.68it/s]Running 10000 simulations.:  59%|█████▉    | 5905/10000 [00:40<00:27, 150.51it/s]Running 10000 simulations.:  59%|█████▉    | 5921/10000 [00:40<00:27, 150.36it/s]Running 10000 simulations.:  59%|█████▉    | 5937/10000 [00:40<00:26, 150.75it/s]Running 10000 simulations.:  60%|█████▉    | 5953/10000 [00:40<00:26, 151.57it/s]Running 10000 simulations.:  60%|█████▉    | 5969/10000 [00:40<00:26, 152.05it/s]Running 10000 simulations.:  60%|█████▉    | 5985/10000 [00:40<00:26, 151.68it/s]Running 10000 simulations.:  60%|██████    | 6001/10000 [00:40<00:26, 151.26it/s]Running 10000 simulations.:  60%|██████    | 6017/10000 [00:40<00:26, 151.79it/s]Running 10000 simulations.:  60%|██████    | 6033/10000 [00:40<00:26, 151.98it/s]Running 10000 simulations.:  60%|██████    | 6049/10000 [00:40<00:26, 151.65it/s]Running 10000 simulations.:  61%|██████    | 6065/10000 [00:41<00:25, 151.44it/s]Running 10000 simulations.:  61%|██████    | 6081/10000 [00:41<00:25, 151.42it/s]Running 10000 simulations.:  61%|██████    | 6097/10000 [00:41<00:25, 151.77it/s]Running 10000 simulations.:  61%|██████    | 6113/10000 [00:41<00:25, 151.35it/s]Running 10000 simulations.:  61%|██████▏   | 6129/10000 [00:41<00:25, 151.27it/s]Running 10000 simulations.:  61%|██████▏   | 6145/10000 [00:41<00:25, 151.42it/s]Running 10000 simulations.:  62%|██████▏   | 6161/10000 [00:41<00:25, 151.43it/s]Running 10000 simulations.:  62%|██████▏   | 6177/10000 [00:41<00:25, 150.91it/s]Running 10000 simulations.:  62%|██████▏   | 6193/10000 [00:41<00:25, 150.95it/s]Running 10000 simulations.:  62%|██████▏   | 6209/10000 [00:42<00:25, 151.06it/s]Running 10000 simulations.:  62%|██████▏   | 6225/10000 [00:42<00:25, 150.73it/s]Running 10000 simulations.:  62%|██████▏   | 6241/10000 [00:42<00:24, 150.50it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:42<00:24, 150.59it/s]Running 10000 simulations.:  63%|██████▎   | 6273/10000 [00:42<00:24, 151.01it/s]Running 10000 simulations.:  63%|██████▎   | 6289/10000 [00:42<00:24, 151.09it/s]Running 10000 simulations.:  63%|██████▎   | 6305/10000 [00:42<00:24, 150.37it/s]Running 10000 simulations.:  63%|██████▎   | 6321/10000 [00:42<00:24, 149.93it/s]Running 10000 simulations.:  63%|██████▎   | 6337/10000 [00:42<00:24, 150.22it/s]Running 10000 simulations.:  64%|██████▎   | 6353/10000 [00:43<00:24, 150.42it/s]Running 10000 simulations.:  64%|██████▎   | 6369/10000 [00:43<00:24, 150.32it/s]Running 10000 simulations.:  64%|██████▍   | 6385/10000 [00:43<00:24, 150.31it/s]Running 10000 simulations.:  64%|██████▍   | 6401/10000 [00:43<00:24, 149.88it/s]Running 10000 simulations.:  64%|██████▍   | 6416/10000 [00:43<00:23, 149.81it/s]Running 10000 simulations.:  64%|██████▍   | 6431/10000 [00:43<00:23, 149.73it/s]Running 10000 simulations.:  64%|██████▍   | 6447/10000 [00:43<00:23, 149.85it/s]Running 10000 simulations.:  65%|██████▍   | 6462/10000 [00:43<00:23, 149.50it/s]Running 10000 simulations.:  65%|██████▍   | 6477/10000 [00:43<00:23, 149.15it/s]Running 10000 simulations.:  65%|██████▍   | 6492/10000 [00:43<00:23, 149.29it/s]Running 10000 simulations.:  65%|██████▌   | 6507/10000 [00:44<00:23, 149.40it/s]Running 10000 simulations.:  65%|██████▌   | 6523/10000 [00:44<00:23, 149.60it/s]Running 10000 simulations.:  65%|██████▌   | 6538/10000 [00:44<00:23, 149.40it/s]Running 10000 simulations.:  66%|██████▌   | 6553/10000 [00:44<00:23, 149.37it/s]Running 10000 simulations.:  66%|██████▌   | 6569/10000 [00:44<00:22, 149.71it/s]Running 10000 simulations.:  66%|██████▌   | 6585/10000 [00:44<00:22, 151.48it/s]Running 10000 simulations.:  66%|██████▌   | 6601/10000 [00:44<00:22, 151.43it/s]Running 10000 simulations.:  66%|██████▌   | 6617/10000 [00:44<00:22, 149.86it/s]Running 10000 simulations.:  66%|██████▋   | 6632/10000 [00:44<00:22, 148.94it/s]Running 10000 simulations.:  66%|██████▋   | 6647/10000 [00:44<00:22, 147.51it/s]Running 10000 simulations.:  67%|██████▋   | 6662/10000 [00:45<00:22, 146.85it/s]Running 10000 simulations.:  67%|██████▋   | 6677/10000 [00:45<00:22, 146.23it/s]Running 10000 simulations.:  67%|██████▋   | 6692/10000 [00:45<00:22, 145.02it/s]Running 10000 simulations.:  67%|██████▋   | 6707/10000 [00:45<00:22, 145.08it/s]Running 10000 simulations.:  67%|██████▋   | 6722/10000 [00:45<00:22, 144.92it/s]Running 10000 simulations.:  67%|██████▋   | 6737/10000 [00:45<00:22, 144.99it/s]Running 10000 simulations.:  68%|██████▊   | 6752/10000 [00:45<00:22, 144.72it/s]Running 10000 simulations.:  68%|██████▊   | 6767/10000 [00:45<00:22, 144.60it/s]Running 10000 simulations.:  68%|██████▊   | 6783/10000 [00:45<00:21, 148.34it/s]Running 10000 simulations.:  68%|██████▊   | 6800/10000 [00:46<00:20, 153.06it/s]Running 10000 simulations.:  68%|██████▊   | 6816/10000 [00:46<00:21, 150.82it/s]Running 10000 simulations.:  68%|██████▊   | 6832/10000 [00:46<00:21, 149.37it/s]Running 10000 simulations.:  68%|██████▊   | 6847/10000 [00:46<00:21, 148.53it/s]Running 10000 simulations.:  69%|██████▊   | 6862/10000 [00:46<00:21, 147.78it/s]Running 10000 simulations.:  69%|██████▉   | 6877/10000 [00:46<00:21, 147.13it/s]Running 10000 simulations.:  69%|██████▉   | 6892/10000 [00:46<00:21, 147.03it/s]Running 10000 simulations.:  69%|██████▉   | 6907/10000 [00:46<00:21, 147.18it/s]Running 10000 simulations.:  69%|██████▉   | 6922/10000 [00:46<00:20, 146.94it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:46<00:20, 146.11it/s]Running 10000 simulations.:  70%|██████▉   | 6952/10000 [00:47<00:20, 145.95it/s]Running 10000 simulations.:  70%|██████▉   | 6967/10000 [00:47<00:20, 145.93it/s]Running 10000 simulations.:  70%|██████▉   | 6982/10000 [00:47<00:20, 146.50it/s]Running 10000 simulations.:  70%|██████▉   | 6997/10000 [00:47<00:20, 146.29it/s]Running 10000 simulations.:  70%|███████   | 7012/10000 [00:47<00:20, 145.93it/s]Running 10000 simulations.:  70%|███████   | 7027/10000 [00:47<00:20, 145.95it/s]Running 10000 simulations.:  70%|███████   | 7042/10000 [00:47<00:20, 145.70it/s]Running 10000 simulations.:  71%|███████   | 7057/10000 [00:47<00:20, 146.24it/s]Running 10000 simulations.:  71%|███████   | 7072/10000 [00:47<00:20, 145.92it/s]Running 10000 simulations.:  71%|███████   | 7087/10000 [00:47<00:19, 145.67it/s]Running 10000 simulations.:  71%|███████   | 7102/10000 [00:48<00:19, 145.39it/s]Running 10000 simulations.:  71%|███████   | 7117/10000 [00:48<00:19, 145.33it/s]Running 10000 simulations.:  71%|███████▏  | 7132/10000 [00:48<00:19, 145.42it/s]Running 10000 simulations.:  71%|███████▏  | 7147/10000 [00:48<00:19, 145.50it/s]Running 10000 simulations.:  72%|███████▏  | 7162/10000 [00:48<00:19, 145.53it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:48<00:19, 145.43it/s]Running 10000 simulations.:  72%|███████▏  | 7192/10000 [00:48<00:19, 145.49it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:48<00:19, 146.35it/s]Running 10000 simulations.:  72%|███████▏  | 7222/10000 [00:48<00:19, 146.07it/s]Running 10000 simulations.:  72%|███████▏  | 7237/10000 [00:49<00:18, 145.74it/s]Running 10000 simulations.:  73%|███████▎  | 7252/10000 [00:49<00:18, 146.22it/s]Running 10000 simulations.:  73%|███████▎  | 7267/10000 [00:49<00:18, 146.47it/s]Running 10000 simulations.:  73%|███████▎  | 7282/10000 [00:49<00:18, 146.49it/s]Running 10000 simulations.:  73%|███████▎  | 7297/10000 [00:49<00:18, 146.73it/s]Running 10000 simulations.:  73%|███████▎  | 7312/10000 [00:49<00:18, 146.37it/s]Running 10000 simulations.:  73%|███████▎  | 7327/10000 [00:49<00:18, 145.31it/s]Running 10000 simulations.:  73%|███████▎  | 7342/10000 [00:49<00:18, 145.31it/s]Running 10000 simulations.:  74%|███████▎  | 7357/10000 [00:49<00:18, 145.47it/s]Running 10000 simulations.:  74%|███████▎  | 7372/10000 [00:49<00:18, 145.79it/s]Running 10000 simulations.:  74%|███████▍  | 7387/10000 [00:50<00:17, 146.30it/s]Running 10000 simulations.:  74%|███████▍  | 7402/10000 [00:50<00:17, 146.20it/s]Running 10000 simulations.:  74%|███████▍  | 7417/10000 [00:50<00:17, 146.01it/s]Running 10000 simulations.:  74%|███████▍  | 7432/10000 [00:50<00:17, 146.27it/s]Running 10000 simulations.:  74%|███████▍  | 7447/10000 [00:50<00:17, 146.15it/s]Running 10000 simulations.:  75%|███████▍  | 7462/10000 [00:50<00:17, 146.32it/s]Running 10000 simulations.:  75%|███████▍  | 7477/10000 [00:50<00:17, 146.18it/s]Running 10000 simulations.:  75%|███████▍  | 7492/10000 [00:50<00:17, 145.98it/s]Running 10000 simulations.:  75%|███████▌  | 7507/10000 [00:50<00:17, 146.05it/s]Running 10000 simulations.:  75%|███████▌  | 7522/10000 [00:50<00:16, 145.89it/s]Running 10000 simulations.:  75%|███████▌  | 7537/10000 [00:51<00:16, 146.11it/s]Running 10000 simulations.:  76%|███████▌  | 7552/10000 [00:51<00:16, 146.13it/s]Running 10000 simulations.:  76%|███████▌  | 7567/10000 [00:51<00:16, 146.42it/s]Running 10000 simulations.:  76%|███████▌  | 7582/10000 [00:51<00:16, 146.61it/s]Running 10000 simulations.:  76%|███████▌  | 7597/10000 [00:51<00:16, 146.65it/s]Running 10000 simulations.:  76%|███████▌  | 7612/10000 [00:51<00:16, 146.46it/s]Running 10000 simulations.:  76%|███████▋  | 7627/10000 [00:51<00:16, 146.75it/s]Running 10000 simulations.:  76%|███████▋  | 7642/10000 [00:51<00:16, 146.63it/s]Running 10000 simulations.:  77%|███████▋  | 7657/10000 [00:51<00:15, 146.67it/s]Running 10000 simulations.:  77%|███████▋  | 7672/10000 [00:51<00:15, 146.30it/s]Running 10000 simulations.:  77%|███████▋  | 7687/10000 [00:52<00:15, 146.32it/s]Running 10000 simulations.:  77%|███████▋  | 7702/10000 [00:52<00:15, 146.51it/s]Running 10000 simulations.:  77%|███████▋  | 7717/10000 [00:52<00:15, 146.35it/s]Running 10000 simulations.:  77%|███████▋  | 7732/10000 [00:52<00:15, 146.43it/s]Running 10000 simulations.:  77%|███████▋  | 7747/10000 [00:52<00:15, 146.49it/s]Running 10000 simulations.:  78%|███████▊  | 7762/10000 [00:52<00:15, 146.58it/s]Running 10000 simulations.:  78%|███████▊  | 7777/10000 [00:52<00:15, 147.02it/s]Running 10000 simulations.:  78%|███████▊  | 7792/10000 [00:52<00:14, 147.27it/s]Running 10000 simulations.:  78%|███████▊  | 7807/10000 [00:52<00:14, 147.57it/s]Running 10000 simulations.:  78%|███████▊  | 7822/10000 [00:53<00:14, 147.51it/s]Running 10000 simulations.:  78%|███████▊  | 7837/10000 [00:53<00:14, 147.65it/s]Running 10000 simulations.:  79%|███████▊  | 7852/10000 [00:53<00:14, 147.64it/s]Running 10000 simulations.:  79%|███████▊  | 7867/10000 [00:53<00:14, 148.08it/s]Running 10000 simulations.:  79%|███████▉  | 7882/10000 [00:53<00:14, 148.30it/s]Running 10000 simulations.:  79%|███████▉  | 7897/10000 [00:53<00:14, 148.37it/s]Running 10000 simulations.:  79%|███████▉  | 7912/10000 [00:53<00:14, 148.08it/s]Running 10000 simulations.:  79%|███████▉  | 7927/10000 [00:53<00:14, 147.89it/s]Running 10000 simulations.:  79%|███████▉  | 7942/10000 [00:53<00:13, 147.81it/s]Running 10000 simulations.:  80%|███████▉  | 7957/10000 [00:53<00:13, 147.74it/s]Running 10000 simulations.:  80%|███████▉  | 7972/10000 [00:54<00:13, 147.72it/s]Running 10000 simulations.:  80%|███████▉  | 7987/10000 [00:54<00:13, 147.97it/s]Running 10000 simulations.:  80%|████████  | 8002/10000 [00:54<00:13, 147.80it/s]Running 10000 simulations.:  80%|████████  | 8017/10000 [00:54<00:13, 147.76it/s]Running 10000 simulations.:  80%|████████  | 8032/10000 [00:54<00:13, 147.58it/s]Running 10000 simulations.:  80%|████████  | 8047/10000 [00:54<00:13, 147.42it/s]Running 10000 simulations.:  81%|████████  | 8062/10000 [00:54<00:13, 147.41it/s]Running 10000 simulations.:  81%|████████  | 8078/10000 [00:54<00:12, 148.56it/s]Running 10000 simulations.:  81%|████████  | 8093/10000 [00:54<00:12, 148.20it/s]Running 10000 simulations.:  81%|████████  | 8108/10000 [00:54<00:12, 148.58it/s]Running 10000 simulations.:  81%|████████  | 8123/10000 [00:55<00:12, 148.25it/s]Running 10000 simulations.:  81%|████████▏ | 8139/10000 [00:55<00:12, 148.80it/s]Running 10000 simulations.:  82%|████████▏ | 8155/10000 [00:55<00:12, 149.17it/s]Running 10000 simulations.:  82%|████████▏ | 8170/10000 [00:55<00:12, 149.09it/s]Running 10000 simulations.:  82%|████████▏ | 8185/10000 [00:55<00:12, 148.63it/s]Running 10000 simulations.:  82%|████████▏ | 8200/10000 [00:55<00:12, 148.09it/s]Running 10000 simulations.:  82%|████████▏ | 8215/10000 [00:55<00:12, 147.99it/s]Running 10000 simulations.:  82%|████████▏ | 8230/10000 [00:55<00:11, 148.13it/s]Running 10000 simulations.:  82%|████████▏ | 8245/10000 [00:55<00:11, 148.22it/s]Running 10000 simulations.:  83%|████████▎ | 8260/10000 [00:55<00:11, 147.86it/s]Running 10000 simulations.:  83%|████████▎ | 8275/10000 [00:56<00:11, 147.77it/s]Running 10000 simulations.:  83%|████████▎ | 8290/10000 [00:56<00:11, 147.88it/s]Running 10000 simulations.:  83%|████████▎ | 8305/10000 [00:56<00:11, 148.03it/s]Running 10000 simulations.:  83%|████████▎ | 8320/10000 [00:56<00:11, 147.81it/s]Running 10000 simulations.:  83%|████████▎ | 8335/10000 [00:56<00:11, 147.54it/s]Running 10000 simulations.:  84%|████████▎ | 8350/10000 [00:56<00:11, 147.50it/s]Running 10000 simulations.:  84%|████████▎ | 8365/10000 [00:56<00:11, 147.10it/s]Running 10000 simulations.:  84%|████████▍ | 8380/10000 [00:56<00:11, 147.18it/s]Running 10000 simulations.:  84%|████████▍ | 8395/10000 [00:56<00:10, 147.16it/s]Running 10000 simulations.:  84%|████████▍ | 8410/10000 [00:56<00:10, 147.19it/s]Running 10000 simulations.:  84%|████████▍ | 8425/10000 [00:57<00:10, 147.01it/s]Running 10000 simulations.:  84%|████████▍ | 8440/10000 [00:57<00:10, 147.06it/s]Running 10000 simulations.:  85%|████████▍ | 8455/10000 [00:57<00:10, 147.83it/s]Running 10000 simulations.:  85%|████████▍ | 8470/10000 [00:57<00:10, 148.31it/s]Running 10000 simulations.:  85%|████████▍ | 8485/10000 [00:57<00:10, 148.19it/s]Running 10000 simulations.:  85%|████████▌ | 8500/10000 [00:57<00:10, 148.55it/s]Running 10000 simulations.:  85%|████████▌ | 8515/10000 [00:57<00:10, 148.38it/s]Running 10000 simulations.:  85%|████████▌ | 8530/10000 [00:57<00:09, 148.03it/s]Running 10000 simulations.:  85%|████████▌ | 8545/10000 [00:57<00:09, 148.06it/s]Running 10000 simulations.:  86%|████████▌ | 8560/10000 [00:57<00:09, 148.46it/s]Running 10000 simulations.:  86%|████████▌ | 8575/10000 [00:58<00:09, 148.61it/s]Running 10000 simulations.:  86%|████████▌ | 8590/10000 [00:58<00:09, 148.17it/s]Running 10000 simulations.:  86%|████████▌ | 8605/10000 [00:58<00:09, 146.88it/s]Running 10000 simulations.:  86%|████████▌ | 8620/10000 [00:58<00:09, 147.15it/s]Running 10000 simulations.:  86%|████████▋ | 8635/10000 [00:58<00:09, 147.00it/s]Running 10000 simulations.:  87%|████████▋ | 8651/10000 [00:58<00:09, 148.32it/s]Running 10000 simulations.:  87%|████████▋ | 8666/10000 [00:58<00:09, 145.26it/s]Running 10000 simulations.:  87%|████████▋ | 8682/10000 [00:58<00:08, 148.47it/s]Running 10000 simulations.:  87%|████████▋ | 8697/10000 [00:58<00:08, 148.21it/s]Running 10000 simulations.:  87%|████████▋ | 8712/10000 [00:59<00:08, 147.54it/s]Running 10000 simulations.:  87%|████████▋ | 8727/10000 [00:59<00:08, 147.29it/s]Running 10000 simulations.:  87%|████████▋ | 8742/10000 [00:59<00:08, 146.91it/s]Running 10000 simulations.:  88%|████████▊ | 8757/10000 [00:59<00:08, 146.94it/s]Running 10000 simulations.:  88%|████████▊ | 8772/10000 [00:59<00:08, 146.20it/s]Running 10000 simulations.:  88%|████████▊ | 8787/10000 [00:59<00:08, 146.45it/s]Running 10000 simulations.:  88%|████████▊ | 8802/10000 [00:59<00:08, 146.00it/s]Running 10000 simulations.:  88%|████████▊ | 8817/10000 [00:59<00:08, 146.38it/s]Running 10000 simulations.:  88%|████████▊ | 8832/10000 [00:59<00:07, 146.12it/s]Running 10000 simulations.:  88%|████████▊ | 8847/10000 [00:59<00:07, 146.36it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [01:00<00:07, 146.62it/s]Running 10000 simulations.:  89%|████████▉ | 8877/10000 [01:00<00:07, 146.13it/s]Running 10000 simulations.:  89%|████████▉ | 8892/10000 [01:00<00:07, 145.26it/s]Running 10000 simulations.:  89%|████████▉ | 8907/10000 [01:00<00:07, 145.40it/s]Running 10000 simulations.:  89%|████████▉ | 8922/10000 [01:00<00:07, 145.44it/s]Running 10000 simulations.:  89%|████████▉ | 8937/10000 [01:00<00:07, 145.69it/s]Running 10000 simulations.:  90%|████████▉ | 8952/10000 [01:00<00:07, 146.04it/s]Running 10000 simulations.:  90%|████████▉ | 8967/10000 [01:00<00:07, 145.75it/s]Running 10000 simulations.:  90%|████████▉ | 8982/10000 [01:00<00:06, 146.10it/s]Running 10000 simulations.:  90%|████████▉ | 8997/10000 [01:00<00:06, 145.42it/s]Running 10000 simulations.:  90%|█████████ | 9012/10000 [01:01<00:06, 145.19it/s]Running 10000 simulations.:  90%|█████████ | 9027/10000 [01:01<00:06, 144.95it/s]Running 10000 simulations.:  90%|█████████ | 9042/10000 [01:01<00:06, 145.31it/s]Running 10000 simulations.:  91%|█████████ | 9057/10000 [01:01<00:06, 145.78it/s]Running 10000 simulations.:  91%|█████████ | 9072/10000 [01:01<00:06, 145.75it/s]Running 10000 simulations.:  91%|█████████ | 9087/10000 [01:01<00:06, 145.77it/s]Running 10000 simulations.:  91%|█████████ | 9102/10000 [01:01<00:06, 145.46it/s]Running 10000 simulations.:  91%|█████████ | 9117/10000 [01:01<00:06, 145.83it/s]Running 10000 simulations.:  91%|█████████▏| 9132/10000 [01:01<00:05, 145.08it/s]Running 10000 simulations.:  91%|█████████▏| 9147/10000 [01:02<00:05, 144.69it/s]Running 10000 simulations.:  92%|█████████▏| 9162/10000 [01:02<00:05, 143.77it/s]Running 10000 simulations.:  92%|█████████▏| 9177/10000 [01:02<00:05, 142.74it/s]Running 10000 simulations.:  92%|█████████▏| 9192/10000 [01:02<00:05, 142.01it/s]Running 10000 simulations.:  92%|█████████▏| 9207/10000 [01:02<00:05, 142.11it/s]Running 10000 simulations.:  92%|█████████▏| 9222/10000 [01:02<00:05, 142.32it/s]Running 10000 simulations.:  92%|█████████▏| 9237/10000 [01:02<00:05, 141.56it/s]Running 10000 simulations.:  93%|█████████▎| 9252/10000 [01:02<00:05, 140.85it/s]Running 10000 simulations.:  93%|█████████▎| 9267/10000 [01:02<00:05, 140.66it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [01:02<00:05, 140.45it/s]Running 10000 simulations.:  93%|█████████▎| 9297/10000 [01:03<00:05, 140.45it/s]Running 10000 simulations.:  93%|█████████▎| 9312/10000 [01:03<00:04, 140.55it/s]Running 10000 simulations.:  93%|█████████▎| 9327/10000 [01:03<00:04, 140.72it/s]Running 10000 simulations.:  93%|█████████▎| 9342/10000 [01:03<00:04, 140.07it/s]Running 10000 simulations.:  94%|█████████▎| 9357/10000 [01:03<00:04, 140.19it/s]Running 10000 simulations.:  94%|█████████▎| 9372/10000 [01:03<00:04, 140.05it/s]Running 10000 simulations.:  94%|█████████▍| 9387/10000 [01:03<00:04, 140.14it/s]Running 10000 simulations.:  94%|█████████▍| 9402/10000 [01:03<00:04, 139.81it/s]Running 10000 simulations.:  94%|█████████▍| 9417/10000 [01:03<00:04, 139.94it/s]Running 10000 simulations.:  94%|█████████▍| 9432/10000 [01:04<00:04, 140.39it/s]Running 10000 simulations.:  94%|█████████▍| 9447/10000 [01:04<00:03, 140.66it/s]Running 10000 simulations.:  95%|█████████▍| 9462/10000 [01:04<00:03, 141.43it/s]Running 10000 simulations.:  95%|█████████▍| 9477/10000 [01:04<00:03, 142.32it/s]Running 10000 simulations.:  95%|█████████▍| 9492/10000 [01:04<00:03, 142.34it/s]Running 10000 simulations.:  95%|█████████▌| 9507/10000 [01:04<00:03, 142.40it/s]Running 10000 simulations.:  95%|█████████▌| 9522/10000 [01:04<00:03, 142.59it/s]Running 10000 simulations.:  95%|█████████▌| 9537/10000 [01:04<00:03, 142.83it/s]Running 10000 simulations.:  96%|█████████▌| 9552/10000 [01:04<00:03, 142.86it/s]Running 10000 simulations.:  96%|█████████▌| 9567/10000 [01:04<00:03, 142.71it/s]Running 10000 simulations.:  96%|█████████▌| 9582/10000 [01:05<00:02, 143.05it/s]Running 10000 simulations.:  96%|█████████▌| 9597/10000 [01:05<00:02, 143.42it/s]Running 10000 simulations.:  96%|█████████▌| 9612/10000 [01:05<00:02, 143.98it/s]Running 10000 simulations.:  96%|█████████▋| 9627/10000 [01:05<00:02, 143.78it/s]Running 10000 simulations.:  96%|█████████▋| 9642/10000 [01:05<00:02, 144.22it/s]Running 10000 simulations.:  97%|█████████▋| 9657/10000 [01:05<00:02, 144.25it/s]Running 10000 simulations.:  97%|█████████▋| 9672/10000 [01:05<00:02, 144.43it/s]Running 10000 simulations.:  97%|█████████▋| 9687/10000 [01:05<00:02, 144.87it/s]Running 10000 simulations.:  97%|█████████▋| 9702/10000 [01:05<00:02, 144.88it/s]Running 10000 simulations.:  97%|█████████▋| 9717/10000 [01:06<00:01, 145.46it/s]Running 10000 simulations.:  97%|█████████▋| 9732/10000 [01:06<00:01, 145.80it/s]Running 10000 simulations.:  97%|█████████▋| 9747/10000 [01:06<00:01, 145.92it/s]Running 10000 simulations.:  98%|█████████▊| 9762/10000 [01:06<00:01, 145.81it/s]Running 10000 simulations.:  98%|█████████▊| 9777/10000 [01:06<00:01, 145.58it/s]Running 10000 simulations.:  98%|█████████▊| 9792/10000 [01:06<00:01, 145.97it/s]Running 10000 simulations.:  98%|█████████▊| 9807/10000 [01:06<00:01, 146.10it/s]Running 10000 simulations.:  98%|█████████▊| 9822/10000 [01:06<00:01, 146.52it/s]Running 10000 simulations.:  98%|█████████▊| 9837/10000 [01:06<00:01, 146.23it/s]Running 10000 simulations.:  99%|█████████▊| 9852/10000 [01:06<00:01, 145.98it/s]Running 10000 simulations.:  99%|█████████▊| 9867/10000 [01:07<00:00, 146.02it/s]Running 10000 simulations.:  99%|█████████▉| 9882/10000 [01:07<00:00, 145.83it/s]Running 10000 simulations.:  99%|█████████▉| 9897/10000 [01:07<00:00, 146.05it/s]Running 10000 simulations.:  99%|█████████▉| 9912/10000 [01:07<00:00, 146.50it/s]Running 10000 simulations.:  99%|█████████▉| 9927/10000 [01:07<00:00, 146.43it/s]Running 10000 simulations.:  99%|█████████▉| 9942/10000 [01:07<00:00, 146.02it/s]Running 10000 simulations.: 100%|█████████▉| 9957/10000 [01:07<00:00, 145.63it/s]Running 10000 simulations.: 100%|█████████▉| 9972/10000 [01:07<00:00, 145.30it/s]Running 10000 simulations.: 100%|█████████▉| 9987/10000 [01:07<00:00, 144.73it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:07<00:00, 147.15it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 16/10000 [00:00<01:05, 152.51it/s]Running 10000 simulations.:   0%|          | 32/10000 [00:00<01:05, 152.14it/s]Running 10000 simulations.:   0%|          | 48/10000 [00:00<01:05, 151.58it/s]Running 10000 simulations.:   1%|          | 64/10000 [00:00<01:05, 151.81it/s]Running 10000 simulations.:   1%|          | 80/10000 [00:00<01:05, 151.98it/s]Running 10000 simulations.:   1%|          | 97/10000 [00:00<01:03, 156.85it/s]Running 10000 simulations.:   1%|          | 115/10000 [00:00<01:01, 161.71it/s]Running 10000 simulations.:   1%|▏         | 131/10000 [00:00<01:02, 158.52it/s]Running 10000 simulations.:   1%|▏         | 147/10000 [00:00<01:03, 155.66it/s]Running 10000 simulations.:   2%|▏         | 163/10000 [00:01<01:03, 154.87it/s]Running 10000 simulations.:   2%|▏         | 179/10000 [00:01<01:03, 154.39it/s]Running 10000 simulations.:   2%|▏         | 195/10000 [00:01<01:03, 153.90it/s]Running 10000 simulations.:   2%|▏         | 211/10000 [00:01<01:03, 153.91it/s]Running 10000 simulations.:   2%|▏         | 227/10000 [00:01<01:04, 151.99it/s]Running 10000 simulations.:   2%|▏         | 243/10000 [00:01<01:05, 150.07it/s]Running 10000 simulations.:   3%|▎         | 258/10000 [00:01<01:05, 149.07it/s]Running 10000 simulations.:   3%|▎         | 273/10000 [00:01<01:05, 148.08it/s]Running 10000 simulations.:   3%|▎         | 288/10000 [00:01<01:05, 147.38it/s]Running 10000 simulations.:   3%|▎         | 303/10000 [00:01<01:05, 147.18it/s]Running 10000 simulations.:   3%|▎         | 318/10000 [00:02<01:06, 146.67it/s]Running 10000 simulations.:   3%|▎         | 333/10000 [00:02<01:05, 147.19it/s]Running 10000 simulations.:   3%|▎         | 348/10000 [00:02<01:05, 147.92it/s]Running 10000 simulations.:   4%|▎         | 363/10000 [00:02<01:05, 147.98it/s]Running 10000 simulations.:   4%|▍         | 378/10000 [00:02<01:04, 148.57it/s]Running 10000 simulations.:   4%|▍         | 393/10000 [00:02<01:04, 148.49it/s]Running 10000 simulations.:   4%|▍         | 408/10000 [00:02<01:05, 147.23it/s]Running 10000 simulations.:   4%|▍         | 423/10000 [00:02<01:05, 146.96it/s]Running 10000 simulations.:   4%|▍         | 438/10000 [00:02<01:05, 146.20it/s]Running 10000 simulations.:   5%|▍         | 453/10000 [00:03<01:05, 145.60it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:03<01:05, 146.51it/s]Running 10000 simulations.:   5%|▍         | 483/10000 [00:03<01:04, 146.74it/s]Running 10000 simulations.:   5%|▍         | 498/10000 [00:03<01:04, 147.32it/s]Running 10000 simulations.:   5%|▌         | 513/10000 [00:03<01:04, 147.42it/s]Running 10000 simulations.:   5%|▌         | 528/10000 [00:03<01:04, 146.46it/s]Running 10000 simulations.:   5%|▌         | 543/10000 [00:03<01:04, 146.56it/s]Running 10000 simulations.:   6%|▌         | 558/10000 [00:03<01:04, 147.12it/s]Running 10000 simulations.:   6%|▌         | 573/10000 [00:03<01:04, 147.23it/s]Running 10000 simulations.:   6%|▌         | 588/10000 [00:03<01:03, 147.76it/s]Running 10000 simulations.:   6%|▌         | 603/10000 [00:04<01:04, 145.64it/s]Running 10000 simulations.:   6%|▌         | 618/10000 [00:04<01:04, 146.18it/s]Running 10000 simulations.:   6%|▋         | 633/10000 [00:04<01:03, 146.68it/s]Running 10000 simulations.:   6%|▋         | 648/10000 [00:04<01:03, 146.52it/s]Running 10000 simulations.:   7%|▋         | 663/10000 [00:04<01:03, 145.99it/s]Running 10000 simulations.:   7%|▋         | 679/10000 [00:04<01:03, 147.08it/s]Running 10000 simulations.:   7%|▋         | 695/10000 [00:04<01:02, 148.15it/s]Running 10000 simulations.:   7%|▋         | 710/10000 [00:04<01:02, 148.49it/s]Running 10000 simulations.:   7%|▋         | 725/10000 [00:04<01:02, 148.54it/s]Running 10000 simulations.:   7%|▋         | 740/10000 [00:04<01:03, 146.92it/s]Running 10000 simulations.:   8%|▊         | 755/10000 [00:05<01:03, 146.03it/s]Running 10000 simulations.:   8%|▊         | 770/10000 [00:05<01:03, 144.33it/s]Running 10000 simulations.:   8%|▊         | 785/10000 [00:05<01:04, 143.82it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:05<01:04, 142.80it/s]Running 10000 simulations.:   8%|▊         | 815/10000 [00:05<01:04, 142.15it/s]Running 10000 simulations.:   8%|▊         | 830/10000 [00:05<01:04, 141.54it/s]Running 10000 simulations.:   8%|▊         | 845/10000 [00:05<01:04, 141.13it/s]Running 10000 simulations.:   9%|▊         | 860/10000 [00:05<01:04, 140.76it/s]Running 10000 simulations.:   9%|▉         | 875/10000 [00:05<01:04, 140.67it/s]Running 10000 simulations.:   9%|▉         | 890/10000 [00:06<01:04, 140.23it/s]Running 10000 simulations.:   9%|▉         | 905/10000 [00:06<01:05, 139.38it/s]Running 10000 simulations.:   9%|▉         | 919/10000 [00:06<01:05, 139.10it/s]Running 10000 simulations.:   9%|▉         | 933/10000 [00:06<01:05, 138.80it/s]Running 10000 simulations.:   9%|▉         | 947/10000 [00:06<01:09, 130.73it/s]Running 10000 simulations.:  10%|▉         | 962/10000 [00:06<01:07, 133.49it/s]Running 10000 simulations.:  10%|▉         | 977/10000 [00:06<01:06, 135.53it/s]Running 10000 simulations.:  10%|▉         | 992/10000 [00:06<01:05, 137.28it/s]Running 10000 simulations.:  10%|█         | 1006/10000 [00:06<01:05, 137.59it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:06<01:05, 137.99it/s]Running 10000 simulations.:  10%|█         | 1034/10000 [00:07<01:04, 138.36it/s]Running 10000 simulations.:  10%|█         | 1048/10000 [00:07<01:04, 138.74it/s]Running 10000 simulations.:  11%|█         | 1062/10000 [00:07<01:04, 138.50it/s]Running 10000 simulations.:  11%|█         | 1076/10000 [00:07<01:04, 138.93it/s]Running 10000 simulations.:  11%|█         | 1091/10000 [00:07<01:03, 139.63it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:07<01:03, 140.05it/s]Running 10000 simulations.:  11%|█         | 1121/10000 [00:07<01:03, 140.52it/s]Running 10000 simulations.:  11%|█▏        | 1136/10000 [00:07<01:03, 139.78it/s]Running 10000 simulations.:  12%|█▏        | 1150/10000 [00:07<01:03, 139.57it/s]Running 10000 simulations.:  12%|█▏        | 1164/10000 [00:08<01:03, 139.39it/s]Running 10000 simulations.:  12%|█▏        | 1178/10000 [00:08<01:03, 139.39it/s]Running 10000 simulations.:  12%|█▏        | 1192/10000 [00:08<01:03, 139.28it/s]Running 10000 simulations.:  12%|█▏        | 1206/10000 [00:08<01:03, 139.46it/s]Running 10000 simulations.:  12%|█▏        | 1221/10000 [00:08<01:02, 139.62it/s]Running 10000 simulations.:  12%|█▏        | 1236/10000 [00:08<01:02, 140.15it/s]Running 10000 simulations.:  13%|█▎        | 1251/10000 [00:08<01:01, 141.15it/s]Running 10000 simulations.:  13%|█▎        | 1266/10000 [00:08<01:01, 141.33it/s]Running 10000 simulations.:  13%|█▎        | 1281/10000 [00:08<01:01, 141.01it/s]Running 10000 simulations.:  13%|█▎        | 1296/10000 [00:08<01:01, 140.44it/s]Running 10000 simulations.:  13%|█▎        | 1311/10000 [00:09<01:01, 140.16it/s]Running 10000 simulations.:  13%|█▎        | 1326/10000 [00:09<01:02, 139.72it/s]Running 10000 simulations.:  13%|█▎        | 1341/10000 [00:09<01:01, 140.53it/s]Running 10000 simulations.:  14%|█▎        | 1356/10000 [00:09<01:01, 140.57it/s]Running 10000 simulations.:  14%|█▎        | 1371/10000 [00:09<01:01, 140.66it/s]Running 10000 simulations.:  14%|█▍        | 1386/10000 [00:09<01:01, 139.62it/s]Running 10000 simulations.:  14%|█▍        | 1400/10000 [00:09<01:01, 139.02it/s]Running 10000 simulations.:  14%|█▍        | 1414/10000 [00:09<01:01, 138.65it/s]Running 10000 simulations.:  14%|█▍        | 1428/10000 [00:09<01:01, 138.57it/s]Running 10000 simulations.:  14%|█▍        | 1442/10000 [00:09<01:01, 138.84it/s]Running 10000 simulations.:  15%|█▍        | 1456/10000 [00:10<01:01, 138.44it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:10<01:01, 138.16it/s]Running 10000 simulations.:  15%|█▍        | 1485/10000 [00:10<01:01, 138.72it/s]Running 10000 simulations.:  15%|█▍        | 1499/10000 [00:10<01:01, 139.02it/s]Running 10000 simulations.:  15%|█▌        | 1513/10000 [00:10<01:00, 139.13it/s]Running 10000 simulations.:  15%|█▌        | 1527/10000 [00:10<01:00, 139.37it/s]Running 10000 simulations.:  15%|█▌        | 1542/10000 [00:10<01:00, 139.88it/s]Running 10000 simulations.:  16%|█▌        | 1556/10000 [00:10<01:00, 139.17it/s]Running 10000 simulations.:  16%|█▌        | 1570/10000 [00:10<01:00, 138.89it/s]Running 10000 simulations.:  16%|█▌        | 1584/10000 [00:11<01:00, 139.17it/s]Running 10000 simulations.:  16%|█▌        | 1598/10000 [00:11<01:00, 138.97it/s]Running 10000 simulations.:  16%|█▌        | 1612/10000 [00:11<01:00, 138.42it/s]Running 10000 simulations.:  16%|█▋        | 1626/10000 [00:11<01:00, 138.87it/s]Running 10000 simulations.:  16%|█▋        | 1640/10000 [00:11<01:00, 139.04it/s]Running 10000 simulations.:  17%|█▋        | 1654/10000 [00:11<01:00, 138.60it/s]Running 10000 simulations.:  17%|█▋        | 1668/10000 [00:11<01:00, 138.26it/s]Running 10000 simulations.:  17%|█▋        | 1682/10000 [00:11<01:00, 138.49it/s]Running 10000 simulations.:  17%|█▋        | 1696/10000 [00:11<00:59, 138.52it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:11<00:59, 138.76it/s]Running 10000 simulations.:  17%|█▋        | 1724/10000 [00:12<00:59, 139.05it/s]Running 10000 simulations.:  17%|█▋        | 1738/10000 [00:12<00:59, 139.07it/s]Running 10000 simulations.:  18%|█▊        | 1753/10000 [00:12<00:58, 140.22it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:12<00:56, 146.14it/s]Running 10000 simulations.:  18%|█▊        | 1787/10000 [00:12<00:54, 150.52it/s]Running 10000 simulations.:  18%|█▊        | 1803/10000 [00:12<00:55, 146.42it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:12<00:56, 143.81it/s]Running 10000 simulations.:  18%|█▊        | 1833/10000 [00:12<00:57, 141.79it/s]Running 10000 simulations.:  18%|█▊        | 1848/10000 [00:12<00:58, 140.52it/s]Running 10000 simulations.:  19%|█▊        | 1863/10000 [00:12<00:57, 140.76it/s]Running 10000 simulations.:  19%|█▉        | 1878/10000 [00:13<00:57, 141.45it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:13<00:57, 140.52it/s]Running 10000 simulations.:  19%|█▉        | 1908/10000 [00:13<00:57, 139.60it/s]Running 10000 simulations.:  19%|█▉        | 1922/10000 [00:13<00:58, 139.16it/s]Running 10000 simulations.:  19%|█▉        | 1936/10000 [00:13<00:57, 139.37it/s]Running 10000 simulations.:  20%|█▉        | 1951/10000 [00:13<00:57, 139.65it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:13<00:57, 139.65it/s]Running 10000 simulations.:  20%|█▉        | 1979/10000 [00:13<00:57, 139.51it/s]Running 10000 simulations.:  20%|█▉        | 1993/10000 [00:13<00:57, 139.18it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:14<00:57, 139.72it/s]Running 10000 simulations.:  20%|██        | 2022/10000 [00:14<00:57, 138.88it/s]Running 10000 simulations.:  20%|██        | 2036/10000 [00:14<00:57, 138.54it/s]Running 10000 simulations.:  20%|██        | 2050/10000 [00:14<00:57, 138.08it/s]Running 10000 simulations.:  21%|██        | 2064/10000 [00:14<00:57, 137.98it/s]Running 10000 simulations.:  21%|██        | 2078/10000 [00:14<00:57, 137.74it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:14<00:57, 137.55it/s]Running 10000 simulations.:  21%|██        | 2107/10000 [00:14<00:57, 138.46it/s]Running 10000 simulations.:  21%|██        | 2121/10000 [00:14<00:56, 138.39it/s]Running 10000 simulations.:  21%|██▏       | 2135/10000 [00:14<00:56, 138.71it/s]Running 10000 simulations.:  21%|██▏       | 2149/10000 [00:15<00:56, 138.90it/s]Running 10000 simulations.:  22%|██▏       | 2163/10000 [00:15<00:56, 138.70it/s]Running 10000 simulations.:  22%|██▏       | 2177/10000 [00:15<00:56, 138.57it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:15<00:56, 138.48it/s]Running 10000 simulations.:  22%|██▏       | 2205/10000 [00:15<00:56, 138.14it/s]Running 10000 simulations.:  22%|██▏       | 2219/10000 [00:15<00:56, 137.99it/s]Running 10000 simulations.:  22%|██▏       | 2233/10000 [00:15<00:56, 137.91it/s]Running 10000 simulations.:  22%|██▏       | 2247/10000 [00:15<00:56, 138.26it/s]Running 10000 simulations.:  23%|██▎       | 2261/10000 [00:15<00:55, 138.51it/s]Running 10000 simulations.:  23%|██▎       | 2275/10000 [00:15<00:55, 138.93it/s]Running 10000 simulations.:  23%|██▎       | 2289/10000 [00:16<00:55, 139.06it/s]Running 10000 simulations.:  23%|██▎       | 2304/10000 [00:16<00:55, 139.59it/s]Running 10000 simulations.:  23%|██▎       | 2319/10000 [00:16<00:54, 139.79it/s]Running 10000 simulations.:  23%|██▎       | 2333/10000 [00:16<00:55, 138.72it/s]Running 10000 simulations.:  23%|██▎       | 2347/10000 [00:16<00:55, 138.20it/s]Running 10000 simulations.:  24%|██▎       | 2361/10000 [00:16<00:55, 137.85it/s]Running 10000 simulations.:  24%|██▍       | 2375/10000 [00:16<00:55, 137.45it/s]Running 10000 simulations.:  24%|██▍       | 2389/10000 [00:16<00:55, 137.33it/s]Running 10000 simulations.:  24%|██▍       | 2403/10000 [00:16<00:55, 137.86it/s]Running 10000 simulations.:  24%|██▍       | 2417/10000 [00:16<00:54, 138.43it/s]Running 10000 simulations.:  24%|██▍       | 2431/10000 [00:17<00:56, 134.84it/s]Running 10000 simulations.:  24%|██▍       | 2446/10000 [00:17<00:55, 135.40it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:17<00:55, 136.45it/s]Running 10000 simulations.:  25%|██▍       | 2474/10000 [00:17<00:54, 137.21it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:17<00:54, 137.28it/s]Running 10000 simulations.:  25%|██▌       | 2502/10000 [00:17<00:54, 137.68it/s]Running 10000 simulations.:  25%|██▌       | 2516/10000 [00:17<00:54, 137.68it/s]Running 10000 simulations.:  25%|██▌       | 2530/10000 [00:17<00:54, 137.82it/s]Running 10000 simulations.:  25%|██▌       | 2544/10000 [00:17<00:54, 137.97it/s]Running 10000 simulations.:  26%|██▌       | 2558/10000 [00:18<00:53, 138.05it/s]Running 10000 simulations.:  26%|██▌       | 2572/10000 [00:18<00:53, 138.37it/s]Running 10000 simulations.:  26%|██▌       | 2586/10000 [00:18<00:53, 137.41it/s]Running 10000 simulations.:  26%|██▌       | 2600/10000 [00:18<00:54, 137.01it/s]Running 10000 simulations.:  26%|██▌       | 2614/10000 [00:18<00:53, 137.22it/s]Running 10000 simulations.:  26%|██▋       | 2628/10000 [00:18<00:53, 136.93it/s]Running 10000 simulations.:  26%|██▋       | 2642/10000 [00:18<00:53, 136.69it/s]Running 10000 simulations.:  27%|██▋       | 2656/10000 [00:18<00:53, 137.57it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:18<00:53, 138.26it/s]Running 10000 simulations.:  27%|██▋       | 2684/10000 [00:18<00:52, 138.52it/s]Running 10000 simulations.:  27%|██▋       | 2698/10000 [00:19<00:52, 138.31it/s]Running 10000 simulations.:  27%|██▋       | 2712/10000 [00:19<00:52, 138.05it/s]Running 10000 simulations.:  27%|██▋       | 2726/10000 [00:19<00:52, 137.87it/s]Running 10000 simulations.:  27%|██▋       | 2740/10000 [00:19<00:52, 137.40it/s]Running 10000 simulations.:  28%|██▊       | 2754/10000 [00:19<00:52, 137.01it/s]Running 10000 simulations.:  28%|██▊       | 2768/10000 [00:19<00:52, 136.68it/s]Running 10000 simulations.:  28%|██▊       | 2782/10000 [00:19<00:52, 136.96it/s]Running 10000 simulations.:  28%|██▊       | 2796/10000 [00:19<00:52, 137.74it/s]Running 10000 simulations.:  28%|██▊       | 2810/10000 [00:19<00:52, 138.08it/s]Running 10000 simulations.:  28%|██▊       | 2824/10000 [00:19<00:52, 137.22it/s]Running 10000 simulations.:  28%|██▊       | 2838/10000 [00:20<00:52, 136.82it/s]Running 10000 simulations.:  29%|██▊       | 2852/10000 [00:20<00:52, 136.89it/s]Running 10000 simulations.:  29%|██▊       | 2866/10000 [00:20<00:51, 137.37it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:20<00:51, 137.79it/s]Running 10000 simulations.:  29%|██▉       | 2894/10000 [00:20<00:51, 137.93it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:20<00:51, 137.73it/s]Running 10000 simulations.:  29%|██▉       | 2922/10000 [00:20<00:51, 137.61it/s]Running 10000 simulations.:  29%|██▉       | 2936/10000 [00:20<00:51, 137.11it/s]Running 10000 simulations.:  30%|██▉       | 2950/10000 [00:20<00:51, 137.12it/s]Running 10000 simulations.:  30%|██▉       | 2964/10000 [00:20<00:51, 137.48it/s]Running 10000 simulations.:  30%|██▉       | 2979/10000 [00:21<00:50, 138.51it/s]Running 10000 simulations.:  30%|██▉       | 2993/10000 [00:21<00:50, 138.93it/s]Running 10000 simulations.:  30%|███       | 3007/10000 [00:21<00:50, 139.14it/s]Running 10000 simulations.:  30%|███       | 3021/10000 [00:21<00:50, 138.80it/s]Running 10000 simulations.:  30%|███       | 3035/10000 [00:21<00:50, 138.33it/s]Running 10000 simulations.:  30%|███       | 3049/10000 [00:21<00:50, 138.63it/s]Running 10000 simulations.:  31%|███       | 3063/10000 [00:21<00:50, 138.09it/s]Running 10000 simulations.:  31%|███       | 3077/10000 [00:21<00:50, 137.68it/s]Running 10000 simulations.:  31%|███       | 3091/10000 [00:21<00:50, 137.80it/s]Running 10000 simulations.:  31%|███       | 3105/10000 [00:21<00:50, 137.71it/s]Running 10000 simulations.:  31%|███       | 3119/10000 [00:22<00:49, 138.05it/s]Running 10000 simulations.:  31%|███▏      | 3133/10000 [00:22<00:49, 138.13it/s]Running 10000 simulations.:  31%|███▏      | 3147/10000 [00:22<00:49, 138.21it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:22<00:49, 138.03it/s]Running 10000 simulations.:  32%|███▏      | 3175/10000 [00:22<00:49, 137.67it/s]Running 10000 simulations.:  32%|███▏      | 3189/10000 [00:22<00:49, 137.34it/s]Running 10000 simulations.:  32%|███▏      | 3203/10000 [00:22<00:49, 137.48it/s]Running 10000 simulations.:  32%|███▏      | 3217/10000 [00:22<00:49, 137.25it/s]Running 10000 simulations.:  32%|███▏      | 3231/10000 [00:22<00:49, 137.27it/s]Running 10000 simulations.:  32%|███▏      | 3245/10000 [00:23<00:49, 137.54it/s]Running 10000 simulations.:  33%|███▎      | 3259/10000 [00:23<00:48, 137.87it/s]Running 10000 simulations.:  33%|███▎      | 3273/10000 [00:23<00:48, 138.12it/s]Running 10000 simulations.:  33%|███▎      | 3287/10000 [00:23<00:48, 138.18it/s]Running 10000 simulations.:  33%|███▎      | 3301/10000 [00:23<00:48, 137.81it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:23<00:48, 137.44it/s]Running 10000 simulations.:  33%|███▎      | 3329/10000 [00:23<00:48, 136.95it/s]Running 10000 simulations.:  33%|███▎      | 3343/10000 [00:23<00:48, 136.71it/s]Running 10000 simulations.:  34%|███▎      | 3357/10000 [00:23<00:48, 137.05it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:23<00:48, 137.73it/s]Running 10000 simulations.:  34%|███▍      | 3385/10000 [00:24<00:47, 138.01it/s]Running 10000 simulations.:  34%|███▍      | 3399/10000 [00:24<00:47, 138.35it/s]Running 10000 simulations.:  34%|███▍      | 3414/10000 [00:24<00:47, 138.89it/s]Running 10000 simulations.:  34%|███▍      | 3428/10000 [00:24<00:47, 138.15it/s]Running 10000 simulations.:  34%|███▍      | 3442/10000 [00:24<00:47, 136.73it/s]Running 10000 simulations.:  35%|███▍      | 3456/10000 [00:24<00:48, 136.06it/s]Running 10000 simulations.:  35%|███▍      | 3470/10000 [00:24<00:48, 135.81it/s]Running 10000 simulations.:  35%|███▍      | 3484/10000 [00:24<00:47, 136.50it/s]Running 10000 simulations.:  35%|███▍      | 3498/10000 [00:24<00:47, 137.23it/s]Running 10000 simulations.:  35%|███▌      | 3513/10000 [00:24<00:46, 138.06it/s]Running 10000 simulations.:  35%|███▌      | 3529/10000 [00:25<00:45, 142.76it/s]Running 10000 simulations.:  35%|███▌      | 3545/10000 [00:25<00:43, 147.40it/s]Running 10000 simulations.:  36%|███▌      | 3561/10000 [00:25<00:43, 149.46it/s]Running 10000 simulations.:  36%|███▌      | 3577/10000 [00:25<00:44, 145.43it/s]Running 10000 simulations.:  36%|███▌      | 3592/10000 [00:25<00:44, 142.69it/s]Running 10000 simulations.:  36%|███▌      | 3607/10000 [00:25<00:45, 140.79it/s]Running 10000 simulations.:  36%|███▌      | 3622/10000 [00:25<00:45, 139.99it/s]Running 10000 simulations.:  36%|███▋      | 3637/10000 [00:25<00:45, 139.74it/s]Running 10000 simulations.:  37%|███▋      | 3651/10000 [00:25<00:45, 139.56it/s]Running 10000 simulations.:  37%|███▋      | 3665/10000 [00:26<00:45, 139.01it/s]Running 10000 simulations.:  37%|███▋      | 3679/10000 [00:26<00:45, 138.70it/s]Running 10000 simulations.:  37%|███▋      | 3693/10000 [00:26<00:45, 138.50it/s]Running 10000 simulations.:  37%|███▋      | 3707/10000 [00:26<00:45, 138.44it/s]Running 10000 simulations.:  37%|███▋      | 3721/10000 [00:26<00:45, 138.30it/s]Running 10000 simulations.:  37%|███▋      | 3735/10000 [00:26<00:45, 137.68it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:26<00:45, 137.37it/s]Running 10000 simulations.:  38%|███▊      | 3763/10000 [00:26<00:45, 137.80it/s]Running 10000 simulations.:  38%|███▊      | 3777/10000 [00:26<00:45, 137.98it/s]Running 10000 simulations.:  38%|███▊      | 3791/10000 [00:26<00:44, 138.27it/s]Running 10000 simulations.:  38%|███▊      | 3805/10000 [00:27<00:44, 138.48it/s]Running 10000 simulations.:  38%|███▊      | 3819/10000 [00:27<00:44, 138.15it/s]Running 10000 simulations.:  38%|███▊      | 3833/10000 [00:27<00:44, 137.67it/s]Running 10000 simulations.:  38%|███▊      | 3847/10000 [00:27<00:44, 137.49it/s]Running 10000 simulations.:  39%|███▊      | 3861/10000 [00:27<00:44, 137.11it/s]Running 10000 simulations.:  39%|███▉      | 3875/10000 [00:27<00:44, 137.55it/s]Running 10000 simulations.:  39%|███▉      | 3889/10000 [00:27<00:44, 137.47it/s]Running 10000 simulations.:  39%|███▉      | 3903/10000 [00:27<00:44, 137.67it/s]Running 10000 simulations.:  39%|███▉      | 3917/10000 [00:27<00:44, 136.67it/s]Running 10000 simulations.:  39%|███▉      | 3931/10000 [00:27<00:44, 136.37it/s]Running 10000 simulations.:  39%|███▉      | 3945/10000 [00:28<00:44, 137.22it/s]Running 10000 simulations.:  40%|███▉      | 3959/10000 [00:28<00:43, 137.61it/s]Running 10000 simulations.:  40%|███▉      | 3973/10000 [00:28<00:43, 137.72it/s]Running 10000 simulations.:  40%|███▉      | 3987/10000 [00:28<00:43, 137.95it/s]Running 10000 simulations.:  40%|████      | 4001/10000 [00:28<00:43, 137.57it/s]Running 10000 simulations.:  40%|████      | 4015/10000 [00:28<00:43, 136.74it/s]Running 10000 simulations.:  40%|████      | 4029/10000 [00:28<00:43, 136.81it/s]Running 10000 simulations.:  40%|████      | 4043/10000 [00:28<00:43, 136.49it/s]Running 10000 simulations.:  41%|████      | 4057/10000 [00:28<00:43, 136.14it/s]Running 10000 simulations.:  41%|████      | 4071/10000 [00:28<00:43, 136.21it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:29<00:43, 136.32it/s]Running 10000 simulations.:  41%|████      | 4099/10000 [00:29<00:43, 136.66it/s]Running 10000 simulations.:  41%|████      | 4113/10000 [00:29<00:43, 136.53it/s]Running 10000 simulations.:  41%|████▏     | 4127/10000 [00:29<00:42, 136.59it/s]Running 10000 simulations.:  41%|████▏     | 4141/10000 [00:29<00:42, 136.64it/s]Running 10000 simulations.:  42%|████▏     | 4155/10000 [00:29<00:42, 136.30it/s]Running 10000 simulations.:  42%|████▏     | 4169/10000 [00:29<00:42, 135.64it/s]Running 10000 simulations.:  42%|████▏     | 4183/10000 [00:29<00:43, 134.73it/s]Running 10000 simulations.:  42%|████▏     | 4197/10000 [00:29<00:43, 134.53it/s]Running 10000 simulations.:  42%|████▏     | 4211/10000 [00:30<00:43, 133.94it/s]Running 10000 simulations.:  42%|████▏     | 4225/10000 [00:30<00:42, 134.51it/s]Running 10000 simulations.:  42%|████▏     | 4240/10000 [00:30<00:42, 136.72it/s]Running 10000 simulations.:  43%|████▎     | 4255/10000 [00:30<00:41, 138.52it/s]Running 10000 simulations.:  43%|████▎     | 4270/10000 [00:30<00:40, 140.16it/s]Running 10000 simulations.:  43%|████▎     | 4285/10000 [00:30<00:40, 140.81it/s]Running 10000 simulations.:  43%|████▎     | 4300/10000 [00:30<00:40, 141.36it/s]Running 10000 simulations.:  43%|████▎     | 4315/10000 [00:30<00:40, 141.93it/s]Running 10000 simulations.:  43%|████▎     | 4330/10000 [00:30<00:39, 142.36it/s]Running 10000 simulations.:  43%|████▎     | 4345/10000 [00:30<00:39, 142.67it/s]Running 10000 simulations.:  44%|████▎     | 4360/10000 [00:31<00:39, 142.84it/s]Running 10000 simulations.:  44%|████▍     | 4375/10000 [00:31<00:39, 143.19it/s]Running 10000 simulations.:  44%|████▍     | 4390/10000 [00:31<00:39, 143.17it/s]Running 10000 simulations.:  44%|████▍     | 4405/10000 [00:31<00:39, 143.38it/s]Running 10000 simulations.:  44%|████▍     | 4420/10000 [00:31<00:38, 143.34it/s]Running 10000 simulations.:  44%|████▍     | 4435/10000 [00:31<00:38, 143.20it/s]Running 10000 simulations.:  44%|████▍     | 4450/10000 [00:31<00:38, 143.05it/s]Running 10000 simulations.:  45%|████▍     | 4465/10000 [00:31<00:38, 143.28it/s]Running 10000 simulations.:  45%|████▍     | 4480/10000 [00:31<00:38, 143.27it/s]Running 10000 simulations.:  45%|████▍     | 4495/10000 [00:32<00:38, 143.07it/s]Running 10000 simulations.:  45%|████▌     | 4510/10000 [00:32<00:38, 143.14it/s]Running 10000 simulations.:  45%|████▌     | 4525/10000 [00:32<00:38, 143.01it/s]Running 10000 simulations.:  45%|████▌     | 4540/10000 [00:32<00:38, 143.57it/s]Running 10000 simulations.:  46%|████▌     | 4555/10000 [00:32<00:37, 144.55it/s]Running 10000 simulations.:  46%|████▌     | 4570/10000 [00:32<00:37, 144.65it/s]Running 10000 simulations.:  46%|████▌     | 4585/10000 [00:32<00:37, 144.41it/s]Running 10000 simulations.:  46%|████▌     | 4600/10000 [00:32<00:37, 144.77it/s]Running 10000 simulations.:  46%|████▌     | 4615/10000 [00:32<00:37, 144.54it/s]Running 10000 simulations.:  46%|████▋     | 4630/10000 [00:32<00:37, 144.14it/s]Running 10000 simulations.:  46%|████▋     | 4645/10000 [00:33<00:37, 143.72it/s]Running 10000 simulations.:  47%|████▋     | 4660/10000 [00:33<00:37, 143.53it/s]Running 10000 simulations.:  47%|████▋     | 4675/10000 [00:33<00:37, 143.85it/s]Running 10000 simulations.:  47%|████▋     | 4690/10000 [00:33<00:37, 143.51it/s]Running 10000 simulations.:  47%|████▋     | 4705/10000 [00:33<00:36, 143.53it/s]Running 10000 simulations.:  47%|████▋     | 4720/10000 [00:33<00:36, 143.28it/s]Running 10000 simulations.:  47%|████▋     | 4735/10000 [00:33<00:36, 143.07it/s]Running 10000 simulations.:  48%|████▊     | 4750/10000 [00:33<00:36, 143.31it/s]Running 10000 simulations.:  48%|████▊     | 4765/10000 [00:33<00:36, 143.36it/s]Running 10000 simulations.:  48%|████▊     | 4780/10000 [00:33<00:36, 143.00it/s]Running 10000 simulations.:  48%|████▊     | 4795/10000 [00:34<00:36, 143.54it/s]Running 10000 simulations.:  48%|████▊     | 4810/10000 [00:34<00:36, 143.26it/s]Running 10000 simulations.:  48%|████▊     | 4825/10000 [00:34<00:36, 143.12it/s]Running 10000 simulations.:  48%|████▊     | 4840/10000 [00:34<00:35, 143.51it/s]Running 10000 simulations.:  49%|████▊     | 4855/10000 [00:34<00:35, 143.50it/s]Running 10000 simulations.:  49%|████▊     | 4870/10000 [00:34<00:35, 143.33it/s]Running 10000 simulations.:  49%|████▉     | 4885/10000 [00:34<00:35, 143.54it/s]Running 10000 simulations.:  49%|████▉     | 4900/10000 [00:34<00:35, 143.87it/s]Running 10000 simulations.:  49%|████▉     | 4915/10000 [00:34<00:35, 144.16it/s]Running 10000 simulations.:  49%|████▉     | 4930/10000 [00:35<00:35, 144.20it/s]Running 10000 simulations.:  49%|████▉     | 4945/10000 [00:35<00:35, 143.64it/s]Running 10000 simulations.:  50%|████▉     | 4960/10000 [00:35<00:35, 143.41it/s]Running 10000 simulations.:  50%|████▉     | 4975/10000 [00:35<00:35, 143.43it/s]Running 10000 simulations.:  50%|████▉     | 4990/10000 [00:35<00:34, 143.58it/s]Running 10000 simulations.:  50%|█████     | 5005/10000 [00:35<00:34, 143.67it/s]Running 10000 simulations.:  50%|█████     | 5020/10000 [00:35<00:34, 143.95it/s]Running 10000 simulations.:  50%|█████     | 5035/10000 [00:35<00:34, 143.82it/s]Running 10000 simulations.:  50%|█████     | 5050/10000 [00:35<00:34, 143.99it/s]Running 10000 simulations.:  51%|█████     | 5065/10000 [00:35<00:34, 144.53it/s]Running 10000 simulations.:  51%|█████     | 5080/10000 [00:36<00:34, 144.09it/s]Running 10000 simulations.:  51%|█████     | 5095/10000 [00:36<00:34, 143.56it/s]Running 10000 simulations.:  51%|█████     | 5110/10000 [00:36<00:34, 143.27it/s]Running 10000 simulations.:  51%|█████▏    | 5125/10000 [00:36<00:35, 135.49it/s]Running 10000 simulations.:  51%|█████▏    | 5140/10000 [00:36<00:35, 137.45it/s]Running 10000 simulations.:  52%|█████▏    | 5155/10000 [00:36<00:34, 139.09it/s]Running 10000 simulations.:  52%|█████▏    | 5170/10000 [00:36<00:34, 140.17it/s]Running 10000 simulations.:  52%|█████▏    | 5185/10000 [00:36<00:34, 141.25it/s]Running 10000 simulations.:  52%|█████▏    | 5200/10000 [00:36<00:33, 142.36it/s]Running 10000 simulations.:  52%|█████▏    | 5215/10000 [00:37<00:33, 142.62it/s]Running 10000 simulations.:  52%|█████▏    | 5230/10000 [00:37<00:33, 142.37it/s]Running 10000 simulations.:  52%|█████▏    | 5246/10000 [00:37<00:32, 146.70it/s]Running 10000 simulations.:  53%|█████▎    | 5263/10000 [00:37<00:31, 150.46it/s]Running 10000 simulations.:  53%|█████▎    | 5279/10000 [00:37<00:31, 147.62it/s]Running 10000 simulations.:  53%|█████▎    | 5294/10000 [00:37<00:31, 147.12it/s]Running 10000 simulations.:  53%|█████▎    | 5309/10000 [00:37<00:31, 146.83it/s]Running 10000 simulations.:  53%|█████▎    | 5324/10000 [00:37<00:31, 146.62it/s]Running 10000 simulations.:  53%|█████▎    | 5339/10000 [00:37<00:31, 146.25it/s]Running 10000 simulations.:  54%|█████▎    | 5354/10000 [00:37<00:31, 145.93it/s]Running 10000 simulations.:  54%|█████▎    | 5369/10000 [00:38<00:31, 145.67it/s]Running 10000 simulations.:  54%|█████▍    | 5384/10000 [00:38<00:31, 145.58it/s]Running 10000 simulations.:  54%|█████▍    | 5399/10000 [00:38<00:31, 145.50it/s]Running 10000 simulations.:  54%|█████▍    | 5414/10000 [00:38<00:31, 145.61it/s]Running 10000 simulations.:  54%|█████▍    | 5429/10000 [00:38<00:31, 145.89it/s]Running 10000 simulations.:  54%|█████▍    | 5444/10000 [00:38<00:31, 146.10it/s]Running 10000 simulations.:  55%|█████▍    | 5459/10000 [00:38<00:31, 146.20it/s]Running 10000 simulations.:  55%|█████▍    | 5474/10000 [00:38<00:30, 146.10it/s]Running 10000 simulations.:  55%|█████▍    | 5489/10000 [00:38<00:30, 146.07it/s]Running 10000 simulations.:  55%|█████▌    | 5504/10000 [00:39<00:30, 146.38it/s]Running 10000 simulations.:  55%|█████▌    | 5519/10000 [00:39<00:30, 146.27it/s]Running 10000 simulations.:  55%|█████▌    | 5534/10000 [00:39<00:30, 145.68it/s]Running 10000 simulations.:  55%|█████▌    | 5549/10000 [00:39<00:30, 145.20it/s]Running 10000 simulations.:  56%|█████▌    | 5564/10000 [00:39<00:30, 145.10it/s]Running 10000 simulations.:  56%|█████▌    | 5579/10000 [00:39<00:30, 145.14it/s]Running 10000 simulations.:  56%|█████▌    | 5594/10000 [00:39<00:30, 145.30it/s]Running 10000 simulations.:  56%|█████▌    | 5609/10000 [00:39<00:30, 145.76it/s]Running 10000 simulations.:  56%|█████▌    | 5624/10000 [00:39<00:30, 145.54it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:39<00:30, 145.33it/s]Running 10000 simulations.:  57%|█████▋    | 5654/10000 [00:40<00:29, 145.15it/s]Running 10000 simulations.:  57%|█████▋    | 5669/10000 [00:40<00:29, 145.10it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:40<00:29, 145.11it/s]Running 10000 simulations.:  57%|█████▋    | 5699/10000 [00:40<00:29, 145.13it/s]Running 10000 simulations.:  57%|█████▋    | 5714/10000 [00:40<00:29, 145.29it/s]Running 10000 simulations.:  57%|█████▋    | 5729/10000 [00:40<00:29, 145.51it/s]Running 10000 simulations.:  57%|█████▋    | 5744/10000 [00:40<00:29, 145.16it/s]Running 10000 simulations.:  58%|█████▊    | 5759/10000 [00:40<00:29, 144.97it/s]Running 10000 simulations.:  58%|█████▊    | 5774/10000 [00:40<00:29, 145.28it/s]Running 10000 simulations.:  58%|█████▊    | 5789/10000 [00:40<00:28, 145.54it/s]Running 10000 simulations.:  58%|█████▊    | 5804/10000 [00:41<00:28, 145.66it/s]Running 10000 simulations.:  58%|█████▊    | 5819/10000 [00:41<00:28, 145.60it/s]Running 10000 simulations.:  58%|█████▊    | 5834/10000 [00:41<00:28, 145.69it/s]Running 10000 simulations.:  58%|█████▊    | 5849/10000 [00:41<00:28, 145.84it/s]Running 10000 simulations.:  59%|█████▊    | 5864/10000 [00:41<00:28, 145.51it/s]Running 10000 simulations.:  59%|█████▉    | 5879/10000 [00:41<00:28, 145.42it/s]Running 10000 simulations.:  59%|█████▉    | 5894/10000 [00:41<00:28, 145.08it/s]Running 10000 simulations.:  59%|█████▉    | 5909/10000 [00:41<00:28, 145.02it/s]Running 10000 simulations.:  59%|█████▉    | 5924/10000 [00:41<00:28, 145.00it/s]Running 10000 simulations.:  59%|█████▉    | 5939/10000 [00:41<00:28, 145.01it/s]Running 10000 simulations.:  60%|█████▉    | 5954/10000 [00:42<00:27, 145.16it/s]Running 10000 simulations.:  60%|█████▉    | 5969/10000 [00:42<00:27, 145.04it/s]Running 10000 simulations.:  60%|█████▉    | 5984/10000 [00:42<00:27, 144.87it/s]Running 10000 simulations.:  60%|█████▉    | 5999/10000 [00:42<00:27, 144.82it/s]Running 10000 simulations.:  60%|██████    | 6014/10000 [00:42<00:27, 144.81it/s]Running 10000 simulations.:  60%|██████    | 6029/10000 [00:42<00:27, 144.71it/s]Running 10000 simulations.:  60%|██████    | 6044/10000 [00:42<00:27, 144.53it/s]Running 10000 simulations.:  61%|██████    | 6059/10000 [00:42<00:27, 144.84it/s]Running 10000 simulations.:  61%|██████    | 6074/10000 [00:42<00:27, 145.03it/s]Running 10000 simulations.:  61%|██████    | 6089/10000 [00:43<00:27, 144.42it/s]Running 10000 simulations.:  61%|██████    | 6104/10000 [00:43<00:27, 144.06it/s]Running 10000 simulations.:  61%|██████    | 6119/10000 [00:43<00:27, 143.32it/s]Running 10000 simulations.:  61%|██████▏   | 6134/10000 [00:43<00:26, 143.49it/s]Running 10000 simulations.:  61%|██████▏   | 6149/10000 [00:43<00:26, 144.40it/s]Running 10000 simulations.:  62%|██████▏   | 6164/10000 [00:43<00:26, 144.89it/s]Running 10000 simulations.:  62%|██████▏   | 6179/10000 [00:43<00:26, 145.50it/s]Running 10000 simulations.:  62%|██████▏   | 6194/10000 [00:43<00:26, 145.85it/s]Running 10000 simulations.:  62%|██████▏   | 6209/10000 [00:43<00:25, 146.07it/s]Running 10000 simulations.:  62%|██████▏   | 6224/10000 [00:43<00:25, 146.23it/s]Running 10000 simulations.:  62%|██████▏   | 6239/10000 [00:44<00:25, 146.89it/s]Running 10000 simulations.:  63%|██████▎   | 6254/10000 [00:44<00:25, 146.79it/s]Running 10000 simulations.:  63%|██████▎   | 6269/10000 [00:44<00:25, 146.72it/s]Running 10000 simulations.:  63%|██████▎   | 6284/10000 [00:44<00:25, 146.97it/s]Running 10000 simulations.:  63%|██████▎   | 6299/10000 [00:44<00:25, 146.67it/s]Running 10000 simulations.:  63%|██████▎   | 6314/10000 [00:44<00:25, 146.70it/s]Running 10000 simulations.:  63%|██████▎   | 6329/10000 [00:44<00:25, 146.44it/s]Running 10000 simulations.:  63%|██████▎   | 6344/10000 [00:44<00:24, 146.32it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:44<00:24, 146.59it/s]Running 10000 simulations.:  64%|██████▎   | 6374/10000 [00:44<00:24, 146.77it/s]Running 10000 simulations.:  64%|██████▍   | 6389/10000 [00:45<00:24, 147.00it/s]Running 10000 simulations.:  64%|██████▍   | 6404/10000 [00:45<00:24, 146.63it/s]Running 10000 simulations.:  64%|██████▍   | 6419/10000 [00:45<00:24, 146.40it/s]Running 10000 simulations.:  64%|██████▍   | 6434/10000 [00:45<00:24, 146.31it/s]Running 10000 simulations.:  64%|██████▍   | 6449/10000 [00:45<00:24, 145.89it/s]Running 10000 simulations.:  65%|██████▍   | 6464/10000 [00:45<00:24, 146.01it/s]Running 10000 simulations.:  65%|██████▍   | 6479/10000 [00:45<00:24, 146.15it/s]Running 10000 simulations.:  65%|██████▍   | 6494/10000 [00:45<00:23, 146.11it/s]Running 10000 simulations.:  65%|██████▌   | 6509/10000 [00:45<00:23, 146.11it/s]Running 10000 simulations.:  65%|██████▌   | 6524/10000 [00:46<00:23, 145.94it/s]Running 10000 simulations.:  65%|██████▌   | 6539/10000 [00:46<00:23, 145.86it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:46<00:23, 145.95it/s]Running 10000 simulations.:  66%|██████▌   | 6569/10000 [00:46<00:23, 145.61it/s]Running 10000 simulations.:  66%|██████▌   | 6584/10000 [00:46<00:23, 145.23it/s]Running 10000 simulations.:  66%|██████▌   | 6599/10000 [00:46<00:23, 145.72it/s]Running 10000 simulations.:  66%|██████▌   | 6614/10000 [00:46<00:23, 145.87it/s]Running 10000 simulations.:  66%|██████▋   | 6629/10000 [00:46<00:23, 145.66it/s]Running 10000 simulations.:  66%|██████▋   | 6644/10000 [00:46<00:22, 146.01it/s]Running 10000 simulations.:  67%|██████▋   | 6659/10000 [00:46<00:22, 145.40it/s]Running 10000 simulations.:  67%|██████▋   | 6674/10000 [00:47<00:22, 145.15it/s]Running 10000 simulations.:  67%|██████▋   | 6689/10000 [00:47<00:22, 145.17it/s]Running 10000 simulations.:  67%|██████▋   | 6704/10000 [00:47<00:22, 145.02it/s]Running 10000 simulations.:  67%|██████▋   | 6719/10000 [00:47<00:22, 145.43it/s]Running 10000 simulations.:  67%|██████▋   | 6734/10000 [00:47<00:22, 145.78it/s]Running 10000 simulations.:  67%|██████▋   | 6749/10000 [00:47<00:22, 145.98it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:47<00:22, 145.69it/s]Running 10000 simulations.:  68%|██████▊   | 6779/10000 [00:47<00:22, 145.98it/s]Running 10000 simulations.:  68%|██████▊   | 6794/10000 [00:47<00:21, 146.06it/s]Running 10000 simulations.:  68%|██████▊   | 6809/10000 [00:47<00:21, 145.73it/s]Running 10000 simulations.:  68%|██████▊   | 6824/10000 [00:48<00:21, 145.63it/s]Running 10000 simulations.:  68%|██████▊   | 6839/10000 [00:48<00:21, 145.52it/s]Running 10000 simulations.:  69%|██████▊   | 6854/10000 [00:48<00:21, 145.87it/s]Running 10000 simulations.:  69%|██████▊   | 6869/10000 [00:48<00:21, 145.79it/s]Running 10000 simulations.:  69%|██████▉   | 6884/10000 [00:48<00:21, 145.61it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:48<00:21, 145.59it/s]Running 10000 simulations.:  69%|██████▉   | 6914/10000 [00:48<00:21, 145.48it/s]Running 10000 simulations.:  69%|██████▉   | 6929/10000 [00:48<00:21, 145.50it/s]Running 10000 simulations.:  69%|██████▉   | 6944/10000 [00:48<00:20, 145.93it/s]Running 10000 simulations.:  70%|██████▉   | 6959/10000 [00:48<00:20, 146.42it/s]Running 10000 simulations.:  70%|██████▉   | 6974/10000 [00:49<00:20, 146.57it/s]Running 10000 simulations.:  70%|██████▉   | 6989/10000 [00:49<00:20, 147.03it/s]Running 10000 simulations.:  70%|███████   | 7004/10000 [00:49<00:20, 147.33it/s]Running 10000 simulations.:  70%|███████   | 7019/10000 [00:49<00:20, 146.64it/s]Running 10000 simulations.:  70%|███████   | 7034/10000 [00:49<00:20, 146.45it/s]Running 10000 simulations.:  70%|███████   | 7049/10000 [00:49<00:20, 146.16it/s]Running 10000 simulations.:  71%|███████   | 7064/10000 [00:49<00:20, 146.39it/s]Running 10000 simulations.:  71%|███████   | 7079/10000 [00:49<00:19, 146.54it/s]Running 10000 simulations.:  71%|███████   | 7094/10000 [00:49<00:19, 146.21it/s]Running 10000 simulations.:  71%|███████   | 7109/10000 [00:50<00:19, 145.83it/s]Running 10000 simulations.:  71%|███████   | 7124/10000 [00:50<00:19, 145.76it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:50<00:19, 148.61it/s]Running 10000 simulations.:  72%|███████▏  | 7157/10000 [00:50<00:18, 153.74it/s]Running 10000 simulations.:  72%|███████▏  | 7173/10000 [00:50<00:18, 151.72it/s]Running 10000 simulations.:  72%|███████▏  | 7189/10000 [00:50<00:18, 149.75it/s]Running 10000 simulations.:  72%|███████▏  | 7205/10000 [00:50<00:18, 148.33it/s]Running 10000 simulations.:  72%|███████▏  | 7220/10000 [00:50<00:18, 147.59it/s]Running 10000 simulations.:  72%|███████▏  | 7235/10000 [00:50<00:18, 147.08it/s]Running 10000 simulations.:  72%|███████▎  | 7250/10000 [00:50<00:18, 146.65it/s]Running 10000 simulations.:  73%|███████▎  | 7265/10000 [00:51<00:18, 146.43it/s]Running 10000 simulations.:  73%|███████▎  | 7280/10000 [00:51<00:18, 146.19it/s]Running 10000 simulations.:  73%|███████▎  | 7295/10000 [00:51<00:18, 146.38it/s]Running 10000 simulations.:  73%|███████▎  | 7310/10000 [00:51<00:18, 146.37it/s]Running 10000 simulations.:  73%|███████▎  | 7325/10000 [00:51<00:18, 146.75it/s]Running 10000 simulations.:  73%|███████▎  | 7340/10000 [00:51<00:18, 147.31it/s]Running 10000 simulations.:  74%|███████▎  | 7355/10000 [00:51<00:17, 147.04it/s]Running 10000 simulations.:  74%|███████▎  | 7370/10000 [00:51<00:17, 146.49it/s]Running 10000 simulations.:  74%|███████▍  | 7385/10000 [00:51<00:17, 146.26it/s]Running 10000 simulations.:  74%|███████▍  | 7400/10000 [00:51<00:17, 146.27it/s]Running 10000 simulations.:  74%|███████▍  | 7415/10000 [00:52<00:17, 145.99it/s]Running 10000 simulations.:  74%|███████▍  | 7430/10000 [00:52<00:17, 145.75it/s]Running 10000 simulations.:  74%|███████▍  | 7445/10000 [00:52<00:17, 145.89it/s]Running 10000 simulations.:  75%|███████▍  | 7460/10000 [00:52<00:17, 146.20it/s]Running 10000 simulations.:  75%|███████▍  | 7475/10000 [00:52<00:17, 145.95it/s]Running 10000 simulations.:  75%|███████▍  | 7490/10000 [00:52<00:17, 145.96it/s]Running 10000 simulations.:  75%|███████▌  | 7505/10000 [00:52<00:17, 146.07it/s]Running 10000 simulations.:  75%|███████▌  | 7520/10000 [00:52<00:17, 145.88it/s]Running 10000 simulations.:  75%|███████▌  | 7535/10000 [00:52<00:16, 145.96it/s]Running 10000 simulations.:  76%|███████▌  | 7550/10000 [00:53<00:16, 146.59it/s]Running 10000 simulations.:  76%|███████▌  | 7565/10000 [00:53<00:16, 146.68it/s]Running 10000 simulations.:  76%|███████▌  | 7580/10000 [00:53<00:16, 147.10it/s]Running 10000 simulations.:  76%|███████▌  | 7595/10000 [00:53<00:16, 147.25it/s]Running 10000 simulations.:  76%|███████▌  | 7610/10000 [00:53<00:16, 147.03it/s]Running 10000 simulations.:  76%|███████▋  | 7625/10000 [00:53<00:16, 147.05it/s]Running 10000 simulations.:  76%|███████▋  | 7640/10000 [00:53<00:16, 146.64it/s]Running 10000 simulations.:  77%|███████▋  | 7655/10000 [00:53<00:16, 146.42it/s]Running 10000 simulations.:  77%|███████▋  | 7670/10000 [00:53<00:15, 146.83it/s]Running 10000 simulations.:  77%|███████▋  | 7685/10000 [00:53<00:15, 146.55it/s]Running 10000 simulations.:  77%|███████▋  | 7700/10000 [00:54<00:15, 146.26it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:54<00:15, 146.09it/s]Running 10000 simulations.:  77%|███████▋  | 7730/10000 [00:54<00:15, 145.97it/s]Running 10000 simulations.:  77%|███████▋  | 7745/10000 [00:54<00:15, 145.89it/s]Running 10000 simulations.:  78%|███████▊  | 7760/10000 [00:54<00:15, 145.95it/s]Running 10000 simulations.:  78%|███████▊  | 7775/10000 [00:54<00:15, 145.78it/s]Running 10000 simulations.:  78%|███████▊  | 7790/10000 [00:54<00:15, 145.57it/s]Running 10000 simulations.:  78%|███████▊  | 7805/10000 [00:54<00:15, 145.62it/s]Running 10000 simulations.:  78%|███████▊  | 7820/10000 [00:54<00:14, 145.67it/s]Running 10000 simulations.:  78%|███████▊  | 7835/10000 [00:54<00:14, 146.24it/s]Running 10000 simulations.:  78%|███████▊  | 7850/10000 [00:55<00:14, 146.37it/s]Running 10000 simulations.:  79%|███████▊  | 7865/10000 [00:55<00:14, 146.23it/s]Running 10000 simulations.:  79%|███████▉  | 7880/10000 [00:55<00:14, 146.07it/s]Running 10000 simulations.:  79%|███████▉  | 7895/10000 [00:55<00:14, 145.90it/s]Running 10000 simulations.:  79%|███████▉  | 7910/10000 [00:55<00:14, 145.84it/s]Running 10000 simulations.:  79%|███████▉  | 7925/10000 [00:55<00:14, 145.50it/s]Running 10000 simulations.:  79%|███████▉  | 7940/10000 [00:55<00:14, 145.64it/s]Running 10000 simulations.:  80%|███████▉  | 7955/10000 [00:55<00:14, 145.01it/s]Running 10000 simulations.:  80%|███████▉  | 7970/10000 [00:55<00:14, 144.99it/s]Running 10000 simulations.:  80%|███████▉  | 7985/10000 [00:55<00:13, 145.26it/s]Running 10000 simulations.:  80%|████████  | 8000/10000 [00:56<00:13, 145.53it/s]Running 10000 simulations.:  80%|████████  | 8015/10000 [00:56<00:13, 145.57it/s]Running 10000 simulations.:  80%|████████  | 8030/10000 [00:56<00:13, 145.44it/s]Running 10000 simulations.:  80%|████████  | 8045/10000 [00:56<00:13, 146.05it/s]Running 10000 simulations.:  81%|████████  | 8060/10000 [00:56<00:13, 145.97it/s]Running 10000 simulations.:  81%|████████  | 8075/10000 [00:56<00:13, 146.55it/s]Running 10000 simulations.:  81%|████████  | 8090/10000 [00:56<00:13, 146.82it/s]Running 10000 simulations.:  81%|████████  | 8105/10000 [00:56<00:12, 146.83it/s]Running 10000 simulations.:  81%|████████  | 8120/10000 [00:56<00:12, 146.97it/s]Running 10000 simulations.:  81%|████████▏ | 8135/10000 [00:57<00:12, 147.39it/s]Running 10000 simulations.:  82%|████████▏ | 8150/10000 [00:57<00:12, 147.89it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:57<00:12, 147.82it/s]Running 10000 simulations.:  82%|████████▏ | 8180/10000 [00:57<00:12, 148.10it/s]Running 10000 simulations.:  82%|████████▏ | 8195/10000 [00:57<00:12, 147.61it/s]Running 10000 simulations.:  82%|████████▏ | 8210/10000 [00:57<00:12, 147.29it/s]Running 10000 simulations.:  82%|████████▏ | 8225/10000 [00:57<00:12, 143.97it/s]Running 10000 simulations.:  82%|████████▏ | 8240/10000 [00:57<00:12, 144.55it/s]Running 10000 simulations.:  83%|████████▎ | 8255/10000 [00:57<00:12, 145.03it/s]Running 10000 simulations.:  83%|████████▎ | 8270/10000 [00:57<00:11, 145.61it/s]Running 10000 simulations.:  83%|████████▎ | 8285/10000 [00:58<00:11, 145.81it/s]Running 10000 simulations.:  83%|████████▎ | 8300/10000 [00:58<00:11, 146.72it/s]Running 10000 simulations.:  83%|████████▎ | 8315/10000 [00:58<00:11, 147.51it/s]Running 10000 simulations.:  83%|████████▎ | 8330/10000 [00:58<00:11, 148.00it/s]Running 10000 simulations.:  83%|████████▎ | 8345/10000 [00:58<00:11, 147.78it/s]Running 10000 simulations.:  84%|████████▎ | 8360/10000 [00:58<00:11, 147.55it/s]Running 10000 simulations.:  84%|████████▍ | 8375/10000 [00:58<00:11, 147.23it/s]Running 10000 simulations.:  84%|████████▍ | 8390/10000 [00:58<00:10, 147.31it/s]Running 10000 simulations.:  84%|████████▍ | 8405/10000 [00:58<00:10, 147.28it/s]Running 10000 simulations.:  84%|████████▍ | 8420/10000 [00:58<00:10, 147.33it/s]Running 10000 simulations.:  84%|████████▍ | 8435/10000 [00:59<00:10, 147.09it/s]Running 10000 simulations.:  84%|████████▍ | 8450/10000 [00:59<00:10, 146.97it/s]Running 10000 simulations.:  85%|████████▍ | 8465/10000 [00:59<00:10, 146.89it/s]Running 10000 simulations.:  85%|████████▍ | 8480/10000 [00:59<00:10, 146.43it/s]Running 10000 simulations.:  85%|████████▍ | 8495/10000 [00:59<00:10, 146.80it/s]Running 10000 simulations.:  85%|████████▌ | 8510/10000 [00:59<00:10, 147.06it/s]Running 10000 simulations.:  85%|████████▌ | 8525/10000 [00:59<00:10, 147.23it/s]Running 10000 simulations.:  85%|████████▌ | 8540/10000 [00:59<00:09, 147.74it/s]Running 10000 simulations.:  86%|████████▌ | 8555/10000 [00:59<00:09, 147.93it/s]Running 10000 simulations.:  86%|████████▌ | 8570/10000 [00:59<00:09, 147.74it/s]Running 10000 simulations.:  86%|████████▌ | 8585/10000 [01:00<00:09, 147.03it/s]Running 10000 simulations.:  86%|████████▌ | 8600/10000 [01:00<00:09, 147.10it/s]Running 10000 simulations.:  86%|████████▌ | 8615/10000 [01:00<00:09, 147.16it/s]Running 10000 simulations.:  86%|████████▋ | 8630/10000 [01:00<00:09, 147.13it/s]Running 10000 simulations.:  86%|████████▋ | 8645/10000 [01:00<00:09, 147.02it/s]Running 10000 simulations.:  87%|████████▋ | 8660/10000 [01:00<00:09, 147.05it/s]Running 10000 simulations.:  87%|████████▋ | 8675/10000 [01:00<00:09, 147.14it/s]Running 10000 simulations.:  87%|████████▋ | 8690/10000 [01:00<00:08, 147.38it/s]Running 10000 simulations.:  87%|████████▋ | 8705/10000 [01:00<00:08, 147.41it/s]Running 10000 simulations.:  87%|████████▋ | 8720/10000 [01:00<00:08, 147.75it/s]Running 10000 simulations.:  87%|████████▋ | 8735/10000 [01:01<00:08, 147.84it/s]Running 10000 simulations.:  88%|████████▊ | 8750/10000 [01:01<00:08, 148.41it/s]Running 10000 simulations.:  88%|████████▊ | 8765/10000 [01:01<00:08, 148.09it/s]Running 10000 simulations.:  88%|████████▊ | 8780/10000 [01:01<00:08, 147.14it/s]Running 10000 simulations.:  88%|████████▊ | 8795/10000 [01:01<00:08, 146.00it/s]Running 10000 simulations.:  88%|████████▊ | 8810/10000 [01:01<00:08, 145.39it/s]Running 10000 simulations.:  88%|████████▊ | 8825/10000 [01:01<00:08, 145.77it/s]Running 10000 simulations.:  88%|████████▊ | 8841/10000 [01:01<00:07, 147.45it/s]Running 10000 simulations.:  89%|████████▊ | 8858/10000 [01:01<00:07, 153.15it/s]Running 10000 simulations.:  89%|████████▉ | 8875/10000 [01:02<00:07, 155.86it/s]Running 10000 simulations.:  89%|████████▉ | 8891/10000 [01:02<00:07, 152.73it/s]Running 10000 simulations.:  89%|████████▉ | 8907/10000 [01:02<00:07, 150.41it/s]Running 10000 simulations.:  89%|████████▉ | 8923/10000 [01:02<00:07, 149.23it/s]Running 10000 simulations.:  89%|████████▉ | 8938/10000 [01:02<00:07, 148.80it/s]Running 10000 simulations.:  90%|████████▉ | 8953/10000 [01:02<00:07, 146.72it/s]Running 10000 simulations.:  90%|████████▉ | 8968/10000 [01:02<00:07, 145.00it/s]Running 10000 simulations.:  90%|████████▉ | 8983/10000 [01:02<00:07, 143.83it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [01:02<00:06, 143.66it/s]Running 10000 simulations.:  90%|█████████ | 9013/10000 [01:02<00:06, 144.01it/s]Running 10000 simulations.:  90%|█████████ | 9028/10000 [01:03<00:06, 143.98it/s]Running 10000 simulations.:  90%|█████████ | 9043/10000 [01:03<00:06, 144.26it/s]Running 10000 simulations.:  91%|█████████ | 9058/10000 [01:03<00:06, 144.32it/s]Running 10000 simulations.:  91%|█████████ | 9073/10000 [01:03<00:06, 144.80it/s]Running 10000 simulations.:  91%|█████████ | 9088/10000 [01:03<00:06, 145.32it/s]Running 10000 simulations.:  91%|█████████ | 9103/10000 [01:03<00:06, 143.88it/s]Running 10000 simulations.:  91%|█████████ | 9118/10000 [01:03<00:06, 143.33it/s]Running 10000 simulations.:  91%|█████████▏| 9133/10000 [01:03<00:06, 143.67it/s]Running 10000 simulations.:  91%|█████████▏| 9148/10000 [01:03<00:05, 144.17it/s]Running 10000 simulations.:  92%|█████████▏| 9163/10000 [01:04<00:05, 144.67it/s]Running 10000 simulations.:  92%|█████████▏| 9178/10000 [01:04<00:05, 144.58it/s]Running 10000 simulations.:  92%|█████████▏| 9193/10000 [01:04<00:05, 144.56it/s]Running 10000 simulations.:  92%|█████████▏| 9208/10000 [01:04<00:05, 144.87it/s]Running 10000 simulations.:  92%|█████████▏| 9223/10000 [01:04<00:05, 144.70it/s]Running 10000 simulations.:  92%|█████████▏| 9238/10000 [01:04<00:05, 143.84it/s]Running 10000 simulations.:  93%|█████████▎| 9253/10000 [01:04<00:05, 142.76it/s]Running 10000 simulations.:  93%|█████████▎| 9268/10000 [01:04<00:05, 142.32it/s]Running 10000 simulations.:  93%|█████████▎| 9283/10000 [01:04<00:05, 143.22it/s]Running 10000 simulations.:  93%|█████████▎| 9298/10000 [01:04<00:04, 143.98it/s]Running 10000 simulations.:  93%|█████████▎| 9313/10000 [01:05<00:04, 144.44it/s]Running 10000 simulations.:  93%|█████████▎| 9328/10000 [01:05<00:04, 144.55it/s]Running 10000 simulations.:  93%|█████████▎| 9343/10000 [01:05<00:04, 144.23it/s]Running 10000 simulations.:  94%|█████████▎| 9358/10000 [01:05<00:04, 143.74it/s]Running 10000 simulations.:  94%|█████████▎| 9373/10000 [01:05<00:04, 143.78it/s]Running 10000 simulations.:  94%|█████████▍| 9388/10000 [01:05<00:04, 143.18it/s]Running 10000 simulations.:  94%|█████████▍| 9403/10000 [01:05<00:04, 142.41it/s]Running 10000 simulations.:  94%|█████████▍| 9418/10000 [01:05<00:04, 142.08it/s]Running 10000 simulations.:  94%|█████████▍| 9433/10000 [01:05<00:03, 142.58it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [01:06<00:03, 143.09it/s]Running 10000 simulations.:  95%|█████████▍| 9463/10000 [01:06<00:03, 142.87it/s]Running 10000 simulations.:  95%|█████████▍| 9478/10000 [01:06<00:03, 143.45it/s]Running 10000 simulations.:  95%|█████████▍| 9493/10000 [01:06<00:03, 143.89it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [01:06<00:03, 136.93it/s]Running 10000 simulations.:  95%|█████████▌| 9523/10000 [01:06<00:03, 139.57it/s]Running 10000 simulations.:  95%|█████████▌| 9538/10000 [01:06<00:03, 141.13it/s]Running 10000 simulations.:  96%|█████████▌| 9553/10000 [01:06<00:03, 141.62it/s]Running 10000 simulations.:  96%|█████████▌| 9568/10000 [01:06<00:03, 141.60it/s]Running 10000 simulations.:  96%|█████████▌| 9583/10000 [01:06<00:02, 141.85it/s]Running 10000 simulations.:  96%|█████████▌| 9598/10000 [01:07<00:02, 143.06it/s]Running 10000 simulations.:  96%|█████████▌| 9613/10000 [01:07<00:02, 143.92it/s]Running 10000 simulations.:  96%|█████████▋| 9628/10000 [01:07<00:02, 144.58it/s]Running 10000 simulations.:  96%|█████████▋| 9643/10000 [01:07<00:02, 144.73it/s]Running 10000 simulations.:  97%|█████████▋| 9658/10000 [01:07<00:02, 144.77it/s]Running 10000 simulations.:  97%|█████████▋| 9673/10000 [01:07<00:02, 144.22it/s]Running 10000 simulations.:  97%|█████████▋| 9688/10000 [01:07<00:02, 144.52it/s]Running 10000 simulations.:  97%|█████████▋| 9703/10000 [01:07<00:02, 144.58it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [01:07<00:01, 145.35it/s]Running 10000 simulations.:  97%|█████████▋| 9733/10000 [01:08<00:01, 144.64it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [01:08<00:01, 144.00it/s]Running 10000 simulations.:  98%|█████████▊| 9763/10000 [01:08<00:01, 144.30it/s]Running 10000 simulations.:  98%|█████████▊| 9778/10000 [01:08<00:01, 144.99it/s]Running 10000 simulations.:  98%|█████████▊| 9793/10000 [01:08<00:01, 145.56it/s]Running 10000 simulations.:  98%|█████████▊| 9808/10000 [01:08<00:01, 145.66it/s]Running 10000 simulations.:  98%|█████████▊| 9823/10000 [01:08<00:01, 145.50it/s]Running 10000 simulations.:  98%|█████████▊| 9838/10000 [01:08<00:01, 145.64it/s]Running 10000 simulations.:  99%|█████████▊| 9853/10000 [01:08<00:01, 146.64it/s]Running 10000 simulations.:  99%|█████████▊| 9868/10000 [01:08<00:00, 145.79it/s]Running 10000 simulations.:  99%|█████████▉| 9883/10000 [01:09<00:00, 145.40it/s]Running 10000 simulations.:  99%|█████████▉| 9898/10000 [01:09<00:00, 146.02it/s]Running 10000 simulations.:  99%|█████████▉| 9913/10000 [01:09<00:00, 146.50it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [01:09<00:00, 146.85it/s]Running 10000 simulations.:  99%|█████████▉| 9943/10000 [01:09<00:00, 146.80it/s]Running 10000 simulations.: 100%|█████████▉| 9958/10000 [01:09<00:00, 146.70it/s]Running 10000 simulations.: 100%|█████████▉| 9973/10000 [01:09<00:00, 146.96it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [01:09<00:00, 146.98it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:09<00:00, 143.21it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:08, 146.56it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<01:07, 146.62it/s]Running 10000 simulations.:   0%|          | 45/10000 [00:00<01:07, 147.41it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<01:07, 147.11it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<01:07, 146.79it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<01:07, 146.70it/s]Running 10000 simulations.:   1%|          | 105/10000 [00:00<01:07, 146.47it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<01:07, 146.16it/s]Running 10000 simulations.:   1%|▏         | 135/10000 [00:00<01:07, 146.07it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:01<01:07, 145.84it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:01<01:07, 146.20it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:01<01:07, 146.07it/s]Running 10000 simulations.:   2%|▏         | 195/10000 [00:01<01:07, 146.12it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:01<01:06, 146.13it/s]Running 10000 simulations.:   2%|▏         | 225/10000 [00:01<01:06, 146.27it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:01<01:07, 145.58it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<01:07, 145.05it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:01<01:07, 144.67it/s]Running 10000 simulations.:   3%|▎         | 285/10000 [00:01<01:07, 144.32it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:02<01:07, 144.59it/s]Running 10000 simulations.:   3%|▎         | 315/10000 [00:02<01:07, 144.50it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:02<01:07, 144.26it/s]Running 10000 simulations.:   3%|▎         | 345/10000 [00:02<01:07, 144.04it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:02<01:07, 143.88it/s]Running 10000 simulations.:   4%|▍         | 375/10000 [00:02<01:06, 143.74it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:02<01:06, 143.58it/s]Running 10000 simulations.:   4%|▍         | 405/10000 [00:02<01:06, 143.71it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:02<01:06, 143.73it/s]Running 10000 simulations.:   4%|▍         | 435/10000 [00:02<01:06, 143.53it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:03<01:06, 143.32it/s]Running 10000 simulations.:   5%|▍         | 465/10000 [00:03<01:06, 143.02it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:03<01:06, 142.91it/s]Running 10000 simulations.:   5%|▍         | 495/10000 [00:03<01:06, 142.80it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:03<01:06, 142.85it/s]Running 10000 simulations.:   5%|▌         | 525/10000 [00:03<01:06, 143.07it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:03<01:05, 143.90it/s]Running 10000 simulations.:   6%|▌         | 555/10000 [00:03<01:05, 143.77it/s]Running 10000 simulations.:   6%|▌         | 570/10000 [00:03<01:05, 143.84it/s]Running 10000 simulations.:   6%|▌         | 585/10000 [00:04<01:05, 143.08it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:04<01:06, 142.39it/s]Running 10000 simulations.:   6%|▌         | 615/10000 [00:04<01:06, 142.09it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:04<01:05, 142.14it/s]Running 10000 simulations.:   6%|▋         | 645/10000 [00:04<01:05, 141.88it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:04<01:05, 141.75it/s]Running 10000 simulations.:   7%|▋         | 675/10000 [00:04<01:05, 141.61it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:04<01:05, 142.51it/s]Running 10000 simulations.:   7%|▋         | 707/10000 [00:04<01:02, 148.57it/s]Running 10000 simulations.:   7%|▋         | 724/10000 [00:04<01:00, 152.94it/s]Running 10000 simulations.:   7%|▋         | 740/10000 [00:05<01:01, 150.71it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:05<01:02, 147.88it/s]Running 10000 simulations.:   8%|▊         | 771/10000 [00:05<01:03, 145.91it/s]Running 10000 simulations.:   8%|▊         | 786/10000 [00:05<01:03, 145.25it/s]Running 10000 simulations.:   8%|▊         | 801/10000 [00:05<01:03, 145.01it/s]Running 10000 simulations.:   8%|▊         | 816/10000 [00:05<01:03, 144.11it/s]Running 10000 simulations.:   8%|▊         | 831/10000 [00:05<01:03, 143.77it/s]Running 10000 simulations.:   8%|▊         | 846/10000 [00:05<01:03, 143.44it/s]Running 10000 simulations.:   9%|▊         | 861/10000 [00:05<01:04, 141.21it/s]Running 10000 simulations.:   9%|▉         | 876/10000 [00:06<01:04, 141.04it/s]Running 10000 simulations.:   9%|▉         | 891/10000 [00:06<01:04, 141.57it/s]Running 10000 simulations.:   9%|▉         | 906/10000 [00:06<01:04, 141.71it/s]Running 10000 simulations.:   9%|▉         | 921/10000 [00:06<01:04, 141.69it/s]Running 10000 simulations.:   9%|▉         | 936/10000 [00:06<01:03, 141.81it/s]Running 10000 simulations.:  10%|▉         | 951/10000 [00:06<01:03, 141.80it/s]Running 10000 simulations.:  10%|▉         | 966/10000 [00:06<01:03, 141.98it/s]Running 10000 simulations.:  10%|▉         | 981/10000 [00:06<01:03, 141.90it/s]Running 10000 simulations.:  10%|▉         | 996/10000 [00:06<01:03, 141.58it/s]Running 10000 simulations.:  10%|█         | 1011/10000 [00:07<01:03, 141.76it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:07<01:03, 141.53it/s]Running 10000 simulations.:  10%|█         | 1041/10000 [00:07<01:03, 141.82it/s]Running 10000 simulations.:  11%|█         | 1056/10000 [00:07<01:03, 141.83it/s]Running 10000 simulations.:  11%|█         | 1071/10000 [00:07<01:03, 141.54it/s]Running 10000 simulations.:  11%|█         | 1086/10000 [00:07<01:02, 142.12it/s]Running 10000 simulations.:  11%|█         | 1101/10000 [00:07<01:02, 142.22it/s]Running 10000 simulations.:  11%|█         | 1116/10000 [00:07<01:02, 141.72it/s]Running 10000 simulations.:  11%|█▏        | 1131/10000 [00:07<01:02, 141.54it/s]Running 10000 simulations.:  11%|█▏        | 1146/10000 [00:07<01:02, 141.80it/s]Running 10000 simulations.:  12%|█▏        | 1161/10000 [00:08<01:02, 141.90it/s]Running 10000 simulations.:  12%|█▏        | 1176/10000 [00:08<01:01, 142.71it/s]Running 10000 simulations.:  12%|█▏        | 1191/10000 [00:08<01:01, 142.99it/s]Running 10000 simulations.:  12%|█▏        | 1206/10000 [00:08<01:01, 143.63it/s]Running 10000 simulations.:  12%|█▏        | 1223/10000 [00:08<00:58, 149.07it/s]Running 10000 simulations.:  12%|█▏        | 1239/10000 [00:08<00:57, 152.04it/s]Running 10000 simulations.:  13%|█▎        | 1255/10000 [00:08<00:57, 152.73it/s]Running 10000 simulations.:  13%|█▎        | 1271/10000 [00:08<00:57, 150.66it/s]Running 10000 simulations.:  13%|█▎        | 1287/10000 [00:08<00:58, 149.40it/s]Running 10000 simulations.:  13%|█▎        | 1302/10000 [00:09<00:58, 148.09it/s]Running 10000 simulations.:  13%|█▎        | 1317/10000 [00:09<00:58, 147.23it/s]Running 10000 simulations.:  13%|█▎        | 1332/10000 [00:09<00:58, 147.10it/s]Running 10000 simulations.:  13%|█▎        | 1347/10000 [00:09<00:59, 146.52it/s]Running 10000 simulations.:  14%|█▎        | 1362/10000 [00:09<00:59, 146.09it/s]Running 10000 simulations.:  14%|█▍        | 1377/10000 [00:09<00:59, 145.86it/s]Running 10000 simulations.:  14%|█▍        | 1392/10000 [00:09<00:58, 145.99it/s]Running 10000 simulations.:  14%|█▍        | 1407/10000 [00:09<00:58, 145.77it/s]Running 10000 simulations.:  14%|█▍        | 1422/10000 [00:09<00:58, 145.58it/s]Running 10000 simulations.:  14%|█▍        | 1437/10000 [00:09<00:58, 145.62it/s]Running 10000 simulations.:  15%|█▍        | 1452/10000 [00:10<00:58, 144.96it/s]Running 10000 simulations.:  15%|█▍        | 1467/10000 [00:10<00:58, 144.90it/s]Running 10000 simulations.:  15%|█▍        | 1482/10000 [00:10<00:58, 144.83it/s]Running 10000 simulations.:  15%|█▍        | 1497/10000 [00:10<00:58, 145.04it/s]Running 10000 simulations.:  15%|█▌        | 1512/10000 [00:10<00:58, 145.60it/s]Running 10000 simulations.:  15%|█▌        | 1527/10000 [00:10<00:58, 145.82it/s]Running 10000 simulations.:  15%|█▌        | 1542/10000 [00:10<00:58, 144.94it/s]Running 10000 simulations.:  16%|█▌        | 1557/10000 [00:10<00:58, 144.97it/s]Running 10000 simulations.:  16%|█▌        | 1572/10000 [00:10<00:58, 145.02it/s]Running 10000 simulations.:  16%|█▌        | 1587/10000 [00:10<00:58, 145.03it/s]Running 10000 simulations.:  16%|█▌        | 1602/10000 [00:11<00:57, 145.28it/s]Running 10000 simulations.:  16%|█▌        | 1617/10000 [00:11<00:57, 145.50it/s]Running 10000 simulations.:  16%|█▋        | 1632/10000 [00:11<00:57, 145.60it/s]Running 10000 simulations.:  16%|█▋        | 1647/10000 [00:11<00:57, 145.96it/s]Running 10000 simulations.:  17%|█▋        | 1662/10000 [00:11<00:57, 146.21it/s]Running 10000 simulations.:  17%|█▋        | 1677/10000 [00:11<00:56, 146.36it/s]Running 10000 simulations.:  17%|█▋        | 1692/10000 [00:11<00:56, 146.50it/s]Running 10000 simulations.:  17%|█▋        | 1707/10000 [00:11<00:56, 145.88it/s]Running 10000 simulations.:  17%|█▋        | 1722/10000 [00:11<00:56, 145.90it/s]Running 10000 simulations.:  17%|█▋        | 1738/10000 [00:12<00:56, 147.09it/s]Running 10000 simulations.:  18%|█▊        | 1753/10000 [00:12<00:55, 147.91it/s]Running 10000 simulations.:  18%|█▊        | 1768/10000 [00:12<00:55, 148.43it/s]Running 10000 simulations.:  18%|█▊        | 1784/10000 [00:12<00:55, 149.08it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:12<00:54, 149.28it/s]Running 10000 simulations.:  18%|█▊        | 1815/10000 [00:12<00:54, 149.78it/s]Running 10000 simulations.:  18%|█▊        | 1831/10000 [00:12<00:54, 150.34it/s]Running 10000 simulations.:  18%|█▊        | 1847/10000 [00:12<00:54, 150.34it/s]Running 10000 simulations.:  19%|█▊        | 1863/10000 [00:12<00:54, 150.04it/s]Running 10000 simulations.:  19%|█▉        | 1879/10000 [00:12<00:53, 150.69it/s]Running 10000 simulations.:  19%|█▉        | 1895/10000 [00:13<00:53, 150.62it/s]Running 10000 simulations.:  19%|█▉        | 1911/10000 [00:13<00:53, 150.68it/s]Running 10000 simulations.:  19%|█▉        | 1927/10000 [00:13<00:53, 150.98it/s]Running 10000 simulations.:  19%|█▉        | 1943/10000 [00:13<00:53, 151.07it/s]Running 10000 simulations.:  20%|█▉        | 1959/10000 [00:13<00:53, 151.08it/s]Running 10000 simulations.:  20%|█▉        | 1975/10000 [00:13<00:53, 150.85it/s]Running 10000 simulations.:  20%|█▉        | 1991/10000 [00:13<00:53, 150.51it/s]Running 10000 simulations.:  20%|██        | 2007/10000 [00:13<00:53, 150.02it/s]Running 10000 simulations.:  20%|██        | 2023/10000 [00:13<00:53, 149.98it/s]Running 10000 simulations.:  20%|██        | 2039/10000 [00:14<00:53, 150.15it/s]Running 10000 simulations.:  21%|██        | 2055/10000 [00:14<00:52, 150.01it/s]Running 10000 simulations.:  21%|██        | 2071/10000 [00:14<00:52, 150.70it/s]Running 10000 simulations.:  21%|██        | 2087/10000 [00:14<00:52, 150.91it/s]Running 10000 simulations.:  21%|██        | 2103/10000 [00:14<00:52, 151.01it/s]Running 10000 simulations.:  21%|██        | 2119/10000 [00:14<00:52, 150.80it/s]Running 10000 simulations.:  21%|██▏       | 2135/10000 [00:14<00:52, 150.62it/s]Running 10000 simulations.:  22%|██▏       | 2151/10000 [00:14<00:52, 150.67it/s]Running 10000 simulations.:  22%|██▏       | 2167/10000 [00:14<00:51, 150.78it/s]Running 10000 simulations.:  22%|██▏       | 2183/10000 [00:14<00:51, 151.09it/s]Running 10000 simulations.:  22%|██▏       | 2199/10000 [00:15<00:51, 151.24it/s]Running 10000 simulations.:  22%|██▏       | 2215/10000 [00:15<00:51, 150.98it/s]Running 10000 simulations.:  22%|██▏       | 2231/10000 [00:15<00:51, 150.54it/s]Running 10000 simulations.:  22%|██▏       | 2247/10000 [00:15<00:51, 150.27it/s]Running 10000 simulations.:  23%|██▎       | 2263/10000 [00:15<00:52, 148.61it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:15<00:51, 148.99it/s]Running 10000 simulations.:  23%|██▎       | 2294/10000 [00:15<00:51, 149.89it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:15<00:51, 150.17it/s]Running 10000 simulations.:  23%|██▎       | 2326/10000 [00:15<00:51, 150.45it/s]Running 10000 simulations.:  23%|██▎       | 2342/10000 [00:16<00:50, 151.00it/s]Running 10000 simulations.:  24%|██▎       | 2358/10000 [00:16<00:50, 151.15it/s]Running 10000 simulations.:  24%|██▎       | 2374/10000 [00:16<00:50, 150.89it/s]Running 10000 simulations.:  24%|██▍       | 2390/10000 [00:16<00:50, 150.80it/s]Running 10000 simulations.:  24%|██▍       | 2406/10000 [00:16<00:50, 150.40it/s]Running 10000 simulations.:  24%|██▍       | 2422/10000 [00:16<00:50, 150.19it/s]Running 10000 simulations.:  24%|██▍       | 2438/10000 [00:16<00:50, 150.35it/s]Running 10000 simulations.:  25%|██▍       | 2454/10000 [00:16<00:50, 150.51it/s]Running 10000 simulations.:  25%|██▍       | 2470/10000 [00:16<00:50, 150.28it/s]Running 10000 simulations.:  25%|██▍       | 2486/10000 [00:16<00:50, 150.20it/s]Running 10000 simulations.:  25%|██▌       | 2502/10000 [00:17<00:49, 151.03it/s]Running 10000 simulations.:  25%|██▌       | 2518/10000 [00:17<00:49, 151.14it/s]Running 10000 simulations.:  25%|██▌       | 2534/10000 [00:17<00:49, 150.61it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:17<00:49, 150.53it/s]Running 10000 simulations.:  26%|██▌       | 2566/10000 [00:17<00:49, 150.36it/s]Running 10000 simulations.:  26%|██▌       | 2582/10000 [00:17<00:49, 150.39it/s]Running 10000 simulations.:  26%|██▌       | 2598/10000 [00:17<00:49, 148.83it/s]Running 10000 simulations.:  26%|██▌       | 2613/10000 [00:17<00:49, 147.88it/s]Running 10000 simulations.:  26%|██▋       | 2628/10000 [00:17<00:49, 147.94it/s]Running 10000 simulations.:  26%|██▋       | 2644/10000 [00:18<00:49, 148.65it/s]Running 10000 simulations.:  27%|██▋       | 2660/10000 [00:18<00:48, 149.95it/s]Running 10000 simulations.:  27%|██▋       | 2676/10000 [00:18<00:48, 150.37it/s]Running 10000 simulations.:  27%|██▋       | 2692/10000 [00:18<00:48, 150.40it/s]Running 10000 simulations.:  27%|██▋       | 2708/10000 [00:18<00:48, 150.50it/s]Running 10000 simulations.:  27%|██▋       | 2724/10000 [00:18<00:48, 150.67it/s]Running 10000 simulations.:  27%|██▋       | 2740/10000 [00:18<00:48, 150.56it/s]Running 10000 simulations.:  28%|██▊       | 2756/10000 [00:18<00:48, 150.40it/s]Running 10000 simulations.:  28%|██▊       | 2772/10000 [00:18<00:48, 150.18it/s]Running 10000 simulations.:  28%|██▊       | 2788/10000 [00:18<00:48, 150.11it/s]Running 10000 simulations.:  28%|██▊       | 2804/10000 [00:19<00:50, 142.07it/s]Running 10000 simulations.:  28%|██▊       | 2820/10000 [00:19<00:49, 144.50it/s]Running 10000 simulations.:  28%|██▊       | 2836/10000 [00:19<00:48, 146.44it/s]Running 10000 simulations.:  29%|██▊       | 2852/10000 [00:19<00:48, 147.93it/s]Running 10000 simulations.:  29%|██▊       | 2868/10000 [00:19<00:47, 148.81it/s]Running 10000 simulations.:  29%|██▉       | 2884/10000 [00:19<00:47, 149.81it/s]Running 10000 simulations.:  29%|██▉       | 2900/10000 [00:19<00:47, 150.09it/s]Running 10000 simulations.:  29%|██▉       | 2916/10000 [00:19<00:47, 150.12it/s]Running 10000 simulations.:  29%|██▉       | 2932/10000 [00:19<00:47, 150.11it/s]Running 10000 simulations.:  29%|██▉       | 2948/10000 [00:20<00:46, 150.22it/s]Running 10000 simulations.:  30%|██▉       | 2964/10000 [00:20<00:46, 150.36it/s]Running 10000 simulations.:  30%|██▉       | 2980/10000 [00:20<00:46, 150.38it/s]Running 10000 simulations.:  30%|██▉       | 2996/10000 [00:20<00:46, 150.15it/s]Running 10000 simulations.:  30%|███       | 3012/10000 [00:20<00:46, 150.23it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:20<00:46, 150.07it/s]Running 10000 simulations.:  30%|███       | 3044/10000 [00:20<00:46, 150.51it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:20<00:46, 150.81it/s]Running 10000 simulations.:  31%|███       | 3076/10000 [00:20<00:45, 150.71it/s]Running 10000 simulations.:  31%|███       | 3092/10000 [00:21<00:45, 150.48it/s]Running 10000 simulations.:  31%|███       | 3108/10000 [00:21<00:45, 150.41it/s]Running 10000 simulations.:  31%|███       | 3124/10000 [00:21<00:45, 150.26it/s]Running 10000 simulations.:  31%|███▏      | 3140/10000 [00:21<00:45, 150.05it/s]Running 10000 simulations.:  32%|███▏      | 3156/10000 [00:21<00:45, 149.84it/s]Running 10000 simulations.:  32%|███▏      | 3171/10000 [00:21<00:45, 149.77it/s]Running 10000 simulations.:  32%|███▏      | 3187/10000 [00:21<00:45, 150.15it/s]Running 10000 simulations.:  32%|███▏      | 3203/10000 [00:21<00:45, 150.60it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:21<00:45, 150.44it/s]Running 10000 simulations.:  32%|███▏      | 3235/10000 [00:21<00:44, 150.48it/s]Running 10000 simulations.:  33%|███▎      | 3251/10000 [00:22<00:44, 150.31it/s]Running 10000 simulations.:  33%|███▎      | 3267/10000 [00:22<00:44, 150.31it/s]Running 10000 simulations.:  33%|███▎      | 3283/10000 [00:22<00:44, 150.44it/s]Running 10000 simulations.:  33%|███▎      | 3299/10000 [00:22<00:44, 150.63it/s]Running 10000 simulations.:  33%|███▎      | 3315/10000 [00:22<00:44, 150.48it/s]Running 10000 simulations.:  33%|███▎      | 3331/10000 [00:22<00:44, 150.28it/s]Running 10000 simulations.:  33%|███▎      | 3347/10000 [00:22<00:44, 150.33it/s]Running 10000 simulations.:  34%|███▎      | 3363/10000 [00:22<00:44, 150.78it/s]Running 10000 simulations.:  34%|███▍      | 3379/10000 [00:22<00:43, 150.90it/s]Running 10000 simulations.:  34%|███▍      | 3395/10000 [00:23<00:43, 150.49it/s]Running 10000 simulations.:  34%|███▍      | 3411/10000 [00:23<00:43, 150.64it/s]Running 10000 simulations.:  34%|███▍      | 3427/10000 [00:23<00:43, 150.50it/s]Running 10000 simulations.:  34%|███▍      | 3443/10000 [00:23<00:43, 150.35it/s]Running 10000 simulations.:  35%|███▍      | 3459/10000 [00:23<00:43, 150.04it/s]Running 10000 simulations.:  35%|███▍      | 3475/10000 [00:23<00:43, 150.13it/s]Running 10000 simulations.:  35%|███▍      | 3491/10000 [00:23<00:43, 150.48it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:23<00:43, 150.52it/s]Running 10000 simulations.:  35%|███▌      | 3523/10000 [00:23<00:43, 149.46it/s]Running 10000 simulations.:  35%|███▌      | 3538/10000 [00:23<00:43, 148.35it/s]Running 10000 simulations.:  36%|███▌      | 3553/10000 [00:24<00:44, 144.94it/s]Running 10000 simulations.:  36%|███▌      | 3568/10000 [00:24<00:44, 146.13it/s]Running 10000 simulations.:  36%|███▌      | 3584/10000 [00:24<00:43, 147.66it/s]Running 10000 simulations.:  36%|███▌      | 3600/10000 [00:24<00:43, 148.38it/s]Running 10000 simulations.:  36%|███▌      | 3616/10000 [00:24<00:42, 149.04it/s]Running 10000 simulations.:  36%|███▋      | 3632/10000 [00:24<00:42, 149.49it/s]Running 10000 simulations.:  36%|███▋      | 3648/10000 [00:24<00:42, 149.89it/s]Running 10000 simulations.:  37%|███▋      | 3664/10000 [00:24<00:42, 150.05it/s]Running 10000 simulations.:  37%|███▋      | 3680/10000 [00:24<00:42, 149.88it/s]Running 10000 simulations.:  37%|███▋      | 3696/10000 [00:25<00:41, 150.14it/s]Running 10000 simulations.:  37%|███▋      | 3712/10000 [00:25<00:41, 150.15it/s]Running 10000 simulations.:  37%|███▋      | 3728/10000 [00:25<00:41, 150.40it/s]Running 10000 simulations.:  37%|███▋      | 3744/10000 [00:25<00:41, 150.48it/s]Running 10000 simulations.:  38%|███▊      | 3760/10000 [00:25<00:41, 150.95it/s]Running 10000 simulations.:  38%|███▊      | 3776/10000 [00:25<00:41, 150.81it/s]Running 10000 simulations.:  38%|███▊      | 3792/10000 [00:25<00:41, 150.64it/s]Running 10000 simulations.:  38%|███▊      | 3808/10000 [00:25<00:41, 150.30it/s]Running 10000 simulations.:  38%|███▊      | 3824/10000 [00:25<00:41, 150.10it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:26<00:41, 150.08it/s]Running 10000 simulations.:  39%|███▊      | 3856/10000 [00:26<00:40, 150.37it/s]Running 10000 simulations.:  39%|███▊      | 3872/10000 [00:26<00:40, 150.34it/s]Running 10000 simulations.:  39%|███▉      | 3888/10000 [00:26<00:40, 150.66it/s]Running 10000 simulations.:  39%|███▉      | 3904/10000 [00:26<00:40, 150.64it/s]Running 10000 simulations.:  39%|███▉      | 3920/10000 [00:26<00:40, 150.20it/s]Running 10000 simulations.:  39%|███▉      | 3936/10000 [00:26<00:40, 150.18it/s]Running 10000 simulations.:  40%|███▉      | 3952/10000 [00:26<00:40, 150.33it/s]Running 10000 simulations.:  40%|███▉      | 3968/10000 [00:26<00:40, 150.36it/s]Running 10000 simulations.:  40%|███▉      | 3984/10000 [00:26<00:40, 150.02it/s]Running 10000 simulations.:  40%|████      | 4000/10000 [00:27<00:39, 150.06it/s]Running 10000 simulations.:  40%|████      | 4016/10000 [00:27<00:39, 150.95it/s]Running 10000 simulations.:  40%|████      | 4032/10000 [00:27<00:39, 150.99it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:27<00:39, 150.84it/s]Running 10000 simulations.:  41%|████      | 4064/10000 [00:27<00:39, 150.90it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:27<00:39, 151.20it/s]Running 10000 simulations.:  41%|████      | 4096/10000 [00:27<00:39, 151.17it/s]Running 10000 simulations.:  41%|████      | 4112/10000 [00:27<00:38, 151.91it/s]Running 10000 simulations.:  41%|████▏     | 4128/10000 [00:27<00:38, 151.73it/s]Running 10000 simulations.:  41%|████▏     | 4144/10000 [00:28<00:38, 152.08it/s]Running 10000 simulations.:  42%|████▏     | 4160/10000 [00:28<00:38, 151.35it/s]Running 10000 simulations.:  42%|████▏     | 4176/10000 [00:28<00:38, 150.91it/s]Running 10000 simulations.:  42%|████▏     | 4192/10000 [00:28<00:38, 150.69it/s]Running 10000 simulations.:  42%|████▏     | 4208/10000 [00:28<00:38, 150.54it/s]Running 10000 simulations.:  42%|████▏     | 4224/10000 [00:28<00:38, 150.58it/s]Running 10000 simulations.:  42%|████▏     | 4240/10000 [00:28<00:38, 150.39it/s]Running 10000 simulations.:  43%|████▎     | 4256/10000 [00:28<00:38, 150.35it/s]Running 10000 simulations.:  43%|████▎     | 4272/10000 [00:28<00:38, 150.30it/s]Running 10000 simulations.:  43%|████▎     | 4288/10000 [00:28<00:38, 150.31it/s]Running 10000 simulations.:  43%|████▎     | 4304/10000 [00:29<00:37, 150.07it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:29<00:37, 150.05it/s]Running 10000 simulations.:  43%|████▎     | 4336/10000 [00:29<00:37, 150.10it/s]Running 10000 simulations.:  44%|████▎     | 4352/10000 [00:29<00:37, 150.20it/s]Running 10000 simulations.:  44%|████▎     | 4368/10000 [00:29<00:37, 150.44it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:29<00:37, 150.17it/s]Running 10000 simulations.:  44%|████▍     | 4400/10000 [00:29<00:37, 150.36it/s]Running 10000 simulations.:  44%|████▍     | 4416/10000 [00:29<00:37, 149.91it/s]Running 10000 simulations.:  44%|████▍     | 4432/10000 [00:29<00:37, 149.94it/s]Running 10000 simulations.:  44%|████▍     | 4447/10000 [00:30<00:37, 149.08it/s]Running 10000 simulations.:  45%|████▍     | 4462/10000 [00:30<00:37, 149.19it/s]Running 10000 simulations.:  45%|████▍     | 4477/10000 [00:30<00:36, 149.34it/s]Running 10000 simulations.:  45%|████▍     | 4492/10000 [00:30<00:36, 149.37it/s]Running 10000 simulations.:  45%|████▌     | 4507/10000 [00:30<00:36, 149.31it/s]Running 10000 simulations.:  45%|████▌     | 4522/10000 [00:30<00:36, 149.25it/s]Running 10000 simulations.:  45%|████▌     | 4537/10000 [00:30<00:36, 149.43it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:30<00:36, 149.82it/s]Running 10000 simulations.:  46%|████▌     | 4569/10000 [00:30<00:36, 149.98it/s]Running 10000 simulations.:  46%|████▌     | 4585/10000 [00:30<00:36, 150.16it/s]Running 10000 simulations.:  46%|████▌     | 4601/10000 [00:31<00:36, 149.97it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:31<00:36, 149.31it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:31<00:35, 149.46it/s]Running 10000 simulations.:  46%|████▋     | 4647/10000 [00:31<00:35, 149.93it/s]Running 10000 simulations.:  47%|████▋     | 4663/10000 [00:31<00:35, 150.35it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:31<00:35, 150.22it/s]Running 10000 simulations.:  47%|████▋     | 4695/10000 [00:31<00:35, 150.81it/s]Running 10000 simulations.:  47%|████▋     | 4711/10000 [00:31<00:35, 151.03it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:31<00:34, 151.32it/s]Running 10000 simulations.:  47%|████▋     | 4743/10000 [00:32<00:34, 150.80it/s]Running 10000 simulations.:  48%|████▊     | 4759/10000 [00:32<00:34, 150.61it/s]Running 10000 simulations.:  48%|████▊     | 4775/10000 [00:32<00:34, 151.20it/s]Running 10000 simulations.:  48%|████▊     | 4791/10000 [00:32<00:34, 150.96it/s]Running 10000 simulations.:  48%|████▊     | 4807/10000 [00:32<00:34, 150.77it/s]Running 10000 simulations.:  48%|████▊     | 4823/10000 [00:32<00:34, 150.73it/s]Running 10000 simulations.:  48%|████▊     | 4839/10000 [00:32<00:34, 150.65it/s]Running 10000 simulations.:  49%|████▊     | 4855/10000 [00:32<00:34, 150.72it/s]Running 10000 simulations.:  49%|████▊     | 4871/10000 [00:32<00:33, 150.95it/s]Running 10000 simulations.:  49%|████▉     | 4887/10000 [00:32<00:33, 150.77it/s]Running 10000 simulations.:  49%|████▉     | 4903/10000 [00:33<00:33, 150.58it/s]Running 10000 simulations.:  49%|████▉     | 4919/10000 [00:33<00:34, 149.09it/s]Running 10000 simulations.:  49%|████▉     | 4934/10000 [00:33<00:34, 146.98it/s]Running 10000 simulations.:  49%|████▉     | 4949/10000 [00:33<00:34, 147.78it/s]Running 10000 simulations.:  50%|████▉     | 4965/10000 [00:33<00:33, 148.64it/s]Running 10000 simulations.:  50%|████▉     | 4981/10000 [00:33<00:33, 149.15it/s]Running 10000 simulations.:  50%|████▉     | 4996/10000 [00:33<00:33, 149.34it/s]Running 10000 simulations.:  50%|█████     | 5011/10000 [00:33<00:33, 149.51it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:33<00:33, 150.01it/s]Running 10000 simulations.:  50%|█████     | 5043/10000 [00:34<00:33, 149.97it/s]Running 10000 simulations.:  51%|█████     | 5059/10000 [00:34<00:32, 150.29it/s]Running 10000 simulations.:  51%|█████     | 5075/10000 [00:34<00:32, 149.82it/s]Running 10000 simulations.:  51%|█████     | 5091/10000 [00:34<00:32, 150.00it/s]Running 10000 simulations.:  51%|█████     | 5107/10000 [00:34<00:32, 150.17it/s]Running 10000 simulations.:  51%|█████     | 5123/10000 [00:34<00:32, 150.14it/s]Running 10000 simulations.:  51%|█████▏    | 5139/10000 [00:34<00:32, 150.15it/s]Running 10000 simulations.:  52%|█████▏    | 5155/10000 [00:34<00:32, 150.24it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:34<00:31, 151.03it/s]Running 10000 simulations.:  52%|█████▏    | 5187/10000 [00:34<00:31, 150.81it/s]Running 10000 simulations.:  52%|█████▏    | 5203/10000 [00:35<00:31, 150.27it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:35<00:31, 150.21it/s]Running 10000 simulations.:  52%|█████▏    | 5235/10000 [00:35<00:31, 149.82it/s]Running 10000 simulations.:  52%|█████▎    | 5250/10000 [00:35<00:31, 149.62it/s]Running 10000 simulations.:  53%|█████▎    | 5265/10000 [00:35<00:31, 147.97it/s]Running 10000 simulations.:  53%|█████▎    | 5280/10000 [00:35<00:31, 148.28it/s]Running 10000 simulations.:  53%|█████▎    | 5296/10000 [00:35<00:31, 149.14it/s]Running 10000 simulations.:  53%|█████▎    | 5312/10000 [00:35<00:31, 149.53it/s]Running 10000 simulations.:  53%|█████▎    | 5327/10000 [00:35<00:31, 149.46it/s]Running 10000 simulations.:  53%|█████▎    | 5342/10000 [00:36<00:31, 149.46it/s]Running 10000 simulations.:  54%|█████▎    | 5357/10000 [00:36<00:31, 149.53it/s]Running 10000 simulations.:  54%|█████▎    | 5372/10000 [00:36<00:30, 149.60it/s]Running 10000 simulations.:  54%|█████▍    | 5387/10000 [00:36<00:30, 149.52it/s]Running 10000 simulations.:  54%|█████▍    | 5402/10000 [00:36<00:30, 149.57it/s]Running 10000 simulations.:  54%|█████▍    | 5417/10000 [00:36<00:30, 149.39it/s]Running 10000 simulations.:  54%|█████▍    | 5433/10000 [00:36<00:30, 149.68it/s]Running 10000 simulations.:  54%|█████▍    | 5448/10000 [00:36<00:30, 149.42it/s]Running 10000 simulations.:  55%|█████▍    | 5464/10000 [00:36<00:30, 149.70it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:36<00:30, 149.38it/s]Running 10000 simulations.:  55%|█████▍    | 5494/10000 [00:37<00:30, 149.48it/s]Running 10000 simulations.:  55%|█████▌    | 5509/10000 [00:37<00:30, 149.44it/s]Running 10000 simulations.:  55%|█████▌    | 5524/10000 [00:37<00:29, 149.46it/s]Running 10000 simulations.:  55%|█████▌    | 5539/10000 [00:37<00:29, 149.23it/s]Running 10000 simulations.:  56%|█████▌    | 5554/10000 [00:37<00:29, 149.12it/s]Running 10000 simulations.:  56%|█████▌    | 5569/10000 [00:37<00:29, 148.93it/s]Running 10000 simulations.:  56%|█████▌    | 5584/10000 [00:37<00:29, 148.84it/s]Running 10000 simulations.:  56%|█████▌    | 5599/10000 [00:37<00:29, 149.00it/s]Running 10000 simulations.:  56%|█████▌    | 5615/10000 [00:37<00:29, 149.42it/s]Running 10000 simulations.:  56%|█████▋    | 5630/10000 [00:37<00:29, 149.39it/s]Running 10000 simulations.:  56%|█████▋    | 5645/10000 [00:38<00:29, 149.17it/s]Running 10000 simulations.:  57%|█████▋    | 5660/10000 [00:38<00:29, 149.15it/s]Running 10000 simulations.:  57%|█████▋    | 5675/10000 [00:38<00:28, 149.36it/s]Running 10000 simulations.:  57%|█████▋    | 5690/10000 [00:38<00:28, 149.12it/s]Running 10000 simulations.:  57%|█████▋    | 5705/10000 [00:38<00:28, 149.20it/s]Running 10000 simulations.:  57%|█████▋    | 5720/10000 [00:38<00:28, 149.38it/s]Running 10000 simulations.:  57%|█████▋    | 5736/10000 [00:38<00:28, 149.65it/s]Running 10000 simulations.:  58%|█████▊    | 5751/10000 [00:38<00:28, 149.62it/s]Running 10000 simulations.:  58%|█████▊    | 5766/10000 [00:38<00:28, 149.64it/s]Running 10000 simulations.:  58%|█████▊    | 5781/10000 [00:38<00:28, 149.74it/s]Running 10000 simulations.:  58%|█████▊    | 5796/10000 [00:39<00:28, 149.50it/s]Running 10000 simulations.:  58%|█████▊    | 5811/10000 [00:39<00:28, 149.48it/s]Running 10000 simulations.:  58%|█████▊    | 5827/10000 [00:39<00:27, 149.79it/s]Running 10000 simulations.:  58%|█████▊    | 5843/10000 [00:39<00:27, 150.58it/s]Running 10000 simulations.:  59%|█████▊    | 5859/10000 [00:39<00:27, 150.34it/s]Running 10000 simulations.:  59%|█████▉    | 5875/10000 [00:39<00:27, 150.32it/s]Running 10000 simulations.:  59%|█████▉    | 5891/10000 [00:39<00:27, 150.08it/s]Running 10000 simulations.:  59%|█████▉    | 5907/10000 [00:39<00:27, 150.44it/s]Running 10000 simulations.:  59%|█████▉    | 5923/10000 [00:39<00:27, 150.66it/s]Running 10000 simulations.:  59%|█████▉    | 5939/10000 [00:40<00:26, 150.48it/s]Running 10000 simulations.:  60%|█████▉    | 5955/10000 [00:40<00:26, 150.59it/s]Running 10000 simulations.:  60%|█████▉    | 5971/10000 [00:40<00:26, 152.01it/s]Running 10000 simulations.:  60%|█████▉    | 5987/10000 [00:40<00:26, 152.38it/s]Running 10000 simulations.:  60%|██████    | 6003/10000 [00:40<00:26, 152.89it/s]Running 10000 simulations.:  60%|██████    | 6019/10000 [00:40<00:25, 153.23it/s]Running 10000 simulations.:  60%|██████    | 6035/10000 [00:40<00:25, 152.96it/s]Running 10000 simulations.:  61%|██████    | 6051/10000 [00:40<00:25, 152.90it/s]Running 10000 simulations.:  61%|██████    | 6067/10000 [00:40<00:25, 152.52it/s]Running 10000 simulations.:  61%|██████    | 6083/10000 [00:40<00:25, 152.56it/s]Running 10000 simulations.:  61%|██████    | 6099/10000 [00:41<00:25, 152.69it/s]Running 10000 simulations.:  61%|██████    | 6115/10000 [00:41<00:25, 152.86it/s]Running 10000 simulations.:  61%|██████▏   | 6131/10000 [00:41<00:25, 152.83it/s]Running 10000 simulations.:  61%|██████▏   | 6147/10000 [00:41<00:25, 152.81it/s]Running 10000 simulations.:  62%|██████▏   | 6163/10000 [00:41<00:24, 153.73it/s]Running 10000 simulations.:  62%|██████▏   | 6179/10000 [00:41<00:24, 153.19it/s]Running 10000 simulations.:  62%|██████▏   | 6195/10000 [00:41<00:24, 152.71it/s]Running 10000 simulations.:  62%|██████▏   | 6211/10000 [00:41<00:24, 152.01it/s]Running 10000 simulations.:  62%|██████▏   | 6227/10000 [00:41<00:24, 152.12it/s]Running 10000 simulations.:  62%|██████▏   | 6243/10000 [00:41<00:24, 152.16it/s]Running 10000 simulations.:  63%|██████▎   | 6259/10000 [00:42<00:24, 151.82it/s]Running 10000 simulations.:  63%|██████▎   | 6275/10000 [00:42<00:24, 151.34it/s]Running 10000 simulations.:  63%|██████▎   | 6291/10000 [00:42<00:24, 150.54it/s]Running 10000 simulations.:  63%|██████▎   | 6307/10000 [00:42<00:24, 150.04it/s]Running 10000 simulations.:  63%|██████▎   | 6323/10000 [00:42<00:24, 150.57it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:42<00:24, 151.96it/s]Running 10000 simulations.:  64%|██████▎   | 6355/10000 [00:42<00:23, 152.23it/s]Running 10000 simulations.:  64%|██████▎   | 6371/10000 [00:42<00:23, 152.69it/s]Running 10000 simulations.:  64%|██████▍   | 6387/10000 [00:42<00:23, 153.07it/s]Running 10000 simulations.:  64%|██████▍   | 6403/10000 [00:43<00:23, 152.70it/s]Running 10000 simulations.:  64%|██████▍   | 6419/10000 [00:43<00:23, 153.03it/s]Running 10000 simulations.:  64%|██████▍   | 6435/10000 [00:43<00:23, 153.07it/s]Running 10000 simulations.:  65%|██████▍   | 6451/10000 [00:43<00:23, 153.23it/s]Running 10000 simulations.:  65%|██████▍   | 6467/10000 [00:43<00:23, 153.32it/s]Running 10000 simulations.:  65%|██████▍   | 6483/10000 [00:43<00:22, 153.37it/s]Running 10000 simulations.:  65%|██████▍   | 6499/10000 [00:43<00:22, 153.87it/s]Running 10000 simulations.:  65%|██████▌   | 6515/10000 [00:43<00:22, 154.53it/s]Running 10000 simulations.:  65%|██████▌   | 6531/10000 [00:43<00:22, 154.08it/s]Running 10000 simulations.:  65%|██████▌   | 6547/10000 [00:43<00:22, 153.81it/s]Running 10000 simulations.:  66%|██████▌   | 6563/10000 [00:44<00:22, 154.99it/s]Running 10000 simulations.:  66%|██████▌   | 6579/10000 [00:44<00:22, 155.05it/s]Running 10000 simulations.:  66%|██████▌   | 6595/10000 [00:44<00:21, 155.38it/s]Running 10000 simulations.:  66%|██████▌   | 6611/10000 [00:44<00:22, 153.83it/s]Running 10000 simulations.:  66%|██████▋   | 6627/10000 [00:44<00:21, 153.63it/s]Running 10000 simulations.:  66%|██████▋   | 6643/10000 [00:44<00:21, 154.22it/s]Running 10000 simulations.:  67%|██████▋   | 6659/10000 [00:44<00:21, 154.27it/s]Running 10000 simulations.:  67%|██████▋   | 6675/10000 [00:44<00:21, 154.43it/s]Running 10000 simulations.:  67%|██████▋   | 6691/10000 [00:44<00:21, 154.26it/s]Running 10000 simulations.:  67%|██████▋   | 6707/10000 [00:45<00:21, 154.00it/s]Running 10000 simulations.:  67%|██████▋   | 6723/10000 [00:45<00:21, 154.35it/s]Running 10000 simulations.:  67%|██████▋   | 6739/10000 [00:45<00:21, 154.13it/s]Running 10000 simulations.:  68%|██████▊   | 6755/10000 [00:45<00:21, 154.17it/s]Running 10000 simulations.:  68%|██████▊   | 6771/10000 [00:45<00:20, 154.48it/s]Running 10000 simulations.:  68%|██████▊   | 6787/10000 [00:45<00:20, 154.55it/s]Running 10000 simulations.:  68%|██████▊   | 6803/10000 [00:45<00:20, 154.31it/s]Running 10000 simulations.:  68%|██████▊   | 6819/10000 [00:45<00:20, 153.83it/s]Running 10000 simulations.:  68%|██████▊   | 6835/10000 [00:45<00:20, 153.71it/s]Running 10000 simulations.:  69%|██████▊   | 6851/10000 [00:45<00:20, 153.67it/s]Running 10000 simulations.:  69%|██████▊   | 6867/10000 [00:46<00:20, 153.84it/s]Running 10000 simulations.:  69%|██████▉   | 6883/10000 [00:46<00:20, 153.57it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:46<00:20, 153.42it/s]Running 10000 simulations.:  69%|██████▉   | 6915/10000 [00:46<00:20, 153.28it/s]Running 10000 simulations.:  69%|██████▉   | 6931/10000 [00:46<00:19, 153.50it/s]Running 10000 simulations.:  69%|██████▉   | 6947/10000 [00:46<00:19, 153.65it/s]Running 10000 simulations.:  70%|██████▉   | 6963/10000 [00:46<00:19, 153.74it/s]Running 10000 simulations.:  70%|██████▉   | 6979/10000 [00:46<00:19, 153.68it/s]Running 10000 simulations.:  70%|██████▉   | 6995/10000 [00:46<00:19, 153.30it/s]Running 10000 simulations.:  70%|███████   | 7011/10000 [00:47<00:19, 153.31it/s]Running 10000 simulations.:  70%|███████   | 7027/10000 [00:47<00:19, 153.30it/s]Running 10000 simulations.:  70%|███████   | 7043/10000 [00:47<00:19, 153.30it/s]Running 10000 simulations.:  71%|███████   | 7059/10000 [00:47<00:19, 153.38it/s]Running 10000 simulations.:  71%|███████   | 7075/10000 [00:47<00:19, 153.59it/s]Running 10000 simulations.:  71%|███████   | 7091/10000 [00:47<00:18, 153.61it/s]Running 10000 simulations.:  71%|███████   | 7107/10000 [00:47<00:18, 154.22it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:47<00:18, 154.71it/s]Running 10000 simulations.:  71%|███████▏  | 7139/10000 [00:47<00:18, 154.73it/s]Running 10000 simulations.:  72%|███████▏  | 7155/10000 [00:47<00:18, 155.01it/s]Running 10000 simulations.:  72%|███████▏  | 7171/10000 [00:48<00:18, 155.09it/s]Running 10000 simulations.:  72%|███████▏  | 7187/10000 [00:48<00:18, 154.79it/s]Running 10000 simulations.:  72%|███████▏  | 7203/10000 [00:48<00:18, 154.07it/s]Running 10000 simulations.:  72%|███████▏  | 7219/10000 [00:48<00:18, 153.49it/s]Running 10000 simulations.:  72%|███████▏  | 7235/10000 [00:48<00:18, 153.42it/s]Running 10000 simulations.:  73%|███████▎  | 7251/10000 [00:48<00:17, 153.18it/s]Running 10000 simulations.:  73%|███████▎  | 7267/10000 [00:48<00:17, 154.45it/s]Running 10000 simulations.:  73%|███████▎  | 7283/10000 [00:48<00:17, 151.69it/s]Running 10000 simulations.:  73%|███████▎  | 7299/10000 [00:48<00:17, 152.55it/s]Running 10000 simulations.:  73%|███████▎  | 7315/10000 [00:48<00:17, 153.13it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:49<00:18, 145.81it/s]Running 10000 simulations.:  73%|███████▎  | 7347/10000 [00:49<00:17, 148.35it/s]Running 10000 simulations.:  74%|███████▎  | 7363/10000 [00:49<00:17, 150.01it/s]Running 10000 simulations.:  74%|███████▍  | 7379/10000 [00:49<00:17, 151.46it/s]Running 10000 simulations.:  74%|███████▍  | 7395/10000 [00:49<00:17, 152.76it/s]Running 10000 simulations.:  74%|███████▍  | 7411/10000 [00:49<00:16, 153.51it/s]Running 10000 simulations.:  74%|███████▍  | 7427/10000 [00:49<00:16, 153.44it/s]Running 10000 simulations.:  74%|███████▍  | 7443/10000 [00:49<00:16, 152.95it/s]Running 10000 simulations.:  75%|███████▍  | 7459/10000 [00:49<00:16, 153.62it/s]Running 10000 simulations.:  75%|███████▍  | 7475/10000 [00:50<00:16, 153.46it/s]Running 10000 simulations.:  75%|███████▍  | 7491/10000 [00:50<00:16, 153.34it/s]Running 10000 simulations.:  75%|███████▌  | 7507/10000 [00:50<00:16, 153.90it/s]Running 10000 simulations.:  75%|███████▌  | 7523/10000 [00:50<00:16, 153.89it/s]Running 10000 simulations.:  75%|███████▌  | 7539/10000 [00:50<00:16, 153.27it/s]Running 10000 simulations.:  76%|███████▌  | 7555/10000 [00:50<00:16, 152.36it/s]Running 10000 simulations.:  76%|███████▌  | 7571/10000 [00:50<00:15, 152.29it/s]Running 10000 simulations.:  76%|███████▌  | 7587/10000 [00:50<00:15, 152.57it/s]Running 10000 simulations.:  76%|███████▌  | 7603/10000 [00:50<00:15, 152.83it/s]Running 10000 simulations.:  76%|███████▌  | 7619/10000 [00:50<00:15, 153.37it/s]Running 10000 simulations.:  76%|███████▋  | 7635/10000 [00:51<00:15, 153.65it/s]Running 10000 simulations.:  77%|███████▋  | 7651/10000 [00:51<00:15, 153.62it/s]Running 10000 simulations.:  77%|███████▋  | 7667/10000 [00:51<00:15, 152.72it/s]Running 10000 simulations.:  77%|███████▋  | 7683/10000 [00:51<00:15, 151.40it/s]Running 10000 simulations.:  77%|███████▋  | 7699/10000 [00:51<00:15, 152.09it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:51<00:14, 152.86it/s]Running 10000 simulations.:  77%|███████▋  | 7731/10000 [00:51<00:14, 153.29it/s]Running 10000 simulations.:  77%|███████▋  | 7747/10000 [00:51<00:14, 153.15it/s]Running 10000 simulations.:  78%|███████▊  | 7763/10000 [00:51<00:14, 153.00it/s]Running 10000 simulations.:  78%|███████▊  | 7779/10000 [00:52<00:14, 152.94it/s]Running 10000 simulations.:  78%|███████▊  | 7795/10000 [00:52<00:14, 152.32it/s]Running 10000 simulations.:  78%|███████▊  | 7811/10000 [00:52<00:14, 152.35it/s]Running 10000 simulations.:  78%|███████▊  | 7827/10000 [00:52<00:14, 152.63it/s]Running 10000 simulations.:  78%|███████▊  | 7843/10000 [00:52<00:14, 152.42it/s]Running 10000 simulations.:  79%|███████▊  | 7859/10000 [00:52<00:14, 152.43it/s]Running 10000 simulations.:  79%|███████▉  | 7875/10000 [00:52<00:13, 152.27it/s]Running 10000 simulations.:  79%|███████▉  | 7891/10000 [00:52<00:13, 151.51it/s]Running 10000 simulations.:  79%|███████▉  | 7907/10000 [00:52<00:13, 151.51it/s]Running 10000 simulations.:  79%|███████▉  | 7923/10000 [00:52<00:13, 151.77it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:53<00:13, 152.03it/s]Running 10000 simulations.:  80%|███████▉  | 7955/10000 [00:53<00:13, 152.24it/s]Running 10000 simulations.:  80%|███████▉  | 7971/10000 [00:53<00:13, 152.15it/s]Running 10000 simulations.:  80%|███████▉  | 7987/10000 [00:53<00:13, 152.10it/s]Running 10000 simulations.:  80%|████████  | 8003/10000 [00:53<00:13, 152.42it/s]Running 10000 simulations.:  80%|████████  | 8019/10000 [00:53<00:13, 152.31it/s]Running 10000 simulations.:  80%|████████  | 8035/10000 [00:53<00:12, 152.15it/s]Running 10000 simulations.:  81%|████████  | 8051/10000 [00:53<00:12, 152.27it/s]Running 10000 simulations.:  81%|████████  | 8067/10000 [00:53<00:12, 152.53it/s]Running 10000 simulations.:  81%|████████  | 8083/10000 [00:54<00:12, 152.50it/s]Running 10000 simulations.:  81%|████████  | 8099/10000 [00:54<00:12, 152.54it/s]Running 10000 simulations.:  81%|████████  | 8115/10000 [00:54<00:12, 152.73it/s]Running 10000 simulations.:  81%|████████▏ | 8131/10000 [00:54<00:12, 153.05it/s]Running 10000 simulations.:  81%|████████▏ | 8147/10000 [00:54<00:12, 153.03it/s]Running 10000 simulations.:  82%|████████▏ | 8163/10000 [00:54<00:12, 152.89it/s]Running 10000 simulations.:  82%|████████▏ | 8179/10000 [00:54<00:11, 152.38it/s]Running 10000 simulations.:  82%|████████▏ | 8195/10000 [00:54<00:11, 152.44it/s]Running 10000 simulations.:  82%|████████▏ | 8211/10000 [00:54<00:11, 152.23it/s]Running 10000 simulations.:  82%|████████▏ | 8227/10000 [00:54<00:11, 152.19it/s]Running 10000 simulations.:  82%|████████▏ | 8243/10000 [00:55<00:11, 152.84it/s]Running 10000 simulations.:  83%|████████▎ | 8259/10000 [00:55<00:11, 152.81it/s]Running 10000 simulations.:  83%|████████▎ | 8275/10000 [00:55<00:11, 152.89it/s]Running 10000 simulations.:  83%|████████▎ | 8291/10000 [00:55<00:11, 153.11it/s]Running 10000 simulations.:  83%|████████▎ | 8307/10000 [00:55<00:11, 152.90it/s]Running 10000 simulations.:  83%|████████▎ | 8323/10000 [00:55<00:10, 153.53it/s]Running 10000 simulations.:  83%|████████▎ | 8339/10000 [00:55<00:10, 153.47it/s]Running 10000 simulations.:  84%|████████▎ | 8355/10000 [00:55<00:10, 153.68it/s]Running 10000 simulations.:  84%|████████▎ | 8371/10000 [00:55<00:10, 154.08it/s]Running 10000 simulations.:  84%|████████▍ | 8387/10000 [00:56<00:10, 154.63it/s]Running 10000 simulations.:  84%|████████▍ | 8403/10000 [00:56<00:10, 154.40it/s]Running 10000 simulations.:  84%|████████▍ | 8419/10000 [00:56<00:10, 154.33it/s]Running 10000 simulations.:  84%|████████▍ | 8435/10000 [00:56<00:10, 154.33it/s]Running 10000 simulations.:  85%|████████▍ | 8451/10000 [00:56<00:10, 154.49it/s]Running 10000 simulations.:  85%|████████▍ | 8467/10000 [00:56<00:09, 154.87it/s]Running 10000 simulations.:  85%|████████▍ | 8483/10000 [00:56<00:09, 155.29it/s]Running 10000 simulations.:  85%|████████▍ | 8499/10000 [00:56<00:09, 154.90it/s]Running 10000 simulations.:  85%|████████▌ | 8515/10000 [00:56<00:09, 154.85it/s]Running 10000 simulations.:  85%|████████▌ | 8531/10000 [00:56<00:09, 154.49it/s]Running 10000 simulations.:  85%|████████▌ | 8547/10000 [00:57<00:09, 154.28it/s]Running 10000 simulations.:  86%|████████▌ | 8563/10000 [00:57<00:09, 154.36it/s]Running 10000 simulations.:  86%|████████▌ | 8579/10000 [00:57<00:09, 154.21it/s]Running 10000 simulations.:  86%|████████▌ | 8595/10000 [00:57<00:09, 154.12it/s]Running 10000 simulations.:  86%|████████▌ | 8611/10000 [00:57<00:09, 153.86it/s]Running 10000 simulations.:  86%|████████▋ | 8627/10000 [00:57<00:08, 154.77it/s]Running 10000 simulations.:  86%|████████▋ | 8643/10000 [00:57<00:08, 154.47it/s]Running 10000 simulations.:  87%|████████▋ | 8659/10000 [00:57<00:08, 154.11it/s]Running 10000 simulations.:  87%|████████▋ | 8675/10000 [00:57<00:08, 153.62it/s]Running 10000 simulations.:  87%|████████▋ | 8691/10000 [00:57<00:08, 153.56it/s]Running 10000 simulations.:  87%|████████▋ | 8707/10000 [00:58<00:08, 153.48it/s]Running 10000 simulations.:  87%|████████▋ | 8723/10000 [00:58<00:08, 153.86it/s]Running 10000 simulations.:  87%|████████▋ | 8739/10000 [00:58<00:08, 153.68it/s]Running 10000 simulations.:  88%|████████▊ | 8755/10000 [00:58<00:08, 153.53it/s]Running 10000 simulations.:  88%|████████▊ | 8771/10000 [00:58<00:07, 153.86it/s]Running 10000 simulations.:  88%|████████▊ | 8787/10000 [00:58<00:07, 154.02it/s]Running 10000 simulations.:  88%|████████▊ | 8803/10000 [00:58<00:07, 153.79it/s]Running 10000 simulations.:  88%|████████▊ | 8819/10000 [00:58<00:07, 153.85it/s]Running 10000 simulations.:  88%|████████▊ | 8835/10000 [00:58<00:07, 152.73it/s]Running 10000 simulations.:  89%|████████▊ | 8851/10000 [00:59<00:07, 152.81it/s]Running 10000 simulations.:  89%|████████▊ | 8867/10000 [00:59<00:07, 152.68it/s]Running 10000 simulations.:  89%|████████▉ | 8883/10000 [00:59<00:07, 153.35it/s]Running 10000 simulations.:  89%|████████▉ | 8899/10000 [00:59<00:07, 152.86it/s]Running 10000 simulations.:  89%|████████▉ | 8915/10000 [00:59<00:07, 153.01it/s]Running 10000 simulations.:  89%|████████▉ | 8931/10000 [00:59<00:06, 153.12it/s]Running 10000 simulations.:  89%|████████▉ | 8947/10000 [00:59<00:06, 152.76it/s]Running 10000 simulations.:  90%|████████▉ | 8963/10000 [00:59<00:06, 150.72it/s]Running 10000 simulations.:  90%|████████▉ | 8979/10000 [00:59<00:06, 151.81it/s]Running 10000 simulations.:  90%|████████▉ | 8995/10000 [00:59<00:06, 152.01it/s]Running 10000 simulations.:  90%|█████████ | 9011/10000 [01:00<00:06, 151.69it/s]Running 10000 simulations.:  90%|█████████ | 9027/10000 [01:00<00:06, 151.42it/s]Running 10000 simulations.:  90%|█████████ | 9043/10000 [01:00<00:06, 151.53it/s]Running 10000 simulations.:  91%|█████████ | 9059/10000 [01:00<00:06, 152.64it/s]Running 10000 simulations.:  91%|█████████ | 9075/10000 [01:00<00:06, 153.25it/s]Running 10000 simulations.:  91%|█████████ | 9091/10000 [01:00<00:05, 153.12it/s]Running 10000 simulations.:  91%|█████████ | 9107/10000 [01:00<00:05, 153.21it/s]Running 10000 simulations.:  91%|█████████ | 9123/10000 [01:00<00:05, 153.67it/s]Running 10000 simulations.:  91%|█████████▏| 9139/10000 [01:00<00:05, 153.77it/s]Running 10000 simulations.:  92%|█████████▏| 9155/10000 [01:01<00:05, 153.35it/s]Running 10000 simulations.:  92%|█████████▏| 9171/10000 [01:01<00:05, 153.02it/s]Running 10000 simulations.:  92%|█████████▏| 9187/10000 [01:01<00:05, 152.93it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [01:01<00:05, 152.58it/s]Running 10000 simulations.:  92%|█████████▏| 9219/10000 [01:01<00:05, 152.44it/s]Running 10000 simulations.:  92%|█████████▏| 9235/10000 [01:01<00:05, 152.38it/s]Running 10000 simulations.:  93%|█████████▎| 9251/10000 [01:01<00:04, 152.32it/s]Running 10000 simulations.:  93%|█████████▎| 9267/10000 [01:01<00:04, 152.19it/s]Running 10000 simulations.:  93%|█████████▎| 9283/10000 [01:01<00:04, 152.23it/s]Running 10000 simulations.:  93%|█████████▎| 9299/10000 [01:01<00:04, 151.92it/s]Running 10000 simulations.:  93%|█████████▎| 9315/10000 [01:02<00:04, 151.84it/s]Running 10000 simulations.:  93%|█████████▎| 9331/10000 [01:02<00:04, 151.75it/s]Running 10000 simulations.:  93%|█████████▎| 9347/10000 [01:02<00:04, 151.70it/s]Running 10000 simulations.:  94%|█████████▎| 9363/10000 [01:02<00:04, 151.93it/s]Running 10000 simulations.:  94%|█████████▍| 9379/10000 [01:02<00:04, 152.03it/s]Running 10000 simulations.:  94%|█████████▍| 9395/10000 [01:02<00:03, 152.43it/s]Running 10000 simulations.:  94%|█████████▍| 9411/10000 [01:02<00:03, 152.22it/s]Running 10000 simulations.:  94%|█████████▍| 9427/10000 [01:02<00:03, 152.19it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [01:02<00:03, 152.23it/s]Running 10000 simulations.:  95%|█████████▍| 9459/10000 [01:03<00:03, 152.11it/s]Running 10000 simulations.:  95%|█████████▍| 9475/10000 [01:03<00:03, 152.21it/s]Running 10000 simulations.:  95%|█████████▍| 9491/10000 [01:03<00:03, 152.44it/s]Running 10000 simulations.:  95%|█████████▌| 9507/10000 [01:03<00:03, 152.69it/s]Running 10000 simulations.:  95%|█████████▌| 9523/10000 [01:03<00:03, 152.55it/s]Running 10000 simulations.:  95%|█████████▌| 9539/10000 [01:03<00:03, 152.35it/s]Running 10000 simulations.:  96%|█████████▌| 9555/10000 [01:03<00:02, 152.65it/s]Running 10000 simulations.:  96%|█████████▌| 9571/10000 [01:03<00:02, 152.70it/s]Running 10000 simulations.:  96%|█████████▌| 9587/10000 [01:03<00:02, 153.05it/s]Running 10000 simulations.:  96%|█████████▌| 9603/10000 [01:03<00:02, 153.10it/s]Running 10000 simulations.:  96%|█████████▌| 9619/10000 [01:04<00:02, 152.63it/s]Running 10000 simulations.:  96%|█████████▋| 9635/10000 [01:04<00:02, 152.53it/s]Running 10000 simulations.:  97%|█████████▋| 9651/10000 [01:04<00:02, 152.36it/s]Running 10000 simulations.:  97%|█████████▋| 9667/10000 [01:04<00:02, 153.02it/s]Running 10000 simulations.:  97%|█████████▋| 9683/10000 [01:04<00:02, 153.13it/s]Running 10000 simulations.:  97%|█████████▋| 9699/10000 [01:04<00:02, 150.46it/s]Running 10000 simulations.:  97%|█████████▋| 9715/10000 [01:04<00:01, 150.15it/s]Running 10000 simulations.:  97%|█████████▋| 9731/10000 [01:04<00:01, 150.83it/s]Running 10000 simulations.:  97%|█████████▋| 9747/10000 [01:04<00:01, 151.64it/s]Running 10000 simulations.:  98%|█████████▊| 9763/10000 [01:05<00:01, 151.92it/s]Running 10000 simulations.:  98%|█████████▊| 9779/10000 [01:05<00:01, 151.96it/s]Running 10000 simulations.:  98%|█████████▊| 9795/10000 [01:05<00:01, 152.58it/s]Running 10000 simulations.:  98%|█████████▊| 9811/10000 [01:05<00:01, 152.64it/s]Running 10000 simulations.:  98%|█████████▊| 9827/10000 [01:05<00:01, 152.43it/s]Running 10000 simulations.:  98%|█████████▊| 9843/10000 [01:05<00:01, 152.48it/s]Running 10000 simulations.:  99%|█████████▊| 9859/10000 [01:05<00:00, 152.68it/s]Running 10000 simulations.:  99%|█████████▉| 9875/10000 [01:05<00:00, 152.95it/s]Running 10000 simulations.:  99%|█████████▉| 9891/10000 [01:05<00:00, 153.19it/s]Running 10000 simulations.:  99%|█████████▉| 9907/10000 [01:05<00:00, 153.33it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [01:06<00:00, 154.46it/s]Running 10000 simulations.:  99%|█████████▉| 9939/10000 [01:06<00:00, 154.91it/s]Running 10000 simulations.: 100%|█████████▉| 9955/10000 [01:06<00:00, 154.38it/s]Running 10000 simulations.: 100%|█████████▉| 9971/10000 [01:06<00:00, 154.14it/s]Running 10000 simulations.: 100%|█████████▉| 9987/10000 [01:06<00:00, 154.08it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:06<00:00, 150.27it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 16/10000 [00:00<01:03, 157.66it/s]Running 10000 simulations.:   0%|          | 32/10000 [00:00<01:03, 156.14it/s]Running 10000 simulations.:   0%|          | 47/10000 [00:00<01:04, 153.49it/s]Running 10000 simulations.:   1%|          | 62/10000 [00:00<01:05, 152.10it/s]Running 10000 simulations.:   1%|          | 77/10000 [00:00<01:06, 150.21it/s]Running 10000 simulations.:   1%|          | 93/10000 [00:00<01:05, 151.63it/s]Running 10000 simulations.:   1%|          | 111/10000 [00:00<01:02, 157.83it/s]Running 10000 simulations.:   1%|▏         | 129/10000 [00:00<01:00, 162.19it/s]Running 10000 simulations.:   1%|▏         | 146/10000 [00:00<01:00, 161.66it/s]Running 10000 simulations.:   2%|▏         | 162/10000 [00:01<01:02, 156.43it/s]Running 10000 simulations.:   2%|▏         | 178/10000 [00:01<01:04, 153.18it/s]Running 10000 simulations.:   2%|▏         | 194/10000 [00:01<01:04, 152.58it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:01<01:05, 149.92it/s]Running 10000 simulations.:   2%|▏         | 226/10000 [00:01<01:05, 150.08it/s]Running 10000 simulations.:   2%|▏         | 242/10000 [00:01<01:04, 150.34it/s]Running 10000 simulations.:   3%|▎         | 258/10000 [00:01<01:04, 150.79it/s]Running 10000 simulations.:   3%|▎         | 274/10000 [00:01<01:04, 149.81it/s]Running 10000 simulations.:   3%|▎         | 289/10000 [00:01<01:05, 149.21it/s]Running 10000 simulations.:   3%|▎         | 304/10000 [00:01<01:05, 148.53it/s]Running 10000 simulations.:   3%|▎         | 320/10000 [00:02<01:04, 149.11it/s]Running 10000 simulations.:   3%|▎         | 336/10000 [00:02<01:04, 149.51it/s]Running 10000 simulations.:   4%|▎         | 352/10000 [00:02<01:04, 149.60it/s]Running 10000 simulations.:   4%|▎         | 367/10000 [00:02<01:04, 149.44it/s]Running 10000 simulations.:   4%|▍         | 382/10000 [00:02<01:04, 148.50it/s]Running 10000 simulations.:   4%|▍         | 397/10000 [00:02<01:05, 146.72it/s]Running 10000 simulations.:   4%|▍         | 412/10000 [00:02<01:05, 145.89it/s]Running 10000 simulations.:   4%|▍         | 427/10000 [00:02<01:05, 146.68it/s]Running 10000 simulations.:   4%|▍         | 442/10000 [00:02<01:05, 146.80it/s]Running 10000 simulations.:   5%|▍         | 457/10000 [00:03<01:04, 146.97it/s]Running 10000 simulations.:   5%|▍         | 472/10000 [00:03<01:05, 146.24it/s]Running 10000 simulations.:   5%|▍         | 487/10000 [00:03<01:05, 145.97it/s]Running 10000 simulations.:   5%|▌         | 502/10000 [00:03<01:04, 147.14it/s]Running 10000 simulations.:   5%|▌         | 518/10000 [00:03<01:04, 148.11it/s]Running 10000 simulations.:   5%|▌         | 533/10000 [00:03<01:04, 146.89it/s]Running 10000 simulations.:   5%|▌         | 548/10000 [00:03<01:04, 146.69it/s]Running 10000 simulations.:   6%|▌         | 563/10000 [00:03<01:04, 146.39it/s]Running 10000 simulations.:   6%|▌         | 578/10000 [00:03<01:04, 146.97it/s]Running 10000 simulations.:   6%|▌         | 593/10000 [00:03<01:03, 147.60it/s]Running 10000 simulations.:   6%|▌         | 609/10000 [00:04<01:03, 148.69it/s]Running 10000 simulations.:   6%|▌         | 624/10000 [00:04<01:03, 148.35it/s]Running 10000 simulations.:   6%|▋         | 639/10000 [00:04<01:03, 147.65it/s]Running 10000 simulations.:   7%|▋         | 654/10000 [00:04<01:03, 146.65it/s]Running 10000 simulations.:   7%|▋         | 669/10000 [00:04<01:03, 147.37it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:04<01:02, 148.08it/s]Running 10000 simulations.:   7%|▋         | 700/10000 [00:04<01:02, 148.61it/s]Running 10000 simulations.:   7%|▋         | 715/10000 [00:04<01:02, 147.53it/s]Running 10000 simulations.:   7%|▋         | 730/10000 [00:04<01:03, 146.67it/s]Running 10000 simulations.:   7%|▋         | 745/10000 [00:04<01:03, 146.59it/s]Running 10000 simulations.:   8%|▊         | 760/10000 [00:05<01:03, 145.53it/s]Running 10000 simulations.:   8%|▊         | 775/10000 [00:05<01:03, 145.81it/s]Running 10000 simulations.:   8%|▊         | 790/10000 [00:05<01:03, 145.76it/s]Running 10000 simulations.:   8%|▊         | 805/10000 [00:05<01:03, 145.28it/s]Running 10000 simulations.:   8%|▊         | 820/10000 [00:05<01:03, 145.37it/s]Running 10000 simulations.:   8%|▊         | 835/10000 [00:05<01:03, 144.75it/s]Running 10000 simulations.:   8%|▊         | 850/10000 [00:05<01:03, 144.39it/s]Running 10000 simulations.:   9%|▊         | 866/10000 [00:05<01:02, 147.13it/s]Running 10000 simulations.:   9%|▉         | 882/10000 [00:05<01:00, 150.32it/s]Running 10000 simulations.:   9%|▉         | 898/10000 [00:06<01:00, 151.54it/s]Running 10000 simulations.:   9%|▉         | 914/10000 [00:06<00:59, 152.87it/s]Running 10000 simulations.:   9%|▉         | 930/10000 [00:06<00:58, 153.90it/s]Running 10000 simulations.:   9%|▉         | 946/10000 [00:06<00:58, 154.60it/s]Running 10000 simulations.:  10%|▉         | 962/10000 [00:06<00:58, 154.55it/s]Running 10000 simulations.:  10%|▉         | 978/10000 [00:06<00:58, 154.87it/s]Running 10000 simulations.:  10%|▉         | 994/10000 [00:06<00:58, 154.54it/s]Running 10000 simulations.:  10%|█         | 1010/10000 [00:06<00:58, 154.49it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:06<00:57, 155.20it/s]Running 10000 simulations.:  10%|█         | 1042/10000 [00:06<00:57, 155.56it/s]Running 10000 simulations.:  11%|█         | 1058/10000 [00:07<00:57, 155.82it/s]Running 10000 simulations.:  11%|█         | 1074/10000 [00:07<00:57, 154.66it/s]Running 10000 simulations.:  11%|█         | 1090/10000 [00:07<00:58, 151.94it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:07<00:58, 152.73it/s]Running 10000 simulations.:  11%|█         | 1122/10000 [00:07<00:57, 153.26it/s]Running 10000 simulations.:  11%|█▏        | 1138/10000 [00:07<00:57, 153.94it/s]Running 10000 simulations.:  12%|█▏        | 1154/10000 [00:07<00:57, 154.44it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:07<00:57, 154.73it/s]Running 10000 simulations.:  12%|█▏        | 1186/10000 [00:07<00:56, 154.68it/s]Running 10000 simulations.:  12%|█▏        | 1202/10000 [00:07<00:56, 154.97it/s]Running 10000 simulations.:  12%|█▏        | 1218/10000 [00:08<00:56, 155.21it/s]Running 10000 simulations.:  12%|█▏        | 1234/10000 [00:08<00:56, 155.88it/s]Running 10000 simulations.:  12%|█▎        | 1250/10000 [00:08<00:56, 155.85it/s]Running 10000 simulations.:  13%|█▎        | 1266/10000 [00:08<00:56, 155.42it/s]Running 10000 simulations.:  13%|█▎        | 1282/10000 [00:08<00:56, 155.00it/s]Running 10000 simulations.:  13%|█▎        | 1298/10000 [00:08<00:55, 156.04it/s]Running 10000 simulations.:  13%|█▎        | 1315/10000 [00:08<00:55, 157.43it/s]Running 10000 simulations.:  13%|█▎        | 1331/10000 [00:08<00:54, 157.88it/s]Running 10000 simulations.:  13%|█▎        | 1347/10000 [00:08<00:54, 157.93it/s]Running 10000 simulations.:  14%|█▎        | 1363/10000 [00:09<00:54, 157.86it/s]Running 10000 simulations.:  14%|█▍        | 1379/10000 [00:09<00:54, 157.05it/s]Running 10000 simulations.:  14%|█▍        | 1395/10000 [00:09<00:55, 156.22it/s]Running 10000 simulations.:  14%|█▍        | 1411/10000 [00:09<00:55, 155.63it/s]Running 10000 simulations.:  14%|█▍        | 1427/10000 [00:09<00:55, 155.37it/s]Running 10000 simulations.:  14%|█▍        | 1443/10000 [00:09<00:55, 155.48it/s]Running 10000 simulations.:  15%|█▍        | 1459/10000 [00:09<00:54, 155.75it/s]Running 10000 simulations.:  15%|█▍        | 1475/10000 [00:09<00:54, 155.65it/s]Running 10000 simulations.:  15%|█▍        | 1491/10000 [00:09<00:54, 155.74it/s]Running 10000 simulations.:  15%|█▌        | 1507/10000 [00:09<00:54, 155.15it/s]Running 10000 simulations.:  15%|█▌        | 1523/10000 [00:10<00:54, 155.21it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:10<00:54, 155.55it/s]Running 10000 simulations.:  16%|█▌        | 1555/10000 [00:10<00:54, 156.12it/s]Running 10000 simulations.:  16%|█▌        | 1571/10000 [00:10<00:54, 155.91it/s]Running 10000 simulations.:  16%|█▌        | 1587/10000 [00:10<00:54, 155.10it/s]Running 10000 simulations.:  16%|█▌        | 1603/10000 [00:10<00:54, 154.77it/s]Running 10000 simulations.:  16%|█▌        | 1619/10000 [00:10<00:54, 152.87it/s]Running 10000 simulations.:  16%|█▋        | 1635/10000 [00:10<00:54, 152.54it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:10<00:54, 153.45it/s]Running 10000 simulations.:  17%|█▋        | 1667/10000 [00:10<00:54, 153.93it/s]Running 10000 simulations.:  17%|█▋        | 1683/10000 [00:11<00:53, 154.80it/s]Running 10000 simulations.:  17%|█▋        | 1699/10000 [00:11<00:53, 155.05it/s]Running 10000 simulations.:  17%|█▋        | 1715/10000 [00:11<00:53, 155.23it/s]Running 10000 simulations.:  17%|█▋        | 1731/10000 [00:11<00:53, 155.31it/s]Running 10000 simulations.:  17%|█▋        | 1747/10000 [00:11<00:53, 155.08it/s]Running 10000 simulations.:  18%|█▊        | 1765/10000 [00:11<00:51, 160.02it/s]Running 10000 simulations.:  18%|█▊        | 1782/10000 [00:11<00:50, 161.86it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:11<00:51, 160.11it/s]Running 10000 simulations.:  18%|█▊        | 1816/10000 [00:11<00:51, 158.29it/s]Running 10000 simulations.:  18%|█▊        | 1832/10000 [00:12<00:51, 157.27it/s]Running 10000 simulations.:  18%|█▊        | 1848/10000 [00:12<00:51, 157.28it/s]Running 10000 simulations.:  19%|█▊        | 1864/10000 [00:12<00:51, 157.33it/s]Running 10000 simulations.:  19%|█▉        | 1880/10000 [00:12<00:51, 156.55it/s]Running 10000 simulations.:  19%|█▉        | 1896/10000 [00:12<00:52, 155.70it/s]Running 10000 simulations.:  19%|█▉        | 1912/10000 [00:12<00:51, 155.84it/s]Running 10000 simulations.:  19%|█▉        | 1928/10000 [00:12<00:51, 155.83it/s]Running 10000 simulations.:  19%|█▉        | 1944/10000 [00:12<00:51, 156.34it/s]Running 10000 simulations.:  20%|█▉        | 1960/10000 [00:12<00:51, 156.47it/s]Running 10000 simulations.:  20%|█▉        | 1976/10000 [00:12<00:51, 156.49it/s]Running 10000 simulations.:  20%|█▉        | 1992/10000 [00:13<00:51, 156.46it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:13<00:51, 155.78it/s]Running 10000 simulations.:  20%|██        | 2024/10000 [00:13<00:51, 155.51it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:13<00:51, 155.53it/s]Running 10000 simulations.:  21%|██        | 2056/10000 [00:13<00:51, 155.17it/s]Running 10000 simulations.:  21%|██        | 2072/10000 [00:13<00:50, 155.47it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:13<00:50, 155.64it/s]Running 10000 simulations.:  21%|██        | 2104/10000 [00:13<00:50, 155.73it/s]Running 10000 simulations.:  21%|██        | 2120/10000 [00:13<00:50, 155.59it/s]Running 10000 simulations.:  21%|██▏       | 2136/10000 [00:13<00:50, 155.19it/s]Running 10000 simulations.:  22%|██▏       | 2152/10000 [00:14<00:50, 155.23it/s]Running 10000 simulations.:  22%|██▏       | 2168/10000 [00:14<00:50, 155.84it/s]Running 10000 simulations.:  22%|██▏       | 2184/10000 [00:14<00:50, 156.16it/s]Running 10000 simulations.:  22%|██▏       | 2200/10000 [00:14<00:49, 156.25it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:14<00:49, 156.58it/s]Running 10000 simulations.:  22%|██▏       | 2232/10000 [00:14<00:49, 156.61it/s]Running 10000 simulations.:  22%|██▏       | 2248/10000 [00:14<00:49, 156.42it/s]Running 10000 simulations.:  23%|██▎       | 2264/10000 [00:14<00:49, 156.53it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:14<00:49, 156.28it/s]Running 10000 simulations.:  23%|██▎       | 2296/10000 [00:14<00:49, 156.49it/s]Running 10000 simulations.:  23%|██▎       | 2312/10000 [00:15<00:49, 156.54it/s]Running 10000 simulations.:  23%|██▎       | 2328/10000 [00:15<00:48, 156.90it/s]Running 10000 simulations.:  23%|██▎       | 2344/10000 [00:15<00:48, 156.84it/s]Running 10000 simulations.:  24%|██▎       | 2360/10000 [00:15<00:48, 156.75it/s]Running 10000 simulations.:  24%|██▍       | 2376/10000 [00:15<00:48, 156.56it/s]Running 10000 simulations.:  24%|██▍       | 2392/10000 [00:15<00:48, 155.90it/s]Running 10000 simulations.:  24%|██▍       | 2408/10000 [00:15<00:48, 155.06it/s]Running 10000 simulations.:  24%|██▍       | 2424/10000 [00:15<00:49, 154.15it/s]Running 10000 simulations.:  24%|██▍       | 2440/10000 [00:15<00:49, 153.92it/s]Running 10000 simulations.:  25%|██▍       | 2456/10000 [00:16<00:48, 154.02it/s]Running 10000 simulations.:  25%|██▍       | 2472/10000 [00:16<00:48, 154.29it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:16<00:48, 154.04it/s]Running 10000 simulations.:  25%|██▌       | 2504/10000 [00:16<00:48, 153.80it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:16<00:48, 153.73it/s]Running 10000 simulations.:  25%|██▌       | 2536/10000 [00:16<00:48, 153.90it/s]Running 10000 simulations.:  26%|██▌       | 2552/10000 [00:16<00:48, 154.49it/s]Running 10000 simulations.:  26%|██▌       | 2568/10000 [00:16<00:47, 155.46it/s]Running 10000 simulations.:  26%|██▌       | 2584/10000 [00:16<00:47, 156.29it/s]Running 10000 simulations.:  26%|██▌       | 2600/10000 [00:16<00:47, 156.10it/s]Running 10000 simulations.:  26%|██▌       | 2616/10000 [00:17<00:47, 155.77it/s]Running 10000 simulations.:  26%|██▋       | 2632/10000 [00:17<00:47, 155.97it/s]Running 10000 simulations.:  26%|██▋       | 2648/10000 [00:17<00:46, 156.94it/s]Running 10000 simulations.:  27%|██▋       | 2664/10000 [00:17<00:46, 157.81it/s]Running 10000 simulations.:  27%|██▋       | 2680/10000 [00:17<00:46, 157.96it/s]Running 10000 simulations.:  27%|██▋       | 2696/10000 [00:17<00:46, 157.12it/s]Running 10000 simulations.:  27%|██▋       | 2712/10000 [00:17<00:46, 156.31it/s]Running 10000 simulations.:  27%|██▋       | 2728/10000 [00:17<00:46, 156.45it/s]Running 10000 simulations.:  27%|██▋       | 2744/10000 [00:17<00:46, 157.31it/s]Running 10000 simulations.:  28%|██▊       | 2760/10000 [00:17<00:45, 157.42it/s]Running 10000 simulations.:  28%|██▊       | 2776/10000 [00:18<00:46, 156.08it/s]Running 10000 simulations.:  28%|██▊       | 2792/10000 [00:18<00:46, 156.25it/s]Running 10000 simulations.:  28%|██▊       | 2808/10000 [00:18<00:45, 156.84it/s]Running 10000 simulations.:  28%|██▊       | 2824/10000 [00:18<00:45, 156.49it/s]Running 10000 simulations.:  28%|██▊       | 2840/10000 [00:18<00:45, 157.46it/s]Running 10000 simulations.:  29%|██▊       | 2856/10000 [00:18<00:45, 157.30it/s]Running 10000 simulations.:  29%|██▊       | 2872/10000 [00:18<00:45, 156.82it/s]Running 10000 simulations.:  29%|██▉       | 2888/10000 [00:18<00:45, 156.53it/s]Running 10000 simulations.:  29%|██▉       | 2904/10000 [00:18<00:45, 156.54it/s]Running 10000 simulations.:  29%|██▉       | 2920/10000 [00:18<00:45, 156.73it/s]Running 10000 simulations.:  29%|██▉       | 2936/10000 [00:19<00:45, 156.50it/s]Running 10000 simulations.:  30%|██▉       | 2952/10000 [00:19<00:44, 156.67it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:19<00:45, 155.55it/s]Running 10000 simulations.:  30%|██▉       | 2984/10000 [00:19<00:45, 154.65it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:19<00:45, 154.88it/s]Running 10000 simulations.:  30%|███       | 3016/10000 [00:19<00:45, 155.00it/s]Running 10000 simulations.:  30%|███       | 3032/10000 [00:19<00:45, 154.82it/s]Running 10000 simulations.:  30%|███       | 3048/10000 [00:19<00:44, 155.31it/s]Running 10000 simulations.:  31%|███       | 3064/10000 [00:19<00:44, 155.44it/s]Running 10000 simulations.:  31%|███       | 3080/10000 [00:20<00:44, 154.91it/s]Running 10000 simulations.:  31%|███       | 3096/10000 [00:20<00:44, 155.11it/s]Running 10000 simulations.:  31%|███       | 3112/10000 [00:20<00:44, 155.00it/s]Running 10000 simulations.:  31%|███▏      | 3128/10000 [00:20<00:44, 154.58it/s]Running 10000 simulations.:  31%|███▏      | 3144/10000 [00:20<00:44, 154.82it/s]Running 10000 simulations.:  32%|███▏      | 3160/10000 [00:20<00:44, 155.25it/s]Running 10000 simulations.:  32%|███▏      | 3176/10000 [00:20<00:44, 154.68it/s]Running 10000 simulations.:  32%|███▏      | 3192/10000 [00:20<00:44, 154.66it/s]Running 10000 simulations.:  32%|███▏      | 3208/10000 [00:20<00:43, 154.73it/s]Running 10000 simulations.:  32%|███▏      | 3224/10000 [00:20<00:43, 154.39it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:21<00:43, 154.53it/s]Running 10000 simulations.:  33%|███▎      | 3256/10000 [00:21<00:43, 154.21it/s]Running 10000 simulations.:  33%|███▎      | 3272/10000 [00:21<00:43, 154.20it/s]Running 10000 simulations.:  33%|███▎      | 3288/10000 [00:21<00:43, 154.21it/s]Running 10000 simulations.:  33%|███▎      | 3304/10000 [00:21<00:43, 154.14it/s]Running 10000 simulations.:  33%|███▎      | 3320/10000 [00:21<00:43, 154.10it/s]Running 10000 simulations.:  33%|███▎      | 3336/10000 [00:21<00:43, 154.38it/s]Running 10000 simulations.:  34%|███▎      | 3352/10000 [00:21<00:43, 153.88it/s]Running 10000 simulations.:  34%|███▎      | 3368/10000 [00:21<00:43, 153.81it/s]Running 10000 simulations.:  34%|███▍      | 3384/10000 [00:21<00:42, 154.40it/s]Running 10000 simulations.:  34%|███▍      | 3400/10000 [00:22<00:42, 154.46it/s]Running 10000 simulations.:  34%|███▍      | 3416/10000 [00:22<00:42, 154.63it/s]Running 10000 simulations.:  34%|███▍      | 3432/10000 [00:22<00:42, 154.74it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:22<00:42, 154.46it/s]Running 10000 simulations.:  35%|███▍      | 3464/10000 [00:22<00:42, 154.05it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:22<00:42, 154.13it/s]Running 10000 simulations.:  35%|███▍      | 3496/10000 [00:22<00:41, 155.37it/s]Running 10000 simulations.:  35%|███▌      | 3512/10000 [00:22<00:41, 155.77it/s]Running 10000 simulations.:  35%|███▌      | 3528/10000 [00:22<00:41, 155.12it/s]Running 10000 simulations.:  35%|███▌      | 3544/10000 [00:23<00:41, 154.48it/s]Running 10000 simulations.:  36%|███▌      | 3562/10000 [00:23<00:40, 159.40it/s]Running 10000 simulations.:  36%|███▌      | 3580/10000 [00:23<00:39, 163.58it/s]Running 10000 simulations.:  36%|███▌      | 3597/10000 [00:23<00:38, 164.94it/s]Running 10000 simulations.:  36%|███▌      | 3614/10000 [00:23<00:39, 161.20it/s]Running 10000 simulations.:  36%|███▋      | 3631/10000 [00:23<00:39, 159.84it/s]Running 10000 simulations.:  36%|███▋      | 3648/10000 [00:23<00:40, 158.26it/s]Running 10000 simulations.:  37%|███▋      | 3664/10000 [00:23<00:40, 156.67it/s]Running 10000 simulations.:  37%|███▋      | 3680/10000 [00:23<00:41, 152.98it/s]Running 10000 simulations.:  37%|███▋      | 3696/10000 [00:23<00:41, 153.47it/s]Running 10000 simulations.:  37%|███▋      | 3712/10000 [00:24<00:40, 154.34it/s]Running 10000 simulations.:  37%|███▋      | 3728/10000 [00:24<00:40, 154.39it/s]Running 10000 simulations.:  37%|███▋      | 3744/10000 [00:24<00:40, 155.32it/s]Running 10000 simulations.:  38%|███▊      | 3760/10000 [00:24<00:40, 155.02it/s]Running 10000 simulations.:  38%|███▊      | 3776/10000 [00:24<00:39, 156.40it/s]Running 10000 simulations.:  38%|███▊      | 3792/10000 [00:24<00:39, 156.72it/s]Running 10000 simulations.:  38%|███▊      | 3808/10000 [00:24<00:39, 156.18it/s]Running 10000 simulations.:  38%|███▊      | 3824/10000 [00:24<00:39, 154.68it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:24<00:39, 154.09it/s]Running 10000 simulations.:  39%|███▊      | 3856/10000 [00:25<00:40, 153.56it/s]Running 10000 simulations.:  39%|███▊      | 3872/10000 [00:25<00:39, 154.39it/s]Running 10000 simulations.:  39%|███▉      | 3888/10000 [00:25<00:39, 155.15it/s]Running 10000 simulations.:  39%|███▉      | 3904/10000 [00:25<00:39, 155.79it/s]Running 10000 simulations.:  39%|███▉      | 3920/10000 [00:25<00:39, 155.58it/s]Running 10000 simulations.:  39%|███▉      | 3936/10000 [00:25<00:39, 155.02it/s]Running 10000 simulations.:  40%|███▉      | 3952/10000 [00:25<00:38, 155.19it/s]Running 10000 simulations.:  40%|███▉      | 3968/10000 [00:25<00:39, 154.45it/s]Running 10000 simulations.:  40%|███▉      | 3984/10000 [00:25<00:38, 155.19it/s]Running 10000 simulations.:  40%|████      | 4000/10000 [00:25<00:38, 155.06it/s]Running 10000 simulations.:  40%|████      | 4016/10000 [00:26<00:38, 155.96it/s]Running 10000 simulations.:  40%|████      | 4032/10000 [00:26<00:38, 155.47it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:26<00:38, 154.80it/s]Running 10000 simulations.:  41%|████      | 4064/10000 [00:26<00:38, 154.41it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:26<00:38, 154.49it/s]Running 10000 simulations.:  41%|████      | 4096/10000 [00:26<00:38, 154.56it/s]Running 10000 simulations.:  41%|████      | 4112/10000 [00:26<00:37, 155.09it/s]Running 10000 simulations.:  41%|████▏     | 4128/10000 [00:26<00:40, 146.09it/s]Running 10000 simulations.:  41%|████▏     | 4144/10000 [00:26<00:39, 148.79it/s]Running 10000 simulations.:  42%|████▏     | 4160/10000 [00:26<00:38, 151.77it/s]Running 10000 simulations.:  42%|████▏     | 4176/10000 [00:27<00:38, 152.01it/s]Running 10000 simulations.:  42%|████▏     | 4192/10000 [00:27<00:38, 150.67it/s]Running 10000 simulations.:  42%|████▏     | 4208/10000 [00:27<00:38, 151.82it/s]Running 10000 simulations.:  42%|████▏     | 4224/10000 [00:27<00:37, 153.52it/s]Running 10000 simulations.:  42%|████▏     | 4240/10000 [00:27<00:37, 154.63it/s]Running 10000 simulations.:  43%|████▎     | 4256/10000 [00:27<00:37, 154.51it/s]Running 10000 simulations.:  43%|████▎     | 4272/10000 [00:27<00:37, 154.57it/s]Running 10000 simulations.:  43%|████▎     | 4288/10000 [00:27<00:37, 150.33it/s]Running 10000 simulations.:  43%|████▎     | 4304/10000 [00:27<00:37, 150.78it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:28<00:37, 150.94it/s]Running 10000 simulations.:  43%|████▎     | 4336/10000 [00:28<00:37, 151.65it/s]Running 10000 simulations.:  44%|████▎     | 4352/10000 [00:28<00:37, 151.84it/s]Running 10000 simulations.:  44%|████▎     | 4368/10000 [00:28<00:37, 152.09it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:28<00:36, 152.91it/s]Running 10000 simulations.:  44%|████▍     | 4400/10000 [00:28<00:36, 152.93it/s]Running 10000 simulations.:  44%|████▍     | 4416/10000 [00:28<00:36, 152.60it/s]Running 10000 simulations.:  44%|████▍     | 4432/10000 [00:28<00:36, 152.94it/s]Running 10000 simulations.:  44%|████▍     | 4448/10000 [00:28<00:36, 153.12it/s]Running 10000 simulations.:  45%|████▍     | 4464/10000 [00:28<00:35, 154.41it/s]Running 10000 simulations.:  45%|████▍     | 4480/10000 [00:29<00:35, 155.02it/s]Running 10000 simulations.:  45%|████▍     | 4496/10000 [00:29<00:35, 155.13it/s]Running 10000 simulations.:  45%|████▌     | 4512/10000 [00:29<00:35, 155.69it/s]Running 10000 simulations.:  45%|████▌     | 4528/10000 [00:29<00:35, 155.42it/s]Running 10000 simulations.:  45%|████▌     | 4544/10000 [00:29<00:35, 155.03it/s]Running 10000 simulations.:  46%|████▌     | 4560/10000 [00:29<00:35, 154.79it/s]Running 10000 simulations.:  46%|████▌     | 4576/10000 [00:29<00:34, 155.26it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:29<00:34, 155.46it/s]Running 10000 simulations.:  46%|████▌     | 4608/10000 [00:29<00:34, 155.17it/s]Running 10000 simulations.:  46%|████▌     | 4624/10000 [00:30<00:34, 155.03it/s]Running 10000 simulations.:  46%|████▋     | 4640/10000 [00:30<00:34, 154.47it/s]Running 10000 simulations.:  47%|████▋     | 4656/10000 [00:30<00:34, 154.01it/s]Running 10000 simulations.:  47%|████▋     | 4672/10000 [00:30<00:34, 153.72it/s]Running 10000 simulations.:  47%|████▋     | 4688/10000 [00:30<00:34, 154.54it/s]Running 10000 simulations.:  47%|████▋     | 4704/10000 [00:30<00:34, 155.49it/s]Running 10000 simulations.:  47%|████▋     | 4720/10000 [00:30<00:34, 154.99it/s]Running 10000 simulations.:  47%|████▋     | 4736/10000 [00:30<00:34, 154.19it/s]Running 10000 simulations.:  48%|████▊     | 4752/10000 [00:30<00:33, 154.51it/s]Running 10000 simulations.:  48%|████▊     | 4768/10000 [00:30<00:33, 154.36it/s]Running 10000 simulations.:  48%|████▊     | 4784/10000 [00:31<00:33, 154.09it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:31<00:33, 153.91it/s]Running 10000 simulations.:  48%|████▊     | 4816/10000 [00:31<00:33, 153.19it/s]Running 10000 simulations.:  48%|████▊     | 4832/10000 [00:31<00:33, 152.41it/s]Running 10000 simulations.:  48%|████▊     | 4848/10000 [00:31<00:33, 152.42it/s]Running 10000 simulations.:  49%|████▊     | 4864/10000 [00:31<00:33, 152.21it/s]Running 10000 simulations.:  49%|████▉     | 4880/10000 [00:31<00:33, 152.02it/s]Running 10000 simulations.:  49%|████▉     | 4896/10000 [00:31<00:33, 151.99it/s]Running 10000 simulations.:  49%|████▉     | 4912/10000 [00:31<00:33, 152.22it/s]Running 10000 simulations.:  49%|████▉     | 4928/10000 [00:31<00:32, 153.89it/s]Running 10000 simulations.:  49%|████▉     | 4944/10000 [00:32<00:32, 153.84it/s]Running 10000 simulations.:  50%|████▉     | 4960/10000 [00:32<00:32, 154.15it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:32<00:32, 155.68it/s]Running 10000 simulations.:  50%|████▉     | 4992/10000 [00:32<00:32, 155.52it/s]Running 10000 simulations.:  50%|█████     | 5008/10000 [00:32<00:32, 155.59it/s]Running 10000 simulations.:  50%|█████     | 5024/10000 [00:32<00:32, 154.91it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:32<00:31, 155.28it/s]Running 10000 simulations.:  51%|█████     | 5056/10000 [00:32<00:31, 155.34it/s]Running 10000 simulations.:  51%|█████     | 5072/10000 [00:32<00:31, 154.94it/s]Running 10000 simulations.:  51%|█████     | 5088/10000 [00:33<00:31, 154.66it/s]Running 10000 simulations.:  51%|█████     | 5104/10000 [00:33<00:31, 154.75it/s]Running 10000 simulations.:  51%|█████     | 5120/10000 [00:33<00:31, 154.57it/s]Running 10000 simulations.:  51%|█████▏    | 5136/10000 [00:33<00:31, 153.75it/s]Running 10000 simulations.:  52%|█████▏    | 5152/10000 [00:33<00:31, 154.02it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:33<00:30, 157.69it/s]Running 10000 simulations.:  52%|█████▏    | 5187/10000 [00:33<00:29, 161.90it/s]Running 10000 simulations.:  52%|█████▏    | 5204/10000 [00:33<00:29, 162.29it/s]Running 10000 simulations.:  52%|█████▏    | 5221/10000 [00:33<00:30, 159.01it/s]Running 10000 simulations.:  52%|█████▏    | 5237/10000 [00:33<00:30, 157.39it/s]Running 10000 simulations.:  53%|█████▎    | 5253/10000 [00:34<00:30, 155.83it/s]Running 10000 simulations.:  53%|█████▎    | 5269/10000 [00:34<00:30, 154.85it/s]Running 10000 simulations.:  53%|█████▎    | 5285/10000 [00:34<00:30, 154.81it/s]Running 10000 simulations.:  53%|█████▎    | 5301/10000 [00:34<00:30, 153.89it/s]Running 10000 simulations.:  53%|█████▎    | 5317/10000 [00:34<00:30, 152.79it/s]Running 10000 simulations.:  53%|█████▎    | 5333/10000 [00:34<00:30, 152.91it/s]Running 10000 simulations.:  53%|█████▎    | 5349/10000 [00:34<00:30, 153.30it/s]Running 10000 simulations.:  54%|█████▎    | 5365/10000 [00:34<00:30, 152.82it/s]Running 10000 simulations.:  54%|█████▍    | 5381/10000 [00:34<00:30, 152.03it/s]Running 10000 simulations.:  54%|█████▍    | 5397/10000 [00:35<00:30, 151.90it/s]Running 10000 simulations.:  54%|█████▍    | 5413/10000 [00:35<00:30, 152.24it/s]Running 10000 simulations.:  54%|█████▍    | 5429/10000 [00:35<00:29, 152.76it/s]Running 10000 simulations.:  54%|█████▍    | 5445/10000 [00:35<00:29, 153.30it/s]Running 10000 simulations.:  55%|█████▍    | 5461/10000 [00:35<00:29, 153.78it/s]Running 10000 simulations.:  55%|█████▍    | 5477/10000 [00:35<00:29, 154.23it/s]Running 10000 simulations.:  55%|█████▍    | 5493/10000 [00:35<00:29, 152.59it/s]Running 10000 simulations.:  55%|█████▌    | 5509/10000 [00:35<00:29, 150.39it/s]Running 10000 simulations.:  55%|█████▌    | 5525/10000 [00:35<00:29, 151.00it/s]Running 10000 simulations.:  55%|█████▌    | 5541/10000 [00:35<00:29, 152.28it/s]Running 10000 simulations.:  56%|█████▌    | 5557/10000 [00:36<00:29, 152.50it/s]Running 10000 simulations.:  56%|█████▌    | 5573/10000 [00:36<00:29, 152.39it/s]Running 10000 simulations.:  56%|█████▌    | 5589/10000 [00:36<00:29, 152.00it/s]Running 10000 simulations.:  56%|█████▌    | 5605/10000 [00:36<00:28, 151.69it/s]Running 10000 simulations.:  56%|█████▌    | 5621/10000 [00:36<00:28, 153.13it/s]Running 10000 simulations.:  56%|█████▋    | 5637/10000 [00:36<00:28, 154.17it/s]Running 10000 simulations.:  57%|█████▋    | 5653/10000 [00:36<00:29, 149.32it/s]Running 10000 simulations.:  57%|█████▋    | 5668/10000 [00:36<00:29, 147.85it/s]Running 10000 simulations.:  57%|█████▋    | 5683/10000 [00:36<00:29, 148.10it/s]Running 10000 simulations.:  57%|█████▋    | 5699/10000 [00:37<00:28, 149.06it/s]Running 10000 simulations.:  57%|█████▋    | 5715/10000 [00:37<00:28, 150.24it/s]Running 10000 simulations.:  57%|█████▋    | 5731/10000 [00:37<00:28, 151.25it/s]Running 10000 simulations.:  57%|█████▋    | 5747/10000 [00:37<00:28, 148.67it/s]Running 10000 simulations.:  58%|█████▊    | 5762/10000 [00:37<00:29, 144.69it/s]Running 10000 simulations.:  58%|█████▊    | 5777/10000 [00:37<00:29, 142.20it/s]Running 10000 simulations.:  58%|█████▊    | 5792/10000 [00:37<00:29, 142.12it/s]Running 10000 simulations.:  58%|█████▊    | 5807/10000 [00:37<00:29, 143.60it/s]Running 10000 simulations.:  58%|█████▊    | 5823/10000 [00:37<00:28, 145.99it/s]Running 10000 simulations.:  58%|█████▊    | 5838/10000 [00:37<00:28, 145.92it/s]Running 10000 simulations.:  59%|█████▊    | 5853/10000 [00:38<00:28, 145.77it/s]Running 10000 simulations.:  59%|█████▊    | 5869/10000 [00:38<00:28, 147.23it/s]Running 10000 simulations.:  59%|█████▉    | 5885/10000 [00:38<00:27, 149.64it/s]Running 10000 simulations.:  59%|█████▉    | 5900/10000 [00:38<00:28, 145.39it/s]Running 10000 simulations.:  59%|█████▉    | 5915/10000 [00:38<00:28, 142.41it/s]Running 10000 simulations.:  59%|█████▉    | 5930/10000 [00:38<00:28, 142.98it/s]Running 10000 simulations.:  59%|█████▉    | 5945/10000 [00:38<00:27, 144.83it/s]Running 10000 simulations.:  60%|█████▉    | 5961/10000 [00:38<00:27, 146.59it/s]Running 10000 simulations.:  60%|█████▉    | 5977/10000 [00:38<00:26, 149.39it/s]Running 10000 simulations.:  60%|█████▉    | 5992/10000 [00:39<00:27, 148.02it/s]Running 10000 simulations.:  60%|██████    | 6007/10000 [00:39<00:27, 143.91it/s]Running 10000 simulations.:  60%|██████    | 6022/10000 [00:39<00:28, 141.03it/s]Running 10000 simulations.:  60%|██████    | 6037/10000 [00:39<00:28, 140.58it/s]Running 10000 simulations.:  61%|██████    | 6052/10000 [00:39<00:27, 142.40it/s]Running 10000 simulations.:  61%|██████    | 6067/10000 [00:39<00:27, 144.10it/s]Running 10000 simulations.:  61%|██████    | 6083/10000 [00:39<00:26, 146.23it/s]Running 10000 simulations.:  61%|██████    | 6099/10000 [00:39<00:26, 149.56it/s]Running 10000 simulations.:  61%|██████    | 6114/10000 [00:39<00:26, 147.30it/s]Running 10000 simulations.:  61%|██████▏   | 6129/10000 [00:39<00:26, 144.40it/s]Running 10000 simulations.:  61%|██████▏   | 6144/10000 [00:40<00:27, 142.25it/s]Running 10000 simulations.:  62%|██████▏   | 6159/10000 [00:40<00:27, 141.91it/s]Running 10000 simulations.:  62%|██████▏   | 6174/10000 [00:40<00:26, 143.68it/s]Running 10000 simulations.:  62%|██████▏   | 6190/10000 [00:40<00:26, 146.24it/s]Running 10000 simulations.:  62%|██████▏   | 6206/10000 [00:40<00:25, 149.33it/s]Running 10000 simulations.:  62%|██████▏   | 6222/10000 [00:40<00:24, 152.37it/s]Running 10000 simulations.:  62%|██████▏   | 6238/10000 [00:40<00:25, 148.31it/s]Running 10000 simulations.:  63%|██████▎   | 6253/10000 [00:40<00:25, 144.41it/s]Running 10000 simulations.:  63%|██████▎   | 6268/10000 [00:40<00:26, 141.77it/s]Running 10000 simulations.:  63%|██████▎   | 6283/10000 [00:41<00:26, 142.68it/s]Running 10000 simulations.:  63%|██████▎   | 6298/10000 [00:41<00:25, 144.58it/s]Running 10000 simulations.:  63%|██████▎   | 6314/10000 [00:41<00:25, 146.37it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:41<00:24, 148.27it/s]Running 10000 simulations.:  63%|██████▎   | 6346/10000 [00:41<00:24, 149.59it/s]Running 10000 simulations.:  64%|██████▎   | 6361/10000 [00:41<00:24, 145.56it/s]Running 10000 simulations.:  64%|██████▍   | 6376/10000 [00:41<00:25, 143.92it/s]Running 10000 simulations.:  64%|██████▍   | 6391/10000 [00:41<00:24, 144.82it/s]Running 10000 simulations.:  64%|██████▍   | 6407/10000 [00:41<00:24, 147.56it/s]Running 10000 simulations.:  64%|██████▍   | 6423/10000 [00:41<00:24, 148.60it/s]Running 10000 simulations.:  64%|██████▍   | 6439/10000 [00:42<00:23, 149.93it/s]Running 10000 simulations.:  65%|██████▍   | 6455/10000 [00:42<00:24, 146.58it/s]Running 10000 simulations.:  65%|██████▍   | 6470/10000 [00:42<00:24, 144.00it/s]Running 10000 simulations.:  65%|██████▍   | 6485/10000 [00:42<00:24, 144.64it/s]Running 10000 simulations.:  65%|██████▌   | 6500/10000 [00:42<00:24, 145.20it/s]Running 10000 simulations.:  65%|██████▌   | 6516/10000 [00:42<00:23, 146.94it/s]Running 10000 simulations.:  65%|██████▌   | 6532/10000 [00:42<00:23, 149.20it/s]Running 10000 simulations.:  65%|██████▌   | 6547/10000 [00:42<00:23, 148.64it/s]Running 10000 simulations.:  66%|██████▌   | 6562/10000 [00:42<00:23, 147.43it/s]Running 10000 simulations.:  66%|██████▌   | 6577/10000 [00:43<00:23, 147.97it/s]Running 10000 simulations.:  66%|██████▌   | 6592/10000 [00:43<00:22, 148.24it/s]Running 10000 simulations.:  66%|██████▌   | 6608/10000 [00:43<00:22, 149.62it/s]Running 10000 simulations.:  66%|██████▌   | 6623/10000 [00:43<00:22, 148.98it/s]Running 10000 simulations.:  66%|██████▋   | 6638/10000 [00:43<00:22, 149.09it/s]Running 10000 simulations.:  67%|██████▋   | 6654/10000 [00:43<00:22, 149.89it/s]Running 10000 simulations.:  67%|██████▋   | 6669/10000 [00:43<00:22, 149.42it/s]Running 10000 simulations.:  67%|██████▋   | 6684/10000 [00:43<00:22, 147.75it/s]Running 10000 simulations.:  67%|██████▋   | 6699/10000 [00:43<00:22, 148.32it/s]Running 10000 simulations.:  67%|██████▋   | 6714/10000 [00:43<00:22, 148.27it/s]Running 10000 simulations.:  67%|██████▋   | 6729/10000 [00:44<00:22, 148.65it/s]Running 10000 simulations.:  67%|██████▋   | 6745/10000 [00:44<00:21, 149.75it/s]Running 10000 simulations.:  68%|██████▊   | 6761/10000 [00:44<00:21, 150.35it/s]Running 10000 simulations.:  68%|██████▊   | 6777/10000 [00:44<00:21, 148.99it/s]Running 10000 simulations.:  68%|██████▊   | 6792/10000 [00:44<00:21, 147.42it/s]Running 10000 simulations.:  68%|██████▊   | 6808/10000 [00:44<00:21, 148.56it/s]Running 10000 simulations.:  68%|██████▊   | 6824/10000 [00:44<00:21, 149.35it/s]Running 10000 simulations.:  68%|██████▊   | 6840/10000 [00:44<00:21, 149.64it/s]Running 10000 simulations.:  69%|██████▊   | 6856/10000 [00:44<00:20, 149.98it/s]Running 10000 simulations.:  69%|██████▊   | 6872/10000 [00:45<00:20, 149.70it/s]Running 10000 simulations.:  69%|██████▉   | 6887/10000 [00:45<00:21, 147.57it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:45<00:20, 147.98it/s]Running 10000 simulations.:  69%|██████▉   | 6918/10000 [00:45<00:20, 148.97it/s]Running 10000 simulations.:  69%|██████▉   | 6934/10000 [00:45<00:20, 150.05it/s]Running 10000 simulations.:  70%|██████▉   | 6951/10000 [00:45<00:19, 153.28it/s]Running 10000 simulations.:  70%|██████▉   | 6968/10000 [00:45<00:19, 157.39it/s]Running 10000 simulations.:  70%|██████▉   | 6984/10000 [00:45<00:19, 153.41it/s]Running 10000 simulations.:  70%|███████   | 7000/10000 [00:45<00:19, 152.51it/s]Running 10000 simulations.:  70%|███████   | 7016/10000 [00:45<00:19, 152.68it/s]Running 10000 simulations.:  70%|███████   | 7032/10000 [00:46<00:19, 152.97it/s]Running 10000 simulations.:  70%|███████   | 7048/10000 [00:46<00:19, 153.27it/s]Running 10000 simulations.:  71%|███████   | 7064/10000 [00:46<00:19, 153.66it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:46<00:19, 151.27it/s]Running 10000 simulations.:  71%|███████   | 7096/10000 [00:46<00:19, 150.32it/s]Running 10000 simulations.:  71%|███████   | 7112/10000 [00:46<00:19, 150.46it/s]Running 10000 simulations.:  71%|███████▏  | 7128/10000 [00:46<00:18, 151.54it/s]Running 10000 simulations.:  71%|███████▏  | 7144/10000 [00:46<00:18, 152.41it/s]Running 10000 simulations.:  72%|███████▏  | 7160/10000 [00:46<00:18, 152.98it/s]Running 10000 simulations.:  72%|███████▏  | 7176/10000 [00:47<00:18, 150.90it/s]Running 10000 simulations.:  72%|███████▏  | 7192/10000 [00:47<00:18, 148.45it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:47<00:18, 148.54it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:47<00:18, 149.20it/s]Running 10000 simulations.:  72%|███████▏  | 7239/10000 [00:47<00:18, 150.07it/s]Running 10000 simulations.:  73%|███████▎  | 7255/10000 [00:47<00:18, 151.25it/s]Running 10000 simulations.:  73%|███████▎  | 7271/10000 [00:47<00:18, 151.12it/s]Running 10000 simulations.:  73%|███████▎  | 7287/10000 [00:47<00:18, 149.30it/s]Running 10000 simulations.:  73%|███████▎  | 7302/10000 [00:47<00:18, 147.88it/s]Running 10000 simulations.:  73%|███████▎  | 7317/10000 [00:47<00:18, 147.69it/s]Running 10000 simulations.:  73%|███████▎  | 7332/10000 [00:48<00:17, 148.35it/s]Running 10000 simulations.:  73%|███████▎  | 7348/10000 [00:48<00:17, 149.32it/s]Running 10000 simulations.:  74%|███████▎  | 7363/10000 [00:48<00:17, 148.65it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:48<00:17, 148.29it/s]Running 10000 simulations.:  74%|███████▍  | 7394/10000 [00:48<00:17, 149.32it/s]Running 10000 simulations.:  74%|███████▍  | 7410/10000 [00:48<00:17, 149.72it/s]Running 10000 simulations.:  74%|███████▍  | 7425/10000 [00:48<00:17, 147.61it/s]Running 10000 simulations.:  74%|███████▍  | 7440/10000 [00:48<00:17, 147.60it/s]Running 10000 simulations.:  75%|███████▍  | 7456/10000 [00:48<00:17, 148.73it/s]Running 10000 simulations.:  75%|███████▍  | 7472/10000 [00:48<00:16, 149.27it/s]Running 10000 simulations.:  75%|███████▍  | 7488/10000 [00:49<00:16, 149.66it/s]Running 10000 simulations.:  75%|███████▌  | 7504/10000 [00:49<00:16, 150.26it/s]Running 10000 simulations.:  75%|███████▌  | 7520/10000 [00:49<00:16, 148.85it/s]Running 10000 simulations.:  75%|███████▌  | 7535/10000 [00:49<00:16, 148.36it/s]Running 10000 simulations.:  76%|███████▌  | 7551/10000 [00:49<00:16, 149.26it/s]Running 10000 simulations.:  76%|███████▌  | 7567/10000 [00:49<00:16, 150.32it/s]Running 10000 simulations.:  76%|███████▌  | 7583/10000 [00:49<00:15, 151.31it/s]Running 10000 simulations.:  76%|███████▌  | 7599/10000 [00:49<00:15, 151.95it/s]Running 10000 simulations.:  76%|███████▌  | 7615/10000 [00:49<00:15, 150.72it/s]Running 10000 simulations.:  76%|███████▋  | 7631/10000 [00:50<00:15, 149.57it/s]Running 10000 simulations.:  76%|███████▋  | 7646/10000 [00:50<00:15, 148.73it/s]Running 10000 simulations.:  77%|███████▋  | 7662/10000 [00:50<00:15, 149.53it/s]Running 10000 simulations.:  77%|███████▋  | 7678/10000 [00:50<00:15, 149.92it/s]Running 10000 simulations.:  77%|███████▋  | 7694/10000 [00:50<00:15, 150.52it/s]Running 10000 simulations.:  77%|███████▋  | 7710/10000 [00:50<00:15, 151.23it/s]Running 10000 simulations.:  77%|███████▋  | 7726/10000 [00:50<00:15, 150.68it/s]Running 10000 simulations.:  77%|███████▋  | 7742/10000 [00:50<00:15, 149.07it/s]Running 10000 simulations.:  78%|███████▊  | 7758/10000 [00:50<00:14, 149.83it/s]Running 10000 simulations.:  78%|███████▊  | 7774/10000 [00:51<00:14, 150.68it/s]Running 10000 simulations.:  78%|███████▊  | 7790/10000 [00:51<00:14, 151.65it/s]Running 10000 simulations.:  78%|███████▊  | 7806/10000 [00:51<00:14, 152.62it/s]Running 10000 simulations.:  78%|███████▊  | 7822/10000 [00:51<00:14, 152.93it/s]Running 10000 simulations.:  78%|███████▊  | 7838/10000 [00:51<00:14, 150.56it/s]Running 10000 simulations.:  79%|███████▊  | 7854/10000 [00:51<00:14, 149.79it/s]Running 10000 simulations.:  79%|███████▊  | 7870/10000 [00:51<00:14, 150.21it/s]Running 10000 simulations.:  79%|███████▉  | 7886/10000 [00:51<00:14, 150.57it/s]Running 10000 simulations.:  79%|███████▉  | 7902/10000 [00:51<00:13, 151.46it/s]Running 10000 simulations.:  79%|███████▉  | 7918/10000 [00:51<00:13, 152.48it/s]Running 10000 simulations.:  79%|███████▉  | 7934/10000 [00:52<00:13, 150.98it/s]Running 10000 simulations.:  80%|███████▉  | 7950/10000 [00:52<00:13, 150.88it/s]Running 10000 simulations.:  80%|███████▉  | 7966/10000 [00:52<00:13, 151.89it/s]Running 10000 simulations.:  80%|███████▉  | 7982/10000 [00:52<00:13, 152.60it/s]Running 10000 simulations.:  80%|███████▉  | 7998/10000 [00:52<00:13, 152.18it/s]Running 10000 simulations.:  80%|████████  | 8014/10000 [00:52<00:12, 153.07it/s]Running 10000 simulations.:  80%|████████  | 8030/10000 [00:52<00:13, 151.25it/s]Running 10000 simulations.:  80%|████████  | 8046/10000 [00:52<00:12, 151.07it/s]Running 10000 simulations.:  81%|████████  | 8062/10000 [00:52<00:12, 151.34it/s]Running 10000 simulations.:  81%|████████  | 8078/10000 [00:53<00:12, 151.50it/s]Running 10000 simulations.:  81%|████████  | 8094/10000 [00:53<00:12, 151.16it/s]Running 10000 simulations.:  81%|████████  | 8110/10000 [00:53<00:12, 151.58it/s]Running 10000 simulations.:  81%|████████▏ | 8126/10000 [00:53<00:12, 151.13it/s]Running 10000 simulations.:  81%|████████▏ | 8142/10000 [00:53<00:12, 150.01it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:53<00:12, 150.85it/s]Running 10000 simulations.:  82%|████████▏ | 8174/10000 [00:53<00:12, 151.83it/s]Running 10000 simulations.:  82%|████████▏ | 8190/10000 [00:53<00:11, 151.48it/s]Running 10000 simulations.:  82%|████████▏ | 8206/10000 [00:53<00:11, 150.95it/s]Running 10000 simulations.:  82%|████████▏ | 8222/10000 [00:53<00:11, 150.98it/s]Running 10000 simulations.:  82%|████████▏ | 8238/10000 [00:54<00:11, 151.87it/s]Running 10000 simulations.:  83%|████████▎ | 8254/10000 [00:54<00:11, 151.02it/s]Running 10000 simulations.:  83%|████████▎ | 8270/10000 [00:54<00:11, 150.10it/s]Running 10000 simulations.:  83%|████████▎ | 8286/10000 [00:54<00:11, 150.71it/s]Running 10000 simulations.:  83%|████████▎ | 8302/10000 [00:54<00:11, 151.50it/s]Running 10000 simulations.:  83%|████████▎ | 8318/10000 [00:54<00:11, 151.95it/s]Running 10000 simulations.:  83%|████████▎ | 8334/10000 [00:54<00:10, 152.26it/s]Running 10000 simulations.:  84%|████████▎ | 8350/10000 [00:54<00:10, 151.59it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [00:54<00:10, 149.58it/s]Running 10000 simulations.:  84%|████████▍ | 8382/10000 [00:55<00:10, 149.82it/s]Running 10000 simulations.:  84%|████████▍ | 8398/10000 [00:55<00:10, 150.64it/s]Running 10000 simulations.:  84%|████████▍ | 8414/10000 [00:55<00:10, 151.86it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:55<00:10, 152.80it/s]Running 10000 simulations.:  84%|████████▍ | 8446/10000 [00:55<00:10, 153.26it/s]Running 10000 simulations.:  85%|████████▍ | 8462/10000 [00:55<00:10, 151.56it/s]Running 10000 simulations.:  85%|████████▍ | 8478/10000 [00:55<00:10, 150.69it/s]Running 10000 simulations.:  85%|████████▍ | 8494/10000 [00:55<00:09, 151.47it/s]Running 10000 simulations.:  85%|████████▌ | 8510/10000 [00:55<00:09, 152.22it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [00:55<00:09, 152.19it/s]Running 10000 simulations.:  85%|████████▌ | 8542/10000 [00:56<00:09, 152.87it/s]Running 10000 simulations.:  86%|████████▌ | 8558/10000 [00:56<00:09, 152.56it/s]Running 10000 simulations.:  86%|████████▌ | 8574/10000 [00:56<00:09, 150.65it/s]Running 10000 simulations.:  86%|████████▌ | 8590/10000 [00:56<00:09, 150.64it/s]Running 10000 simulations.:  86%|████████▌ | 8606/10000 [00:56<00:09, 151.22it/s]Running 10000 simulations.:  86%|████████▌ | 8622/10000 [00:56<00:09, 152.02it/s]Running 10000 simulations.:  86%|████████▋ | 8638/10000 [00:56<00:09, 147.39it/s]Running 10000 simulations.:  87%|████████▋ | 8655/10000 [00:56<00:08, 152.18it/s]Running 10000 simulations.:  87%|████████▋ | 8671/10000 [00:56<00:08, 149.98it/s]Running 10000 simulations.:  87%|████████▋ | 8687/10000 [00:57<00:08, 149.49it/s]Running 10000 simulations.:  87%|████████▋ | 8703/10000 [00:57<00:08, 150.15it/s]Running 10000 simulations.:  87%|████████▋ | 8719/10000 [00:57<00:08, 150.83it/s]Running 10000 simulations.:  87%|████████▋ | 8735/10000 [00:57<00:08, 151.31it/s]Running 10000 simulations.:  88%|████████▊ | 8751/10000 [00:57<00:08, 151.43it/s]Running 10000 simulations.:  88%|████████▊ | 8767/10000 [00:57<00:08, 149.87it/s]Running 10000 simulations.:  88%|████████▊ | 8782/10000 [00:57<00:08, 147.99it/s]Running 10000 simulations.:  88%|████████▊ | 8797/10000 [00:57<00:08, 146.99it/s]Running 10000 simulations.:  88%|████████▊ | 8813/10000 [00:57<00:08, 148.31it/s]Running 10000 simulations.:  88%|████████▊ | 8829/10000 [00:57<00:07, 149.72it/s]Running 10000 simulations.:  88%|████████▊ | 8845/10000 [00:58<00:07, 150.47it/s]Running 10000 simulations.:  89%|████████▊ | 8861/10000 [00:58<00:07, 151.53it/s]Running 10000 simulations.:  89%|████████▉ | 8877/10000 [00:58<00:07, 150.09it/s]Running 10000 simulations.:  89%|████████▉ | 8893/10000 [00:58<00:07, 148.35it/s]Running 10000 simulations.:  89%|████████▉ | 8909/10000 [00:58<00:07, 149.00it/s]Running 10000 simulations.:  89%|████████▉ | 8924/10000 [00:58<00:07, 149.18it/s]Running 10000 simulations.:  89%|████████▉ | 8939/10000 [00:58<00:07, 149.26it/s]Running 10000 simulations.:  90%|████████▉ | 8954/10000 [00:58<00:07, 148.47it/s]Running 10000 simulations.:  90%|████████▉ | 8969/10000 [00:58<00:06, 148.82it/s]Running 10000 simulations.:  90%|████████▉ | 8985/10000 [00:59<00:06, 150.44it/s]Running 10000 simulations.:  90%|█████████ | 9001/10000 [00:59<00:06, 149.40it/s]Running 10000 simulations.:  90%|█████████ | 9016/10000 [00:59<00:06, 148.07it/s]Running 10000 simulations.:  90%|█████████ | 9031/10000 [00:59<00:06, 147.12it/s]Running 10000 simulations.:  90%|█████████ | 9047/10000 [00:59<00:06, 148.05it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [00:59<00:06, 149.33it/s]Running 10000 simulations.:  91%|█████████ | 9079/10000 [00:59<00:06, 149.73it/s]Running 10000 simulations.:  91%|█████████ | 9095/10000 [00:59<00:06, 150.63it/s]Running 10000 simulations.:  91%|█████████ | 9111/10000 [00:59<00:05, 151.01it/s]Running 10000 simulations.:  91%|█████████▏| 9127/10000 [00:59<00:05, 149.15it/s]Running 10000 simulations.:  91%|█████████▏| 9142/10000 [01:00<00:05, 148.90it/s]Running 10000 simulations.:  92%|█████████▏| 9157/10000 [01:00<00:05, 149.05it/s]Running 10000 simulations.:  92%|█████████▏| 9173/10000 [01:00<00:05, 149.54it/s]Running 10000 simulations.:  92%|█████████▏| 9189/10000 [01:00<00:05, 150.20it/s]Running 10000 simulations.:  92%|█████████▏| 9205/10000 [01:00<00:05, 150.43it/s]Running 10000 simulations.:  92%|█████████▏| 9221/10000 [01:00<00:05, 148.56it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [01:00<00:05, 148.01it/s]Running 10000 simulations.:  93%|█████████▎| 9252/10000 [01:00<00:05, 148.68it/s]Running 10000 simulations.:  93%|█████████▎| 9268/10000 [01:00<00:04, 149.83it/s]Running 10000 simulations.:  93%|█████████▎| 9284/10000 [01:01<00:04, 151.02it/s]Running 10000 simulations.:  93%|█████████▎| 9300/10000 [01:01<00:04, 151.89it/s]Running 10000 simulations.:  93%|█████████▎| 9316/10000 [01:01<00:04, 151.46it/s]Running 10000 simulations.:  93%|█████████▎| 9332/10000 [01:01<00:04, 153.85it/s]Running 10000 simulations.:  93%|█████████▎| 9348/10000 [01:01<00:04, 154.79it/s]Running 10000 simulations.:  94%|█████████▎| 9364/10000 [01:01<00:04, 154.21it/s]Running 10000 simulations.:  94%|█████████▍| 9380/10000 [01:01<00:03, 155.00it/s]Running 10000 simulations.:  94%|█████████▍| 9396/10000 [01:01<00:03, 155.65it/s]Running 10000 simulations.:  94%|█████████▍| 9412/10000 [01:01<00:03, 156.21it/s]Running 10000 simulations.:  94%|█████████▍| 9428/10000 [01:01<00:03, 156.30it/s]Running 10000 simulations.:  94%|█████████▍| 9444/10000 [01:02<00:03, 154.05it/s]Running 10000 simulations.:  95%|█████████▍| 9460/10000 [01:02<00:03, 152.41it/s]Running 10000 simulations.:  95%|█████████▍| 9476/10000 [01:02<00:03, 152.29it/s]Running 10000 simulations.:  95%|█████████▍| 9492/10000 [01:02<00:03, 153.47it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [01:02<00:03, 154.15it/s]Running 10000 simulations.:  95%|█████████▌| 9524/10000 [01:02<00:03, 155.25it/s]Running 10000 simulations.:  95%|█████████▌| 9540/10000 [01:02<00:02, 156.59it/s]Running 10000 simulations.:  96%|█████████▌| 9556/10000 [01:02<00:02, 155.71it/s]Running 10000 simulations.:  96%|█████████▌| 9572/10000 [01:02<00:02, 153.70it/s]Running 10000 simulations.:  96%|█████████▌| 9588/10000 [01:02<00:02, 154.26it/s]Running 10000 simulations.:  96%|█████████▌| 9604/10000 [01:03<00:02, 155.14it/s]Running 10000 simulations.:  96%|█████████▌| 9620/10000 [01:03<00:02, 155.42it/s]Running 10000 simulations.:  96%|█████████▋| 9636/10000 [01:03<00:02, 156.69it/s]Running 10000 simulations.:  97%|█████████▋| 9652/10000 [01:03<00:02, 156.57it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [01:03<00:02, 154.15it/s]Running 10000 simulations.:  97%|█████████▋| 9684/10000 [01:03<00:02, 154.71it/s]Running 10000 simulations.:  97%|█████████▋| 9700/10000 [01:03<00:01, 156.17it/s]Running 10000 simulations.:  97%|█████████▋| 9716/10000 [01:03<00:01, 157.01it/s]Running 10000 simulations.:  97%|█████████▋| 9732/10000 [01:03<00:01, 157.44it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [01:04<00:01, 158.07it/s]Running 10000 simulations.:  98%|█████████▊| 9764/10000 [01:04<00:01, 156.19it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [01:04<00:01, 154.87it/s]Running 10000 simulations.:  98%|█████████▊| 9796/10000 [01:04<00:01, 156.30it/s]Running 10000 simulations.:  98%|█████████▊| 9813/10000 [01:04<00:01, 157.51it/s]Running 10000 simulations.:  98%|█████████▊| 9829/10000 [01:04<00:01, 157.10it/s]Running 10000 simulations.:  98%|█████████▊| 9845/10000 [01:04<00:00, 156.55it/s]Running 10000 simulations.:  99%|█████████▊| 9861/10000 [01:04<00:00, 156.74it/s]Running 10000 simulations.:  99%|█████████▉| 9878/10000 [01:04<00:00, 158.04it/s]Running 10000 simulations.:  99%|█████████▉| 9894/10000 [01:04<00:00, 156.46it/s]Running 10000 simulations.:  99%|█████████▉| 9910/10000 [01:05<00:00, 155.47it/s]Running 10000 simulations.:  99%|█████████▉| 9926/10000 [01:05<00:00, 156.61it/s]Running 10000 simulations.:  99%|█████████▉| 9942/10000 [01:05<00:00, 157.60it/s]Running 10000 simulations.: 100%|█████████▉| 9958/10000 [01:05<00:00, 158.05it/s]Running 10000 simulations.: 100%|█████████▉| 9975/10000 [01:05<00:00, 158.80it/s]Running 10000 simulations.: 100%|█████████▉| 9991/10000 [01:05<00:00, 158.70it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:05<00:00, 152.39it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 17/10000 [00:00<01:00, 165.75it/s]Running 10000 simulations.:   0%|          | 34/10000 [00:00<01:00, 165.52it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<01:00, 165.39it/s]Running 10000 simulations.:   1%|          | 68/10000 [00:00<01:00, 164.73it/s]Running 10000 simulations.:   1%|          | 85/10000 [00:00<01:00, 164.51it/s]Running 10000 simulations.:   1%|          | 102/10000 [00:00<01:00, 164.15it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<01:00, 163.94it/s]Running 10000 simulations.:   1%|▏         | 136/10000 [00:00<01:00, 163.67it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<01:00, 163.79it/s]Running 10000 simulations.:   2%|▏         | 170/10000 [00:01<01:00, 163.78it/s]Running 10000 simulations.:   2%|▏         | 187/10000 [00:01<01:00, 163.46it/s]Running 10000 simulations.:   2%|▏         | 204/10000 [00:01<01:00, 163.12it/s]Running 10000 simulations.:   2%|▏         | 221/10000 [00:01<00:59, 163.59it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:01<00:59, 163.90it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<00:59, 163.72it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<00:59, 163.79it/s]Running 10000 simulations.:   3%|▎         | 289/10000 [00:01<00:59, 164.28it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:58, 165.01it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:58, 165.81it/s]Running 10000 simulations.:   3%|▎         | 340/10000 [00:02<00:58, 165.63it/s]Running 10000 simulations.:   4%|▎         | 357/10000 [00:02<00:58, 165.00it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:02<00:58, 164.70it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:02<00:58, 164.74it/s]Running 10000 simulations.:   4%|▍         | 408/10000 [00:02<00:58, 165.11it/s]Running 10000 simulations.:   4%|▍         | 425/10000 [00:02<00:58, 165.01it/s]Running 10000 simulations.:   4%|▍         | 442/10000 [00:02<00:57, 164.82it/s]Running 10000 simulations.:   5%|▍         | 459/10000 [00:02<00:58, 164.46it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:02<00:57, 164.28it/s]Running 10000 simulations.:   5%|▍         | 493/10000 [00:02<00:57, 164.79it/s]Running 10000 simulations.:   5%|▌         | 512/10000 [00:03<00:55, 169.72it/s]Running 10000 simulations.:   5%|▌         | 530/10000 [00:03<00:55, 172.16it/s]Running 10000 simulations.:   5%|▌         | 548/10000 [00:03<00:55, 169.86it/s]Running 10000 simulations.:   6%|▌         | 566/10000 [00:03<00:56, 167.83it/s]Running 10000 simulations.:   6%|▌         | 583/10000 [00:03<00:56, 166.63it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:03<00:57, 163.00it/s]Running 10000 simulations.:   6%|▌         | 617/10000 [00:03<00:57, 162.17it/s]Running 10000 simulations.:   6%|▋         | 634/10000 [00:03<00:57, 162.32it/s]Running 10000 simulations.:   7%|▋         | 651/10000 [00:03<00:57, 163.06it/s]Running 10000 simulations.:   7%|▋         | 668/10000 [00:04<00:57, 163.24it/s]Running 10000 simulations.:   7%|▋         | 685/10000 [00:04<00:56, 163.61it/s]Running 10000 simulations.:   7%|▋         | 702/10000 [00:04<00:56, 163.84it/s]Running 10000 simulations.:   7%|▋         | 719/10000 [00:04<00:56, 163.57it/s]Running 10000 simulations.:   7%|▋         | 736/10000 [00:04<00:56, 163.79it/s]Running 10000 simulations.:   8%|▊         | 753/10000 [00:04<00:56, 164.46it/s]Running 10000 simulations.:   8%|▊         | 770/10000 [00:04<00:56, 164.18it/s]Running 10000 simulations.:   8%|▊         | 787/10000 [00:04<00:56, 164.48it/s]Running 10000 simulations.:   8%|▊         | 804/10000 [00:04<00:55, 164.65it/s]Running 10000 simulations.:   8%|▊         | 821/10000 [00:04<00:55, 164.83it/s]Running 10000 simulations.:   8%|▊         | 838/10000 [00:05<00:55, 164.46it/s]Running 10000 simulations.:   9%|▊         | 855/10000 [00:05<00:55, 164.10it/s]Running 10000 simulations.:   9%|▊         | 872/10000 [00:05<00:55, 163.78it/s]Running 10000 simulations.:   9%|▉         | 889/10000 [00:05<00:55, 163.73it/s]Running 10000 simulations.:   9%|▉         | 906/10000 [00:05<00:55, 164.12it/s]Running 10000 simulations.:   9%|▉         | 923/10000 [00:05<00:55, 164.19it/s]Running 10000 simulations.:   9%|▉         | 940/10000 [00:05<00:55, 164.43it/s]Running 10000 simulations.:  10%|▉         | 957/10000 [00:05<00:54, 164.54it/s]Running 10000 simulations.:  10%|▉         | 974/10000 [00:05<00:54, 164.56it/s]Running 10000 simulations.:  10%|▉         | 991/10000 [00:06<00:54, 164.51it/s]Running 10000 simulations.:  10%|█         | 1008/10000 [00:06<00:54, 164.62it/s]Running 10000 simulations.:  10%|█         | 1025/10000 [00:06<00:54, 164.70it/s]Running 10000 simulations.:  10%|█         | 1042/10000 [00:06<00:54, 164.72it/s]Running 10000 simulations.:  11%|█         | 1059/10000 [00:06<00:54, 164.56it/s]Running 10000 simulations.:  11%|█         | 1076/10000 [00:06<00:54, 164.46it/s]Running 10000 simulations.:  11%|█         | 1093/10000 [00:06<00:54, 164.50it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:06<00:54, 164.59it/s]Running 10000 simulations.:  11%|█▏        | 1127/10000 [00:06<00:54, 163.18it/s]Running 10000 simulations.:  11%|█▏        | 1144/10000 [00:06<00:55, 159.05it/s]Running 10000 simulations.:  12%|█▏        | 1160/10000 [00:07<00:56, 156.69it/s]Running 10000 simulations.:  12%|█▏        | 1176/10000 [00:07<00:56, 155.25it/s]Running 10000 simulations.:  12%|█▏        | 1192/10000 [00:07<00:57, 153.79it/s]Running 10000 simulations.:  12%|█▏        | 1208/10000 [00:07<00:57, 153.03it/s]Running 10000 simulations.:  12%|█▏        | 1224/10000 [00:07<00:57, 152.62it/s]Running 10000 simulations.:  12%|█▏        | 1240/10000 [00:07<00:57, 152.82it/s]Running 10000 simulations.:  13%|█▎        | 1257/10000 [00:07<00:56, 155.20it/s]Running 10000 simulations.:  13%|█▎        | 1274/10000 [00:07<00:55, 156.93it/s]Running 10000 simulations.:  13%|█▎        | 1291/10000 [00:07<00:54, 158.90it/s]Running 10000 simulations.:  13%|█▎        | 1308/10000 [00:08<00:54, 160.56it/s]Running 10000 simulations.:  13%|█▎        | 1325/10000 [00:08<00:54, 160.16it/s]Running 10000 simulations.:  13%|█▎        | 1342/10000 [00:08<00:54, 157.62it/s]Running 10000 simulations.:  14%|█▎        | 1358/10000 [00:08<00:55, 155.65it/s]Running 10000 simulations.:  14%|█▎        | 1374/10000 [00:08<00:55, 154.09it/s]Running 10000 simulations.:  14%|█▍        | 1390/10000 [00:08<00:56, 152.91it/s]Running 10000 simulations.:  14%|█▍        | 1406/10000 [00:08<00:56, 152.98it/s]Running 10000 simulations.:  14%|█▍        | 1422/10000 [00:08<00:56, 152.58it/s]Running 10000 simulations.:  14%|█▍        | 1438/10000 [00:08<00:55, 153.55it/s]Running 10000 simulations.:  15%|█▍        | 1455/10000 [00:08<00:54, 155.85it/s]Running 10000 simulations.:  15%|█▍        | 1472/10000 [00:09<00:54, 157.57it/s]Running 10000 simulations.:  15%|█▍        | 1489/10000 [00:09<00:53, 158.82it/s]Running 10000 simulations.:  15%|█▌        | 1506/10000 [00:09<00:52, 160.65it/s]Running 10000 simulations.:  15%|█▌        | 1523/10000 [00:09<00:53, 159.27it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:09<00:53, 157.29it/s]Running 10000 simulations.:  16%|█▌        | 1555/10000 [00:09<00:54, 155.72it/s]Running 10000 simulations.:  16%|█▌        | 1571/10000 [00:09<00:54, 154.76it/s]Running 10000 simulations.:  16%|█▌        | 1587/10000 [00:09<00:54, 153.51it/s]Running 10000 simulations.:  16%|█▌        | 1603/10000 [00:09<00:54, 153.44it/s]Running 10000 simulations.:  16%|█▌        | 1619/10000 [00:10<00:54, 152.96it/s]Running 10000 simulations.:  16%|█▋        | 1635/10000 [00:10<00:54, 153.70it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:10<00:53, 154.87it/s]Running 10000 simulations.:  17%|█▋        | 1667/10000 [00:10<00:53, 155.89it/s]Running 10000 simulations.:  17%|█▋        | 1684/10000 [00:10<00:52, 157.04it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:10<00:52, 158.59it/s]Running 10000 simulations.:  17%|█▋        | 1717/10000 [00:10<00:52, 156.94it/s]Running 10000 simulations.:  17%|█▋        | 1733/10000 [00:10<00:53, 155.49it/s]Running 10000 simulations.:  17%|█▋        | 1749/10000 [00:10<00:53, 154.43it/s]Running 10000 simulations.:  18%|█▊        | 1765/10000 [00:10<00:53, 152.78it/s]Running 10000 simulations.:  18%|█▊        | 1781/10000 [00:11<00:53, 152.31it/s]Running 10000 simulations.:  18%|█▊        | 1797/10000 [00:11<00:53, 152.72it/s]Running 10000 simulations.:  18%|█▊        | 1813/10000 [00:11<00:53, 153.13it/s]Running 10000 simulations.:  18%|█▊        | 1830/10000 [00:11<00:52, 155.29it/s]Running 10000 simulations.:  18%|█▊        | 1847/10000 [00:11<00:51, 157.32it/s]Running 10000 simulations.:  19%|█▊        | 1864/10000 [00:11<00:51, 158.67it/s]Running 10000 simulations.:  19%|█▉        | 1881/10000 [00:11<00:50, 160.12it/s]Running 10000 simulations.:  19%|█▉        | 1898/10000 [00:11<00:50, 160.13it/s]Running 10000 simulations.:  19%|█▉        | 1915/10000 [00:11<00:51, 157.12it/s]Running 10000 simulations.:  19%|█▉        | 1931/10000 [00:12<00:51, 155.19it/s]Running 10000 simulations.:  19%|█▉        | 1947/10000 [00:12<00:52, 154.12it/s]Running 10000 simulations.:  20%|█▉        | 1963/10000 [00:12<00:52, 152.43it/s]Running 10000 simulations.:  20%|█▉        | 1979/10000 [00:12<00:52, 152.73it/s]Running 10000 simulations.:  20%|█▉        | 1995/10000 [00:12<00:52, 152.71it/s]Running 10000 simulations.:  20%|██        | 2011/10000 [00:12<00:51, 153.93it/s]Running 10000 simulations.:  20%|██        | 2027/10000 [00:12<00:51, 155.35it/s]Running 10000 simulations.:  20%|██        | 2044/10000 [00:12<00:50, 156.99it/s]Running 10000 simulations.:  21%|██        | 2060/10000 [00:12<00:50, 156.96it/s]Running 10000 simulations.:  21%|██        | 2076/10000 [00:12<00:50, 156.54it/s]Running 10000 simulations.:  21%|██        | 2093/10000 [00:13<00:50, 158.08it/s]Running 10000 simulations.:  21%|██        | 2109/10000 [00:13<00:49, 157.97it/s]Running 10000 simulations.:  21%|██▏       | 2125/10000 [00:13<00:50, 156.17it/s]Running 10000 simulations.:  21%|██▏       | 2141/10000 [00:13<00:50, 154.96it/s]Running 10000 simulations.:  22%|██▏       | 2157/10000 [00:13<00:50, 153.92it/s]Running 10000 simulations.:  22%|██▏       | 2173/10000 [00:13<00:51, 152.68it/s]Running 10000 simulations.:  22%|██▏       | 2189/10000 [00:13<00:50, 153.26it/s]Running 10000 simulations.:  22%|██▏       | 2205/10000 [00:13<00:51, 152.82it/s]Running 10000 simulations.:  22%|██▏       | 2221/10000 [00:13<00:50, 154.40it/s]Running 10000 simulations.:  22%|██▏       | 2237/10000 [00:13<00:49, 155.93it/s]Running 10000 simulations.:  23%|██▎       | 2254/10000 [00:14<00:49, 157.43it/s]Running 10000 simulations.:  23%|██▎       | 2271/10000 [00:14<00:48, 158.85it/s]Running 10000 simulations.:  23%|██▎       | 2288/10000 [00:14<00:48, 159.96it/s]Running 10000 simulations.:  23%|██▎       | 2305/10000 [00:14<00:48, 157.30it/s]Running 10000 simulations.:  23%|██▎       | 2321/10000 [00:14<00:49, 155.70it/s]Running 10000 simulations.:  23%|██▎       | 2337/10000 [00:14<00:49, 154.93it/s]Running 10000 simulations.:  24%|██▎       | 2353/10000 [00:14<00:49, 153.97it/s]Running 10000 simulations.:  24%|██▎       | 2371/10000 [00:14<00:48, 158.89it/s]Running 10000 simulations.:  24%|██▍       | 2388/10000 [00:14<00:47, 160.35it/s]Running 10000 simulations.:  24%|██▍       | 2405/10000 [00:15<00:47, 158.39it/s]Running 10000 simulations.:  24%|██▍       | 2422/10000 [00:15<00:47, 159.24it/s]Running 10000 simulations.:  24%|██▍       | 2439/10000 [00:15<00:47, 159.61it/s]Running 10000 simulations.:  25%|██▍       | 2456/10000 [00:15<00:46, 160.96it/s]Running 10000 simulations.:  25%|██▍       | 2473/10000 [00:15<00:46, 161.99it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:15<00:46, 159.99it/s]Running 10000 simulations.:  25%|██▌       | 2507/10000 [00:15<00:47, 157.33it/s]Running 10000 simulations.:  25%|██▌       | 2523/10000 [00:15<00:48, 155.51it/s]Running 10000 simulations.:  25%|██▌       | 2539/10000 [00:15<00:48, 154.06it/s]Running 10000 simulations.:  26%|██▌       | 2555/10000 [00:16<00:48, 153.08it/s]Running 10000 simulations.:  26%|██▌       | 2571/10000 [00:16<00:48, 153.28it/s]Running 10000 simulations.:  26%|██▌       | 2587/10000 [00:16<00:48, 152.79it/s]Running 10000 simulations.:  26%|██▌       | 2603/10000 [00:16<00:47, 154.40it/s]Running 10000 simulations.:  26%|██▌       | 2620/10000 [00:16<00:47, 156.04it/s]Running 10000 simulations.:  26%|██▋       | 2637/10000 [00:16<00:46, 157.93it/s]Running 10000 simulations.:  27%|██▋       | 2654/10000 [00:16<00:46, 159.49it/s]Running 10000 simulations.:  27%|██▋       | 2671/10000 [00:16<00:45, 160.09it/s]Running 10000 simulations.:  27%|██▋       | 2688/10000 [00:16<00:46, 157.62it/s]Running 10000 simulations.:  27%|██▋       | 2704/10000 [00:16<00:46, 155.78it/s]Running 10000 simulations.:  27%|██▋       | 2720/10000 [00:17<00:47, 154.85it/s]Running 10000 simulations.:  27%|██▋       | 2736/10000 [00:17<00:47, 153.53it/s]Running 10000 simulations.:  28%|██▊       | 2752/10000 [00:17<00:47, 153.55it/s]Running 10000 simulations.:  28%|██▊       | 2768/10000 [00:17<00:47, 153.28it/s]Running 10000 simulations.:  28%|██▊       | 2784/10000 [00:17<00:46, 153.69it/s]Running 10000 simulations.:  28%|██▊       | 2800/10000 [00:17<00:46, 155.11it/s]Running 10000 simulations.:  28%|██▊       | 2817/10000 [00:17<00:45, 156.95it/s]Running 10000 simulations.:  28%|██▊       | 2834/10000 [00:17<00:45, 158.74it/s]Running 10000 simulations.:  29%|██▊       | 2851/10000 [00:17<00:44, 160.44it/s]Running 10000 simulations.:  29%|██▊       | 2868/10000 [00:18<00:44, 159.22it/s]Running 10000 simulations.:  29%|██▉       | 2884/10000 [00:18<00:45, 156.92it/s]Running 10000 simulations.:  29%|██▉       | 2900/10000 [00:18<00:45, 154.95it/s]Running 10000 simulations.:  29%|██▉       | 2916/10000 [00:18<00:46, 153.64it/s]Running 10000 simulations.:  29%|██▉       | 2932/10000 [00:18<00:46, 152.54it/s]Running 10000 simulations.:  29%|██▉       | 2948/10000 [00:18<00:46, 152.62it/s]Running 10000 simulations.:  30%|██▉       | 2964/10000 [00:18<00:46, 152.61it/s]Running 10000 simulations.:  30%|██▉       | 2980/10000 [00:18<00:45, 153.62it/s]Running 10000 simulations.:  30%|██▉       | 2997/10000 [00:18<00:45, 155.51it/s]Running 10000 simulations.:  30%|███       | 3014/10000 [00:18<00:44, 157.16it/s]Running 10000 simulations.:  30%|███       | 3031/10000 [00:19<00:43, 159.17it/s]Running 10000 simulations.:  30%|███       | 3048/10000 [00:19<00:43, 160.82it/s]Running 10000 simulations.:  31%|███       | 3065/10000 [00:19<00:43, 159.29it/s]Running 10000 simulations.:  31%|███       | 3081/10000 [00:19<00:44, 156.37it/s]Running 10000 simulations.:  31%|███       | 3097/10000 [00:19<00:44, 154.57it/s]Running 10000 simulations.:  31%|███       | 3113/10000 [00:19<00:44, 153.20it/s]Running 10000 simulations.:  31%|███▏      | 3129/10000 [00:19<00:45, 152.14it/s]Running 10000 simulations.:  31%|███▏      | 3145/10000 [00:19<00:45, 152.30it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:19<00:45, 151.53it/s]Running 10000 simulations.:  32%|███▏      | 3177/10000 [00:20<00:44, 153.50it/s]Running 10000 simulations.:  32%|███▏      | 3194/10000 [00:20<00:43, 155.53it/s]Running 10000 simulations.:  32%|███▏      | 3211/10000 [00:20<00:43, 157.77it/s]Running 10000 simulations.:  32%|███▏      | 3228/10000 [00:20<00:42, 159.64it/s]Running 10000 simulations.:  32%|███▏      | 3245/10000 [00:20<00:42, 160.04it/s]Running 10000 simulations.:  33%|███▎      | 3262/10000 [00:20<00:43, 155.96it/s]Running 10000 simulations.:  33%|███▎      | 3278/10000 [00:20<00:43, 154.60it/s]Running 10000 simulations.:  33%|███▎      | 3294/10000 [00:20<00:43, 153.48it/s]Running 10000 simulations.:  33%|███▎      | 3310/10000 [00:20<00:44, 150.70it/s]Running 10000 simulations.:  33%|███▎      | 3326/10000 [00:20<00:44, 150.85it/s]Running 10000 simulations.:  33%|███▎      | 3342/10000 [00:21<00:44, 151.29it/s]Running 10000 simulations.:  34%|███▎      | 3358/10000 [00:21<00:43, 152.25it/s]Running 10000 simulations.:  34%|███▍      | 3375/10000 [00:21<00:42, 154.53it/s]Running 10000 simulations.:  34%|███▍      | 3392/10000 [00:21<00:42, 157.25it/s]Running 10000 simulations.:  34%|███▍      | 3409/10000 [00:21<00:41, 158.80it/s]Running 10000 simulations.:  34%|███▍      | 3426/10000 [00:21<00:41, 160.07it/s]Running 10000 simulations.:  34%|███▍      | 3443/10000 [00:21<00:41, 156.50it/s]Running 10000 simulations.:  35%|███▍      | 3459/10000 [00:21<00:42, 154.80it/s]Running 10000 simulations.:  35%|███▍      | 3475/10000 [00:21<00:42, 153.66it/s]Running 10000 simulations.:  35%|███▍      | 3491/10000 [00:22<00:42, 152.97it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:22<00:43, 150.75it/s]Running 10000 simulations.:  35%|███▌      | 3523/10000 [00:22<00:42, 151.61it/s]Running 10000 simulations.:  35%|███▌      | 3539/10000 [00:22<00:42, 151.43it/s]Running 10000 simulations.:  36%|███▌      | 3556/10000 [00:22<00:41, 154.07it/s]Running 10000 simulations.:  36%|███▌      | 3573/10000 [00:22<00:41, 156.19it/s]Running 10000 simulations.:  36%|███▌      | 3589/10000 [00:22<00:40, 157.26it/s]Running 10000 simulations.:  36%|███▌      | 3605/10000 [00:22<00:40, 157.31it/s]Running 10000 simulations.:  36%|███▌      | 3621/10000 [00:22<00:40, 157.86it/s]Running 10000 simulations.:  36%|███▋      | 3638/10000 [00:22<00:39, 159.27it/s]Running 10000 simulations.:  37%|███▋      | 3655/10000 [00:23<00:39, 160.21it/s]Running 10000 simulations.:  37%|███▋      | 3672/10000 [00:23<00:42, 150.24it/s]Running 10000 simulations.:  37%|███▋      | 3688/10000 [00:23<00:41, 150.34it/s]Running 10000 simulations.:  37%|███▋      | 3704/10000 [00:23<00:41, 150.68it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:23<00:41, 150.61it/s]Running 10000 simulations.:  37%|███▋      | 3736/10000 [00:23<00:41, 150.72it/s]Running 10000 simulations.:  38%|███▊      | 3752/10000 [00:23<00:41, 151.28it/s]Running 10000 simulations.:  38%|███▊      | 3768/10000 [00:23<00:40, 152.21it/s]Running 10000 simulations.:  38%|███▊      | 3785/10000 [00:23<00:40, 154.50it/s]Running 10000 simulations.:  38%|███▊      | 3802/10000 [00:24<00:39, 156.64it/s]Running 10000 simulations.:  38%|███▊      | 3819/10000 [00:24<00:39, 158.23it/s]Running 10000 simulations.:  38%|███▊      | 3836/10000 [00:24<00:38, 160.00it/s]Running 10000 simulations.:  39%|███▊      | 3853/10000 [00:24<00:38, 158.50it/s]Running 10000 simulations.:  39%|███▊      | 3869/10000 [00:24<00:39, 156.23it/s]Running 10000 simulations.:  39%|███▉      | 3885/10000 [00:24<00:39, 155.17it/s]Running 10000 simulations.:  39%|███▉      | 3901/10000 [00:24<00:39, 154.19it/s]Running 10000 simulations.:  39%|███▉      | 3917/10000 [00:24<00:39, 152.91it/s]Running 10000 simulations.:  39%|███▉      | 3933/10000 [00:24<00:39, 153.06it/s]Running 10000 simulations.:  39%|███▉      | 3949/10000 [00:24<00:39, 152.70it/s]Running 10000 simulations.:  40%|███▉      | 3965/10000 [00:25<00:39, 154.29it/s]Running 10000 simulations.:  40%|███▉      | 3982/10000 [00:25<00:38, 156.22it/s]Running 10000 simulations.:  40%|███▉      | 3999/10000 [00:25<00:37, 158.10it/s]Running 10000 simulations.:  40%|████      | 4016/10000 [00:25<00:37, 159.97it/s]Running 10000 simulations.:  40%|████      | 4033/10000 [00:25<00:37, 160.85it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:25<00:37, 158.33it/s]Running 10000 simulations.:  41%|████      | 4067/10000 [00:25<00:36, 161.62it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:25<00:35, 165.62it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:25<00:36, 160.03it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:26<00:37, 156.83it/s]Running 10000 simulations.:  41%|████▏     | 4135/10000 [00:26<00:37, 155.80it/s]Running 10000 simulations.:  42%|████▏     | 4151/10000 [00:26<00:37, 155.78it/s]Running 10000 simulations.:  42%|████▏     | 4167/10000 [00:26<00:37, 156.96it/s]Running 10000 simulations.:  42%|████▏     | 4184/10000 [00:26<00:36, 158.20it/s]Running 10000 simulations.:  42%|████▏     | 4201/10000 [00:26<00:36, 159.43it/s]Running 10000 simulations.:  42%|████▏     | 4218/10000 [00:26<00:35, 160.63it/s]Running 10000 simulations.:  42%|████▏     | 4235/10000 [00:26<00:36, 157.84it/s]Running 10000 simulations.:  43%|████▎     | 4251/10000 [00:26<00:36, 155.86it/s]Running 10000 simulations.:  43%|████▎     | 4267/10000 [00:27<00:37, 154.69it/s]Running 10000 simulations.:  43%|████▎     | 4283/10000 [00:27<00:37, 153.60it/s]Running 10000 simulations.:  43%|████▎     | 4299/10000 [00:27<00:37, 152.31it/s]Running 10000 simulations.:  43%|████▎     | 4315/10000 [00:27<00:37, 152.55it/s]Running 10000 simulations.:  43%|████▎     | 4331/10000 [00:27<00:37, 152.47it/s]Running 10000 simulations.:  43%|████▎     | 4347/10000 [00:27<00:36, 154.29it/s]Running 10000 simulations.:  44%|████▎     | 4364/10000 [00:27<00:36, 156.36it/s]Running 10000 simulations.:  44%|████▍     | 4381/10000 [00:27<00:35, 158.31it/s]Running 10000 simulations.:  44%|████▍     | 4398/10000 [00:27<00:35, 159.86it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:27<00:34, 160.98it/s]Running 10000 simulations.:  44%|████▍     | 4432/10000 [00:28<00:35, 157.30it/s]Running 10000 simulations.:  44%|████▍     | 4448/10000 [00:28<00:35, 155.77it/s]Running 10000 simulations.:  45%|████▍     | 4464/10000 [00:28<00:35, 154.47it/s]Running 10000 simulations.:  45%|████▍     | 4480/10000 [00:28<00:36, 153.18it/s]Running 10000 simulations.:  45%|████▍     | 4496/10000 [00:28<00:36, 152.62it/s]Running 10000 simulations.:  45%|████▌     | 4512/10000 [00:28<00:35, 152.56it/s]Running 10000 simulations.:  45%|████▌     | 4528/10000 [00:28<00:35, 152.61it/s]Running 10000 simulations.:  45%|████▌     | 4545/10000 [00:28<00:35, 154.83it/s]Running 10000 simulations.:  46%|████▌     | 4562/10000 [00:28<00:34, 156.71it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:29<00:34, 158.41it/s]Running 10000 simulations.:  46%|████▌     | 4596/10000 [00:29<00:33, 160.44it/s]Running 10000 simulations.:  46%|████▌     | 4613/10000 [00:29<00:33, 158.56it/s]Running 10000 simulations.:  46%|████▋     | 4629/10000 [00:29<00:34, 155.03it/s]Running 10000 simulations.:  46%|████▋     | 4645/10000 [00:29<00:34, 153.96it/s]Running 10000 simulations.:  47%|████▋     | 4661/10000 [00:29<00:34, 153.25it/s]Running 10000 simulations.:  47%|████▋     | 4677/10000 [00:29<00:34, 152.30it/s]Running 10000 simulations.:  47%|████▋     | 4693/10000 [00:29<00:34, 152.73it/s]Running 10000 simulations.:  47%|████▋     | 4709/10000 [00:29<00:34, 152.87it/s]Running 10000 simulations.:  47%|████▋     | 4725/10000 [00:29<00:34, 154.28it/s]Running 10000 simulations.:  47%|████▋     | 4742/10000 [00:30<00:33, 156.12it/s]Running 10000 simulations.:  48%|████▊     | 4759/10000 [00:30<00:33, 158.20it/s]Running 10000 simulations.:  48%|████▊     | 4776/10000 [00:30<00:32, 159.49it/s]Running 10000 simulations.:  48%|████▊     | 4793/10000 [00:30<00:32, 160.38it/s]Running 10000 simulations.:  48%|████▊     | 4810/10000 [00:30<00:33, 156.65it/s]Running 10000 simulations.:  48%|████▊     | 4826/10000 [00:30<00:33, 154.50it/s]Running 10000 simulations.:  48%|████▊     | 4842/10000 [00:30<00:33, 153.68it/s]Running 10000 simulations.:  49%|████▊     | 4858/10000 [00:30<00:33, 152.74it/s]Running 10000 simulations.:  49%|████▊     | 4874/10000 [00:30<00:33, 151.88it/s]Running 10000 simulations.:  49%|████▉     | 4890/10000 [00:31<00:33, 152.23it/s]Running 10000 simulations.:  49%|████▉     | 4906/10000 [00:31<00:33, 151.72it/s]Running 10000 simulations.:  49%|████▉     | 4923/10000 [00:31<00:32, 154.74it/s]Running 10000 simulations.:  49%|████▉     | 4940/10000 [00:31<00:32, 156.42it/s]Running 10000 simulations.:  50%|████▉     | 4957/10000 [00:31<00:31, 158.33it/s]Running 10000 simulations.:  50%|████▉     | 4973/10000 [00:31<00:31, 157.99it/s]Running 10000 simulations.:  50%|████▉     | 4990/10000 [00:31<00:31, 158.73it/s]Running 10000 simulations.:  50%|█████     | 5007/10000 [00:31<00:31, 159.81it/s]Running 10000 simulations.:  50%|█████     | 5024/10000 [00:31<00:31, 160.05it/s]Running 10000 simulations.:  50%|█████     | 5041/10000 [00:31<00:31, 156.03it/s]Running 10000 simulations.:  51%|█████     | 5057/10000 [00:32<00:32, 153.37it/s]Running 10000 simulations.:  51%|█████     | 5073/10000 [00:32<00:32, 151.68it/s]Running 10000 simulations.:  51%|█████     | 5089/10000 [00:32<00:32, 150.01it/s]Running 10000 simulations.:  51%|█████     | 5105/10000 [00:32<00:33, 147.37it/s]Running 10000 simulations.:  51%|█████     | 5121/10000 [00:32<00:32, 148.75it/s]Running 10000 simulations.:  51%|█████▏    | 5136/10000 [00:32<00:32, 148.35it/s]Running 10000 simulations.:  52%|█████▏    | 5152/10000 [00:32<00:31, 151.58it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:32<00:31, 154.18it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:32<00:30, 156.67it/s]Running 10000 simulations.:  52%|█████▏    | 5203/10000 [00:33<00:30, 158.57it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:33<00:30, 158.44it/s]Running 10000 simulations.:  52%|█████▏    | 5235/10000 [00:33<00:31, 153.39it/s]Running 10000 simulations.:  53%|█████▎    | 5251/10000 [00:33<00:31, 151.77it/s]Running 10000 simulations.:  53%|█████▎    | 5267/10000 [00:33<00:31, 150.38it/s]Running 10000 simulations.:  53%|█████▎    | 5283/10000 [00:33<00:31, 148.67it/s]Running 10000 simulations.:  53%|█████▎    | 5298/10000 [00:33<00:31, 147.19it/s]Running 10000 simulations.:  53%|█████▎    | 5314/10000 [00:33<00:31, 149.08it/s]Running 10000 simulations.:  53%|█████▎    | 5329/10000 [00:33<00:31, 148.43it/s]Running 10000 simulations.:  53%|█████▎    | 5345/10000 [00:33<00:30, 151.09it/s]Running 10000 simulations.:  54%|█████▎    | 5361/10000 [00:34<00:30, 153.14it/s]Running 10000 simulations.:  54%|█████▍    | 5378/10000 [00:34<00:29, 155.76it/s]Running 10000 simulations.:  54%|█████▍    | 5395/10000 [00:34<00:29, 158.32it/s]Running 10000 simulations.:  54%|█████▍    | 5412/10000 [00:34<00:28, 159.74it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:34<00:29, 155.70it/s]Running 10000 simulations.:  54%|█████▍    | 5444/10000 [00:34<00:29, 152.06it/s]Running 10000 simulations.:  55%|█████▍    | 5460/10000 [00:34<00:30, 150.48it/s]Running 10000 simulations.:  55%|█████▍    | 5476/10000 [00:34<00:30, 150.63it/s]Running 10000 simulations.:  55%|█████▍    | 5492/10000 [00:34<00:30, 149.23it/s]Running 10000 simulations.:  55%|█████▌    | 5508/10000 [00:35<00:29, 150.51it/s]Running 10000 simulations.:  55%|█████▌    | 5524/10000 [00:35<00:29, 150.31it/s]Running 10000 simulations.:  55%|█████▌    | 5540/10000 [00:35<00:29, 151.79it/s]Running 10000 simulations.:  56%|█████▌    | 5556/10000 [00:35<00:28, 154.04it/s]Running 10000 simulations.:  56%|█████▌    | 5573/10000 [00:35<00:28, 156.91it/s]Running 10000 simulations.:  56%|█████▌    | 5590/10000 [00:35<00:27, 158.42it/s]Running 10000 simulations.:  56%|█████▌    | 5607/10000 [00:35<00:27, 159.09it/s]Running 10000 simulations.:  56%|█████▌    | 5623/10000 [00:35<00:28, 155.51it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:35<00:28, 151.62it/s]Running 10000 simulations.:  57%|█████▋    | 5655/10000 [00:36<00:28, 150.40it/s]Running 10000 simulations.:  57%|█████▋    | 5671/10000 [00:36<00:28, 150.13it/s]Running 10000 simulations.:  57%|█████▋    | 5687/10000 [00:36<00:29, 147.72it/s]Running 10000 simulations.:  57%|█████▋    | 5702/10000 [00:36<00:29, 148.16it/s]Running 10000 simulations.:  57%|█████▋    | 5717/10000 [00:36<00:29, 147.44it/s]Running 10000 simulations.:  57%|█████▋    | 5733/10000 [00:36<00:28, 149.14it/s]Running 10000 simulations.:  57%|█████▋    | 5749/10000 [00:36<00:27, 152.18it/s]Running 10000 simulations.:  58%|█████▊    | 5766/10000 [00:36<00:27, 154.78it/s]Running 10000 simulations.:  58%|█████▊    | 5783/10000 [00:36<00:26, 156.97it/s]Running 10000 simulations.:  58%|█████▊    | 5800/10000 [00:36<00:26, 158.80it/s]Running 10000 simulations.:  58%|█████▊    | 5816/10000 [00:37<00:26, 156.26it/s]Running 10000 simulations.:  58%|█████▊    | 5832/10000 [00:37<00:27, 152.75it/s]Running 10000 simulations.:  58%|█████▊    | 5848/10000 [00:37<00:27, 150.05it/s]Running 10000 simulations.:  59%|█████▊    | 5864/10000 [00:37<00:28, 147.20it/s]Running 10000 simulations.:  59%|█████▉    | 5879/10000 [00:37<00:28, 144.34it/s]Running 10000 simulations.:  59%|█████▉    | 5894/10000 [00:37<00:28, 145.95it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:37<00:27, 147.78it/s]Running 10000 simulations.:  59%|█████▉    | 5928/10000 [00:37<00:26, 155.03it/s]Running 10000 simulations.:  59%|█████▉    | 5947/10000 [00:37<00:24, 163.70it/s]Running 10000 simulations.:  60%|█████▉    | 5964/10000 [00:38<00:24, 163.12it/s]Running 10000 simulations.:  60%|█████▉    | 5981/10000 [00:38<00:24, 163.02it/s]Running 10000 simulations.:  60%|█████▉    | 5998/10000 [00:38<00:24, 162.92it/s]Running 10000 simulations.:  60%|██████    | 6015/10000 [00:38<00:24, 160.20it/s]Running 10000 simulations.:  60%|██████    | 6032/10000 [00:38<00:25, 154.22it/s]Running 10000 simulations.:  60%|██████    | 6048/10000 [00:38<00:26, 150.60it/s]Running 10000 simulations.:  61%|██████    | 6064/10000 [00:38<00:26, 150.68it/s]Running 10000 simulations.:  61%|██████    | 6080/10000 [00:38<00:26, 148.28it/s]Running 10000 simulations.:  61%|██████    | 6096/10000 [00:38<00:26, 149.59it/s]Running 10000 simulations.:  61%|██████    | 6112/10000 [00:38<00:25, 150.09it/s]Running 10000 simulations.:  61%|██████▏   | 6128/10000 [00:39<00:25, 151.39it/s]Running 10000 simulations.:  61%|██████▏   | 6144/10000 [00:39<00:25, 153.48it/s]Running 10000 simulations.:  62%|██████▏   | 6161/10000 [00:39<00:24, 155.67it/s]Running 10000 simulations.:  62%|██████▏   | 6178/10000 [00:39<00:24, 157.74it/s]Running 10000 simulations.:  62%|██████▏   | 6195/10000 [00:39<00:23, 159.69it/s]Running 10000 simulations.:  62%|██████▏   | 6211/10000 [00:39<00:24, 156.54it/s]Running 10000 simulations.:  62%|██████▏   | 6227/10000 [00:39<00:24, 154.02it/s]Running 10000 simulations.:  62%|██████▏   | 6243/10000 [00:39<00:24, 153.40it/s]Running 10000 simulations.:  63%|██████▎   | 6259/10000 [00:39<00:24, 152.94it/s]Running 10000 simulations.:  63%|██████▎   | 6275/10000 [00:40<00:24, 152.07it/s]Running 10000 simulations.:  63%|██████▎   | 6291/10000 [00:40<00:24, 151.60it/s]Running 10000 simulations.:  63%|██████▎   | 6307/10000 [00:40<00:24, 150.92it/s]Running 10000 simulations.:  63%|██████▎   | 6323/10000 [00:40<00:24, 151.21it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:40<00:23, 153.03it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:40<00:23, 155.54it/s]Running 10000 simulations.:  64%|██████▎   | 6373/10000 [00:40<00:23, 157.44it/s]Running 10000 simulations.:  64%|██████▍   | 6390/10000 [00:40<00:22, 159.10it/s]Running 10000 simulations.:  64%|██████▍   | 6406/10000 [00:40<00:22, 156.30it/s]Running 10000 simulations.:  64%|██████▍   | 6422/10000 [00:40<00:23, 154.55it/s]Running 10000 simulations.:  64%|██████▍   | 6438/10000 [00:41<00:23, 153.44it/s]Running 10000 simulations.:  65%|██████▍   | 6454/10000 [00:41<00:23, 152.61it/s]Running 10000 simulations.:  65%|██████▍   | 6470/10000 [00:41<00:23, 149.50it/s]Running 10000 simulations.:  65%|██████▍   | 6486/10000 [00:41<00:23, 150.16it/s]Running 10000 simulations.:  65%|██████▌   | 6502/10000 [00:41<00:23, 150.40it/s]Running 10000 simulations.:  65%|██████▌   | 6518/10000 [00:41<00:22, 152.55it/s]Running 10000 simulations.:  65%|██████▌   | 6534/10000 [00:41<00:22, 154.54it/s]Running 10000 simulations.:  66%|██████▌   | 6551/10000 [00:41<00:22, 156.11it/s]Running 10000 simulations.:  66%|██████▌   | 6567/10000 [00:41<00:21, 156.78it/s]Running 10000 simulations.:  66%|██████▌   | 6584/10000 [00:42<00:21, 157.81it/s]Running 10000 simulations.:  66%|██████▌   | 6601/10000 [00:42<00:21, 159.80it/s]Running 10000 simulations.:  66%|██████▌   | 6618/10000 [00:42<00:21, 160.32it/s]Running 10000 simulations.:  66%|██████▋   | 6635/10000 [00:42<00:21, 156.33it/s]Running 10000 simulations.:  67%|██████▋   | 6651/10000 [00:42<00:21, 154.31it/s]Running 10000 simulations.:  67%|██████▋   | 6667/10000 [00:42<00:21, 153.16it/s]Running 10000 simulations.:  67%|██████▋   | 6683/10000 [00:42<00:22, 150.61it/s]Running 10000 simulations.:  67%|██████▋   | 6699/10000 [00:42<00:21, 150.68it/s]Running 10000 simulations.:  67%|██████▋   | 6715/10000 [00:42<00:21, 151.30it/s]Running 10000 simulations.:  67%|██████▋   | 6731/10000 [00:42<00:21, 151.12it/s]Running 10000 simulations.:  67%|██████▋   | 6747/10000 [00:43<00:21, 153.26it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:43<00:20, 155.32it/s]Running 10000 simulations.:  68%|██████▊   | 6781/10000 [00:43<00:20, 157.88it/s]Running 10000 simulations.:  68%|██████▊   | 6798/10000 [00:43<00:20, 159.09it/s]Running 10000 simulations.:  68%|██████▊   | 6815/10000 [00:43<00:19, 159.35it/s]Running 10000 simulations.:  68%|██████▊   | 6831/10000 [00:43<00:20, 154.88it/s]Running 10000 simulations.:  68%|██████▊   | 6847/10000 [00:43<00:20, 153.50it/s]Running 10000 simulations.:  69%|██████▊   | 6863/10000 [00:43<00:20, 153.22it/s]Running 10000 simulations.:  69%|██████▉   | 6879/10000 [00:43<00:20, 149.99it/s]Running 10000 simulations.:  69%|██████▉   | 6895/10000 [00:44<00:20, 149.02it/s]Running 10000 simulations.:  69%|██████▉   | 6911/10000 [00:44<00:20, 149.96it/s]Running 10000 simulations.:  69%|██████▉   | 6927/10000 [00:44<00:20, 151.07it/s]Running 10000 simulations.:  69%|██████▉   | 6944/10000 [00:44<00:19, 154.10it/s]Running 10000 simulations.:  70%|██████▉   | 6961/10000 [00:44<00:19, 156.21it/s]Running 10000 simulations.:  70%|██████▉   | 6978/10000 [00:44<00:19, 157.80it/s]Running 10000 simulations.:  70%|██████▉   | 6995/10000 [00:44<00:18, 159.23it/s]Running 10000 simulations.:  70%|███████   | 7011/10000 [00:44<00:18, 157.59it/s]Running 10000 simulations.:  70%|███████   | 7027/10000 [00:44<00:19, 154.01it/s]Running 10000 simulations.:  70%|███████   | 7043/10000 [00:45<00:19, 153.05it/s]Running 10000 simulations.:  71%|███████   | 7059/10000 [00:45<00:19, 152.21it/s]Running 10000 simulations.:  71%|███████   | 7075/10000 [00:45<00:19, 151.29it/s]Running 10000 simulations.:  71%|███████   | 7091/10000 [00:45<00:19, 151.41it/s]Running 10000 simulations.:  71%|███████   | 7107/10000 [00:45<00:19, 151.95it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:45<00:18, 151.96it/s]Running 10000 simulations.:  71%|███████▏  | 7139/10000 [00:45<00:18, 153.96it/s]Running 10000 simulations.:  72%|███████▏  | 7156/10000 [00:45<00:18, 156.74it/s]Running 10000 simulations.:  72%|███████▏  | 7173/10000 [00:45<00:17, 158.75it/s]Running 10000 simulations.:  72%|███████▏  | 7190/10000 [00:45<00:17, 159.88it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:46<00:17, 156.60it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:46<00:17, 154.74it/s]Running 10000 simulations.:  72%|███████▏  | 7239/10000 [00:46<00:17, 153.74it/s]Running 10000 simulations.:  73%|███████▎  | 7255/10000 [00:46<00:17, 153.36it/s]Running 10000 simulations.:  73%|███████▎  | 7271/10000 [00:46<00:18, 149.62it/s]Running 10000 simulations.:  73%|███████▎  | 7286/10000 [00:46<00:18, 149.36it/s]Running 10000 simulations.:  73%|███████▎  | 7302/10000 [00:46<00:17, 150.25it/s]Running 10000 simulations.:  73%|███████▎  | 7318/10000 [00:46<00:17, 152.62it/s]Running 10000 simulations.:  73%|███████▎  | 7335/10000 [00:46<00:17, 154.76it/s]Running 10000 simulations.:  74%|███████▎  | 7352/10000 [00:47<00:16, 156.88it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:47<00:16, 158.85it/s]Running 10000 simulations.:  74%|███████▍  | 7386/10000 [00:47<00:16, 159.32it/s]Running 10000 simulations.:  74%|███████▍  | 7402/10000 [00:47<00:16, 155.81it/s]Running 10000 simulations.:  74%|███████▍  | 7418/10000 [00:47<00:16, 152.92it/s]Running 10000 simulations.:  74%|███████▍  | 7434/10000 [00:47<00:17, 150.11it/s]Running 10000 simulations.:  74%|███████▍  | 7450/10000 [00:47<00:17, 148.20it/s]Running 10000 simulations.:  75%|███████▍  | 7465/10000 [00:47<00:17, 146.79it/s]Running 10000 simulations.:  75%|███████▍  | 7481/10000 [00:47<00:16, 148.51it/s]Running 10000 simulations.:  75%|███████▍  | 7497/10000 [00:47<00:16, 149.34it/s]Running 10000 simulations.:  75%|███████▌  | 7513/10000 [00:48<00:16, 150.81it/s]Running 10000 simulations.:  75%|███████▌  | 7529/10000 [00:48<00:16, 152.57it/s]Running 10000 simulations.:  75%|███████▌  | 7546/10000 [00:48<00:15, 155.01it/s]Running 10000 simulations.:  76%|███████▌  | 7563/10000 [00:48<00:15, 157.31it/s]Running 10000 simulations.:  76%|███████▌  | 7580/10000 [00:48<00:15, 159.07it/s]Running 10000 simulations.:  76%|███████▌  | 7596/10000 [00:48<00:15, 155.82it/s]Running 10000 simulations.:  76%|███████▌  | 7612/10000 [00:48<00:15, 156.61it/s]Running 10000 simulations.:  76%|███████▋  | 7629/10000 [00:48<00:14, 159.23it/s]Running 10000 simulations.:  76%|███████▋  | 7645/10000 [00:48<00:14, 158.98it/s]Running 10000 simulations.:  77%|███████▋  | 7661/10000 [00:49<00:15, 153.32it/s]Running 10000 simulations.:  77%|███████▋  | 7677/10000 [00:49<00:15, 151.72it/s]Running 10000 simulations.:  77%|███████▋  | 7693/10000 [00:49<00:15, 152.86it/s]Running 10000 simulations.:  77%|███████▋  | 7709/10000 [00:49<00:15, 151.48it/s]Running 10000 simulations.:  77%|███████▋  | 7725/10000 [00:49<00:14, 153.06it/s]Running 10000 simulations.:  77%|███████▋  | 7742/10000 [00:49<00:14, 155.27it/s]Running 10000 simulations.:  78%|███████▊  | 7759/10000 [00:49<00:14, 157.25it/s]Running 10000 simulations.:  78%|███████▊  | 7776/10000 [00:49<00:14, 158.71it/s]Running 10000 simulations.:  78%|███████▊  | 7792/10000 [00:49<00:14, 156.66it/s]Running 10000 simulations.:  78%|███████▊  | 7808/10000 [00:49<00:14, 153.87it/s]Running 10000 simulations.:  78%|███████▊  | 7824/10000 [00:50<00:14, 151.63it/s]Running 10000 simulations.:  78%|███████▊  | 7840/10000 [00:50<00:14, 151.57it/s]Running 10000 simulations.:  79%|███████▊  | 7856/10000 [00:50<00:14, 149.09it/s]Running 10000 simulations.:  79%|███████▊  | 7871/10000 [00:50<00:14, 148.40it/s]Running 10000 simulations.:  79%|███████▉  | 7887/10000 [00:50<00:14, 149.81it/s]Running 10000 simulations.:  79%|███████▉  | 7903/10000 [00:50<00:13, 151.03it/s]Running 10000 simulations.:  79%|███████▉  | 7920/10000 [00:50<00:13, 154.02it/s]Running 10000 simulations.:  79%|███████▉  | 7937/10000 [00:50<00:13, 156.04it/s]Running 10000 simulations.:  80%|███████▉  | 7954/10000 [00:50<00:12, 158.27it/s]Running 10000 simulations.:  80%|███████▉  | 7970/10000 [00:51<00:12, 158.51it/s]Running 10000 simulations.:  80%|███████▉  | 7987/10000 [00:51<00:12, 159.42it/s]Running 10000 simulations.:  80%|████████  | 8004/10000 [00:51<00:12, 160.70it/s]Running 10000 simulations.:  80%|████████  | 8021/10000 [00:51<00:12, 161.23it/s]Running 10000 simulations.:  80%|████████  | 8038/10000 [00:51<00:12, 156.87it/s]Running 10000 simulations.:  81%|████████  | 8054/10000 [00:51<00:12, 154.01it/s]Running 10000 simulations.:  81%|████████  | 8070/10000 [00:51<00:12, 150.53it/s]Running 10000 simulations.:  81%|████████  | 8086/10000 [00:51<00:12, 149.01it/s]Running 10000 simulations.:  81%|████████  | 8101/10000 [00:51<00:12, 147.39it/s]Running 10000 simulations.:  81%|████████  | 8117/10000 [00:51<00:12, 149.45it/s]Running 10000 simulations.:  81%|████████▏ | 8132/10000 [00:52<00:12, 148.88it/s]Running 10000 simulations.:  81%|████████▏ | 8148/10000 [00:52<00:12, 151.62it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:52<00:11, 154.23it/s]Running 10000 simulations.:  82%|████████▏ | 8182/10000 [00:52<00:11, 156.30it/s]Running 10000 simulations.:  82%|████████▏ | 8199/10000 [00:52<00:11, 157.64it/s]Running 10000 simulations.:  82%|████████▏ | 8216/10000 [00:52<00:11, 158.56it/s]Running 10000 simulations.:  82%|████████▏ | 8232/10000 [00:52<00:11, 154.28it/s]Running 10000 simulations.:  82%|████████▏ | 8248/10000 [00:52<00:11, 152.88it/s]Running 10000 simulations.:  83%|████████▎ | 8264/10000 [00:52<00:11, 149.98it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:53<00:11, 148.04it/s]Running 10000 simulations.:  83%|████████▎ | 8295/10000 [00:53<00:11, 146.66it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:53<00:12, 140.61it/s]Running 10000 simulations.:  83%|████████▎ | 8325/10000 [00:53<00:11, 142.44it/s]Running 10000 simulations.:  83%|████████▎ | 8341/10000 [00:53<00:11, 146.08it/s]Running 10000 simulations.:  84%|████████▎ | 8357/10000 [00:53<00:10, 149.80it/s]Running 10000 simulations.:  84%|████████▎ | 8374/10000 [00:53<00:10, 152.88it/s]Running 10000 simulations.:  84%|████████▍ | 8391/10000 [00:53<00:10, 155.45it/s]Running 10000 simulations.:  84%|████████▍ | 8408/10000 [00:53<00:10, 157.26it/s]Running 10000 simulations.:  84%|████████▍ | 8424/10000 [00:54<00:10, 155.43it/s]Running 10000 simulations.:  84%|████████▍ | 8440/10000 [00:54<00:10, 154.27it/s]Running 10000 simulations.:  85%|████████▍ | 8456/10000 [00:54<00:10, 153.52it/s]Running 10000 simulations.:  85%|████████▍ | 8472/10000 [00:54<00:10, 152.33it/s]Running 10000 simulations.:  85%|████████▍ | 8488/10000 [00:54<00:09, 152.07it/s]Running 10000 simulations.:  85%|████████▌ | 8504/10000 [00:54<00:09, 152.10it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:54<00:09, 151.62it/s]Running 10000 simulations.:  85%|████████▌ | 8536/10000 [00:54<00:09, 153.30it/s]Running 10000 simulations.:  86%|████████▌ | 8552/10000 [00:54<00:09, 154.71it/s]Running 10000 simulations.:  86%|████████▌ | 8568/10000 [00:54<00:09, 155.76it/s]Running 10000 simulations.:  86%|████████▌ | 8584/10000 [00:55<00:09, 156.85it/s]Running 10000 simulations.:  86%|████████▌ | 8600/10000 [00:55<00:08, 157.00it/s]Running 10000 simulations.:  86%|████████▌ | 8616/10000 [00:55<00:08, 155.42it/s]Running 10000 simulations.:  86%|████████▋ | 8632/10000 [00:55<00:08, 154.42it/s]Running 10000 simulations.:  86%|████████▋ | 8648/10000 [00:55<00:08, 153.58it/s]Running 10000 simulations.:  87%|████████▋ | 8664/10000 [00:55<00:08, 152.57it/s]Running 10000 simulations.:  87%|████████▋ | 8680/10000 [00:55<00:08, 153.02it/s]Running 10000 simulations.:  87%|████████▋ | 8696/10000 [00:55<00:08, 153.24it/s]Running 10000 simulations.:  87%|████████▋ | 8712/10000 [00:55<00:08, 153.13it/s]Running 10000 simulations.:  87%|████████▋ | 8728/10000 [00:55<00:08, 154.55it/s]Running 10000 simulations.:  87%|████████▋ | 8744/10000 [00:56<00:08, 155.70it/s]Running 10000 simulations.:  88%|████████▊ | 8760/10000 [00:56<00:07, 156.79it/s]Running 10000 simulations.:  88%|████████▊ | 8777/10000 [00:56<00:07, 158.44it/s]Running 10000 simulations.:  88%|████████▊ | 8793/10000 [00:56<00:07, 158.34it/s]Running 10000 simulations.:  88%|████████▊ | 8809/10000 [00:56<00:07, 156.32it/s]Running 10000 simulations.:  88%|████████▊ | 8825/10000 [00:56<00:07, 154.93it/s]Running 10000 simulations.:  88%|████████▊ | 8841/10000 [00:56<00:07, 153.95it/s]Running 10000 simulations.:  89%|████████▊ | 8857/10000 [00:56<00:07, 153.31it/s]Running 10000 simulations.:  89%|████████▊ | 8873/10000 [00:56<00:07, 153.71it/s]Running 10000 simulations.:  89%|████████▉ | 8889/10000 [00:57<00:07, 153.43it/s]Running 10000 simulations.:  89%|████████▉ | 8905/10000 [00:57<00:07, 153.58it/s]Running 10000 simulations.:  89%|████████▉ | 8921/10000 [00:57<00:06, 155.08it/s]Running 10000 simulations.:  89%|████████▉ | 8937/10000 [00:57<00:06, 155.96it/s]Running 10000 simulations.:  90%|████████▉ | 8954/10000 [00:57<00:06, 157.24it/s]Running 10000 simulations.:  90%|████████▉ | 8970/10000 [00:57<00:06, 157.84it/s]Running 10000 simulations.:  90%|████████▉ | 8986/10000 [00:57<00:06, 157.32it/s]Running 10000 simulations.:  90%|█████████ | 9002/10000 [00:57<00:06, 155.90it/s]Running 10000 simulations.:  90%|█████████ | 9018/10000 [00:57<00:06, 154.75it/s]Running 10000 simulations.:  90%|█████████ | 9034/10000 [00:57<00:06, 154.28it/s]Running 10000 simulations.:  90%|█████████ | 9050/10000 [00:58<00:06, 153.36it/s]Running 10000 simulations.:  91%|█████████ | 9066/10000 [00:58<00:06, 154.23it/s]Running 10000 simulations.:  91%|█████████ | 9082/10000 [00:58<00:05, 154.56it/s]Running 10000 simulations.:  91%|█████████ | 9098/10000 [00:58<00:05, 155.02it/s]Running 10000 simulations.:  91%|█████████ | 9115/10000 [00:58<00:05, 156.80it/s]Running 10000 simulations.:  91%|█████████▏| 9131/10000 [00:58<00:05, 157.71it/s]Running 10000 simulations.:  91%|█████████▏| 9147/10000 [00:58<00:05, 158.25it/s]Running 10000 simulations.:  92%|█████████▏| 9164/10000 [00:58<00:05, 159.01it/s]Running 10000 simulations.:  92%|█████████▏| 9180/10000 [00:58<00:05, 157.92it/s]Running 10000 simulations.:  92%|█████████▏| 9196/10000 [00:58<00:05, 156.03it/s]Running 10000 simulations.:  92%|█████████▏| 9212/10000 [00:59<00:05, 154.87it/s]Running 10000 simulations.:  92%|█████████▏| 9228/10000 [00:59<00:04, 154.45it/s]Running 10000 simulations.:  92%|█████████▏| 9244/10000 [00:59<00:04, 154.26it/s]Running 10000 simulations.:  93%|█████████▎| 9260/10000 [00:59<00:04, 154.05it/s]Running 10000 simulations.:  93%|█████████▎| 9276/10000 [00:59<00:04, 154.37it/s]Running 10000 simulations.:  93%|█████████▎| 9292/10000 [00:59<00:04, 155.58it/s]Running 10000 simulations.:  93%|█████████▎| 9308/10000 [00:59<00:04, 156.55it/s]Running 10000 simulations.:  93%|█████████▎| 9324/10000 [00:59<00:04, 157.32it/s]Running 10000 simulations.:  93%|█████████▎| 9341/10000 [00:59<00:04, 158.35it/s]Running 10000 simulations.:  94%|█████████▎| 9358/10000 [01:00<00:04, 160.09it/s]Running 10000 simulations.:  94%|█████████▍| 9375/10000 [01:00<00:03, 158.94it/s]Running 10000 simulations.:  94%|█████████▍| 9391/10000 [01:00<00:03, 156.99it/s]Running 10000 simulations.:  94%|█████████▍| 9407/10000 [01:00<00:03, 155.54it/s]Running 10000 simulations.:  94%|█████████▍| 9423/10000 [01:00<00:03, 154.72it/s]Running 10000 simulations.:  94%|█████████▍| 9439/10000 [01:00<00:03, 153.70it/s]Running 10000 simulations.:  95%|█████████▍| 9455/10000 [01:00<00:03, 153.44it/s]Running 10000 simulations.:  95%|█████████▍| 9473/10000 [01:00<00:03, 158.54it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [01:00<00:03, 159.82it/s]Running 10000 simulations.:  95%|█████████▌| 9507/10000 [01:00<00:03, 159.43it/s]Running 10000 simulations.:  95%|█████████▌| 9523/10000 [01:01<00:03, 158.82it/s]Running 10000 simulations.:  95%|█████████▌| 9539/10000 [01:01<00:02, 157.93it/s]Running 10000 simulations.:  96%|█████████▌| 9555/10000 [01:01<00:02, 158.18it/s]Running 10000 simulations.:  96%|█████████▌| 9572/10000 [01:01<00:02, 159.48it/s]Running 10000 simulations.:  96%|█████████▌| 9588/10000 [01:01<00:02, 158.76it/s]Running 10000 simulations.:  96%|█████████▌| 9604/10000 [01:01<00:02, 156.87it/s]Running 10000 simulations.:  96%|█████████▌| 9620/10000 [01:01<00:02, 155.55it/s]Running 10000 simulations.:  96%|█████████▋| 9636/10000 [01:01<00:02, 154.96it/s]Running 10000 simulations.:  97%|█████████▋| 9652/10000 [01:01<00:02, 154.26it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [01:01<00:02, 154.11it/s]Running 10000 simulations.:  97%|█████████▋| 9684/10000 [01:02<00:02, 154.40it/s]Running 10000 simulations.:  97%|█████████▋| 9700/10000 [01:02<00:01, 154.60it/s]Running 10000 simulations.:  97%|█████████▋| 9717/10000 [01:02<00:01, 156.60it/s]Running 10000 simulations.:  97%|█████████▋| 9734/10000 [01:02<00:01, 157.88it/s]Running 10000 simulations.:  98%|█████████▊| 9751/10000 [01:02<00:01, 159.21it/s]Running 10000 simulations.:  98%|█████████▊| 9768/10000 [01:02<00:01, 160.39it/s]Running 10000 simulations.:  98%|█████████▊| 9785/10000 [01:02<00:01, 159.61it/s]Running 10000 simulations.:  98%|█████████▊| 9801/10000 [01:02<00:01, 157.82it/s]Running 10000 simulations.:  98%|█████████▊| 9817/10000 [01:02<00:01, 157.42it/s]Running 10000 simulations.:  98%|█████████▊| 9833/10000 [01:03<00:01, 157.07it/s]Running 10000 simulations.:  98%|█████████▊| 9849/10000 [01:03<00:00, 156.34it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [01:03<00:00, 156.33it/s]Running 10000 simulations.:  99%|█████████▉| 9881/10000 [01:03<00:00, 156.42it/s]Running 10000 simulations.:  99%|█████████▉| 9897/10000 [01:03<00:00, 156.26it/s]Running 10000 simulations.:  99%|█████████▉| 9914/10000 [01:03<00:00, 157.65it/s]Running 10000 simulations.:  99%|█████████▉| 9931/10000 [01:03<00:00, 158.79it/s]Running 10000 simulations.:  99%|█████████▉| 9947/10000 [01:03<00:00, 159.10it/s]Running 10000 simulations.: 100%|█████████▉| 9964/10000 [01:03<00:00, 159.74it/s]Running 10000 simulations.: 100%|█████████▉| 9980/10000 [01:03<00:00, 159.71it/s]Running 10000 simulations.: 100%|█████████▉| 9996/10000 [01:04<00:00, 158.39it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:04<00:00, 156.01it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 18/10000 [00:00<00:58, 170.11it/s]Running 10000 simulations.:   0%|          | 36/10000 [00:00<00:58, 170.70it/s]Running 10000 simulations.:   1%|          | 53/10000 [00:00<00:58, 170.49it/s]Running 10000 simulations.:   1%|          | 71/10000 [00:00<00:58, 170.40it/s]Running 10000 simulations.:   1%|          | 89/10000 [00:00<00:58, 170.64it/s]Running 10000 simulations.:   1%|          | 106/10000 [00:00<00:58, 170.44it/s]Running 10000 simulations.:   1%|          | 123/10000 [00:00<00:58, 170.07it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:58, 169.97it/s]Running 10000 simulations.:   2%|▏         | 158/10000 [00:00<00:57, 170.50it/s]Running 10000 simulations.:   2%|▏         | 176/10000 [00:01<00:57, 170.43it/s]Running 10000 simulations.:   2%|▏         | 193/10000 [00:01<00:57, 169.73it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:01<00:57, 169.63it/s]Running 10000 simulations.:   2%|▏         | 227/10000 [00:01<00:57, 169.69it/s]Running 10000 simulations.:   2%|▏         | 244/10000 [00:01<00:57, 169.59it/s]Running 10000 simulations.:   3%|▎         | 261/10000 [00:01<00:57, 169.22it/s]Running 10000 simulations.:   3%|▎         | 278/10000 [00:01<00:57, 168.65it/s]Running 10000 simulations.:   3%|▎         | 296/10000 [00:01<00:57, 169.36it/s]Running 10000 simulations.:   3%|▎         | 314/10000 [00:01<00:56, 170.26it/s]Running 10000 simulations.:   3%|▎         | 332/10000 [00:01<00:56, 170.82it/s]Running 10000 simulations.:   4%|▎         | 350/10000 [00:02<00:56, 171.13it/s]Running 10000 simulations.:   4%|▎         | 368/10000 [00:02<00:56, 171.13it/s]Running 10000 simulations.:   4%|▍         | 386/10000 [00:02<00:56, 170.49it/s]Running 10000 simulations.:   4%|▍         | 404/10000 [00:02<00:56, 170.54it/s]Running 10000 simulations.:   4%|▍         | 422/10000 [00:02<00:55, 171.20it/s]Running 10000 simulations.:   4%|▍         | 440/10000 [00:02<00:55, 171.32it/s]Running 10000 simulations.:   5%|▍         | 458/10000 [00:02<00:55, 171.21it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:02<00:55, 171.41it/s]Running 10000 simulations.:   5%|▍         | 494/10000 [00:02<00:55, 171.84it/s]Running 10000 simulations.:   5%|▌         | 512/10000 [00:03<00:55, 171.67it/s]Running 10000 simulations.:   5%|▌         | 530/10000 [00:03<00:55, 171.78it/s]Running 10000 simulations.:   5%|▌         | 548/10000 [00:03<00:54, 172.04it/s]Running 10000 simulations.:   6%|▌         | 566/10000 [00:03<00:54, 171.94it/s]Running 10000 simulations.:   6%|▌         | 584/10000 [00:03<00:54, 171.61it/s]Running 10000 simulations.:   6%|▌         | 602/10000 [00:03<00:54, 171.04it/s]Running 10000 simulations.:   6%|▌         | 620/10000 [00:03<00:55, 170.47it/s]Running 10000 simulations.:   6%|▋         | 638/10000 [00:03<00:54, 170.62it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:03<00:54, 171.21it/s]Running 10000 simulations.:   7%|▋         | 674/10000 [00:03<00:54, 170.75it/s]Running 10000 simulations.:   7%|▋         | 692/10000 [00:04<00:54, 170.50it/s]Running 10000 simulations.:   7%|▋         | 710/10000 [00:04<00:54, 170.88it/s]Running 10000 simulations.:   7%|▋         | 728/10000 [00:04<00:54, 171.00it/s]Running 10000 simulations.:   7%|▋         | 746/10000 [00:04<00:53, 171.45it/s]Running 10000 simulations.:   8%|▊         | 764/10000 [00:04<00:53, 171.06it/s]Running 10000 simulations.:   8%|▊         | 782/10000 [00:04<00:53, 171.11it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:04<00:53, 171.22it/s]Running 10000 simulations.:   8%|▊         | 818/10000 [00:04<00:53, 171.15it/s]Running 10000 simulations.:   8%|▊         | 836/10000 [00:04<00:53, 170.25it/s]Running 10000 simulations.:   9%|▊         | 854/10000 [00:05<00:53, 170.19it/s]Running 10000 simulations.:   9%|▊         | 872/10000 [00:05<00:53, 170.12it/s]Running 10000 simulations.:   9%|▉         | 890/10000 [00:05<00:53, 170.36it/s]Running 10000 simulations.:   9%|▉         | 908/10000 [00:05<00:53, 170.29it/s]Running 10000 simulations.:   9%|▉         | 926/10000 [00:05<00:53, 170.11it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:05<00:53, 170.03it/s]Running 10000 simulations.:  10%|▉         | 962/10000 [00:05<00:53, 169.93it/s]Running 10000 simulations.:  10%|▉         | 980/10000 [00:05<00:52, 170.66it/s]Running 10000 simulations.:  10%|▉         | 998/10000 [00:05<00:52, 170.60it/s]Running 10000 simulations.:  10%|█         | 1016/10000 [00:05<00:52, 170.85it/s]Running 10000 simulations.:  10%|█         | 1034/10000 [00:06<00:52, 170.74it/s]Running 10000 simulations.:  11%|█         | 1052/10000 [00:06<00:52, 171.13it/s]Running 10000 simulations.:  11%|█         | 1070/10000 [00:06<01:22, 107.96it/s]Running 10000 simulations.:  11%|█         | 1088/10000 [00:06<01:13, 121.30it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:06<01:06, 132.87it/s]Running 10000 simulations.:  11%|█         | 1124/10000 [00:06<01:02, 142.18it/s]Running 10000 simulations.:  11%|█▏        | 1142/10000 [00:06<00:59, 150.01it/s]Running 10000 simulations.:  12%|█▏        | 1160/10000 [00:06<00:56, 156.01it/s]Running 10000 simulations.:  12%|█▏        | 1178/10000 [00:07<00:55, 160.14it/s]Running 10000 simulations.:  12%|█▏        | 1196/10000 [00:07<00:53, 163.24it/s]Running 10000 simulations.:  12%|█▏        | 1214/10000 [00:07<00:53, 165.30it/s]Running 10000 simulations.:  12%|█▏        | 1231/10000 [00:07<00:52, 166.66it/s]Running 10000 simulations.:  12%|█▏        | 1249/10000 [00:07<00:52, 167.78it/s]Running 10000 simulations.:  13%|█▎        | 1267/10000 [00:07<00:51, 169.11it/s]Running 10000 simulations.:  13%|█▎        | 1285/10000 [00:07<00:51, 169.36it/s]Running 10000 simulations.:  13%|█▎        | 1303/10000 [00:07<00:51, 170.05it/s]Running 10000 simulations.:  13%|█▎        | 1321/10000 [00:07<00:50, 170.82it/s]Running 10000 simulations.:  13%|█▎        | 1339/10000 [00:08<00:50, 171.15it/s]Running 10000 simulations.:  14%|█▎        | 1357/10000 [00:08<00:50, 171.54it/s]Running 10000 simulations.:  14%|█▍        | 1375/10000 [00:08<00:50, 171.82it/s]Running 10000 simulations.:  14%|█▍        | 1393/10000 [00:08<00:50, 171.82it/s]Running 10000 simulations.:  14%|█▍        | 1411/10000 [00:08<00:50, 171.49it/s]Running 10000 simulations.:  14%|█▍        | 1429/10000 [00:08<00:49, 171.98it/s]Running 10000 simulations.:  14%|█▍        | 1450/10000 [00:08<00:47, 179.59it/s]Running 10000 simulations.:  15%|█▍        | 1469/10000 [00:08<00:46, 182.25it/s]Running 10000 simulations.:  15%|█▍        | 1488/10000 [00:08<00:47, 178.14it/s]Running 10000 simulations.:  15%|█▌        | 1506/10000 [00:08<00:48, 175.44it/s]Running 10000 simulations.:  15%|█▌        | 1524/10000 [00:09<00:48, 174.51it/s]Running 10000 simulations.:  15%|█▌        | 1542/10000 [00:09<00:48, 173.53it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:09<00:48, 172.42it/s]Running 10000 simulations.:  16%|█▌        | 1578/10000 [00:09<00:49, 171.69it/s]Running 10000 simulations.:  16%|█▌        | 1596/10000 [00:09<00:49, 171.24it/s]Running 10000 simulations.:  16%|█▌        | 1614/10000 [00:09<00:49, 171.09it/s]Running 10000 simulations.:  16%|█▋        | 1632/10000 [00:09<00:49, 170.72it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:09<00:49, 170.22it/s]Running 10000 simulations.:  17%|█▋        | 1668/10000 [00:09<00:48, 170.49it/s]Running 10000 simulations.:  17%|█▋        | 1686/10000 [00:10<00:48, 170.21it/s]Running 10000 simulations.:  17%|█▋        | 1704/10000 [00:10<00:48, 170.44it/s]Running 10000 simulations.:  17%|█▋        | 1722/10000 [00:10<00:48, 170.33it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:10<00:48, 170.29it/s]Running 10000 simulations.:  18%|█▊        | 1758/10000 [00:10<00:48, 170.06it/s]Running 10000 simulations.:  18%|█▊        | 1776/10000 [00:10<00:48, 170.09it/s]Running 10000 simulations.:  18%|█▊        | 1794/10000 [00:10<00:48, 170.04it/s]Running 10000 simulations.:  18%|█▊        | 1812/10000 [00:10<00:48, 169.93it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:10<00:48, 169.74it/s]Running 10000 simulations.:  18%|█▊        | 1847/10000 [00:10<00:47, 170.00it/s]Running 10000 simulations.:  19%|█▊        | 1865/10000 [00:11<00:47, 170.15it/s]Running 10000 simulations.:  19%|█▉        | 1883/10000 [00:11<00:47, 169.26it/s]Running 10000 simulations.:  19%|█▉        | 1900/10000 [00:11<00:47, 169.03it/s]Running 10000 simulations.:  19%|█▉        | 1917/10000 [00:11<00:47, 168.88it/s]Running 10000 simulations.:  19%|█▉        | 1934/10000 [00:11<00:47, 168.79it/s]Running 10000 simulations.:  20%|█▉        | 1952/10000 [00:11<00:47, 169.20it/s]Running 10000 simulations.:  20%|█▉        | 1969/10000 [00:11<00:47, 168.37it/s]Running 10000 simulations.:  20%|█▉        | 1986/10000 [00:11<00:47, 168.02it/s]Running 10000 simulations.:  20%|██        | 2003/10000 [00:11<00:47, 168.14it/s]Running 10000 simulations.:  20%|██        | 2020/10000 [00:12<00:47, 168.09it/s]Running 10000 simulations.:  20%|██        | 2037/10000 [00:12<00:47, 167.68it/s]Running 10000 simulations.:  21%|██        | 2054/10000 [00:12<00:47, 168.01it/s]Running 10000 simulations.:  21%|██        | 2071/10000 [00:12<00:47, 167.61it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:12<00:47, 168.10it/s]Running 10000 simulations.:  21%|██        | 2105/10000 [00:12<00:46, 168.58it/s]Running 10000 simulations.:  21%|██        | 2122/10000 [00:12<00:46, 168.33it/s]Running 10000 simulations.:  21%|██▏       | 2139/10000 [00:12<00:46, 168.06it/s]Running 10000 simulations.:  22%|██▏       | 2156/10000 [00:12<00:46, 168.29it/s]Running 10000 simulations.:  22%|██▏       | 2173/10000 [00:12<00:46, 168.56it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:13<00:46, 168.91it/s]Running 10000 simulations.:  22%|██▏       | 2207/10000 [00:13<00:46, 168.75it/s]Running 10000 simulations.:  22%|██▏       | 2224/10000 [00:13<00:46, 168.45it/s]Running 10000 simulations.:  22%|██▏       | 2241/10000 [00:13<00:46, 167.83it/s]Running 10000 simulations.:  23%|██▎       | 2258/10000 [00:13<00:46, 167.71it/s]Running 10000 simulations.:  23%|██▎       | 2275/10000 [00:13<00:46, 167.93it/s]Running 10000 simulations.:  23%|██▎       | 2292/10000 [00:13<00:46, 167.07it/s]Running 10000 simulations.:  23%|██▎       | 2309/10000 [00:13<00:46, 167.06it/s]Running 10000 simulations.:  23%|██▎       | 2326/10000 [00:13<00:45, 167.68it/s]Running 10000 simulations.:  23%|██▎       | 2343/10000 [00:13<00:45, 167.17it/s]Running 10000 simulations.:  24%|██▎       | 2360/10000 [00:14<00:45, 167.03it/s]Running 10000 simulations.:  24%|██▍       | 2377/10000 [00:14<00:45, 167.35it/s]Running 10000 simulations.:  24%|██▍       | 2394/10000 [00:14<00:45, 167.43it/s]Running 10000 simulations.:  24%|██▍       | 2411/10000 [00:14<00:45, 167.46it/s]Running 10000 simulations.:  24%|██▍       | 2428/10000 [00:14<00:45, 167.06it/s]Running 10000 simulations.:  24%|██▍       | 2445/10000 [00:14<00:45, 166.95it/s]Running 10000 simulations.:  25%|██▍       | 2462/10000 [00:14<00:45, 167.26it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:14<00:44, 167.15it/s]Running 10000 simulations.:  25%|██▍       | 2496/10000 [00:14<00:44, 167.03it/s]Running 10000 simulations.:  25%|██▌       | 2513/10000 [00:14<00:44, 166.96it/s]Running 10000 simulations.:  25%|██▌       | 2530/10000 [00:15<00:44, 167.04it/s]Running 10000 simulations.:  25%|██▌       | 2547/10000 [00:15<00:44, 167.00it/s]Running 10000 simulations.:  26%|██▌       | 2564/10000 [00:15<00:44, 166.92it/s]Running 10000 simulations.:  26%|██▌       | 2581/10000 [00:15<00:44, 167.27it/s]Running 10000 simulations.:  26%|██▌       | 2598/10000 [00:15<00:44, 167.54it/s]Running 10000 simulations.:  26%|██▌       | 2615/10000 [00:15<00:44, 167.32it/s]Running 10000 simulations.:  26%|██▋       | 2632/10000 [00:15<00:43, 167.60it/s]Running 10000 simulations.:  26%|██▋       | 2649/10000 [00:15<00:43, 168.04it/s]Running 10000 simulations.:  27%|██▋       | 2666/10000 [00:15<00:43, 167.62it/s]Running 10000 simulations.:  27%|██▋       | 2683/10000 [00:15<00:43, 167.64it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:16<00:43, 167.73it/s]Running 10000 simulations.:  27%|██▋       | 2717/10000 [00:16<00:43, 167.86it/s]Running 10000 simulations.:  27%|██▋       | 2734/10000 [00:16<00:43, 167.73it/s]Running 10000 simulations.:  28%|██▊       | 2751/10000 [00:16<00:43, 167.69it/s]Running 10000 simulations.:  28%|██▊       | 2768/10000 [00:16<00:43, 167.36it/s]Running 10000 simulations.:  28%|██▊       | 2785/10000 [00:16<00:43, 167.28it/s]Running 10000 simulations.:  28%|██▊       | 2802/10000 [00:16<00:43, 167.26it/s]Running 10000 simulations.:  28%|██▊       | 2819/10000 [00:16<00:42, 167.45it/s]Running 10000 simulations.:  28%|██▊       | 2836/10000 [00:16<00:42, 167.32it/s]Running 10000 simulations.:  29%|██▊       | 2853/10000 [00:16<00:42, 166.93it/s]Running 10000 simulations.:  29%|██▊       | 2870/10000 [00:17<00:42, 166.97it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:17<00:42, 167.11it/s]Running 10000 simulations.:  29%|██▉       | 2904/10000 [00:17<00:42, 167.12it/s]Running 10000 simulations.:  29%|██▉       | 2921/10000 [00:17<00:42, 167.21it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:17<00:42, 167.17it/s]Running 10000 simulations.:  30%|██▉       | 2955/10000 [00:17<00:42, 167.62it/s]Running 10000 simulations.:  30%|██▉       | 2972/10000 [00:17<00:41, 167.44it/s]Running 10000 simulations.:  30%|██▉       | 2989/10000 [00:17<00:41, 167.50it/s]Running 10000 simulations.:  30%|███       | 3006/10000 [00:17<00:41, 167.53it/s]Running 10000 simulations.:  30%|███       | 3023/10000 [00:18<00:41, 167.19it/s]Running 10000 simulations.:  30%|███       | 3040/10000 [00:18<00:41, 167.40it/s]Running 10000 simulations.:  31%|███       | 3057/10000 [00:18<00:41, 168.01it/s]Running 10000 simulations.:  31%|███       | 3074/10000 [00:18<00:41, 167.78it/s]Running 10000 simulations.:  31%|███       | 3092/10000 [00:18<00:41, 168.41it/s]Running 10000 simulations.:  31%|███       | 3109/10000 [00:18<00:41, 167.68it/s]Running 10000 simulations.:  31%|███▏      | 3127/10000 [00:18<00:40, 168.59it/s]Running 10000 simulations.:  31%|███▏      | 3144/10000 [00:18<00:40, 168.24it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:18<00:40, 168.39it/s]Running 10000 simulations.:  32%|███▏      | 3178/10000 [00:18<00:40, 168.29it/s]Running 10000 simulations.:  32%|███▏      | 3195/10000 [00:19<00:40, 168.36it/s]Running 10000 simulations.:  32%|███▏      | 3212/10000 [00:19<00:40, 168.17it/s]Running 10000 simulations.:  32%|███▏      | 3229/10000 [00:19<00:40, 167.73it/s]Running 10000 simulations.:  32%|███▏      | 3246/10000 [00:19<00:40, 167.90it/s]Running 10000 simulations.:  33%|███▎      | 3265/10000 [00:19<00:39, 171.54it/s]Running 10000 simulations.:  33%|███▎      | 3283/10000 [00:19<00:38, 172.87it/s]Running 10000 simulations.:  33%|███▎      | 3301/10000 [00:19<00:39, 171.18it/s]Running 10000 simulations.:  33%|███▎      | 3319/10000 [00:19<00:39, 170.05it/s]Running 10000 simulations.:  33%|███▎      | 3337/10000 [00:19<00:39, 169.52it/s]Running 10000 simulations.:  34%|███▎      | 3354/10000 [00:19<00:39, 168.59it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:20<00:39, 168.36it/s]Running 10000 simulations.:  34%|███▍      | 3388/10000 [00:20<00:39, 168.37it/s]Running 10000 simulations.:  34%|███▍      | 3405/10000 [00:20<00:39, 168.59it/s]Running 10000 simulations.:  34%|███▍      | 3422/10000 [00:20<00:39, 168.38it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:20<00:39, 168.11it/s]Running 10000 simulations.:  35%|███▍      | 3456/10000 [00:20<00:39, 167.46it/s]Running 10000 simulations.:  35%|███▍      | 3473/10000 [00:20<00:39, 167.20it/s]Running 10000 simulations.:  35%|███▍      | 3490/10000 [00:20<00:38, 167.36it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:20<00:38, 167.78it/s]Running 10000 simulations.:  35%|███▌      | 3524/10000 [00:20<00:38, 167.48it/s]Running 10000 simulations.:  35%|███▌      | 3541/10000 [00:21<00:38, 167.48it/s]Running 10000 simulations.:  36%|███▌      | 3558/10000 [00:21<00:38, 167.54it/s]Running 10000 simulations.:  36%|███▌      | 3575/10000 [00:21<00:38, 167.60it/s]Running 10000 simulations.:  36%|███▌      | 3592/10000 [00:21<00:38, 167.50it/s]Running 10000 simulations.:  36%|███▌      | 3609/10000 [00:21<00:38, 167.01it/s]Running 10000 simulations.:  36%|███▋      | 3626/10000 [00:21<00:38, 167.09it/s]Running 10000 simulations.:  36%|███▋      | 3643/10000 [00:21<00:37, 167.70it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:21<00:37, 167.28it/s]Running 10000 simulations.:  37%|███▋      | 3677/10000 [00:21<00:37, 166.96it/s]Running 10000 simulations.:  37%|███▋      | 3694/10000 [00:21<00:37, 167.05it/s]Running 10000 simulations.:  37%|███▋      | 3711/10000 [00:22<00:37, 167.03it/s]Running 10000 simulations.:  37%|███▋      | 3728/10000 [00:22<00:37, 167.13it/s]Running 10000 simulations.:  37%|███▋      | 3745/10000 [00:22<00:37, 167.09it/s]Running 10000 simulations.:  38%|███▊      | 3762/10000 [00:22<00:37, 167.00it/s]Running 10000 simulations.:  38%|███▊      | 3779/10000 [00:22<00:37, 166.29it/s]Running 10000 simulations.:  38%|███▊      | 3796/10000 [00:22<00:38, 159.64it/s]Running 10000 simulations.:  38%|███▊      | 3813/10000 [00:22<00:38, 161.38it/s]Running 10000 simulations.:  38%|███▊      | 3830/10000 [00:22<00:37, 162.72it/s]Running 10000 simulations.:  38%|███▊      | 3847/10000 [00:22<00:37, 163.62it/s]Running 10000 simulations.:  39%|███▊      | 3864/10000 [00:23<00:37, 164.46it/s]Running 10000 simulations.:  39%|███▉      | 3881/10000 [00:23<00:37, 165.34it/s]Running 10000 simulations.:  39%|███▉      | 3898/10000 [00:23<00:36, 165.42it/s]Running 10000 simulations.:  39%|███▉      | 3915/10000 [00:23<00:36, 165.52it/s]Running 10000 simulations.:  39%|███▉      | 3932/10000 [00:23<00:36, 165.83it/s]Running 10000 simulations.:  39%|███▉      | 3949/10000 [00:23<00:36, 166.56it/s]Running 10000 simulations.:  40%|███▉      | 3966/10000 [00:23<00:36, 166.91it/s]Running 10000 simulations.:  40%|███▉      | 3983/10000 [00:23<00:36, 166.92it/s]Running 10000 simulations.:  40%|████      | 4000/10000 [00:23<00:35, 167.07it/s]Running 10000 simulations.:  40%|████      | 4017/10000 [00:23<00:35, 166.87it/s]Running 10000 simulations.:  40%|████      | 4034/10000 [00:24<00:35, 167.22it/s]Running 10000 simulations.:  41%|████      | 4051/10000 [00:24<00:35, 167.08it/s]Running 10000 simulations.:  41%|████      | 4068/10000 [00:24<00:35, 167.03it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:24<00:35, 167.38it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:24<00:35, 167.41it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:24<00:35, 167.08it/s]Running 10000 simulations.:  41%|████▏     | 4136/10000 [00:24<00:35, 167.16it/s]Running 10000 simulations.:  42%|████▏     | 4153/10000 [00:24<00:34, 167.21it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:24<00:34, 167.04it/s]Running 10000 simulations.:  42%|████▏     | 4187/10000 [00:24<00:34, 167.18it/s]Running 10000 simulations.:  42%|████▏     | 4204/10000 [00:25<00:34, 166.91it/s]Running 10000 simulations.:  42%|████▏     | 4221/10000 [00:25<00:34, 166.71it/s]Running 10000 simulations.:  42%|████▏     | 4238/10000 [00:25<00:34, 166.67it/s]Running 10000 simulations.:  43%|████▎     | 4255/10000 [00:25<00:34, 166.84it/s]Running 10000 simulations.:  43%|████▎     | 4272/10000 [00:25<00:34, 167.37it/s]Running 10000 simulations.:  43%|████▎     | 4289/10000 [00:25<00:34, 167.52it/s]Running 10000 simulations.:  43%|████▎     | 4306/10000 [00:25<00:33, 167.90it/s]Running 10000 simulations.:  43%|████▎     | 4323/10000 [00:25<00:33, 167.66it/s]Running 10000 simulations.:  43%|████▎     | 4340/10000 [00:25<00:33, 167.80it/s]Running 10000 simulations.:  44%|████▎     | 4357/10000 [00:25<00:33, 167.63it/s]Running 10000 simulations.:  44%|████▎     | 4374/10000 [00:26<00:33, 167.73it/s]Running 10000 simulations.:  44%|████▍     | 4391/10000 [00:26<00:33, 167.47it/s]Running 10000 simulations.:  44%|████▍     | 4408/10000 [00:26<00:33, 167.00it/s]Running 10000 simulations.:  44%|████▍     | 4425/10000 [00:26<00:33, 166.64it/s]Running 10000 simulations.:  44%|████▍     | 4442/10000 [00:26<00:33, 167.09it/s]Running 10000 simulations.:  45%|████▍     | 4459/10000 [00:26<00:33, 166.91it/s]Running 10000 simulations.:  45%|████▍     | 4476/10000 [00:26<00:33, 166.92it/s]Running 10000 simulations.:  45%|████▍     | 4493/10000 [00:26<00:32, 167.18it/s]Running 10000 simulations.:  45%|████▌     | 4510/10000 [00:26<00:32, 166.66it/s]Running 10000 simulations.:  45%|████▌     | 4527/10000 [00:27<00:32, 166.79it/s]Running 10000 simulations.:  45%|████▌     | 4544/10000 [00:27<00:32, 166.58it/s]Running 10000 simulations.:  46%|████▌     | 4561/10000 [00:27<00:32, 166.51it/s]Running 10000 simulations.:  46%|████▌     | 4578/10000 [00:27<00:32, 165.99it/s]Running 10000 simulations.:  46%|████▌     | 4595/10000 [00:27<00:32, 166.02it/s]Running 10000 simulations.:  46%|████▌     | 4612/10000 [00:27<00:32, 166.03it/s]Running 10000 simulations.:  46%|████▋     | 4629/10000 [00:27<00:32, 166.13it/s]Running 10000 simulations.:  46%|████▋     | 4646/10000 [00:27<00:32, 165.92it/s]Running 10000 simulations.:  47%|████▋     | 4663/10000 [00:27<00:32, 166.48it/s]Running 10000 simulations.:  47%|████▋     | 4680/10000 [00:27<00:31, 166.37it/s]Running 10000 simulations.:  47%|████▋     | 4697/10000 [00:28<00:31, 166.52it/s]Running 10000 simulations.:  47%|████▋     | 4714/10000 [00:28<00:31, 166.92it/s]Running 10000 simulations.:  47%|████▋     | 4731/10000 [00:28<00:31, 167.04it/s]Running 10000 simulations.:  47%|████▋     | 4748/10000 [00:28<00:31, 167.12it/s]Running 10000 simulations.:  48%|████▊     | 4765/10000 [00:28<00:31, 167.21it/s]Running 10000 simulations.:  48%|████▊     | 4782/10000 [00:28<00:31, 166.78it/s]Running 10000 simulations.:  48%|████▊     | 4799/10000 [00:28<00:31, 166.64it/s]Running 10000 simulations.:  48%|████▊     | 4816/10000 [00:28<00:31, 166.71it/s]Running 10000 simulations.:  48%|████▊     | 4833/10000 [00:28<00:31, 166.68it/s]Running 10000 simulations.:  48%|████▊     | 4850/10000 [00:28<00:30, 166.55it/s]Running 10000 simulations.:  49%|████▊     | 4867/10000 [00:29<00:30, 166.71it/s]Running 10000 simulations.:  49%|████▉     | 4884/10000 [00:29<00:30, 166.72it/s]Running 10000 simulations.:  49%|████▉     | 4902/10000 [00:29<00:29, 170.11it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:29<00:29, 171.76it/s]Running 10000 simulations.:  49%|████▉     | 4938/10000 [00:29<00:29, 170.42it/s]Running 10000 simulations.:  50%|████▉     | 4956/10000 [00:29<00:29, 169.09it/s]Running 10000 simulations.:  50%|████▉     | 4973/10000 [00:29<00:29, 168.11it/s]Running 10000 simulations.:  50%|████▉     | 4990/10000 [00:29<00:29, 167.02it/s]Running 10000 simulations.:  50%|█████     | 5007/10000 [00:29<00:30, 166.28it/s]Running 10000 simulations.:  50%|█████     | 5024/10000 [00:29<00:29, 166.57it/s]Running 10000 simulations.:  50%|█████     | 5041/10000 [00:30<00:29, 165.81it/s]Running 10000 simulations.:  51%|█████     | 5058/10000 [00:30<00:29, 165.95it/s]Running 10000 simulations.:  51%|█████     | 5075/10000 [00:30<00:29, 166.09it/s]Running 10000 simulations.:  51%|█████     | 5092/10000 [00:30<00:29, 165.94it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:30<00:29, 165.70it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:30<00:29, 165.88it/s]Running 10000 simulations.:  51%|█████▏    | 5143/10000 [00:30<00:29, 166.42it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:30<00:29, 166.36it/s]Running 10000 simulations.:  52%|█████▏    | 5177/10000 [00:30<00:29, 165.73it/s]Running 10000 simulations.:  52%|█████▏    | 5194/10000 [00:31<00:28, 166.02it/s]Running 10000 simulations.:  52%|█████▏    | 5211/10000 [00:31<00:28, 165.83it/s]Running 10000 simulations.:  52%|█████▏    | 5228/10000 [00:31<00:28, 166.20it/s]Running 10000 simulations.:  52%|█████▏    | 5245/10000 [00:31<00:28, 166.16it/s]Running 10000 simulations.:  53%|█████▎    | 5262/10000 [00:31<00:28, 166.78it/s]Running 10000 simulations.:  53%|█████▎    | 5279/10000 [00:31<00:28, 166.82it/s]Running 10000 simulations.:  53%|█████▎    | 5296/10000 [00:31<00:28, 166.38it/s]Running 10000 simulations.:  53%|█████▎    | 5313/10000 [00:31<00:28, 166.15it/s]Running 10000 simulations.:  53%|█████▎    | 5330/10000 [00:31<00:28, 166.17it/s]Running 10000 simulations.:  53%|█████▎    | 5347/10000 [00:31<00:28, 166.01it/s]Running 10000 simulations.:  54%|█████▎    | 5364/10000 [00:32<00:27, 165.76it/s]Running 10000 simulations.:  54%|█████▍    | 5381/10000 [00:32<00:27, 165.62it/s]Running 10000 simulations.:  54%|█████▍    | 5398/10000 [00:32<00:27, 165.75it/s]Running 10000 simulations.:  54%|█████▍    | 5415/10000 [00:32<00:27, 165.22it/s]Running 10000 simulations.:  54%|█████▍    | 5432/10000 [00:32<00:27, 165.05it/s]Running 10000 simulations.:  54%|█████▍    | 5449/10000 [00:32<00:27, 165.80it/s]Running 10000 simulations.:  55%|█████▍    | 5466/10000 [00:32<00:27, 165.97it/s]Running 10000 simulations.:  55%|█████▍    | 5483/10000 [00:32<00:27, 165.69it/s]Running 10000 simulations.:  55%|█████▌    | 5500/10000 [00:32<00:27, 166.09it/s]Running 10000 simulations.:  55%|█████▌    | 5517/10000 [00:32<00:26, 166.12it/s]Running 10000 simulations.:  55%|█████▌    | 5534/10000 [00:33<00:26, 165.97it/s]Running 10000 simulations.:  56%|█████▌    | 5551/10000 [00:33<00:26, 166.26it/s]Running 10000 simulations.:  56%|█████▌    | 5568/10000 [00:33<00:26, 166.72it/s]Running 10000 simulations.:  56%|█████▌    | 5585/10000 [00:33<00:26, 166.75it/s]Running 10000 simulations.:  56%|█████▌    | 5602/10000 [00:33<00:26, 167.13it/s]Running 10000 simulations.:  56%|█████▌    | 5619/10000 [00:33<00:26, 166.93it/s]Running 10000 simulations.:  56%|█████▋    | 5636/10000 [00:33<00:26, 166.24it/s]Running 10000 simulations.:  57%|█████▋    | 5653/10000 [00:33<00:26, 165.99it/s]Running 10000 simulations.:  57%|█████▋    | 5670/10000 [00:33<00:25, 166.55it/s]Running 10000 simulations.:  57%|█████▋    | 5687/10000 [00:33<00:25, 166.02it/s]Running 10000 simulations.:  57%|█████▋    | 5704/10000 [00:34<00:25, 165.93it/s]Running 10000 simulations.:  57%|█████▋    | 5721/10000 [00:34<00:25, 166.13it/s]Running 10000 simulations.:  57%|█████▋    | 5738/10000 [00:34<00:25, 166.29it/s]Running 10000 simulations.:  58%|█████▊    | 5755/10000 [00:34<00:25, 166.54it/s]Running 10000 simulations.:  58%|█████▊    | 5772/10000 [00:34<00:25, 166.26it/s]Running 10000 simulations.:  58%|█████▊    | 5789/10000 [00:34<00:25, 165.98it/s]Running 10000 simulations.:  58%|█████▊    | 5806/10000 [00:34<00:25, 165.80it/s]Running 10000 simulations.:  58%|█████▊    | 5823/10000 [00:34<00:25, 165.93it/s]Running 10000 simulations.:  58%|█████▊    | 5840/10000 [00:34<00:25, 165.86it/s]Running 10000 simulations.:  59%|█████▊    | 5857/10000 [00:34<00:24, 165.82it/s]Running 10000 simulations.:  59%|█████▊    | 5874/10000 [00:35<00:24, 165.87it/s]Running 10000 simulations.:  59%|█████▉    | 5891/10000 [00:35<00:24, 165.99it/s]Running 10000 simulations.:  59%|█████▉    | 5908/10000 [00:35<00:24, 165.39it/s]Running 10000 simulations.:  59%|█████▉    | 5925/10000 [00:35<00:24, 165.92it/s]Running 10000 simulations.:  59%|█████▉    | 5942/10000 [00:35<00:24, 165.90it/s]Running 10000 simulations.:  60%|█████▉    | 5959/10000 [00:35<00:24, 165.72it/s]Running 10000 simulations.:  60%|█████▉    | 5976/10000 [00:35<00:24, 166.13it/s]Running 10000 simulations.:  60%|█████▉    | 5993/10000 [00:35<00:24, 166.52it/s]Running 10000 simulations.:  60%|██████    | 6010/10000 [00:35<00:23, 166.40it/s]Running 10000 simulations.:  60%|██████    | 6027/10000 [00:36<00:23, 165.84it/s]Running 10000 simulations.:  60%|██████    | 6044/10000 [00:36<00:23, 166.17it/s]Running 10000 simulations.:  61%|██████    | 6061/10000 [00:36<00:23, 165.82it/s]Running 10000 simulations.:  61%|██████    | 6078/10000 [00:36<00:23, 165.84it/s]Running 10000 simulations.:  61%|██████    | 6095/10000 [00:36<00:23, 165.88it/s]Running 10000 simulations.:  61%|██████    | 6112/10000 [00:36<00:23, 165.62it/s]Running 10000 simulations.:  61%|██████▏   | 6129/10000 [00:36<00:23, 165.68it/s]Running 10000 simulations.:  61%|██████▏   | 6146/10000 [00:36<00:23, 166.20it/s]Running 10000 simulations.:  62%|██████▏   | 6163/10000 [00:36<00:23, 166.28it/s]Running 10000 simulations.:  62%|██████▏   | 6180/10000 [00:36<00:22, 166.38it/s]Running 10000 simulations.:  62%|██████▏   | 6197/10000 [00:37<00:22, 167.05it/s]Running 10000 simulations.:  62%|██████▏   | 6214/10000 [00:37<00:22, 166.95it/s]Running 10000 simulations.:  62%|██████▏   | 6231/10000 [00:37<00:22, 166.55it/s]Running 10000 simulations.:  62%|██████▏   | 6248/10000 [00:37<00:22, 166.24it/s]Running 10000 simulations.:  63%|██████▎   | 6265/10000 [00:37<00:22, 165.89it/s]Running 10000 simulations.:  63%|██████▎   | 6282/10000 [00:37<00:22, 166.08it/s]Running 10000 simulations.:  63%|██████▎   | 6299/10000 [00:37<00:22, 166.06it/s]Running 10000 simulations.:  63%|██████▎   | 6316/10000 [00:37<00:22, 166.74it/s]Running 10000 simulations.:  63%|██████▎   | 6333/10000 [00:37<00:21, 166.94it/s]Running 10000 simulations.:  64%|██████▎   | 6350/10000 [00:37<00:21, 166.44it/s]Running 10000 simulations.:  64%|██████▎   | 6367/10000 [00:38<00:21, 166.46it/s]Running 10000 simulations.:  64%|██████▍   | 6384/10000 [00:38<00:21, 166.01it/s]Running 10000 simulations.:  64%|██████▍   | 6401/10000 [00:38<00:21, 166.11it/s]Running 10000 simulations.:  64%|██████▍   | 6418/10000 [00:38<00:21, 166.07it/s]Running 10000 simulations.:  64%|██████▍   | 6435/10000 [00:38<00:21, 165.96it/s]Running 10000 simulations.:  65%|██████▍   | 6452/10000 [00:38<00:21, 165.91it/s]Running 10000 simulations.:  65%|██████▍   | 6469/10000 [00:38<00:21, 166.17it/s]Running 10000 simulations.:  65%|██████▍   | 6486/10000 [00:38<00:21, 166.52it/s]Running 10000 simulations.:  65%|██████▌   | 6503/10000 [00:38<00:20, 166.74it/s]Running 10000 simulations.:  65%|██████▌   | 6520/10000 [00:38<00:20, 166.74it/s]Running 10000 simulations.:  65%|██████▌   | 6537/10000 [00:39<00:20, 166.77it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:39<00:20, 167.20it/s]Running 10000 simulations.:  66%|██████▌   | 6571/10000 [00:39<00:20, 166.87it/s]Running 10000 simulations.:  66%|██████▌   | 6588/10000 [00:39<00:20, 166.93it/s]Running 10000 simulations.:  66%|██████▌   | 6605/10000 [00:39<00:20, 166.83it/s]Running 10000 simulations.:  66%|██████▌   | 6622/10000 [00:39<00:20, 167.07it/s]Running 10000 simulations.:  66%|██████▋   | 6639/10000 [00:39<00:20, 166.87it/s]Running 10000 simulations.:  67%|██████▋   | 6656/10000 [00:39<00:20, 167.08it/s]Running 10000 simulations.:  67%|██████▋   | 6673/10000 [00:39<00:19, 166.72it/s]Running 10000 simulations.:  67%|██████▋   | 6691/10000 [00:40<00:19, 169.58it/s]Running 10000 simulations.:  67%|██████▋   | 6710/10000 [00:40<00:18, 174.74it/s]Running 10000 simulations.:  67%|██████▋   | 6728/10000 [00:40<00:18, 172.58it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:40<00:19, 170.73it/s]Running 10000 simulations.:  68%|██████▊   | 6764/10000 [00:40<00:19, 169.35it/s]Running 10000 simulations.:  68%|██████▊   | 6781/10000 [00:40<00:19, 168.79it/s]Running 10000 simulations.:  68%|██████▊   | 6798/10000 [00:40<00:19, 168.41it/s]Running 10000 simulations.:  68%|██████▊   | 6815/10000 [00:40<00:18, 167.89it/s]Running 10000 simulations.:  68%|██████▊   | 6832/10000 [00:40<00:18, 167.67it/s]Running 10000 simulations.:  68%|██████▊   | 6849/10000 [00:40<00:18, 166.92it/s]Running 10000 simulations.:  69%|██████▊   | 6866/10000 [00:41<00:18, 167.24it/s]Running 10000 simulations.:  69%|██████▉   | 6883/10000 [00:41<00:18, 166.92it/s]Running 10000 simulations.:  69%|██████▉   | 6900/10000 [00:41<00:18, 166.75it/s]Running 10000 simulations.:  69%|██████▉   | 6917/10000 [00:41<00:18, 166.84it/s]Running 10000 simulations.:  69%|██████▉   | 6934/10000 [00:41<00:18, 167.22it/s]Running 10000 simulations.:  70%|██████▉   | 6951/10000 [00:41<00:18, 167.39it/s]Running 10000 simulations.:  70%|██████▉   | 6968/10000 [00:41<00:18, 167.43it/s]Running 10000 simulations.:  70%|██████▉   | 6985/10000 [00:41<00:18, 167.47it/s]Running 10000 simulations.:  70%|███████   | 7002/10000 [00:41<00:17, 167.43it/s]Running 10000 simulations.:  70%|███████   | 7019/10000 [00:41<00:17, 167.14it/s]Running 10000 simulations.:  70%|███████   | 7036/10000 [00:42<00:17, 167.32it/s]Running 10000 simulations.:  71%|███████   | 7053/10000 [00:42<00:17, 166.55it/s]Running 10000 simulations.:  71%|███████   | 7070/10000 [00:42<00:17, 166.56it/s]Running 10000 simulations.:  71%|███████   | 7087/10000 [00:42<00:17, 166.42it/s]Running 10000 simulations.:  71%|███████   | 7104/10000 [00:42<00:17, 166.32it/s]Running 10000 simulations.:  71%|███████   | 7121/10000 [00:42<00:17, 166.36it/s]Running 10000 simulations.:  71%|███████▏  | 7138/10000 [00:42<00:17, 166.95it/s]Running 10000 simulations.:  72%|███████▏  | 7155/10000 [00:42<00:17, 166.41it/s]Running 10000 simulations.:  72%|███████▏  | 7172/10000 [00:42<00:16, 166.37it/s]Running 10000 simulations.:  72%|███████▏  | 7189/10000 [00:42<00:16, 166.46it/s]Running 10000 simulations.:  72%|███████▏  | 7206/10000 [00:43<00:16, 166.32it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:43<00:16, 166.00it/s]Running 10000 simulations.:  72%|███████▏  | 7240/10000 [00:43<00:16, 165.96it/s]Running 10000 simulations.:  73%|███████▎  | 7257/10000 [00:43<00:16, 165.96it/s]Running 10000 simulations.:  73%|███████▎  | 7274/10000 [00:43<00:16, 166.00it/s]Running 10000 simulations.:  73%|███████▎  | 7291/10000 [00:43<00:16, 166.08it/s]Running 10000 simulations.:  73%|███████▎  | 7308/10000 [00:43<00:16, 165.93it/s]Running 10000 simulations.:  73%|███████▎  | 7325/10000 [00:43<00:16, 165.31it/s]Running 10000 simulations.:  73%|███████▎  | 7342/10000 [00:43<00:16, 165.27it/s]Running 10000 simulations.:  74%|███████▎  | 7359/10000 [00:43<00:15, 165.65it/s]Running 10000 simulations.:  74%|███████▍  | 7376/10000 [00:44<00:15, 166.17it/s]Running 10000 simulations.:  74%|███████▍  | 7393/10000 [00:44<00:15, 166.11it/s]Running 10000 simulations.:  74%|███████▍  | 7410/10000 [00:44<00:15, 166.50it/s]Running 10000 simulations.:  74%|███████▍  | 7427/10000 [00:44<00:15, 166.88it/s]Running 10000 simulations.:  74%|███████▍  | 7444/10000 [00:44<00:15, 166.86it/s]Running 10000 simulations.:  75%|███████▍  | 7461/10000 [00:44<00:15, 166.52it/s]Running 10000 simulations.:  75%|███████▍  | 7478/10000 [00:44<00:15, 166.36it/s]Running 10000 simulations.:  75%|███████▍  | 7495/10000 [00:44<00:15, 166.81it/s]Running 10000 simulations.:  75%|███████▌  | 7512/10000 [00:44<00:14, 167.20it/s]Running 10000 simulations.:  75%|███████▌  | 7529/10000 [00:45<00:14, 167.00it/s]Running 10000 simulations.:  75%|███████▌  | 7546/10000 [00:45<00:14, 166.65it/s]Running 10000 simulations.:  76%|███████▌  | 7563/10000 [00:45<00:14, 166.47it/s]Running 10000 simulations.:  76%|███████▌  | 7580/10000 [00:45<00:14, 166.87it/s]Running 10000 simulations.:  76%|███████▌  | 7597/10000 [00:45<00:14, 167.08it/s]Running 10000 simulations.:  76%|███████▌  | 7614/10000 [00:45<00:14, 166.98it/s]Running 10000 simulations.:  76%|███████▋  | 7631/10000 [00:45<00:14, 166.84it/s]Running 10000 simulations.:  76%|███████▋  | 7648/10000 [00:45<00:14, 167.18it/s]Running 10000 simulations.:  77%|███████▋  | 7665/10000 [00:45<00:13, 167.32it/s]Running 10000 simulations.:  77%|███████▋  | 7682/10000 [00:45<00:13, 166.61it/s]Running 10000 simulations.:  77%|███████▋  | 7699/10000 [00:46<00:13, 166.44it/s]Running 10000 simulations.:  77%|███████▋  | 7716/10000 [00:46<00:13, 166.86it/s]Running 10000 simulations.:  77%|███████▋  | 7733/10000 [00:46<00:13, 167.28it/s]Running 10000 simulations.:  78%|███████▊  | 7750/10000 [00:46<00:13, 166.77it/s]Running 10000 simulations.:  78%|███████▊  | 7767/10000 [00:46<00:13, 166.94it/s]Running 10000 simulations.:  78%|███████▊  | 7784/10000 [00:46<00:13, 166.79it/s]Running 10000 simulations.:  78%|███████▊  | 7801/10000 [00:46<00:13, 166.95it/s]Running 10000 simulations.:  78%|███████▊  | 7818/10000 [00:46<00:13, 167.19it/s]Running 10000 simulations.:  78%|███████▊  | 7835/10000 [00:46<00:12, 167.06it/s]Running 10000 simulations.:  79%|███████▊  | 7852/10000 [00:46<00:12, 167.06it/s]Running 10000 simulations.:  79%|███████▊  | 7869/10000 [00:47<00:12, 166.22it/s]Running 10000 simulations.:  79%|███████▉  | 7886/10000 [00:47<00:12, 165.83it/s]Running 10000 simulations.:  79%|███████▉  | 7903/10000 [00:47<00:12, 166.07it/s]Running 10000 simulations.:  79%|███████▉  | 7920/10000 [00:47<00:12, 166.49it/s]Running 10000 simulations.:  79%|███████▉  | 7937/10000 [00:47<00:12, 166.55it/s]Running 10000 simulations.:  80%|███████▉  | 7954/10000 [00:47<00:12, 166.39it/s]Running 10000 simulations.:  80%|███████▉  | 7971/10000 [00:47<00:12, 165.93it/s]Running 10000 simulations.:  80%|███████▉  | 7988/10000 [00:47<00:12, 166.04it/s]Running 10000 simulations.:  80%|████████  | 8005/10000 [00:47<00:12, 166.01it/s]Running 10000 simulations.:  80%|████████  | 8022/10000 [00:47<00:11, 166.18it/s]Running 10000 simulations.:  80%|████████  | 8039/10000 [00:48<00:11, 166.57it/s]Running 10000 simulations.:  81%|████████  | 8056/10000 [00:48<00:11, 166.18it/s]Running 10000 simulations.:  81%|████████  | 8073/10000 [00:48<00:11, 166.15it/s]Running 10000 simulations.:  81%|████████  | 8090/10000 [00:48<00:11, 166.12it/s]Running 10000 simulations.:  81%|████████  | 8107/10000 [00:48<00:11, 166.68it/s]Running 10000 simulations.:  81%|████████  | 8124/10000 [00:48<00:11, 166.97it/s]Running 10000 simulations.:  81%|████████▏ | 8141/10000 [00:48<00:11, 166.64it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:48<00:11, 166.58it/s]Running 10000 simulations.:  82%|████████▏ | 8175/10000 [00:48<00:10, 166.37it/s]Running 10000 simulations.:  82%|████████▏ | 8192/10000 [00:48<00:10, 166.63it/s]Running 10000 simulations.:  82%|████████▏ | 8209/10000 [00:49<00:10, 166.75it/s]Running 10000 simulations.:  82%|████████▏ | 8226/10000 [00:49<00:10, 166.76it/s]Running 10000 simulations.:  82%|████████▏ | 8243/10000 [00:49<00:10, 166.97it/s]Running 10000 simulations.:  83%|████████▎ | 8260/10000 [00:49<00:10, 166.50it/s]Running 10000 simulations.:  83%|████████▎ | 8277/10000 [00:49<00:10, 166.42it/s]Running 10000 simulations.:  83%|████████▎ | 8294/10000 [00:49<00:10, 166.15it/s]Running 10000 simulations.:  83%|████████▎ | 8311/10000 [00:49<00:10, 166.10it/s]Running 10000 simulations.:  83%|████████▎ | 8329/10000 [00:49<00:09, 168.32it/s]Running 10000 simulations.:  83%|████████▎ | 8348/10000 [00:49<00:09, 173.73it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [00:50<00:09, 171.52it/s]Running 10000 simulations.:  84%|████████▍ | 8384/10000 [00:50<00:09, 170.38it/s]Running 10000 simulations.:  84%|████████▍ | 8402/10000 [00:50<00:09, 169.58it/s]Running 10000 simulations.:  84%|████████▍ | 8419/10000 [00:50<00:09, 168.34it/s]Running 10000 simulations.:  84%|████████▍ | 8436/10000 [00:50<00:09, 167.63it/s]Running 10000 simulations.:  85%|████████▍ | 8453/10000 [00:50<00:09, 167.86it/s]Running 10000 simulations.:  85%|████████▍ | 8470/10000 [00:50<00:09, 167.95it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [00:50<00:09, 167.41it/s]Running 10000 simulations.:  85%|████████▌ | 8504/10000 [00:50<00:08, 167.13it/s]Running 10000 simulations.:  85%|████████▌ | 8521/10000 [00:50<00:08, 167.20it/s]Running 10000 simulations.:  85%|████████▌ | 8538/10000 [00:51<00:08, 167.04it/s]Running 10000 simulations.:  86%|████████▌ | 8555/10000 [00:51<00:08, 166.90it/s]Running 10000 simulations.:  86%|████████▌ | 8572/10000 [00:51<00:08, 166.57it/s]Running 10000 simulations.:  86%|████████▌ | 8589/10000 [00:51<00:08, 166.62it/s]Running 10000 simulations.:  86%|████████▌ | 8606/10000 [00:51<00:08, 166.80it/s]Running 10000 simulations.:  86%|████████▌ | 8623/10000 [00:51<00:08, 167.21it/s]Running 10000 simulations.:  86%|████████▋ | 8640/10000 [00:51<00:08, 167.29it/s]Running 10000 simulations.:  87%|████████▋ | 8657/10000 [00:51<00:08, 167.31it/s]Running 10000 simulations.:  87%|████████▋ | 8674/10000 [00:51<00:07, 167.04it/s]Running 10000 simulations.:  87%|████████▋ | 8691/10000 [00:51<00:07, 167.19it/s]Running 10000 simulations.:  87%|████████▋ | 8708/10000 [00:52<00:07, 167.36it/s]Running 10000 simulations.:  87%|████████▋ | 8725/10000 [00:52<00:07, 167.36it/s]Running 10000 simulations.:  87%|████████▋ | 8742/10000 [00:52<00:07, 166.98it/s]Running 10000 simulations.:  88%|████████▊ | 8759/10000 [00:52<00:07, 167.18it/s]Running 10000 simulations.:  88%|████████▊ | 8776/10000 [00:52<00:07, 167.20it/s]Running 10000 simulations.:  88%|████████▊ | 8793/10000 [00:52<00:07, 161.20it/s]Running 10000 simulations.:  88%|████████▊ | 8810/10000 [00:52<00:07, 163.73it/s]Running 10000 simulations.:  88%|████████▊ | 8828/10000 [00:52<00:07, 165.79it/s]Running 10000 simulations.:  88%|████████▊ | 8845/10000 [00:52<00:06, 165.60it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [00:53<00:06, 166.22it/s]Running 10000 simulations.:  89%|████████▉ | 8879/10000 [00:53<00:06, 167.00it/s]Running 10000 simulations.:  89%|████████▉ | 8896/10000 [00:53<00:06, 167.08it/s]Running 10000 simulations.:  89%|████████▉ | 8913/10000 [00:53<00:06, 167.58it/s]Running 10000 simulations.:  89%|████████▉ | 8930/10000 [00:53<00:06, 167.97it/s]Running 10000 simulations.:  89%|████████▉ | 8947/10000 [00:53<00:06, 167.30it/s]Running 10000 simulations.:  90%|████████▉ | 8964/10000 [00:53<00:06, 166.83it/s]Running 10000 simulations.:  90%|████████▉ | 8981/10000 [00:53<00:06, 166.33it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:53<00:06, 166.95it/s]Running 10000 simulations.:  90%|█████████ | 9015/10000 [00:53<00:05, 166.81it/s]Running 10000 simulations.:  90%|█████████ | 9032/10000 [00:54<00:05, 166.63it/s]Running 10000 simulations.:  90%|█████████ | 9049/10000 [00:54<00:05, 167.13it/s]Running 10000 simulations.:  91%|█████████ | 9066/10000 [00:54<00:05, 167.41it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [00:54<00:05, 167.68it/s]Running 10000 simulations.:  91%|█████████ | 9100/10000 [00:54<00:05, 167.89it/s]Running 10000 simulations.:  91%|█████████ | 9117/10000 [00:54<00:05, 168.18it/s]Running 10000 simulations.:  91%|█████████▏| 9134/10000 [00:54<00:05, 168.39it/s]Running 10000 simulations.:  92%|█████████▏| 9151/10000 [00:54<00:05, 168.57it/s]Running 10000 simulations.:  92%|█████████▏| 9168/10000 [00:54<00:05, 165.90it/s]Running 10000 simulations.:  92%|█████████▏| 9185/10000 [00:54<00:04, 166.01it/s]Running 10000 simulations.:  92%|█████████▏| 9202/10000 [00:55<00:04, 166.47it/s]Running 10000 simulations.:  92%|█████████▏| 9219/10000 [00:55<00:04, 166.45it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [00:55<00:04, 166.65it/s]Running 10000 simulations.:  93%|█████████▎| 9253/10000 [00:55<00:04, 166.34it/s]Running 10000 simulations.:  93%|█████████▎| 9270/10000 [00:55<00:04, 166.71it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [00:55<00:04, 166.58it/s]Running 10000 simulations.:  93%|█████████▎| 9304/10000 [00:55<00:04, 166.45it/s]Running 10000 simulations.:  93%|█████████▎| 9321/10000 [00:55<00:04, 166.92it/s]Running 10000 simulations.:  93%|█████████▎| 9338/10000 [00:55<00:03, 166.78it/s]Running 10000 simulations.:  94%|█████████▎| 9355/10000 [00:55<00:03, 166.63it/s]Running 10000 simulations.:  94%|█████████▎| 9372/10000 [00:56<00:03, 166.95it/s]Running 10000 simulations.:  94%|█████████▍| 9389/10000 [00:56<00:03, 166.59it/s]Running 10000 simulations.:  94%|█████████▍| 9406/10000 [00:56<00:03, 166.75it/s]Running 10000 simulations.:  94%|█████████▍| 9423/10000 [00:56<00:03, 166.35it/s]Running 10000 simulations.:  94%|█████████▍| 9440/10000 [00:56<00:03, 166.46it/s]Running 10000 simulations.:  95%|█████████▍| 9457/10000 [00:56<00:03, 166.66it/s]Running 10000 simulations.:  95%|█████████▍| 9474/10000 [00:56<00:03, 166.94it/s]Running 10000 simulations.:  95%|█████████▍| 9491/10000 [00:56<00:03, 166.66it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [00:56<00:02, 167.10it/s]Running 10000 simulations.:  95%|█████████▌| 9525/10000 [00:56<00:02, 167.55it/s]Running 10000 simulations.:  95%|█████████▌| 9542/10000 [00:57<00:02, 167.35it/s]Running 10000 simulations.:  96%|█████████▌| 9559/10000 [00:57<00:02, 167.39it/s]Running 10000 simulations.:  96%|█████████▌| 9576/10000 [00:57<00:02, 167.22it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:57<00:02, 167.41it/s]Running 10000 simulations.:  96%|█████████▌| 9610/10000 [00:57<00:02, 167.44it/s]Running 10000 simulations.:  96%|█████████▋| 9627/10000 [00:57<00:02, 167.45it/s]Running 10000 simulations.:  96%|█████████▋| 9644/10000 [00:57<00:02, 168.17it/s]Running 10000 simulations.:  97%|█████████▋| 9661/10000 [00:57<00:02, 167.94it/s]Running 10000 simulations.:  97%|█████████▋| 9678/10000 [00:57<00:01, 167.35it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:57<00:01, 167.89it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [00:58<00:01, 167.45it/s]Running 10000 simulations.:  97%|█████████▋| 9729/10000 [00:58<00:01, 167.07it/s]Running 10000 simulations.:  97%|█████████▋| 9746/10000 [00:58<00:01, 167.11it/s]Running 10000 simulations.:  98%|█████████▊| 9763/10000 [00:58<00:01, 167.31it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [00:58<00:01, 167.17it/s]Running 10000 simulations.:  98%|█████████▊| 9797/10000 [00:58<00:01, 167.78it/s]Running 10000 simulations.:  98%|█████████▊| 9814/10000 [00:58<00:01, 168.13it/s]Running 10000 simulations.:  98%|█████████▊| 9831/10000 [00:58<00:01, 167.77it/s]Running 10000 simulations.:  98%|█████████▊| 9848/10000 [00:58<00:00, 167.71it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [00:59<00:00, 167.64it/s]Running 10000 simulations.:  99%|█████████▉| 9882/10000 [00:59<00:00, 167.84it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:59<00:00, 167.74it/s]Running 10000 simulations.:  99%|█████████▉| 9916/10000 [00:59<00:00, 168.13it/s]Running 10000 simulations.:  99%|█████████▉| 9933/10000 [00:59<00:00, 167.70it/s]Running 10000 simulations.: 100%|█████████▉| 9950/10000 [00:59<00:00, 167.11it/s]Running 10000 simulations.: 100%|█████████▉| 9967/10000 [00:59<00:00, 167.64it/s]Running 10000 simulations.: 100%|█████████▉| 9984/10000 [00:59<00:00, 167.87it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:59<00:00, 167.21it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 18/10000 [00:00<00:58, 172.10it/s]Running 10000 simulations.:   0%|          | 35/10000 [00:00<00:58, 171.25it/s]Running 10000 simulations.:   1%|          | 53/10000 [00:00<00:58, 171.07it/s]Running 10000 simulations.:   1%|          | 71/10000 [00:00<00:57, 171.40it/s]Running 10000 simulations.:   1%|          | 89/10000 [00:00<00:57, 171.05it/s]Running 10000 simulations.:   1%|          | 106/10000 [00:00<00:58, 170.12it/s]Running 10000 simulations.:   1%|          | 123/10000 [00:00<00:58, 170.08it/s]Running 10000 simulations.:   1%|▏         | 140/10000 [00:00<00:58, 169.27it/s]Running 10000 simulations.:   2%|▏         | 161/10000 [00:00<00:55, 178.64it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:01<00:54, 181.84it/s]Running 10000 simulations.:   2%|▏         | 198/10000 [00:01<00:54, 178.28it/s]Running 10000 simulations.:   2%|▏         | 216/10000 [00:01<00:55, 176.10it/s]Running 10000 simulations.:   2%|▏         | 234/10000 [00:01<00:55, 174.77it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:01<00:56, 173.73it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:01<00:56, 172.82it/s]Running 10000 simulations.:   3%|▎         | 288/10000 [00:01<00:56, 171.76it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:56, 171.85it/s]Running 10000 simulations.:   3%|▎         | 324/10000 [00:01<00:56, 171.97it/s]Running 10000 simulations.:   3%|▎         | 342/10000 [00:01<00:56, 171.88it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:02<00:56, 171.60it/s]Running 10000 simulations.:   4%|▍         | 378/10000 [00:02<00:56, 171.73it/s]Running 10000 simulations.:   4%|▍         | 396/10000 [00:02<00:55, 171.56it/s]Running 10000 simulations.:   4%|▍         | 414/10000 [00:02<00:55, 171.74it/s]Running 10000 simulations.:   4%|▍         | 432/10000 [00:02<00:55, 171.96it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:02<00:55, 171.85it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:02<00:55, 172.00it/s]Running 10000 simulations.:   5%|▍         | 486/10000 [00:02<00:55, 171.40it/s]Running 10000 simulations.:   5%|▌         | 504/10000 [00:02<00:55, 171.16it/s]Running 10000 simulations.:   5%|▌         | 522/10000 [00:03<00:55, 171.15it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:03<00:55, 170.92it/s]Running 10000 simulations.:   6%|▌         | 558/10000 [00:03<00:55, 171.18it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:03<00:55, 171.27it/s]Running 10000 simulations.:   6%|▌         | 594/10000 [00:03<00:54, 171.50it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:03<00:54, 171.76it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:03<00:54, 171.38it/s]Running 10000 simulations.:   6%|▋         | 648/10000 [00:03<00:54, 171.20it/s]Running 10000 simulations.:   7%|▋         | 666/10000 [00:03<00:54, 171.36it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:03<00:54, 170.36it/s]Running 10000 simulations.:   7%|▋         | 702/10000 [00:04<00:54, 170.05it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:04<00:54, 169.94it/s]Running 10000 simulations.:   7%|▋         | 738/10000 [00:04<00:54, 170.60it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:04<00:54, 171.05it/s]Running 10000 simulations.:   8%|▊         | 774/10000 [00:04<00:54, 170.73it/s]Running 10000 simulations.:   8%|▊         | 792/10000 [00:04<00:53, 170.53it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:04<00:54, 170.15it/s]Running 10000 simulations.:   8%|▊         | 828/10000 [00:04<00:53, 170.34it/s]Running 10000 simulations.:   8%|▊         | 846/10000 [00:04<00:53, 169.98it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:05<00:53, 170.39it/s]Running 10000 simulations.:   9%|▉         | 882/10000 [00:05<00:53, 169.83it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:05<00:53, 170.15it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:05<00:53, 170.70it/s]Running 10000 simulations.:   9%|▉         | 936/10000 [00:05<00:53, 170.51it/s]Running 10000 simulations.:  10%|▉         | 954/10000 [00:05<00:52, 170.84it/s]Running 10000 simulations.:  10%|▉         | 972/10000 [00:05<00:52, 171.16it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:05<00:52, 171.41it/s]Running 10000 simulations.:  10%|█         | 1008/10000 [00:05<00:52, 171.30it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:05<00:52, 171.16it/s]Running 10000 simulations.:  10%|█         | 1044/10000 [00:06<00:52, 171.36it/s]Running 10000 simulations.:  11%|█         | 1062/10000 [00:06<00:52, 171.49it/s]Running 10000 simulations.:  11%|█         | 1080/10000 [00:06<00:52, 171.36it/s]Running 10000 simulations.:  11%|█         | 1098/10000 [00:06<00:52, 171.06it/s]Running 10000 simulations.:  11%|█         | 1116/10000 [00:06<00:52, 170.77it/s]Running 10000 simulations.:  11%|█▏        | 1134/10000 [00:06<00:51, 170.51it/s]Running 10000 simulations.:  12%|█▏        | 1152/10000 [00:06<00:51, 171.07it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:06<00:51, 170.64it/s]Running 10000 simulations.:  12%|█▏        | 1188/10000 [00:06<00:51, 170.45it/s]Running 10000 simulations.:  12%|█▏        | 1206/10000 [00:07<00:51, 169.88it/s]Running 10000 simulations.:  12%|█▏        | 1224/10000 [00:07<00:51, 169.95it/s]Running 10000 simulations.:  12%|█▏        | 1241/10000 [00:07<00:51, 169.80it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:07<00:51, 170.63it/s]Running 10000 simulations.:  13%|█▎        | 1277/10000 [00:07<00:51, 171.00it/s]Running 10000 simulations.:  13%|█▎        | 1295/10000 [00:07<00:50, 171.30it/s]Running 10000 simulations.:  13%|█▎        | 1313/10000 [00:07<00:50, 171.81it/s]Running 10000 simulations.:  13%|█▎        | 1331/10000 [00:07<00:50, 171.19it/s]Running 10000 simulations.:  13%|█▎        | 1349/10000 [00:07<00:50, 170.65it/s]Running 10000 simulations.:  14%|█▎        | 1367/10000 [00:07<00:50, 171.07it/s]Running 10000 simulations.:  14%|█▍        | 1385/10000 [00:08<00:50, 171.39it/s]Running 10000 simulations.:  14%|█▍        | 1403/10000 [00:08<00:50, 171.47it/s]Running 10000 simulations.:  14%|█▍        | 1421/10000 [00:08<00:50, 171.37it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:08<00:50, 170.96it/s]Running 10000 simulations.:  15%|█▍        | 1457/10000 [00:08<00:50, 170.78it/s]Running 10000 simulations.:  15%|█▍        | 1475/10000 [00:08<00:49, 171.25it/s]Running 10000 simulations.:  15%|█▍        | 1493/10000 [00:08<00:49, 170.83it/s]Running 10000 simulations.:  15%|█▌        | 1511/10000 [00:08<00:49, 170.09it/s]Running 10000 simulations.:  15%|█▌        | 1529/10000 [00:08<00:49, 169.58it/s]Running 10000 simulations.:  15%|█▌        | 1546/10000 [00:09<00:49, 169.43it/s]Running 10000 simulations.:  16%|█▌        | 1563/10000 [00:09<00:49, 169.23it/s]Running 10000 simulations.:  16%|█▌        | 1580/10000 [00:09<00:49, 169.37it/s]Running 10000 simulations.:  16%|█▌        | 1598/10000 [00:09<00:49, 169.87it/s]Running 10000 simulations.:  16%|█▌        | 1615/10000 [00:09<00:49, 169.77it/s]Running 10000 simulations.:  16%|█▋        | 1633/10000 [00:09<00:49, 170.51it/s]Running 10000 simulations.:  17%|█▋        | 1651/10000 [00:09<00:48, 170.62it/s]Running 10000 simulations.:  17%|█▋        | 1669/10000 [00:09<00:48, 170.74it/s]Running 10000 simulations.:  17%|█▋        | 1687/10000 [00:09<00:48, 170.59it/s]Running 10000 simulations.:  17%|█▋        | 1705/10000 [00:09<00:48, 170.84it/s]Running 10000 simulations.:  17%|█▋        | 1723/10000 [00:10<00:48, 170.98it/s]Running 10000 simulations.:  17%|█▋        | 1741/10000 [00:10<00:48, 171.16it/s]Running 10000 simulations.:  18%|█▊        | 1759/10000 [00:10<00:48, 170.60it/s]Running 10000 simulations.:  18%|█▊        | 1777/10000 [00:10<00:48, 171.03it/s]Running 10000 simulations.:  18%|█▊        | 1795/10000 [00:10<00:47, 171.25it/s]Running 10000 simulations.:  18%|█▊        | 1815/10000 [00:10<00:46, 177.40it/s]Running 10000 simulations.:  18%|█▊        | 1835/10000 [00:10<00:44, 182.36it/s]Running 10000 simulations.:  19%|█▊        | 1854/10000 [00:10<00:45, 177.72it/s]Running 10000 simulations.:  19%|█▊        | 1872/10000 [00:10<00:46, 175.32it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:11<00:46, 173.88it/s]Running 10000 simulations.:  19%|█▉        | 1908/10000 [00:11<00:46, 173.49it/s]Running 10000 simulations.:  19%|█▉        | 1926/10000 [00:11<00:46, 172.69it/s]Running 10000 simulations.:  19%|█▉        | 1944/10000 [00:11<00:46, 172.15it/s]Running 10000 simulations.:  20%|█▉        | 1962/10000 [00:11<00:46, 171.58it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:11<00:46, 171.44it/s]Running 10000 simulations.:  20%|█▉        | 1998/10000 [00:11<00:46, 172.05it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:11<00:46, 171.53it/s]Running 10000 simulations.:  20%|██        | 2034/10000 [00:11<00:46, 171.26it/s]Running 10000 simulations.:  21%|██        | 2052/10000 [00:11<00:46, 170.74it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:12<00:46, 170.02it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:12<00:46, 170.07it/s]Running 10000 simulations.:  21%|██        | 2106/10000 [00:12<00:46, 170.55it/s]Running 10000 simulations.:  21%|██        | 2124/10000 [00:12<00:46, 170.31it/s]Running 10000 simulations.:  21%|██▏       | 2142/10000 [00:12<00:46, 169.72it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:12<00:46, 169.86it/s]Running 10000 simulations.:  22%|██▏       | 2177/10000 [00:12<00:46, 169.32it/s]Running 10000 simulations.:  22%|██▏       | 2194/10000 [00:12<00:46, 168.96it/s]Running 10000 simulations.:  22%|██▏       | 2211/10000 [00:12<00:46, 168.91it/s]Running 10000 simulations.:  22%|██▏       | 2228/10000 [00:12<00:46, 168.55it/s]Running 10000 simulations.:  22%|██▏       | 2245/10000 [00:13<00:45, 168.71it/s]Running 10000 simulations.:  23%|██▎       | 2262/10000 [00:13<00:45, 168.96it/s]Running 10000 simulations.:  23%|██▎       | 2279/10000 [00:13<00:45, 168.62it/s]Running 10000 simulations.:  23%|██▎       | 2296/10000 [00:13<00:45, 168.58it/s]Running 10000 simulations.:  23%|██▎       | 2313/10000 [00:13<00:45, 168.80it/s]Running 10000 simulations.:  23%|██▎       | 2330/10000 [00:13<00:45, 168.77it/s]Running 10000 simulations.:  23%|██▎       | 2347/10000 [00:13<00:45, 168.33it/s]Running 10000 simulations.:  24%|██▎       | 2364/10000 [00:13<00:45, 168.63it/s]Running 10000 simulations.:  24%|██▍       | 2381/10000 [00:13<00:45, 169.02it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:14<00:45, 168.64it/s]Running 10000 simulations.:  24%|██▍       | 2415/10000 [00:14<00:45, 167.81it/s]Running 10000 simulations.:  24%|██▍       | 2432/10000 [00:14<00:45, 167.54it/s]Running 10000 simulations.:  24%|██▍       | 2449/10000 [00:14<00:45, 167.46it/s]Running 10000 simulations.:  25%|██▍       | 2466/10000 [00:14<00:44, 167.50it/s]Running 10000 simulations.:  25%|██▍       | 2483/10000 [00:14<00:44, 167.90it/s]Running 10000 simulations.:  25%|██▌       | 2500/10000 [00:14<00:44, 168.05it/s]Running 10000 simulations.:  25%|██▌       | 2517/10000 [00:14<00:44, 167.52it/s]Running 10000 simulations.:  25%|██▌       | 2534/10000 [00:14<00:44, 167.48it/s]Running 10000 simulations.:  26%|██▌       | 2551/10000 [00:14<00:44, 167.95it/s]Running 10000 simulations.:  26%|██▌       | 2568/10000 [00:15<00:44, 168.19it/s]Running 10000 simulations.:  26%|██▌       | 2585/10000 [00:15<00:44, 167.75it/s]Running 10000 simulations.:  26%|██▌       | 2602/10000 [00:15<00:44, 167.43it/s]Running 10000 simulations.:  26%|██▌       | 2619/10000 [00:15<00:43, 168.07it/s]Running 10000 simulations.:  26%|██▋       | 2637/10000 [00:15<00:43, 168.65it/s]Running 10000 simulations.:  27%|██▋       | 2654/10000 [00:15<00:43, 168.04it/s]Running 10000 simulations.:  27%|██▋       | 2671/10000 [00:15<00:43, 167.71it/s]Running 10000 simulations.:  27%|██▋       | 2688/10000 [00:15<00:43, 167.17it/s]Running 10000 simulations.:  27%|██▋       | 2705/10000 [00:15<00:43, 167.57it/s]Running 10000 simulations.:  27%|██▋       | 2722/10000 [00:15<00:43, 167.38it/s]Running 10000 simulations.:  27%|██▋       | 2739/10000 [00:16<00:43, 167.31it/s]Running 10000 simulations.:  28%|██▊       | 2756/10000 [00:16<00:43, 167.09it/s]Running 10000 simulations.:  28%|██▊       | 2773/10000 [00:16<00:43, 167.72it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:16<00:42, 167.89it/s]Running 10000 simulations.:  28%|██▊       | 2807/10000 [00:16<00:42, 168.04it/s]Running 10000 simulations.:  28%|██▊       | 2824/10000 [00:16<00:42, 167.76it/s]Running 10000 simulations.:  28%|██▊       | 2841/10000 [00:16<00:42, 168.15it/s]Running 10000 simulations.:  29%|██▊       | 2858/10000 [00:16<00:42, 168.53it/s]Running 10000 simulations.:  29%|██▉       | 2875/10000 [00:16<00:42, 168.91it/s]Running 10000 simulations.:  29%|██▉       | 2892/10000 [00:16<00:42, 169.01it/s]Running 10000 simulations.:  29%|██▉       | 2909/10000 [00:17<00:41, 169.07it/s]Running 10000 simulations.:  29%|██▉       | 2926/10000 [00:17<00:41, 169.10it/s]Running 10000 simulations.:  29%|██▉       | 2943/10000 [00:17<00:41, 168.60it/s]Running 10000 simulations.:  30%|██▉       | 2960/10000 [00:17<00:41, 168.49it/s]Running 10000 simulations.:  30%|██▉       | 2977/10000 [00:17<00:41, 168.62it/s]Running 10000 simulations.:  30%|██▉       | 2994/10000 [00:17<00:41, 168.62it/s]Running 10000 simulations.:  30%|███       | 3011/10000 [00:17<00:41, 168.47it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:17<00:41, 168.34it/s]Running 10000 simulations.:  30%|███       | 3045/10000 [00:17<00:41, 168.57it/s]Running 10000 simulations.:  31%|███       | 3062/10000 [00:17<00:41, 168.06it/s]Running 10000 simulations.:  31%|███       | 3079/10000 [00:18<00:41, 167.56it/s]Running 10000 simulations.:  31%|███       | 3096/10000 [00:18<00:41, 167.88it/s]Running 10000 simulations.:  31%|███       | 3113/10000 [00:18<00:40, 168.04it/s]Running 10000 simulations.:  31%|███▏      | 3130/10000 [00:18<00:41, 167.53it/s]Running 10000 simulations.:  31%|███▏      | 3147/10000 [00:18<00:40, 167.17it/s]Running 10000 simulations.:  32%|███▏      | 3164/10000 [00:18<00:40, 167.73it/s]Running 10000 simulations.:  32%|███▏      | 3181/10000 [00:18<00:40, 168.08it/s]Running 10000 simulations.:  32%|███▏      | 3198/10000 [00:18<00:40, 167.92it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:18<00:40, 168.30it/s]Running 10000 simulations.:  32%|███▏      | 3232/10000 [00:18<00:40, 168.69it/s]Running 10000 simulations.:  32%|███▏      | 3249/10000 [00:19<00:39, 169.04it/s]Running 10000 simulations.:  33%|███▎      | 3266/10000 [00:19<00:39, 169.27it/s]Running 10000 simulations.:  33%|███▎      | 3284/10000 [00:19<00:39, 169.40it/s]Running 10000 simulations.:  33%|███▎      | 3301/10000 [00:19<00:39, 168.93it/s]Running 10000 simulations.:  33%|███▎      | 3318/10000 [00:19<00:39, 168.24it/s]Running 10000 simulations.:  33%|███▎      | 3335/10000 [00:19<00:39, 167.92it/s]Running 10000 simulations.:  34%|███▎      | 3352/10000 [00:19<00:39, 167.44it/s]Running 10000 simulations.:  34%|███▎      | 3369/10000 [00:19<00:39, 168.03it/s]Running 10000 simulations.:  34%|███▍      | 3386/10000 [00:19<00:39, 168.49it/s]Running 10000 simulations.:  34%|███▍      | 3403/10000 [00:19<00:39, 168.70it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:20<00:38, 169.00it/s]Running 10000 simulations.:  34%|███▍      | 3437/10000 [00:20<00:38, 168.67it/s]Running 10000 simulations.:  35%|███▍      | 3454/10000 [00:20<00:38, 169.04it/s]Running 10000 simulations.:  35%|███▍      | 3471/10000 [00:20<00:38, 168.67it/s]Running 10000 simulations.:  35%|███▍      | 3488/10000 [00:20<00:38, 168.74it/s]Running 10000 simulations.:  35%|███▌      | 3505/10000 [00:20<00:38, 168.50it/s]Running 10000 simulations.:  35%|███▌      | 3522/10000 [00:20<00:38, 168.52it/s]Running 10000 simulations.:  35%|███▌      | 3539/10000 [00:20<00:38, 168.34it/s]Running 10000 simulations.:  36%|███▌      | 3556/10000 [00:20<00:38, 168.56it/s]Running 10000 simulations.:  36%|███▌      | 3573/10000 [00:20<00:38, 168.04it/s]Running 10000 simulations.:  36%|███▌      | 3590/10000 [00:21<00:38, 167.94it/s]Running 10000 simulations.:  36%|███▌      | 3607/10000 [00:21<00:38, 167.84it/s]Running 10000 simulations.:  36%|███▋      | 3625/10000 [00:21<00:37, 170.01it/s]Running 10000 simulations.:  36%|███▋      | 3644/10000 [00:21<00:36, 173.04it/s]Running 10000 simulations.:  37%|███▋      | 3662/10000 [00:21<00:37, 170.49it/s]Running 10000 simulations.:  37%|███▋      | 3680/10000 [00:21<00:37, 169.20it/s]Running 10000 simulations.:  37%|███▋      | 3697/10000 [00:21<00:37, 168.22it/s]Running 10000 simulations.:  37%|███▋      | 3714/10000 [00:21<00:37, 168.42it/s]Running 10000 simulations.:  37%|███▋      | 3731/10000 [00:21<00:37, 167.70it/s]Running 10000 simulations.:  37%|███▋      | 3748/10000 [00:22<00:37, 168.24it/s]Running 10000 simulations.:  38%|███▊      | 3765/10000 [00:22<00:36, 168.64it/s]Running 10000 simulations.:  38%|███▊      | 3782/10000 [00:22<00:36, 169.00it/s]Running 10000 simulations.:  38%|███▊      | 3799/10000 [00:22<00:36, 168.68it/s]Running 10000 simulations.:  38%|███▊      | 3816/10000 [00:22<00:36, 168.09it/s]Running 10000 simulations.:  38%|███▊      | 3833/10000 [00:22<00:36, 168.28it/s]Running 10000 simulations.:  38%|███▊      | 3850/10000 [00:22<00:36, 168.42it/s]Running 10000 simulations.:  39%|███▊      | 3867/10000 [00:22<00:36, 168.83it/s]Running 10000 simulations.:  39%|███▉      | 3884/10000 [00:22<00:36, 168.88it/s]Running 10000 simulations.:  39%|███▉      | 3901/10000 [00:22<00:36, 168.77it/s]Running 10000 simulations.:  39%|███▉      | 3918/10000 [00:23<00:36, 168.22it/s]Running 10000 simulations.:  39%|███▉      | 3935/10000 [00:23<00:35, 168.56it/s]Running 10000 simulations.:  40%|███▉      | 3952/10000 [00:23<00:35, 168.96it/s]Running 10000 simulations.:  40%|███▉      | 3969/10000 [00:23<00:35, 168.90it/s]Running 10000 simulations.:  40%|███▉      | 3986/10000 [00:23<00:35, 168.25it/s]Running 10000 simulations.:  40%|████      | 4003/10000 [00:23<00:35, 167.53it/s]Running 10000 simulations.:  40%|████      | 4020/10000 [00:23<00:35, 167.47it/s]Running 10000 simulations.:  40%|████      | 4037/10000 [00:23<00:35, 167.41it/s]Running 10000 simulations.:  41%|████      | 4054/10000 [00:23<00:35, 167.27it/s]Running 10000 simulations.:  41%|████      | 4071/10000 [00:23<00:35, 167.31it/s]Running 10000 simulations.:  41%|████      | 4088/10000 [00:24<00:35, 168.03it/s]Running 10000 simulations.:  41%|████      | 4105/10000 [00:24<00:35, 167.95it/s]Running 10000 simulations.:  41%|████      | 4122/10000 [00:24<00:34, 168.45it/s]Running 10000 simulations.:  41%|████▏     | 4142/10000 [00:24<00:33, 174.61it/s]Running 10000 simulations.:  42%|████▏     | 4162/10000 [00:24<00:32, 180.36it/s]Running 10000 simulations.:  42%|████▏     | 4181/10000 [00:24<00:32, 179.36it/s]Running 10000 simulations.:  42%|████▏     | 4199/10000 [00:24<00:32, 177.81it/s]Running 10000 simulations.:  42%|████▏     | 4217/10000 [00:24<00:32, 176.95it/s]Running 10000 simulations.:  42%|████▏     | 4235/10000 [00:24<00:32, 176.83it/s]Running 10000 simulations.:  43%|████▎     | 4253/10000 [00:24<00:32, 176.62it/s]Running 10000 simulations.:  43%|████▎     | 4271/10000 [00:25<00:32, 176.95it/s]Running 10000 simulations.:  43%|████▎     | 4289/10000 [00:25<00:32, 176.15it/s]Running 10000 simulations.:  43%|████▎     | 4307/10000 [00:25<00:32, 176.35it/s]Running 10000 simulations.:  43%|████▎     | 4325/10000 [00:25<00:32, 176.14it/s]Running 10000 simulations.:  43%|████▎     | 4343/10000 [00:25<00:32, 175.97it/s]Running 10000 simulations.:  44%|████▎     | 4361/10000 [00:25<00:32, 175.89it/s]Running 10000 simulations.:  44%|████▍     | 4379/10000 [00:25<00:32, 175.13it/s]Running 10000 simulations.:  44%|████▍     | 4397/10000 [00:25<00:31, 175.75it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:25<00:31, 175.88it/s]Running 10000 simulations.:  44%|████▍     | 4433/10000 [00:25<00:31, 175.37it/s]Running 10000 simulations.:  45%|████▍     | 4451/10000 [00:26<00:31, 174.31it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:26<00:31, 174.35it/s]Running 10000 simulations.:  45%|████▍     | 4487/10000 [00:26<00:31, 174.05it/s]Running 10000 simulations.:  45%|████▌     | 4505/10000 [00:26<00:31, 174.38it/s]Running 10000 simulations.:  45%|████▌     | 4523/10000 [00:26<00:31, 174.42it/s]Running 10000 simulations.:  45%|████▌     | 4541/10000 [00:26<00:31, 174.95it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:26<00:31, 174.31it/s]Running 10000 simulations.:  46%|████▌     | 4577/10000 [00:26<00:31, 174.86it/s]Running 10000 simulations.:  46%|████▌     | 4595/10000 [00:26<00:31, 174.10it/s]Running 10000 simulations.:  46%|████▌     | 4613/10000 [00:27<00:30, 174.27it/s]Running 10000 simulations.:  46%|████▋     | 4631/10000 [00:27<00:30, 173.79it/s]Running 10000 simulations.:  46%|████▋     | 4649/10000 [00:27<00:30, 172.66it/s]Running 10000 simulations.:  47%|████▋     | 4667/10000 [00:27<00:30, 173.28it/s]Running 10000 simulations.:  47%|████▋     | 4685/10000 [00:27<00:30, 173.77it/s]Running 10000 simulations.:  47%|████▋     | 4703/10000 [00:27<00:30, 174.06it/s]Running 10000 simulations.:  47%|████▋     | 4721/10000 [00:27<00:30, 173.98it/s]Running 10000 simulations.:  47%|████▋     | 4739/10000 [00:27<00:30, 173.76it/s]Running 10000 simulations.:  48%|████▊     | 4757/10000 [00:27<00:30, 172.73it/s]Running 10000 simulations.:  48%|████▊     | 4775/10000 [00:27<00:30, 172.44it/s]Running 10000 simulations.:  48%|████▊     | 4793/10000 [00:28<00:30, 171.77it/s]Running 10000 simulations.:  48%|████▊     | 4811/10000 [00:28<00:30, 172.63it/s]Running 10000 simulations.:  48%|████▊     | 4829/10000 [00:28<00:29, 173.84it/s]Running 10000 simulations.:  48%|████▊     | 4847/10000 [00:28<00:29, 175.03it/s]Running 10000 simulations.:  49%|████▊     | 4865/10000 [00:28<00:29, 175.47it/s]Running 10000 simulations.:  49%|████▉     | 4883/10000 [00:28<00:29, 174.18it/s]Running 10000 simulations.:  49%|████▉     | 4901/10000 [00:28<00:29, 173.83it/s]Running 10000 simulations.:  49%|████▉     | 4919/10000 [00:28<00:29, 173.19it/s]Running 10000 simulations.:  49%|████▉     | 4937/10000 [00:28<00:29, 173.05it/s]Running 10000 simulations.:  50%|████▉     | 4955/10000 [00:29<00:29, 173.77it/s]Running 10000 simulations.:  50%|████▉     | 4973/10000 [00:29<00:28, 174.10it/s]Running 10000 simulations.:  50%|████▉     | 4991/10000 [00:29<00:28, 174.14it/s]Running 10000 simulations.:  50%|█████     | 5009/10000 [00:29<00:28, 173.21it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:29<00:28, 172.37it/s]Running 10000 simulations.:  50%|█████     | 5045/10000 [00:29<00:28, 173.08it/s]Running 10000 simulations.:  51%|█████     | 5063/10000 [00:29<00:28, 172.69it/s]Running 10000 simulations.:  51%|█████     | 5081/10000 [00:29<00:28, 173.23it/s]Running 10000 simulations.:  51%|█████     | 5099/10000 [00:29<00:28, 172.84it/s]Running 10000 simulations.:  51%|█████     | 5117/10000 [00:29<00:28, 173.49it/s]Running 10000 simulations.:  51%|█████▏    | 5135/10000 [00:30<00:28, 173.35it/s]Running 10000 simulations.:  52%|█████▏    | 5153/10000 [00:30<00:27, 174.04it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:30<00:27, 173.19it/s]Running 10000 simulations.:  52%|█████▏    | 5189/10000 [00:30<00:27, 172.92it/s]Running 10000 simulations.:  52%|█████▏    | 5207/10000 [00:30<00:27, 172.89it/s]Running 10000 simulations.:  52%|█████▏    | 5225/10000 [00:30<00:27, 171.82it/s]Running 10000 simulations.:  52%|█████▏    | 5243/10000 [00:30<00:27, 172.31it/s]Running 10000 simulations.:  53%|█████▎    | 5261/10000 [00:30<00:28, 166.58it/s]Running 10000 simulations.:  53%|█████▎    | 5279/10000 [00:30<00:28, 168.34it/s]Running 10000 simulations.:  53%|█████▎    | 5297/10000 [00:30<00:27, 170.03it/s]Running 10000 simulations.:  53%|█████▎    | 5315/10000 [00:31<00:27, 170.85it/s]Running 10000 simulations.:  53%|█████▎    | 5333/10000 [00:31<00:27, 171.27it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:31<00:27, 172.14it/s]Running 10000 simulations.:  54%|█████▎    | 5369/10000 [00:31<00:26, 172.53it/s]Running 10000 simulations.:  54%|█████▍    | 5387/10000 [00:31<00:26, 172.50it/s]Running 10000 simulations.:  54%|█████▍    | 5405/10000 [00:31<00:26, 172.38it/s]Running 10000 simulations.:  54%|█████▍    | 5423/10000 [00:31<00:26, 172.61it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:31<00:26, 173.44it/s]Running 10000 simulations.:  55%|█████▍    | 5459/10000 [00:31<00:26, 173.50it/s]Running 10000 simulations.:  55%|█████▍    | 5477/10000 [00:32<00:26, 173.27it/s]Running 10000 simulations.:  55%|█████▍    | 5495/10000 [00:32<00:25, 173.75it/s]Running 10000 simulations.:  55%|█████▌    | 5513/10000 [00:32<00:25, 173.64it/s]Running 10000 simulations.:  55%|█████▌    | 5531/10000 [00:32<00:25, 173.65it/s]Running 10000 simulations.:  55%|█████▌    | 5549/10000 [00:32<00:25, 173.50it/s]Running 10000 simulations.:  56%|█████▌    | 5567/10000 [00:32<00:25, 173.20it/s]Running 10000 simulations.:  56%|█████▌    | 5585/10000 [00:32<00:25, 172.69it/s]Running 10000 simulations.:  56%|█████▌    | 5603/10000 [00:32<00:25, 172.80it/s]Running 10000 simulations.:  56%|█████▌    | 5621/10000 [00:32<00:25, 172.92it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:32<00:25, 172.56it/s]Running 10000 simulations.:  57%|█████▋    | 5657/10000 [00:33<00:25, 172.82it/s]Running 10000 simulations.:  57%|█████▋    | 5675/10000 [00:33<00:25, 172.75it/s]Running 10000 simulations.:  57%|█████▋    | 5693/10000 [00:33<00:24, 173.12it/s]Running 10000 simulations.:  57%|█████▋    | 5711/10000 [00:33<00:24, 173.62it/s]Running 10000 simulations.:  57%|█████▋    | 5729/10000 [00:33<00:24, 173.04it/s]Running 10000 simulations.:  57%|█████▋    | 5747/10000 [00:33<00:24, 172.57it/s]Running 10000 simulations.:  58%|█████▊    | 5765/10000 [00:33<00:24, 172.95it/s]Running 10000 simulations.:  58%|█████▊    | 5783/10000 [00:33<00:24, 173.70it/s]Running 10000 simulations.:  58%|█████▊    | 5801/10000 [00:33<00:24, 174.34it/s]Running 10000 simulations.:  58%|█████▊    | 5819/10000 [00:34<00:24, 174.03it/s]Running 10000 simulations.:  58%|█████▊    | 5837/10000 [00:34<00:23, 173.97it/s]Running 10000 simulations.:  59%|█████▊    | 5855/10000 [00:34<00:23, 174.50it/s]Running 10000 simulations.:  59%|█████▊    | 5873/10000 [00:34<00:23, 173.42it/s]Running 10000 simulations.:  59%|█████▉    | 5891/10000 [00:34<00:23, 173.19it/s]Running 10000 simulations.:  59%|█████▉    | 5909/10000 [00:34<00:23, 173.31it/s]Running 10000 simulations.:  59%|█████▉    | 5927/10000 [00:34<00:23, 173.43it/s]Running 10000 simulations.:  59%|█████▉    | 5945/10000 [00:34<00:23, 173.62it/s]Running 10000 simulations.:  60%|█████▉    | 5963/10000 [00:34<00:23, 172.69it/s]Running 10000 simulations.:  60%|█████▉    | 5981/10000 [00:34<00:23, 172.33it/s]Running 10000 simulations.:  60%|█████▉    | 5999/10000 [00:35<00:23, 172.39it/s]Running 10000 simulations.:  60%|██████    | 6017/10000 [00:35<00:23, 172.46it/s]Running 10000 simulations.:  60%|██████    | 6035/10000 [00:35<00:23, 171.16it/s]Running 10000 simulations.:  61%|██████    | 6053/10000 [00:35<00:23, 171.27it/s]Running 10000 simulations.:  61%|██████    | 6071/10000 [00:35<00:22, 170.83it/s]Running 10000 simulations.:  61%|██████    | 6089/10000 [00:35<00:22, 170.95it/s]Running 10000 simulations.:  61%|██████    | 6107/10000 [00:35<00:22, 170.29it/s]Running 10000 simulations.:  61%|██████▏   | 6125/10000 [00:35<00:22, 171.27it/s]Running 10000 simulations.:  61%|██████▏   | 6143/10000 [00:35<00:22, 171.77it/s]Running 10000 simulations.:  62%|██████▏   | 6161/10000 [00:35<00:22, 172.24it/s]Running 10000 simulations.:  62%|██████▏   | 6179/10000 [00:36<00:22, 171.36it/s]Running 10000 simulations.:  62%|██████▏   | 6197/10000 [00:36<00:22, 171.92it/s]Running 10000 simulations.:  62%|██████▏   | 6215/10000 [00:36<00:22, 171.59it/s]Running 10000 simulations.:  62%|██████▏   | 6233/10000 [00:36<00:21, 171.93it/s]Running 10000 simulations.:  63%|██████▎   | 6251/10000 [00:36<00:21, 171.87it/s]Running 10000 simulations.:  63%|██████▎   | 6269/10000 [00:36<00:21, 170.88it/s]Running 10000 simulations.:  63%|██████▎   | 6287/10000 [00:36<00:21, 170.94it/s]Running 10000 simulations.:  63%|██████▎   | 6305/10000 [00:36<00:21, 170.57it/s]Running 10000 simulations.:  63%|██████▎   | 6323/10000 [00:36<00:21, 170.35it/s]Running 10000 simulations.:  63%|██████▎   | 6341/10000 [00:37<00:21, 169.91it/s]Running 10000 simulations.:  64%|██████▎   | 6358/10000 [00:37<00:21, 169.65it/s]Running 10000 simulations.:  64%|██████▍   | 6376/10000 [00:37<00:21, 170.08it/s]Running 10000 simulations.:  64%|██████▍   | 6394/10000 [00:37<00:21, 170.37it/s]Running 10000 simulations.:  64%|██████▍   | 6412/10000 [00:37<00:21, 170.34it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:37<00:20, 170.11it/s]Running 10000 simulations.:  64%|██████▍   | 6448/10000 [00:37<00:20, 170.63it/s]Running 10000 simulations.:  65%|██████▍   | 6466/10000 [00:37<00:20, 170.80it/s]Running 10000 simulations.:  65%|██████▍   | 6484/10000 [00:37<00:20, 170.12it/s]Running 10000 simulations.:  65%|██████▌   | 6502/10000 [00:37<00:20, 169.33it/s]Running 10000 simulations.:  65%|██████▌   | 6519/10000 [00:38<00:20, 169.51it/s]Running 10000 simulations.:  65%|██████▌   | 6536/10000 [00:38<00:20, 169.49it/s]Running 10000 simulations.:  66%|██████▌   | 6554/10000 [00:38<00:20, 170.05it/s]Running 10000 simulations.:  66%|██████▌   | 6572/10000 [00:38<00:20, 170.05it/s]Running 10000 simulations.:  66%|██████▌   | 6590/10000 [00:38<00:19, 170.59it/s]Running 10000 simulations.:  66%|██████▌   | 6608/10000 [00:38<00:19, 171.11it/s]Running 10000 simulations.:  66%|██████▋   | 6626/10000 [00:38<00:19, 170.91it/s]Running 10000 simulations.:  66%|██████▋   | 6644/10000 [00:38<00:19, 171.27it/s]Running 10000 simulations.:  67%|██████▋   | 6662/10000 [00:38<00:19, 171.01it/s]Running 10000 simulations.:  67%|██████▋   | 6680/10000 [00:39<00:19, 170.85it/s]Running 10000 simulations.:  67%|██████▋   | 6698/10000 [00:39<00:19, 170.35it/s]Running 10000 simulations.:  67%|██████▋   | 6716/10000 [00:39<00:19, 170.21it/s]Running 10000 simulations.:  67%|██████▋   | 6734/10000 [00:39<00:19, 169.93it/s]Running 10000 simulations.:  68%|██████▊   | 6752/10000 [00:39<00:19, 170.19it/s]Running 10000 simulations.:  68%|██████▊   | 6770/10000 [00:39<00:19, 169.99it/s]Running 10000 simulations.:  68%|██████▊   | 6787/10000 [00:39<00:18, 169.81it/s]Running 10000 simulations.:  68%|██████▊   | 6805/10000 [00:39<00:18, 170.56it/s]Running 10000 simulations.:  68%|██████▊   | 6823/10000 [00:39<00:18, 169.92it/s]Running 10000 simulations.:  68%|██████▊   | 6841/10000 [00:39<00:18, 170.87it/s]Running 10000 simulations.:  69%|██████▊   | 6859/10000 [00:40<00:18, 171.69it/s]Running 10000 simulations.:  69%|██████▉   | 6877/10000 [00:40<00:18, 172.33it/s]Running 10000 simulations.:  69%|██████▉   | 6895/10000 [00:40<00:17, 172.53it/s]Running 10000 simulations.:  69%|██████▉   | 6913/10000 [00:40<00:17, 172.99it/s]Running 10000 simulations.:  69%|██████▉   | 6931/10000 [00:40<00:17, 173.62it/s]Running 10000 simulations.:  69%|██████▉   | 6949/10000 [00:40<00:17, 173.97it/s]Running 10000 simulations.:  70%|██████▉   | 6967/10000 [00:40<00:17, 173.88it/s]Running 10000 simulations.:  70%|██████▉   | 6985/10000 [00:40<00:17, 174.09it/s]Running 10000 simulations.:  70%|███████   | 7003/10000 [00:40<00:17, 173.68it/s]Running 10000 simulations.:  70%|███████   | 7021/10000 [00:41<00:17, 172.97it/s]Running 10000 simulations.:  70%|███████   | 7039/10000 [00:41<00:17, 172.92it/s]Running 10000 simulations.:  71%|███████   | 7057/10000 [00:41<00:17, 172.95it/s]Running 10000 simulations.:  71%|███████   | 7075/10000 [00:41<00:16, 173.25it/s]Running 10000 simulations.:  71%|███████   | 7093/10000 [00:41<00:16, 173.53it/s]Running 10000 simulations.:  71%|███████   | 7111/10000 [00:41<00:16, 172.89it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:41<00:16, 173.41it/s]Running 10000 simulations.:  71%|███████▏  | 7147/10000 [00:41<00:16, 173.49it/s]Running 10000 simulations.:  72%|███████▏  | 7165/10000 [00:41<00:16, 173.92it/s]Running 10000 simulations.:  72%|███████▏  | 7183/10000 [00:41<00:16, 173.72it/s]Running 10000 simulations.:  72%|███████▏  | 7201/10000 [00:42<00:16, 172.34it/s]Running 10000 simulations.:  72%|███████▏  | 7219/10000 [00:42<00:16, 171.12it/s]Running 10000 simulations.:  72%|███████▏  | 7237/10000 [00:42<00:16, 170.57it/s]Running 10000 simulations.:  73%|███████▎  | 7255/10000 [00:42<00:16, 169.99it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:42<00:16, 169.99it/s]Running 10000 simulations.:  73%|███████▎  | 7291/10000 [00:42<00:15, 170.45it/s]Running 10000 simulations.:  73%|███████▎  | 7309/10000 [00:42<00:15, 170.53it/s]Running 10000 simulations.:  73%|███████▎  | 7327/10000 [00:42<00:15, 169.59it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:42<00:15, 171.59it/s]Running 10000 simulations.:  74%|███████▎  | 7363/10000 [00:43<00:15, 172.18it/s]Running 10000 simulations.:  74%|███████▍  | 7381/10000 [00:43<00:15, 172.81it/s]Running 10000 simulations.:  74%|███████▍  | 7399/10000 [00:43<00:15, 172.74it/s]Running 10000 simulations.:  74%|███████▍  | 7417/10000 [00:43<00:14, 173.23it/s]Running 10000 simulations.:  74%|███████▍  | 7435/10000 [00:43<00:14, 173.52it/s]Running 10000 simulations.:  75%|███████▍  | 7453/10000 [00:43<00:14, 173.11it/s]Running 10000 simulations.:  75%|███████▍  | 7471/10000 [00:43<00:14, 173.27it/s]Running 10000 simulations.:  75%|███████▍  | 7489/10000 [00:43<00:14, 173.23it/s]Running 10000 simulations.:  75%|███████▌  | 7507/10000 [00:43<00:14, 173.87it/s]Running 10000 simulations.:  75%|███████▌  | 7525/10000 [00:43<00:14, 172.72it/s]Running 10000 simulations.:  75%|███████▌  | 7543/10000 [00:44<00:14, 170.53it/s]Running 10000 simulations.:  76%|███████▌  | 7561/10000 [00:44<00:14, 171.65it/s]Running 10000 simulations.:  76%|███████▌  | 7579/10000 [00:44<00:14, 172.43it/s]Running 10000 simulations.:  76%|███████▌  | 7597/10000 [00:44<00:13, 172.95it/s]Running 10000 simulations.:  76%|███████▌  | 7615/10000 [00:44<00:13, 173.36it/s]Running 10000 simulations.:  76%|███████▋  | 7633/10000 [00:44<00:13, 173.49it/s]Running 10000 simulations.:  77%|███████▋  | 7651/10000 [00:44<00:13, 173.63it/s]Running 10000 simulations.:  77%|███████▋  | 7669/10000 [00:44<00:13, 173.94it/s]Running 10000 simulations.:  77%|███████▋  | 7687/10000 [00:44<00:13, 173.63it/s]Running 10000 simulations.:  77%|███████▋  | 7705/10000 [00:44<00:13, 174.09it/s]Running 10000 simulations.:  77%|███████▋  | 7723/10000 [00:45<00:13, 174.26it/s]Running 10000 simulations.:  77%|███████▋  | 7741/10000 [00:45<00:12, 173.86it/s]Running 10000 simulations.:  78%|███████▊  | 7759/10000 [00:45<00:12, 173.18it/s]Running 10000 simulations.:  78%|███████▊  | 7777/10000 [00:45<00:12, 173.34it/s]Running 10000 simulations.:  78%|███████▊  | 7795/10000 [00:45<00:12, 173.06it/s]Running 10000 simulations.:  78%|███████▊  | 7813/10000 [00:45<00:12, 173.58it/s]Running 10000 simulations.:  78%|███████▊  | 7831/10000 [00:45<00:12, 174.18it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:45<00:12, 173.97it/s]Running 10000 simulations.:  79%|███████▊  | 7867/10000 [00:45<00:12, 174.34it/s]Running 10000 simulations.:  79%|███████▉  | 7885/10000 [00:46<00:12, 174.12it/s]Running 10000 simulations.:  79%|███████▉  | 7903/10000 [00:46<00:12, 174.08it/s]Running 10000 simulations.:  79%|███████▉  | 7921/10000 [00:46<00:11, 174.18it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:46<00:11, 174.47it/s]Running 10000 simulations.:  80%|███████▉  | 7957/10000 [00:46<00:11, 173.38it/s]Running 10000 simulations.:  80%|███████▉  | 7975/10000 [00:46<00:11, 172.00it/s]Running 10000 simulations.:  80%|███████▉  | 7993/10000 [00:46<00:11, 172.18it/s]Running 10000 simulations.:  80%|████████  | 8011/10000 [00:46<00:11, 172.24it/s]Running 10000 simulations.:  80%|████████  | 8029/10000 [00:46<00:11, 172.31it/s]Running 10000 simulations.:  80%|████████  | 8047/10000 [00:46<00:11, 172.48it/s]Running 10000 simulations.:  81%|████████  | 8065/10000 [00:47<00:11, 173.20it/s]Running 10000 simulations.:  81%|████████  | 8083/10000 [00:47<00:11, 173.39it/s]Running 10000 simulations.:  81%|████████  | 8101/10000 [00:47<00:10, 173.75it/s]Running 10000 simulations.:  81%|████████  | 8119/10000 [00:47<00:10, 173.19it/s]Running 10000 simulations.:  81%|████████▏ | 8137/10000 [00:47<00:10, 172.50it/s]Running 10000 simulations.:  82%|████████▏ | 8155/10000 [00:47<00:10, 171.97it/s]Running 10000 simulations.:  82%|████████▏ | 8173/10000 [00:47<00:10, 172.10it/s]Running 10000 simulations.:  82%|████████▏ | 8191/10000 [00:47<00:10, 172.80it/s]Running 10000 simulations.:  82%|████████▏ | 8209/10000 [00:47<00:10, 171.52it/s]Running 10000 simulations.:  82%|████████▏ | 8227/10000 [00:48<00:10, 170.23it/s]Running 10000 simulations.:  82%|████████▏ | 8245/10000 [00:48<00:10, 171.53it/s]Running 10000 simulations.:  83%|████████▎ | 8263/10000 [00:48<00:10, 172.59it/s]Running 10000 simulations.:  83%|████████▎ | 8281/10000 [00:48<00:09, 173.57it/s]Running 10000 simulations.:  83%|████████▎ | 8299/10000 [00:48<00:09, 173.82it/s]Running 10000 simulations.:  83%|████████▎ | 8317/10000 [00:48<00:09, 173.92it/s]Running 10000 simulations.:  83%|████████▎ | 8335/10000 [00:48<00:09, 174.04it/s]Running 10000 simulations.:  84%|████████▎ | 8353/10000 [00:48<00:09, 173.97it/s]Running 10000 simulations.:  84%|████████▎ | 8371/10000 [00:48<00:09, 172.47it/s]Running 10000 simulations.:  84%|████████▍ | 8389/10000 [00:48<00:09, 172.14it/s]Running 10000 simulations.:  84%|████████▍ | 8407/10000 [00:49<00:09, 172.78it/s]Running 10000 simulations.:  84%|████████▍ | 8425/10000 [00:49<00:09, 173.24it/s]Running 10000 simulations.:  84%|████████▍ | 8443/10000 [00:49<00:08, 173.72it/s]Running 10000 simulations.:  85%|████████▍ | 8461/10000 [00:49<00:08, 173.76it/s]Running 10000 simulations.:  85%|████████▍ | 8479/10000 [00:49<00:08, 173.92it/s]Running 10000 simulations.:  85%|████████▍ | 8497/10000 [00:49<00:08, 173.90it/s]Running 10000 simulations.:  85%|████████▌ | 8515/10000 [00:49<00:08, 173.73it/s]Running 10000 simulations.:  85%|████████▌ | 8533/10000 [00:49<00:08, 173.86it/s]Running 10000 simulations.:  86%|████████▌ | 8551/10000 [00:49<00:08, 174.01it/s]Running 10000 simulations.:  86%|████████▌ | 8569/10000 [00:49<00:08, 173.97it/s]Running 10000 simulations.:  86%|████████▌ | 8587/10000 [00:50<00:08, 173.71it/s]Running 10000 simulations.:  86%|████████▌ | 8605/10000 [00:50<00:08, 173.89it/s]Running 10000 simulations.:  86%|████████▌ | 8623/10000 [00:50<00:07, 173.68it/s]Running 10000 simulations.:  86%|████████▋ | 8641/10000 [00:50<00:07, 173.12it/s]Running 10000 simulations.:  87%|████████▋ | 8659/10000 [00:50<00:07, 173.52it/s]Running 10000 simulations.:  87%|████████▋ | 8677/10000 [00:50<00:07, 173.88it/s]Running 10000 simulations.:  87%|████████▋ | 8695/10000 [00:50<00:07, 174.34it/s]Running 10000 simulations.:  87%|████████▋ | 8713/10000 [00:50<00:07, 174.67it/s]Running 10000 simulations.:  87%|████████▋ | 8731/10000 [00:50<00:07, 175.25it/s]Running 10000 simulations.:  87%|████████▋ | 8749/10000 [00:51<00:07, 174.40it/s]Running 10000 simulations.:  88%|████████▊ | 8767/10000 [00:51<00:07, 173.93it/s]Running 10000 simulations.:  88%|████████▊ | 8785/10000 [00:51<00:06, 174.45it/s]Running 10000 simulations.:  88%|████████▊ | 8803/10000 [00:51<00:06, 174.51it/s]Running 10000 simulations.:  88%|████████▊ | 8821/10000 [00:51<00:06, 175.06it/s]Running 10000 simulations.:  88%|████████▊ | 8839/10000 [00:51<00:06, 175.43it/s]Running 10000 simulations.:  89%|████████▊ | 8857/10000 [00:51<00:06, 175.43it/s]Running 10000 simulations.:  89%|████████▉ | 8875/10000 [00:51<00:06, 173.47it/s]Running 10000 simulations.:  89%|████████▉ | 8893/10000 [00:51<00:06, 172.80it/s]Running 10000 simulations.:  89%|████████▉ | 8911/10000 [00:51<00:06, 173.60it/s]Running 10000 simulations.:  89%|████████▉ | 8929/10000 [00:52<00:06, 174.22it/s]Running 10000 simulations.:  89%|████████▉ | 8947/10000 [00:52<00:06, 174.26it/s]Running 10000 simulations.:  90%|████████▉ | 8965/10000 [00:52<00:05, 174.37it/s]Running 10000 simulations.:  90%|████████▉ | 8983/10000 [00:52<00:05, 173.70it/s]Running 10000 simulations.:  90%|█████████ | 9001/10000 [00:52<00:05, 174.07it/s]Running 10000 simulations.:  90%|█████████ | 9019/10000 [00:52<00:05, 174.61it/s]Running 10000 simulations.:  90%|█████████ | 9037/10000 [00:52<00:05, 174.62it/s]Running 10000 simulations.:  91%|█████████ | 9055/10000 [00:52<00:05, 174.61it/s]Running 10000 simulations.:  91%|█████████ | 9073/10000 [00:52<00:05, 174.47it/s]Running 10000 simulations.:  91%|█████████ | 9091/10000 [00:52<00:05, 173.29it/s]Running 10000 simulations.:  91%|█████████ | 9109/10000 [00:53<00:05, 173.92it/s]Running 10000 simulations.:  91%|█████████▏| 9127/10000 [00:53<00:04, 174.83it/s]Running 10000 simulations.:  91%|█████████▏| 9145/10000 [00:53<00:04, 175.18it/s]Running 10000 simulations.:  92%|█████████▏| 9163/10000 [00:53<00:04, 175.50it/s]Running 10000 simulations.:  92%|█████████▏| 9181/10000 [00:53<00:04, 175.45it/s]Running 10000 simulations.:  92%|█████████▏| 9199/10000 [00:53<00:04, 175.30it/s]Running 10000 simulations.:  92%|█████████▏| 9217/10000 [00:53<00:04, 174.85it/s]Running 10000 simulations.:  92%|█████████▏| 9235/10000 [00:53<00:04, 174.59it/s]Running 10000 simulations.:  93%|█████████▎| 9253/10000 [00:53<00:04, 174.40it/s]Running 10000 simulations.:  93%|█████████▎| 9271/10000 [00:53<00:04, 174.25it/s]Running 10000 simulations.:  93%|█████████▎| 9289/10000 [00:54<00:04, 174.75it/s]Running 10000 simulations.:  93%|█████████▎| 9307/10000 [00:54<00:03, 174.86it/s]Running 10000 simulations.:  93%|█████████▎| 9325/10000 [00:54<00:03, 174.78it/s]Running 10000 simulations.:  93%|█████████▎| 9343/10000 [00:54<00:03, 174.69it/s]Running 10000 simulations.:  94%|█████████▎| 9361/10000 [00:54<00:03, 174.92it/s]Running 10000 simulations.:  94%|█████████▍| 9379/10000 [00:54<00:03, 174.86it/s]Running 10000 simulations.:  94%|█████████▍| 9397/10000 [00:54<00:03, 174.96it/s]Running 10000 simulations.:  94%|█████████▍| 9415/10000 [00:54<00:03, 174.97it/s]Running 10000 simulations.:  94%|█████████▍| 9433/10000 [00:54<00:03, 174.83it/s]Running 10000 simulations.:  95%|█████████▍| 9451/10000 [00:55<00:03, 174.71it/s]Running 10000 simulations.:  95%|█████████▍| 9469/10000 [00:55<00:03, 174.56it/s]Running 10000 simulations.:  95%|█████████▍| 9487/10000 [00:55<00:02, 174.89it/s]Running 10000 simulations.:  95%|█████████▌| 9505/10000 [00:55<00:02, 174.68it/s]Running 10000 simulations.:  95%|█████████▌| 9523/10000 [00:55<00:02, 174.34it/s]Running 10000 simulations.:  95%|█████████▌| 9541/10000 [00:55<00:02, 173.74it/s]Running 10000 simulations.:  96%|█████████▌| 9559/10000 [00:55<00:02, 174.49it/s]Running 10000 simulations.:  96%|█████████▌| 9577/10000 [00:55<00:02, 174.81it/s]Running 10000 simulations.:  96%|█████████▌| 9595/10000 [00:55<00:02, 175.20it/s]Running 10000 simulations.:  96%|█████████▌| 9613/10000 [00:55<00:02, 175.01it/s]Running 10000 simulations.:  96%|█████████▋| 9631/10000 [00:56<00:02, 175.12it/s]Running 10000 simulations.:  96%|█████████▋| 9649/10000 [00:56<00:02, 175.49it/s]Running 10000 simulations.:  97%|█████████▋| 9667/10000 [00:56<00:01, 175.63it/s]Running 10000 simulations.:  97%|█████████▋| 9685/10000 [00:56<00:01, 175.66it/s]Running 10000 simulations.:  97%|█████████▋| 9703/10000 [00:56<00:01, 175.49it/s]Running 10000 simulations.:  97%|█████████▋| 9721/10000 [00:56<00:01, 175.80it/s]Running 10000 simulations.:  97%|█████████▋| 9739/10000 [00:56<00:01, 175.85it/s]Running 10000 simulations.:  98%|█████████▊| 9757/10000 [00:56<00:01, 176.37it/s]Running 10000 simulations.:  98%|█████████▊| 9775/10000 [00:56<00:01, 175.91it/s]Running 10000 simulations.:  98%|█████████▊| 9793/10000 [00:56<00:01, 176.12it/s]Running 10000 simulations.:  98%|█████████▊| 9811/10000 [00:57<00:01, 176.02it/s]Running 10000 simulations.:  98%|█████████▊| 9829/10000 [00:57<00:00, 176.08it/s]Running 10000 simulations.:  98%|█████████▊| 9847/10000 [00:57<00:00, 175.83it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [00:57<00:00, 175.79it/s]Running 10000 simulations.:  99%|█████████▉| 9883/10000 [00:57<00:00, 176.06it/s]Running 10000 simulations.:  99%|█████████▉| 9901/10000 [00:57<00:00, 176.14it/s]Running 10000 simulations.:  99%|█████████▉| 9919/10000 [00:57<00:00, 176.20it/s]Running 10000 simulations.:  99%|█████████▉| 9937/10000 [00:57<00:00, 176.29it/s]Running 10000 simulations.: 100%|█████████▉| 9955/10000 [00:57<00:00, 176.22it/s]Running 10000 simulations.: 100%|█████████▉| 9973/10000 [00:57<00:00, 176.16it/s]Running 10000 simulations.: 100%|█████████▉| 9991/10000 [00:58<00:00, 176.33it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:58<00:00, 171.97it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 17/10000 [00:00<00:59, 168.57it/s]Running 10000 simulations.:   0%|          | 34/10000 [00:00<00:59, 168.74it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<00:58, 168.66it/s]Running 10000 simulations.:   1%|          | 68/10000 [00:00<00:58, 168.46it/s]Running 10000 simulations.:   1%|          | 86/10000 [00:00<00:58, 169.35it/s]Running 10000 simulations.:   1%|          | 104/10000 [00:00<00:58, 169.80it/s]Running 10000 simulations.:   1%|          | 122/10000 [00:00<00:58, 169.93it/s]Running 10000 simulations.:   1%|▏         | 139/10000 [00:00<00:58, 169.66it/s]Running 10000 simulations.:   2%|▏         | 157/10000 [00:00<00:57, 170.19it/s]Running 10000 simulations.:   2%|▏         | 175/10000 [00:01<00:57, 170.37it/s]Running 10000 simulations.:   2%|▏         | 192/10000 [00:01<00:57, 170.14it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:01<00:57, 170.87it/s]Running 10000 simulations.:   2%|▏         | 228/10000 [00:01<00:57, 170.94it/s]Running 10000 simulations.:   2%|▏         | 246/10000 [00:01<00:57, 170.84it/s]Running 10000 simulations.:   3%|▎         | 263/10000 [00:01<00:57, 170.07it/s]Running 10000 simulations.:   3%|▎         | 280/10000 [00:01<00:57, 169.71it/s]Running 10000 simulations.:   3%|▎         | 297/10000 [00:01<00:57, 169.54it/s]Running 10000 simulations.:   3%|▎         | 314/10000 [00:01<00:57, 169.36it/s]Running 10000 simulations.:   3%|▎         | 331/10000 [00:01<00:57, 169.33it/s]Running 10000 simulations.:   3%|▎         | 349/10000 [00:02<00:56, 169.66it/s]Running 10000 simulations.:   4%|▎         | 367/10000 [00:02<00:56, 169.83it/s]Running 10000 simulations.:   4%|▍         | 384/10000 [00:02<00:56, 169.80it/s]Running 10000 simulations.:   4%|▍         | 402/10000 [00:02<00:56, 170.44it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:02<00:56, 170.19it/s]Running 10000 simulations.:   4%|▍         | 438/10000 [00:02<00:56, 169.84it/s]Running 10000 simulations.:   5%|▍         | 455/10000 [00:02<00:56, 169.69it/s]Running 10000 simulations.:   5%|▍         | 472/10000 [00:02<00:56, 169.62it/s]Running 10000 simulations.:   5%|▍         | 490/10000 [00:02<00:55, 170.05it/s]Running 10000 simulations.:   5%|▌         | 508/10000 [00:02<00:55, 169.74it/s]Running 10000 simulations.:   5%|▌         | 525/10000 [00:03<00:55, 169.65it/s]Running 10000 simulations.:   5%|▌         | 542/10000 [00:03<00:55, 169.45it/s]Running 10000 simulations.:   6%|▌         | 559/10000 [00:03<00:55, 169.60it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:03<00:55, 169.58it/s]Running 10000 simulations.:   6%|▌         | 593/10000 [00:03<00:55, 169.29it/s]Running 10000 simulations.:   6%|▌         | 611/10000 [00:03<00:55, 169.68it/s]Running 10000 simulations.:   6%|▋         | 629/10000 [00:03<00:55, 170.01it/s]Running 10000 simulations.:   6%|▋         | 647/10000 [00:03<00:54, 170.35it/s]Running 10000 simulations.:   7%|▋         | 665/10000 [00:03<00:54, 170.34it/s]Running 10000 simulations.:   7%|▋         | 683/10000 [00:04<00:54, 170.39it/s]Running 10000 simulations.:   7%|▋         | 701/10000 [00:04<00:54, 170.59it/s]Running 10000 simulations.:   7%|▋         | 719/10000 [00:04<00:54, 170.36it/s]Running 10000 simulations.:   7%|▋         | 737/10000 [00:04<00:54, 170.31it/s]Running 10000 simulations.:   8%|▊         | 755/10000 [00:04<00:54, 169.79it/s]Running 10000 simulations.:   8%|▊         | 772/10000 [00:04<00:54, 169.49it/s]Running 10000 simulations.:   8%|▊         | 789/10000 [00:04<00:54, 169.36it/s]Running 10000 simulations.:   8%|▊         | 807/10000 [00:04<00:54, 169.59it/s]Running 10000 simulations.:   8%|▊         | 824/10000 [00:04<00:54, 169.67it/s]Running 10000 simulations.:   8%|▊         | 841/10000 [00:04<00:54, 169.50it/s]Running 10000 simulations.:   9%|▊         | 859/10000 [00:05<00:53, 169.68it/s]Running 10000 simulations.:   9%|▉         | 876/10000 [00:05<00:53, 169.49it/s]Running 10000 simulations.:   9%|▉         | 894/10000 [00:05<00:53, 169.72it/s]Running 10000 simulations.:   9%|▉         | 912/10000 [00:05<00:53, 169.87it/s]Running 10000 simulations.:   9%|▉         | 929/10000 [00:05<00:53, 169.86it/s]Running 10000 simulations.:   9%|▉         | 947/10000 [00:05<00:53, 170.41it/s]Running 10000 simulations.:  10%|▉         | 965/10000 [00:05<00:52, 170.81it/s]Running 10000 simulations.:  10%|▉         | 983/10000 [00:05<00:53, 169.97it/s]Running 10000 simulations.:  10%|█         | 1000/10000 [00:05<00:53, 169.36it/s]Running 10000 simulations.:  10%|█         | 1017/10000 [00:05<00:53, 169.07it/s]Running 10000 simulations.:  10%|█         | 1034/10000 [00:06<00:53, 168.75it/s]Running 10000 simulations.:  11%|█         | 1051/10000 [00:06<00:53, 168.77it/s]Running 10000 simulations.:  11%|█         | 1068/10000 [00:06<00:53, 168.21it/s]Running 10000 simulations.:  11%|█         | 1085/10000 [00:06<00:52, 168.23it/s]Running 10000 simulations.:  11%|█         | 1102/10000 [00:06<00:52, 168.09it/s]Running 10000 simulations.:  11%|█         | 1119/10000 [00:06<00:52, 167.88it/s]Running 10000 simulations.:  11%|█▏        | 1136/10000 [00:06<00:52, 168.22it/s]Running 10000 simulations.:  12%|█▏        | 1153/10000 [00:06<00:52, 168.13it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:06<00:52, 167.92it/s]Running 10000 simulations.:  12%|█▏        | 1187/10000 [00:07<00:52, 167.81it/s]Running 10000 simulations.:  12%|█▏        | 1204/10000 [00:07<00:52, 167.98it/s]Running 10000 simulations.:  12%|█▏        | 1221/10000 [00:07<00:52, 167.99it/s]Running 10000 simulations.:  12%|█▏        | 1238/10000 [00:07<00:52, 167.90it/s]Running 10000 simulations.:  13%|█▎        | 1255/10000 [00:07<00:52, 167.80it/s]Running 10000 simulations.:  13%|█▎        | 1272/10000 [00:07<00:51, 167.89it/s]Running 10000 simulations.:  13%|█▎        | 1289/10000 [00:07<00:51, 168.32it/s]Running 10000 simulations.:  13%|█▎        | 1307/10000 [00:07<00:51, 169.23it/s]Running 10000 simulations.:  13%|█▎        | 1325/10000 [00:07<00:50, 170.14it/s]Running 10000 simulations.:  13%|█▎        | 1343/10000 [00:07<00:50, 169.79it/s]Running 10000 simulations.:  14%|█▎        | 1360/10000 [00:08<00:50, 169.45it/s]Running 10000 simulations.:  14%|█▍        | 1377/10000 [00:08<00:50, 169.51it/s]Running 10000 simulations.:  14%|█▍        | 1397/10000 [00:08<00:48, 175.77it/s]Running 10000 simulations.:  14%|█▍        | 1417/10000 [00:08<00:47, 180.06it/s]Running 10000 simulations.:  14%|█▍        | 1436/10000 [00:08<00:48, 176.26it/s]Running 10000 simulations.:  15%|█▍        | 1454/10000 [00:08<00:49, 174.17it/s]Running 10000 simulations.:  15%|█▍        | 1472/10000 [00:08<00:49, 172.61it/s]Running 10000 simulations.:  15%|█▍        | 1490/10000 [00:08<00:49, 171.40it/s]Running 10000 simulations.:  15%|█▌        | 1508/10000 [00:08<00:49, 170.46it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:08<00:49, 169.65it/s]Running 10000 simulations.:  15%|█▌        | 1543/10000 [00:09<00:49, 169.31it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:09<00:50, 168.74it/s]Running 10000 simulations.:  16%|█▌        | 1577/10000 [00:09<00:49, 168.94it/s]Running 10000 simulations.:  16%|█▌        | 1594/10000 [00:09<00:49, 168.37it/s]Running 10000 simulations.:  16%|█▌        | 1612/10000 [00:09<00:49, 168.85it/s]Running 10000 simulations.:  16%|█▋        | 1629/10000 [00:09<00:49, 169.13it/s]Running 10000 simulations.:  16%|█▋        | 1646/10000 [00:09<00:49, 169.15it/s]Running 10000 simulations.:  17%|█▋        | 1663/10000 [00:09<00:49, 169.05it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:09<00:49, 168.97it/s]Running 10000 simulations.:  17%|█▋        | 1697/10000 [00:09<00:49, 168.62it/s]Running 10000 simulations.:  17%|█▋        | 1714/10000 [00:10<00:49, 168.32it/s]Running 10000 simulations.:  17%|█▋        | 1731/10000 [00:10<00:49, 168.45it/s]Running 10000 simulations.:  17%|█▋        | 1748/10000 [00:10<00:49, 168.35it/s]Running 10000 simulations.:  18%|█▊        | 1765/10000 [00:10<00:49, 167.98it/s]Running 10000 simulations.:  18%|█▊        | 1782/10000 [00:10<00:48, 168.14it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:10<00:48, 168.25it/s]Running 10000 simulations.:  18%|█▊        | 1816/10000 [00:10<00:48, 168.51it/s]Running 10000 simulations.:  18%|█▊        | 1833/10000 [00:10<00:48, 168.46it/s]Running 10000 simulations.:  18%|█▊        | 1850/10000 [00:10<00:48, 167.83it/s]Running 10000 simulations.:  19%|█▊        | 1867/10000 [00:11<00:48, 168.00it/s]Running 10000 simulations.:  19%|█▉        | 1885/10000 [00:11<00:48, 168.98it/s]Running 10000 simulations.:  19%|█▉        | 1902/10000 [00:11<00:47, 168.77it/s]Running 10000 simulations.:  19%|█▉        | 1919/10000 [00:11<00:48, 167.57it/s]Running 10000 simulations.:  19%|█▉        | 1936/10000 [00:11<00:48, 166.77it/s]Running 10000 simulations.:  20%|█▉        | 1953/10000 [00:11<00:48, 166.34it/s]Running 10000 simulations.:  20%|█▉        | 1970/10000 [00:11<00:48, 165.83it/s]Running 10000 simulations.:  20%|█▉        | 1987/10000 [00:11<00:48, 165.58it/s]Running 10000 simulations.:  20%|██        | 2004/10000 [00:11<00:48, 165.49it/s]Running 10000 simulations.:  20%|██        | 2021/10000 [00:11<00:48, 165.34it/s]Running 10000 simulations.:  20%|██        | 2038/10000 [00:12<00:48, 165.56it/s]Running 10000 simulations.:  21%|██        | 2055/10000 [00:12<00:47, 165.67it/s]Running 10000 simulations.:  21%|██        | 2072/10000 [00:12<00:47, 165.17it/s]Running 10000 simulations.:  21%|██        | 2089/10000 [00:12<00:47, 165.28it/s]Running 10000 simulations.:  21%|██        | 2106/10000 [00:12<00:47, 165.45it/s]Running 10000 simulations.:  21%|██        | 2123/10000 [00:12<00:47, 165.47it/s]Running 10000 simulations.:  21%|██▏       | 2140/10000 [00:12<00:47, 165.41it/s]Running 10000 simulations.:  22%|██▏       | 2157/10000 [00:12<00:47, 165.72it/s]Running 10000 simulations.:  22%|██▏       | 2174/10000 [00:12<00:47, 165.62it/s]Running 10000 simulations.:  22%|██▏       | 2191/10000 [00:12<00:47, 165.84it/s]Running 10000 simulations.:  22%|██▏       | 2208/10000 [00:13<00:46, 165.88it/s]Running 10000 simulations.:  22%|██▏       | 2225/10000 [00:13<00:46, 166.36it/s]Running 10000 simulations.:  22%|██▏       | 2242/10000 [00:13<00:46, 166.24it/s]Running 10000 simulations.:  23%|██▎       | 2259/10000 [00:13<00:46, 166.03it/s]Running 10000 simulations.:  23%|██▎       | 2276/10000 [00:13<00:46, 165.83it/s]Running 10000 simulations.:  23%|██▎       | 2293/10000 [00:13<00:46, 165.62it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:13<00:46, 165.50it/s]Running 10000 simulations.:  23%|██▎       | 2327/10000 [00:13<00:46, 165.47it/s]Running 10000 simulations.:  23%|██▎       | 2344/10000 [00:13<00:46, 166.14it/s]Running 10000 simulations.:  24%|██▎       | 2361/10000 [00:13<00:45, 166.68it/s]Running 10000 simulations.:  24%|██▍       | 2378/10000 [00:14<00:45, 166.68it/s]Running 10000 simulations.:  24%|██▍       | 2395/10000 [00:14<00:45, 166.22it/s]Running 10000 simulations.:  24%|██▍       | 2412/10000 [00:14<00:45, 166.33it/s]Running 10000 simulations.:  24%|██▍       | 2429/10000 [00:14<00:45, 166.58it/s]Running 10000 simulations.:  24%|██▍       | 2446/10000 [00:14<00:45, 166.69it/s]Running 10000 simulations.:  25%|██▍       | 2463/10000 [00:14<00:45, 166.57it/s]Running 10000 simulations.:  25%|██▍       | 2480/10000 [00:14<00:44, 167.30it/s]Running 10000 simulations.:  25%|██▍       | 2498/10000 [00:14<00:44, 168.25it/s]Running 10000 simulations.:  25%|██▌       | 2516/10000 [00:14<00:44, 169.12it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:15<00:44, 168.99it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:15<00:44, 168.57it/s]Running 10000 simulations.:  26%|██▌       | 2567/10000 [00:15<00:44, 168.11it/s]Running 10000 simulations.:  26%|██▌       | 2584/10000 [00:15<00:44, 167.91it/s]Running 10000 simulations.:  26%|██▌       | 2601/10000 [00:15<00:44, 168.06it/s]Running 10000 simulations.:  26%|██▌       | 2618/10000 [00:15<00:43, 168.08it/s]Running 10000 simulations.:  26%|██▋       | 2635/10000 [00:15<00:43, 168.12it/s]Running 10000 simulations.:  27%|██▋       | 2652/10000 [00:15<00:43, 168.16it/s]Running 10000 simulations.:  27%|██▋       | 2669/10000 [00:15<00:43, 168.24it/s]Running 10000 simulations.:  27%|██▋       | 2686/10000 [00:15<00:43, 168.10it/s]Running 10000 simulations.:  27%|██▋       | 2703/10000 [00:16<00:43, 168.32it/s]Running 10000 simulations.:  27%|██▋       | 2720/10000 [00:16<00:43, 168.09it/s]Running 10000 simulations.:  27%|██▋       | 2737/10000 [00:16<00:43, 168.55it/s]Running 10000 simulations.:  28%|██▊       | 2754/10000 [00:16<00:42, 168.84it/s]Running 10000 simulations.:  28%|██▊       | 2771/10000 [00:16<00:42, 168.79it/s]Running 10000 simulations.:  28%|██▊       | 2788/10000 [00:16<00:42, 168.62it/s]Running 10000 simulations.:  28%|██▊       | 2805/10000 [00:16<00:42, 168.61it/s]Running 10000 simulations.:  28%|██▊       | 2822/10000 [00:16<00:42, 168.83it/s]Running 10000 simulations.:  28%|██▊       | 2839/10000 [00:16<00:42, 168.79it/s]Running 10000 simulations.:  29%|██▊       | 2856/10000 [00:16<00:42, 168.57it/s]Running 10000 simulations.:  29%|██▊       | 2874/10000 [00:17<00:42, 169.20it/s]Running 10000 simulations.:  29%|██▉       | 2891/10000 [00:17<00:41, 169.28it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:17<00:41, 169.00it/s]Running 10000 simulations.:  29%|██▉       | 2925/10000 [00:17<00:41, 168.74it/s]Running 10000 simulations.:  29%|██▉       | 2942/10000 [00:17<00:41, 168.39it/s]Running 10000 simulations.:  30%|██▉       | 2959/10000 [00:17<00:41, 168.38it/s]Running 10000 simulations.:  30%|██▉       | 2976/10000 [00:17<00:41, 168.54it/s]Running 10000 simulations.:  30%|██▉       | 2993/10000 [00:17<00:41, 168.68it/s]Running 10000 simulations.:  30%|███       | 3010/10000 [00:17<00:41, 168.62it/s]Running 10000 simulations.:  30%|███       | 3027/10000 [00:17<00:41, 168.77it/s]Running 10000 simulations.:  30%|███       | 3046/10000 [00:18<00:40, 173.06it/s]Running 10000 simulations.:  31%|███       | 3065/10000 [00:18<00:39, 177.80it/s]Running 10000 simulations.:  31%|███       | 3083/10000 [00:18<00:39, 174.28it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:18<00:40, 171.22it/s]Running 10000 simulations.:  31%|███       | 3119/10000 [00:18<00:40, 169.64it/s]Running 10000 simulations.:  31%|███▏      | 3137/10000 [00:18<00:40, 168.91it/s]Running 10000 simulations.:  32%|███▏      | 3154/10000 [00:18<00:40, 168.14it/s]Running 10000 simulations.:  32%|███▏      | 3171/10000 [00:18<00:40, 167.40it/s]Running 10000 simulations.:  32%|███▏      | 3188/10000 [00:18<00:40, 166.96it/s]Running 10000 simulations.:  32%|███▏      | 3205/10000 [00:18<00:40, 166.76it/s]Running 10000 simulations.:  32%|███▏      | 3222/10000 [00:19<00:40, 166.30it/s]Running 10000 simulations.:  32%|███▏      | 3239/10000 [00:19<00:40, 166.00it/s]Running 10000 simulations.:  33%|███▎      | 3256/10000 [00:19<00:40, 166.03it/s]Running 10000 simulations.:  33%|███▎      | 3273/10000 [00:19<00:40, 165.78it/s]Running 10000 simulations.:  33%|███▎      | 3290/10000 [00:19<00:40, 165.96it/s]Running 10000 simulations.:  33%|███▎      | 3307/10000 [00:19<00:40, 166.35it/s]Running 10000 simulations.:  33%|███▎      | 3324/10000 [00:19<00:40, 166.66it/s]Running 10000 simulations.:  33%|███▎      | 3341/10000 [00:19<00:40, 166.25it/s]Running 10000 simulations.:  34%|███▎      | 3358/10000 [00:19<00:39, 166.06it/s]Running 10000 simulations.:  34%|███▍      | 3375/10000 [00:20<00:39, 165.77it/s]Running 10000 simulations.:  34%|███▍      | 3392/10000 [00:20<00:39, 165.67it/s]Running 10000 simulations.:  34%|███▍      | 3409/10000 [00:20<00:41, 159.06it/s]Running 10000 simulations.:  34%|███▍      | 3426/10000 [00:20<00:40, 160.89it/s]Running 10000 simulations.:  34%|███▍      | 3443/10000 [00:20<00:40, 162.71it/s]Running 10000 simulations.:  35%|███▍      | 3460/10000 [00:20<00:39, 164.27it/s]Running 10000 simulations.:  35%|███▍      | 3477/10000 [00:20<00:39, 165.21it/s]Running 10000 simulations.:  35%|███▍      | 3494/10000 [00:20<00:39, 165.64it/s]Running 10000 simulations.:  35%|███▌      | 3511/10000 [00:20<00:39, 166.13it/s]Running 10000 simulations.:  35%|███▌      | 3528/10000 [00:20<00:38, 166.12it/s]Running 10000 simulations.:  35%|███▌      | 3545/10000 [00:21<00:38, 166.79it/s]Running 10000 simulations.:  36%|███▌      | 3562/10000 [00:21<00:38, 166.32it/s]Running 10000 simulations.:  36%|███▌      | 3579/10000 [00:21<00:38, 166.09it/s]Running 10000 simulations.:  36%|███▌      | 3596/10000 [00:21<00:38, 166.01it/s]Running 10000 simulations.:  36%|███▌      | 3613/10000 [00:21<00:38, 166.25it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:21<00:38, 166.35it/s]Running 10000 simulations.:  36%|███▋      | 3647/10000 [00:21<00:38, 166.33it/s]Running 10000 simulations.:  37%|███▋      | 3664/10000 [00:21<00:38, 165.88it/s]Running 10000 simulations.:  37%|███▋      | 3681/10000 [00:21<00:37, 166.30it/s]Running 10000 simulations.:  37%|███▋      | 3698/10000 [00:21<00:37, 166.40it/s]Running 10000 simulations.:  37%|███▋      | 3715/10000 [00:22<00:37, 166.43it/s]Running 10000 simulations.:  37%|███▋      | 3732/10000 [00:22<00:37, 166.10it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:22<00:37, 166.16it/s]Running 10000 simulations.:  38%|███▊      | 3766/10000 [00:22<00:37, 165.93it/s]Running 10000 simulations.:  38%|███▊      | 3783/10000 [00:22<00:37, 165.89it/s]Running 10000 simulations.:  38%|███▊      | 3800/10000 [00:22<00:37, 165.72it/s]Running 10000 simulations.:  38%|███▊      | 3817/10000 [00:22<00:37, 165.66it/s]Running 10000 simulations.:  38%|███▊      | 3834/10000 [00:22<00:37, 165.41it/s]Running 10000 simulations.:  39%|███▊      | 3851/10000 [00:22<00:37, 165.42it/s]Running 10000 simulations.:  39%|███▊      | 3868/10000 [00:22<00:36, 165.75it/s]Running 10000 simulations.:  39%|███▉      | 3885/10000 [00:23<00:37, 165.26it/s]Running 10000 simulations.:  39%|███▉      | 3902/10000 [00:23<00:36, 165.22it/s]Running 10000 simulations.:  39%|███▉      | 3919/10000 [00:23<00:36, 165.22it/s]Running 10000 simulations.:  39%|███▉      | 3936/10000 [00:23<00:36, 165.28it/s]Running 10000 simulations.:  40%|███▉      | 3953/10000 [00:23<00:36, 165.46it/s]Running 10000 simulations.:  40%|███▉      | 3970/10000 [00:23<00:36, 165.59it/s]Running 10000 simulations.:  40%|███▉      | 3987/10000 [00:23<00:36, 165.60it/s]Running 10000 simulations.:  40%|████      | 4004/10000 [00:23<00:36, 165.38it/s]Running 10000 simulations.:  40%|████      | 4021/10000 [00:23<00:36, 165.31it/s]Running 10000 simulations.:  40%|████      | 4038/10000 [00:24<00:35, 165.62it/s]Running 10000 simulations.:  41%|████      | 4055/10000 [00:24<00:35, 166.01it/s]Running 10000 simulations.:  41%|████      | 4072/10000 [00:24<00:35, 166.53it/s]Running 10000 simulations.:  41%|████      | 4089/10000 [00:24<00:35, 166.98it/s]Running 10000 simulations.:  41%|████      | 4106/10000 [00:24<00:35, 167.17it/s]Running 10000 simulations.:  41%|████      | 4123/10000 [00:24<00:35, 166.70it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:24<00:35, 166.32it/s]Running 10000 simulations.:  42%|████▏     | 4157/10000 [00:24<00:35, 166.61it/s]Running 10000 simulations.:  42%|████▏     | 4174/10000 [00:24<00:34, 166.66it/s]Running 10000 simulations.:  42%|████▏     | 4191/10000 [00:24<00:34, 167.04it/s]Running 10000 simulations.:  42%|████▏     | 4208/10000 [00:25<00:34, 166.54it/s]Running 10000 simulations.:  42%|████▏     | 4225/10000 [00:25<00:34, 166.58it/s]Running 10000 simulations.:  42%|████▏     | 4242/10000 [00:25<00:34, 166.82it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:25<00:34, 167.11it/s]Running 10000 simulations.:  43%|████▎     | 4276/10000 [00:25<00:34, 167.34it/s]Running 10000 simulations.:  43%|████▎     | 4293/10000 [00:25<00:34, 167.54it/s]Running 10000 simulations.:  43%|████▎     | 4310/10000 [00:25<00:33, 167.72it/s]Running 10000 simulations.:  43%|████▎     | 4327/10000 [00:25<00:33, 167.62it/s]Running 10000 simulations.:  43%|████▎     | 4344/10000 [00:25<00:33, 167.27it/s]Running 10000 simulations.:  44%|████▎     | 4361/10000 [00:25<00:33, 166.85it/s]Running 10000 simulations.:  44%|████▍     | 4378/10000 [00:26<00:33, 166.41it/s]Running 10000 simulations.:  44%|████▍     | 4395/10000 [00:26<00:33, 166.10it/s]Running 10000 simulations.:  44%|████▍     | 4412/10000 [00:26<00:33, 165.91it/s]Running 10000 simulations.:  44%|████▍     | 4429/10000 [00:26<00:33, 166.04it/s]Running 10000 simulations.:  44%|████▍     | 4446/10000 [00:26<00:33, 166.11it/s]Running 10000 simulations.:  45%|████▍     | 4463/10000 [00:26<00:33, 166.34it/s]Running 10000 simulations.:  45%|████▍     | 4480/10000 [00:26<00:33, 166.49it/s]Running 10000 simulations.:  45%|████▍     | 4497/10000 [00:26<00:33, 166.72it/s]Running 10000 simulations.:  45%|████▌     | 4514/10000 [00:26<00:32, 166.40it/s]Running 10000 simulations.:  45%|████▌     | 4531/10000 [00:26<00:32, 165.95it/s]Running 10000 simulations.:  45%|████▌     | 4548/10000 [00:27<00:32, 165.77it/s]Running 10000 simulations.:  46%|████▌     | 4565/10000 [00:27<00:32, 166.13it/s]Running 10000 simulations.:  46%|████▌     | 4582/10000 [00:27<00:32, 166.26it/s]Running 10000 simulations.:  46%|████▌     | 4599/10000 [00:27<00:32, 165.99it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:27<00:32, 166.07it/s]Running 10000 simulations.:  46%|████▋     | 4633/10000 [00:27<00:32, 166.36it/s]Running 10000 simulations.:  46%|████▋     | 4650/10000 [00:27<00:32, 166.38it/s]Running 10000 simulations.:  47%|████▋     | 4667/10000 [00:27<00:32, 166.17it/s]Running 10000 simulations.:  47%|████▋     | 4684/10000 [00:27<00:31, 166.21it/s]Running 10000 simulations.:  47%|████▋     | 4701/10000 [00:27<00:31, 165.82it/s]Running 10000 simulations.:  47%|████▋     | 4718/10000 [00:28<00:31, 165.59it/s]Running 10000 simulations.:  47%|████▋     | 4735/10000 [00:28<00:31, 165.47it/s]Running 10000 simulations.:  48%|████▊     | 4752/10000 [00:28<00:31, 165.69it/s]Running 10000 simulations.:  48%|████▊     | 4769/10000 [00:28<00:31, 165.56it/s]Running 10000 simulations.:  48%|████▊     | 4786/10000 [00:28<00:31, 165.50it/s]Running 10000 simulations.:  48%|████▊     | 4803/10000 [00:28<00:31, 165.44it/s]Running 10000 simulations.:  48%|████▊     | 4820/10000 [00:28<00:31, 165.27it/s]Running 10000 simulations.:  48%|████▊     | 4837/10000 [00:28<00:31, 166.06it/s]Running 10000 simulations.:  49%|████▊     | 4855/10000 [00:28<00:30, 169.74it/s]Running 10000 simulations.:  49%|████▊     | 4873/10000 [00:29<00:30, 170.83it/s]Running 10000 simulations.:  49%|████▉     | 4891/10000 [00:29<00:30, 169.45it/s]Running 10000 simulations.:  49%|████▉     | 4908/10000 [00:29<00:30, 168.83it/s]Running 10000 simulations.:  49%|████▉     | 4925/10000 [00:29<00:30, 168.60it/s]Running 10000 simulations.:  49%|████▉     | 4942/10000 [00:29<00:30, 168.04it/s]Running 10000 simulations.:  50%|████▉     | 4959/10000 [00:29<00:30, 167.17it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:29<00:30, 166.52it/s]Running 10000 simulations.:  50%|████▉     | 4993/10000 [00:29<00:30, 166.33it/s]Running 10000 simulations.:  50%|█████     | 5010/10000 [00:29<00:29, 167.25it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:29<00:29, 167.69it/s]Running 10000 simulations.:  50%|█████     | 5044/10000 [00:30<00:29, 167.31it/s]Running 10000 simulations.:  51%|█████     | 5061/10000 [00:30<00:29, 166.72it/s]Running 10000 simulations.:  51%|█████     | 5078/10000 [00:30<00:29, 166.42it/s]Running 10000 simulations.:  51%|█████     | 5095/10000 [00:30<00:29, 166.23it/s]Running 10000 simulations.:  51%|█████     | 5112/10000 [00:30<00:29, 166.20it/s]Running 10000 simulations.:  51%|█████▏    | 5129/10000 [00:30<00:29, 166.49it/s]Running 10000 simulations.:  51%|█████▏    | 5146/10000 [00:30<00:29, 166.64it/s]Running 10000 simulations.:  52%|█████▏    | 5163/10000 [00:30<00:29, 166.71it/s]Running 10000 simulations.:  52%|█████▏    | 5180/10000 [00:30<00:28, 166.29it/s]Running 10000 simulations.:  52%|█████▏    | 5197/10000 [00:30<00:28, 166.49it/s]Running 10000 simulations.:  52%|█████▏    | 5214/10000 [00:31<00:28, 166.28it/s]Running 10000 simulations.:  52%|█████▏    | 5231/10000 [00:31<00:28, 166.10it/s]Running 10000 simulations.:  52%|█████▏    | 5248/10000 [00:31<00:28, 166.40it/s]Running 10000 simulations.:  53%|█████▎    | 5265/10000 [00:31<00:28, 166.57it/s]Running 10000 simulations.:  53%|█████▎    | 5282/10000 [00:31<00:28, 166.57it/s]Running 10000 simulations.:  53%|█████▎    | 5299/10000 [00:31<00:28, 166.69it/s]Running 10000 simulations.:  53%|█████▎    | 5316/10000 [00:31<00:28, 167.17it/s]Running 10000 simulations.:  53%|█████▎    | 5333/10000 [00:31<00:27, 167.38it/s]Running 10000 simulations.:  54%|█████▎    | 5350/10000 [00:31<00:27, 167.71it/s]Running 10000 simulations.:  54%|█████▎    | 5367/10000 [00:31<00:27, 167.76it/s]Running 10000 simulations.:  54%|█████▍    | 5384/10000 [00:32<00:27, 167.68it/s]Running 10000 simulations.:  54%|█████▍    | 5401/10000 [00:32<00:27, 167.79it/s]Running 10000 simulations.:  54%|█████▍    | 5418/10000 [00:32<00:27, 168.06it/s]Running 10000 simulations.:  54%|█████▍    | 5435/10000 [00:32<00:27, 168.19it/s]Running 10000 simulations.:  55%|█████▍    | 5452/10000 [00:32<00:27, 168.19it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:32<00:26, 168.24it/s]Running 10000 simulations.:  55%|█████▍    | 5486/10000 [00:32<00:26, 168.07it/s]Running 10000 simulations.:  55%|█████▌    | 5503/10000 [00:32<00:26, 168.03it/s]Running 10000 simulations.:  55%|█████▌    | 5520/10000 [00:32<00:26, 167.60it/s]Running 10000 simulations.:  55%|█████▌    | 5537/10000 [00:32<00:26, 167.12it/s]Running 10000 simulations.:  56%|█████▌    | 5554/10000 [00:33<00:26, 166.96it/s]Running 10000 simulations.:  56%|█████▌    | 5571/10000 [00:33<00:26, 167.35it/s]Running 10000 simulations.:  56%|█████▌    | 5588/10000 [00:33<00:26, 167.58it/s]Running 10000 simulations.:  56%|█████▌    | 5605/10000 [00:33<00:26, 167.75it/s]Running 10000 simulations.:  56%|█████▌    | 5622/10000 [00:33<00:26, 167.56it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:33<00:26, 167.04it/s]Running 10000 simulations.:  57%|█████▋    | 5656/10000 [00:33<00:26, 166.55it/s]Running 10000 simulations.:  57%|█████▋    | 5673/10000 [00:33<00:25, 166.57it/s]Running 10000 simulations.:  57%|█████▋    | 5690/10000 [00:33<00:25, 166.22it/s]Running 10000 simulations.:  57%|█████▋    | 5707/10000 [00:34<00:25, 166.78it/s]Running 10000 simulations.:  57%|█████▋    | 5724/10000 [00:34<00:25, 166.82it/s]Running 10000 simulations.:  57%|█████▋    | 5741/10000 [00:34<00:25, 166.51it/s]Running 10000 simulations.:  58%|█████▊    | 5758/10000 [00:34<00:25, 166.51it/s]Running 10000 simulations.:  58%|█████▊    | 5775/10000 [00:34<00:25, 166.23it/s]Running 10000 simulations.:  58%|█████▊    | 5792/10000 [00:34<00:25, 166.45it/s]Running 10000 simulations.:  58%|█████▊    | 5809/10000 [00:34<00:25, 166.78it/s]Running 10000 simulations.:  58%|█████▊    | 5826/10000 [00:34<00:25, 166.57it/s]Running 10000 simulations.:  58%|█████▊    | 5843/10000 [00:34<00:24, 166.30it/s]Running 10000 simulations.:  59%|█████▊    | 5860/10000 [00:34<00:24, 166.08it/s]Running 10000 simulations.:  59%|█████▉    | 5877/10000 [00:35<00:24, 166.09it/s]Running 10000 simulations.:  59%|█████▉    | 5894/10000 [00:35<00:24, 164.60it/s]Running 10000 simulations.:  59%|█████▉    | 5911/10000 [00:35<00:24, 165.07it/s]Running 10000 simulations.:  59%|█████▉    | 5928/10000 [00:35<00:24, 165.52it/s]Running 10000 simulations.:  59%|█████▉    | 5945/10000 [00:35<00:24, 165.92it/s]Running 10000 simulations.:  60%|█████▉    | 5962/10000 [00:35<00:24, 166.12it/s]Running 10000 simulations.:  60%|█████▉    | 5979/10000 [00:35<00:24, 166.23it/s]Running 10000 simulations.:  60%|█████▉    | 5996/10000 [00:35<00:24, 166.41it/s]Running 10000 simulations.:  60%|██████    | 6013/10000 [00:35<00:23, 166.17it/s]Running 10000 simulations.:  60%|██████    | 6030/10000 [00:35<00:23, 166.68it/s]Running 10000 simulations.:  60%|██████    | 6047/10000 [00:36<00:23, 167.04it/s]Running 10000 simulations.:  61%|██████    | 6064/10000 [00:36<00:23, 166.69it/s]Running 10000 simulations.:  61%|██████    | 6081/10000 [00:36<00:23, 166.63it/s]Running 10000 simulations.:  61%|██████    | 6098/10000 [00:36<00:23, 166.38it/s]Running 10000 simulations.:  61%|██████    | 6115/10000 [00:36<00:23, 166.16it/s]Running 10000 simulations.:  61%|██████▏   | 6132/10000 [00:36<00:23, 166.07it/s]Running 10000 simulations.:  61%|██████▏   | 6149/10000 [00:36<00:23, 166.38it/s]Running 10000 simulations.:  62%|██████▏   | 6166/10000 [00:36<00:22, 166.79it/s]Running 10000 simulations.:  62%|██████▏   | 6183/10000 [00:36<00:22, 166.29it/s]Running 10000 simulations.:  62%|██████▏   | 6200/10000 [00:36<00:22, 166.00it/s]Running 10000 simulations.:  62%|██████▏   | 6217/10000 [00:37<00:22, 165.63it/s]Running 10000 simulations.:  62%|██████▏   | 6234/10000 [00:37<00:22, 165.92it/s]Running 10000 simulations.:  63%|██████▎   | 6251/10000 [00:37<00:22, 165.94it/s]Running 10000 simulations.:  63%|██████▎   | 6268/10000 [00:37<00:22, 165.91it/s]Running 10000 simulations.:  63%|██████▎   | 6285/10000 [00:37<00:22, 166.00it/s]Running 10000 simulations.:  63%|██████▎   | 6302/10000 [00:37<00:22, 166.14it/s]Running 10000 simulations.:  63%|██████▎   | 6319/10000 [00:37<00:22, 166.26it/s]Running 10000 simulations.:  63%|██████▎   | 6336/10000 [00:37<00:22, 165.64it/s]Running 10000 simulations.:  64%|██████▎   | 6353/10000 [00:37<00:22, 165.34it/s]Running 10000 simulations.:  64%|██████▎   | 6370/10000 [00:38<00:22, 164.88it/s]Running 10000 simulations.:  64%|██████▍   | 6387/10000 [00:38<00:21, 164.36it/s]Running 10000 simulations.:  64%|██████▍   | 6404/10000 [00:38<00:21, 164.63it/s]Running 10000 simulations.:  64%|██████▍   | 6421/10000 [00:38<00:21, 164.15it/s]Running 10000 simulations.:  64%|██████▍   | 6438/10000 [00:38<00:21, 164.05it/s]Running 10000 simulations.:  65%|██████▍   | 6455/10000 [00:38<00:21, 164.17it/s]Running 10000 simulations.:  65%|██████▍   | 6472/10000 [00:38<00:21, 164.76it/s]Running 10000 simulations.:  65%|██████▍   | 6490/10000 [00:38<00:20, 168.22it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:38<00:20, 169.26it/s]Running 10000 simulations.:  65%|██████▌   | 6525/10000 [00:38<00:20, 167.38it/s]Running 10000 simulations.:  65%|██████▌   | 6542/10000 [00:39<00:20, 166.16it/s]Running 10000 simulations.:  66%|██████▌   | 6559/10000 [00:39<00:20, 165.51it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:39<00:20, 164.80it/s]Running 10000 simulations.:  66%|██████▌   | 6593/10000 [00:39<00:20, 164.32it/s]Running 10000 simulations.:  66%|██████▌   | 6610/10000 [00:39<00:20, 164.40it/s]Running 10000 simulations.:  66%|██████▋   | 6627/10000 [00:39<00:20, 164.35it/s]Running 10000 simulations.:  66%|██████▋   | 6644/10000 [00:39<00:20, 164.00it/s]Running 10000 simulations.:  67%|██████▋   | 6661/10000 [00:39<00:20, 164.11it/s]Running 10000 simulations.:  67%|██████▋   | 6678/10000 [00:39<00:20, 164.18it/s]Running 10000 simulations.:  67%|██████▋   | 6695/10000 [00:39<00:20, 164.36it/s]Running 10000 simulations.:  67%|██████▋   | 6712/10000 [00:40<00:20, 164.28it/s]Running 10000 simulations.:  67%|██████▋   | 6729/10000 [00:40<00:19, 164.50it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:40<00:19, 165.06it/s]Running 10000 simulations.:  68%|██████▊   | 6763/10000 [00:40<00:19, 164.75it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:40<00:19, 164.91it/s]Running 10000 simulations.:  68%|██████▊   | 6797/10000 [00:40<00:19, 165.27it/s]Running 10000 simulations.:  68%|██████▊   | 6814/10000 [00:40<00:19, 165.52it/s]Running 10000 simulations.:  68%|██████▊   | 6831/10000 [00:40<00:19, 165.18it/s]Running 10000 simulations.:  68%|██████▊   | 6848/10000 [00:40<00:19, 165.28it/s]Running 10000 simulations.:  69%|██████▊   | 6865/10000 [00:41<00:19, 164.89it/s]Running 10000 simulations.:  69%|██████▉   | 6882/10000 [00:41<00:18, 164.61it/s]Running 10000 simulations.:  69%|██████▉   | 6899/10000 [00:41<00:18, 164.28it/s]Running 10000 simulations.:  69%|██████▉   | 6916/10000 [00:41<00:18, 164.59it/s]Running 10000 simulations.:  69%|██████▉   | 6933/10000 [00:41<00:18, 165.16it/s]Running 10000 simulations.:  70%|██████▉   | 6950/10000 [00:41<00:18, 165.77it/s]Running 10000 simulations.:  70%|██████▉   | 6967/10000 [00:41<00:18, 165.91it/s]Running 10000 simulations.:  70%|██████▉   | 6984/10000 [00:41<00:18, 166.45it/s]Running 10000 simulations.:  70%|███████   | 7001/10000 [00:41<00:18, 166.32it/s]Running 10000 simulations.:  70%|███████   | 7018/10000 [00:41<00:17, 165.89it/s]Running 10000 simulations.:  70%|███████   | 7035/10000 [00:42<00:17, 166.00it/s]Running 10000 simulations.:  71%|███████   | 7052/10000 [00:42<00:17, 165.97it/s]Running 10000 simulations.:  71%|███████   | 7069/10000 [00:42<00:17, 165.94it/s]Running 10000 simulations.:  71%|███████   | 7086/10000 [00:42<00:17, 165.54it/s]Running 10000 simulations.:  71%|███████   | 7103/10000 [00:42<00:17, 165.14it/s]Running 10000 simulations.:  71%|███████   | 7120/10000 [00:42<00:17, 165.47it/s]Running 10000 simulations.:  71%|███████▏  | 7137/10000 [00:42<00:17, 165.50it/s]Running 10000 simulations.:  72%|███████▏  | 7154/10000 [00:42<00:17, 165.28it/s]Running 10000 simulations.:  72%|███████▏  | 7171/10000 [00:42<00:17, 164.83it/s]Running 10000 simulations.:  72%|███████▏  | 7188/10000 [00:42<00:17, 164.98it/s]Running 10000 simulations.:  72%|███████▏  | 7205/10000 [00:43<00:16, 164.69it/s]Running 10000 simulations.:  72%|███████▏  | 7222/10000 [00:43<00:16, 164.66it/s]Running 10000 simulations.:  72%|███████▏  | 7239/10000 [00:43<00:16, 164.36it/s]Running 10000 simulations.:  73%|███████▎  | 7256/10000 [00:43<00:16, 163.89it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:43<00:16, 163.71it/s]Running 10000 simulations.:  73%|███████▎  | 7290/10000 [00:43<00:16, 163.85it/s]Running 10000 simulations.:  73%|███████▎  | 7307/10000 [00:43<00:16, 163.92it/s]Running 10000 simulations.:  73%|███████▎  | 7324/10000 [00:43<00:16, 164.49it/s]Running 10000 simulations.:  73%|███████▎  | 7341/10000 [00:43<00:16, 164.72it/s]Running 10000 simulations.:  74%|███████▎  | 7358/10000 [00:43<00:16, 165.08it/s]Running 10000 simulations.:  74%|███████▍  | 7375/10000 [00:44<00:15, 165.37it/s]Running 10000 simulations.:  74%|███████▍  | 7392/10000 [00:44<00:15, 165.20it/s]Running 10000 simulations.:  74%|███████▍  | 7409/10000 [00:44<00:15, 164.68it/s]Running 10000 simulations.:  74%|███████▍  | 7426/10000 [00:44<00:15, 164.68it/s]Running 10000 simulations.:  74%|███████▍  | 7443/10000 [00:44<00:15, 164.30it/s]Running 10000 simulations.:  75%|███████▍  | 7460/10000 [00:44<00:15, 164.48it/s]Running 10000 simulations.:  75%|███████▍  | 7477/10000 [00:44<00:15, 164.97it/s]Running 10000 simulations.:  75%|███████▍  | 7494/10000 [00:44<00:15, 164.70it/s]Running 10000 simulations.:  75%|███████▌  | 7511/10000 [00:44<00:15, 165.01it/s]Running 10000 simulations.:  75%|███████▌  | 7528/10000 [00:45<00:14, 165.13it/s]Running 10000 simulations.:  75%|███████▌  | 7545/10000 [00:45<00:14, 164.86it/s]Running 10000 simulations.:  76%|███████▌  | 7562/10000 [00:45<00:14, 164.78it/s]Running 10000 simulations.:  76%|███████▌  | 7579/10000 [00:45<00:14, 164.87it/s]Running 10000 simulations.:  76%|███████▌  | 7596/10000 [00:45<00:14, 165.19it/s]Running 10000 simulations.:  76%|███████▌  | 7613/10000 [00:45<00:14, 164.84it/s]Running 10000 simulations.:  76%|███████▋  | 7630/10000 [00:45<00:14, 164.78it/s]Running 10000 simulations.:  76%|███████▋  | 7647/10000 [00:45<00:14, 164.46it/s]Running 10000 simulations.:  77%|███████▋  | 7664/10000 [00:45<00:14, 164.36it/s]Running 10000 simulations.:  77%|███████▋  | 7681/10000 [00:45<00:14, 164.28it/s]Running 10000 simulations.:  77%|███████▋  | 7698/10000 [00:46<00:13, 164.72it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:46<00:13, 164.97it/s]Running 10000 simulations.:  77%|███████▋  | 7732/10000 [00:46<00:13, 165.93it/s]Running 10000 simulations.:  77%|███████▋  | 7749/10000 [00:46<00:13, 165.94it/s]Running 10000 simulations.:  78%|███████▊  | 7766/10000 [00:46<00:13, 165.99it/s]Running 10000 simulations.:  78%|███████▊  | 7783/10000 [00:46<00:13, 166.35it/s]Running 10000 simulations.:  78%|███████▊  | 7800/10000 [00:46<00:13, 166.08it/s]Running 10000 simulations.:  78%|███████▊  | 7817/10000 [00:46<00:13, 165.71it/s]Running 10000 simulations.:  78%|███████▊  | 7834/10000 [00:46<00:13, 165.53it/s]Running 10000 simulations.:  79%|███████▊  | 7851/10000 [00:46<00:13, 165.17it/s]Running 10000 simulations.:  79%|███████▊  | 7868/10000 [00:47<00:12, 164.67it/s]Running 10000 simulations.:  79%|███████▉  | 7885/10000 [00:47<00:12, 164.62it/s]Running 10000 simulations.:  79%|███████▉  | 7902/10000 [00:47<00:12, 164.80it/s]Running 10000 simulations.:  79%|███████▉  | 7919/10000 [00:47<00:12, 164.78it/s]Running 10000 simulations.:  79%|███████▉  | 7936/10000 [00:47<00:12, 165.33it/s]Running 10000 simulations.:  80%|███████▉  | 7953/10000 [00:47<00:12, 165.46it/s]Running 10000 simulations.:  80%|███████▉  | 7970/10000 [00:47<00:12, 164.94it/s]Running 10000 simulations.:  80%|███████▉  | 7987/10000 [00:47<00:12, 165.20it/s]Running 10000 simulations.:  80%|████████  | 8004/10000 [00:47<00:12, 164.89it/s]Running 10000 simulations.:  80%|████████  | 8021/10000 [00:48<00:12, 164.57it/s]Running 10000 simulations.:  80%|████████  | 8038/10000 [00:48<00:11, 164.53it/s]Running 10000 simulations.:  81%|████████  | 8055/10000 [00:48<00:11, 164.14it/s]Running 10000 simulations.:  81%|████████  | 8072/10000 [00:48<00:11, 164.13it/s]Running 10000 simulations.:  81%|████████  | 8089/10000 [00:48<00:11, 164.09it/s]Running 10000 simulations.:  81%|████████  | 8106/10000 [00:48<00:11, 164.06it/s]Running 10000 simulations.:  81%|████████  | 8123/10000 [00:48<00:11, 163.83it/s]Running 10000 simulations.:  81%|████████▏ | 8140/10000 [00:48<00:11, 164.18it/s]Running 10000 simulations.:  82%|████████▏ | 8157/10000 [00:48<00:11, 164.90it/s]Running 10000 simulations.:  82%|████████▏ | 8174/10000 [00:48<00:11, 165.04it/s]Running 10000 simulations.:  82%|████████▏ | 8191/10000 [00:49<00:10, 165.49it/s]Running 10000 simulations.:  82%|████████▏ | 8208/10000 [00:49<00:10, 165.73it/s]Running 10000 simulations.:  82%|████████▏ | 8225/10000 [00:49<00:10, 166.00it/s]Running 10000 simulations.:  82%|████████▏ | 8242/10000 [00:49<00:10, 166.28it/s]Running 10000 simulations.:  83%|████████▎ | 8259/10000 [00:49<00:10, 166.41it/s]Running 10000 simulations.:  83%|████████▎ | 8277/10000 [00:49<00:10, 168.54it/s]Running 10000 simulations.:  83%|████████▎ | 8296/10000 [00:49<00:09, 171.82it/s]Running 10000 simulations.:  83%|████████▎ | 8314/10000 [00:49<00:09, 169.92it/s]Running 10000 simulations.:  83%|████████▎ | 8332/10000 [00:49<00:09, 168.87it/s]Running 10000 simulations.:  83%|████████▎ | 8349/10000 [00:49<00:09, 168.25it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [00:50<00:09, 166.65it/s]Running 10000 simulations.:  84%|████████▍ | 8383/10000 [00:50<00:10, 160.04it/s]Running 10000 simulations.:  84%|████████▍ | 8400/10000 [00:50<00:09, 162.76it/s]Running 10000 simulations.:  84%|████████▍ | 8417/10000 [00:50<00:09, 164.78it/s]Running 10000 simulations.:  84%|████████▍ | 8434/10000 [00:50<00:09, 165.69it/s]Running 10000 simulations.:  85%|████████▍ | 8451/10000 [00:50<00:09, 166.16it/s]Running 10000 simulations.:  85%|████████▍ | 8468/10000 [00:50<00:09, 165.85it/s]Running 10000 simulations.:  85%|████████▍ | 8485/10000 [00:50<00:09, 166.02it/s]Running 10000 simulations.:  85%|████████▌ | 8502/10000 [00:50<00:08, 166.59it/s]Running 10000 simulations.:  85%|████████▌ | 8519/10000 [00:51<00:08, 167.10it/s]Running 10000 simulations.:  85%|████████▌ | 8536/10000 [00:51<00:08, 166.76it/s]Running 10000 simulations.:  86%|████████▌ | 8553/10000 [00:51<00:08, 166.46it/s]Running 10000 simulations.:  86%|████████▌ | 8570/10000 [00:51<00:08, 166.36it/s]Running 10000 simulations.:  86%|████████▌ | 8587/10000 [00:51<00:08, 165.59it/s]Running 10000 simulations.:  86%|████████▌ | 8604/10000 [00:51<00:08, 164.79it/s]Running 10000 simulations.:  86%|████████▌ | 8621/10000 [00:51<00:08, 165.07it/s]Running 10000 simulations.:  86%|████████▋ | 8638/10000 [00:51<00:08, 165.21it/s]Running 10000 simulations.:  87%|████████▋ | 8655/10000 [00:51<00:08, 165.10it/s]Running 10000 simulations.:  87%|████████▋ | 8672/10000 [00:51<00:08, 165.27it/s]Running 10000 simulations.:  87%|████████▋ | 8689/10000 [00:52<00:07, 165.88it/s]Running 10000 simulations.:  87%|████████▋ | 8706/10000 [00:52<00:07, 166.58it/s]Running 10000 simulations.:  87%|████████▋ | 8723/10000 [00:52<00:07, 166.88it/s]Running 10000 simulations.:  87%|████████▋ | 8740/10000 [00:52<00:07, 166.31it/s]Running 10000 simulations.:  88%|████████▊ | 8757/10000 [00:52<00:07, 165.46it/s]Running 10000 simulations.:  88%|████████▊ | 8774/10000 [00:52<00:07, 165.83it/s]Running 10000 simulations.:  88%|████████▊ | 8791/10000 [00:52<00:07, 165.41it/s]Running 10000 simulations.:  88%|████████▊ | 8808/10000 [00:52<00:07, 165.33it/s]Running 10000 simulations.:  88%|████████▊ | 8825/10000 [00:52<00:07, 165.23it/s]Running 10000 simulations.:  88%|████████▊ | 8842/10000 [00:52<00:06, 165.86it/s]Running 10000 simulations.:  89%|████████▊ | 8859/10000 [00:53<00:06, 166.03it/s]Running 10000 simulations.:  89%|████████▉ | 8876/10000 [00:53<00:06, 165.89it/s]Running 10000 simulations.:  89%|████████▉ | 8893/10000 [00:53<00:06, 165.42it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [00:53<00:06, 164.86it/s]Running 10000 simulations.:  89%|████████▉ | 8927/10000 [00:53<00:06, 164.81it/s]Running 10000 simulations.:  89%|████████▉ | 8944/10000 [00:53<00:06, 165.09it/s]Running 10000 simulations.:  90%|████████▉ | 8961/10000 [00:53<00:06, 165.19it/s]Running 10000 simulations.:  90%|████████▉ | 8978/10000 [00:53<00:06, 165.54it/s]Running 10000 simulations.:  90%|████████▉ | 8995/10000 [00:53<00:06, 165.94it/s]Running 10000 simulations.:  90%|█████████ | 9012/10000 [00:53<00:05, 166.19it/s]Running 10000 simulations.:  90%|█████████ | 9029/10000 [00:54<00:05, 166.38it/s]Running 10000 simulations.:  90%|█████████ | 9046/10000 [00:54<00:05, 166.41it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [00:54<00:05, 166.05it/s]Running 10000 simulations.:  91%|█████████ | 9080/10000 [00:54<00:05, 165.42it/s]Running 10000 simulations.:  91%|█████████ | 9097/10000 [00:54<00:05, 166.36it/s]Running 10000 simulations.:  91%|█████████ | 9114/10000 [00:54<00:05, 166.28it/s]Running 10000 simulations.:  91%|█████████▏| 9131/10000 [00:54<00:05, 165.75it/s]Running 10000 simulations.:  91%|█████████▏| 9148/10000 [00:54<00:05, 166.59it/s]Running 10000 simulations.:  92%|█████████▏| 9165/10000 [00:54<00:05, 166.99it/s]Running 10000 simulations.:  92%|█████████▏| 9182/10000 [00:55<00:04, 167.36it/s]Running 10000 simulations.:  92%|█████████▏| 9199/10000 [00:55<00:04, 166.88it/s]Running 10000 simulations.:  92%|█████████▏| 9216/10000 [00:55<00:04, 166.64it/s]Running 10000 simulations.:  92%|█████████▏| 9233/10000 [00:55<00:04, 166.49it/s]Running 10000 simulations.:  92%|█████████▎| 9250/10000 [00:55<00:04, 166.69it/s]Running 10000 simulations.:  93%|█████████▎| 9267/10000 [00:55<00:04, 166.60it/s]Running 10000 simulations.:  93%|█████████▎| 9284/10000 [00:55<00:04, 165.92it/s]Running 10000 simulations.:  93%|█████████▎| 9301/10000 [00:55<00:04, 166.23it/s]Running 10000 simulations.:  93%|█████████▎| 9318/10000 [00:55<00:04, 167.00it/s]Running 10000 simulations.:  93%|█████████▎| 9335/10000 [00:55<00:03, 166.88it/s]Running 10000 simulations.:  94%|█████████▎| 9352/10000 [00:56<00:03, 167.20it/s]Running 10000 simulations.:  94%|█████████▎| 9369/10000 [00:56<00:03, 166.88it/s]Running 10000 simulations.:  94%|█████████▍| 9386/10000 [00:56<00:03, 166.22it/s]Running 10000 simulations.:  94%|█████████▍| 9403/10000 [00:56<00:03, 165.99it/s]Running 10000 simulations.:  94%|█████████▍| 9420/10000 [00:56<00:03, 166.12it/s]Running 10000 simulations.:  94%|█████████▍| 9437/10000 [00:56<00:03, 165.90it/s]Running 10000 simulations.:  95%|█████████▍| 9454/10000 [00:56<00:03, 165.54it/s]Running 10000 simulations.:  95%|█████████▍| 9471/10000 [00:56<00:03, 165.48it/s]Running 10000 simulations.:  95%|█████████▍| 9488/10000 [00:56<00:03, 165.63it/s]Running 10000 simulations.:  95%|█████████▌| 9505/10000 [00:56<00:02, 165.53it/s]Running 10000 simulations.:  95%|█████████▌| 9522/10000 [00:57<00:02, 165.31it/s]Running 10000 simulations.:  95%|█████████▌| 9539/10000 [00:57<00:02, 165.16it/s]Running 10000 simulations.:  96%|█████████▌| 9556/10000 [00:57<00:02, 165.14it/s]Running 10000 simulations.:  96%|█████████▌| 9573/10000 [00:57<00:02, 165.09it/s]Running 10000 simulations.:  96%|█████████▌| 9590/10000 [00:57<00:02, 165.03it/s]Running 10000 simulations.:  96%|█████████▌| 9607/10000 [00:57<00:02, 165.04it/s]Running 10000 simulations.:  96%|█████████▌| 9624/10000 [00:57<00:02, 164.88it/s]Running 10000 simulations.:  96%|█████████▋| 9641/10000 [00:57<00:02, 165.03it/s]Running 10000 simulations.:  97%|█████████▋| 9658/10000 [00:57<00:02, 165.40it/s]Running 10000 simulations.:  97%|█████████▋| 9675/10000 [00:57<00:01, 165.65it/s]Running 10000 simulations.:  97%|█████████▋| 9692/10000 [00:58<00:01, 165.83it/s]Running 10000 simulations.:  97%|█████████▋| 9709/10000 [00:58<00:01, 166.13it/s]Running 10000 simulations.:  97%|█████████▋| 9726/10000 [00:58<00:01, 166.44it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [00:58<00:01, 167.43it/s]Running 10000 simulations.:  98%|█████████▊| 9760/10000 [00:58<00:01, 167.54it/s]Running 10000 simulations.:  98%|█████████▊| 9777/10000 [00:58<00:01, 167.59it/s]Running 10000 simulations.:  98%|█████████▊| 9794/10000 [00:58<00:01, 167.36it/s]Running 10000 simulations.:  98%|█████████▊| 9811/10000 [00:58<00:01, 167.30it/s]Running 10000 simulations.:  98%|█████████▊| 9828/10000 [00:58<00:01, 167.42it/s]Running 10000 simulations.:  98%|█████████▊| 9845/10000 [00:59<00:00, 167.26it/s]Running 10000 simulations.:  99%|█████████▊| 9862/10000 [00:59<00:00, 166.83it/s]Running 10000 simulations.:  99%|█████████▉| 9879/10000 [00:59<00:00, 167.00it/s]Running 10000 simulations.:  99%|█████████▉| 9896/10000 [00:59<00:00, 167.35it/s]Running 10000 simulations.:  99%|█████████▉| 9914/10000 [00:59<00:00, 170.15it/s]Running 10000 simulations.:  99%|█████████▉| 9933/10000 [00:59<00:00, 174.00it/s]Running 10000 simulations.: 100%|█████████▉| 9951/10000 [00:59<00:00, 171.79it/s]Running 10000 simulations.: 100%|█████████▉| 9969/10000 [00:59<00:00, 170.39it/s]Running 10000 simulations.: 100%|█████████▉| 9987/10000 [00:59<00:00, 169.84it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:59<00:00, 166.91it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<00:33, 293.39it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<00:33, 294.39it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<00:33, 294.12it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<00:33, 294.75it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:33, 294.86it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:00<00:33, 295.50it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:00<00:33, 295.88it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:00<00:32, 295.97it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:00<00:32, 296.08it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:01<00:32, 295.51it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:01<00:32, 294.05it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:01<00:32, 293.45it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:32, 294.09it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:32, 293.84it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:01<00:32, 293.92it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:01<00:32, 294.33it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:01<00:32, 294.30it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:01<00:32, 293.71it/s]Running 10000 simulations.:   6%|▌         | 570/10000 [00:01<00:32, 292.84it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:02<00:32, 292.01it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:02<00:31, 292.85it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:02<00:31, 294.06it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:02<00:31, 294.66it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:02<00:31, 295.12it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:02<00:31, 295.90it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:02<00:31, 295.51it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:02<00:31, 294.89it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:02<00:30, 295.57it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:02<00:30, 296.00it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:30, 296.48it/s]Running 10000 simulations.:   9%|▉         | 930/10000 [00:03<00:30, 296.19it/s]Running 10000 simulations.:  10%|▉         | 960/10000 [00:03<00:30, 295.90it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:03<00:30, 295.64it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:03<00:30, 294.50it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:03<00:30, 294.21it/s]Running 10000 simulations.:  11%|█         | 1080/10000 [00:03<00:30, 294.21it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:03<00:30, 294.27it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:03<00:30, 293.61it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:03<00:30, 293.16it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:29, 293.86it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:04<00:29, 294.27it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:04<00:29, 294.63it/s]Running 10000 simulations.:  13%|█▎        | 1290/10000 [00:04<00:29, 295.02it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:04<00:29, 295.85it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:04<00:29, 296.38it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:04<00:29, 295.89it/s]Running 10000 simulations.:  14%|█▍        | 1410/10000 [00:04<00:29, 294.47it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:04<00:29, 294.53it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:04<00:28, 295.43it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:05<00:28, 296.21it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:05<00:28, 296.55it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:05<00:28, 296.28it/s]Running 10000 simulations.:  16%|█▌        | 1590/10000 [00:05<00:28, 296.62it/s]Running 10000 simulations.:  16%|█▌        | 1620/10000 [00:05<00:28, 296.85it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:05<00:28, 296.90it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:05<00:28, 296.89it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:05<00:27, 297.02it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:05<00:27, 295.23it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:06<00:27, 294.23it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:06<00:27, 294.53it/s]Running 10000 simulations.:  18%|█▊        | 1830/10000 [00:06<00:27, 295.28it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:06<00:27, 295.90it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:06<00:27, 296.09it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:06<00:27, 296.56it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:06<00:27, 296.77it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:06<00:27, 296.67it/s]Running 10000 simulations.:  20%|██        | 2010/10000 [00:06<00:26, 296.76it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:06<00:26, 297.07it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:07<00:26, 297.13it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:07<00:26, 296.92it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:07<00:26, 297.14it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:07<00:26, 296.68it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:07<00:26, 295.36it/s]Running 10000 simulations.:  22%|██▏       | 2220/10000 [00:07<00:26, 294.82it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:07<00:26, 294.23it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:07<00:26, 292.72it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:07<00:26, 291.42it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:07<00:26, 291.35it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:08<00:26, 291.87it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:08<00:26, 292.21it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:08<00:25, 291.42it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:08<00:25, 291.17it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:08<00:25, 292.08it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:08<00:25, 293.21it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:08<00:25, 293.69it/s]Running 10000 simulations.:  26%|██▌       | 2580/10000 [00:08<00:25, 294.04it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:08<00:25, 294.68it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:08<00:24, 294.95it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:09<00:24, 294.44it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:09<00:24, 294.11it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:09<00:24, 292.79it/s]Running 10000 simulations.:  28%|██▊       | 2760/10000 [00:09<00:24, 292.53it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:09<00:24, 292.38it/s]Running 10000 simulations.:  28%|██▊       | 2820/10000 [00:09<00:24, 292.92it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:09<00:24, 293.83it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:09<00:24, 294.46it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:09<00:24, 294.77it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:09<00:23, 295.04it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:10<00:23, 295.47it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:10<00:23, 295.97it/s]Running 10000 simulations.:  30%|███       | 3030/10000 [00:10<00:23, 296.34it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:10<00:23, 296.59it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:10<00:23, 296.31it/s]Running 10000 simulations.:  31%|███       | 3120/10000 [00:10<00:23, 296.33it/s]Running 10000 simulations.:  32%|███▏      | 3150/10000 [00:10<00:23, 295.32it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:10<00:23, 295.33it/s]Running 10000 simulations.:  32%|███▏      | 3210/10000 [00:10<00:23, 295.17it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:10<00:22, 295.59it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:11<00:22, 296.11it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:11<00:22, 296.36it/s]Running 10000 simulations.:  33%|███▎      | 3330/10000 [00:11<00:22, 296.50it/s]Running 10000 simulations.:  34%|███▎      | 3360/10000 [00:11<00:22, 296.09it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:11<00:22, 294.81it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:11<00:22, 294.89it/s]Running 10000 simulations.:  34%|███▍      | 3450/10000 [00:11<00:22, 295.17it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:11<00:22, 294.51it/s]Running 10000 simulations.:  35%|███▌      | 3510/10000 [00:11<00:22, 292.94it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:12<00:22, 292.00it/s]Running 10000 simulations.:  36%|███▌      | 3570/10000 [00:12<00:21, 292.73it/s]Running 10000 simulations.:  36%|███▌      | 3600/10000 [00:12<00:21, 293.65it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:12<00:21, 294.20it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:12<00:21, 295.14it/s]Running 10000 simulations.:  37%|███▋      | 3690/10000 [00:12<00:21, 295.85it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:12<00:21, 296.17it/s]Running 10000 simulations.:  38%|███▊      | 3750/10000 [00:12<00:21, 296.27it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:12<00:20, 296.21it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:12<00:20, 296.49it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:13<00:20, 296.46it/s]Running 10000 simulations.:  39%|███▊      | 3870/10000 [00:13<00:20, 296.45it/s]Running 10000 simulations.:  39%|███▉      | 3900/10000 [00:13<00:20, 296.59it/s]Running 10000 simulations.:  39%|███▉      | 3930/10000 [00:13<00:20, 296.57it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:13<00:20, 296.69it/s]Running 10000 simulations.:  40%|███▉      | 3990/10000 [00:13<00:20, 296.55it/s]Running 10000 simulations.:  40%|████      | 4020/10000 [00:13<00:20, 296.65it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:13<00:20, 296.52it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:13<00:19, 296.81it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:13<00:19, 296.89it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:14<00:19, 296.49it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:14<00:19, 295.71it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:14<00:19, 294.56it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:14<00:19, 294.25it/s]Running 10000 simulations.:  43%|████▎     | 4260/10000 [00:14<00:19, 293.31it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:14<00:19, 293.85it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:14<00:19, 293.80it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:14<00:19, 294.34it/s]Running 10000 simulations.:  44%|████▍     | 4380/10000 [00:14<00:19, 294.49it/s]Running 10000 simulations.:  44%|████▍     | 4410/10000 [00:14<00:18, 294.62it/s]Running 10000 simulations.:  44%|████▍     | 4440/10000 [00:15<00:18, 295.69it/s]Running 10000 simulations.:  45%|████▍     | 4470/10000 [00:15<00:18, 295.73it/s]Running 10000 simulations.:  45%|████▌     | 4500/10000 [00:15<00:18, 296.05it/s]Running 10000 simulations.:  45%|████▌     | 4530/10000 [00:15<00:18, 295.63it/s]Running 10000 simulations.:  46%|████▌     | 4560/10000 [00:15<00:18, 295.53it/s]Running 10000 simulations.:  46%|████▌     | 4590/10000 [00:15<00:18, 293.70it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:15<00:18, 292.77it/s]Running 10000 simulations.:  46%|████▋     | 4650/10000 [00:15<00:18, 293.06it/s]Running 10000 simulations.:  47%|████▋     | 4680/10000 [00:15<00:18, 294.20it/s]Running 10000 simulations.:  47%|████▋     | 4710/10000 [00:15<00:17, 294.82it/s]Running 10000 simulations.:  47%|████▋     | 4740/10000 [00:16<00:17, 295.20it/s]Running 10000 simulations.:  48%|████▊     | 4770/10000 [00:16<00:17, 292.22it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:16<00:17, 289.17it/s]Running 10000 simulations.:  48%|████▊     | 4829/10000 [00:16<00:18, 286.81it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:16<00:17, 289.64it/s]Running 10000 simulations.:  49%|████▉     | 4888/10000 [00:16<00:17, 288.14it/s]Running 10000 simulations.:  49%|████▉     | 4917/10000 [00:16<00:17, 286.92it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:16<00:17, 285.97it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:16<00:17, 288.39it/s]Running 10000 simulations.:  50%|█████     | 5006/10000 [00:16<00:17, 290.77it/s]Running 10000 simulations.:  50%|█████     | 5036/10000 [00:17<00:17, 291.13it/s]Running 10000 simulations.:  51%|█████     | 5066/10000 [00:17<00:16, 292.90it/s]Running 10000 simulations.:  51%|█████     | 5096/10000 [00:17<00:16, 292.07it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:17<00:16, 291.41it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:17<00:16, 291.04it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:17<00:16, 291.02it/s]Running 10000 simulations.:  52%|█████▏    | 5216/10000 [00:17<00:16, 290.66it/s]Running 10000 simulations.:  52%|█████▏    | 5246/10000 [00:17<00:16, 291.40it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:17<00:16, 292.53it/s]Running 10000 simulations.:  53%|█████▎    | 5306/10000 [00:18<00:15, 293.58it/s]Running 10000 simulations.:  53%|█████▎    | 5336/10000 [00:18<00:15, 293.97it/s]Running 10000 simulations.:  54%|█████▎    | 5366/10000 [00:18<00:15, 293.54it/s]Running 10000 simulations.:  54%|█████▍    | 5396/10000 [00:18<00:15, 294.29it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:18<00:15, 294.66it/s]Running 10000 simulations.:  55%|█████▍    | 5456/10000 [00:18<00:15, 295.23it/s]Running 10000 simulations.:  55%|█████▍    | 5486/10000 [00:18<00:15, 295.72it/s]Running 10000 simulations.:  55%|█████▌    | 5516/10000 [00:18<00:15, 295.87it/s]Running 10000 simulations.:  55%|█████▌    | 5546/10000 [00:18<00:15, 296.22it/s]Running 10000 simulations.:  56%|█████▌    | 5576/10000 [00:18<00:14, 296.29it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:19<00:14, 295.32it/s]Running 10000 simulations.:  56%|█████▋    | 5636/10000 [00:19<00:14, 295.54it/s]Running 10000 simulations.:  57%|█████▋    | 5666/10000 [00:19<00:14, 296.01it/s]Running 10000 simulations.:  57%|█████▋    | 5696/10000 [00:19<00:14, 295.58it/s]Running 10000 simulations.:  57%|█████▋    | 5726/10000 [00:19<00:14, 294.52it/s]Running 10000 simulations.:  58%|█████▊    | 5756/10000 [00:19<00:14, 294.31it/s]Running 10000 simulations.:  58%|█████▊    | 5786/10000 [00:19<00:14, 293.25it/s]Running 10000 simulations.:  58%|█████▊    | 5816/10000 [00:19<00:14, 292.15it/s]Running 10000 simulations.:  58%|█████▊    | 5846/10000 [00:19<00:14, 291.19it/s]Running 10000 simulations.:  59%|█████▉    | 5876/10000 [00:19<00:14, 291.64it/s]Running 10000 simulations.:  59%|█████▉    | 5906/10000 [00:20<00:13, 292.67it/s]Running 10000 simulations.:  59%|█████▉    | 5936/10000 [00:20<00:13, 293.86it/s]Running 10000 simulations.:  60%|█████▉    | 5966/10000 [00:20<00:13, 294.42it/s]Running 10000 simulations.:  60%|█████▉    | 5996/10000 [00:20<00:13, 294.22it/s]Running 10000 simulations.:  60%|██████    | 6026/10000 [00:20<00:13, 294.72it/s]Running 10000 simulations.:  61%|██████    | 6056/10000 [00:20<00:13, 294.76it/s]Running 10000 simulations.:  61%|██████    | 6086/10000 [00:20<00:13, 294.23it/s]Running 10000 simulations.:  61%|██████    | 6116/10000 [00:20<00:13, 285.23it/s]Running 10000 simulations.:  61%|██████▏   | 6146/10000 [00:20<00:13, 287.97it/s]Running 10000 simulations.:  62%|██████▏   | 6176/10000 [00:20<00:13, 289.21it/s]Running 10000 simulations.:  62%|██████▏   | 6206/10000 [00:21<00:13, 290.98it/s]Running 10000 simulations.:  62%|██████▏   | 6236/10000 [00:21<00:12, 292.32it/s]Running 10000 simulations.:  63%|██████▎   | 6266/10000 [00:21<00:12, 291.60it/s]Running 10000 simulations.:  63%|██████▎   | 6296/10000 [00:21<00:12, 290.94it/s]Running 10000 simulations.:  63%|██████▎   | 6326/10000 [00:21<00:12, 291.72it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:21<00:12, 292.39it/s]Running 10000 simulations.:  64%|██████▍   | 6386/10000 [00:21<00:12, 291.26it/s]Running 10000 simulations.:  64%|██████▍   | 6416/10000 [00:21<00:12, 291.00it/s]Running 10000 simulations.:  64%|██████▍   | 6446/10000 [00:21<00:12, 291.49it/s]Running 10000 simulations.:  65%|██████▍   | 6476/10000 [00:22<00:12, 292.56it/s]Running 10000 simulations.:  65%|██████▌   | 6506/10000 [00:22<00:11, 293.50it/s]Running 10000 simulations.:  65%|██████▌   | 6536/10000 [00:22<00:11, 293.57it/s]Running 10000 simulations.:  66%|██████▌   | 6566/10000 [00:22<00:11, 294.10it/s]Running 10000 simulations.:  66%|██████▌   | 6596/10000 [00:22<00:11, 294.12it/s]Running 10000 simulations.:  66%|██████▋   | 6626/10000 [00:22<00:11, 294.17it/s]Running 10000 simulations.:  67%|██████▋   | 6656/10000 [00:22<00:11, 294.67it/s]Running 10000 simulations.:  67%|██████▋   | 6686/10000 [00:22<00:11, 294.44it/s]Running 10000 simulations.:  67%|██████▋   | 6716/10000 [00:22<00:11, 294.63it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:22<00:11, 294.60it/s]Running 10000 simulations.:  68%|██████▊   | 6776/10000 [00:23<00:10, 294.82it/s]Running 10000 simulations.:  68%|██████▊   | 6806/10000 [00:23<00:10, 295.06it/s]Running 10000 simulations.:  68%|██████▊   | 6836/10000 [00:23<00:10, 295.16it/s]Running 10000 simulations.:  69%|██████▊   | 6866/10000 [00:23<00:10, 294.22it/s]Running 10000 simulations.:  69%|██████▉   | 6896/10000 [00:23<00:10, 292.94it/s]Running 10000 simulations.:  69%|██████▉   | 6926/10000 [00:23<00:10, 292.08it/s]Running 10000 simulations.:  70%|██████▉   | 6956/10000 [00:23<00:10, 291.14it/s]Running 10000 simulations.:  70%|██████▉   | 6986/10000 [00:23<00:10, 292.05it/s]Running 10000 simulations.:  70%|███████   | 7016/10000 [00:23<00:10, 293.11it/s]Running 10000 simulations.:  70%|███████   | 7046/10000 [00:23<00:10, 293.87it/s]Running 10000 simulations.:  71%|███████   | 7076/10000 [00:24<00:09, 294.35it/s]Running 10000 simulations.:  71%|███████   | 7106/10000 [00:24<00:09, 294.74it/s]Running 10000 simulations.:  71%|███████▏  | 7136/10000 [00:24<00:09, 294.67it/s]Running 10000 simulations.:  72%|███████▏  | 7166/10000 [00:24<00:09, 293.75it/s]Running 10000 simulations.:  72%|███████▏  | 7196/10000 [00:24<00:09, 294.11it/s]Running 10000 simulations.:  72%|███████▏  | 7226/10000 [00:24<00:09, 294.62it/s]Running 10000 simulations.:  73%|███████▎  | 7256/10000 [00:24<00:09, 294.17it/s]Running 10000 simulations.:  73%|███████▎  | 7286/10000 [00:24<00:09, 294.18it/s]Running 10000 simulations.:  73%|███████▎  | 7316/10000 [00:24<00:09, 293.87it/s]Running 10000 simulations.:  73%|███████▎  | 7346/10000 [00:24<00:09, 292.92it/s]Running 10000 simulations.:  74%|███████▍  | 7376/10000 [00:25<00:08, 292.10it/s]Running 10000 simulations.:  74%|███████▍  | 7406/10000 [00:25<00:08, 291.29it/s]Running 10000 simulations.:  74%|███████▍  | 7436/10000 [00:25<00:08, 290.81it/s]Running 10000 simulations.:  75%|███████▍  | 7466/10000 [00:25<00:08, 291.33it/s]Running 10000 simulations.:  75%|███████▍  | 7496/10000 [00:25<00:08, 292.18it/s]Running 10000 simulations.:  75%|███████▌  | 7526/10000 [00:25<00:08, 293.17it/s]Running 10000 simulations.:  76%|███████▌  | 7556/10000 [00:25<00:08, 293.39it/s]Running 10000 simulations.:  76%|███████▌  | 7586/10000 [00:25<00:08, 292.61it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:25<00:08, 292.86it/s]Running 10000 simulations.:  76%|███████▋  | 7646/10000 [00:25<00:08, 292.72it/s]Running 10000 simulations.:  77%|███████▋  | 7676/10000 [00:26<00:07, 291.55it/s]Running 10000 simulations.:  77%|███████▋  | 7706/10000 [00:26<00:07, 290.96it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:26<00:07, 292.01it/s]Running 10000 simulations.:  78%|███████▊  | 7766/10000 [00:26<00:07, 292.72it/s]Running 10000 simulations.:  78%|███████▊  | 7796/10000 [00:26<00:07, 293.63it/s]Running 10000 simulations.:  78%|███████▊  | 7826/10000 [00:26<00:07, 293.62it/s]Running 10000 simulations.:  79%|███████▊  | 7856/10000 [00:26<00:07, 293.33it/s]Running 10000 simulations.:  79%|███████▉  | 7886/10000 [00:26<00:07, 292.96it/s]Running 10000 simulations.:  79%|███████▉  | 7916/10000 [00:26<00:07, 292.77it/s]Running 10000 simulations.:  79%|███████▉  | 7946/10000 [00:27<00:07, 293.27it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:27<00:06, 293.26it/s]Running 10000 simulations.:  80%|████████  | 8006/10000 [00:27<00:06, 292.80it/s]Running 10000 simulations.:  80%|████████  | 8036/10000 [00:27<00:06, 292.49it/s]Running 10000 simulations.:  81%|████████  | 8066/10000 [00:27<00:06, 292.33it/s]Running 10000 simulations.:  81%|████████  | 8096/10000 [00:27<00:06, 291.82it/s]Running 10000 simulations.:  81%|████████▏ | 8126/10000 [00:27<00:06, 292.06it/s]Running 10000 simulations.:  82%|████████▏ | 8156/10000 [00:27<00:06, 292.82it/s]Running 10000 simulations.:  82%|████████▏ | 8186/10000 [00:27<00:06, 293.36it/s]Running 10000 simulations.:  82%|████████▏ | 8216/10000 [00:27<00:06, 293.84it/s]Running 10000 simulations.:  82%|████████▏ | 8246/10000 [00:28<00:05, 294.10it/s]Running 10000 simulations.:  83%|████████▎ | 8276/10000 [00:28<00:05, 293.77it/s]Running 10000 simulations.:  83%|████████▎ | 8306/10000 [00:28<00:05, 294.40it/s]Running 10000 simulations.:  83%|████████▎ | 8336/10000 [00:28<00:05, 294.22it/s]Running 10000 simulations.:  84%|████████▎ | 8366/10000 [00:28<00:05, 295.16it/s]Running 10000 simulations.:  84%|████████▍ | 8396/10000 [00:28<00:05, 295.65it/s]Running 10000 simulations.:  84%|████████▍ | 8426/10000 [00:28<00:05, 296.02it/s]Running 10000 simulations.:  85%|████████▍ | 8456/10000 [00:28<00:05, 295.97it/s]Running 10000 simulations.:  85%|████████▍ | 8486/10000 [00:28<00:05, 295.71it/s]Running 10000 simulations.:  85%|████████▌ | 8516/10000 [00:28<00:05, 294.92it/s]Running 10000 simulations.:  85%|████████▌ | 8546/10000 [00:29<00:04, 295.16it/s]Running 10000 simulations.:  86%|████████▌ | 8576/10000 [00:29<00:04, 294.47it/s]Running 10000 simulations.:  86%|████████▌ | 8606/10000 [00:29<00:04, 292.83it/s]Running 10000 simulations.:  86%|████████▋ | 8636/10000 [00:29<00:04, 292.10it/s]Running 10000 simulations.:  87%|████████▋ | 8666/10000 [00:29<00:04, 291.81it/s]Running 10000 simulations.:  87%|████████▋ | 8696/10000 [00:29<00:04, 292.24it/s]Running 10000 simulations.:  87%|████████▋ | 8726/10000 [00:29<00:04, 292.88it/s]Running 10000 simulations.:  88%|████████▊ | 8756/10000 [00:29<00:04, 292.91it/s]Running 10000 simulations.:  88%|████████▊ | 8786/10000 [00:29<00:04, 292.86it/s]Running 10000 simulations.:  88%|████████▊ | 8816/10000 [00:29<00:04, 293.37it/s]Running 10000 simulations.:  88%|████████▊ | 8846/10000 [00:30<00:03, 294.01it/s]Running 10000 simulations.:  89%|████████▉ | 8876/10000 [00:30<00:03, 294.98it/s]Running 10000 simulations.:  89%|████████▉ | 8906/10000 [00:30<00:03, 295.00it/s]Running 10000 simulations.:  89%|████████▉ | 8936/10000 [00:30<00:03, 295.30it/s]Running 10000 simulations.:  90%|████████▉ | 8966/10000 [00:30<00:03, 295.29it/s]Running 10000 simulations.:  90%|████████▉ | 8996/10000 [00:30<00:03, 294.45it/s]Running 10000 simulations.:  90%|█████████ | 9026/10000 [00:30<00:03, 293.61it/s]Running 10000 simulations.:  91%|█████████ | 9056/10000 [00:30<00:03, 293.26it/s]Running 10000 simulations.:  91%|█████████ | 9086/10000 [00:30<00:03, 293.21it/s]Running 10000 simulations.:  91%|█████████ | 9116/10000 [00:31<00:03, 293.70it/s]Running 10000 simulations.:  91%|█████████▏| 9146/10000 [00:31<00:02, 294.01it/s]Running 10000 simulations.:  92%|█████████▏| 9176/10000 [00:31<00:02, 294.46it/s]Running 10000 simulations.:  92%|█████████▏| 9206/10000 [00:31<00:02, 294.37it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [00:31<00:02, 293.83it/s]Running 10000 simulations.:  93%|█████████▎| 9266/10000 [00:31<00:02, 293.16it/s]Running 10000 simulations.:  93%|█████████▎| 9296/10000 [00:31<00:02, 292.55it/s]Running 10000 simulations.:  93%|█████████▎| 9326/10000 [00:31<00:02, 293.54it/s]Running 10000 simulations.:  94%|█████████▎| 9356/10000 [00:31<00:02, 294.61it/s]Running 10000 simulations.:  94%|█████████▍| 9387/10000 [00:31<00:02, 296.25it/s]Running 10000 simulations.:  94%|█████████▍| 9418/10000 [00:32<00:01, 297.59it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [00:32<00:01, 298.04it/s]Running 10000 simulations.:  95%|█████████▍| 9478/10000 [00:32<00:01, 297.95it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [00:32<00:01, 297.73it/s]Running 10000 simulations.:  95%|█████████▌| 9538/10000 [00:32<00:01, 298.27it/s]Running 10000 simulations.:  96%|█████████▌| 9569/10000 [00:32<00:01, 298.96it/s]Running 10000 simulations.:  96%|█████████▌| 9599/10000 [00:32<00:01, 297.89it/s]Running 10000 simulations.:  96%|█████████▋| 9629/10000 [00:32<00:01, 298.32it/s]Running 10000 simulations.:  97%|█████████▋| 9660/10000 [00:32<00:01, 299.17it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [00:32<00:01, 298.64it/s]Running 10000 simulations.:  97%|█████████▋| 9721/10000 [00:33<00:00, 299.19it/s]Running 10000 simulations.:  98%|█████████▊| 9752/10000 [00:33<00:00, 299.66it/s]Running 10000 simulations.:  98%|█████████▊| 9782/10000 [00:33<00:00, 299.34it/s]Running 10000 simulations.:  98%|█████████▊| 9812/10000 [00:33<00:00, 299.15it/s]Running 10000 simulations.:  98%|█████████▊| 9843/10000 [00:33<00:00, 299.63it/s]Running 10000 simulations.:  99%|█████████▊| 9873/10000 [00:33<00:00, 299.25it/s]Running 10000 simulations.:  99%|█████████▉| 9903/10000 [00:33<00:00, 298.46it/s]Running 10000 simulations.:  99%|█████████▉| 9933/10000 [00:33<00:00, 296.87it/s]Running 10000 simulations.: 100%|█████████▉| 9963/10000 [00:33<00:00, 296.71it/s]Running 10000 simulations.: 100%|█████████▉| 9993/10000 [00:33<00:00, 297.53it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:33<00:00, 294.30it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55085it [00:00, 573410.72it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55061it [00:00, 579532.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55042it [00:00, 584134.69it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55111it [00:00, 572086.91it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50137it [00:00, 526619.80it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54921it [00:00, 578262.19it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55008it [00:00, 577629.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54916it [00:00, 566597.62it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55022it [00:00, 577688.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54995it [00:00, 570953.41it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54972it [00:00, 585083.90it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54969it [00:00, 565462.76it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54953it [00:00, 568639.74it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55177it [00:00, 570571.93it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54972it [00:00, 589225.60it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54985it [00:00, 585648.78it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55057it [00:00, 576372.12it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54936it [00:00, 588062.77it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54998it [00:00, 595288.17it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54951it [00:00, 572500.35it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55029it [00:00, 578929.91it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54924it [00:00, 568237.31it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55086it [00:00, 589877.71it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55012it [00:00, 582893.06it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55054it [00:00, 584408.43it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55029it [00:00, 571925.03it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55018it [00:00, 567397.38it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55088it [00:00, 566750.85it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55027it [00:00, 582058.00it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55022it [00:00, 577992.21it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627386.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59940it [00:00, 620380.17it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617847.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59990it [00:00, 626121.45it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59037it [00:00, 612424.44it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53118it [00:00, 562685.42it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 635256.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629518.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633798.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630851.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57954it [00:00, 609086.54it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630240.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624933.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624574.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59997it [00:00, 630289.63it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58589it [00:00, 606798.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627869.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621266.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58104it [00:00, 606118.84it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616869.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630172.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632310.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 631402.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 631756.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622534.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624472.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618296.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 625035.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633305.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55601it [00:00, 496780.19it/s]           Drawing 50000 posterior samples: 55601it [00:00, 495067.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621490.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59975it [00:00, 633905.57it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621321.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617721.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54059it [00:00, 571176.36it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56291it [00:00, 592993.55it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620283.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621730.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632178.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624436.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59996it [00:00, 633504.93it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623510.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 625416.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621957.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 634598.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59721it [00:00, 612459.64it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618977.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 634896.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59888it [00:00, 631615.62it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 631529.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620101.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633383.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632865.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621575.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 626469.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624892.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627912.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632512.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 634397.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52639it [00:00, 546073.25it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622353.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59718it [00:00, 619125.94it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622793.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 630187.53it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52066it [00:00, 540547.46it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53283it [00:00, 555844.59it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628241.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620305.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623178.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 635812.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59980it [00:00, 633171.80it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630942.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630711.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629146.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59998it [00:00, 625342.87it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58980it [00:00, 620603.62it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 619270.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616836.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57641it [00:00, 608316.61it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628324.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628763.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622023.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624198.82it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629726.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 631495.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632485.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630781.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628000.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622597.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54988it [00:00, 499379.42it/s]           Drawing 50000 posterior samples: 54988it [00:00, 497891.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 631284.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59287it [00:00, 625610.60it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623608.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 632840.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  98%|█████████▊| 49092/50000 [00:00<00:00, 444675.99it/s]Drawing 50000 posterior samples: 56058it [00:00, 442840.31it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53386it [00:00, 564479.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618999.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617468.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618692.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632878.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59650it [00:00, 621576.74it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630563.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629484.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 631504.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 614328.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57667it [00:00, 600995.22it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59911it [00:00, 632298.60it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 636426.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59060it [00:00, 621227.21it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629584.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620349.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622377.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616185.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630383.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 626865.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 631261.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59991it [00:00, 631441.23it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624978.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628394.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 52915it [00:00, 550339.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55104it [00:00, 589112.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55000it [00:00, 584604.58it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54921it [00:00, 586701.33it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55071it [00:00, 575843.17it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57584it [00:00, 530805.07it/s]           Drawing 50000 posterior samples: 57584it [00:00, 529194.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54982it [00:00, 591306.28it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55029it [00:00, 591338.67it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54952it [00:00, 582856.59it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55007it [00:00, 589989.75it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55000it [00:00, 579782.40it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55025it [00:00, 577893.46it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55012it [00:00, 587586.65it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54841it [00:00, 567809.99it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54796it [00:00, 579879.25it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55016it [00:00, 590267.41it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54968it [00:00, 580602.23it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54958it [00:00, 593573.12it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54931it [00:00, 580910.69it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54975it [00:00, 584198.20it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54936it [00:00, 590563.23it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55070it [00:00, 580696.90it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54931it [00:00, 573096.28it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54958it [00:00, 577943.77it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55083it [00:00, 590086.63it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55048it [00:00, 586167.97it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55089it [00:00, 585058.33it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54881it [00:00, 589153.56it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54954it [00:00, 593406.15it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54996it [00:00, 591282.49it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55012it [00:00, 593933.05it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632957.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59996it [00:00, 622400.40it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624520.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59965it [00:00, 623364.68it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55887it [00:00, 590405.86it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57562it [00:00, 598090.84it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628539.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632617.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618897.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633349.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59837it [00:00, 622846.05it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630036.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627771.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632009.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59962it [00:00, 632416.74it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59339it [00:00, 617095.70it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633919.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633310.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56602it [00:00, 600318.09it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620011.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629684.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633198.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621071.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622771.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616459.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 634030.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627453.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628467.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 626310.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 50811it [00:00, 457557.98it/s]           Drawing 50000 posterior samples: 50811it [00:00, 456155.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54859it [00:00, 583018.69it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51862it [00:00, 541721.44it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54906it [00:00, 557051.80it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54913it [00:00, 564370.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 53829it [00:00, 496389.22it/s]           Drawing 50000 posterior samples: 53829it [00:00, 494456.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54896it [00:00, 576635.39it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54979it [00:00, 565791.82it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54960it [00:00, 565668.46it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54886it [00:00, 562634.29it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54943it [00:00, 569036.04it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54936it [00:00, 577268.08it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54918it [00:00, 575034.67it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54973it [00:00, 569671.68it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54772it [00:00, 578351.37it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54832it [00:00, 579613.84it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54936it [00:00, 581363.74it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54571it [00:00, 571571.10it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54873it [00:00, 569192.30it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54898it [00:00, 569205.27it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54853it [00:00, 579901.59it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54989it [00:00, 577997.32it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55005it [00:00, 568884.49it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54961it [00:00, 580274.03it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54831it [00:00, 574858.48it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55013it [00:00, 573331.43it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54981it [00:00, 576192.02it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54866it [00:00, 572191.83it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54875it [00:00, 578458.90it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 55005it [00:00, 568562.04it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 54955it [00:00, 579002.44it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633894.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59996it [00:00, 625746.53it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617881.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 625155.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59469it [00:00, 621786.92it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 56106it [00:00, 583922.95it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628950.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 626715.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628264.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617901.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59963it [00:00, 625428.78it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 633345.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630929.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 625546.83it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59995it [00:00, 630450.22it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58883it [00:00, 619848.87it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620809.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623047.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58968it [00:00, 620740.53it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627609.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618198.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628309.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628450.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624725.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620345.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 626019.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 634963.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621209.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 635552.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57094it [00:00, 517721.72it/s]           Drawing 50000 posterior samples: 57094it [00:00, 516277.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630777.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59545it [00:00, 628907.43it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624927.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59988it [00:00, 628068.25it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51281it [00:00, 538043.08it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 57644it [00:00, 600560.03it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628422.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 629240.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 625972.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 621781.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59946it [00:00, 630646.31it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623228.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 624288.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 622862.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 616943.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59792it [00:00, 626053.65it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59872it [00:00, 629716.19it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623640.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 58832it [00:00, 623704.41it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632691.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 628544.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 618154.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 630214.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 632243.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 623197.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 620035.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 59999it [00:00, 615726.14it/s]           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 627386.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 617928.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples: 51641it [00:00, 466993.35it/s]           Drawing 50000 posterior samples: 51641it [00:00, 465602.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
warning: file exists
30
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Neural network successfully converged after 231 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Neural network successfully converged after 207 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Neural network successfully converged after 218 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Training neural network. Epochs trained:  372Training neural network. Epochs trained:  373Training neural network. Epochs trained:  374Training neural network. Epochs trained:  375Training neural network. Epochs trained:  376Training neural network. Epochs trained:  377Training neural network. Epochs trained:  378Training neural network. Epochs trained:  379Training neural network. Epochs trained:  380Training neural network. Epochs trained:  381Training neural network. Epochs trained:  382Training neural network. Epochs trained:  383Training neural network. Epochs trained:  384Training neural network. Epochs trained:  385Neural network successfully converged after 385 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Neural network successfully converged after 317 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Neural network successfully converged after 317 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Neural network successfully converged after 289 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Neural network successfully converged after 154 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Training neural network. Epochs trained:  372Training neural network. Epochs trained:  373Training neural network. Epochs trained:  374Training neural network. Epochs trained:  375Training neural network. Epochs trained:  376Training neural network. Epochs trained:  377Training neural network. Epochs trained:  378Training neural network. Epochs trained:  379Training neural network. Epochs trained:  380Training neural network. Epochs trained:  381Training neural network. Epochs trained:  382Training neural network. Epochs trained:  383Training neural network. Epochs trained:  384Training neural network. Epochs trained:  385Training neural network. Epochs trained:  386Training neural network. Epochs trained:  387Training neural network. Epochs trained:  388Training neural network. Epochs trained:  389Training neural network. Epochs trained:  390Training neural network. Epochs trained:  391Training neural network. Epochs trained:  392Training neural network. Epochs trained:  393Training neural network. Epochs trained:  394Training neural network. Epochs trained:  395Training neural network. Epochs trained:  396Training neural network. Epochs trained:  397Training neural network. Epochs trained:  398Training neural network. Epochs trained:  399Training neural network. Epochs trained:  400Training neural network. Epochs trained:  401Training neural network. Epochs trained:  402Training neural network. Epochs trained:  403Training neural network. Epochs trained:  404Training neural network. Epochs trained:  405Training neural network. Epochs trained:  406Training neural network. Epochs trained:  407Training neural network. Epochs trained:  408Training neural network. Epochs trained:  409Training neural network. Epochs trained:  410Training neural network. Epochs trained:  411Training neural network. Epochs trained:  412Training neural network. Epochs trained:  413Training neural network. Epochs trained:  414Training neural network. Epochs trained:  415Training neural network. Epochs trained:  416Training neural network. Epochs trained:  417Training neural network. Epochs trained:  418Training neural network. Epochs trained:  419Training neural network. Epochs trained:  420Training neural network. Epochs trained:  421Training neural network. Epochs trained:  422Training neural network. Epochs trained:  423Training neural network. Epochs trained:  424Training neural network. Epochs trained:  425Training neural network. Epochs trained:  426Training neural network. Epochs trained:  427Training neural network. Epochs trained:  428Training neural network. Epochs trained:  429Training neural network. Epochs trained:  430Training neural network. Epochs trained:  431Training neural network. Epochs trained:  432Training neural network. Epochs trained:  433Training neural network. Epochs trained:  434Training neural network. Epochs trained:  435Training neural network. Epochs trained:  436Training neural network. Epochs trained:  437Training neural network. Epochs trained:  438Training neural network. Epochs trained:  439Training neural network. Epochs trained:  440Training neural network. Epochs trained:  441Training neural network. Epochs trained:  442Training neural network. Epochs trained:  443Training neural network. Epochs trained:  444Training neural network. Epochs trained:  445Training neural network. Epochs trained:  446Training neural network. Epochs trained:  447Training neural network. Epochs trained:  448Training neural network. Epochs trained:  449Training neural network. Epochs trained:  450Training neural network. Epochs trained:  451Training neural network. Epochs trained:  452Training neural network. Epochs trained:  453Neural network successfully converged after 453 epochs.
warning: file exists
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Neural network successfully converged after 254 epochs.
warning: file exists
log prob true 4.3235974
warning: file exists
log prob true 4.0299335
warning: file exists
log prob true 4.3546286
warning: file exists
log prob true 3.1130223
warning: file exists
log prob true 3.320394
warning: file exists
log prob true 3.0910337
warning: file exists
log prob true 3.6422186
warning: file exists
log prob true 4.4022646
warning: file exists
log prob true 3.95169
warning: file exists
log prob true 3.61705
warning: file exists
log prob true 3.201665
warning: file exists
log prob true 4.205308
warning: file exists
log prob true 4.413801
warning: file exists
log prob true 3.812679
warning: file exists
log prob true 3.6180658
warning: file exists
log prob true 3.3109987
warning: file exists
log prob true 3.8565173
warning: file exists
log prob true 4.2229257
warning: file exists
log prob true 3.3019266
warning: file exists
log prob true 4.342148
warning: file exists
log prob true 4.0551186
warning: file exists
log prob true 3.795142
warning: file exists
log prob true 4.4950376
warning: file exists
log prob true 3.9325352
warning: file exists
log prob true 4.4595523
warning: file exists
log prob true 4.0864515
warning: file exists
log prob true 3.3006573
warning: file exists
log prob true 3.7524953
warning: file exists
log prob true 4.3661957
warning: file exists
log prob true 2.9740355
warning: file exists
log prob true 7.2287736
warning: file exists
log prob true 6.8608036
warning: file exists
log prob true 7.082637
warning: file exists
log prob true 6.6117787
warning: file exists
log prob true 6.1905813
warning: file exists
log prob true 6.444141
warning: file exists
log prob true 6.6148815
warning: file exists
log prob true 7.1316156
warning: file exists
log prob true 6.7484746
warning: file exists
log prob true 6.9588904
warning: file exists
log prob true 6.3094707
warning: file exists
log prob true 7.0841303
warning: file exists
log prob true 7.5302873
warning: file exists
log prob true 7.0417976
warning: file exists
log prob true 6.536829
warning: file exists
log prob true 6.341527
warning: file exists
log prob true 6.634459
warning: file exists
log prob true 6.9102626
warning: file exists
log prob true 6.4767485
warning: file exists
log prob true 7.205965
warning: file exists
log prob true 7.140041
warning: file exists
log prob true 6.8244085
warning: file exists
log prob true 7.032273
warning: file exists
log prob true 6.74589
warning: file exists
log prob true 6.50662
warning: file exists
log prob true 6.923686
warning: file exists
log prob true 6.2995925
warning: file exists
log prob true 6.663484
warning: file exists
log prob true 6.940533
warning: file exists
log prob true 6.7077456
warning: file exists
log prob true 7.5034432
warning: file exists
log prob true 7.0076895
warning: file exists
log prob true 7.4071794
warning: file exists
log prob true 7.06656
warning: file exists
log prob true 6.8473268
warning: file exists
log prob true 6.7680907
warning: file exists
log prob true 6.8813562
warning: file exists
log prob true 7.2998104
warning: file exists
log prob true 7.0492854
warning: file exists
log prob true 7.0381274
warning: file exists
log prob true 6.868722
warning: file exists
log prob true 7.2877617
warning: file exists
log prob true 7.7428255
warning: file exists
log prob true 7.269911
warning: file exists
log prob true 6.792614
warning: file exists
log prob true 6.537148
warning: file exists
log prob true 6.80634
warning: file exists
log prob true 6.9088283
warning: file exists
log prob true 6.7910404
warning: file exists
log prob true 7.4363365
warning: file exists
log prob true 7.4846673
warning: file exists
log prob true 7.0811734
warning: file exists
log prob true 7.4090886
warning: file exists
log prob true 6.8899
warning: file exists
log prob true 7.4452987
warning: file exists
log prob true 7.162275
warning: file exists
log prob true 6.39472
warning: file exists
log prob true 6.835438
warning: file exists
log prob true 7.3022814
warning: file exists
log prob true 6.859063
warning: file exists
log prob true 7.3626995
warning: file exists
log prob true 6.8866234
warning: file exists
log prob true 7.245272
warning: file exists
log prob true 6.735778
warning: file exists
log prob true 6.2325044
warning: file exists
log prob true 6.746558
warning: file exists
log prob true 6.618803
warning: file exists
log prob true 7.1157684
warning: file exists
log prob true 6.700116
warning: file exists
log prob true 7.0302877
warning: file exists
log prob true 6.810153
warning: file exists
log prob true 7.0821357
warning: file exists
log prob true 7.441025
warning: file exists
log prob true 6.8367276
warning: file exists
log prob true 6.530749
warning: file exists
log prob true 6.4613805
warning: file exists
log prob true 6.743889
warning: file exists
log prob true 6.9660053
warning: file exists
log prob true 6.636133
warning: file exists
log prob true 7.2231517
warning: file exists
log prob true 6.946705
warning: file exists
log prob true 6.911206
warning: file exists
log prob true 7.364711
warning: file exists
log prob true 6.712828
warning: file exists
log prob true 7.265654
warning: file exists
log prob true 6.967718
warning: file exists
log prob true 6.2401657
warning: file exists
log prob true 6.705954
warning: file exists
log prob true 6.9936337
warning: file exists
log prob true 6.731461
warning: file exists
log prob true 7.053881
warning: file exists
log prob true 6.4823337
warning: file exists
log prob true 6.797912
warning: file exists
log prob true 6.4941807
warning: file exists
log prob true 6.503846
warning: file exists
log prob true 6.412161
warning: file exists
log prob true 6.527108
warning: file exists
log prob true 6.7715983
warning: file exists
log prob true 6.571763
warning: file exists
log prob true 6.663877
warning: file exists
log prob true 6.373026
warning: file exists
log prob true 6.6690946
warning: file exists
log prob true 7.145216
warning: file exists
log prob true 6.8246913
warning: file exists
log prob true 6.279536
warning: file exists
log prob true 6.0592227
warning: file exists
log prob true 6.245665
warning: file exists
log prob true 6.690909
warning: file exists
log prob true 6.289362
warning: file exists
log prob true 7.004309
warning: file exists
log prob true 6.939433
warning: file exists
log prob true 6.6777472
warning: file exists
log prob true 6.889517
warning: file exists
log prob true 6.3204384
warning: file exists
log prob true 6.863069
warning: file exists
log prob true 6.8334465
warning: file exists
log prob true 5.7352643
warning: file exists
log prob true 6.2960234
warning: file exists
log prob true 6.881062
warning: file exists
log prob true 6.093333
warning: file exists
log prob true 4.4737654
warning: file exists
log prob true 3.8395517
warning: file exists
log prob true 4.350725
warning: file exists
log prob true 3.3347251
warning: file exists
log prob true 3.7100706
warning: file exists
log prob true 3.06379
warning: file exists
log prob true 3.6821752
warning: file exists
log prob true 4.2510686
warning: file exists
log prob true 3.9254885
warning: file exists
log prob true 3.6977203
warning: file exists
log prob true 3.1213806
warning: file exists
log prob true 4.212529
warning: file exists
log prob true 4.27931
warning: file exists
log prob true 4.054568
warning: file exists
log prob true 3.5461996
warning: file exists
log prob true 3.1678402
warning: file exists
log prob true 3.9415843
warning: file exists
log prob true 4.22416
warning: file exists
log prob true 3.3916202
warning: file exists
log prob true 4.259424
warning: file exists
log prob true 3.9491212
warning: file exists
log prob true 3.6014798
warning: file exists
log prob true 4.5153627
warning: file exists
log prob true 3.92716
warning: file exists
log prob true 4.3902245
warning: file exists
log prob true 4.064983
warning: file exists
log prob true 3.2806876
warning: file exists
log prob true 3.653241
warning: file exists
log prob true 4.242117
warning: file exists
log prob true 3.0792656
warning: file exists
log prob true 7.145453
warning: file exists
log prob true 6.7109494
warning: file exists
log prob true 6.826594
warning: file exists
log prob true 6.524856
warning: file exists
log prob true 6.1889853
warning: file exists
log prob true 6.256597
warning: file exists
log prob true 6.5532007
warning: file exists
log prob true 6.999411
warning: file exists
log prob true 6.550473
warning: file exists
log prob true 6.648609
warning: file exists
log prob true 6.601497
warning: file exists
log prob true 6.9419117
warning: file exists
log prob true 7.027641
warning: file exists
log prob true 6.9061007
warning: file exists
log prob true 6.2911935
warning: file exists
log prob true 6.2492065
warning: file exists
log prob true 6.5623693
warning: file exists
log prob true 6.749037
warning: file exists
log prob true 6.3037295
warning: file exists
log prob true 7.081409
warning: file exists
log prob true 6.8254547
warning: file exists
log prob true 6.5568647
warning: file exists
log prob true 6.931868
warning: file exists
log prob true 6.5354414
warning: file exists
log prob true 6.9553885
warning: file exists
log prob true 6.760773
warning: file exists
log prob true 6.273208
warning: file exists
log prob true 6.537575
warning: file exists
log prob true 6.654757
warning: file exists
log prob true 6.669788
warning: file exists
log prob true 4.1712985
warning: file exists
log prob true 3.6644108
warning: file exists
log prob true 4.1232266
warning: file exists
log prob true 2.8489134
warning: file exists
log prob true 3.2042944
warning: file exists
log prob true 2.6717832
warning: file exists
log prob true 2.8624623
warning: file exists
log prob true 4.0048532
warning: file exists
log prob true 3.6539235
warning: file exists
log prob true 3.7078667
warning: file exists
log prob true 3.1468694
warning: file exists
log prob true 3.7983744
warning: file exists
log prob true 4.536284
warning: file exists
log prob true 3.8609586
warning: file exists
log prob true 3.2473001
warning: file exists
log prob true 2.9205768
warning: file exists
log prob true 3.64335
warning: file exists
log prob true 3.9272547
warning: file exists
log prob true 2.9013488
warning: file exists
log prob true 4.0173473
warning: file exists
log prob true 3.6786747
warning: file exists
log prob true 3.8605936
warning: file exists
log prob true 4.178618
warning: file exists
log prob true 3.5474138
warning: file exists
log prob true 4.1339045
warning: file exists
log prob true 3.8216348
warning: file exists
log prob true 2.9036381
warning: file exists
log prob true 3.4217563
warning: file exists
log prob true 3.7552538
warning: file exists
log prob true 1.9379339
warning: file exists
log prob true 7.4730415
warning: file exists
log prob true 6.965509
warning: file exists
log prob true 7.12204
warning: file exists
log prob true 6.846698
warning: file exists
log prob true 5.850217
warning: file exists
log prob true 6.7639956
warning: file exists
log prob true 6.769649
warning: file exists
log prob true 7.2626586
warning: file exists
log prob true 6.8142414
warning: file exists
log prob true 7.0984216
warning: file exists
log prob true 6.896307
warning: file exists
log prob true 7.1447306
warning: file exists
log prob true 7.4837666
warning: file exists
log prob true 7.1470504
warning: file exists
log prob true 6.5979047
warning: file exists
log prob true 6.4465117
warning: file exists
log prob true 6.6686873
warning: file exists
log prob true 6.8253183
warning: file exists
log prob true 6.5931854
warning: file exists
log prob true 7.304371
warning: file exists
log prob true 7.0388875
warning: file exists
log prob true 7.0287476
warning: file exists
log prob true 7.320569
warning: file exists
log prob true 6.859053
warning: file exists
log prob true 7.2989817
warning: file exists
log prob true 7.031092
warning: file exists
log prob true 6.458108
warning: file exists
log prob true 6.8733087
warning: file exists
log prob true 7.305844
warning: file exists
log prob true 6.8379645
warning: file exists
log prob true 7.0075803
warning: file exists
log prob true 6.394248
warning: file exists
log prob true 6.5712023
warning: file exists
log prob true 6.5275235
warning: file exists
log prob true 6.1950064
warning: file exists
log prob true 5.9363008
warning: file exists
log prob true 6.2337327
warning: file exists
log prob true 6.7401414
warning: file exists
log prob true 6.3381033
warning: file exists
log prob true 6.530659
warning: file exists
log prob true 6.249166
warning: file exists
log prob true 6.4888315
warning: file exists
log prob true 7.1562634
warning: file exists
log prob true 6.6511674
warning: file exists
log prob true 6.116563
warning: file exists
log prob true 5.6725445
warning: file exists
log prob true 6.1225977
warning: file exists
log prob true 6.5140834
warning: file exists
log prob true 6.317587
warning: file exists
log prob true 6.591308
warning: file exists
log prob true 6.8166423
warning: file exists
log prob true 6.642712
warning: file exists
log prob true 6.840797
warning: file exists
log prob true 6.3246374
warning: file exists
log prob true 6.8259163
warning: file exists
log prob true 6.562406
warning: file exists
log prob true 5.8203764
warning: file exists
log prob true 6.275699
warning: file exists
log prob true 6.785715
warning: file exists
log prob true 6.4751906
script complete
