Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/lstmutils.py:176: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data_window[f'AOC_{l}'] = AOC_scale[l]
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/lstmutils.py:178: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data_window['Y'] = data[member_name]
warning: file exists
saving
10_13_log_mod_b_00
Epoch: 0, training loss: 0.00767
Epoch: 0, validation loss: 0.00409
Epoch: 1, training loss: 0.00409
Epoch: 1, validation loss: 0.00304
Epoch: 2, training loss: 0.00341
Epoch: 2, validation loss: 0.00242
Epoch: 3, training loss: 0.00314
Epoch: 3, validation loss: 0.00258
Epoch: 4, training loss: 0.00266
Epoch: 4, validation loss: 0.00200
Epoch: 5, training loss: 0.00238
Epoch: 5, validation loss: 0.00181
Epoch: 6, training loss: 0.00218
Epoch: 6, validation loss: 0.00168
Epoch: 7, training loss: 0.00193
Epoch: 7, validation loss: 0.00151
Epoch: 8, training loss: 0.00178
Epoch: 8, validation loss: 0.00126
Epoch: 9, training loss: 0.00168
Epoch: 9, validation loss: 0.00116
Epoch: 10, training loss: 0.00155
Epoch: 10, validation loss: 0.00114
Epoch: 11, training loss: 0.00149
Epoch: 11, validation loss: 0.00111
Epoch: 12, training loss: 0.00137
Epoch: 12, validation loss: 0.00092
Epoch: 13, training loss: 0.00135
Epoch: 13, validation loss: 0.00091
Epoch: 14, training loss: 0.00132
Epoch: 14, validation loss: 0.00084
Epoch: 15, training loss: 0.00125
Epoch: 15, validation loss: 0.00078
Epoch: 16, training loss: 0.00122
Epoch: 16, validation loss: 0.00075
Epoch: 17, training loss: 0.00116
Epoch: 17, validation loss: 0.00072
Epoch: 18, training loss: 0.00111
Epoch: 18, validation loss: 0.00068
Epoch: 19, training loss: 0.00107
Epoch: 19, validation loss: 0.00064
Epoch: 20, training loss: 0.00104
Epoch: 20, validation loss: 0.00062
Epoch: 21, training loss: 0.00100
Epoch: 21, validation loss: 0.00060
Epoch: 22, training loss: 0.00097
Epoch: 22, validation loss: 0.00058
Epoch: 23, training loss: 0.00094
Epoch: 23, validation loss: 0.00056
Epoch: 24, training loss: 0.00092
Epoch: 24, validation loss: 0.00054
Epoch: 25, training loss: 0.00089
Epoch: 25, validation loss: 0.00052
Epoch: 26, training loss: 0.00087
Epoch: 26, validation loss: 0.00051
Epoch: 27, training loss: 0.00084
Epoch: 27, validation loss: 0.00050
Epoch: 28, training loss: 0.00082
Epoch: 28, validation loss: 0.00048
Epoch: 29, training loss: 0.00080
Epoch: 29, validation loss: 0.00047
Epoch: 30, training loss: 0.00077
Epoch: 30, validation loss: 0.00046
Epoch: 31, training loss: 0.00075
Epoch: 31, validation loss: 0.00045
Epoch: 32, training loss: 0.00073
Epoch: 32, validation loss: 0.00044
Epoch: 33, training loss: 0.00071
Epoch: 33, validation loss: 0.00043
Epoch: 34, training loss: 0.00069
Epoch: 34, validation loss: 0.00043
Epoch: 35, training loss: 0.00067
Epoch: 35, validation loss: 0.00042
Epoch: 36, training loss: 0.00066
Epoch: 36, validation loss: 0.00041
Epoch: 37, training loss: 0.00064
Epoch: 37, validation loss: 0.00041
Epoch: 38, training loss: 0.00063
Epoch: 38, validation loss: 0.00040
Epoch: 39, training loss: 0.00061
Epoch: 39, validation loss: 0.00040
Epoch: 40, training loss: 0.00060
Epoch: 40, validation loss: 0.00039
Epoch: 41, training loss: 0.00059
Epoch: 41, validation loss: 0.00039
Epoch: 42, training loss: 0.00057
Epoch: 42, validation loss: 0.00039
Epoch: 43, training loss: 0.00056
Epoch: 43, validation loss: 0.00038
Epoch: 44, training loss: 0.00055
Epoch: 44, validation loss: 0.00038
Epoch: 45, training loss: 0.00055
Epoch: 45, validation loss: 0.00038
Epoch: 46, training loss: 0.00054
Epoch: 46, validation loss: 0.00037
Epoch: 47, training loss: 0.00053
Epoch: 47, validation loss: 0.00037
Epoch: 48, training loss: 0.00052
Epoch: 48, validation loss: 0.00037
Epoch: 49, training loss: 0.00051
Epoch: 49, validation loss: 0.00036
Epoch: 50, training loss: 0.00050
Epoch: 50, validation loss: 0.00036
Epoch: 51, training loss: 0.00050
Epoch: 51, validation loss: 0.00036
Epoch: 52, training loss: 0.00049
Epoch: 52, validation loss: 0.00035
Epoch: 53, training loss: 0.00048
Epoch: 53, validation loss: 0.00035
Epoch: 54, training loss: 0.00047
Epoch: 54, validation loss: 0.00034
Epoch: 55, training loss: 0.00055
Epoch: 55, validation loss: 0.00029
Epoch: 56, training loss: 0.00045
Epoch: 56, validation loss: 0.00031
Epoch: 57, training loss: 0.00046
Epoch: 57, validation loss: 0.00031
Epoch: 58, training loss: 0.00046
Epoch: 58, validation loss: 0.00030
Epoch: 59, training loss: 0.00054
Epoch: 59, validation loss: 0.00028
Epoch: 60, training loss: 0.00043
Epoch: 60, validation loss: 0.00029
Epoch: 61, training loss: 0.00043
Epoch: 61, validation loss: 0.00030
Epoch: 62, training loss: 0.00051
Epoch: 62, validation loss: 0.00027
Epoch: 63, training loss: 0.00044
Epoch: 63, validation loss: 0.00026
Epoch: 64, training loss: 0.00045
Epoch: 64, validation loss: 0.00025
Epoch: 65, training loss: 0.00043
Epoch: 65, validation loss: 0.00026
Epoch: 66, training loss: 0.00048
Epoch: 66, validation loss: 0.00026
Epoch: 67, training loss: 0.00043
Epoch: 67, validation loss: 0.00025
Epoch: 68, training loss: 0.00046
Epoch: 68, validation loss: 0.00024
Epoch: 69, training loss: 0.00040
Epoch: 69, validation loss: 0.00025
Epoch: 70, training loss: 0.00047
Epoch: 70, validation loss: 0.00025
Epoch: 71, training loss: 0.00042
Epoch: 71, validation loss: 0.00024
Epoch: 72, training loss: 0.00044
Epoch: 72, validation loss: 0.00024
Epoch: 73, training loss: 0.00039
Epoch: 73, validation loss: 0.00025
Epoch: 74, training loss: 0.00042
Epoch: 74, validation loss: 0.00024
Epoch: 75, training loss: 0.00041
Epoch: 75, validation loss: 0.00022
Epoch: 76, training loss: 0.00043
Epoch: 76, validation loss: 0.00024
Epoch: 77, training loss: 0.00038
Epoch: 77, validation loss: 0.00024
Epoch: 78, training loss: 0.00038
Epoch: 78, validation loss: 0.00023
Epoch: 79, training loss: 0.00045
Epoch: 79, validation loss: 0.00024
Epoch: 80, training loss: 0.00039
Epoch: 80, validation loss: 0.00022
Epoch: 81, training loss: 0.00041
Epoch: 81, validation loss: 0.00023
Epoch: 82, training loss: 0.00039
Epoch: 82, validation loss: 0.00022
Epoch: 83, training loss: 0.00037
Epoch: 83, validation loss: 0.00022
Epoch: 84, training loss: 0.00039
Epoch: 84, validation loss: 0.00022
Epoch: 85, training loss: 0.00039
Epoch: 85, validation loss: 0.00021
Epoch: 86, training loss: 0.00037
Epoch: 86, validation loss: 0.00021
Epoch: 87, training loss: 0.00039
Epoch: 87, validation loss: 0.00021
Epoch: 88, training loss: 0.00039
Epoch: 88, validation loss: 0.00021
Epoch: 89, training loss: 0.00037
Epoch: 89, validation loss: 0.00021
Epoch: 90, training loss: 0.00039
Epoch: 90, validation loss: 0.00020
Epoch: 91, training loss: 0.00038
Epoch: 91, validation loss: 0.00021
Epoch: 92, training loss: 0.00037
Epoch: 92, validation loss: 0.00020
Epoch: 93, training loss: 0.00038
Epoch: 93, validation loss: 0.00020
Epoch: 94, training loss: 0.00037
Epoch: 94, validation loss: 0.00020
Epoch: 95, training loss: 0.00037
Epoch: 95, validation loss: 0.00019
Epoch: 96, training loss: 0.00037
Epoch: 96, validation loss: 0.00019
Epoch: 97, training loss: 0.00037
Epoch: 97, validation loss: 0.00019
Epoch: 98, training loss: 0.00036
Epoch: 98, validation loss: 0.00019
Epoch: 99, training loss: 0.00036
Epoch: 99, validation loss: 0.00019
Epoch: 100, training loss: 0.00036
Epoch: 100, validation loss: 0.00019
Epoch: 101, training loss: 0.00035
Epoch: 101, validation loss: 0.00018
Epoch: 102, training loss: 0.00035
Epoch: 102, validation loss: 0.00018
Epoch: 103, training loss: 0.00035
Epoch: 103, validation loss: 0.00018
Epoch: 104, training loss: 0.00035
Epoch: 104, validation loss: 0.00018
Epoch: 105, training loss: 0.00034
Epoch: 105, validation loss: 0.00018
Epoch: 106, training loss: 0.00034
Epoch: 106, validation loss: 0.00018
Epoch: 107, training loss: 0.00034
Epoch: 107, validation loss: 0.00018
Epoch: 108, training loss: 0.00034
Epoch: 108, validation loss: 0.00017
Epoch: 109, training loss: 0.00033
Epoch: 109, validation loss: 0.00017
Epoch: 110, training loss: 0.00033
Epoch: 110, validation loss: 0.00017
Epoch: 111, training loss: 0.00033
Epoch: 111, validation loss: 0.00017
Epoch: 112, training loss: 0.00033
Epoch: 112, validation loss: 0.00017
Epoch: 113, training loss: 0.00032
Epoch: 113, validation loss: 0.00017
Epoch: 114, training loss: 0.00032
Epoch: 114, validation loss: 0.00017
Epoch: 115, training loss: 0.00032
Epoch: 115, validation loss: 0.00017
Epoch: 116, training loss: 0.00032
Epoch: 116, validation loss: 0.00017
Epoch: 117, training loss: 0.00032
Epoch: 117, validation loss: 0.00016
Epoch: 118, training loss: 0.00031
Epoch: 118, validation loss: 0.00016
Epoch: 119, training loss: 0.00031
Epoch: 119, validation loss: 0.00016
Epoch: 120, training loss: 0.00031
Epoch: 120, validation loss: 0.00016
Epoch: 121, training loss: 0.00031
Epoch: 121, validation loss: 0.00017
Epoch: 122, training loss: 0.00031
Epoch: 122, validation loss: 0.00016
Epoch: 123, training loss: 0.00032
Epoch: 123, validation loss: 0.00020
Epoch: 124, training loss: 0.00029
Epoch: 124, validation loss: 0.00018
Epoch: 125, training loss: 0.00031
Epoch: 125, validation loss: 0.00016
Epoch: 126, training loss: 0.00032
Epoch: 126, validation loss: 0.00019
Epoch: 127, training loss: 0.00031
Epoch: 127, validation loss: 0.00017
Epoch: 128, training loss: 0.00033
Epoch: 128, validation loss: 0.00022
Epoch: 129, training loss: 0.00030
Epoch: 129, validation loss: 0.00020
Epoch: 130, training loss: 0.00029
Epoch: 130, validation loss: 0.00017
Epoch: 131, training loss: 0.00032
Epoch: 131, validation loss: 0.00018
Epoch: 132, training loss: 0.00031
Epoch: 132, validation loss: 0.00019
Epoch: 133, training loss: 0.00029
Epoch: 133, validation loss: 0.00015
Epoch: 134, training loss: 0.00029
Epoch: 134, validation loss: 0.00015
Epoch: 135, training loss: 0.00030
Epoch: 135, validation loss: 0.00015
Epoch: 136, training loss: 0.00031
Epoch: 136, validation loss: 0.00023
Epoch: 137, training loss: 0.00029
Epoch: 137, validation loss: 0.00015
Epoch: 138, training loss: 0.00030
Epoch: 138, validation loss: 0.00016
Epoch: 139, training loss: 0.00029
Epoch: 139, validation loss: 0.00020
Epoch: 140, training loss: 0.00026
Epoch: 140, validation loss: 0.00015
Epoch: 141, training loss: 0.00031
Epoch: 141, validation loss: 0.00016
Epoch: 142, training loss: 0.00029
Epoch: 142, validation loss: 0.00020
Epoch: 143, training loss: 0.00030
Epoch: 143, validation loss: 0.00014
Epoch: 144, training loss: 0.00030
Epoch: 144, validation loss: 0.00018
Epoch: 145, training loss: 0.00029
Epoch: 145, validation loss: 0.00014
Epoch: 146, training loss: 0.00029
Epoch: 146, validation loss: 0.00018
Epoch: 147, training loss: 0.00029
Epoch: 147, validation loss: 0.00014
Epoch: 148, training loss: 0.00028
Epoch: 148, validation loss: 0.00017
Epoch: 149, training loss: 0.00028
Epoch: 149, validation loss: 0.00023
Epoch: 150, training loss: 0.00027
Epoch: 150, validation loss: 0.00015
Epoch: 151, training loss: 0.00028
Epoch: 151, validation loss: 0.00014
Epoch: 152, training loss: 0.00027
Epoch: 152, validation loss: 0.00019
Epoch: 153, training loss: 0.00027
Epoch: 153, validation loss: 0.00019
Epoch: 154, training loss: 0.00028
Epoch: 154, validation loss: 0.00013
Epoch: 155, training loss: 0.00028
Epoch: 155, validation loss: 0.00017
Epoch: 156, training loss: 0.00028
Epoch: 156, validation loss: 0.00013
Epoch: 157, training loss: 0.00028
Epoch: 157, validation loss: 0.00020
Epoch: 158, training loss: 0.00027
Epoch: 158, validation loss: 0.00013
Epoch: 159, training loss: 0.00027
Epoch: 159, validation loss: 0.00015
Epoch: 160, training loss: 0.00028
Epoch: 160, validation loss: 0.00014
Epoch: 161, training loss: 0.00026
Epoch: 161, validation loss: 0.00017
Epoch: 162, training loss: 0.00026
Epoch: 162, validation loss: 0.00021
Epoch: 163, training loss: 0.00025
Epoch: 163, validation loss: 0.00014
Epoch: 164, training loss: 0.00027
Epoch: 164, validation loss: 0.00014
Epoch: 165, training loss: 0.00028
Epoch: 165, validation loss: 0.00018
Epoch: 166, training loss: 0.00025
Epoch: 166, validation loss: 0.00020
Epoch: 167, training loss: 0.00025
Epoch: 167, validation loss: 0.00014
Epoch: 168, training loss: 0.00027
Epoch: 168, validation loss: 0.00014
Epoch: 169, training loss: 0.00027
Epoch: 169, validation loss: 0.00018
Epoch: 170, training loss: 0.00025
Epoch: 170, validation loss: 0.00014
Epoch: 171, training loss: 0.00026
Epoch: 171, validation loss: 0.00014
Epoch: 172, training loss: 0.00026
Epoch: 172, validation loss: 0.00020
Epoch: 173, training loss: 0.00026
Epoch: 173, validation loss: 0.00012
Epoch: 174, training loss: 0.00026
Epoch: 174, validation loss: 0.00014
Epoch: 175, training loss: 0.00027
Epoch: 175, validation loss: 0.00017
Epoch: 176, training loss: 0.00026
Epoch: 176, validation loss: 0.00014
Epoch: 177, training loss: 0.00025
Epoch: 177, validation loss: 0.00014
Epoch: 178, training loss: 0.00026
Epoch: 178, validation loss: 0.00019
Epoch: 179, training loss: 0.00025
Epoch: 179, validation loss: 0.00012
Epoch: 180, training loss: 0.00025
Epoch: 180, validation loss: 0.00013
Epoch: 181, training loss: 0.00026
Epoch: 181, validation loss: 0.00018
Epoch: 182, training loss: 0.00025
Epoch: 182, validation loss: 0.00014
Epoch: 183, training loss: 0.00024
Epoch: 183, validation loss: 0.00013
Epoch: 184, training loss: 0.00025
Epoch: 184, validation loss: 0.00018
Epoch: 185, training loss: 0.00024
Epoch: 185, validation loss: 0.00013
Epoch: 186, training loss: 0.00024
Epoch: 186, validation loss: 0.00015
Epoch: 187, training loss: 0.00025
Epoch: 187, validation loss: 0.00017
Epoch: 188, training loss: 0.00024
Epoch: 188, validation loss: 0.00014
Epoch: 189, training loss: 0.00024
Epoch: 189, validation loss: 0.00014
Epoch: 190, training loss: 0.00025
Epoch: 190, validation loss: 0.00016
Epoch: 191, training loss: 0.00024
Epoch: 191, validation loss: 0.00015
Epoch: 192, training loss: 0.00024
Epoch: 192, validation loss: 0.00015
Epoch: 193, training loss: 0.00024
Epoch: 193, validation loss: 0.00014
Epoch: 194, training loss: 0.00024
Epoch: 194, validation loss: 0.00014
Epoch: 195, training loss: 0.00024
Epoch: 195, validation loss: 0.00015
Epoch: 196, training loss: 0.00024
Epoch: 196, validation loss: 0.00015
Epoch: 197, training loss: 0.00024
Epoch: 197, validation loss: 0.00014
Epoch: 198, training loss: 0.00024
Epoch: 198, validation loss: 0.00013
Epoch: 199, training loss: 0.00024
Epoch: 199, validation loss: 0.00013
Epoch: 200, training loss: 0.00024
Epoch: 200, validation loss: 0.00014
Epoch: 201, training loss: 0.00024
Epoch: 201, validation loss: 0.00014
Epoch: 202, training loss: 0.00024
Epoch: 202, validation loss: 0.00014
Epoch: 203, training loss: 0.00023
Epoch: 203, validation loss: 0.00013
Epoch: 204, training loss: 0.00023
Epoch: 204, validation loss: 0.00013
Epoch: 205, training loss: 0.00023
Epoch: 205, validation loss: 0.00013
Epoch: 206, training loss: 0.00023
Epoch: 206, validation loss: 0.00013
Epoch: 207, training loss: 0.00023
Epoch: 207, validation loss: 0.00013
Epoch: 208, training loss: 0.00023
Epoch: 208, validation loss: 0.00013
Epoch: 209, training loss: 0.00023
Epoch: 209, validation loss: 0.00013
Epoch: 210, training loss: 0.00023
Epoch: 210, validation loss: 0.00013
Epoch: 211, training loss: 0.00023
Epoch: 211, validation loss: 0.00013
Epoch: 212, training loss: 0.00023
Epoch: 212, validation loss: 0.00013
Epoch: 213, training loss: 0.00023
Epoch: 213, validation loss: 0.00013
Epoch: 214, training loss: 0.00023
Epoch: 214, validation loss: 0.00013
Epoch: 215, training loss: 0.00023
Epoch: 215, validation loss: 0.00012
Epoch: 216, training loss: 0.00023
Epoch: 216, validation loss: 0.00012
Epoch: 217, training loss: 0.00023
Epoch: 217, validation loss: 0.00012
Epoch: 218, training loss: 0.00023
Epoch: 218, validation loss: 0.00012
Epoch: 219, training loss: 0.00023
Epoch: 219, validation loss: 0.00012
Epoch: 220, training loss: 0.00023
Epoch: 220, validation loss: 0.00012
Epoch: 221, training loss: 0.00022
Epoch: 221, validation loss: 0.00012
Epoch: 222, training loss: 0.00022
Epoch: 222, validation loss: 0.00012
Epoch: 223, training loss: 0.00022
Epoch: 223, validation loss: 0.00012
Epoch: 224, training loss: 0.00022
Epoch: 224, validation loss: 0.00012
Epoch: 225, training loss: 0.00022
Epoch: 225, validation loss: 0.00012
Epoch: 226, training loss: 0.00022
Epoch: 226, validation loss: 0.00012
Epoch: 227, training loss: 0.00022
Epoch: 227, validation loss: 0.00012
Epoch: 228, training loss: 0.00022
Epoch: 228, validation loss: 0.00012
Epoch: 229, training loss: 0.00022
Epoch: 229, validation loss: 0.00011
Epoch: 230, training loss: 0.00022
Epoch: 230, validation loss: 0.00011
Epoch: 231, training loss: 0.00022
Epoch: 231, validation loss: 0.00011
Epoch: 232, training loss: 0.00022
Epoch: 232, validation loss: 0.00011
Epoch: 233, training loss: 0.00022
Epoch: 233, validation loss: 0.00011
Epoch: 234, training loss: 0.00022
Epoch: 234, validation loss: 0.00011
Epoch: 235, training loss: 0.00022
Epoch: 235, validation loss: 0.00011
Epoch: 236, training loss: 0.00022
Epoch: 236, validation loss: 0.00011
Epoch: 237, training loss: 0.00022
Epoch: 237, validation loss: 0.00011
Epoch: 238, training loss: 0.00022
Epoch: 238, validation loss: 0.00011
Epoch: 239, training loss: 0.00021
Epoch: 239, validation loss: 0.00011
Epoch: 240, training loss: 0.00021
Epoch: 240, validation loss: 0.00011
Epoch: 241, training loss: 0.00021
Epoch: 241, validation loss: 0.00011
Epoch: 242, training loss: 0.00021
Epoch: 242, validation loss: 0.00011
Epoch: 243, training loss: 0.00021
Epoch: 243, validation loss: 0.00011
Epoch: 244, training loss: 0.00021
Epoch: 244, validation loss: 0.00011
Epoch: 245, training loss: 0.00021
Epoch: 245, validation loss: 0.00011
Epoch: 246, training loss: 0.00021
Epoch: 246, validation loss: 0.00011
Epoch: 247, training loss: 0.00021
Epoch: 247, validation loss: 0.00011
Epoch: 248, training loss: 0.00021
Epoch: 248, validation loss: 0.00011
Epoch: 249, training loss: 0.00021
Epoch: 249, validation loss: 0.00011
Epoch: 250, training loss: 0.00021
Epoch: 250, validation loss: 0.00011
Epoch: 251, training loss: 0.00021
Epoch: 251, validation loss: 0.00011
Epoch: 252, training loss: 0.00021
Epoch: 252, validation loss: 0.00010
Epoch: 253, training loss: 0.00021
Epoch: 253, validation loss: 0.00011
Epoch: 254, training loss: 0.00021
Epoch: 254, validation loss: 0.00010
Epoch: 255, training loss: 0.00021
Epoch: 255, validation loss: 0.00010
Epoch: 256, training loss: 0.00021
Epoch: 256, validation loss: 0.00010
Epoch: 257, training loss: 0.00020
Epoch: 257, validation loss: 0.00011
Epoch: 258, training loss: 0.00021
Epoch: 258, validation loss: 0.00010
Epoch: 259, training loss: 0.00020
Epoch: 259, validation loss: 0.00011
Epoch: 260, training loss: 0.00021
Epoch: 260, validation loss: 0.00010
Epoch: 261, training loss: 0.00020
Epoch: 261, validation loss: 0.00010
Epoch: 262, training loss: 0.00021
Epoch: 262, validation loss: 0.00010
Epoch: 263, training loss: 0.00020
Epoch: 263, validation loss: 0.00010
Epoch: 264, training loss: 0.00020
Epoch: 264, validation loss: 0.00010
Epoch: 265, training loss: 0.00020
Epoch: 265, validation loss: 0.00010
Epoch: 266, training loss: 0.00020
Epoch: 266, validation loss: 0.00010
Epoch: 267, training loss: 0.00020
Epoch: 267, validation loss: 0.00010
Epoch: 268, training loss: 0.00020
Epoch: 268, validation loss: 0.00010
Epoch: 269, training loss: 0.00020
Epoch: 269, validation loss: 0.00010
Epoch: 270, training loss: 0.00020
Epoch: 270, validation loss: 0.00010
Epoch: 271, training loss: 0.00020
Epoch: 271, validation loss: 0.00010
Epoch: 272, training loss: 0.00020
Epoch: 272, validation loss: 0.00010
Epoch: 273, training loss: 0.00020
Epoch: 273, validation loss: 0.00010
Epoch: 274, training loss: 0.00020
Epoch: 274, validation loss: 0.00010
Epoch: 275, training loss: 0.00020
Epoch: 275, validation loss: 0.00010
Epoch: 276, training loss: 0.00020
Epoch: 276, validation loss: 0.00010
Epoch: 277, training loss: 0.00020
Epoch: 277, validation loss: 0.00010
Epoch: 278, training loss: 0.00020
Epoch: 278, validation loss: 0.00010
Epoch: 279, training loss: 0.00020
Epoch: 279, validation loss: 0.00010
Epoch: 280, training loss: 0.00020
Epoch: 280, validation loss: 0.00010
Epoch: 281, training loss: 0.00020
Epoch: 281, validation loss: 0.00010
Epoch: 282, training loss: 0.00019
Epoch: 282, validation loss: 0.00010
Epoch: 283, training loss: 0.00020
Epoch: 283, validation loss: 0.00010
Epoch: 284, training loss: 0.00020
Epoch: 284, validation loss: 0.00010
Epoch: 285, training loss: 0.00020
Epoch: 285, validation loss: 0.00010
Epoch: 286, training loss: 0.00020
Epoch: 286, validation loss: 0.00010
Epoch: 287, training loss: 0.00020
Epoch: 287, validation loss: 0.00010
Epoch: 288, training loss: 0.00019
Epoch: 288, validation loss: 0.00010
Epoch: 289, training loss: 0.00020
Epoch: 289, validation loss: 0.00010
Epoch: 290, training loss: 0.00019
Epoch: 290, validation loss: 0.00010
Epoch: 291, training loss: 0.00020
Epoch: 291, validation loss: 0.00010
Epoch: 292, training loss: 0.00019
Epoch: 292, validation loss: 0.00010
Epoch: 293, training loss: 0.00020
Epoch: 293, validation loss: 0.00010
Epoch: 294, training loss: 0.00019
Epoch: 294, validation loss: 0.00010
Epoch: 295, training loss: 0.00020
Epoch: 295, validation loss: 0.00010
Epoch: 296, training loss: 0.00019
Epoch: 296, validation loss: 0.00010
Epoch: 297, training loss: 0.00019
Epoch: 297, validation loss: 0.00010
Epoch: 298, training loss: 0.00019
Epoch: 298, validation loss: 0.00010
Epoch: 299, training loss: 0.00019
Epoch: 299, validation loss: 0.00010

0:15:31.947172
the relationship between loss and epochs for given hyper parameters
Traceback (most recent call last):
  File "lstm_sbi.py", line 144, in <module>
    list_df_cond = buildLSTM(lstm_name, lstm_path, save_lstm, shuffle_it_in, 
  File "/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/03_sbi_lstm/lstm_build.py", line 284, in buildLSTM
    r2_out, stats_out = evallstm(lstm=lstm_out, dataY=temp_df['DataY'][idx], dataX=temp_df['DataX'][idx],
IndexError: too many indices for tensor of dimension 2
