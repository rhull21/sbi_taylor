Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 17/10000 [00:00<01:00, 164.73it/s]Running 10000 simulations.:   0%|          | 34/10000 [00:00<01:00, 165.74it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<01:00, 164.91it/s]Running 10000 simulations.:   1%|          | 68/10000 [00:00<01:00, 165.42it/s]Running 10000 simulations.:   1%|          | 85/10000 [00:00<00:59, 165.45it/s]Running 10000 simulations.:   1%|          | 102/10000 [00:00<01:00, 164.82it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<01:00, 164.56it/s]Running 10000 simulations.:   1%|▏         | 136/10000 [00:00<01:00, 164.25it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:59, 164.22it/s]Running 10000 simulations.:   2%|▏         | 170/10000 [00:01<00:59, 163.99it/s]Running 10000 simulations.:   2%|▏         | 187/10000 [00:01<00:59, 164.52it/s]Running 10000 simulations.:   2%|▏         | 204/10000 [00:01<00:59, 164.36it/s]Running 10000 simulations.:   2%|▏         | 221/10000 [00:01<00:59, 163.98it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:01<00:59, 164.30it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<00:59, 164.22it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<00:59, 164.81it/s]Running 10000 simulations.:   3%|▎         | 289/10000 [00:01<00:58, 164.90it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:58, 164.77it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:58, 165.41it/s]Running 10000 simulations.:   3%|▎         | 340/10000 [00:02<00:58, 165.13it/s]Running 10000 simulations.:   4%|▎         | 357/10000 [00:02<00:58, 164.87it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:02<00:58, 164.36it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:02<00:58, 164.70it/s]Running 10000 simulations.:   4%|▍         | 408/10000 [00:02<00:58, 165.21it/s]Running 10000 simulations.:   4%|▍         | 425/10000 [00:02<00:58, 164.92it/s]Running 10000 simulations.:   4%|▍         | 442/10000 [00:02<00:57, 165.08it/s]Running 10000 simulations.:   5%|▍         | 459/10000 [00:02<00:57, 165.11it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:02<00:57, 164.99it/s]Running 10000 simulations.:   5%|▍         | 493/10000 [00:02<00:57, 165.23it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:03<00:57, 165.05it/s]Running 10000 simulations.:   5%|▌         | 527/10000 [00:03<00:57, 165.08it/s]Running 10000 simulations.:   5%|▌         | 544/10000 [00:03<00:57, 164.97it/s]Running 10000 simulations.:   6%|▌         | 561/10000 [00:03<00:57, 164.75it/s]Running 10000 simulations.:   6%|▌         | 578/10000 [00:03<00:57, 164.94it/s]Running 10000 simulations.:   6%|▌         | 595/10000 [00:03<00:57, 164.66it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:03<00:57, 164.42it/s]Running 10000 simulations.:   6%|▋         | 629/10000 [00:03<00:56, 164.59it/s]Running 10000 simulations.:   6%|▋         | 646/10000 [00:03<00:57, 163.98it/s]Running 10000 simulations.:   7%|▋         | 663/10000 [00:04<00:56, 163.90it/s]Running 10000 simulations.:   7%|▋         | 680/10000 [00:04<00:56, 164.39it/s]Running 10000 simulations.:   7%|▋         | 697/10000 [00:04<00:56, 164.03it/s]Running 10000 simulations.:   7%|▋         | 714/10000 [00:04<00:57, 161.27it/s]Running 10000 simulations.:   7%|▋         | 731/10000 [00:04<00:58, 158.70it/s]Running 10000 simulations.:   7%|▋         | 747/10000 [00:04<00:58, 156.85it/s]Running 10000 simulations.:   8%|▊         | 763/10000 [00:04<00:59, 155.52it/s]Running 10000 simulations.:   8%|▊         | 779/10000 [00:04<00:59, 154.19it/s]Running 10000 simulations.:   8%|▊         | 795/10000 [00:04<00:59, 154.10it/s]Running 10000 simulations.:   8%|▊         | 811/10000 [00:04<00:59, 154.27it/s]Running 10000 simulations.:   8%|▊         | 827/10000 [00:05<00:59, 154.49it/s]Running 10000 simulations.:   8%|▊         | 843/10000 [00:05<00:59, 153.60it/s]Running 10000 simulations.:   9%|▊         | 859/10000 [00:05<00:59, 152.87it/s]Running 10000 simulations.:   9%|▉         | 875/10000 [00:05<00:59, 153.60it/s]Running 10000 simulations.:   9%|▉         | 892/10000 [00:05<00:58, 155.66it/s]Running 10000 simulations.:   9%|▉         | 908/10000 [00:05<00:57, 156.90it/s]Running 10000 simulations.:   9%|▉         | 924/10000 [00:05<00:58, 156.04it/s]Running 10000 simulations.:   9%|▉         | 940/10000 [00:05<00:58, 155.35it/s]Running 10000 simulations.:  10%|▉         | 956/10000 [00:05<00:58, 153.67it/s]Running 10000 simulations.:  10%|▉         | 972/10000 [00:06<00:58, 153.99it/s]Running 10000 simulations.:  10%|▉         | 988/10000 [00:06<00:58, 154.20it/s]Running 10000 simulations.:  10%|█         | 1004/10000 [00:06<00:59, 152.18it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:06<00:58, 152.82it/s]Running 10000 simulations.:  10%|█         | 1036/10000 [00:06<00:58, 153.06it/s]Running 10000 simulations.:  11%|█         | 1052/10000 [00:06<00:58, 154.20it/s]Running 10000 simulations.:  11%|█         | 1068/10000 [00:06<00:58, 151.63it/s]Running 10000 simulations.:  11%|█         | 1084/10000 [00:06<01:00, 147.46it/s]Running 10000 simulations.:  11%|█         | 1099/10000 [00:06<01:02, 141.47it/s]Running 10000 simulations.:  11%|█         | 1114/10000 [00:06<01:02, 142.70it/s]Running 10000 simulations.:  11%|█▏        | 1130/10000 [00:07<01:00, 145.72it/s]Running 10000 simulations.:  11%|█▏        | 1146/10000 [00:07<00:59, 147.84it/s]Running 10000 simulations.:  12%|█▏        | 1162/10000 [00:07<00:58, 150.02it/s]Running 10000 simulations.:  12%|█▏        | 1178/10000 [00:07<00:58, 151.40it/s]Running 10000 simulations.:  12%|█▏        | 1194/10000 [00:07<00:57, 152.36it/s]Running 10000 simulations.:  12%|█▏        | 1210/10000 [00:07<00:57, 153.47it/s]Running 10000 simulations.:  12%|█▏        | 1226/10000 [00:07<00:56, 154.60it/s]Running 10000 simulations.:  12%|█▏        | 1243/10000 [00:07<00:56, 156.24it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:07<00:55, 156.28it/s]Running 10000 simulations.:  13%|█▎        | 1275/10000 [00:08<00:55, 156.53it/s]Running 10000 simulations.:  13%|█▎        | 1291/10000 [00:08<00:55, 156.67it/s]Running 10000 simulations.:  13%|█▎        | 1308/10000 [00:08<00:55, 157.70it/s]Running 10000 simulations.:  13%|█▎        | 1324/10000 [00:08<00:55, 156.75it/s]Running 10000 simulations.:  13%|█▎        | 1340/10000 [00:08<00:55, 156.59it/s]Running 10000 simulations.:  14%|█▎        | 1356/10000 [00:08<00:55, 155.85it/s]Running 10000 simulations.:  14%|█▎        | 1372/10000 [00:08<00:55, 155.74it/s]Running 10000 simulations.:  14%|█▍        | 1388/10000 [00:08<00:55, 155.21it/s]Running 10000 simulations.:  14%|█▍        | 1404/10000 [00:08<00:55, 155.67it/s]Running 10000 simulations.:  14%|█▍        | 1420/10000 [00:08<00:55, 155.40it/s]Running 10000 simulations.:  14%|█▍        | 1436/10000 [00:09<00:55, 155.40it/s]Running 10000 simulations.:  15%|█▍        | 1452/10000 [00:09<00:55, 154.75it/s]Running 10000 simulations.:  15%|█▍        | 1468/10000 [00:09<00:55, 154.65it/s]Running 10000 simulations.:  15%|█▍        | 1484/10000 [00:09<00:54, 155.73it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:09<00:54, 155.12it/s]Running 10000 simulations.:  15%|█▌        | 1517/10000 [00:09<00:53, 158.21it/s]Running 10000 simulations.:  15%|█▌        | 1535/10000 [00:09<00:51, 164.11it/s]Running 10000 simulations.:  16%|█▌        | 1554/10000 [00:09<00:50, 168.74it/s]Running 10000 simulations.:  16%|█▌        | 1571/10000 [00:09<00:51, 163.85it/s]Running 10000 simulations.:  16%|█▌        | 1588/10000 [00:09<00:52, 160.62it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:10<00:53, 158.35it/s]Running 10000 simulations.:  16%|█▌        | 1621/10000 [00:10<00:53, 156.90it/s]Running 10000 simulations.:  16%|█▋        | 1637/10000 [00:10<00:53, 155.62it/s]Running 10000 simulations.:  17%|█▋        | 1653/10000 [00:10<00:53, 155.02it/s]Running 10000 simulations.:  17%|█▋        | 1669/10000 [00:10<00:53, 154.50it/s]Running 10000 simulations.:  17%|█▋        | 1685/10000 [00:10<00:53, 154.45it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:10<00:53, 154.25it/s]Running 10000 simulations.:  17%|█▋        | 1717/10000 [00:10<00:53, 154.23it/s]Running 10000 simulations.:  17%|█▋        | 1733/10000 [00:10<00:53, 154.44it/s]Running 10000 simulations.:  17%|█▋        | 1749/10000 [00:11<00:52, 155.84it/s]Running 10000 simulations.:  18%|█▊        | 1765/10000 [00:11<00:52, 156.84it/s]Running 10000 simulations.:  18%|█▊        | 1781/10000 [00:11<00:52, 157.28it/s]Running 10000 simulations.:  18%|█▊        | 1797/10000 [00:11<00:52, 157.63it/s]Running 10000 simulations.:  18%|█▊        | 1813/10000 [00:11<00:51, 157.77it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:11<00:51, 157.97it/s]Running 10000 simulations.:  18%|█▊        | 1845/10000 [00:11<00:51, 158.32it/s]Running 10000 simulations.:  19%|█▊        | 1861/10000 [00:11<00:51, 158.10it/s]Running 10000 simulations.:  19%|█▉        | 1877/10000 [00:11<00:51, 158.43it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:11<00:51, 158.55it/s]Running 10000 simulations.:  19%|█▉        | 1909/10000 [00:12<00:51, 158.31it/s]Running 10000 simulations.:  19%|█▉        | 1925/10000 [00:12<00:51, 158.14it/s]Running 10000 simulations.:  19%|█▉        | 1941/10000 [00:12<00:50, 158.67it/s]Running 10000 simulations.:  20%|█▉        | 1958/10000 [00:12<00:50, 159.14it/s]Running 10000 simulations.:  20%|█▉        | 1974/10000 [00:12<00:50, 158.89it/s]Running 10000 simulations.:  20%|█▉        | 1990/10000 [00:12<00:50, 158.64it/s]Running 10000 simulations.:  20%|██        | 2006/10000 [00:12<00:50, 158.57it/s]Running 10000 simulations.:  20%|██        | 2022/10000 [00:12<00:50, 158.57it/s]Running 10000 simulations.:  20%|██        | 2038/10000 [00:12<00:50, 158.58it/s]Running 10000 simulations.:  21%|██        | 2054/10000 [00:12<00:50, 158.45it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:13<00:50, 158.29it/s]Running 10000 simulations.:  21%|██        | 2087/10000 [00:13<00:49, 158.92it/s]Running 10000 simulations.:  21%|██        | 2103/10000 [00:13<00:49, 158.73it/s]Running 10000 simulations.:  21%|██        | 2119/10000 [00:13<00:49, 158.46it/s]Running 10000 simulations.:  21%|██▏       | 2135/10000 [00:13<00:49, 158.41it/s]Running 10000 simulations.:  22%|██▏       | 2151/10000 [00:13<00:49, 158.84it/s]Running 10000 simulations.:  22%|██▏       | 2168/10000 [00:13<00:49, 159.29it/s]Running 10000 simulations.:  22%|██▏       | 2184/10000 [00:13<00:49, 158.98it/s]Running 10000 simulations.:  22%|██▏       | 2200/10000 [00:13<00:49, 158.86it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:13<00:49, 158.81it/s]Running 10000 simulations.:  22%|██▏       | 2232/10000 [00:14<00:48, 158.87it/s]Running 10000 simulations.:  22%|██▏       | 2248/10000 [00:14<00:48, 158.62it/s]Running 10000 simulations.:  23%|██▎       | 2264/10000 [00:14<00:49, 157.71it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:14<00:49, 155.70it/s]Running 10000 simulations.:  23%|██▎       | 2296/10000 [00:14<00:49, 154.75it/s]Running 10000 simulations.:  23%|██▎       | 2312/10000 [00:14<00:50, 153.69it/s]Running 10000 simulations.:  23%|██▎       | 2328/10000 [00:14<00:50, 152.75it/s]Running 10000 simulations.:  23%|██▎       | 2344/10000 [00:14<00:50, 152.57it/s]Running 10000 simulations.:  24%|██▎       | 2360/10000 [00:14<00:50, 151.69it/s]Running 10000 simulations.:  24%|██▍       | 2376/10000 [00:15<00:50, 152.12it/s]Running 10000 simulations.:  24%|██▍       | 2392/10000 [00:15<00:50, 151.53it/s]Running 10000 simulations.:  24%|██▍       | 2408/10000 [00:15<00:49, 152.61it/s]Running 10000 simulations.:  24%|██▍       | 2424/10000 [00:15<00:49, 151.55it/s]Running 10000 simulations.:  24%|██▍       | 2440/10000 [00:15<00:49, 151.94it/s]Running 10000 simulations.:  25%|██▍       | 2456/10000 [00:15<00:49, 152.04it/s]Running 10000 simulations.:  25%|██▍       | 2472/10000 [00:15<00:49, 151.78it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:15<00:49, 150.65it/s]Running 10000 simulations.:  25%|██▌       | 2504/10000 [00:15<00:49, 150.71it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:15<00:49, 151.31it/s]Running 10000 simulations.:  25%|██▌       | 2536/10000 [00:16<00:48, 152.94it/s]Running 10000 simulations.:  26%|██▌       | 2552/10000 [00:16<00:48, 153.74it/s]Running 10000 simulations.:  26%|██▌       | 2568/10000 [00:16<00:48, 153.67it/s]Running 10000 simulations.:  26%|██▌       | 2584/10000 [00:16<00:48, 153.98it/s]Running 10000 simulations.:  26%|██▌       | 2600/10000 [00:16<00:48, 153.34it/s]Running 10000 simulations.:  26%|██▌       | 2616/10000 [00:16<00:48, 151.45it/s]Running 10000 simulations.:  26%|██▋       | 2632/10000 [00:16<00:48, 151.25it/s]Running 10000 simulations.:  26%|██▋       | 2648/10000 [00:16<00:48, 151.43it/s]Running 10000 simulations.:  27%|██▋       | 2664/10000 [00:16<00:48, 151.43it/s]Running 10000 simulations.:  27%|██▋       | 2680/10000 [00:17<00:48, 150.79it/s]Running 10000 simulations.:  27%|██▋       | 2696/10000 [00:17<00:48, 149.79it/s]Running 10000 simulations.:  27%|██▋       | 2711/10000 [00:17<00:48, 149.83it/s]Running 10000 simulations.:  27%|██▋       | 2726/10000 [00:17<00:48, 149.82it/s]Running 10000 simulations.:  27%|██▋       | 2741/10000 [00:17<00:49, 147.91it/s]Running 10000 simulations.:  28%|██▊       | 2756/10000 [00:17<00:49, 146.97it/s]Running 10000 simulations.:  28%|██▊       | 2771/10000 [00:17<00:49, 145.90it/s]Running 10000 simulations.:  28%|██▊       | 2786/10000 [00:17<00:50, 144.08it/s]Running 10000 simulations.:  28%|██▊       | 2801/10000 [00:17<00:50, 141.86it/s]Running 10000 simulations.:  28%|██▊       | 2816/10000 [00:17<00:50, 141.15it/s]Running 10000 simulations.:  28%|██▊       | 2831/10000 [00:18<00:50, 142.77it/s]Running 10000 simulations.:  28%|██▊       | 2847/10000 [00:18<00:49, 145.03it/s]Running 10000 simulations.:  29%|██▊       | 2862/10000 [00:18<00:48, 146.49it/s]Running 10000 simulations.:  29%|██▉       | 2877/10000 [00:18<00:48, 147.18it/s]Running 10000 simulations.:  29%|██▉       | 2892/10000 [00:18<00:48, 147.97it/s]Running 10000 simulations.:  29%|██▉       | 2907/10000 [00:18<00:47, 148.45it/s]Running 10000 simulations.:  29%|██▉       | 2922/10000 [00:18<00:47, 148.67it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:18<00:47, 149.33it/s]Running 10000 simulations.:  30%|██▉       | 2953/10000 [00:18<00:47, 149.43it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:18<00:47, 149.52it/s]Running 10000 simulations.:  30%|██▉       | 2984/10000 [00:19<00:46, 150.48it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:19<00:46, 149.74it/s]Running 10000 simulations.:  30%|███       | 3015/10000 [00:19<00:46, 149.49it/s]Running 10000 simulations.:  30%|███       | 3031/10000 [00:19<00:46, 150.00it/s]Running 10000 simulations.:  30%|███       | 3047/10000 [00:19<00:46, 150.38it/s]Running 10000 simulations.:  31%|███       | 3063/10000 [00:19<00:45, 151.12it/s]Running 10000 simulations.:  31%|███       | 3079/10000 [00:19<00:45, 151.05it/s]Running 10000 simulations.:  31%|███       | 3095/10000 [00:19<00:45, 150.93it/s]Running 10000 simulations.:  31%|███       | 3111/10000 [00:19<00:45, 150.81it/s]Running 10000 simulations.:  31%|███▏      | 3127/10000 [00:20<00:45, 150.52it/s]Running 10000 simulations.:  31%|███▏      | 3143/10000 [00:20<00:45, 150.71it/s]Running 10000 simulations.:  32%|███▏      | 3159/10000 [00:20<00:45, 150.74it/s]Running 10000 simulations.:  32%|███▏      | 3175/10000 [00:20<00:44, 151.67it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:20<00:44, 151.78it/s]Running 10000 simulations.:  32%|███▏      | 3207/10000 [00:20<00:44, 151.25it/s]Running 10000 simulations.:  32%|███▏      | 3223/10000 [00:20<00:44, 151.21it/s]Running 10000 simulations.:  32%|███▏      | 3239/10000 [00:20<00:44, 151.17it/s]Running 10000 simulations.:  33%|███▎      | 3255/10000 [00:20<00:44, 151.22it/s]Running 10000 simulations.:  33%|███▎      | 3271/10000 [00:20<00:44, 151.18it/s]Running 10000 simulations.:  33%|███▎      | 3287/10000 [00:21<00:44, 151.19it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:21<00:44, 151.22it/s]Running 10000 simulations.:  33%|███▎      | 3319/10000 [00:21<00:44, 151.50it/s]Running 10000 simulations.:  33%|███▎      | 3335/10000 [00:21<00:44, 150.97it/s]Running 10000 simulations.:  34%|███▎      | 3351/10000 [00:21<00:44, 150.45it/s]Running 10000 simulations.:  34%|███▎      | 3367/10000 [00:21<00:44, 150.30it/s]Running 10000 simulations.:  34%|███▍      | 3383/10000 [00:21<00:43, 151.64it/s]Running 10000 simulations.:  34%|███▍      | 3399/10000 [00:21<00:43, 150.98it/s]Running 10000 simulations.:  34%|███▍      | 3415/10000 [00:21<00:43, 150.69it/s]Running 10000 simulations.:  34%|███▍      | 3431/10000 [00:22<00:43, 150.82it/s]Running 10000 simulations.:  34%|███▍      | 3447/10000 [00:22<00:43, 150.72it/s]Running 10000 simulations.:  35%|███▍      | 3463/10000 [00:22<00:43, 150.83it/s]Running 10000 simulations.:  35%|███▍      | 3479/10000 [00:22<00:43, 150.64it/s]Running 10000 simulations.:  35%|███▍      | 3495/10000 [00:22<00:43, 150.97it/s]Running 10000 simulations.:  35%|███▌      | 3511/10000 [00:22<00:43, 150.89it/s]Running 10000 simulations.:  35%|███▌      | 3527/10000 [00:22<00:42, 150.63it/s]Running 10000 simulations.:  35%|███▌      | 3543/10000 [00:22<00:43, 150.06it/s]Running 10000 simulations.:  36%|███▌      | 3559/10000 [00:22<00:42, 150.15it/s]Running 10000 simulations.:  36%|███▌      | 3575/10000 [00:23<00:42, 150.35it/s]Running 10000 simulations.:  36%|███▌      | 3591/10000 [00:23<00:42, 151.28it/s]Running 10000 simulations.:  36%|███▌      | 3607/10000 [00:23<00:42, 150.46it/s]Running 10000 simulations.:  36%|███▌      | 3623/10000 [00:23<00:42, 150.05it/s]Running 10000 simulations.:  36%|███▋      | 3639/10000 [00:23<00:42, 149.89it/s]Running 10000 simulations.:  37%|███▋      | 3654/10000 [00:23<00:42, 149.72it/s]Running 10000 simulations.:  37%|███▋      | 3670/10000 [00:23<00:42, 149.90it/s]Running 10000 simulations.:  37%|███▋      | 3685/10000 [00:23<00:42, 149.74it/s]Running 10000 simulations.:  37%|███▋      | 3701/10000 [00:23<00:41, 150.00it/s]Running 10000 simulations.:  37%|███▋      | 3717/10000 [00:23<00:41, 150.00it/s]Running 10000 simulations.:  37%|███▋      | 3733/10000 [00:24<00:41, 149.92it/s]Running 10000 simulations.:  37%|███▋      | 3748/10000 [00:24<00:41, 149.56it/s]Running 10000 simulations.:  38%|███▊      | 3763/10000 [00:24<00:41, 149.62it/s]Running 10000 simulations.:  38%|███▊      | 3779/10000 [00:24<00:41, 150.64it/s]Running 10000 simulations.:  38%|███▊      | 3797/10000 [00:24<00:39, 156.26it/s]Running 10000 simulations.:  38%|███▊      | 3815/10000 [00:24<00:38, 160.95it/s]Running 10000 simulations.:  38%|███▊      | 3832/10000 [00:24<00:38, 161.37it/s]Running 10000 simulations.:  38%|███▊      | 3849/10000 [00:24<00:38, 157.91it/s]Running 10000 simulations.:  39%|███▊      | 3865/10000 [00:24<00:39, 155.56it/s]Running 10000 simulations.:  39%|███▉      | 3881/10000 [00:25<00:39, 153.83it/s]Running 10000 simulations.:  39%|███▉      | 3897/10000 [00:25<00:39, 152.96it/s]Running 10000 simulations.:  39%|███▉      | 3913/10000 [00:25<00:40, 151.85it/s]Running 10000 simulations.:  39%|███▉      | 3929/10000 [00:25<00:40, 151.56it/s]Running 10000 simulations.:  39%|███▉      | 3945/10000 [00:25<00:40, 151.29it/s]Running 10000 simulations.:  40%|███▉      | 3961/10000 [00:25<00:40, 150.88it/s]Running 10000 simulations.:  40%|███▉      | 3977/10000 [00:25<00:39, 150.80it/s]Running 10000 simulations.:  40%|███▉      | 3993/10000 [00:25<00:39, 150.40it/s]Running 10000 simulations.:  40%|████      | 4009/10000 [00:25<00:39, 150.52it/s]Running 10000 simulations.:  40%|████      | 4025/10000 [00:25<00:39, 151.37it/s]Running 10000 simulations.:  40%|████      | 4041/10000 [00:26<00:39, 151.35it/s]Running 10000 simulations.:  41%|████      | 4057/10000 [00:26<00:39, 150.53it/s]Running 10000 simulations.:  41%|████      | 4073/10000 [00:26<00:41, 141.99it/s]Running 10000 simulations.:  41%|████      | 4088/10000 [00:26<00:40, 144.28it/s]Running 10000 simulations.:  41%|████      | 4104/10000 [00:26<00:40, 146.12it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:26<00:39, 147.19it/s]Running 10000 simulations.:  41%|████▏     | 4135/10000 [00:26<00:39, 148.19it/s]Running 10000 simulations.:  42%|████▏     | 4151/10000 [00:26<00:39, 149.11it/s]Running 10000 simulations.:  42%|████▏     | 4167/10000 [00:26<00:39, 149.55it/s]Running 10000 simulations.:  42%|████▏     | 4182/10000 [00:27<00:38, 149.36it/s]Running 10000 simulations.:  42%|████▏     | 4197/10000 [00:27<00:38, 149.43it/s]Running 10000 simulations.:  42%|████▏     | 4213/10000 [00:27<00:38, 149.64it/s]Running 10000 simulations.:  42%|████▏     | 4228/10000 [00:27<00:38, 148.36it/s]Running 10000 simulations.:  42%|████▏     | 4244/10000 [00:27<00:38, 149.14it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:27<00:38, 149.22it/s]Running 10000 simulations.:  43%|████▎     | 4275/10000 [00:27<00:38, 149.44it/s]Running 10000 simulations.:  43%|████▎     | 4291/10000 [00:27<00:38, 150.03it/s]Running 10000 simulations.:  43%|████▎     | 4307/10000 [00:27<00:37, 150.20it/s]Running 10000 simulations.:  43%|████▎     | 4323/10000 [00:27<00:37, 150.37it/s]Running 10000 simulations.:  43%|████▎     | 4339/10000 [00:28<00:37, 150.52it/s]Running 10000 simulations.:  44%|████▎     | 4355/10000 [00:28<00:37, 150.25it/s]Running 10000 simulations.:  44%|████▎     | 4371/10000 [00:28<00:37, 150.60it/s]Running 10000 simulations.:  44%|████▍     | 4387/10000 [00:28<00:37, 150.75it/s]Running 10000 simulations.:  44%|████▍     | 4403/10000 [00:28<00:37, 150.86it/s]Running 10000 simulations.:  44%|████▍     | 4419/10000 [00:28<00:36, 151.67it/s]Running 10000 simulations.:  44%|████▍     | 4435/10000 [00:28<00:36, 151.55it/s]Running 10000 simulations.:  45%|████▍     | 4451/10000 [00:28<00:36, 151.32it/s]Running 10000 simulations.:  45%|████▍     | 4467/10000 [00:28<00:36, 151.26it/s]Running 10000 simulations.:  45%|████▍     | 4483/10000 [00:29<00:36, 151.03it/s]Running 10000 simulations.:  45%|████▍     | 4499/10000 [00:29<00:36, 151.04it/s]Running 10000 simulations.:  45%|████▌     | 4515/10000 [00:29<00:36, 150.68it/s]Running 10000 simulations.:  45%|████▌     | 4531/10000 [00:29<00:36, 150.59it/s]Running 10000 simulations.:  45%|████▌     | 4547/10000 [00:29<00:36, 150.74it/s]Running 10000 simulations.:  46%|████▌     | 4563/10000 [00:29<00:36, 150.72it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:29<00:36, 150.28it/s]Running 10000 simulations.:  46%|████▌     | 4595/10000 [00:29<00:35, 150.18it/s]Running 10000 simulations.:  46%|████▌     | 4611/10000 [00:29<00:35, 150.64it/s]Running 10000 simulations.:  46%|████▋     | 4627/10000 [00:29<00:35, 152.04it/s]Running 10000 simulations.:  46%|████▋     | 4643/10000 [00:30<00:35, 151.18it/s]Running 10000 simulations.:  47%|████▋     | 4659/10000 [00:30<00:35, 152.18it/s]Running 10000 simulations.:  47%|████▋     | 4675/10000 [00:30<00:35, 152.14it/s]Running 10000 simulations.:  47%|████▋     | 4691/10000 [00:30<00:35, 151.20it/s]Running 10000 simulations.:  47%|████▋     | 4707/10000 [00:30<00:35, 150.83it/s]Running 10000 simulations.:  47%|████▋     | 4723/10000 [00:30<00:35, 150.48it/s]Running 10000 simulations.:  47%|████▋     | 4739/10000 [00:30<00:35, 150.20it/s]Running 10000 simulations.:  48%|████▊     | 4755/10000 [00:30<00:34, 150.28it/s]Running 10000 simulations.:  48%|████▊     | 4771/10000 [00:30<00:34, 150.11it/s]Running 10000 simulations.:  48%|████▊     | 4787/10000 [00:31<00:34, 150.06it/s]Running 10000 simulations.:  48%|████▊     | 4803/10000 [00:31<00:34, 149.96it/s]Running 10000 simulations.:  48%|████▊     | 4819/10000 [00:31<00:34, 149.97it/s]Running 10000 simulations.:  48%|████▊     | 4835/10000 [00:31<00:34, 151.58it/s]Running 10000 simulations.:  49%|████▊     | 4851/10000 [00:31<00:34, 151.30it/s]Running 10000 simulations.:  49%|████▊     | 4867/10000 [00:31<00:33, 151.46it/s]Running 10000 simulations.:  49%|████▉     | 4883/10000 [00:31<00:33, 151.72it/s]Running 10000 simulations.:  49%|████▉     | 4899/10000 [00:31<00:33, 151.25it/s]Running 10000 simulations.:  49%|████▉     | 4915/10000 [00:31<00:33, 151.45it/s]Running 10000 simulations.:  49%|████▉     | 4931/10000 [00:31<00:33, 151.40it/s]Running 10000 simulations.:  49%|████▉     | 4947/10000 [00:32<00:33, 151.07it/s]Running 10000 simulations.:  50%|████▉     | 4963/10000 [00:32<00:33, 150.64it/s]Running 10000 simulations.:  50%|████▉     | 4979/10000 [00:32<00:33, 150.29it/s]Running 10000 simulations.:  50%|████▉     | 4995/10000 [00:32<00:33, 150.29it/s]Running 10000 simulations.:  50%|█████     | 5011/10000 [00:32<00:33, 150.22it/s]Running 10000 simulations.:  50%|█████     | 5027/10000 [00:32<00:32, 150.73it/s]Running 10000 simulations.:  50%|█████     | 5043/10000 [00:32<00:32, 151.52it/s]Running 10000 simulations.:  51%|█████     | 5059/10000 [00:32<00:32, 151.85it/s]Running 10000 simulations.:  51%|█████     | 5075/10000 [00:32<00:32, 151.64it/s]Running 10000 simulations.:  51%|█████     | 5091/10000 [00:33<00:32, 151.23it/s]Running 10000 simulations.:  51%|█████     | 5107/10000 [00:33<00:32, 150.82it/s]Running 10000 simulations.:  51%|█████     | 5123/10000 [00:33<00:32, 150.21it/s]Running 10000 simulations.:  51%|█████▏    | 5139/10000 [00:33<00:32, 150.60it/s]Running 10000 simulations.:  52%|█████▏    | 5155/10000 [00:33<00:32, 150.35it/s]Running 10000 simulations.:  52%|█████▏    | 5171/10000 [00:33<00:32, 150.52it/s]Running 10000 simulations.:  52%|█████▏    | 5187/10000 [00:33<00:31, 150.90it/s]Running 10000 simulations.:  52%|█████▏    | 5203/10000 [00:33<00:31, 150.70it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:33<00:31, 150.66it/s]Running 10000 simulations.:  52%|█████▏    | 5235/10000 [00:34<00:31, 151.46it/s]Running 10000 simulations.:  53%|█████▎    | 5251/10000 [00:34<00:31, 151.25it/s]Running 10000 simulations.:  53%|█████▎    | 5267/10000 [00:34<00:31, 150.23it/s]Running 10000 simulations.:  53%|█████▎    | 5283/10000 [00:34<00:31, 150.86it/s]Running 10000 simulations.:  53%|█████▎    | 5299/10000 [00:34<00:31, 150.92it/s]Running 10000 simulations.:  53%|█████▎    | 5315/10000 [00:34<00:30, 151.15it/s]Running 10000 simulations.:  53%|█████▎    | 5331/10000 [00:34<00:30, 151.09it/s]Running 10000 simulations.:  53%|█████▎    | 5347/10000 [00:34<00:30, 150.90it/s]Running 10000 simulations.:  54%|█████▎    | 5363/10000 [00:34<00:30, 150.79it/s]Running 10000 simulations.:  54%|█████▍    | 5379/10000 [00:34<00:30, 150.83it/s]Running 10000 simulations.:  54%|█████▍    | 5395/10000 [00:35<00:30, 150.53it/s]Running 10000 simulations.:  54%|█████▍    | 5411/10000 [00:35<00:30, 150.55it/s]Running 10000 simulations.:  54%|█████▍    | 5427/10000 [00:35<00:30, 150.62it/s]Running 10000 simulations.:  54%|█████▍    | 5443/10000 [00:35<00:29, 152.02it/s]Running 10000 simulations.:  55%|█████▍    | 5459/10000 [00:35<00:29, 152.29it/s]Running 10000 simulations.:  55%|█████▍    | 5475/10000 [00:35<00:29, 152.21it/s]Running 10000 simulations.:  55%|█████▍    | 5491/10000 [00:35<00:29, 152.29it/s]Running 10000 simulations.:  55%|█████▌    | 5507/10000 [00:35<00:29, 151.93it/s]Running 10000 simulations.:  55%|█████▌    | 5523/10000 [00:35<00:29, 151.95it/s]Running 10000 simulations.:  55%|█████▌    | 5539/10000 [00:36<00:29, 151.27it/s]Running 10000 simulations.:  56%|█████▌    | 5555/10000 [00:36<00:29, 151.16it/s]Running 10000 simulations.:  56%|█████▌    | 5571/10000 [00:36<00:29, 151.52it/s]Running 10000 simulations.:  56%|█████▌    | 5587/10000 [00:36<00:29, 151.37it/s]Running 10000 simulations.:  56%|█████▌    | 5603/10000 [00:36<00:29, 151.22it/s]Running 10000 simulations.:  56%|█████▌    | 5619/10000 [00:36<00:28, 151.31it/s]Running 10000 simulations.:  56%|█████▋    | 5635/10000 [00:36<00:28, 152.35it/s]Running 10000 simulations.:  57%|█████▋    | 5651/10000 [00:36<00:28, 153.07it/s]Running 10000 simulations.:  57%|█████▋    | 5667/10000 [00:36<00:28, 152.06it/s]Running 10000 simulations.:  57%|█████▋    | 5683/10000 [00:36<00:28, 152.21it/s]Running 10000 simulations.:  57%|█████▋    | 5699/10000 [00:37<00:28, 151.49it/s]Running 10000 simulations.:  57%|█████▋    | 5715/10000 [00:37<00:28, 151.36it/s]Running 10000 simulations.:  57%|█████▋    | 5731/10000 [00:37<00:28, 151.18it/s]Running 10000 simulations.:  57%|█████▋    | 5747/10000 [00:37<00:28, 151.35it/s]Running 10000 simulations.:  58%|█████▊    | 5763/10000 [00:37<00:28, 150.97it/s]Running 10000 simulations.:  58%|█████▊    | 5779/10000 [00:37<00:27, 150.85it/s]Running 10000 simulations.:  58%|█████▊    | 5795/10000 [00:37<00:27, 151.01it/s]Running 10000 simulations.:  58%|█████▊    | 5811/10000 [00:37<00:27, 150.48it/s]Running 10000 simulations.:  58%|█████▊    | 5827/10000 [00:37<00:27, 151.09it/s]Running 10000 simulations.:  58%|█████▊    | 5843/10000 [00:38<00:27, 151.87it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:38<00:26, 157.46it/s]Running 10000 simulations.:  59%|█████▉    | 5879/10000 [00:38<00:25, 161.67it/s]Running 10000 simulations.:  59%|█████▉    | 5896/10000 [00:38<00:25, 162.71it/s]Running 10000 simulations.:  59%|█████▉    | 5913/10000 [00:38<00:25, 157.98it/s]Running 10000 simulations.:  59%|█████▉    | 5929/10000 [00:38<00:26, 155.74it/s]Running 10000 simulations.:  59%|█████▉    | 5945/10000 [00:38<00:26, 154.07it/s]Running 10000 simulations.:  60%|█████▉    | 5961/10000 [00:38<00:26, 152.83it/s]Running 10000 simulations.:  60%|█████▉    | 5977/10000 [00:38<00:26, 151.35it/s]Running 10000 simulations.:  60%|█████▉    | 5993/10000 [00:38<00:26, 150.85it/s]Running 10000 simulations.:  60%|██████    | 6009/10000 [00:39<00:26, 151.09it/s]Running 10000 simulations.:  60%|██████    | 6025/10000 [00:39<00:26, 151.29it/s]Running 10000 simulations.:  60%|██████    | 6041/10000 [00:39<00:26, 150.67it/s]Running 10000 simulations.:  61%|██████    | 6057/10000 [00:39<00:26, 149.87it/s]Running 10000 simulations.:  61%|██████    | 6072/10000 [00:39<00:26, 149.18it/s]Running 10000 simulations.:  61%|██████    | 6088/10000 [00:39<00:26, 149.87it/s]Running 10000 simulations.:  61%|██████    | 6104/10000 [00:39<00:25, 150.01it/s]Running 10000 simulations.:  61%|██████    | 6120/10000 [00:39<00:25, 149.97it/s]Running 10000 simulations.:  61%|██████▏   | 6136/10000 [00:39<00:25, 150.19it/s]Running 10000 simulations.:  62%|██████▏   | 6152/10000 [00:40<00:25, 150.11it/s]Running 10000 simulations.:  62%|██████▏   | 6168/10000 [00:40<00:25, 150.61it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:40<00:25, 150.46it/s]Running 10000 simulations.:  62%|██████▏   | 6200/10000 [00:40<00:25, 150.05it/s]Running 10000 simulations.:  62%|██████▏   | 6216/10000 [00:40<00:25, 150.12it/s]Running 10000 simulations.:  62%|██████▏   | 6232/10000 [00:40<00:25, 149.96it/s]Running 10000 simulations.:  62%|██████▏   | 6247/10000 [00:40<00:25, 149.96it/s]Running 10000 simulations.:  63%|██████▎   | 6262/10000 [00:40<00:25, 149.44it/s]Running 10000 simulations.:  63%|██████▎   | 6277/10000 [00:40<00:24, 149.39it/s]Running 10000 simulations.:  63%|██████▎   | 6293/10000 [00:40<00:24, 151.00it/s]Running 10000 simulations.:  63%|██████▎   | 6309/10000 [00:41<00:24, 150.47it/s]Running 10000 simulations.:  63%|██████▎   | 6325/10000 [00:41<00:24, 149.93it/s]Running 10000 simulations.:  63%|██████▎   | 6340/10000 [00:41<00:24, 149.46it/s]Running 10000 simulations.:  64%|██████▎   | 6355/10000 [00:41<00:24, 148.42it/s]Running 10000 simulations.:  64%|██████▎   | 6370/10000 [00:41<00:24, 147.23it/s]Running 10000 simulations.:  64%|██████▍   | 6385/10000 [00:41<00:24, 146.64it/s]Running 10000 simulations.:  64%|██████▍   | 6400/10000 [00:41<00:24, 146.02it/s]Running 10000 simulations.:  64%|██████▍   | 6415/10000 [00:41<00:24, 145.93it/s]Running 10000 simulations.:  64%|██████▍   | 6430/10000 [00:41<00:24, 146.55it/s]Running 10000 simulations.:  64%|██████▍   | 6445/10000 [00:42<00:24, 146.19it/s]Running 10000 simulations.:  65%|██████▍   | 6460/10000 [00:42<00:24, 146.50it/s]Running 10000 simulations.:  65%|██████▍   | 6475/10000 [00:42<00:24, 146.43it/s]Running 10000 simulations.:  65%|██████▍   | 6490/10000 [00:42<00:23, 147.38it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:42<00:23, 147.64it/s]Running 10000 simulations.:  65%|██████▌   | 6520/10000 [00:42<00:23, 147.08it/s]Running 10000 simulations.:  65%|██████▌   | 6535/10000 [00:42<00:23, 146.29it/s]Running 10000 simulations.:  66%|██████▌   | 6550/10000 [00:42<00:23, 145.99it/s]Running 10000 simulations.:  66%|██████▌   | 6565/10000 [00:42<00:23, 146.17it/s]Running 10000 simulations.:  66%|██████▌   | 6580/10000 [00:42<00:23, 145.58it/s]Running 10000 simulations.:  66%|██████▌   | 6595/10000 [00:43<00:23, 145.81it/s]Running 10000 simulations.:  66%|██████▌   | 6610/10000 [00:43<00:23, 146.01it/s]Running 10000 simulations.:  66%|██████▋   | 6625/10000 [00:43<00:23, 146.29it/s]Running 10000 simulations.:  66%|██████▋   | 6640/10000 [00:43<00:23, 146.01it/s]Running 10000 simulations.:  67%|██████▋   | 6655/10000 [00:43<00:23, 142.93it/s]Running 10000 simulations.:  67%|██████▋   | 6670/10000 [00:43<00:23, 143.77it/s]Running 10000 simulations.:  67%|██████▋   | 6685/10000 [00:43<00:22, 144.20it/s]Running 10000 simulations.:  67%|██████▋   | 6701/10000 [00:43<00:22, 146.52it/s]Running 10000 simulations.:  67%|██████▋   | 6716/10000 [00:43<00:22, 146.35it/s]Running 10000 simulations.:  67%|██████▋   | 6731/10000 [00:43<00:22, 146.12it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:44<00:22, 146.42it/s]Running 10000 simulations.:  68%|██████▊   | 6761/10000 [00:44<00:22, 145.97it/s]Running 10000 simulations.:  68%|██████▊   | 6776/10000 [00:44<00:22, 146.00it/s]Running 10000 simulations.:  68%|██████▊   | 6791/10000 [00:44<00:21, 146.06it/s]Running 10000 simulations.:  68%|██████▊   | 6806/10000 [00:44<00:21, 146.65it/s]Running 10000 simulations.:  68%|██████▊   | 6821/10000 [00:44<00:21, 146.74it/s]Running 10000 simulations.:  68%|██████▊   | 6836/10000 [00:44<00:21, 146.58it/s]Running 10000 simulations.:  69%|██████▊   | 6851/10000 [00:44<00:21, 146.54it/s]Running 10000 simulations.:  69%|██████▊   | 6866/10000 [00:44<00:21, 146.53it/s]Running 10000 simulations.:  69%|██████▉   | 6881/10000 [00:45<00:21, 146.57it/s]Running 10000 simulations.:  69%|██████▉   | 6896/10000 [00:45<00:21, 146.53it/s]Running 10000 simulations.:  69%|██████▉   | 6912/10000 [00:45<00:20, 148.06it/s]Running 10000 simulations.:  69%|██████▉   | 6927/10000 [00:45<00:20, 146.88it/s]Running 10000 simulations.:  69%|██████▉   | 6942/10000 [00:45<00:20, 146.41it/s]Running 10000 simulations.:  70%|██████▉   | 6957/10000 [00:45<00:20, 146.04it/s]Running 10000 simulations.:  70%|██████▉   | 6972/10000 [00:45<00:20, 146.24it/s]Running 10000 simulations.:  70%|██████▉   | 6987/10000 [00:45<00:20, 145.95it/s]Running 10000 simulations.:  70%|███████   | 7002/10000 [00:45<00:20, 145.65it/s]Running 10000 simulations.:  70%|███████   | 7017/10000 [00:45<00:20, 145.40it/s]Running 10000 simulations.:  70%|███████   | 7032/10000 [00:46<00:20, 145.55it/s]Running 10000 simulations.:  70%|███████   | 7047/10000 [00:46<00:20, 145.41it/s]Running 10000 simulations.:  71%|███████   | 7062/10000 [00:46<00:20, 145.79it/s]Running 10000 simulations.:  71%|███████   | 7077/10000 [00:46<00:19, 146.24it/s]Running 10000 simulations.:  71%|███████   | 7092/10000 [00:46<00:19, 146.26it/s]Running 10000 simulations.:  71%|███████   | 7108/10000 [00:46<00:19, 147.92it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:46<00:19, 146.95it/s]Running 10000 simulations.:  71%|███████▏  | 7138/10000 [00:46<00:19, 146.69it/s]Running 10000 simulations.:  72%|███████▏  | 7153/10000 [00:46<00:19, 146.64it/s]Running 10000 simulations.:  72%|███████▏  | 7168/10000 [00:46<00:19, 146.67it/s]Running 10000 simulations.:  72%|███████▏  | 7183/10000 [00:47<00:19, 146.48it/s]Running 10000 simulations.:  72%|███████▏  | 7198/10000 [00:47<00:19, 146.72it/s]Running 10000 simulations.:  72%|███████▏  | 7213/10000 [00:47<00:18, 147.08it/s]Running 10000 simulations.:  72%|███████▏  | 7228/10000 [00:47<00:18, 147.14it/s]Running 10000 simulations.:  72%|███████▏  | 7243/10000 [00:47<00:18, 146.82it/s]Running 10000 simulations.:  73%|███████▎  | 7258/10000 [00:47<00:18, 146.98it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:47<00:18, 147.35it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:47<00:18, 148.72it/s]Running 10000 simulations.:  73%|███████▎  | 7305/10000 [00:47<00:18, 149.59it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:47<00:17, 150.80it/s]Running 10000 simulations.:  73%|███████▎  | 7337/10000 [00:48<00:17, 150.60it/s]Running 10000 simulations.:  74%|███████▎  | 7353/10000 [00:48<00:17, 150.95it/s]Running 10000 simulations.:  74%|███████▎  | 7369/10000 [00:48<00:17, 150.98it/s]Running 10000 simulations.:  74%|███████▍  | 7385/10000 [00:48<00:17, 150.99it/s]Running 10000 simulations.:  74%|███████▍  | 7401/10000 [00:48<00:17, 151.14it/s]Running 10000 simulations.:  74%|███████▍  | 7417/10000 [00:48<00:17, 151.04it/s]Running 10000 simulations.:  74%|███████▍  | 7433/10000 [00:48<00:17, 149.39it/s]Running 10000 simulations.:  74%|███████▍  | 7449/10000 [00:48<00:17, 149.72it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:48<00:16, 149.47it/s]Running 10000 simulations.:  75%|███████▍  | 7480/10000 [00:49<00:16, 149.71it/s]Running 10000 simulations.:  75%|███████▍  | 7495/10000 [00:49<00:16, 149.55it/s]Running 10000 simulations.:  75%|███████▌  | 7511/10000 [00:49<00:16, 150.08it/s]Running 10000 simulations.:  75%|███████▌  | 7527/10000 [00:49<00:16, 150.62it/s]Running 10000 simulations.:  75%|███████▌  | 7543/10000 [00:49<00:16, 150.44it/s]Running 10000 simulations.:  76%|███████▌  | 7559/10000 [00:49<00:16, 151.00it/s]Running 10000 simulations.:  76%|███████▌  | 7575/10000 [00:49<00:16, 151.31it/s]Running 10000 simulations.:  76%|███████▌  | 7591/10000 [00:49<00:15, 150.91it/s]Running 10000 simulations.:  76%|███████▌  | 7607/10000 [00:49<00:15, 151.08it/s]Running 10000 simulations.:  76%|███████▌  | 7623/10000 [00:50<00:15, 151.15it/s]Running 10000 simulations.:  76%|███████▋  | 7639/10000 [00:50<00:15, 151.42it/s]Running 10000 simulations.:  77%|███████▋  | 7655/10000 [00:50<00:15, 151.60it/s]Running 10000 simulations.:  77%|███████▋  | 7671/10000 [00:50<00:15, 151.73it/s]Running 10000 simulations.:  77%|███████▋  | 7687/10000 [00:50<00:15, 151.72it/s]Running 10000 simulations.:  77%|███████▋  | 7703/10000 [00:50<00:15, 151.67it/s]Running 10000 simulations.:  77%|███████▋  | 7719/10000 [00:50<00:14, 152.93it/s]Running 10000 simulations.:  77%|███████▋  | 7735/10000 [00:50<00:14, 152.71it/s]Running 10000 simulations.:  78%|███████▊  | 7751/10000 [00:50<00:14, 152.38it/s]Running 10000 simulations.:  78%|███████▊  | 7767/10000 [00:50<00:14, 152.11it/s]Running 10000 simulations.:  78%|███████▊  | 7783/10000 [00:51<00:14, 152.31it/s]Running 10000 simulations.:  78%|███████▊  | 7799/10000 [00:51<00:14, 152.30it/s]Running 10000 simulations.:  78%|███████▊  | 7815/10000 [00:51<00:14, 153.11it/s]Running 10000 simulations.:  78%|███████▊  | 7831/10000 [00:51<00:14, 153.50it/s]Running 10000 simulations.:  78%|███████▊  | 7847/10000 [00:51<00:13, 154.23it/s]Running 10000 simulations.:  79%|███████▊  | 7863/10000 [00:51<00:13, 153.62it/s]Running 10000 simulations.:  79%|███████▉  | 7879/10000 [00:51<00:14, 151.36it/s]Running 10000 simulations.:  79%|███████▉  | 7895/10000 [00:51<00:13, 152.12it/s]Running 10000 simulations.:  79%|███████▉  | 7911/10000 [00:51<00:13, 154.04it/s]Running 10000 simulations.:  79%|███████▉  | 7928/10000 [00:51<00:13, 155.92it/s]Running 10000 simulations.:  79%|███████▉  | 7944/10000 [00:52<00:13, 156.64it/s]Running 10000 simulations.:  80%|███████▉  | 7960/10000 [00:52<00:13, 156.16it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:52<00:12, 156.60it/s]Running 10000 simulations.:  80%|███████▉  | 7992/10000 [00:52<00:12, 157.29it/s]Running 10000 simulations.:  80%|████████  | 8008/10000 [00:52<00:12, 157.22it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:52<00:12, 157.13it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:52<00:12, 157.02it/s]Running 10000 simulations.:  81%|████████  | 8056/10000 [00:52<00:12, 157.56it/s]Running 10000 simulations.:  81%|████████  | 8072/10000 [00:52<00:12, 157.57it/s]Running 10000 simulations.:  81%|████████  | 8088/10000 [00:53<00:12, 157.73it/s]Running 10000 simulations.:  81%|████████  | 8104/10000 [00:53<00:12, 157.63it/s]Running 10000 simulations.:  81%|████████  | 8120/10000 [00:53<00:20, 92.26it/s] Running 10000 simulations.:  81%|████████▏ | 8136/10000 [00:53<00:17, 105.42it/s]Running 10000 simulations.:  82%|████████▏ | 8152/10000 [00:53<00:15, 117.27it/s]Running 10000 simulations.:  82%|████████▏ | 8168/10000 [00:53<00:14, 126.94it/s]Running 10000 simulations.:  82%|████████▏ | 8185/10000 [00:53<00:13, 135.53it/s]Running 10000 simulations.:  82%|████████▏ | 8201/10000 [00:53<00:12, 141.80it/s]Running 10000 simulations.:  82%|████████▏ | 8217/10000 [00:54<00:12, 146.35it/s]Running 10000 simulations.:  82%|████████▏ | 8233/10000 [00:54<00:11, 149.95it/s]Running 10000 simulations.:  82%|████████▏ | 8249/10000 [00:54<00:11, 152.66it/s]Running 10000 simulations.:  83%|████████▎ | 8265/10000 [00:54<00:11, 154.50it/s]Running 10000 simulations.:  83%|████████▎ | 8281/10000 [00:54<00:11, 155.68it/s]Running 10000 simulations.:  83%|████████▎ | 8297/10000 [00:54<00:10, 156.72it/s]Running 10000 simulations.:  83%|████████▎ | 8314/10000 [00:54<00:10, 157.67it/s]Running 10000 simulations.:  83%|████████▎ | 8331/10000 [00:54<00:10, 158.42it/s]Running 10000 simulations.:  83%|████████▎ | 8347/10000 [00:54<00:10, 157.81it/s]Running 10000 simulations.:  84%|████████▎ | 8364/10000 [00:54<00:10, 158.39it/s]Running 10000 simulations.:  84%|████████▍ | 8380/10000 [00:55<00:10, 157.92it/s]Running 10000 simulations.:  84%|████████▍ | 8396/10000 [00:55<00:10, 157.31it/s]Running 10000 simulations.:  84%|████████▍ | 8412/10000 [00:55<00:10, 157.37it/s]Running 10000 simulations.:  84%|████████▍ | 8428/10000 [00:55<00:09, 158.09it/s]Running 10000 simulations.:  84%|████████▍ | 8444/10000 [00:55<00:09, 158.19it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:55<00:09, 157.98it/s]Running 10000 simulations.:  85%|████████▍ | 8476/10000 [00:55<00:09, 157.61it/s]Running 10000 simulations.:  85%|████████▍ | 8492/10000 [00:55<00:09, 157.31it/s]Running 10000 simulations.:  85%|████████▌ | 8508/10000 [00:55<00:09, 157.64it/s]Running 10000 simulations.:  85%|████████▌ | 8524/10000 [00:56<00:09, 158.05it/s]Running 10000 simulations.:  85%|████████▌ | 8541/10000 [00:56<00:09, 158.48it/s]Running 10000 simulations.:  86%|████████▌ | 8557/10000 [00:56<00:09, 148.12it/s]Running 10000 simulations.:  86%|████████▌ | 8573/10000 [00:56<00:09, 150.02it/s]Running 10000 simulations.:  86%|████████▌ | 8589/10000 [00:56<00:09, 151.91it/s]Running 10000 simulations.:  86%|████████▌ | 8605/10000 [00:56<00:09, 153.30it/s]Running 10000 simulations.:  86%|████████▌ | 8621/10000 [00:56<00:08, 154.40it/s]Running 10000 simulations.:  86%|████████▋ | 8637/10000 [00:56<00:08, 154.83it/s]Running 10000 simulations.:  87%|████████▋ | 8653/10000 [00:56<00:08, 154.70it/s]Running 10000 simulations.:  87%|████████▋ | 8669/10000 [00:56<00:08, 155.96it/s]Running 10000 simulations.:  87%|████████▋ | 8685/10000 [00:57<00:08, 156.49it/s]Running 10000 simulations.:  87%|████████▋ | 8701/10000 [00:57<00:08, 157.03it/s]Running 10000 simulations.:  87%|████████▋ | 8717/10000 [00:57<00:08, 156.86it/s]Running 10000 simulations.:  87%|████████▋ | 8733/10000 [00:57<00:08, 155.31it/s]Running 10000 simulations.:  87%|████████▋ | 8749/10000 [00:57<00:08, 152.84it/s]Running 10000 simulations.:  88%|████████▊ | 8765/10000 [00:57<00:08, 150.61it/s]Running 10000 simulations.:  88%|████████▊ | 8781/10000 [00:57<00:08, 149.34it/s]Running 10000 simulations.:  88%|████████▊ | 8796/10000 [00:57<00:08, 147.60it/s]Running 10000 simulations.:  88%|████████▊ | 8811/10000 [00:57<00:08, 146.80it/s]Running 10000 simulations.:  88%|████████▊ | 8826/10000 [00:57<00:07, 147.47it/s]Running 10000 simulations.:  88%|████████▊ | 8841/10000 [00:58<00:07, 147.14it/s]Running 10000 simulations.:  89%|████████▊ | 8856/10000 [00:58<00:07, 146.76it/s]Running 10000 simulations.:  89%|████████▊ | 8871/10000 [00:58<00:07, 145.73it/s]Running 10000 simulations.:  89%|████████▉ | 8886/10000 [00:58<00:07, 145.64it/s]Running 10000 simulations.:  89%|████████▉ | 8901/10000 [00:58<00:07, 146.35it/s]Running 10000 simulations.:  89%|████████▉ | 8917/10000 [00:58<00:07, 148.44it/s]Running 10000 simulations.:  89%|████████▉ | 8933/10000 [00:58<00:07, 148.98it/s]Running 10000 simulations.:  89%|████████▉ | 8948/10000 [00:58<00:07, 149.06it/s]Running 10000 simulations.:  90%|████████▉ | 8963/10000 [00:58<00:07, 147.18it/s]Running 10000 simulations.:  90%|████████▉ | 8978/10000 [00:59<00:06, 146.73it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [00:59<00:06, 147.56it/s]Running 10000 simulations.:  90%|█████████ | 9008/10000 [00:59<00:06, 146.49it/s]Running 10000 simulations.:  90%|█████████ | 9023/10000 [00:59<00:06, 146.84it/s]Running 10000 simulations.:  90%|█████████ | 9038/10000 [00:59<00:06, 146.44it/s]Running 10000 simulations.:  91%|█████████ | 9053/10000 [00:59<00:06, 146.84it/s]Running 10000 simulations.:  91%|█████████ | 9068/10000 [00:59<00:06, 145.48it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [00:59<00:06, 142.34it/s]Running 10000 simulations.:  91%|█████████ | 9098/10000 [00:59<00:06, 139.34it/s]Running 10000 simulations.:  91%|█████████ | 9112/10000 [00:59<00:06, 138.49it/s]Running 10000 simulations.:  91%|█████████▏| 9127/10000 [01:00<00:06, 140.64it/s]Running 10000 simulations.:  91%|█████████▏| 9142/10000 [01:00<00:05, 143.11it/s]Running 10000 simulations.:  92%|█████████▏| 9158/10000 [01:00<00:05, 145.26it/s]Running 10000 simulations.:  92%|█████████▏| 9173/10000 [01:00<00:05, 145.44it/s]Running 10000 simulations.:  92%|█████████▏| 9188/10000 [01:00<00:05, 145.19it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [01:00<00:05, 145.21it/s]Running 10000 simulations.:  92%|█████████▏| 9218/10000 [01:00<00:05, 145.38it/s]Running 10000 simulations.:  92%|█████████▏| 9233/10000 [01:00<00:05, 145.83it/s]Running 10000 simulations.:  92%|█████████▏| 9248/10000 [01:00<00:05, 145.94it/s]Running 10000 simulations.:  93%|█████████▎| 9263/10000 [01:01<00:05, 146.38it/s]Running 10000 simulations.:  93%|█████████▎| 9278/10000 [01:01<00:04, 146.61it/s]Running 10000 simulations.:  93%|█████████▎| 9293/10000 [01:01<00:04, 146.45it/s]Running 10000 simulations.:  93%|█████████▎| 9308/10000 [01:01<00:04, 146.52it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [01:01<00:04, 145.80it/s]Running 10000 simulations.:  93%|█████████▎| 9338/10000 [01:01<00:04, 146.13it/s]Running 10000 simulations.:  94%|█████████▎| 9353/10000 [01:01<00:04, 147.14it/s]Running 10000 simulations.:  94%|█████████▎| 9368/10000 [01:01<00:04, 146.22it/s]Running 10000 simulations.:  94%|█████████▍| 9383/10000 [01:01<00:04, 145.47it/s]Running 10000 simulations.:  94%|█████████▍| 9398/10000 [01:01<00:04, 145.87it/s]Running 10000 simulations.:  94%|█████████▍| 9413/10000 [01:02<00:04, 146.31it/s]Running 10000 simulations.:  94%|█████████▍| 9428/10000 [01:02<00:03, 146.54it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [01:02<00:03, 146.00it/s]Running 10000 simulations.:  95%|█████████▍| 9458/10000 [01:02<00:03, 146.36it/s]Running 10000 simulations.:  95%|█████████▍| 9473/10000 [01:02<00:03, 146.15it/s]Running 10000 simulations.:  95%|█████████▍| 9488/10000 [01:02<00:03, 145.96it/s]Running 10000 simulations.:  95%|█████████▌| 9503/10000 [01:02<00:03, 145.50it/s]Running 10000 simulations.:  95%|█████████▌| 9518/10000 [01:02<00:03, 145.38it/s]Running 10000 simulations.:  95%|█████████▌| 9533/10000 [01:02<00:03, 145.52it/s]Running 10000 simulations.:  95%|█████████▌| 9548/10000 [01:02<00:03, 145.52it/s]Running 10000 simulations.:  96%|█████████▌| 9563/10000 [01:03<00:02, 146.12it/s]Running 10000 simulations.:  96%|█████████▌| 9578/10000 [01:03<00:02, 146.33it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [01:03<00:02, 146.22it/s]Running 10000 simulations.:  96%|█████████▌| 9608/10000 [01:03<00:02, 146.01it/s]Running 10000 simulations.:  96%|█████████▌| 9623/10000 [01:03<00:02, 146.26it/s]Running 10000 simulations.:  96%|█████████▋| 9638/10000 [01:03<00:02, 146.22it/s]Running 10000 simulations.:  97%|█████████▋| 9653/10000 [01:03<00:02, 145.95it/s]Running 10000 simulations.:  97%|█████████▋| 9668/10000 [01:03<00:02, 145.96it/s]Running 10000 simulations.:  97%|█████████▋| 9683/10000 [01:03<00:02, 145.65it/s]Running 10000 simulations.:  97%|█████████▋| 9698/10000 [01:03<00:02, 145.49it/s]Running 10000 simulations.:  97%|█████████▋| 9713/10000 [01:04<00:01, 145.29it/s]Running 10000 simulations.:  97%|█████████▋| 9728/10000 [01:04<00:01, 145.90it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [01:04<00:01, 145.16it/s]Running 10000 simulations.:  98%|█████████▊| 9758/10000 [01:04<00:01, 146.08it/s]Running 10000 simulations.:  98%|█████████▊| 9773/10000 [01:04<00:01, 145.83it/s]Running 10000 simulations.:  98%|█████████▊| 9788/10000 [01:04<00:01, 146.31it/s]Running 10000 simulations.:  98%|█████████▊| 9803/10000 [01:04<00:01, 146.13it/s]Running 10000 simulations.:  98%|█████████▊| 9818/10000 [01:04<00:01, 146.20it/s]Running 10000 simulations.:  98%|█████████▊| 9833/10000 [01:04<00:01, 146.08it/s]Running 10000 simulations.:  98%|█████████▊| 9848/10000 [01:05<00:01, 146.19it/s]Running 10000 simulations.:  99%|█████████▊| 9863/10000 [01:05<00:00, 146.39it/s]Running 10000 simulations.:  99%|█████████▉| 9878/10000 [01:05<00:00, 146.09it/s]Running 10000 simulations.:  99%|█████████▉| 9893/10000 [01:05<00:00, 145.78it/s]Running 10000 simulations.:  99%|█████████▉| 9908/10000 [01:05<00:00, 145.82it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [01:05<00:00, 145.55it/s]Running 10000 simulations.:  99%|█████████▉| 9938/10000 [01:05<00:00, 145.05it/s]Running 10000 simulations.: 100%|█████████▉| 9953/10000 [01:05<00:00, 145.48it/s]Running 10000 simulations.: 100%|█████████▉| 9968/10000 [01:05<00:00, 146.25it/s]Running 10000 simulations.: 100%|█████████▉| 9983/10000 [01:05<00:00, 145.75it/s]Running 10000 simulations.: 100%|█████████▉| 9998/10000 [01:06<00:00, 144.96it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:06<00:00, 151.39it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:10, 142.20it/s]Running 10000 simulations.:   0%|          | 29/10000 [00:00<01:10, 141.42it/s]Running 10000 simulations.:   0%|          | 44/10000 [00:00<01:10, 141.03it/s]Running 10000 simulations.:   1%|          | 58/10000 [00:00<01:10, 140.33it/s]Running 10000 simulations.:   1%|          | 72/10000 [00:00<01:11, 139.80it/s]Running 10000 simulations.:   1%|          | 87/10000 [00:00<01:10, 139.92it/s]Running 10000 simulations.:   1%|          | 101/10000 [00:00<01:10, 139.87it/s]Running 10000 simulations.:   1%|          | 116/10000 [00:00<01:10, 140.02it/s]Running 10000 simulations.:   1%|▏         | 131/10000 [00:00<01:10, 140.32it/s]Running 10000 simulations.:   1%|▏         | 145/10000 [00:01<01:10, 140.15it/s]Running 10000 simulations.:   2%|▏         | 159/10000 [00:01<01:10, 139.82it/s]Running 10000 simulations.:   2%|▏         | 174/10000 [00:01<01:10, 139.91it/s]Running 10000 simulations.:   2%|▏         | 189/10000 [00:01<01:09, 140.23it/s]Running 10000 simulations.:   2%|▏         | 203/10000 [00:01<01:10, 139.62it/s]Running 10000 simulations.:   2%|▏         | 218/10000 [00:01<01:09, 139.98it/s]Running 10000 simulations.:   2%|▏         | 233/10000 [00:01<01:09, 140.63it/s]Running 10000 simulations.:   2%|▏         | 248/10000 [00:01<01:09, 140.35it/s]Running 10000 simulations.:   3%|▎         | 263/10000 [00:01<01:09, 140.35it/s]Running 10000 simulations.:   3%|▎         | 278/10000 [00:01<01:09, 139.85it/s]Running 10000 simulations.:   3%|▎         | 292/10000 [00:02<01:09, 139.34it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:02<01:09, 139.06it/s]Running 10000 simulations.:   3%|▎         | 320/10000 [00:02<01:09, 138.67it/s]Running 10000 simulations.:   3%|▎         | 334/10000 [00:02<01:10, 138.07it/s]Running 10000 simulations.:   3%|▎         | 348/10000 [00:02<01:09, 138.18it/s]Running 10000 simulations.:   4%|▎         | 362/10000 [00:02<01:09, 138.05it/s]Running 10000 simulations.:   4%|▍         | 376/10000 [00:02<01:09, 138.49it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:02<01:09, 139.08it/s]Running 10000 simulations.:   4%|▍         | 406/10000 [00:02<01:08, 139.45it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:03<01:08, 139.47it/s]Running 10000 simulations.:   4%|▍         | 435/10000 [00:03<01:08, 140.23it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:03<01:07, 140.57it/s]Running 10000 simulations.:   5%|▍         | 465/10000 [00:03<01:08, 139.97it/s]Running 10000 simulations.:   5%|▍         | 479/10000 [00:03<01:08, 139.65it/s]Running 10000 simulations.:   5%|▍         | 493/10000 [00:03<01:08, 139.30it/s]Running 10000 simulations.:   5%|▌         | 507/10000 [00:03<01:08, 139.03it/s]Running 10000 simulations.:   5%|▌         | 522/10000 [00:03<01:07, 139.66it/s]Running 10000 simulations.:   5%|▌         | 537/10000 [00:03<01:07, 140.46it/s]Running 10000 simulations.:   6%|▌         | 552/10000 [00:03<01:07, 140.79it/s]Running 10000 simulations.:   6%|▌         | 567/10000 [00:04<01:06, 140.93it/s]Running 10000 simulations.:   6%|▌         | 582/10000 [00:04<01:06, 141.61it/s]Running 10000 simulations.:   6%|▌         | 597/10000 [00:04<01:06, 142.30it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:04<01:06, 142.18it/s]Running 10000 simulations.:   6%|▋         | 627/10000 [00:04<01:05, 142.72it/s]Running 10000 simulations.:   6%|▋         | 642/10000 [00:04<01:05, 142.62it/s]Running 10000 simulations.:   7%|▋         | 657/10000 [00:04<01:04, 144.50it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:04<01:04, 145.21it/s]Running 10000 simulations.:   7%|▋         | 687/10000 [00:04<01:03, 145.74it/s]Running 10000 simulations.:   7%|▋         | 702/10000 [00:04<01:03, 146.82it/s]Running 10000 simulations.:   7%|▋         | 717/10000 [00:05<01:03, 146.54it/s]Running 10000 simulations.:   7%|▋         | 732/10000 [00:05<01:03, 146.50it/s]Running 10000 simulations.:   7%|▋         | 747/10000 [00:05<01:03, 146.81it/s]Running 10000 simulations.:   8%|▊         | 762/10000 [00:05<01:02, 146.73it/s]Running 10000 simulations.:   8%|▊         | 777/10000 [00:05<01:02, 147.24it/s]Running 10000 simulations.:   8%|▊         | 792/10000 [00:05<01:02, 146.94it/s]Running 10000 simulations.:   8%|▊         | 807/10000 [00:05<01:02, 146.42it/s]Running 10000 simulations.:   8%|▊         | 822/10000 [00:05<01:02, 146.68it/s]Running 10000 simulations.:   8%|▊         | 837/10000 [00:05<01:02, 146.72it/s]Running 10000 simulations.:   9%|▊         | 852/10000 [00:06<01:02, 146.09it/s]Running 10000 simulations.:   9%|▊         | 867/10000 [00:06<01:02, 146.45it/s]Running 10000 simulations.:   9%|▉         | 884/10000 [00:06<00:59, 152.10it/s]Running 10000 simulations.:   9%|▉         | 901/10000 [00:06<00:58, 156.13it/s]Running 10000 simulations.:   9%|▉         | 917/10000 [00:06<00:59, 153.48it/s]Running 10000 simulations.:   9%|▉         | 933/10000 [00:06<01:00, 150.31it/s]Running 10000 simulations.:   9%|▉         | 949/10000 [00:06<01:01, 148.31it/s]Running 10000 simulations.:  10%|▉         | 964/10000 [00:06<01:01, 146.76it/s]Running 10000 simulations.:  10%|▉         | 979/10000 [00:06<01:02, 145.46it/s]Running 10000 simulations.:  10%|▉         | 994/10000 [00:06<01:02, 144.55it/s]Running 10000 simulations.:  10%|█         | 1009/10000 [00:07<01:02, 144.11it/s]Running 10000 simulations.:  10%|█         | 1024/10000 [00:07<01:02, 143.52it/s]Running 10000 simulations.:  10%|█         | 1039/10000 [00:07<01:02, 143.09it/s]Running 10000 simulations.:  11%|█         | 1054/10000 [00:07<01:03, 141.45it/s]Running 10000 simulations.:  11%|█         | 1069/10000 [00:07<01:03, 140.82it/s]Running 10000 simulations.:  11%|█         | 1084/10000 [00:07<01:02, 141.81it/s]Running 10000 simulations.:  11%|█         | 1099/10000 [00:07<01:02, 141.60it/s]Running 10000 simulations.:  11%|█         | 1114/10000 [00:07<01:02, 142.81it/s]Running 10000 simulations.:  11%|█▏        | 1129/10000 [00:07<01:01, 143.99it/s]Running 10000 simulations.:  11%|█▏        | 1144/10000 [00:08<01:01, 144.07it/s]Running 10000 simulations.:  12%|█▏        | 1159/10000 [00:08<01:01, 144.06it/s]Running 10000 simulations.:  12%|█▏        | 1174/10000 [00:08<01:01, 144.04it/s]Running 10000 simulations.:  12%|█▏        | 1189/10000 [00:08<01:01, 143.58it/s]Running 10000 simulations.:  12%|█▏        | 1204/10000 [00:08<01:01, 144.07it/s]Running 10000 simulations.:  12%|█▏        | 1219/10000 [00:08<01:00, 144.74it/s]Running 10000 simulations.:  12%|█▏        | 1234/10000 [00:08<01:01, 143.47it/s]Running 10000 simulations.:  12%|█▏        | 1249/10000 [00:08<01:01, 143.23it/s]Running 10000 simulations.:  13%|█▎        | 1264/10000 [00:08<01:00, 144.19it/s]Running 10000 simulations.:  13%|█▎        | 1279/10000 [00:08<01:00, 143.22it/s]Running 10000 simulations.:  13%|█▎        | 1294/10000 [00:09<01:01, 142.40it/s]Running 10000 simulations.:  13%|█▎        | 1309/10000 [00:09<01:01, 142.26it/s]Running 10000 simulations.:  13%|█▎        | 1324/10000 [00:09<01:00, 142.71it/s]Running 10000 simulations.:  13%|█▎        | 1339/10000 [00:09<01:00, 143.19it/s]Running 10000 simulations.:  14%|█▎        | 1354/10000 [00:09<01:00, 142.78it/s]Running 10000 simulations.:  14%|█▎        | 1369/10000 [00:09<01:00, 141.70it/s]Running 10000 simulations.:  14%|█▍        | 1384/10000 [00:09<01:00, 141.63it/s]Running 10000 simulations.:  14%|█▍        | 1399/10000 [00:09<01:00, 142.05it/s]Running 10000 simulations.:  14%|█▍        | 1414/10000 [00:09<01:00, 141.95it/s]Running 10000 simulations.:  14%|█▍        | 1429/10000 [00:10<01:01, 138.43it/s]Running 10000 simulations.:  14%|█▍        | 1443/10000 [00:10<01:01, 138.42it/s]Running 10000 simulations.:  15%|█▍        | 1458/10000 [00:10<01:01, 139.87it/s]Running 10000 simulations.:  15%|█▍        | 1473/10000 [00:10<01:00, 139.83it/s]Running 10000 simulations.:  15%|█▍        | 1488/10000 [00:10<01:00, 140.14it/s]Running 10000 simulations.:  15%|█▌        | 1503/10000 [00:10<01:00, 140.46it/s]Running 10000 simulations.:  15%|█▌        | 1518/10000 [00:10<01:00, 140.85it/s]Running 10000 simulations.:  15%|█▌        | 1533/10000 [00:10<00:59, 141.77it/s]Running 10000 simulations.:  15%|█▌        | 1548/10000 [00:10<00:59, 142.15it/s]Running 10000 simulations.:  16%|█▌        | 1563/10000 [00:10<00:59, 141.64it/s]Running 10000 simulations.:  16%|█▌        | 1578/10000 [00:11<01:00, 140.32it/s]Running 10000 simulations.:  16%|█▌        | 1593/10000 [00:11<01:00, 139.20it/s]Running 10000 simulations.:  16%|█▌        | 1608/10000 [00:11<01:00, 139.55it/s]Running 10000 simulations.:  16%|█▌        | 1623/10000 [00:11<00:59, 140.82it/s]Running 10000 simulations.:  16%|█▋        | 1638/10000 [00:11<00:59, 140.90it/s]Running 10000 simulations.:  17%|█▋        | 1653/10000 [00:11<00:59, 141.34it/s]Running 10000 simulations.:  17%|█▋        | 1668/10000 [00:11<00:58, 141.60it/s]Running 10000 simulations.:  17%|█▋        | 1683/10000 [00:11<00:58, 142.59it/s]Running 10000 simulations.:  17%|█▋        | 1698/10000 [00:11<00:58, 142.55it/s]Running 10000 simulations.:  17%|█▋        | 1713/10000 [00:12<00:58, 142.43it/s]Running 10000 simulations.:  17%|█▋        | 1728/10000 [00:12<00:58, 141.54it/s]Running 10000 simulations.:  17%|█▋        | 1743/10000 [00:12<00:58, 141.65it/s]Running 10000 simulations.:  18%|█▊        | 1758/10000 [00:12<00:58, 142.07it/s]Running 10000 simulations.:  18%|█▊        | 1773/10000 [00:12<00:57, 142.00it/s]Running 10000 simulations.:  18%|█▊        | 1788/10000 [00:12<00:57, 142.56it/s]Running 10000 simulations.:  18%|█▊        | 1803/10000 [00:12<00:57, 142.60it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:12<00:57, 142.35it/s]Running 10000 simulations.:  18%|█▊        | 1833/10000 [00:12<00:57, 142.27it/s]Running 10000 simulations.:  18%|█▊        | 1848/10000 [00:12<00:57, 141.81it/s]Running 10000 simulations.:  19%|█▊        | 1863/10000 [00:13<00:57, 141.08it/s]Running 10000 simulations.:  19%|█▉        | 1878/10000 [00:13<00:57, 140.77it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:13<00:57, 140.60it/s]Running 10000 simulations.:  19%|█▉        | 1908/10000 [00:13<00:57, 140.42it/s]Running 10000 simulations.:  19%|█▉        | 1923/10000 [00:13<00:57, 140.51it/s]Running 10000 simulations.:  19%|█▉        | 1938/10000 [00:13<00:57, 140.58it/s]Running 10000 simulations.:  20%|█▉        | 1953/10000 [00:13<00:56, 142.42it/s]Running 10000 simulations.:  20%|█▉        | 1968/10000 [00:13<00:56, 142.48it/s]Running 10000 simulations.:  20%|█▉        | 1983/10000 [00:13<00:56, 142.01it/s]Running 10000 simulations.:  20%|█▉        | 1998/10000 [00:14<00:56, 142.26it/s]Running 10000 simulations.:  20%|██        | 2013/10000 [00:14<00:56, 141.96it/s]Running 10000 simulations.:  20%|██        | 2028/10000 [00:14<00:56, 141.90it/s]Running 10000 simulations.:  20%|██        | 2043/10000 [00:14<00:56, 141.38it/s]Running 10000 simulations.:  21%|██        | 2058/10000 [00:14<00:56, 141.56it/s]Running 10000 simulations.:  21%|██        | 2073/10000 [00:14<00:56, 141.25it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:14<00:55, 142.00it/s]Running 10000 simulations.:  21%|██        | 2103/10000 [00:14<00:55, 142.35it/s]Running 10000 simulations.:  21%|██        | 2118/10000 [00:14<00:55, 142.32it/s]Running 10000 simulations.:  21%|██▏       | 2133/10000 [00:14<00:55, 142.32it/s]Running 10000 simulations.:  21%|██▏       | 2148/10000 [00:15<00:55, 142.05it/s]Running 10000 simulations.:  22%|██▏       | 2163/10000 [00:15<00:54, 143.39it/s]Running 10000 simulations.:  22%|██▏       | 2178/10000 [00:15<00:54, 143.18it/s]Running 10000 simulations.:  22%|██▏       | 2193/10000 [00:15<00:54, 142.25it/s]Running 10000 simulations.:  22%|██▏       | 2208/10000 [00:15<00:55, 141.58it/s]Running 10000 simulations.:  22%|██▏       | 2223/10000 [00:15<00:55, 141.04it/s]Running 10000 simulations.:  22%|██▏       | 2238/10000 [00:15<00:54, 141.54it/s]Running 10000 simulations.:  23%|██▎       | 2253/10000 [00:15<00:54, 141.00it/s]Running 10000 simulations.:  23%|██▎       | 2268/10000 [00:15<00:54, 140.58it/s]Running 10000 simulations.:  23%|██▎       | 2283/10000 [00:16<00:54, 140.57it/s]Running 10000 simulations.:  23%|██▎       | 2298/10000 [00:16<00:54, 140.51it/s]Running 10000 simulations.:  23%|██▎       | 2313/10000 [00:16<00:54, 141.91it/s]Running 10000 simulations.:  23%|██▎       | 2328/10000 [00:16<00:53, 142.08it/s]Running 10000 simulations.:  23%|██▎       | 2343/10000 [00:16<00:53, 141.98it/s]Running 10000 simulations.:  24%|██▎       | 2358/10000 [00:16<00:53, 142.55it/s]Running 10000 simulations.:  24%|██▎       | 2373/10000 [00:16<00:52, 144.27it/s]Running 10000 simulations.:  24%|██▍       | 2388/10000 [00:16<00:53, 143.31it/s]Running 10000 simulations.:  24%|██▍       | 2403/10000 [00:16<00:53, 142.40it/s]Running 10000 simulations.:  24%|██▍       | 2418/10000 [00:16<00:53, 142.81it/s]Running 10000 simulations.:  24%|██▍       | 2433/10000 [00:17<00:53, 142.46it/s]Running 10000 simulations.:  24%|██▍       | 2448/10000 [00:17<00:53, 141.56it/s]Running 10000 simulations.:  25%|██▍       | 2463/10000 [00:17<00:53, 141.39it/s]Running 10000 simulations.:  25%|██▍       | 2478/10000 [00:17<00:53, 141.55it/s]Running 10000 simulations.:  25%|██▍       | 2493/10000 [00:17<00:53, 141.29it/s]Running 10000 simulations.:  25%|██▌       | 2508/10000 [00:17<00:53, 141.00it/s]Running 10000 simulations.:  25%|██▌       | 2523/10000 [00:17<00:53, 141.03it/s]Running 10000 simulations.:  25%|██▌       | 2538/10000 [00:17<00:52, 141.09it/s]Running 10000 simulations.:  26%|██▌       | 2553/10000 [00:17<00:52, 140.81it/s]Running 10000 simulations.:  26%|██▌       | 2568/10000 [00:18<00:52, 140.44it/s]Running 10000 simulations.:  26%|██▌       | 2583/10000 [00:18<00:52, 141.69it/s]Running 10000 simulations.:  26%|██▌       | 2598/10000 [00:18<00:52, 141.39it/s]Running 10000 simulations.:  26%|██▌       | 2613/10000 [00:18<00:52, 140.98it/s]Running 10000 simulations.:  26%|██▋       | 2628/10000 [00:18<00:52, 140.68it/s]Running 10000 simulations.:  26%|██▋       | 2643/10000 [00:18<00:52, 140.53it/s]Running 10000 simulations.:  27%|██▋       | 2658/10000 [00:18<00:52, 140.47it/s]Running 10000 simulations.:  27%|██▋       | 2673/10000 [00:18<00:52, 140.32it/s]Running 10000 simulations.:  27%|██▋       | 2688/10000 [00:18<00:51, 140.82it/s]Running 10000 simulations.:  27%|██▋       | 2703/10000 [00:19<00:51, 140.65it/s]Running 10000 simulations.:  27%|██▋       | 2718/10000 [00:19<00:54, 134.81it/s]Running 10000 simulations.:  27%|██▋       | 2732/10000 [00:19<00:53, 134.64it/s]Running 10000 simulations.:  27%|██▋       | 2747/10000 [00:19<00:53, 136.84it/s]Running 10000 simulations.:  28%|██▊       | 2761/10000 [00:19<00:52, 137.73it/s]Running 10000 simulations.:  28%|██▊       | 2776/10000 [00:19<00:51, 139.21it/s]Running 10000 simulations.:  28%|██▊       | 2791/10000 [00:19<00:51, 140.47it/s]Running 10000 simulations.:  28%|██▊       | 2806/10000 [00:19<00:51, 140.12it/s]Running 10000 simulations.:  28%|██▊       | 2821/10000 [00:19<00:51, 140.43it/s]Running 10000 simulations.:  28%|██▊       | 2836/10000 [00:19<00:50, 140.59it/s]Running 10000 simulations.:  29%|██▊       | 2851/10000 [00:20<00:51, 139.94it/s]Running 10000 simulations.:  29%|██▊       | 2865/10000 [00:20<00:51, 139.48it/s]Running 10000 simulations.:  29%|██▉       | 2879/10000 [00:20<00:51, 139.26it/s]Running 10000 simulations.:  29%|██▉       | 2894/10000 [00:20<00:50, 139.66it/s]Running 10000 simulations.:  29%|██▉       | 2909/10000 [00:20<00:50, 139.93it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:20<00:50, 139.77it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:20<00:50, 140.62it/s]Running 10000 simulations.:  30%|██▉       | 2953/10000 [00:20<00:50, 140.25it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:20<00:49, 140.83it/s]Running 10000 simulations.:  30%|██▉       | 2983/10000 [00:21<00:49, 141.67it/s]Running 10000 simulations.:  30%|██▉       | 2998/10000 [00:21<00:49, 142.55it/s]Running 10000 simulations.:  30%|███       | 3013/10000 [00:21<00:49, 142.25it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:21<00:49, 141.56it/s]Running 10000 simulations.:  30%|███       | 3043/10000 [00:21<00:49, 141.44it/s]Running 10000 simulations.:  31%|███       | 3058/10000 [00:21<00:49, 141.60it/s]Running 10000 simulations.:  31%|███       | 3073/10000 [00:21<00:48, 141.57it/s]Running 10000 simulations.:  31%|███       | 3088/10000 [00:21<00:48, 142.14it/s]Running 10000 simulations.:  31%|███       | 3103/10000 [00:21<00:48, 142.48it/s]Running 10000 simulations.:  31%|███       | 3118/10000 [00:21<00:48, 141.97it/s]Running 10000 simulations.:  31%|███▏      | 3133/10000 [00:22<00:48, 142.39it/s]Running 10000 simulations.:  31%|███▏      | 3148/10000 [00:22<00:48, 142.37it/s]Running 10000 simulations.:  32%|███▏      | 3163/10000 [00:22<00:48, 142.14it/s]Running 10000 simulations.:  32%|███▏      | 3178/10000 [00:22<00:48, 141.88it/s]Running 10000 simulations.:  32%|███▏      | 3193/10000 [00:22<00:47, 142.31it/s]Running 10000 simulations.:  32%|███▏      | 3209/10000 [00:22<00:46, 146.15it/s]Running 10000 simulations.:  32%|███▏      | 3226/10000 [00:22<00:44, 150.55it/s]Running 10000 simulations.:  32%|███▏      | 3243/10000 [00:22<00:43, 154.01it/s]Running 10000 simulations.:  33%|███▎      | 3259/10000 [00:22<00:44, 150.75it/s]Running 10000 simulations.:  33%|███▎      | 3275/10000 [00:23<00:45, 148.06it/s]Running 10000 simulations.:  33%|███▎      | 3290/10000 [00:23<00:45, 146.16it/s]Running 10000 simulations.:  33%|███▎      | 3305/10000 [00:23<00:46, 143.97it/s]Running 10000 simulations.:  33%|███▎      | 3320/10000 [00:23<00:46, 143.18it/s]Running 10000 simulations.:  33%|███▎      | 3335/10000 [00:23<00:46, 142.56it/s]Running 10000 simulations.:  34%|███▎      | 3350/10000 [00:23<00:46, 141.76it/s]Running 10000 simulations.:  34%|███▎      | 3365/10000 [00:23<00:47, 140.48it/s]Running 10000 simulations.:  34%|███▍      | 3380/10000 [00:23<00:46, 141.18it/s]Running 10000 simulations.:  34%|███▍      | 3395/10000 [00:23<00:46, 141.64it/s]Running 10000 simulations.:  34%|███▍      | 3410/10000 [00:24<00:46, 140.89it/s]Running 10000 simulations.:  34%|███▍      | 3425/10000 [00:24<00:46, 140.96it/s]Running 10000 simulations.:  34%|███▍      | 3440/10000 [00:24<00:46, 141.83it/s]Running 10000 simulations.:  35%|███▍      | 3456/10000 [00:24<00:45, 144.51it/s]Running 10000 simulations.:  35%|███▍      | 3473/10000 [00:24<00:43, 149.04it/s]Running 10000 simulations.:  35%|███▍      | 3489/10000 [00:24<00:43, 149.64it/s]Running 10000 simulations.:  35%|███▌      | 3504/10000 [00:24<00:43, 148.59it/s]Running 10000 simulations.:  35%|███▌      | 3519/10000 [00:24<00:43, 148.15it/s]Running 10000 simulations.:  35%|███▌      | 3534/10000 [00:24<00:43, 147.18it/s]Running 10000 simulations.:  35%|███▌      | 3549/10000 [00:24<00:44, 146.55it/s]Running 10000 simulations.:  36%|███▌      | 3564/10000 [00:25<00:44, 145.92it/s]Running 10000 simulations.:  36%|███▌      | 3579/10000 [00:25<00:44, 145.71it/s]Running 10000 simulations.:  36%|███▌      | 3594/10000 [00:25<00:44, 145.36it/s]Running 10000 simulations.:  36%|███▌      | 3609/10000 [00:25<00:44, 145.18it/s]Running 10000 simulations.:  36%|███▌      | 3624/10000 [00:25<00:43, 145.02it/s]Running 10000 simulations.:  36%|███▋      | 3639/10000 [00:25<00:43, 144.88it/s]Running 10000 simulations.:  37%|███▋      | 3654/10000 [00:25<00:43, 144.89it/s]Running 10000 simulations.:  37%|███▋      | 3669/10000 [00:25<00:43, 144.74it/s]Running 10000 simulations.:  37%|███▋      | 3684/10000 [00:25<00:43, 145.09it/s]Running 10000 simulations.:  37%|███▋      | 3699/10000 [00:25<00:43, 144.94it/s]Running 10000 simulations.:  37%|███▋      | 3714/10000 [00:26<00:43, 144.83it/s]Running 10000 simulations.:  37%|███▋      | 3729/10000 [00:26<00:43, 144.65it/s]Running 10000 simulations.:  37%|███▋      | 3744/10000 [00:26<00:43, 144.33it/s]Running 10000 simulations.:  38%|███▊      | 3759/10000 [00:26<00:43, 144.58it/s]Running 10000 simulations.:  38%|███▊      | 3774/10000 [00:26<00:42, 145.04it/s]Running 10000 simulations.:  38%|███▊      | 3789/10000 [00:26<00:42, 144.82it/s]Running 10000 simulations.:  38%|███▊      | 3804/10000 [00:26<00:43, 143.54it/s]Running 10000 simulations.:  38%|███▊      | 3819/10000 [00:26<00:43, 143.69it/s]Running 10000 simulations.:  38%|███▊      | 3834/10000 [00:26<00:42, 143.64it/s]Running 10000 simulations.:  38%|███▊      | 3849/10000 [00:27<00:42, 144.21it/s]Running 10000 simulations.:  39%|███▊      | 3864/10000 [00:27<00:42, 144.49it/s]Running 10000 simulations.:  39%|███▉      | 3879/10000 [00:27<00:42, 144.08it/s]Running 10000 simulations.:  39%|███▉      | 3894/10000 [00:27<00:42, 144.10it/s]Running 10000 simulations.:  39%|███▉      | 3909/10000 [00:27<00:42, 144.11it/s]Running 10000 simulations.:  39%|███▉      | 3924/10000 [00:27<00:42, 144.32it/s]Running 10000 simulations.:  39%|███▉      | 3939/10000 [00:27<00:41, 144.45it/s]Running 10000 simulations.:  40%|███▉      | 3954/10000 [00:27<00:41, 144.15it/s]Running 10000 simulations.:  40%|███▉      | 3969/10000 [00:27<00:41, 144.20it/s]Running 10000 simulations.:  40%|███▉      | 3984/10000 [00:27<00:41, 144.18it/s]Running 10000 simulations.:  40%|███▉      | 3999/10000 [00:28<00:41, 144.23it/s]Running 10000 simulations.:  40%|████      | 4014/10000 [00:28<00:41, 144.02it/s]Running 10000 simulations.:  40%|████      | 4029/10000 [00:28<00:41, 144.18it/s]Running 10000 simulations.:  40%|████      | 4044/10000 [00:28<00:41, 143.90it/s]Running 10000 simulations.:  41%|████      | 4059/10000 [00:28<00:41, 144.57it/s]Running 10000 simulations.:  41%|████      | 4074/10000 [00:28<00:40, 144.57it/s]Running 10000 simulations.:  41%|████      | 4089/10000 [00:28<00:40, 145.31it/s]Running 10000 simulations.:  41%|████      | 4104/10000 [00:28<00:40, 145.41it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:28<00:40, 145.08it/s]Running 10000 simulations.:  41%|████▏     | 4134/10000 [00:28<00:40, 144.85it/s]Running 10000 simulations.:  41%|████▏     | 4149/10000 [00:29<00:40, 145.09it/s]Running 10000 simulations.:  42%|████▏     | 4164/10000 [00:29<00:40, 145.25it/s]Running 10000 simulations.:  42%|████▏     | 4179/10000 [00:29<00:40, 144.71it/s]Running 10000 simulations.:  42%|████▏     | 4194/10000 [00:29<00:40, 144.51it/s]Running 10000 simulations.:  42%|████▏     | 4209/10000 [00:29<00:39, 145.17it/s]Running 10000 simulations.:  42%|████▏     | 4224/10000 [00:29<00:39, 145.38it/s]Running 10000 simulations.:  42%|████▏     | 4239/10000 [00:29<00:39, 145.76it/s]Running 10000 simulations.:  43%|████▎     | 4254/10000 [00:29<00:39, 146.39it/s]Running 10000 simulations.:  43%|████▎     | 4269/10000 [00:29<00:39, 145.99it/s]Running 10000 simulations.:  43%|████▎     | 4284/10000 [00:30<00:39, 145.77it/s]Running 10000 simulations.:  43%|████▎     | 4299/10000 [00:30<00:39, 145.47it/s]Running 10000 simulations.:  43%|████▎     | 4314/10000 [00:30<00:38, 146.15it/s]Running 10000 simulations.:  43%|████▎     | 4329/10000 [00:30<00:38, 146.54it/s]Running 10000 simulations.:  43%|████▎     | 4344/10000 [00:30<00:38, 145.98it/s]Running 10000 simulations.:  44%|████▎     | 4359/10000 [00:30<00:38, 145.77it/s]Running 10000 simulations.:  44%|████▎     | 4374/10000 [00:30<00:38, 145.47it/s]Running 10000 simulations.:  44%|████▍     | 4389/10000 [00:30<00:38, 145.13it/s]Running 10000 simulations.:  44%|████▍     | 4404/10000 [00:30<00:38, 144.96it/s]Running 10000 simulations.:  44%|████▍     | 4419/10000 [00:30<00:38, 145.53it/s]Running 10000 simulations.:  44%|████▍     | 4434/10000 [00:31<00:38, 145.48it/s]Running 10000 simulations.:  44%|████▍     | 4449/10000 [00:31<00:38, 144.67it/s]Running 10000 simulations.:  45%|████▍     | 4464/10000 [00:31<00:38, 144.62it/s]Running 10000 simulations.:  45%|████▍     | 4479/10000 [00:31<00:38, 144.59it/s]Running 10000 simulations.:  45%|████▍     | 4494/10000 [00:31<00:37, 144.95it/s]Running 10000 simulations.:  45%|████▌     | 4509/10000 [00:31<00:37, 145.22it/s]Running 10000 simulations.:  45%|████▌     | 4524/10000 [00:31<00:37, 145.26it/s]Running 10000 simulations.:  45%|████▌     | 4539/10000 [00:31<00:37, 144.73it/s]Running 10000 simulations.:  46%|████▌     | 4554/10000 [00:31<00:37, 144.57it/s]Running 10000 simulations.:  46%|████▌     | 4569/10000 [00:31<00:37, 144.38it/s]Running 10000 simulations.:  46%|████▌     | 4584/10000 [00:32<00:37, 144.01it/s]Running 10000 simulations.:  46%|████▌     | 4599/10000 [00:32<00:37, 143.02it/s]Running 10000 simulations.:  46%|████▌     | 4614/10000 [00:32<00:37, 142.85it/s]Running 10000 simulations.:  46%|████▋     | 4629/10000 [00:32<00:37, 142.55it/s]Running 10000 simulations.:  46%|████▋     | 4644/10000 [00:32<00:37, 142.54it/s]Running 10000 simulations.:  47%|████▋     | 4659/10000 [00:32<00:37, 143.44it/s]Running 10000 simulations.:  47%|████▋     | 4674/10000 [00:32<00:37, 143.74it/s]Running 10000 simulations.:  47%|████▋     | 4689/10000 [00:32<00:36, 143.82it/s]Running 10000 simulations.:  47%|████▋     | 4704/10000 [00:32<00:36, 144.36it/s]Running 10000 simulations.:  47%|████▋     | 4719/10000 [00:33<00:36, 144.63it/s]Running 10000 simulations.:  47%|████▋     | 4734/10000 [00:33<00:36, 145.42it/s]Running 10000 simulations.:  47%|████▋     | 4749/10000 [00:33<00:36, 145.51it/s]Running 10000 simulations.:  48%|████▊     | 4764/10000 [00:33<00:35, 145.47it/s]Running 10000 simulations.:  48%|████▊     | 4779/10000 [00:33<00:35, 145.41it/s]Running 10000 simulations.:  48%|████▊     | 4794/10000 [00:33<00:36, 144.34it/s]Running 10000 simulations.:  48%|████▊     | 4809/10000 [00:33<00:36, 143.32it/s]Running 10000 simulations.:  48%|████▊     | 4824/10000 [00:33<00:36, 143.26it/s]Running 10000 simulations.:  48%|████▊     | 4839/10000 [00:33<00:35, 143.44it/s]Running 10000 simulations.:  49%|████▊     | 4854/10000 [00:33<00:35, 143.20it/s]Running 10000 simulations.:  49%|████▊     | 4869/10000 [00:34<00:35, 143.42it/s]Running 10000 simulations.:  49%|████▉     | 4884/10000 [00:34<00:35, 143.55it/s]Running 10000 simulations.:  49%|████▉     | 4899/10000 [00:34<00:35, 143.87it/s]Running 10000 simulations.:  49%|████▉     | 4914/10000 [00:34<00:35, 143.74it/s]Running 10000 simulations.:  49%|████▉     | 4929/10000 [00:34<00:35, 143.73it/s]Running 10000 simulations.:  49%|████▉     | 4944/10000 [00:34<00:35, 143.74it/s]Running 10000 simulations.:  50%|████▉     | 4959/10000 [00:34<00:35, 143.91it/s]Running 10000 simulations.:  50%|████▉     | 4974/10000 [00:34<00:35, 143.46it/s]Running 10000 simulations.:  50%|████▉     | 4989/10000 [00:34<00:35, 142.45it/s]Running 10000 simulations.:  50%|█████     | 5004/10000 [00:35<00:35, 142.37it/s]Running 10000 simulations.:  50%|█████     | 5019/10000 [00:35<00:34, 142.32it/s]Running 10000 simulations.:  50%|█████     | 5034/10000 [00:35<00:34, 142.27it/s]Running 10000 simulations.:  50%|█████     | 5049/10000 [00:35<00:34, 142.26it/s]Running 10000 simulations.:  51%|█████     | 5064/10000 [00:35<00:34, 142.57it/s]Running 10000 simulations.:  51%|█████     | 5079/10000 [00:35<00:34, 143.01it/s]Running 10000 simulations.:  51%|█████     | 5094/10000 [00:35<00:34, 143.28it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:35<00:34, 143.21it/s]Running 10000 simulations.:  51%|█████     | 5124/10000 [00:35<00:34, 143.06it/s]Running 10000 simulations.:  51%|█████▏    | 5139/10000 [00:35<00:33, 143.03it/s]Running 10000 simulations.:  52%|█████▏    | 5154/10000 [00:36<00:33, 143.20it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:36<00:33, 143.03it/s]Running 10000 simulations.:  52%|█████▏    | 5184/10000 [00:36<00:33, 142.89it/s]Running 10000 simulations.:  52%|█████▏    | 5199/10000 [00:36<00:33, 142.93it/s]Running 10000 simulations.:  52%|█████▏    | 5214/10000 [00:36<00:33, 142.48it/s]Running 10000 simulations.:  52%|█████▏    | 5229/10000 [00:36<00:33, 142.56it/s]Running 10000 simulations.:  52%|█████▏    | 5244/10000 [00:36<00:33, 142.75it/s]Running 10000 simulations.:  53%|█████▎    | 5259/10000 [00:36<00:33, 142.89it/s]Running 10000 simulations.:  53%|█████▎    | 5274/10000 [00:36<00:33, 143.10it/s]Running 10000 simulations.:  53%|█████▎    | 5289/10000 [00:37<00:32, 143.67it/s]Running 10000 simulations.:  53%|█████▎    | 5304/10000 [00:37<00:32, 144.26it/s]Running 10000 simulations.:  53%|█████▎    | 5319/10000 [00:37<00:32, 143.52it/s]Running 10000 simulations.:  53%|█████▎    | 5334/10000 [00:37<00:32, 143.34it/s]Running 10000 simulations.:  53%|█████▎    | 5349/10000 [00:37<00:32, 143.36it/s]Running 10000 simulations.:  54%|█████▎    | 5364/10000 [00:37<00:32, 143.15it/s]Running 10000 simulations.:  54%|█████▍    | 5379/10000 [00:37<00:32, 143.33it/s]Running 10000 simulations.:  54%|█████▍    | 5394/10000 [00:37<00:32, 143.91it/s]Running 10000 simulations.:  54%|█████▍    | 5409/10000 [00:37<00:31, 143.59it/s]Running 10000 simulations.:  54%|█████▍    | 5424/10000 [00:37<00:31, 143.17it/s]Running 10000 simulations.:  54%|█████▍    | 5439/10000 [00:38<00:31, 142.89it/s]Running 10000 simulations.:  55%|█████▍    | 5454/10000 [00:38<00:31, 142.94it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:38<00:31, 142.99it/s]Running 10000 simulations.:  55%|█████▍    | 5484/10000 [00:38<00:31, 142.99it/s]Running 10000 simulations.:  55%|█████▍    | 5499/10000 [00:38<00:31, 142.76it/s]Running 10000 simulations.:  55%|█████▌    | 5514/10000 [00:38<00:31, 142.77it/s]Running 10000 simulations.:  55%|█████▌    | 5529/10000 [00:38<00:31, 142.67it/s]Running 10000 simulations.:  55%|█████▌    | 5544/10000 [00:38<00:31, 142.55it/s]Running 10000 simulations.:  56%|█████▌    | 5559/10000 [00:38<00:31, 142.73it/s]Running 10000 simulations.:  56%|█████▌    | 5574/10000 [00:38<00:30, 143.38it/s]Running 10000 simulations.:  56%|█████▌    | 5589/10000 [00:39<00:30, 143.60it/s]Running 10000 simulations.:  56%|█████▌    | 5604/10000 [00:39<00:30, 143.77it/s]Running 10000 simulations.:  56%|█████▌    | 5619/10000 [00:39<00:30, 143.74it/s]Running 10000 simulations.:  56%|█████▋    | 5634/10000 [00:39<00:30, 143.99it/s]Running 10000 simulations.:  56%|█████▋    | 5649/10000 [00:39<00:30, 143.95it/s]Running 10000 simulations.:  57%|█████▋    | 5664/10000 [00:39<00:30, 144.08it/s]Running 10000 simulations.:  57%|█████▋    | 5679/10000 [00:39<00:30, 143.74it/s]Running 10000 simulations.:  57%|█████▋    | 5694/10000 [00:39<00:30, 143.29it/s]Running 10000 simulations.:  57%|█████▋    | 5709/10000 [00:39<00:29, 143.30it/s]Running 10000 simulations.:  57%|█████▋    | 5724/10000 [00:40<00:29, 143.08it/s]Running 10000 simulations.:  57%|█████▋    | 5739/10000 [00:40<00:29, 142.84it/s]Running 10000 simulations.:  58%|█████▊    | 5754/10000 [00:40<00:29, 142.61it/s]Running 10000 simulations.:  58%|█████▊    | 5769/10000 [00:40<00:29, 142.94it/s]Running 10000 simulations.:  58%|█████▊    | 5784/10000 [00:40<00:29, 142.95it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:40<00:29, 143.20it/s]Running 10000 simulations.:  58%|█████▊    | 5814/10000 [00:40<00:29, 144.20it/s]Running 10000 simulations.:  58%|█████▊    | 5829/10000 [00:40<00:28, 145.06it/s]Running 10000 simulations.:  58%|█████▊    | 5844/10000 [00:40<00:28, 145.97it/s]Running 10000 simulations.:  59%|█████▊    | 5859/10000 [00:40<00:28, 146.04it/s]Running 10000 simulations.:  59%|█████▊    | 5874/10000 [00:41<00:28, 145.86it/s]Running 10000 simulations.:  59%|█████▉    | 5889/10000 [00:41<00:28, 146.09it/s]Running 10000 simulations.:  59%|█████▉    | 5904/10000 [00:41<00:28, 146.05it/s]Running 10000 simulations.:  59%|█████▉    | 5919/10000 [00:41<00:27, 145.86it/s]Running 10000 simulations.:  59%|█████▉    | 5934/10000 [00:41<00:27, 146.01it/s]Running 10000 simulations.:  59%|█████▉    | 5949/10000 [00:41<00:27, 145.99it/s]Running 10000 simulations.:  60%|█████▉    | 5964/10000 [00:41<00:27, 146.34it/s]Running 10000 simulations.:  60%|█████▉    | 5979/10000 [00:41<00:27, 146.80it/s]Running 10000 simulations.:  60%|█████▉    | 5994/10000 [00:41<00:27, 146.80it/s]Running 10000 simulations.:  60%|██████    | 6009/10000 [00:42<00:27, 146.87it/s]Running 10000 simulations.:  60%|██████    | 6024/10000 [00:42<00:27, 146.70it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:42<00:27, 146.36it/s]Running 10000 simulations.:  61%|██████    | 6054/10000 [00:42<00:26, 146.27it/s]Running 10000 simulations.:  61%|██████    | 6069/10000 [00:42<00:26, 146.14it/s]Running 10000 simulations.:  61%|██████    | 6084/10000 [00:42<00:26, 145.94it/s]Running 10000 simulations.:  61%|██████    | 6099/10000 [00:42<00:26, 145.73it/s]Running 10000 simulations.:  61%|██████    | 6114/10000 [00:42<00:26, 145.83it/s]Running 10000 simulations.:  61%|██████▏   | 6129/10000 [00:42<00:26, 145.82it/s]Running 10000 simulations.:  61%|██████▏   | 6144/10000 [00:42<00:26, 145.65it/s]Running 10000 simulations.:  62%|██████▏   | 6159/10000 [00:43<00:26, 145.81it/s]Running 10000 simulations.:  62%|██████▏   | 6174/10000 [00:43<00:26, 145.80it/s]Running 10000 simulations.:  62%|██████▏   | 6189/10000 [00:43<00:26, 145.86it/s]Running 10000 simulations.:  62%|██████▏   | 6204/10000 [00:43<00:26, 145.76it/s]Running 10000 simulations.:  62%|██████▏   | 6219/10000 [00:43<00:25, 146.00it/s]Running 10000 simulations.:  62%|██████▏   | 6234/10000 [00:43<00:25, 146.19it/s]Running 10000 simulations.:  62%|██████▏   | 6249/10000 [00:43<00:25, 146.18it/s]Running 10000 simulations.:  63%|██████▎   | 6264/10000 [00:43<00:25, 146.29it/s]Running 10000 simulations.:  63%|██████▎   | 6279/10000 [00:43<00:25, 146.25it/s]Running 10000 simulations.:  63%|██████▎   | 6294/10000 [00:43<00:25, 145.97it/s]Running 10000 simulations.:  63%|██████▎   | 6309/10000 [00:44<00:25, 146.03it/s]Running 10000 simulations.:  63%|██████▎   | 6324/10000 [00:44<00:25, 146.39it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:44<00:24, 146.71it/s]Running 10000 simulations.:  64%|██████▎   | 6354/10000 [00:44<00:24, 146.49it/s]Running 10000 simulations.:  64%|██████▎   | 6369/10000 [00:44<00:24, 146.36it/s]Running 10000 simulations.:  64%|██████▍   | 6384/10000 [00:44<00:24, 146.82it/s]Running 10000 simulations.:  64%|██████▍   | 6399/10000 [00:44<00:24, 147.14it/s]Running 10000 simulations.:  64%|██████▍   | 6414/10000 [00:44<00:24, 146.63it/s]Running 10000 simulations.:  64%|██████▍   | 6429/10000 [00:44<00:24, 146.74it/s]Running 10000 simulations.:  64%|██████▍   | 6444/10000 [00:44<00:24, 146.60it/s]Running 10000 simulations.:  65%|██████▍   | 6459/10000 [00:45<00:24, 146.51it/s]Running 10000 simulations.:  65%|██████▍   | 6474/10000 [00:45<00:24, 146.63it/s]Running 10000 simulations.:  65%|██████▍   | 6489/10000 [00:45<00:23, 146.55it/s]Running 10000 simulations.:  65%|██████▌   | 6504/10000 [00:45<00:23, 145.88it/s]Running 10000 simulations.:  65%|██████▌   | 6519/10000 [00:45<00:23, 146.07it/s]Running 10000 simulations.:  65%|██████▌   | 6534/10000 [00:45<00:23, 146.25it/s]Running 10000 simulations.:  65%|██████▌   | 6549/10000 [00:45<00:23, 145.85it/s]Running 10000 simulations.:  66%|██████▌   | 6564/10000 [00:45<00:23, 146.23it/s]Running 10000 simulations.:  66%|██████▌   | 6579/10000 [00:45<00:23, 146.74it/s]Running 10000 simulations.:  66%|██████▌   | 6594/10000 [00:46<00:23, 146.53it/s]Running 10000 simulations.:  66%|██████▌   | 6609/10000 [00:46<00:23, 146.76it/s]Running 10000 simulations.:  66%|██████▌   | 6624/10000 [00:46<00:23, 146.39it/s]Running 10000 simulations.:  66%|██████▋   | 6639/10000 [00:46<00:23, 146.12it/s]Running 10000 simulations.:  67%|██████▋   | 6654/10000 [00:46<00:22, 146.24it/s]Running 10000 simulations.:  67%|██████▋   | 6669/10000 [00:46<00:22, 146.52it/s]Running 10000 simulations.:  67%|██████▋   | 6684/10000 [00:46<00:22, 146.19it/s]Running 10000 simulations.:  67%|██████▋   | 6699/10000 [00:46<00:22, 145.86it/s]Running 10000 simulations.:  67%|██████▋   | 6714/10000 [00:46<00:22, 145.84it/s]Running 10000 simulations.:  67%|██████▋   | 6729/10000 [00:46<00:22, 146.30it/s]Running 10000 simulations.:  67%|██████▋   | 6744/10000 [00:47<00:22, 146.70it/s]Running 10000 simulations.:  68%|██████▊   | 6759/10000 [00:47<00:22, 146.32it/s]Running 10000 simulations.:  68%|██████▊   | 6774/10000 [00:47<00:22, 145.95it/s]Running 10000 simulations.:  68%|██████▊   | 6789/10000 [00:47<00:21, 146.03it/s]Running 10000 simulations.:  68%|██████▊   | 6804/10000 [00:47<00:21, 146.41it/s]Running 10000 simulations.:  68%|██████▊   | 6819/10000 [00:47<00:21, 146.08it/s]Running 10000 simulations.:  68%|██████▊   | 6834/10000 [00:47<00:21, 146.36it/s]Running 10000 simulations.:  68%|██████▊   | 6849/10000 [00:47<00:21, 146.40it/s]Running 10000 simulations.:  69%|██████▊   | 6864/10000 [00:47<00:21, 146.70it/s]Running 10000 simulations.:  69%|██████▉   | 6879/10000 [00:47<00:21, 146.55it/s]Running 10000 simulations.:  69%|██████▉   | 6894/10000 [00:48<00:21, 147.13it/s]Running 10000 simulations.:  69%|██████▉   | 6909/10000 [00:48<00:21, 146.56it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:48<00:21, 146.10it/s]Running 10000 simulations.:  69%|██████▉   | 6939/10000 [00:48<00:21, 144.76it/s]Running 10000 simulations.:  70%|██████▉   | 6954/10000 [00:48<00:21, 144.41it/s]Running 10000 simulations.:  70%|██████▉   | 6969/10000 [00:48<00:20, 144.85it/s]Running 10000 simulations.:  70%|██████▉   | 6984/10000 [00:48<00:20, 144.83it/s]Running 10000 simulations.:  70%|██████▉   | 6999/10000 [00:48<00:20, 145.18it/s]Running 10000 simulations.:  70%|███████   | 7014/10000 [00:48<00:20, 145.44it/s]Running 10000 simulations.:  70%|███████   | 7029/10000 [00:48<00:20, 145.26it/s]Running 10000 simulations.:  70%|███████   | 7044/10000 [00:49<00:20, 145.18it/s]Running 10000 simulations.:  71%|███████   | 7059/10000 [00:49<00:21, 137.36it/s]Running 10000 simulations.:  71%|███████   | 7074/10000 [00:49<00:20, 139.77it/s]Running 10000 simulations.:  71%|███████   | 7089/10000 [00:49<00:20, 142.58it/s]Running 10000 simulations.:  71%|███████   | 7105/10000 [00:49<00:19, 145.04it/s]Running 10000 simulations.:  71%|███████   | 7121/10000 [00:49<00:19, 146.67it/s]Running 10000 simulations.:  71%|███████▏  | 7136/10000 [00:49<00:19, 147.59it/s]Running 10000 simulations.:  72%|███████▏  | 7151/10000 [00:49<00:19, 147.60it/s]Running 10000 simulations.:  72%|███████▏  | 7166/10000 [00:49<00:19, 147.85it/s]Running 10000 simulations.:  72%|███████▏  | 7181/10000 [00:50<00:19, 147.89it/s]Running 10000 simulations.:  72%|███████▏  | 7196/10000 [00:50<00:18, 147.72it/s]Running 10000 simulations.:  72%|███████▏  | 7211/10000 [00:50<00:18, 146.86it/s]Running 10000 simulations.:  72%|███████▏  | 7226/10000 [00:50<00:18, 146.60it/s]Running 10000 simulations.:  72%|███████▏  | 7241/10000 [00:50<00:18, 146.30it/s]Running 10000 simulations.:  73%|███████▎  | 7256/10000 [00:50<00:18, 146.17it/s]Running 10000 simulations.:  73%|███████▎  | 7271/10000 [00:50<00:18, 146.26it/s]Running 10000 simulations.:  73%|███████▎  | 7286/10000 [00:50<00:18, 146.35it/s]Running 10000 simulations.:  73%|███████▎  | 7301/10000 [00:50<00:18, 146.34it/s]Running 10000 simulations.:  73%|███████▎  | 7316/10000 [00:50<00:18, 146.15it/s]Running 10000 simulations.:  73%|███████▎  | 7331/10000 [00:51<00:18, 146.01it/s]Running 10000 simulations.:  73%|███████▎  | 7346/10000 [00:51<00:18, 145.66it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:51<00:18, 145.58it/s]Running 10000 simulations.:  74%|███████▍  | 7376/10000 [00:51<00:18, 145.40it/s]Running 10000 simulations.:  74%|███████▍  | 7391/10000 [00:51<00:17, 145.83it/s]Running 10000 simulations.:  74%|███████▍  | 7406/10000 [00:51<00:17, 145.47it/s]Running 10000 simulations.:  74%|███████▍  | 7421/10000 [00:51<00:17, 145.48it/s]Running 10000 simulations.:  74%|███████▍  | 7436/10000 [00:51<00:17, 145.45it/s]Running 10000 simulations.:  75%|███████▍  | 7451/10000 [00:51<00:17, 145.20it/s]Running 10000 simulations.:  75%|███████▍  | 7466/10000 [00:51<00:17, 145.16it/s]Running 10000 simulations.:  75%|███████▍  | 7481/10000 [00:52<00:17, 144.98it/s]Running 10000 simulations.:  75%|███████▍  | 7496/10000 [00:52<00:17, 145.03it/s]Running 10000 simulations.:  75%|███████▌  | 7511/10000 [00:52<00:17, 145.17it/s]Running 10000 simulations.:  75%|███████▌  | 7526/10000 [00:52<00:17, 144.86it/s]Running 10000 simulations.:  75%|███████▌  | 7541/10000 [00:52<00:16, 144.90it/s]Running 10000 simulations.:  76%|███████▌  | 7556/10000 [00:52<00:16, 145.02it/s]Running 10000 simulations.:  76%|███████▌  | 7571/10000 [00:52<00:16, 144.98it/s]Running 10000 simulations.:  76%|███████▌  | 7586/10000 [00:52<00:16, 145.44it/s]Running 10000 simulations.:  76%|███████▌  | 7601/10000 [00:52<00:16, 145.59it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:53<00:16, 145.51it/s]Running 10000 simulations.:  76%|███████▋  | 7631/10000 [00:53<00:16, 145.48it/s]Running 10000 simulations.:  76%|███████▋  | 7646/10000 [00:53<00:16, 145.64it/s]Running 10000 simulations.:  77%|███████▋  | 7661/10000 [00:53<00:16, 145.97it/s]Running 10000 simulations.:  77%|███████▋  | 7676/10000 [00:53<00:15, 145.66it/s]Running 10000 simulations.:  77%|███████▋  | 7691/10000 [00:53<00:15, 145.77it/s]Running 10000 simulations.:  77%|███████▋  | 7706/10000 [00:53<00:15, 146.87it/s]Running 10000 simulations.:  77%|███████▋  | 7721/10000 [00:53<00:15, 146.85it/s]Running 10000 simulations.:  77%|███████▋  | 7737/10000 [00:53<00:15, 148.34it/s]Running 10000 simulations.:  78%|███████▊  | 7753/10000 [00:53<00:15, 149.63it/s]Running 10000 simulations.:  78%|███████▊  | 7769/10000 [00:54<00:14, 149.94it/s]Running 10000 simulations.:  78%|███████▊  | 7785/10000 [00:54<00:14, 150.04it/s]Running 10000 simulations.:  78%|███████▊  | 7801/10000 [00:54<00:14, 150.62it/s]Running 10000 simulations.:  78%|███████▊  | 7817/10000 [00:54<00:14, 151.66it/s]Running 10000 simulations.:  78%|███████▊  | 7833/10000 [00:54<00:14, 152.27it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:54<00:14, 151.72it/s]Running 10000 simulations.:  79%|███████▊  | 7865/10000 [00:54<00:14, 150.79it/s]Running 10000 simulations.:  79%|███████▉  | 7881/10000 [00:54<00:14, 149.86it/s]Running 10000 simulations.:  79%|███████▉  | 7896/10000 [00:54<00:14, 149.48it/s]Running 10000 simulations.:  79%|███████▉  | 7911/10000 [00:54<00:13, 149.31it/s]Running 10000 simulations.:  79%|███████▉  | 7926/10000 [00:55<00:13, 148.39it/s]Running 10000 simulations.:  79%|███████▉  | 7941/10000 [00:55<00:13, 147.80it/s]Running 10000 simulations.:  80%|███████▉  | 7956/10000 [00:55<00:13, 148.10it/s]Running 10000 simulations.:  80%|███████▉  | 7971/10000 [00:55<00:13, 148.44it/s]Running 10000 simulations.:  80%|███████▉  | 7986/10000 [00:55<00:13, 148.62it/s]Running 10000 simulations.:  80%|████████  | 8001/10000 [00:55<00:13, 148.69it/s]Running 10000 simulations.:  80%|████████  | 8016/10000 [00:55<00:13, 148.24it/s]Running 10000 simulations.:  80%|████████  | 8031/10000 [00:55<00:13, 148.74it/s]Running 10000 simulations.:  80%|████████  | 8047/10000 [00:55<00:13, 149.63it/s]Running 10000 simulations.:  81%|████████  | 8063/10000 [00:56<00:12, 149.87it/s]Running 10000 simulations.:  81%|████████  | 8078/10000 [00:56<00:12, 149.16it/s]Running 10000 simulations.:  81%|████████  | 8094/10000 [00:56<00:12, 149.58it/s]Running 10000 simulations.:  81%|████████  | 8109/10000 [00:56<00:12, 149.69it/s]Running 10000 simulations.:  81%|████████  | 8124/10000 [00:56<00:12, 149.44it/s]Running 10000 simulations.:  81%|████████▏ | 8139/10000 [00:56<00:12, 149.16it/s]Running 10000 simulations.:  82%|████████▏ | 8154/10000 [00:56<00:12, 148.57it/s]Running 10000 simulations.:  82%|████████▏ | 8169/10000 [00:56<00:12, 148.67it/s]Running 10000 simulations.:  82%|████████▏ | 8184/10000 [00:56<00:12, 148.88it/s]Running 10000 simulations.:  82%|████████▏ | 8199/10000 [00:56<00:12, 149.12it/s]Running 10000 simulations.:  82%|████████▏ | 8214/10000 [00:57<00:11, 149.12it/s]Running 10000 simulations.:  82%|████████▏ | 8229/10000 [00:57<00:11, 149.08it/s]Running 10000 simulations.:  82%|████████▏ | 8244/10000 [00:57<00:11, 149.18it/s]Running 10000 simulations.:  83%|████████▎ | 8259/10000 [00:57<00:11, 149.01it/s]Running 10000 simulations.:  83%|████████▎ | 8274/10000 [00:57<00:11, 147.78it/s]Running 10000 simulations.:  83%|████████▎ | 8289/10000 [00:57<00:11, 147.66it/s]Running 10000 simulations.:  83%|████████▎ | 8304/10000 [00:57<00:11, 147.97it/s]Running 10000 simulations.:  83%|████████▎ | 8319/10000 [00:57<00:11, 147.80it/s]Running 10000 simulations.:  83%|████████▎ | 8334/10000 [00:57<00:11, 148.32it/s]Running 10000 simulations.:  83%|████████▎ | 8349/10000 [00:57<00:11, 148.03it/s]Running 10000 simulations.:  84%|████████▎ | 8364/10000 [00:58<00:11, 147.59it/s]Running 10000 simulations.:  84%|████████▍ | 8379/10000 [00:58<00:10, 147.86it/s]Running 10000 simulations.:  84%|████████▍ | 8394/10000 [00:58<00:10, 148.08it/s]Running 10000 simulations.:  84%|████████▍ | 8409/10000 [00:58<00:10, 148.24it/s]Running 10000 simulations.:  84%|████████▍ | 8424/10000 [00:58<00:10, 147.91it/s]Running 10000 simulations.:  84%|████████▍ | 8439/10000 [00:58<00:10, 148.08it/s]Running 10000 simulations.:  85%|████████▍ | 8454/10000 [00:58<00:10, 148.47it/s]Running 10000 simulations.:  85%|████████▍ | 8469/10000 [00:58<00:10, 148.72it/s]Running 10000 simulations.:  85%|████████▍ | 8485/10000 [00:58<00:10, 149.03it/s]Running 10000 simulations.:  85%|████████▌ | 8500/10000 [00:58<00:10, 148.35it/s]Running 10000 simulations.:  85%|████████▌ | 8515/10000 [00:59<00:09, 148.52it/s]Running 10000 simulations.:  85%|████████▌ | 8530/10000 [00:59<00:09, 148.82it/s]Running 10000 simulations.:  85%|████████▌ | 8545/10000 [00:59<00:09, 149.01it/s]Running 10000 simulations.:  86%|████████▌ | 8560/10000 [00:59<00:09, 149.06it/s]Running 10000 simulations.:  86%|████████▌ | 8575/10000 [00:59<00:09, 148.90it/s]Running 10000 simulations.:  86%|████████▌ | 8590/10000 [00:59<00:09, 148.81it/s]Running 10000 simulations.:  86%|████████▌ | 8606/10000 [00:59<00:09, 149.28it/s]Running 10000 simulations.:  86%|████████▌ | 8622/10000 [00:59<00:09, 149.68it/s]Running 10000 simulations.:  86%|████████▋ | 8638/10000 [00:59<00:09, 150.81it/s]Running 10000 simulations.:  87%|████████▋ | 8654/10000 [00:59<00:08, 150.60it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [01:00<00:08, 150.58it/s]Running 10000 simulations.:  87%|████████▋ | 8686/10000 [01:00<00:08, 150.59it/s]Running 10000 simulations.:  87%|████████▋ | 8702/10000 [01:00<00:08, 151.45it/s]Running 10000 simulations.:  87%|████████▋ | 8718/10000 [01:00<00:08, 151.42it/s]Running 10000 simulations.:  87%|████████▋ | 8734/10000 [01:00<00:08, 150.61it/s]Running 10000 simulations.:  88%|████████▊ | 8750/10000 [01:00<00:08, 150.38it/s]Running 10000 simulations.:  88%|████████▊ | 8766/10000 [01:00<00:08, 150.55it/s]Running 10000 simulations.:  88%|████████▊ | 8782/10000 [01:00<00:08, 150.48it/s]Running 10000 simulations.:  88%|████████▊ | 8798/10000 [01:00<00:08, 150.12it/s]Running 10000 simulations.:  88%|████████▊ | 8814/10000 [01:01<00:07, 150.48it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [01:01<00:07, 151.26it/s]Running 10000 simulations.:  88%|████████▊ | 8846/10000 [01:01<00:07, 151.96it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [01:01<00:07, 152.29it/s]Running 10000 simulations.:  89%|████████▉ | 8878/10000 [01:01<00:07, 151.94it/s]Running 10000 simulations.:  89%|████████▉ | 8894/10000 [01:01<00:07, 151.31it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [01:01<00:07, 151.46it/s]Running 10000 simulations.:  89%|████████▉ | 8926/10000 [01:01<00:07, 151.66it/s]Running 10000 simulations.:  89%|████████▉ | 8942/10000 [01:01<00:06, 151.53it/s]Running 10000 simulations.:  90%|████████▉ | 8958/10000 [01:01<00:06, 151.31it/s]Running 10000 simulations.:  90%|████████▉ | 8974/10000 [01:02<00:06, 151.03it/s]Running 10000 simulations.:  90%|████████▉ | 8990/10000 [01:02<00:06, 151.11it/s]Running 10000 simulations.:  90%|█████████ | 9006/10000 [01:02<00:06, 151.16it/s]Running 10000 simulations.:  90%|█████████ | 9022/10000 [01:02<00:06, 151.23it/s]Running 10000 simulations.:  90%|█████████ | 9038/10000 [01:02<00:06, 151.10it/s]Running 10000 simulations.:  91%|█████████ | 9054/10000 [01:02<00:06, 150.84it/s]Running 10000 simulations.:  91%|█████████ | 9070/10000 [01:02<00:06, 150.58it/s]Running 10000 simulations.:  91%|█████████ | 9086/10000 [01:02<00:06, 150.64it/s]Running 10000 simulations.:  91%|█████████ | 9102/10000 [01:02<00:05, 150.79it/s]Running 10000 simulations.:  91%|█████████ | 9118/10000 [01:03<00:05, 150.99it/s]Running 10000 simulations.:  91%|█████████▏| 9134/10000 [01:03<00:05, 150.92it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [01:03<00:05, 150.74it/s]Running 10000 simulations.:  92%|█████████▏| 9166/10000 [01:03<00:05, 150.32it/s]Running 10000 simulations.:  92%|█████████▏| 9182/10000 [01:03<00:05, 149.90it/s]Running 10000 simulations.:  92%|█████████▏| 9197/10000 [01:03<00:05, 149.77it/s]Running 10000 simulations.:  92%|█████████▏| 9212/10000 [01:03<00:05, 149.34it/s]Running 10000 simulations.:  92%|█████████▏| 9227/10000 [01:03<00:05, 149.41it/s]Running 10000 simulations.:  92%|█████████▏| 9242/10000 [01:03<00:05, 149.08it/s]Running 10000 simulations.:  93%|█████████▎| 9257/10000 [01:03<00:04, 149.01it/s]Running 10000 simulations.:  93%|█████████▎| 9272/10000 [01:04<00:04, 148.69it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [01:04<00:04, 147.63it/s]Running 10000 simulations.:  93%|█████████▎| 9302/10000 [01:04<00:04, 147.85it/s]Running 10000 simulations.:  93%|█████████▎| 9318/10000 [01:04<00:04, 148.56it/s]Running 10000 simulations.:  93%|█████████▎| 9333/10000 [01:04<00:04, 148.56it/s]Running 10000 simulations.:  93%|█████████▎| 9348/10000 [01:04<00:04, 148.82it/s]Running 10000 simulations.:  94%|█████████▎| 9363/10000 [01:04<00:04, 148.33it/s]Running 10000 simulations.:  94%|█████████▍| 9379/10000 [01:04<00:04, 148.89it/s]Running 10000 simulations.:  94%|█████████▍| 9395/10000 [01:04<00:04, 149.52it/s]Running 10000 simulations.:  94%|█████████▍| 9411/10000 [01:05<00:03, 150.03it/s]Running 10000 simulations.:  94%|█████████▍| 9427/10000 [01:05<00:03, 148.78it/s]Running 10000 simulations.:  94%|█████████▍| 9442/10000 [01:05<00:03, 148.89it/s]Running 10000 simulations.:  95%|█████████▍| 9458/10000 [01:05<00:03, 149.40it/s]Running 10000 simulations.:  95%|█████████▍| 9473/10000 [01:05<00:03, 149.09it/s]Running 10000 simulations.:  95%|█████████▍| 9488/10000 [01:05<00:03, 149.02it/s]Running 10000 simulations.:  95%|█████████▌| 9503/10000 [01:05<00:03, 148.73it/s]Running 10000 simulations.:  95%|█████████▌| 9519/10000 [01:05<00:03, 149.21it/s]Running 10000 simulations.:  95%|█████████▌| 9534/10000 [01:05<00:03, 149.08it/s]Running 10000 simulations.:  95%|█████████▌| 9549/10000 [01:05<00:03, 148.91it/s]Running 10000 simulations.:  96%|█████████▌| 9564/10000 [01:06<00:02, 148.73it/s]Running 10000 simulations.:  96%|█████████▌| 9579/10000 [01:06<00:02, 148.85it/s]Running 10000 simulations.:  96%|█████████▌| 9594/10000 [01:06<00:02, 148.75it/s]Running 10000 simulations.:  96%|█████████▌| 9609/10000 [01:06<00:02, 148.42it/s]Running 10000 simulations.:  96%|█████████▌| 9624/10000 [01:06<00:02, 148.52it/s]Running 10000 simulations.:  96%|█████████▋| 9639/10000 [01:06<00:02, 148.63it/s]Running 10000 simulations.:  97%|█████████▋| 9654/10000 [01:06<00:02, 148.63it/s]Running 10000 simulations.:  97%|█████████▋| 9669/10000 [01:06<00:02, 148.30it/s]Running 10000 simulations.:  97%|█████████▋| 9684/10000 [01:06<00:02, 148.34it/s]Running 10000 simulations.:  97%|█████████▋| 9699/10000 [01:06<00:02, 148.58it/s]Running 10000 simulations.:  97%|█████████▋| 9714/10000 [01:07<00:01, 148.94it/s]Running 10000 simulations.:  97%|█████████▋| 9729/10000 [01:07<00:01, 148.82it/s]Running 10000 simulations.:  97%|█████████▋| 9744/10000 [01:07<00:01, 147.92it/s]Running 10000 simulations.:  98%|█████████▊| 9759/10000 [01:07<00:01, 148.07it/s]Running 10000 simulations.:  98%|█████████▊| 9774/10000 [01:07<00:01, 148.33it/s]Running 10000 simulations.:  98%|█████████▊| 9789/10000 [01:07<00:01, 148.42it/s]Running 10000 simulations.:  98%|█████████▊| 9805/10000 [01:07<00:01, 148.97it/s]Running 10000 simulations.:  98%|█████████▊| 9820/10000 [01:07<00:01, 147.98it/s]Running 10000 simulations.:  98%|█████████▊| 9835/10000 [01:07<00:01, 148.03it/s]Running 10000 simulations.:  98%|█████████▊| 9850/10000 [01:07<00:01, 147.71it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [01:08<00:00, 147.89it/s]Running 10000 simulations.:  99%|█████████▉| 9880/10000 [01:08<00:00, 148.10it/s]Running 10000 simulations.:  99%|█████████▉| 9895/10000 [01:08<00:00, 148.10it/s]Running 10000 simulations.:  99%|█████████▉| 9910/10000 [01:08<00:00, 147.50it/s]Running 10000 simulations.:  99%|█████████▉| 9925/10000 [01:08<00:00, 147.60it/s]Running 10000 simulations.:  99%|█████████▉| 9940/10000 [01:08<00:00, 147.48it/s]Running 10000 simulations.: 100%|█████████▉| 9955/10000 [01:08<00:00, 147.47it/s]Running 10000 simulations.: 100%|█████████▉| 9970/10000 [01:08<00:00, 146.88it/s]Running 10000 simulations.: 100%|█████████▉| 9985/10000 [01:08<00:00, 147.03it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:08<00:00, 147.26it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:08<00:00, 144.93it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:07, 147.25it/s]Running 10000 simulations.:   0%|          | 31/10000 [00:00<01:06, 148.93it/s]Running 10000 simulations.:   0%|          | 46/10000 [00:00<01:07, 148.28it/s]Running 10000 simulations.:   1%|          | 61/10000 [00:00<01:07, 147.57it/s]Running 10000 simulations.:   1%|          | 76/10000 [00:00<01:07, 148.04it/s]Running 10000 simulations.:   1%|          | 91/10000 [00:00<01:06, 148.62it/s]Running 10000 simulations.:   1%|          | 106/10000 [00:00<01:06, 148.03it/s]Running 10000 simulations.:   1%|          | 121/10000 [00:00<01:06, 148.25it/s]Running 10000 simulations.:   1%|▏         | 136/10000 [00:00<01:06, 148.44it/s]Running 10000 simulations.:   2%|▏         | 152/10000 [00:01<01:05, 150.12it/s]Running 10000 simulations.:   2%|▏         | 167/10000 [00:01<01:05, 149.30it/s]Running 10000 simulations.:   2%|▏         | 182/10000 [00:01<01:05, 149.20it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:01<01:06, 147.02it/s]Running 10000 simulations.:   2%|▏         | 212/10000 [00:01<01:06, 146.86it/s]Running 10000 simulations.:   2%|▏         | 227/10000 [00:01<01:06, 146.24it/s]Running 10000 simulations.:   2%|▏         | 242/10000 [00:01<01:06, 145.97it/s]Running 10000 simulations.:   3%|▎         | 258/10000 [00:01<01:06, 147.24it/s]Running 10000 simulations.:   3%|▎         | 273/10000 [00:01<01:06, 146.58it/s]Running 10000 simulations.:   3%|▎         | 288/10000 [00:01<01:06, 145.95it/s]Running 10000 simulations.:   3%|▎         | 303/10000 [00:02<01:06, 145.25it/s]Running 10000 simulations.:   3%|▎         | 318/10000 [00:02<01:07, 143.80it/s]Running 10000 simulations.:   3%|▎         | 333/10000 [00:02<01:07, 143.06it/s]Running 10000 simulations.:   3%|▎         | 348/10000 [00:02<01:07, 142.57it/s]Running 10000 simulations.:   4%|▎         | 363/10000 [00:02<01:08, 141.51it/s]Running 10000 simulations.:   4%|▍         | 378/10000 [00:02<01:07, 141.61it/s]Running 10000 simulations.:   4%|▍         | 393/10000 [00:02<01:07, 142.71it/s]Running 10000 simulations.:   4%|▍         | 408/10000 [00:02<01:07, 142.61it/s]Running 10000 simulations.:   4%|▍         | 423/10000 [00:02<01:07, 142.07it/s]Running 10000 simulations.:   4%|▍         | 438/10000 [00:03<01:07, 141.67it/s]Running 10000 simulations.:   5%|▍         | 453/10000 [00:03<01:07, 140.44it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:03<01:06, 142.36it/s]Running 10000 simulations.:   5%|▍         | 483/10000 [00:03<01:07, 142.01it/s]Running 10000 simulations.:   5%|▍         | 498/10000 [00:03<01:07, 141.42it/s]Running 10000 simulations.:   5%|▌         | 513/10000 [00:03<01:06, 142.52it/s]Running 10000 simulations.:   5%|▌         | 528/10000 [00:03<01:06, 141.85it/s]Running 10000 simulations.:   5%|▌         | 543/10000 [00:03<01:06, 141.39it/s]Running 10000 simulations.:   6%|▌         | 558/10000 [00:03<01:06, 141.99it/s]Running 10000 simulations.:   6%|▌         | 573/10000 [00:03<01:06, 141.48it/s]Running 10000 simulations.:   6%|▌         | 588/10000 [00:04<01:06, 140.82it/s]Running 10000 simulations.:   6%|▌         | 603/10000 [00:04<01:06, 140.79it/s]Running 10000 simulations.:   6%|▌         | 618/10000 [00:04<01:06, 140.29it/s]Running 10000 simulations.:   6%|▋         | 633/10000 [00:04<01:07, 139.63it/s]Running 10000 simulations.:   6%|▋         | 648/10000 [00:04<01:06, 140.67it/s]Running 10000 simulations.:   7%|▋         | 663/10000 [00:04<01:05, 141.55it/s]Running 10000 simulations.:   7%|▋         | 678/10000 [00:04<01:05, 142.91it/s]Running 10000 simulations.:   7%|▋         | 693/10000 [00:04<01:05, 142.55it/s]Running 10000 simulations.:   7%|▋         | 708/10000 [00:04<01:05, 141.36it/s]Running 10000 simulations.:   7%|▋         | 723/10000 [00:05<01:05, 141.01it/s]Running 10000 simulations.:   7%|▋         | 738/10000 [00:05<01:05, 140.66it/s]Running 10000 simulations.:   8%|▊         | 753/10000 [00:05<01:06, 139.89it/s]Running 10000 simulations.:   8%|▊         | 768/10000 [00:05<01:05, 140.31it/s]Running 10000 simulations.:   8%|▊         | 783/10000 [00:05<01:05, 141.20it/s]Running 10000 simulations.:   8%|▊         | 798/10000 [00:05<01:05, 141.29it/s]Running 10000 simulations.:   8%|▊         | 813/10000 [00:05<01:05, 140.26it/s]Running 10000 simulations.:   8%|▊         | 828/10000 [00:05<01:05, 140.26it/s]Running 10000 simulations.:   8%|▊         | 843/10000 [00:05<01:05, 139.60it/s]Running 10000 simulations.:   9%|▊         | 858/10000 [00:05<01:05, 140.09it/s]Running 10000 simulations.:   9%|▊         | 873/10000 [00:06<01:05, 139.83it/s]Running 10000 simulations.:   9%|▉         | 888/10000 [00:06<01:04, 141.17it/s]Running 10000 simulations.:   9%|▉         | 903/10000 [00:06<01:03, 143.45it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:06<01:02, 144.22it/s]Running 10000 simulations.:   9%|▉         | 933/10000 [00:06<01:03, 143.09it/s]Running 10000 simulations.:   9%|▉         | 948/10000 [00:06<01:03, 143.21it/s]Running 10000 simulations.:  10%|▉         | 963/10000 [00:06<01:03, 143.22it/s]Running 10000 simulations.:  10%|▉         | 978/10000 [00:06<01:02, 143.73it/s]Running 10000 simulations.:  10%|▉         | 993/10000 [00:06<01:02, 144.11it/s]Running 10000 simulations.:  10%|█         | 1008/10000 [00:07<01:02, 143.86it/s]Running 10000 simulations.:  10%|█         | 1023/10000 [00:07<01:02, 143.46it/s]Running 10000 simulations.:  10%|█         | 1038/10000 [00:07<01:02, 142.94it/s]Running 10000 simulations.:  11%|█         | 1053/10000 [00:07<01:02, 143.59it/s]Running 10000 simulations.:  11%|█         | 1068/10000 [00:07<01:02, 143.11it/s]Running 10000 simulations.:  11%|█         | 1083/10000 [00:07<01:02, 143.61it/s]Running 10000 simulations.:  11%|█         | 1098/10000 [00:07<01:01, 144.46it/s]Running 10000 simulations.:  11%|█         | 1113/10000 [00:07<01:01, 145.40it/s]Running 10000 simulations.:  11%|█▏        | 1128/10000 [00:07<01:00, 146.10it/s]Running 10000 simulations.:  11%|█▏        | 1143/10000 [00:07<01:01, 145.17it/s]Running 10000 simulations.:  12%|█▏        | 1158/10000 [00:08<01:01, 144.05it/s]Running 10000 simulations.:  12%|█▏        | 1173/10000 [00:08<01:01, 143.84it/s]Running 10000 simulations.:  12%|█▏        | 1188/10000 [00:08<01:01, 144.27it/s]Running 10000 simulations.:  12%|█▏        | 1203/10000 [00:08<01:00, 144.44it/s]Running 10000 simulations.:  12%|█▏        | 1218/10000 [00:08<01:00, 145.18it/s]Running 10000 simulations.:  12%|█▏        | 1233/10000 [00:08<01:00, 145.62it/s]Running 10000 simulations.:  12%|█▏        | 1248/10000 [00:08<00:59, 145.87it/s]Running 10000 simulations.:  13%|█▎        | 1263/10000 [00:08<01:00, 145.61it/s]Running 10000 simulations.:  13%|█▎        | 1278/10000 [00:08<01:00, 143.65it/s]Running 10000 simulations.:  13%|█▎        | 1293/10000 [00:09<01:00, 143.27it/s]Running 10000 simulations.:  13%|█▎        | 1308/10000 [00:09<01:00, 143.10it/s]Running 10000 simulations.:  13%|█▎        | 1323/10000 [00:09<01:00, 143.74it/s]Running 10000 simulations.:  13%|█▎        | 1340/10000 [00:09<00:57, 149.43it/s]Running 10000 simulations.:  14%|█▎        | 1357/10000 [00:09<00:56, 153.51it/s]Running 10000 simulations.:  14%|█▎        | 1373/10000 [00:09<00:57, 150.40it/s]Running 10000 simulations.:  14%|█▍        | 1389/10000 [00:09<00:57, 148.76it/s]Running 10000 simulations.:  14%|█▍        | 1404/10000 [00:09<00:58, 146.56it/s]Running 10000 simulations.:  14%|█▍        | 1419/10000 [00:09<00:59, 144.49it/s]Running 10000 simulations.:  14%|█▍        | 1434/10000 [00:09<00:59, 143.14it/s]Running 10000 simulations.:  14%|█▍        | 1449/10000 [00:10<00:59, 142.84it/s]Running 10000 simulations.:  15%|█▍        | 1464/10000 [00:10<01:00, 141.51it/s]Running 10000 simulations.:  15%|█▍        | 1479/10000 [00:10<01:00, 141.55it/s]Running 10000 simulations.:  15%|█▍        | 1494/10000 [00:10<00:59, 143.24it/s]Running 10000 simulations.:  15%|█▌        | 1509/10000 [00:10<00:58, 144.14it/s]Running 10000 simulations.:  15%|█▌        | 1524/10000 [00:10<00:58, 144.25it/s]Running 10000 simulations.:  15%|█▌        | 1539/10000 [00:10<00:58, 144.49it/s]Running 10000 simulations.:  16%|█▌        | 1554/10000 [00:10<00:58, 143.72it/s]Running 10000 simulations.:  16%|█▌        | 1569/10000 [00:10<00:58, 143.37it/s]Running 10000 simulations.:  16%|█▌        | 1584/10000 [00:11<00:58, 143.14it/s]Running 10000 simulations.:  16%|█▌        | 1599/10000 [00:11<00:58, 143.07it/s]Running 10000 simulations.:  16%|█▌        | 1614/10000 [00:11<00:58, 143.35it/s]Running 10000 simulations.:  16%|█▋        | 1629/10000 [00:11<00:58, 143.57it/s]Running 10000 simulations.:  16%|█▋        | 1644/10000 [00:11<00:58, 143.54it/s]Running 10000 simulations.:  17%|█▋        | 1659/10000 [00:11<01:01, 136.46it/s]Running 10000 simulations.:  17%|█▋        | 1673/10000 [00:11<01:00, 137.48it/s]Running 10000 simulations.:  17%|█▋        | 1687/10000 [00:11<01:00, 138.20it/s]Running 10000 simulations.:  17%|█▋        | 1702/10000 [00:11<00:59, 139.27it/s]Running 10000 simulations.:  17%|█▋        | 1716/10000 [00:11<00:59, 139.31it/s]Running 10000 simulations.:  17%|█▋        | 1731/10000 [00:12<00:58, 140.42it/s]Running 10000 simulations.:  17%|█▋        | 1746/10000 [00:12<00:58, 141.91it/s]Running 10000 simulations.:  18%|█▊        | 1761/10000 [00:12<00:57, 143.00it/s]Running 10000 simulations.:  18%|█▊        | 1776/10000 [00:12<00:57, 143.77it/s]Running 10000 simulations.:  18%|█▊        | 1791/10000 [00:12<00:56, 145.05it/s]Running 10000 simulations.:  18%|█▊        | 1806/10000 [00:12<00:57, 143.26it/s]Running 10000 simulations.:  18%|█▊        | 1821/10000 [00:12<00:57, 142.03it/s]Running 10000 simulations.:  18%|█▊        | 1836/10000 [00:12<00:57, 142.16it/s]Running 10000 simulations.:  19%|█▊        | 1851/10000 [00:12<00:57, 141.84it/s]Running 10000 simulations.:  19%|█▊        | 1866/10000 [00:13<00:57, 141.45it/s]Running 10000 simulations.:  19%|█▉        | 1881/10000 [00:13<00:57, 142.00it/s]Running 10000 simulations.:  19%|█▉        | 1896/10000 [00:13<00:57, 141.44it/s]Running 10000 simulations.:  19%|█▉        | 1911/10000 [00:13<00:56, 142.30it/s]Running 10000 simulations.:  19%|█▉        | 1926/10000 [00:13<00:56, 142.25it/s]Running 10000 simulations.:  19%|█▉        | 1941/10000 [00:13<00:57, 141.16it/s]Running 10000 simulations.:  20%|█▉        | 1956/10000 [00:13<00:57, 140.50it/s]Running 10000 simulations.:  20%|█▉        | 1971/10000 [00:13<00:57, 140.77it/s]Running 10000 simulations.:  20%|█▉        | 1986/10000 [00:13<00:56, 141.24it/s]Running 10000 simulations.:  20%|██        | 2001/10000 [00:13<00:55, 142.93it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:14<00:55, 144.63it/s]Running 10000 simulations.:  20%|██        | 2031/10000 [00:14<00:55, 144.55it/s]Running 10000 simulations.:  20%|██        | 2046/10000 [00:14<00:55, 143.51it/s]Running 10000 simulations.:  21%|██        | 2061/10000 [00:14<00:54, 144.37it/s]Running 10000 simulations.:  21%|██        | 2076/10000 [00:14<00:54, 144.81it/s]Running 10000 simulations.:  21%|██        | 2091/10000 [00:14<00:54, 144.93it/s]Running 10000 simulations.:  21%|██        | 2106/10000 [00:14<00:54, 145.46it/s]Running 10000 simulations.:  21%|██        | 2121/10000 [00:14<00:54, 144.85it/s]Running 10000 simulations.:  21%|██▏       | 2136/10000 [00:14<00:54, 144.33it/s]Running 10000 simulations.:  22%|██▏       | 2151/10000 [00:14<00:54, 144.45it/s]Running 10000 simulations.:  22%|██▏       | 2166/10000 [00:15<00:54, 144.62it/s]Running 10000 simulations.:  22%|██▏       | 2181/10000 [00:15<00:54, 143.88it/s]Running 10000 simulations.:  22%|██▏       | 2196/10000 [00:15<00:54, 143.59it/s]Running 10000 simulations.:  22%|██▏       | 2211/10000 [00:15<00:54, 143.48it/s]Running 10000 simulations.:  22%|██▏       | 2227/10000 [00:15<00:53, 145.29it/s]Running 10000 simulations.:  22%|██▏       | 2242/10000 [00:15<00:53, 145.18it/s]Running 10000 simulations.:  23%|██▎       | 2257/10000 [00:15<00:54, 142.53it/s]Running 10000 simulations.:  23%|██▎       | 2272/10000 [00:15<00:54, 141.79it/s]Running 10000 simulations.:  23%|██▎       | 2287/10000 [00:15<00:54, 141.83it/s]Running 10000 simulations.:  23%|██▎       | 2302/10000 [00:16<00:54, 141.00it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:16<00:54, 141.51it/s]Running 10000 simulations.:  23%|██▎       | 2332/10000 [00:16<00:53, 142.49it/s]Running 10000 simulations.:  23%|██▎       | 2347/10000 [00:16<00:53, 142.10it/s]Running 10000 simulations.:  24%|██▎       | 2362/10000 [00:16<00:53, 142.00it/s]Running 10000 simulations.:  24%|██▍       | 2377/10000 [00:16<00:53, 141.35it/s]Running 10000 simulations.:  24%|██▍       | 2392/10000 [00:16<00:54, 140.38it/s]Running 10000 simulations.:  24%|██▍       | 2407/10000 [00:16<00:54, 139.85it/s]Running 10000 simulations.:  24%|██▍       | 2421/10000 [00:16<00:54, 139.68it/s]Running 10000 simulations.:  24%|██▍       | 2436/10000 [00:17<00:53, 141.02it/s]Running 10000 simulations.:  25%|██▍       | 2451/10000 [00:17<00:53, 141.86it/s]Running 10000 simulations.:  25%|██▍       | 2466/10000 [00:17<00:53, 141.56it/s]Running 10000 simulations.:  25%|██▍       | 2481/10000 [00:17<00:53, 140.74it/s]Running 10000 simulations.:  25%|██▍       | 2496/10000 [00:17<00:53, 140.76it/s]Running 10000 simulations.:  25%|██▌       | 2511/10000 [00:17<00:53, 139.22it/s]Running 10000 simulations.:  25%|██▌       | 2525/10000 [00:17<00:54, 138.28it/s]Running 10000 simulations.:  25%|██▌       | 2539/10000 [00:17<00:53, 138.22it/s]Running 10000 simulations.:  26%|██▌       | 2553/10000 [00:17<00:54, 137.74it/s]Running 10000 simulations.:  26%|██▌       | 2567/10000 [00:17<00:54, 137.58it/s]Running 10000 simulations.:  26%|██▌       | 2582/10000 [00:18<00:53, 138.79it/s]Running 10000 simulations.:  26%|██▌       | 2596/10000 [00:18<00:53, 138.45it/s]Running 10000 simulations.:  26%|██▌       | 2611/10000 [00:18<00:53, 139.41it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:18<00:52, 139.47it/s]Running 10000 simulations.:  26%|██▋       | 2639/10000 [00:18<00:53, 138.76it/s]Running 10000 simulations.:  27%|██▋       | 2654/10000 [00:18<00:52, 140.21it/s]Running 10000 simulations.:  27%|██▋       | 2669/10000 [00:18<00:52, 140.94it/s]Running 10000 simulations.:  27%|██▋       | 2684/10000 [00:18<00:51, 141.68it/s]Running 10000 simulations.:  27%|██▋       | 2699/10000 [00:18<00:51, 142.77it/s]Running 10000 simulations.:  27%|██▋       | 2714/10000 [00:18<00:50, 143.16it/s]Running 10000 simulations.:  27%|██▋       | 2729/10000 [00:19<00:50, 142.92it/s]Running 10000 simulations.:  27%|██▋       | 2744/10000 [00:19<00:50, 142.67it/s]Running 10000 simulations.:  28%|██▊       | 2759/10000 [00:19<00:50, 142.41it/s]Running 10000 simulations.:  28%|██▊       | 2774/10000 [00:19<00:51, 140.69it/s]Running 10000 simulations.:  28%|██▊       | 2789/10000 [00:19<00:51, 140.55it/s]Running 10000 simulations.:  28%|██▊       | 2804/10000 [00:19<00:51, 140.27it/s]Running 10000 simulations.:  28%|██▊       | 2819/10000 [00:19<00:51, 139.27it/s]Running 10000 simulations.:  28%|██▊       | 2833/10000 [00:19<00:51, 139.20it/s]Running 10000 simulations.:  28%|██▊       | 2848/10000 [00:19<00:51, 140.19it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:20<00:50, 140.97it/s]Running 10000 simulations.:  29%|██▉       | 2878/10000 [00:20<00:49, 142.71it/s]Running 10000 simulations.:  29%|██▉       | 2893/10000 [00:20<00:50, 141.62it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:20<00:50, 140.67it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:20<00:50, 140.08it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:20<00:50, 139.85it/s]Running 10000 simulations.:  30%|██▉       | 2952/10000 [00:20<00:50, 139.52it/s]Running 10000 simulations.:  30%|██▉       | 2966/10000 [00:20<00:50, 139.48it/s]Running 10000 simulations.:  30%|██▉       | 2981/10000 [00:20<00:49, 140.47it/s]Running 10000 simulations.:  30%|██▉       | 2996/10000 [00:20<00:49, 140.29it/s]Running 10000 simulations.:  30%|███       | 3011/10000 [00:21<00:49, 141.84it/s]Running 10000 simulations.:  30%|███       | 3026/10000 [00:21<00:49, 140.82it/s]Running 10000 simulations.:  30%|███       | 3041/10000 [00:21<00:49, 139.76it/s]Running 10000 simulations.:  31%|███       | 3056/10000 [00:21<00:49, 139.94it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:21<00:49, 140.01it/s]Running 10000 simulations.:  31%|███       | 3086/10000 [00:21<00:49, 140.72it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:21<00:48, 141.74it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:21<00:48, 140.94it/s]Running 10000 simulations.:  31%|███▏      | 3131/10000 [00:21<00:48, 140.22it/s]Running 10000 simulations.:  31%|███▏      | 3146/10000 [00:22<00:49, 139.05it/s]Running 10000 simulations.:  32%|███▏      | 3161/10000 [00:22<00:48, 140.22it/s]Running 10000 simulations.:  32%|███▏      | 3176/10000 [00:22<00:48, 140.05it/s]Running 10000 simulations.:  32%|███▏      | 3191/10000 [00:22<00:48, 139.80it/s]Running 10000 simulations.:  32%|███▏      | 3205/10000 [00:22<00:48, 138.75it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:22<00:48, 138.79it/s]Running 10000 simulations.:  32%|███▏      | 3233/10000 [00:22<00:49, 137.66it/s]Running 10000 simulations.:  32%|███▏      | 3247/10000 [00:22<00:49, 136.69it/s]Running 10000 simulations.:  33%|███▎      | 3262/10000 [00:22<00:48, 138.00it/s]Running 10000 simulations.:  33%|███▎      | 3276/10000 [00:23<00:48, 137.77it/s]Running 10000 simulations.:  33%|███▎      | 3291/10000 [00:23<00:48, 139.34it/s]Running 10000 simulations.:  33%|███▎      | 3306/10000 [00:23<00:47, 140.60it/s]Running 10000 simulations.:  33%|███▎      | 3321/10000 [00:23<00:47, 140.63it/s]Running 10000 simulations.:  33%|███▎      | 3336/10000 [00:23<00:47, 139.24it/s]Running 10000 simulations.:  34%|███▎      | 3350/10000 [00:23<00:48, 138.13it/s]Running 10000 simulations.:  34%|███▎      | 3364/10000 [00:23<00:48, 137.03it/s]Running 10000 simulations.:  34%|███▍      | 3378/10000 [00:23<00:48, 137.14it/s]Running 10000 simulations.:  34%|███▍      | 3392/10000 [00:23<00:48, 137.29it/s]Running 10000 simulations.:  34%|███▍      | 3406/10000 [00:23<00:48, 137.37it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:24<00:48, 137.06it/s]Running 10000 simulations.:  34%|███▍      | 3434/10000 [00:24<00:47, 137.71it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:24<00:47, 138.02it/s]Running 10000 simulations.:  35%|███▍      | 3463/10000 [00:24<00:47, 138.53it/s]Running 10000 simulations.:  35%|███▍      | 3478/10000 [00:24<00:46, 138.91it/s]Running 10000 simulations.:  35%|███▍      | 3492/10000 [00:24<00:46, 139.06it/s]Running 10000 simulations.:  35%|███▌      | 3506/10000 [00:24<00:46, 138.59it/s]Running 10000 simulations.:  35%|███▌      | 3521/10000 [00:24<00:46, 139.47it/s]Running 10000 simulations.:  35%|███▌      | 3535/10000 [00:24<00:46, 139.38it/s]Running 10000 simulations.:  35%|███▌      | 3549/10000 [00:24<00:46, 138.43it/s]Running 10000 simulations.:  36%|███▌      | 3563/10000 [00:25<00:46, 137.56it/s]Running 10000 simulations.:  36%|███▌      | 3577/10000 [00:25<00:46, 136.90it/s]Running 10000 simulations.:  36%|███▌      | 3591/10000 [00:25<00:46, 136.81it/s]Running 10000 simulations.:  36%|███▌      | 3605/10000 [00:25<00:46, 136.55it/s]Running 10000 simulations.:  36%|███▌      | 3619/10000 [00:25<00:47, 135.44it/s]Running 10000 simulations.:  36%|███▋      | 3633/10000 [00:25<00:47, 134.61it/s]Running 10000 simulations.:  36%|███▋      | 3647/10000 [00:25<00:47, 134.38it/s]Running 10000 simulations.:  37%|███▋      | 3661/10000 [00:25<00:47, 134.22it/s]Running 10000 simulations.:  37%|███▋      | 3675/10000 [00:25<00:47, 134.16it/s]Running 10000 simulations.:  37%|███▋      | 3689/10000 [00:26<00:46, 134.52it/s]Running 10000 simulations.:  37%|███▋      | 3703/10000 [00:26<00:46, 134.45it/s]Running 10000 simulations.:  37%|███▋      | 3717/10000 [00:26<00:46, 134.71it/s]Running 10000 simulations.:  37%|███▋      | 3731/10000 [00:26<00:46, 135.79it/s]Running 10000 simulations.:  37%|███▋      | 3747/10000 [00:26<00:44, 139.90it/s]Running 10000 simulations.:  38%|███▊      | 3763/10000 [00:26<00:43, 144.46it/s]Running 10000 simulations.:  38%|███▊      | 3779/10000 [00:26<00:42, 146.88it/s]Running 10000 simulations.:  38%|███▊      | 3794/10000 [00:26<00:43, 142.63it/s]Running 10000 simulations.:  38%|███▊      | 3809/10000 [00:26<00:44, 139.81it/s]Running 10000 simulations.:  38%|███▊      | 3824/10000 [00:26<00:44, 138.42it/s]Running 10000 simulations.:  38%|███▊      | 3838/10000 [00:27<00:44, 138.18it/s]Running 10000 simulations.:  39%|███▊      | 3852/10000 [00:27<00:44, 138.19it/s]Running 10000 simulations.:  39%|███▊      | 3866/10000 [00:27<00:44, 136.48it/s]Running 10000 simulations.:  39%|███▉      | 3880/10000 [00:27<00:45, 135.68it/s]Running 10000 simulations.:  39%|███▉      | 3894/10000 [00:27<00:45, 134.98it/s]Running 10000 simulations.:  39%|███▉      | 3908/10000 [00:27<00:45, 134.60it/s]Running 10000 simulations.:  39%|███▉      | 3922/10000 [00:27<00:45, 134.93it/s]Running 10000 simulations.:  39%|███▉      | 3936/10000 [00:27<00:44, 135.47it/s]Running 10000 simulations.:  40%|███▉      | 3950/10000 [00:27<00:44, 135.37it/s]Running 10000 simulations.:  40%|███▉      | 3964/10000 [00:28<00:44, 135.34it/s]Running 10000 simulations.:  40%|███▉      | 3978/10000 [00:28<00:44, 135.74it/s]Running 10000 simulations.:  40%|███▉      | 3993/10000 [00:28<00:43, 137.73it/s]Running 10000 simulations.:  40%|████      | 4007/10000 [00:28<00:43, 138.08it/s]Running 10000 simulations.:  40%|████      | 4021/10000 [00:28<00:43, 138.13it/s]Running 10000 simulations.:  40%|████      | 4036/10000 [00:28<00:42, 139.41it/s]Running 10000 simulations.:  41%|████      | 4051/10000 [00:28<00:42, 140.28it/s]Running 10000 simulations.:  41%|████      | 4066/10000 [00:28<00:41, 141.53it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:28<00:41, 142.71it/s]Running 10000 simulations.:  41%|████      | 4096/10000 [00:28<00:41, 141.98it/s]Running 10000 simulations.:  41%|████      | 4111/10000 [00:29<00:41, 140.82it/s]Running 10000 simulations.:  41%|████▏     | 4126/10000 [00:29<00:42, 139.84it/s]Running 10000 simulations.:  41%|████▏     | 4141/10000 [00:29<00:41, 140.08it/s]Running 10000 simulations.:  42%|████▏     | 4156/10000 [00:29<00:41, 139.61it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:29<00:41, 139.41it/s]Running 10000 simulations.:  42%|████▏     | 4185/10000 [00:29<00:41, 140.18it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:29<00:41, 141.03it/s]Running 10000 simulations.:  42%|████▏     | 4215/10000 [00:29<00:41, 140.38it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:29<00:41, 139.56it/s]Running 10000 simulations.:  42%|████▏     | 4245/10000 [00:30<00:41, 139.50it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:30<00:41, 139.00it/s]Running 10000 simulations.:  43%|████▎     | 4273/10000 [00:30<00:41, 138.43it/s]Running 10000 simulations.:  43%|████▎     | 4287/10000 [00:30<00:41, 138.45it/s]Running 10000 simulations.:  43%|████▎     | 4301/10000 [00:30<00:41, 137.87it/s]Running 10000 simulations.:  43%|████▎     | 4315/10000 [00:30<00:41, 137.79it/s]Running 10000 simulations.:  43%|████▎     | 4329/10000 [00:30<00:41, 137.22it/s]Running 10000 simulations.:  43%|████▎     | 4343/10000 [00:30<00:41, 136.00it/s]Running 10000 simulations.:  44%|████▎     | 4358/10000 [00:30<00:40, 137.69it/s]Running 10000 simulations.:  44%|████▎     | 4372/10000 [00:30<00:40, 137.40it/s]Running 10000 simulations.:  44%|████▍     | 4386/10000 [00:31<00:40, 138.16it/s]Running 10000 simulations.:  44%|████▍     | 4401/10000 [00:31<00:40, 138.98it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:31<00:40, 137.11it/s]Running 10000 simulations.:  44%|████▍     | 4430/10000 [00:31<00:40, 139.09it/s]Running 10000 simulations.:  44%|████▍     | 4445/10000 [00:31<00:39, 139.52it/s]Running 10000 simulations.:  45%|████▍     | 4459/10000 [00:31<00:39, 139.47it/s]Running 10000 simulations.:  45%|████▍     | 4474/10000 [00:31<00:39, 139.71it/s]Running 10000 simulations.:  45%|████▍     | 4489/10000 [00:31<00:39, 141.27it/s]Running 10000 simulations.:  45%|████▌     | 4504/10000 [00:31<00:38, 141.90it/s]Running 10000 simulations.:  45%|████▌     | 4519/10000 [00:31<00:38, 141.64it/s]Running 10000 simulations.:  45%|████▌     | 4534/10000 [00:32<00:38, 141.59it/s]Running 10000 simulations.:  45%|████▌     | 4549/10000 [00:32<00:38, 140.46it/s]Running 10000 simulations.:  46%|████▌     | 4564/10000 [00:32<00:38, 140.20it/s]Running 10000 simulations.:  46%|████▌     | 4579/10000 [00:32<00:38, 140.28it/s]Running 10000 simulations.:  46%|████▌     | 4594/10000 [00:32<00:38, 140.35it/s]Running 10000 simulations.:  46%|████▌     | 4609/10000 [00:32<00:37, 142.19it/s]Running 10000 simulations.:  46%|████▌     | 4624/10000 [00:32<00:37, 142.68it/s]Running 10000 simulations.:  46%|████▋     | 4639/10000 [00:32<00:37, 143.58it/s]Running 10000 simulations.:  47%|████▋     | 4654/10000 [00:32<00:37, 144.38it/s]Running 10000 simulations.:  47%|████▋     | 4669/10000 [00:33<00:37, 140.98it/s]Running 10000 simulations.:  47%|████▋     | 4684/10000 [00:33<00:38, 139.49it/s]Running 10000 simulations.:  47%|████▋     | 4698/10000 [00:33<00:38, 139.15it/s]Running 10000 simulations.:  47%|████▋     | 4712/10000 [00:33<00:38, 138.09it/s]Running 10000 simulations.:  47%|████▋     | 4726/10000 [00:33<00:38, 138.18it/s]Running 10000 simulations.:  47%|████▋     | 4740/10000 [00:33<00:38, 138.37it/s]Running 10000 simulations.:  48%|████▊     | 4755/10000 [00:33<00:37, 140.00it/s]Running 10000 simulations.:  48%|████▊     | 4770/10000 [00:33<00:37, 140.53it/s]Running 10000 simulations.:  48%|████▊     | 4785/10000 [00:33<00:37, 139.56it/s]Running 10000 simulations.:  48%|████▊     | 4799/10000 [00:33<00:37, 137.73it/s]Running 10000 simulations.:  48%|████▊     | 4813/10000 [00:34<00:38, 136.30it/s]Running 10000 simulations.:  48%|████▊     | 4827/10000 [00:34<00:37, 136.99it/s]Running 10000 simulations.:  48%|████▊     | 4841/10000 [00:34<00:37, 137.61it/s]Running 10000 simulations.:  49%|████▊     | 4856/10000 [00:34<00:37, 138.41it/s]Running 10000 simulations.:  49%|████▊     | 4871/10000 [00:34<00:36, 139.77it/s]Running 10000 simulations.:  49%|████▉     | 4885/10000 [00:34<00:36, 138.67it/s]Running 10000 simulations.:  49%|████▉     | 4899/10000 [00:34<00:36, 138.83it/s]Running 10000 simulations.:  49%|████▉     | 4913/10000 [00:34<00:36, 137.82it/s]Running 10000 simulations.:  49%|████▉     | 4927/10000 [00:34<00:36, 137.20it/s]Running 10000 simulations.:  49%|████▉     | 4941/10000 [00:35<00:37, 136.41it/s]Running 10000 simulations.:  50%|████▉     | 4955/10000 [00:35<00:36, 136.60it/s]Running 10000 simulations.:  50%|████▉     | 4969/10000 [00:35<00:36, 136.52it/s]Running 10000 simulations.:  50%|████▉     | 4984/10000 [00:35<00:36, 138.55it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:35<00:35, 139.25it/s]Running 10000 simulations.:  50%|█████     | 5014/10000 [00:35<00:35, 139.80it/s]Running 10000 simulations.:  50%|█████     | 5028/10000 [00:35<00:35, 139.25it/s]Running 10000 simulations.:  50%|█████     | 5042/10000 [00:35<00:35, 138.76it/s]Running 10000 simulations.:  51%|█████     | 5056/10000 [00:35<00:36, 137.25it/s]Running 10000 simulations.:  51%|█████     | 5070/10000 [00:35<00:36, 135.99it/s]Running 10000 simulations.:  51%|█████     | 5085/10000 [00:36<00:35, 138.11it/s]Running 10000 simulations.:  51%|█████     | 5099/10000 [00:36<00:35, 137.13it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:36<00:35, 137.30it/s]Running 10000 simulations.:  51%|█████▏    | 5127/10000 [00:36<00:36, 133.93it/s]Running 10000 simulations.:  51%|█████▏    | 5141/10000 [00:36<00:35, 135.30it/s]Running 10000 simulations.:  52%|█████▏    | 5155/10000 [00:36<00:35, 136.29it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:36<00:35, 137.04it/s]Running 10000 simulations.:  52%|█████▏    | 5183/10000 [00:36<00:35, 136.58it/s]Running 10000 simulations.:  52%|█████▏    | 5197/10000 [00:36<00:35, 135.82it/s]Running 10000 simulations.:  52%|█████▏    | 5211/10000 [00:36<00:35, 135.37it/s]Running 10000 simulations.:  52%|█████▏    | 5225/10000 [00:37<00:35, 136.09it/s]Running 10000 simulations.:  52%|█████▏    | 5239/10000 [00:37<00:34, 136.40it/s]Running 10000 simulations.:  53%|█████▎    | 5253/10000 [00:37<00:34, 137.25it/s]Running 10000 simulations.:  53%|█████▎    | 5267/10000 [00:37<00:34, 136.63it/s]Running 10000 simulations.:  53%|█████▎    | 5281/10000 [00:37<00:34, 136.21it/s]Running 10000 simulations.:  53%|█████▎    | 5296/10000 [00:37<00:33, 138.39it/s]Running 10000 simulations.:  53%|█████▎    | 5310/10000 [00:37<00:34, 137.26it/s]Running 10000 simulations.:  53%|█████▎    | 5324/10000 [00:37<00:34, 137.21it/s]Running 10000 simulations.:  53%|█████▎    | 5339/10000 [00:37<00:33, 138.13it/s]Running 10000 simulations.:  54%|█████▎    | 5353/10000 [00:38<00:33, 137.19it/s]Running 10000 simulations.:  54%|█████▎    | 5367/10000 [00:38<00:33, 136.69it/s]Running 10000 simulations.:  54%|█████▍    | 5381/10000 [00:38<00:33, 136.26it/s]Running 10000 simulations.:  54%|█████▍    | 5395/10000 [00:38<00:33, 136.03it/s]Running 10000 simulations.:  54%|█████▍    | 5409/10000 [00:38<00:33, 136.19it/s]Running 10000 simulations.:  54%|█████▍    | 5423/10000 [00:38<00:33, 136.84it/s]Running 10000 simulations.:  54%|█████▍    | 5437/10000 [00:38<00:33, 137.51it/s]Running 10000 simulations.:  55%|█████▍    | 5451/10000 [00:38<00:33, 137.66it/s]Running 10000 simulations.:  55%|█████▍    | 5465/10000 [00:38<00:33, 137.32it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:38<00:32, 137.44it/s]Running 10000 simulations.:  55%|█████▍    | 5493/10000 [00:39<00:32, 136.60it/s]Running 10000 simulations.:  55%|█████▌    | 5508/10000 [00:39<00:32, 138.46it/s]Running 10000 simulations.:  55%|█████▌    | 5522/10000 [00:39<00:32, 137.86it/s]Running 10000 simulations.:  55%|█████▌    | 5536/10000 [00:39<00:32, 136.92it/s]Running 10000 simulations.:  56%|█████▌    | 5550/10000 [00:39<00:32, 137.11it/s]Running 10000 simulations.:  56%|█████▌    | 5564/10000 [00:39<00:32, 137.44it/s]Running 10000 simulations.:  56%|█████▌    | 5578/10000 [00:39<00:32, 136.99it/s]Running 10000 simulations.:  56%|█████▌    | 5592/10000 [00:39<00:32, 136.43it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:39<00:32, 136.73it/s]Running 10000 simulations.:  56%|█████▌    | 5620/10000 [00:39<00:32, 136.79it/s]Running 10000 simulations.:  56%|█████▋    | 5634/10000 [00:40<00:31, 136.54it/s]Running 10000 simulations.:  56%|█████▋    | 5649/10000 [00:40<00:31, 137.61it/s]Running 10000 simulations.:  57%|█████▋    | 5663/10000 [00:40<00:31, 136.73it/s]Running 10000 simulations.:  57%|█████▋    | 5677/10000 [00:40<00:31, 136.62it/s]Running 10000 simulations.:  57%|█████▋    | 5691/10000 [00:40<00:31, 136.60it/s]Running 10000 simulations.:  57%|█████▋    | 5705/10000 [00:40<00:31, 136.61it/s]Running 10000 simulations.:  57%|█████▋    | 5720/10000 [00:40<00:31, 138.02it/s]Running 10000 simulations.:  57%|█████▋    | 5734/10000 [00:40<00:30, 137.64it/s]Running 10000 simulations.:  57%|█████▋    | 5748/10000 [00:40<00:31, 136.66it/s]Running 10000 simulations.:  58%|█████▊    | 5762/10000 [00:40<00:31, 136.35it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:41<00:30, 136.97it/s]Running 10000 simulations.:  58%|█████▊    | 5790/10000 [00:41<00:30, 137.26it/s]Running 10000 simulations.:  58%|█████▊    | 5805/10000 [00:41<00:30, 138.61it/s]Running 10000 simulations.:  58%|█████▊    | 5819/10000 [00:41<00:30, 137.48it/s]Running 10000 simulations.:  58%|█████▊    | 5833/10000 [00:41<00:32, 128.79it/s]Running 10000 simulations.:  58%|█████▊    | 5847/10000 [00:41<00:31, 130.33it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:41<00:31, 131.76it/s]Running 10000 simulations.:  59%|█████▉    | 5875/10000 [00:41<00:31, 132.89it/s]Running 10000 simulations.:  59%|█████▉    | 5889/10000 [00:41<00:30, 133.88it/s]Running 10000 simulations.:  59%|█████▉    | 5903/10000 [00:42<00:30, 134.80it/s]Running 10000 simulations.:  59%|█████▉    | 5917/10000 [00:42<00:30, 135.69it/s]Running 10000 simulations.:  59%|█████▉    | 5932/10000 [00:42<00:29, 138.09it/s]Running 10000 simulations.:  59%|█████▉    | 5948/10000 [00:42<00:28, 143.77it/s]Running 10000 simulations.:  60%|█████▉    | 5964/10000 [00:42<00:27, 147.67it/s]Running 10000 simulations.:  60%|█████▉    | 5979/10000 [00:42<00:27, 144.41it/s]Running 10000 simulations.:  60%|█████▉    | 5994/10000 [00:42<00:28, 142.11it/s]Running 10000 simulations.:  60%|██████    | 6009/10000 [00:42<00:28, 140.15it/s]Running 10000 simulations.:  60%|██████    | 6024/10000 [00:42<00:28, 139.93it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:43<00:28, 140.14it/s]Running 10000 simulations.:  61%|██████    | 6054/10000 [00:43<00:28, 140.60it/s]Running 10000 simulations.:  61%|██████    | 6069/10000 [00:43<00:28, 138.99it/s]Running 10000 simulations.:  61%|██████    | 6083/10000 [00:43<00:28, 137.91it/s]Running 10000 simulations.:  61%|██████    | 6097/10000 [00:43<00:28, 136.76it/s]Running 10000 simulations.:  61%|██████    | 6111/10000 [00:43<00:28, 136.20it/s]Running 10000 simulations.:  61%|██████▏   | 6125/10000 [00:43<00:28, 136.29it/s]Running 10000 simulations.:  61%|██████▏   | 6139/10000 [00:43<00:28, 136.56it/s]Running 10000 simulations.:  62%|██████▏   | 6153/10000 [00:43<00:27, 137.46it/s]Running 10000 simulations.:  62%|██████▏   | 6167/10000 [00:43<00:27, 137.29it/s]Running 10000 simulations.:  62%|██████▏   | 6182/10000 [00:44<00:27, 138.83it/s]Running 10000 simulations.:  62%|██████▏   | 6196/10000 [00:44<00:27, 138.30it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:44<00:27, 138.39it/s]Running 10000 simulations.:  62%|██████▏   | 6224/10000 [00:44<00:27, 138.29it/s]Running 10000 simulations.:  62%|██████▏   | 6238/10000 [00:44<00:27, 137.67it/s]Running 10000 simulations.:  63%|██████▎   | 6252/10000 [00:44<00:27, 137.00it/s]Running 10000 simulations.:  63%|██████▎   | 6266/10000 [00:44<00:27, 136.95it/s]Running 10000 simulations.:  63%|██████▎   | 6280/10000 [00:44<00:27, 136.83it/s]Running 10000 simulations.:  63%|██████▎   | 6294/10000 [00:44<00:27, 136.44it/s]Running 10000 simulations.:  63%|██████▎   | 6308/10000 [00:44<00:27, 136.25it/s]Running 10000 simulations.:  63%|██████▎   | 6322/10000 [00:45<00:27, 135.36it/s]Running 10000 simulations.:  63%|██████▎   | 6336/10000 [00:45<00:27, 135.38it/s]Running 10000 simulations.:  64%|██████▎   | 6350/10000 [00:45<00:27, 135.06it/s]Running 10000 simulations.:  64%|██████▎   | 6364/10000 [00:45<00:26, 135.15it/s]Running 10000 simulations.:  64%|██████▍   | 6378/10000 [00:45<00:26, 134.93it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:45<00:26, 137.32it/s]Running 10000 simulations.:  64%|██████▍   | 6407/10000 [00:45<00:26, 137.72it/s]Running 10000 simulations.:  64%|██████▍   | 6421/10000 [00:45<00:26, 137.60it/s]Running 10000 simulations.:  64%|██████▍   | 6435/10000 [00:45<00:26, 136.99it/s]Running 10000 simulations.:  64%|██████▍   | 6449/10000 [00:45<00:25, 137.05it/s]Running 10000 simulations.:  65%|██████▍   | 6463/10000 [00:46<00:25, 136.35it/s]Running 10000 simulations.:  65%|██████▍   | 6477/10000 [00:46<00:25, 136.93it/s]Running 10000 simulations.:  65%|██████▍   | 6491/10000 [00:46<00:25, 135.73it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:46<00:25, 135.81it/s]Running 10000 simulations.:  65%|██████▌   | 6519/10000 [00:46<00:25, 134.85it/s]Running 10000 simulations.:  65%|██████▌   | 6533/10000 [00:46<00:25, 135.10it/s]Running 10000 simulations.:  65%|██████▌   | 6547/10000 [00:46<00:25, 134.54it/s]Running 10000 simulations.:  66%|██████▌   | 6561/10000 [00:46<00:25, 135.32it/s]Running 10000 simulations.:  66%|██████▌   | 6575/10000 [00:46<00:25, 135.34it/s]Running 10000 simulations.:  66%|██████▌   | 6589/10000 [00:47<00:25, 135.80it/s]Running 10000 simulations.:  66%|██████▌   | 6603/10000 [00:47<00:24, 136.43it/s]Running 10000 simulations.:  66%|██████▌   | 6617/10000 [00:47<00:24, 137.26it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:47<00:24, 136.91it/s]Running 10000 simulations.:  66%|██████▋   | 6645/10000 [00:47<00:24, 136.09it/s]Running 10000 simulations.:  67%|██████▋   | 6659/10000 [00:47<00:24, 135.63it/s]Running 10000 simulations.:  67%|██████▋   | 6673/10000 [00:47<00:24, 135.67it/s]Running 10000 simulations.:  67%|██████▋   | 6687/10000 [00:47<00:24, 136.74it/s]Running 10000 simulations.:  67%|██████▋   | 6701/10000 [00:47<00:23, 137.70it/s]Running 10000 simulations.:  67%|██████▋   | 6715/10000 [00:47<00:23, 138.36it/s]Running 10000 simulations.:  67%|██████▋   | 6729/10000 [00:48<00:23, 137.26it/s]Running 10000 simulations.:  67%|██████▋   | 6743/10000 [00:48<00:23, 136.73it/s]Running 10000 simulations.:  68%|██████▊   | 6757/10000 [00:48<00:23, 136.47it/s]Running 10000 simulations.:  68%|██████▊   | 6771/10000 [00:48<00:23, 135.84it/s]Running 10000 simulations.:  68%|██████▊   | 6785/10000 [00:48<00:23, 135.38it/s]Running 10000 simulations.:  68%|██████▊   | 6799/10000 [00:48<00:23, 135.64it/s]Running 10000 simulations.:  68%|██████▊   | 6813/10000 [00:48<00:23, 136.22it/s]Running 10000 simulations.:  68%|██████▊   | 6828/10000 [00:48<00:22, 139.53it/s]Running 10000 simulations.:  68%|██████▊   | 6842/10000 [00:48<00:22, 139.45it/s]Running 10000 simulations.:  69%|██████▊   | 6856/10000 [00:48<00:22, 138.80it/s]Running 10000 simulations.:  69%|██████▊   | 6870/10000 [00:49<00:22, 138.75it/s]Running 10000 simulations.:  69%|██████▉   | 6884/10000 [00:49<00:22, 137.96it/s]Running 10000 simulations.:  69%|██████▉   | 6898/10000 [00:49<00:22, 137.39it/s]Running 10000 simulations.:  69%|██████▉   | 6912/10000 [00:49<00:22, 136.60it/s]Running 10000 simulations.:  69%|██████▉   | 6926/10000 [00:49<00:22, 136.28it/s]Running 10000 simulations.:  69%|██████▉   | 6941/10000 [00:49<00:22, 138.03it/s]Running 10000 simulations.:  70%|██████▉   | 6956/10000 [00:49<00:21, 139.64it/s]Running 10000 simulations.:  70%|██████▉   | 6971/10000 [00:49<00:21, 140.30it/s]Running 10000 simulations.:  70%|██████▉   | 6986/10000 [00:49<00:21, 140.84it/s]Running 10000 simulations.:  70%|███████   | 7001/10000 [00:50<00:21, 140.16it/s]Running 10000 simulations.:  70%|███████   | 7016/10000 [00:50<00:21, 138.85it/s]Running 10000 simulations.:  70%|███████   | 7030/10000 [00:50<00:21, 139.12it/s]Running 10000 simulations.:  70%|███████   | 7045/10000 [00:50<00:20, 140.74it/s]Running 10000 simulations.:  71%|███████   | 7060/10000 [00:50<00:20, 141.09it/s]Running 10000 simulations.:  71%|███████   | 7075/10000 [00:50<00:20, 141.85it/s]Running 10000 simulations.:  71%|███████   | 7090/10000 [00:50<00:20, 143.25it/s]Running 10000 simulations.:  71%|███████   | 7105/10000 [00:50<00:20, 144.08it/s]Running 10000 simulations.:  71%|███████   | 7120/10000 [00:50<00:19, 144.24it/s]Running 10000 simulations.:  71%|███████▏  | 7135/10000 [00:50<00:19, 143.59it/s]Running 10000 simulations.:  72%|███████▏  | 7150/10000 [00:51<00:19, 143.64it/s]Running 10000 simulations.:  72%|███████▏  | 7165/10000 [00:51<00:19, 144.46it/s]Running 10000 simulations.:  72%|███████▏  | 7180/10000 [00:51<00:19, 144.11it/s]Running 10000 simulations.:  72%|███████▏  | 7195/10000 [00:51<00:19, 143.37it/s]Running 10000 simulations.:  72%|███████▏  | 7210/10000 [00:51<00:19, 144.44it/s]Running 10000 simulations.:  72%|███████▏  | 7225/10000 [00:51<00:19, 144.45it/s]Running 10000 simulations.:  72%|███████▏  | 7240/10000 [00:51<00:19, 144.46it/s]Running 10000 simulations.:  73%|███████▎  | 7255/10000 [00:51<00:18, 145.30it/s]Running 10000 simulations.:  73%|███████▎  | 7270/10000 [00:51<00:19, 143.08it/s]Running 10000 simulations.:  73%|███████▎  | 7285/10000 [00:52<00:19, 141.49it/s]Running 10000 simulations.:  73%|███████▎  | 7300/10000 [00:52<00:19, 141.45it/s]Running 10000 simulations.:  73%|███████▎  | 7315/10000 [00:52<00:19, 141.26it/s]Running 10000 simulations.:  73%|███████▎  | 7330/10000 [00:52<00:18, 140.56it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:52<00:18, 141.25it/s]Running 10000 simulations.:  74%|███████▎  | 7360/10000 [00:52<00:18, 142.24it/s]Running 10000 simulations.:  74%|███████▍  | 7375/10000 [00:52<00:18, 142.74it/s]Running 10000 simulations.:  74%|███████▍  | 7390/10000 [00:52<00:18, 143.06it/s]Running 10000 simulations.:  74%|███████▍  | 7405/10000 [00:52<00:18, 143.08it/s]Running 10000 simulations.:  74%|███████▍  | 7420/10000 [00:52<00:18, 140.71it/s]Running 10000 simulations.:  74%|███████▍  | 7435/10000 [00:53<00:18, 139.47it/s]Running 10000 simulations.:  74%|███████▍  | 7449/10000 [00:53<00:18, 138.75it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:53<00:18, 139.96it/s]Running 10000 simulations.:  75%|███████▍  | 7479/10000 [00:53<00:17, 140.75it/s]Running 10000 simulations.:  75%|███████▍  | 7494/10000 [00:53<00:17, 139.64it/s]Running 10000 simulations.:  75%|███████▌  | 7508/10000 [00:53<00:17, 139.11it/s]Running 10000 simulations.:  75%|███████▌  | 7522/10000 [00:53<00:17, 138.95it/s]Running 10000 simulations.:  75%|███████▌  | 7537/10000 [00:53<00:17, 140.18it/s]Running 10000 simulations.:  76%|███████▌  | 7552/10000 [00:53<00:17, 139.79it/s]Running 10000 simulations.:  76%|███████▌  | 7566/10000 [00:54<00:17, 139.43it/s]Running 10000 simulations.:  76%|███████▌  | 7581/10000 [00:54<00:17, 140.10it/s]Running 10000 simulations.:  76%|███████▌  | 7596/10000 [00:54<00:17, 140.48it/s]Running 10000 simulations.:  76%|███████▌  | 7611/10000 [00:54<00:16, 140.67it/s]Running 10000 simulations.:  76%|███████▋  | 7626/10000 [00:54<00:16, 141.77it/s]Running 10000 simulations.:  76%|███████▋  | 7641/10000 [00:54<00:16, 140.37it/s]Running 10000 simulations.:  77%|███████▋  | 7656/10000 [00:54<00:16, 139.31it/s]Running 10000 simulations.:  77%|███████▋  | 7670/10000 [00:54<00:16, 138.88it/s]Running 10000 simulations.:  77%|███████▋  | 7685/10000 [00:54<00:16, 140.48it/s]Running 10000 simulations.:  77%|███████▋  | 7700/10000 [00:54<00:16, 140.03it/s]Running 10000 simulations.:  77%|███████▋  | 7715/10000 [00:55<00:16, 141.43it/s]Running 10000 simulations.:  77%|███████▋  | 7730/10000 [00:55<00:16, 141.59it/s]Running 10000 simulations.:  77%|███████▋  | 7745/10000 [00:55<00:15, 141.52it/s]Running 10000 simulations.:  78%|███████▊  | 7760/10000 [00:55<00:15, 142.21it/s]Running 10000 simulations.:  78%|███████▊  | 7775/10000 [00:55<00:15, 140.87it/s]Running 10000 simulations.:  78%|███████▊  | 7790/10000 [00:55<00:15, 139.33it/s]Running 10000 simulations.:  78%|███████▊  | 7804/10000 [00:55<00:15, 138.00it/s]Running 10000 simulations.:  78%|███████▊  | 7818/10000 [00:55<00:15, 138.44it/s]Running 10000 simulations.:  78%|███████▊  | 7832/10000 [00:55<00:15, 138.26it/s]Running 10000 simulations.:  78%|███████▊  | 7847/10000 [00:56<00:15, 139.71it/s]Running 10000 simulations.:  79%|███████▊  | 7862/10000 [00:56<00:15, 140.36it/s]Running 10000 simulations.:  79%|███████▉  | 7877/10000 [00:56<00:15, 140.16it/s]Running 10000 simulations.:  79%|███████▉  | 7892/10000 [00:56<00:14, 141.63it/s]Running 10000 simulations.:  79%|███████▉  | 7907/10000 [00:56<00:14, 142.22it/s]Running 10000 simulations.:  79%|███████▉  | 7922/10000 [00:56<00:14, 140.34it/s]Running 10000 simulations.:  79%|███████▉  | 7937/10000 [00:56<00:14, 140.34it/s]Running 10000 simulations.:  80%|███████▉  | 7952/10000 [00:56<00:14, 139.75it/s]Running 10000 simulations.:  80%|███████▉  | 7966/10000 [00:56<00:14, 138.54it/s]Running 10000 simulations.:  80%|███████▉  | 7981/10000 [00:56<00:14, 139.85it/s]Running 10000 simulations.:  80%|███████▉  | 7995/10000 [00:57<00:14, 139.64it/s]Running 10000 simulations.:  80%|████████  | 8010/10000 [00:57<00:14, 139.88it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:57<00:14, 139.98it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:57<00:14, 138.69it/s]Running 10000 simulations.:  81%|████████  | 8054/10000 [00:57<00:14, 137.70it/s]Running 10000 simulations.:  81%|████████  | 8068/10000 [00:57<00:13, 138.03it/s]Running 10000 simulations.:  81%|████████  | 8082/10000 [00:57<00:13, 137.75it/s]Running 10000 simulations.:  81%|████████  | 8096/10000 [00:57<00:13, 137.62it/s]Running 10000 simulations.:  81%|████████  | 8111/10000 [00:57<00:13, 139.55it/s]Running 10000 simulations.:  81%|████████▏ | 8126/10000 [00:58<00:13, 139.98it/s]Running 10000 simulations.:  81%|████████▏ | 8141/10000 [00:58<00:13, 139.83it/s]Running 10000 simulations.:  82%|████████▏ | 8155/10000 [00:58<00:13, 139.25it/s]Running 10000 simulations.:  82%|████████▏ | 8169/10000 [00:58<00:13, 137.72it/s]Running 10000 simulations.:  82%|████████▏ | 8183/10000 [00:58<00:13, 136.83it/s]Running 10000 simulations.:  82%|████████▏ | 8197/10000 [00:58<00:13, 136.58it/s]Running 10000 simulations.:  82%|████████▏ | 8211/10000 [00:58<00:13, 136.26it/s]Running 10000 simulations.:  82%|████████▏ | 8225/10000 [00:58<00:12, 136.76it/s]Running 10000 simulations.:  82%|████████▏ | 8239/10000 [00:58<00:12, 137.44it/s]Running 10000 simulations.:  83%|████████▎ | 8254/10000 [00:58<00:12, 138.66it/s]Running 10000 simulations.:  83%|████████▎ | 8268/10000 [00:59<00:12, 138.96it/s]Running 10000 simulations.:  83%|████████▎ | 8282/10000 [00:59<00:12, 137.85it/s]Running 10000 simulations.:  83%|████████▎ | 8296/10000 [00:59<00:12, 138.29it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:59<00:12, 137.61it/s]Running 10000 simulations.:  83%|████████▎ | 8325/10000 [00:59<00:12, 138.55it/s]Running 10000 simulations.:  83%|████████▎ | 8341/10000 [00:59<00:11, 143.69it/s]Running 10000 simulations.:  84%|████████▎ | 8357/10000 [00:59<00:11, 146.62it/s]Running 10000 simulations.:  84%|████████▎ | 8373/10000 [00:59<00:11, 147.65it/s]Running 10000 simulations.:  84%|████████▍ | 8388/10000 [00:59<00:11, 146.24it/s]Running 10000 simulations.:  84%|████████▍ | 8403/10000 [00:59<00:11, 145.06it/s]Running 10000 simulations.:  84%|████████▍ | 8418/10000 [01:00<00:10, 144.70it/s]Running 10000 simulations.:  84%|████████▍ | 8433/10000 [01:00<00:10, 143.74it/s]Running 10000 simulations.:  84%|████████▍ | 8448/10000 [01:00<00:10, 142.75it/s]Running 10000 simulations.:  85%|████████▍ | 8463/10000 [01:00<00:10, 143.62it/s]Running 10000 simulations.:  85%|████████▍ | 8478/10000 [01:00<00:10, 143.44it/s]Running 10000 simulations.:  85%|████████▍ | 8493/10000 [01:00<00:10, 142.90it/s]Running 10000 simulations.:  85%|████████▌ | 8508/10000 [01:00<00:10, 144.30it/s]Running 10000 simulations.:  85%|████████▌ | 8523/10000 [01:00<00:10, 144.99it/s]Running 10000 simulations.:  85%|████████▌ | 8538/10000 [01:00<00:10, 145.39it/s]Running 10000 simulations.:  86%|████████▌ | 8553/10000 [01:01<00:09, 145.09it/s]Running 10000 simulations.:  86%|████████▌ | 8568/10000 [01:01<00:10, 143.19it/s]Running 10000 simulations.:  86%|████████▌ | 8583/10000 [01:01<00:09, 143.74it/s]Running 10000 simulations.:  86%|████████▌ | 8598/10000 [01:01<00:09, 142.89it/s]Running 10000 simulations.:  86%|████████▌ | 8613/10000 [01:01<00:09, 141.69it/s]Running 10000 simulations.:  86%|████████▋ | 8628/10000 [01:01<00:09, 141.10it/s]Running 10000 simulations.:  86%|████████▋ | 8643/10000 [01:01<00:09, 142.49it/s]Running 10000 simulations.:  87%|████████▋ | 8658/10000 [01:01<00:09, 142.29it/s]Running 10000 simulations.:  87%|████████▋ | 8673/10000 [01:01<00:09, 141.19it/s]Running 10000 simulations.:  87%|████████▋ | 8688/10000 [01:01<00:09, 140.26it/s]Running 10000 simulations.:  87%|████████▋ | 8703/10000 [01:02<00:09, 140.35it/s]Running 10000 simulations.:  87%|████████▋ | 8718/10000 [01:02<00:09, 141.40it/s]Running 10000 simulations.:  87%|████████▋ | 8733/10000 [01:02<00:08, 141.88it/s]Running 10000 simulations.:  87%|████████▋ | 8748/10000 [01:02<00:08, 142.03it/s]Running 10000 simulations.:  88%|████████▊ | 8763/10000 [01:02<00:08, 140.36it/s]Running 10000 simulations.:  88%|████████▊ | 8778/10000 [01:02<00:08, 140.47it/s]Running 10000 simulations.:  88%|████████▊ | 8793/10000 [01:02<00:08, 140.21it/s]Running 10000 simulations.:  88%|████████▊ | 8808/10000 [01:02<00:08, 138.36it/s]Running 10000 simulations.:  88%|████████▊ | 8823/10000 [01:02<00:08, 140.51it/s]Running 10000 simulations.:  88%|████████▊ | 8838/10000 [01:03<00:08, 141.98it/s]Running 10000 simulations.:  89%|████████▊ | 8853/10000 [01:03<00:08, 142.88it/s]Running 10000 simulations.:  89%|████████▊ | 8868/10000 [01:03<00:07, 143.88it/s]Running 10000 simulations.:  89%|████████▉ | 8883/10000 [01:03<00:07, 144.94it/s]Running 10000 simulations.:  89%|████████▉ | 8898/10000 [01:03<00:07, 144.13it/s]Running 10000 simulations.:  89%|████████▉ | 8913/10000 [01:03<00:07, 144.24it/s]Running 10000 simulations.:  89%|████████▉ | 8928/10000 [01:03<00:07, 143.92it/s]Running 10000 simulations.:  89%|████████▉ | 8943/10000 [01:03<00:07, 144.10it/s]Running 10000 simulations.:  90%|████████▉ | 8958/10000 [01:03<00:07, 144.49it/s]Running 10000 simulations.:  90%|████████▉ | 8973/10000 [01:03<00:07, 144.75it/s]Running 10000 simulations.:  90%|████████▉ | 8988/10000 [01:04<00:06, 145.31it/s]Running 10000 simulations.:  90%|█████████ | 9003/10000 [01:04<00:06, 146.01it/s]Running 10000 simulations.:  90%|█████████ | 9018/10000 [01:04<00:06, 145.98it/s]Running 10000 simulations.:  90%|█████████ | 9033/10000 [01:04<00:06, 145.06it/s]Running 10000 simulations.:  90%|█████████ | 9048/10000 [01:04<00:06, 145.10it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [01:04<00:06, 144.78it/s]Running 10000 simulations.:  91%|█████████ | 9078/10000 [01:04<00:06, 145.10it/s]Running 10000 simulations.:  91%|█████████ | 9093/10000 [01:04<00:06, 145.70it/s]Running 10000 simulations.:  91%|█████████ | 9108/10000 [01:04<00:06, 145.72it/s]Running 10000 simulations.:  91%|█████████ | 9123/10000 [01:04<00:06, 145.42it/s]Running 10000 simulations.:  91%|█████████▏| 9138/10000 [01:05<00:05, 145.19it/s]Running 10000 simulations.:  92%|█████████▏| 9153/10000 [01:05<00:05, 144.21it/s]Running 10000 simulations.:  92%|█████████▏| 9168/10000 [01:05<00:05, 143.50it/s]Running 10000 simulations.:  92%|█████████▏| 9183/10000 [01:05<00:05, 143.26it/s]Running 10000 simulations.:  92%|█████████▏| 9198/10000 [01:05<00:05, 143.25it/s]Running 10000 simulations.:  92%|█████████▏| 9213/10000 [01:05<00:05, 143.39it/s]Running 10000 simulations.:  92%|█████████▏| 9228/10000 [01:05<00:05, 143.94it/s]Running 10000 simulations.:  92%|█████████▏| 9243/10000 [01:05<00:05, 143.66it/s]Running 10000 simulations.:  93%|█████████▎| 9258/10000 [01:05<00:05, 143.59it/s]Running 10000 simulations.:  93%|█████████▎| 9273/10000 [01:06<00:05, 143.68it/s]Running 10000 simulations.:  93%|█████████▎| 9288/10000 [01:06<00:04, 143.61it/s]Running 10000 simulations.:  93%|█████████▎| 9303/10000 [01:06<00:04, 143.13it/s]Running 10000 simulations.:  93%|█████████▎| 9318/10000 [01:06<00:04, 142.97it/s]Running 10000 simulations.:  93%|█████████▎| 9333/10000 [01:06<00:04, 143.10it/s]Running 10000 simulations.:  93%|█████████▎| 9348/10000 [01:06<00:04, 142.96it/s]Running 10000 simulations.:  94%|█████████▎| 9363/10000 [01:06<00:04, 142.83it/s]Running 10000 simulations.:  94%|█████████▍| 9378/10000 [01:06<00:04, 142.99it/s]Running 10000 simulations.:  94%|█████████▍| 9393/10000 [01:06<00:04, 142.92it/s]Running 10000 simulations.:  94%|█████████▍| 9408/10000 [01:06<00:04, 142.95it/s]Running 10000 simulations.:  94%|█████████▍| 9423/10000 [01:07<00:04, 143.31it/s]Running 10000 simulations.:  94%|█████████▍| 9438/10000 [01:07<00:03, 143.14it/s]Running 10000 simulations.:  95%|█████████▍| 9453/10000 [01:07<00:03, 143.16it/s]Running 10000 simulations.:  95%|█████████▍| 9468/10000 [01:07<00:03, 143.23it/s]Running 10000 simulations.:  95%|█████████▍| 9483/10000 [01:07<00:03, 142.73it/s]Running 10000 simulations.:  95%|█████████▍| 9498/10000 [01:07<00:03, 142.77it/s]Running 10000 simulations.:  95%|█████████▌| 9513/10000 [01:07<00:03, 143.54it/s]Running 10000 simulations.:  95%|█████████▌| 9528/10000 [01:07<00:03, 144.03it/s]Running 10000 simulations.:  95%|█████████▌| 9543/10000 [01:07<00:03, 144.53it/s]Running 10000 simulations.:  96%|█████████▌| 9558/10000 [01:08<00:03, 144.80it/s]Running 10000 simulations.:  96%|█████████▌| 9573/10000 [01:08<00:02, 144.67it/s]Running 10000 simulations.:  96%|█████████▌| 9588/10000 [01:08<00:02, 145.05it/s]Running 10000 simulations.:  96%|█████████▌| 9603/10000 [01:08<00:02, 143.60it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [01:08<00:02, 143.08it/s]Running 10000 simulations.:  96%|█████████▋| 9633/10000 [01:08<00:02, 142.33it/s]Running 10000 simulations.:  96%|█████████▋| 9648/10000 [01:08<00:02, 142.38it/s]Running 10000 simulations.:  97%|█████████▋| 9663/10000 [01:08<00:02, 142.58it/s]Running 10000 simulations.:  97%|█████████▋| 9678/10000 [01:08<00:02, 141.99it/s]Running 10000 simulations.:  97%|█████████▋| 9693/10000 [01:08<00:02, 141.80it/s]Running 10000 simulations.:  97%|█████████▋| 9708/10000 [01:09<00:02, 140.47it/s]Running 10000 simulations.:  97%|█████████▋| 9723/10000 [01:09<00:01, 140.60it/s]Running 10000 simulations.:  97%|█████████▋| 9738/10000 [01:09<00:01, 140.29it/s]Running 10000 simulations.:  98%|█████████▊| 9753/10000 [01:09<00:01, 140.41it/s]Running 10000 simulations.:  98%|█████████▊| 9768/10000 [01:09<00:01, 140.40it/s]Running 10000 simulations.:  98%|█████████▊| 9783/10000 [01:09<00:01, 140.02it/s]Running 10000 simulations.:  98%|█████████▊| 9798/10000 [01:09<00:01, 140.04it/s]Running 10000 simulations.:  98%|█████████▊| 9813/10000 [01:09<00:01, 139.67it/s]Running 10000 simulations.:  98%|█████████▊| 9828/10000 [01:09<00:01, 140.18it/s]Running 10000 simulations.:  98%|█████████▊| 9843/10000 [01:10<00:01, 140.98it/s]Running 10000 simulations.:  99%|█████████▊| 9858/10000 [01:10<00:01, 141.89it/s]Running 10000 simulations.:  99%|█████████▊| 9873/10000 [01:10<00:00, 141.88it/s]Running 10000 simulations.:  99%|█████████▉| 9888/10000 [01:10<00:00, 142.37it/s]Running 10000 simulations.:  99%|█████████▉| 9903/10000 [01:10<00:00, 143.10it/s]Running 10000 simulations.:  99%|█████████▉| 9918/10000 [01:10<00:00, 143.59it/s]Running 10000 simulations.:  99%|█████████▉| 9933/10000 [01:10<00:00, 144.24it/s]Running 10000 simulations.:  99%|█████████▉| 9948/10000 [01:10<00:00, 145.00it/s]Running 10000 simulations.: 100%|█████████▉| 9963/10000 [01:10<00:00, 143.98it/s]Running 10000 simulations.: 100%|█████████▉| 9978/10000 [01:10<00:00, 144.67it/s]Running 10000 simulations.: 100%|█████████▉| 9993/10000 [01:11<00:00, 145.10it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:11<00:00, 140.57it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 15/10000 [00:00<01:07, 148.86it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<01:06, 149.06it/s]Running 10000 simulations.:   0%|          | 45/10000 [00:00<01:06, 148.96it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<01:06, 148.65it/s]Running 10000 simulations.:   1%|          | 75/10000 [00:00<01:06, 148.63it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<01:06, 148.36it/s]Running 10000 simulations.:   1%|          | 105/10000 [00:00<01:06, 148.50it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<01:06, 148.16it/s]Running 10000 simulations.:   1%|▏         | 135/10000 [00:00<01:06, 148.01it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:01<01:06, 148.06it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:01<01:06, 148.29it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:01<01:06, 148.19it/s]Running 10000 simulations.:   2%|▏         | 195/10000 [00:01<01:06, 147.84it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:01<01:06, 147.74it/s]Running 10000 simulations.:   2%|▏         | 225/10000 [00:01<01:06, 147.76it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:01<01:06, 147.39it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<01:06, 147.07it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:01<01:06, 147.02it/s]Running 10000 simulations.:   3%|▎         | 285/10000 [00:01<01:06, 146.68it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:02<01:05, 147.02it/s]Running 10000 simulations.:   3%|▎         | 315/10000 [00:02<01:05, 147.12it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:02<01:05, 146.92it/s]Running 10000 simulations.:   3%|▎         | 345/10000 [00:02<01:05, 146.62it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:02<01:05, 146.56it/s]Running 10000 simulations.:   4%|▍         | 375/10000 [00:02<01:05, 146.36it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:02<01:05, 146.27it/s]Running 10000 simulations.:   4%|▍         | 405/10000 [00:02<01:05, 146.45it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:02<01:05, 146.53it/s]Running 10000 simulations.:   4%|▍         | 435/10000 [00:02<01:05, 146.87it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:03<01:05, 146.61it/s]Running 10000 simulations.:   5%|▍         | 465/10000 [00:03<01:05, 146.66it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:03<01:04, 147.24it/s]Running 10000 simulations.:   5%|▍         | 496/10000 [00:03<01:04, 148.11it/s]Running 10000 simulations.:   5%|▌         | 512/10000 [00:03<01:03, 149.00it/s]Running 10000 simulations.:   5%|▌         | 528/10000 [00:03<01:03, 149.58it/s]Running 10000 simulations.:   5%|▌         | 544/10000 [00:03<01:03, 149.76it/s]Running 10000 simulations.:   6%|▌         | 560/10000 [00:03<01:02, 150.20it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:03<01:02, 150.48it/s]Running 10000 simulations.:   6%|▌         | 592/10000 [00:03<01:02, 150.69it/s]Running 10000 simulations.:   6%|▌         | 608/10000 [00:04<01:02, 150.67it/s]Running 10000 simulations.:   6%|▌         | 624/10000 [00:04<01:02, 150.91it/s]Running 10000 simulations.:   6%|▋         | 640/10000 [00:04<01:01, 151.14it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:04<01:01, 150.98it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:04<01:01, 151.28it/s]Running 10000 simulations.:   7%|▋         | 688/10000 [00:04<01:01, 151.31it/s]Running 10000 simulations.:   7%|▋         | 704/10000 [00:04<01:01, 151.23it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:04<01:01, 150.79it/s]Running 10000 simulations.:   7%|▋         | 736/10000 [00:04<01:01, 150.47it/s]Running 10000 simulations.:   8%|▊         | 752/10000 [00:05<01:01, 150.12it/s]Running 10000 simulations.:   8%|▊         | 768/10000 [00:05<01:01, 150.06it/s]Running 10000 simulations.:   8%|▊         | 784/10000 [00:05<01:01, 150.19it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:05<01:01, 150.24it/s]Running 10000 simulations.:   8%|▊         | 816/10000 [00:05<01:00, 150.79it/s]Running 10000 simulations.:   8%|▊         | 832/10000 [00:05<01:00, 151.03it/s]Running 10000 simulations.:   8%|▊         | 848/10000 [00:05<01:00, 150.82it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:05<01:00, 151.07it/s]Running 10000 simulations.:   9%|▉         | 880/10000 [00:05<01:00, 150.79it/s]Running 10000 simulations.:   9%|▉         | 896/10000 [00:06<01:00, 150.69it/s]Running 10000 simulations.:   9%|▉         | 912/10000 [00:06<01:00, 150.72it/s]Running 10000 simulations.:   9%|▉         | 928/10000 [00:06<01:00, 150.78it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:06<01:00, 150.50it/s]Running 10000 simulations.:  10%|▉         | 960/10000 [00:06<01:03, 142.01it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:06<01:02, 144.20it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:06<01:01, 145.84it/s]Running 10000 simulations.:  10%|█         | 1005/10000 [00:06<01:02, 145.07it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:06<01:01, 146.36it/s]Running 10000 simulations.:  10%|█         | 1036/10000 [00:06<01:00, 147.90it/s]Running 10000 simulations.:  11%|█         | 1052/10000 [00:07<01:00, 148.87it/s]Running 10000 simulations.:  11%|█         | 1068/10000 [00:07<00:59, 149.40it/s]Running 10000 simulations.:  11%|█         | 1084/10000 [00:07<00:59, 150.19it/s]Running 10000 simulations.:  11%|█         | 1100/10000 [00:07<00:59, 150.74it/s]Running 10000 simulations.:  11%|█         | 1116/10000 [00:07<00:58, 150.75it/s]Running 10000 simulations.:  11%|█▏        | 1132/10000 [00:07<00:58, 150.67it/s]Running 10000 simulations.:  11%|█▏        | 1148/10000 [00:07<00:58, 150.30it/s]Running 10000 simulations.:  12%|█▏        | 1164/10000 [00:07<00:58, 150.41it/s]Running 10000 simulations.:  12%|█▏        | 1180/10000 [00:07<00:58, 150.19it/s]Running 10000 simulations.:  12%|█▏        | 1196/10000 [00:08<00:58, 150.51it/s]Running 10000 simulations.:  12%|█▏        | 1212/10000 [00:08<00:58, 150.15it/s]Running 10000 simulations.:  12%|█▏        | 1228/10000 [00:08<00:58, 150.28it/s]Running 10000 simulations.:  12%|█▏        | 1244/10000 [00:08<00:58, 150.78it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:08<00:57, 151.03it/s]Running 10000 simulations.:  13%|█▎        | 1276/10000 [00:08<00:57, 150.62it/s]Running 10000 simulations.:  13%|█▎        | 1292/10000 [00:08<00:57, 150.47it/s]Running 10000 simulations.:  13%|█▎        | 1308/10000 [00:08<00:57, 150.38it/s]Running 10000 simulations.:  13%|█▎        | 1324/10000 [00:08<00:57, 150.56it/s]Running 10000 simulations.:  13%|█▎        | 1340/10000 [00:08<00:58, 149.19it/s]Running 10000 simulations.:  14%|█▎        | 1355/10000 [00:09<00:58, 148.18it/s]Running 10000 simulations.:  14%|█▎        | 1370/10000 [00:09<00:58, 147.74it/s]Running 10000 simulations.:  14%|█▍        | 1386/10000 [00:09<00:58, 148.48it/s]Running 10000 simulations.:  14%|█▍        | 1402/10000 [00:09<00:57, 149.27it/s]Running 10000 simulations.:  14%|█▍        | 1418/10000 [00:09<00:57, 150.31it/s]Running 10000 simulations.:  14%|█▍        | 1434/10000 [00:09<00:56, 150.60it/s]Running 10000 simulations.:  14%|█▍        | 1450/10000 [00:09<00:56, 150.60it/s]Running 10000 simulations.:  15%|█▍        | 1466/10000 [00:09<00:56, 150.58it/s]Running 10000 simulations.:  15%|█▍        | 1482/10000 [00:09<00:56, 150.81it/s]Running 10000 simulations.:  15%|█▍        | 1498/10000 [00:10<00:56, 150.29it/s]Running 10000 simulations.:  15%|█▌        | 1514/10000 [00:10<00:56, 150.20it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:10<00:56, 150.15it/s]Running 10000 simulations.:  15%|█▌        | 1546/10000 [00:10<00:56, 150.54it/s]Running 10000 simulations.:  16%|█▌        | 1562/10000 [00:10<00:55, 150.94it/s]Running 10000 simulations.:  16%|█▌        | 1578/10000 [00:10<00:55, 150.52it/s]Running 10000 simulations.:  16%|█▌        | 1594/10000 [00:10<00:55, 150.88it/s]Running 10000 simulations.:  16%|█▌        | 1610/10000 [00:10<00:55, 150.62it/s]Running 10000 simulations.:  16%|█▋        | 1626/10000 [00:10<00:55, 150.75it/s]Running 10000 simulations.:  16%|█▋        | 1642/10000 [00:11<00:55, 150.66it/s]Running 10000 simulations.:  17%|█▋        | 1658/10000 [00:11<00:55, 150.82it/s]Running 10000 simulations.:  17%|█▋        | 1674/10000 [00:11<00:55, 150.40it/s]Running 10000 simulations.:  17%|█▋        | 1690/10000 [00:11<00:55, 150.46it/s]Running 10000 simulations.:  17%|█▋        | 1706/10000 [00:11<00:55, 150.66it/s]Running 10000 simulations.:  17%|█▋        | 1722/10000 [00:11<00:54, 150.55it/s]Running 10000 simulations.:  17%|█▋        | 1738/10000 [00:11<00:54, 150.34it/s]Running 10000 simulations.:  18%|█▊        | 1754/10000 [00:11<00:54, 150.17it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:11<00:54, 150.00it/s]Running 10000 simulations.:  18%|█▊        | 1786/10000 [00:11<00:54, 150.15it/s]Running 10000 simulations.:  18%|█▊        | 1802/10000 [00:12<00:54, 150.86it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:12<00:54, 150.79it/s]Running 10000 simulations.:  18%|█▊        | 1834/10000 [00:12<00:54, 150.71it/s]Running 10000 simulations.:  18%|█▊        | 1850/10000 [00:12<00:54, 150.43it/s]Running 10000 simulations.:  19%|█▊        | 1866/10000 [00:12<00:54, 150.32it/s]Running 10000 simulations.:  19%|█▉        | 1882/10000 [00:12<00:54, 150.30it/s]Running 10000 simulations.:  19%|█▉        | 1898/10000 [00:12<00:54, 149.89it/s]Running 10000 simulations.:  19%|█▉        | 1913/10000 [00:12<00:54, 149.76it/s]Running 10000 simulations.:  19%|█▉        | 1928/10000 [00:12<00:53, 149.81it/s]Running 10000 simulations.:  19%|█▉        | 1944/10000 [00:13<00:53, 150.40it/s]Running 10000 simulations.:  20%|█▉        | 1960/10000 [00:13<00:53, 150.22it/s]Running 10000 simulations.:  20%|█▉        | 1976/10000 [00:13<00:53, 150.40it/s]Running 10000 simulations.:  20%|█▉        | 1992/10000 [00:13<00:53, 150.35it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:13<00:53, 150.49it/s]Running 10000 simulations.:  20%|██        | 2024/10000 [00:13<00:53, 150.17it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:13<00:52, 150.38it/s]Running 10000 simulations.:  21%|██        | 2056/10000 [00:13<00:52, 150.40it/s]Running 10000 simulations.:  21%|██        | 2072/10000 [00:13<00:52, 150.44it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:13<00:52, 150.52it/s]Running 10000 simulations.:  21%|██        | 2104/10000 [00:14<00:52, 150.78it/s]Running 10000 simulations.:  21%|██        | 2120/10000 [00:14<00:52, 150.84it/s]Running 10000 simulations.:  21%|██▏       | 2136/10000 [00:14<00:52, 150.87it/s]Running 10000 simulations.:  22%|██▏       | 2152/10000 [00:14<00:52, 150.80it/s]Running 10000 simulations.:  22%|██▏       | 2168/10000 [00:14<00:51, 150.89it/s]Running 10000 simulations.:  22%|██▏       | 2184/10000 [00:14<00:51, 150.37it/s]Running 10000 simulations.:  22%|██▏       | 2200/10000 [00:14<00:51, 150.01it/s]Running 10000 simulations.:  22%|██▏       | 2216/10000 [00:14<00:51, 149.91it/s]Running 10000 simulations.:  22%|██▏       | 2232/10000 [00:14<00:51, 150.31it/s]Running 10000 simulations.:  22%|██▏       | 2248/10000 [00:15<00:51, 150.49it/s]Running 10000 simulations.:  23%|██▎       | 2264/10000 [00:15<00:51, 150.41it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:15<00:51, 148.62it/s]Running 10000 simulations.:  23%|██▎       | 2296/10000 [00:15<00:51, 149.17it/s]Running 10000 simulations.:  23%|██▎       | 2311/10000 [00:15<00:51, 148.89it/s]Running 10000 simulations.:  23%|██▎       | 2327/10000 [00:15<00:51, 149.33it/s]Running 10000 simulations.:  23%|██▎       | 2342/10000 [00:15<00:51, 149.35it/s]Running 10000 simulations.:  24%|██▎       | 2358/10000 [00:15<00:51, 149.77it/s]Running 10000 simulations.:  24%|██▎       | 2373/10000 [00:15<00:50, 149.63it/s]Running 10000 simulations.:  24%|██▍       | 2389/10000 [00:15<00:50, 149.92it/s]Running 10000 simulations.:  24%|██▍       | 2405/10000 [00:16<00:50, 150.19it/s]Running 10000 simulations.:  24%|██▍       | 2421/10000 [00:16<00:50, 150.14it/s]Running 10000 simulations.:  24%|██▍       | 2437/10000 [00:16<00:50, 150.21it/s]Running 10000 simulations.:  25%|██▍       | 2453/10000 [00:16<00:50, 150.11it/s]Running 10000 simulations.:  25%|██▍       | 2469/10000 [00:16<00:50, 150.18it/s]Running 10000 simulations.:  25%|██▍       | 2485/10000 [00:16<00:49, 150.37it/s]Running 10000 simulations.:  25%|██▌       | 2501/10000 [00:16<00:49, 150.36it/s]Running 10000 simulations.:  25%|██▌       | 2517/10000 [00:16<00:49, 150.52it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:16<00:49, 150.53it/s]Running 10000 simulations.:  25%|██▌       | 2549/10000 [00:17<00:49, 150.30it/s]Running 10000 simulations.:  26%|██▌       | 2565/10000 [00:17<00:49, 150.12it/s]Running 10000 simulations.:  26%|██▌       | 2581/10000 [00:17<00:49, 150.03it/s]Running 10000 simulations.:  26%|██▌       | 2597/10000 [00:17<00:49, 149.92it/s]Running 10000 simulations.:  26%|██▌       | 2613/10000 [00:17<00:49, 150.30it/s]Running 10000 simulations.:  26%|██▋       | 2629/10000 [00:17<00:49, 150.38it/s]Running 10000 simulations.:  26%|██▋       | 2645/10000 [00:17<00:48, 150.54it/s]Running 10000 simulations.:  27%|██▋       | 2661/10000 [00:17<00:48, 150.48it/s]Running 10000 simulations.:  27%|██▋       | 2677/10000 [00:17<00:48, 150.22it/s]Running 10000 simulations.:  27%|██▋       | 2693/10000 [00:17<00:48, 150.25it/s]Running 10000 simulations.:  27%|██▋       | 2709/10000 [00:18<00:48, 150.38it/s]Running 10000 simulations.:  27%|██▋       | 2725/10000 [00:18<00:48, 150.22it/s]Running 10000 simulations.:  27%|██▋       | 2741/10000 [00:18<00:48, 150.04it/s]Running 10000 simulations.:  28%|██▊       | 2757/10000 [00:18<00:48, 150.22it/s]Running 10000 simulations.:  28%|██▊       | 2773/10000 [00:18<00:47, 150.80it/s]Running 10000 simulations.:  28%|██▊       | 2789/10000 [00:18<00:47, 150.75it/s]Running 10000 simulations.:  28%|██▊       | 2805/10000 [00:18<00:47, 150.21it/s]Running 10000 simulations.:  28%|██▊       | 2821/10000 [00:18<00:47, 149.95it/s]Running 10000 simulations.:  28%|██▊       | 2837/10000 [00:18<00:47, 150.09it/s]Running 10000 simulations.:  29%|██▊       | 2853/10000 [00:19<00:47, 150.56it/s]Running 10000 simulations.:  29%|██▊       | 2869/10000 [00:19<00:47, 151.25it/s]Running 10000 simulations.:  29%|██▉       | 2885/10000 [00:19<00:47, 151.31it/s]Running 10000 simulations.:  29%|██▉       | 2901/10000 [00:19<00:46, 151.17it/s]Running 10000 simulations.:  29%|██▉       | 2917/10000 [00:19<00:47, 150.50it/s]Running 10000 simulations.:  29%|██▉       | 2933/10000 [00:19<00:46, 150.46it/s]Running 10000 simulations.:  29%|██▉       | 2949/10000 [00:19<00:46, 150.42it/s]Running 10000 simulations.:  30%|██▉       | 2965/10000 [00:19<00:46, 150.10it/s]Running 10000 simulations.:  30%|██▉       | 2981/10000 [00:19<00:46, 150.00it/s]Running 10000 simulations.:  30%|██▉       | 2997/10000 [00:20<00:46, 149.73it/s]Running 10000 simulations.:  30%|███       | 3012/10000 [00:20<00:46, 149.77it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:20<00:46, 150.02it/s]Running 10000 simulations.:  30%|███       | 3044/10000 [00:20<00:46, 149.92it/s]Running 10000 simulations.:  31%|███       | 3059/10000 [00:20<00:46, 149.83it/s]Running 10000 simulations.:  31%|███       | 3075/10000 [00:20<00:46, 149.95it/s]Running 10000 simulations.:  31%|███       | 3091/10000 [00:20<00:46, 150.08it/s]Running 10000 simulations.:  31%|███       | 3107/10000 [00:20<00:45, 150.21it/s]Running 10000 simulations.:  31%|███       | 3123/10000 [00:20<00:45, 150.33it/s]Running 10000 simulations.:  31%|███▏      | 3139/10000 [00:20<00:45, 150.40it/s]Running 10000 simulations.:  32%|███▏      | 3155/10000 [00:21<00:45, 150.49it/s]Running 10000 simulations.:  32%|███▏      | 3171/10000 [00:21<00:45, 150.03it/s]Running 10000 simulations.:  32%|███▏      | 3187/10000 [00:21<00:45, 149.96it/s]Running 10000 simulations.:  32%|███▏      | 3202/10000 [00:21<00:45, 149.53it/s]Running 10000 simulations.:  32%|███▏      | 3217/10000 [00:21<00:45, 149.50it/s]Running 10000 simulations.:  32%|███▏      | 3232/10000 [00:21<00:45, 149.48it/s]Running 10000 simulations.:  32%|███▏      | 3247/10000 [00:21<00:45, 149.18it/s]Running 10000 simulations.:  33%|███▎      | 3262/10000 [00:21<00:45, 149.39it/s]Running 10000 simulations.:  33%|███▎      | 3277/10000 [00:21<00:44, 149.55it/s]Running 10000 simulations.:  33%|███▎      | 3292/10000 [00:21<00:44, 149.38it/s]Running 10000 simulations.:  33%|███▎      | 3308/10000 [00:22<00:44, 149.60it/s]Running 10000 simulations.:  33%|███▎      | 3324/10000 [00:22<00:44, 150.10it/s]Running 10000 simulations.:  33%|███▎      | 3340/10000 [00:22<00:44, 149.86it/s]Running 10000 simulations.:  34%|███▎      | 3355/10000 [00:22<00:44, 148.39it/s]Running 10000 simulations.:  34%|███▎      | 3370/10000 [00:22<00:44, 147.96it/s]Running 10000 simulations.:  34%|███▍      | 3385/10000 [00:22<00:44, 148.38it/s]Running 10000 simulations.:  34%|███▍      | 3401/10000 [00:22<00:44, 149.23it/s]Running 10000 simulations.:  34%|███▍      | 3417/10000 [00:22<00:44, 149.59it/s]Running 10000 simulations.:  34%|███▍      | 3432/10000 [00:22<00:43, 149.64it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:23<00:43, 150.20it/s]Running 10000 simulations.:  35%|███▍      | 3464/10000 [00:23<00:43, 150.48it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:23<00:43, 150.53it/s]Running 10000 simulations.:  35%|███▍      | 3496/10000 [00:23<00:43, 150.35it/s]Running 10000 simulations.:  35%|███▌      | 3512/10000 [00:23<00:43, 150.41it/s]Running 10000 simulations.:  35%|███▌      | 3528/10000 [00:23<00:42, 151.02it/s]Running 10000 simulations.:  35%|███▌      | 3544/10000 [00:23<00:42, 150.61it/s]Running 10000 simulations.:  36%|███▌      | 3560/10000 [00:23<00:42, 150.41it/s]Running 10000 simulations.:  36%|███▌      | 3576/10000 [00:23<00:42, 150.51it/s]Running 10000 simulations.:  36%|███▌      | 3592/10000 [00:23<00:42, 150.53it/s]Running 10000 simulations.:  36%|███▌      | 3608/10000 [00:24<00:42, 150.66it/s]Running 10000 simulations.:  36%|███▌      | 3624/10000 [00:24<00:42, 150.62it/s]Running 10000 simulations.:  36%|███▋      | 3640/10000 [00:24<00:42, 150.81it/s]Running 10000 simulations.:  37%|███▋      | 3656/10000 [00:24<00:42, 150.53it/s]Running 10000 simulations.:  37%|███▋      | 3672/10000 [00:24<00:42, 148.30it/s]Running 10000 simulations.:  37%|███▋      | 3687/10000 [00:24<00:42, 147.06it/s]Running 10000 simulations.:  37%|███▋      | 3703/10000 [00:24<00:42, 148.22it/s]Running 10000 simulations.:  37%|███▋      | 3719/10000 [00:24<00:42, 148.96it/s]Running 10000 simulations.:  37%|███▋      | 3734/10000 [00:24<00:42, 149.09it/s]Running 10000 simulations.:  38%|███▊      | 3750/10000 [00:25<00:41, 149.37it/s]Running 10000 simulations.:  38%|███▊      | 3766/10000 [00:25<00:41, 149.68it/s]Running 10000 simulations.:  38%|███▊      | 3782/10000 [00:25<00:41, 149.97it/s]Running 10000 simulations.:  38%|███▊      | 3798/10000 [00:25<00:41, 150.09it/s]Running 10000 simulations.:  38%|███▊      | 3814/10000 [00:25<00:41, 149.95it/s]Running 10000 simulations.:  38%|███▊      | 3829/10000 [00:25<00:41, 149.94it/s]Running 10000 simulations.:  38%|███▊      | 3845/10000 [00:25<00:41, 150.02it/s]Running 10000 simulations.:  39%|███▊      | 3861/10000 [00:25<00:40, 150.21it/s]Running 10000 simulations.:  39%|███▉      | 3877/10000 [00:25<00:40, 150.04it/s]Running 10000 simulations.:  39%|███▉      | 3893/10000 [00:26<00:40, 150.22it/s]Running 10000 simulations.:  39%|███▉      | 3909/10000 [00:26<00:40, 150.44it/s]Running 10000 simulations.:  39%|███▉      | 3925/10000 [00:26<00:40, 151.14it/s]Running 10000 simulations.:  39%|███▉      | 3941/10000 [00:26<00:40, 150.59it/s]Running 10000 simulations.:  40%|███▉      | 3957/10000 [00:26<00:40, 150.54it/s]Running 10000 simulations.:  40%|███▉      | 3973/10000 [00:26<00:40, 150.29it/s]Running 10000 simulations.:  40%|███▉      | 3989/10000 [00:26<00:40, 149.94it/s]Running 10000 simulations.:  40%|████      | 4004/10000 [00:26<00:40, 149.33it/s]Running 10000 simulations.:  40%|████      | 4019/10000 [00:26<00:40, 147.81it/s]Running 10000 simulations.:  40%|████      | 4034/10000 [00:26<00:40, 148.24it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:27<00:39, 149.28it/s]Running 10000 simulations.:  41%|████      | 4065/10000 [00:27<00:39, 149.33it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:27<00:39, 149.63it/s]Running 10000 simulations.:  41%|████      | 4096/10000 [00:27<00:39, 149.60it/s]Running 10000 simulations.:  41%|████      | 4111/10000 [00:27<00:39, 149.58it/s]Running 10000 simulations.:  41%|████▏     | 4126/10000 [00:27<00:39, 149.56it/s]Running 10000 simulations.:  41%|████▏     | 4141/10000 [00:27<00:39, 149.37it/s]Running 10000 simulations.:  42%|████▏     | 4156/10000 [00:27<00:39, 149.43it/s]Running 10000 simulations.:  42%|████▏     | 4172/10000 [00:27<00:38, 149.74it/s]Running 10000 simulations.:  42%|████▏     | 4188/10000 [00:27<00:38, 149.98it/s]Running 10000 simulations.:  42%|████▏     | 4203/10000 [00:28<00:38, 149.53it/s]Running 10000 simulations.:  42%|████▏     | 4218/10000 [00:28<00:38, 149.54it/s]Running 10000 simulations.:  42%|████▏     | 4233/10000 [00:28<00:38, 149.46it/s]Running 10000 simulations.:  42%|████▏     | 4248/10000 [00:28<00:38, 149.47it/s]Running 10000 simulations.:  43%|████▎     | 4263/10000 [00:28<00:38, 149.32it/s]Running 10000 simulations.:  43%|████▎     | 4278/10000 [00:28<00:38, 149.16it/s]Running 10000 simulations.:  43%|████▎     | 4293/10000 [00:28<00:38, 149.20it/s]Running 10000 simulations.:  43%|████▎     | 4308/10000 [00:28<00:38, 149.17it/s]Running 10000 simulations.:  43%|████▎     | 4323/10000 [00:28<00:38, 149.03it/s]Running 10000 simulations.:  43%|████▎     | 4338/10000 [00:28<00:38, 148.91it/s]Running 10000 simulations.:  44%|████▎     | 4353/10000 [00:29<00:37, 149.03it/s]Running 10000 simulations.:  44%|████▎     | 4369/10000 [00:29<00:37, 149.35it/s]Running 10000 simulations.:  44%|████▍     | 4384/10000 [00:29<00:37, 149.28it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:29<00:37, 149.16it/s]Running 10000 simulations.:  44%|████▍     | 4414/10000 [00:29<00:37, 149.15it/s]Running 10000 simulations.:  44%|████▍     | 4430/10000 [00:29<00:37, 149.43it/s]Running 10000 simulations.:  44%|████▍     | 4445/10000 [00:29<00:37, 149.18it/s]Running 10000 simulations.:  45%|████▍     | 4460/10000 [00:29<00:37, 149.26it/s]Running 10000 simulations.:  45%|████▍     | 4475/10000 [00:29<00:37, 149.31it/s]Running 10000 simulations.:  45%|████▍     | 4490/10000 [00:29<00:36, 149.45it/s]Running 10000 simulations.:  45%|████▌     | 4505/10000 [00:30<00:36, 149.40it/s]Running 10000 simulations.:  45%|████▌     | 4520/10000 [00:30<00:36, 149.52it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:30<00:36, 149.57it/s]Running 10000 simulations.:  46%|████▌     | 4550/10000 [00:30<00:36, 149.50it/s]Running 10000 simulations.:  46%|████▌     | 4565/10000 [00:30<00:36, 149.35it/s]Running 10000 simulations.:  46%|████▌     | 4581/10000 [00:30<00:36, 150.30it/s]Running 10000 simulations.:  46%|████▌     | 4597/10000 [00:30<00:35, 150.65it/s]Running 10000 simulations.:  46%|████▌     | 4613/10000 [00:30<00:35, 150.50it/s]Running 10000 simulations.:  46%|████▋     | 4629/10000 [00:30<00:35, 150.46it/s]Running 10000 simulations.:  46%|████▋     | 4645/10000 [00:31<00:35, 150.55it/s]Running 10000 simulations.:  47%|████▋     | 4661/10000 [00:31<00:35, 150.83it/s]Running 10000 simulations.:  47%|████▋     | 4677/10000 [00:31<00:35, 150.83it/s]Running 10000 simulations.:  47%|████▋     | 4693/10000 [00:31<00:35, 150.65it/s]Running 10000 simulations.:  47%|████▋     | 4709/10000 [00:31<00:35, 151.02it/s]Running 10000 simulations.:  47%|████▋     | 4725/10000 [00:31<00:34, 151.77it/s]Running 10000 simulations.:  47%|████▋     | 4741/10000 [00:31<00:34, 152.10it/s]Running 10000 simulations.:  48%|████▊     | 4757/10000 [00:31<00:34, 152.66it/s]Running 10000 simulations.:  48%|████▊     | 4773/10000 [00:31<00:34, 152.92it/s]Running 10000 simulations.:  48%|████▊     | 4789/10000 [00:31<00:34, 152.74it/s]Running 10000 simulations.:  48%|████▊     | 4805/10000 [00:32<00:34, 152.60it/s]Running 10000 simulations.:  48%|████▊     | 4821/10000 [00:32<00:34, 151.66it/s]Running 10000 simulations.:  48%|████▊     | 4837/10000 [00:32<00:34, 151.61it/s]Running 10000 simulations.:  49%|████▊     | 4853/10000 [00:32<00:33, 151.53it/s]Running 10000 simulations.:  49%|████▊     | 4869/10000 [00:32<00:33, 151.65it/s]Running 10000 simulations.:  49%|████▉     | 4885/10000 [00:32<00:33, 151.68it/s]Running 10000 simulations.:  49%|████▉     | 4901/10000 [00:32<00:33, 151.93it/s]Running 10000 simulations.:  49%|████▉     | 4917/10000 [00:32<00:33, 152.74it/s]Running 10000 simulations.:  49%|████▉     | 4933/10000 [00:32<00:33, 151.61it/s]Running 10000 simulations.:  49%|████▉     | 4949/10000 [00:33<00:33, 151.15it/s]Running 10000 simulations.:  50%|████▉     | 4965/10000 [00:33<00:33, 150.47it/s]Running 10000 simulations.:  50%|████▉     | 4981/10000 [00:33<00:33, 150.79it/s]Running 10000 simulations.:  50%|████▉     | 4997/10000 [00:33<00:33, 150.97it/s]Running 10000 simulations.:  50%|█████     | 5013/10000 [00:33<00:33, 150.28it/s]Running 10000 simulations.:  50%|█████     | 5029/10000 [00:33<00:33, 150.10it/s]Running 10000 simulations.:  50%|█████     | 5045/10000 [00:33<00:33, 149.56it/s]Running 10000 simulations.:  51%|█████     | 5060/10000 [00:33<00:33, 148.84it/s]Running 10000 simulations.:  51%|█████     | 5076/10000 [00:33<00:32, 149.64it/s]Running 10000 simulations.:  51%|█████     | 5092/10000 [00:33<00:32, 150.70it/s]Running 10000 simulations.:  51%|█████     | 5108/10000 [00:34<00:32, 151.16it/s]Running 10000 simulations.:  51%|█████     | 5124/10000 [00:34<00:32, 151.60it/s]Running 10000 simulations.:  51%|█████▏    | 5140/10000 [00:34<00:32, 151.60it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:34<00:31, 151.82it/s]Running 10000 simulations.:  52%|█████▏    | 5172/10000 [00:34<00:31, 151.55it/s]Running 10000 simulations.:  52%|█████▏    | 5188/10000 [00:34<00:31, 151.57it/s]Running 10000 simulations.:  52%|█████▏    | 5204/10000 [00:34<00:31, 151.86it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:34<00:31, 152.02it/s]Running 10000 simulations.:  52%|█████▏    | 5236/10000 [00:34<00:31, 152.32it/s]Running 10000 simulations.:  53%|█████▎    | 5252/10000 [00:35<00:31, 152.77it/s]Running 10000 simulations.:  53%|█████▎    | 5268/10000 [00:35<00:30, 153.27it/s]Running 10000 simulations.:  53%|█████▎    | 5284/10000 [00:35<00:30, 152.37it/s]Running 10000 simulations.:  53%|█████▎    | 5300/10000 [00:35<00:30, 152.83it/s]Running 10000 simulations.:  53%|█████▎    | 5316/10000 [00:35<00:30, 153.15it/s]Running 10000 simulations.:  53%|█████▎    | 5332/10000 [00:35<00:30, 153.30it/s]Running 10000 simulations.:  53%|█████▎    | 5348/10000 [00:35<00:30, 153.57it/s]Running 10000 simulations.:  54%|█████▎    | 5364/10000 [00:35<00:30, 153.25it/s]Running 10000 simulations.:  54%|█████▍    | 5380/10000 [00:35<00:30, 153.65it/s]Running 10000 simulations.:  54%|█████▍    | 5396/10000 [00:35<00:30, 153.27it/s]Running 10000 simulations.:  54%|█████▍    | 5412/10000 [00:36<00:30, 152.62it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:36<00:30, 152.23it/s]Running 10000 simulations.:  54%|█████▍    | 5444/10000 [00:36<00:29, 152.26it/s]Running 10000 simulations.:  55%|█████▍    | 5460/10000 [00:36<00:31, 144.47it/s]Running 10000 simulations.:  55%|█████▍    | 5476/10000 [00:36<00:30, 146.35it/s]Running 10000 simulations.:  55%|█████▍    | 5492/10000 [00:36<00:30, 148.01it/s]Running 10000 simulations.:  55%|█████▌    | 5508/10000 [00:36<00:30, 149.50it/s]Running 10000 simulations.:  55%|█████▌    | 5524/10000 [00:36<00:29, 150.50it/s]Running 10000 simulations.:  55%|█████▌    | 5540/10000 [00:36<00:29, 151.18it/s]Running 10000 simulations.:  56%|█████▌    | 5556/10000 [00:37<00:29, 151.47it/s]Running 10000 simulations.:  56%|█████▌    | 5572/10000 [00:37<00:29, 151.24it/s]Running 10000 simulations.:  56%|█████▌    | 5588/10000 [00:37<00:29, 151.43it/s]Running 10000 simulations.:  56%|█████▌    | 5604/10000 [00:37<00:29, 151.54it/s]Running 10000 simulations.:  56%|█████▌    | 5620/10000 [00:37<00:28, 151.40it/s]Running 10000 simulations.:  56%|█████▋    | 5636/10000 [00:37<00:28, 151.83it/s]Running 10000 simulations.:  57%|█████▋    | 5652/10000 [00:37<00:28, 151.24it/s]Running 10000 simulations.:  57%|█████▋    | 5668/10000 [00:37<00:28, 151.49it/s]Running 10000 simulations.:  57%|█████▋    | 5684/10000 [00:37<00:28, 151.74it/s]Running 10000 simulations.:  57%|█████▋    | 5700/10000 [00:37<00:28, 151.83it/s]Running 10000 simulations.:  57%|█████▋    | 5716/10000 [00:38<00:28, 151.96it/s]Running 10000 simulations.:  57%|█████▋    | 5732/10000 [00:38<00:28, 151.65it/s]Running 10000 simulations.:  57%|█████▋    | 5748/10000 [00:38<00:28, 151.74it/s]Running 10000 simulations.:  58%|█████▊    | 5764/10000 [00:38<00:27, 151.91it/s]Running 10000 simulations.:  58%|█████▊    | 5780/10000 [00:38<00:27, 151.98it/s]Running 10000 simulations.:  58%|█████▊    | 5796/10000 [00:38<00:27, 152.18it/s]Running 10000 simulations.:  58%|█████▊    | 5812/10000 [00:38<00:27, 152.25it/s]Running 10000 simulations.:  58%|█████▊    | 5828/10000 [00:38<00:27, 152.40it/s]Running 10000 simulations.:  58%|█████▊    | 5844/10000 [00:38<00:27, 153.39it/s]Running 10000 simulations.:  59%|█████▊    | 5860/10000 [00:39<00:26, 154.11it/s]Running 10000 simulations.:  59%|█████▉    | 5876/10000 [00:39<00:26, 154.28it/s]Running 10000 simulations.:  59%|█████▉    | 5892/10000 [00:39<00:26, 154.69it/s]Running 10000 simulations.:  59%|█████▉    | 5908/10000 [00:39<00:26, 154.84it/s]Running 10000 simulations.:  59%|█████▉    | 5924/10000 [00:39<00:26, 154.43it/s]Running 10000 simulations.:  59%|█████▉    | 5940/10000 [00:39<00:26, 153.82it/s]Running 10000 simulations.:  60%|█████▉    | 5956/10000 [00:39<00:26, 153.26it/s]Running 10000 simulations.:  60%|█████▉    | 5972/10000 [00:39<00:26, 153.25it/s]Running 10000 simulations.:  60%|█████▉    | 5988/10000 [00:39<00:26, 152.75it/s]Running 10000 simulations.:  60%|██████    | 6004/10000 [00:39<00:26, 153.52it/s]Running 10000 simulations.:  60%|██████    | 6020/10000 [00:40<00:25, 153.49it/s]Running 10000 simulations.:  60%|██████    | 6036/10000 [00:40<00:25, 153.29it/s]Running 10000 simulations.:  61%|██████    | 6052/10000 [00:40<00:25, 153.11it/s]Running 10000 simulations.:  61%|██████    | 6068/10000 [00:40<00:25, 153.24it/s]Running 10000 simulations.:  61%|██████    | 6084/10000 [00:40<00:25, 152.60it/s]Running 10000 simulations.:  61%|██████    | 6100/10000 [00:40<00:25, 152.56it/s]Running 10000 simulations.:  61%|██████    | 6116/10000 [00:40<00:25, 152.55it/s]Running 10000 simulations.:  61%|██████▏   | 6132/10000 [00:40<00:25, 153.33it/s]Running 10000 simulations.:  61%|██████▏   | 6148/10000 [00:40<00:25, 153.94it/s]Running 10000 simulations.:  62%|██████▏   | 6164/10000 [00:41<00:24, 153.68it/s]Running 10000 simulations.:  62%|██████▏   | 6180/10000 [00:41<00:25, 152.70it/s]Running 10000 simulations.:  62%|██████▏   | 6196/10000 [00:41<00:24, 152.72it/s]Running 10000 simulations.:  62%|██████▏   | 6212/10000 [00:41<00:24, 152.39it/s]Running 10000 simulations.:  62%|██████▏   | 6228/10000 [00:41<00:24, 151.99it/s]Running 10000 simulations.:  62%|██████▏   | 6244/10000 [00:41<00:24, 152.45it/s]Running 10000 simulations.:  63%|██████▎   | 6260/10000 [00:41<00:24, 152.75it/s]Running 10000 simulations.:  63%|██████▎   | 6276/10000 [00:41<00:24, 152.31it/s]Running 10000 simulations.:  63%|██████▎   | 6292/10000 [00:41<00:24, 151.01it/s]Running 10000 simulations.:  63%|██████▎   | 6308/10000 [00:41<00:24, 150.72it/s]Running 10000 simulations.:  63%|██████▎   | 6324/10000 [00:42<00:24, 150.89it/s]Running 10000 simulations.:  63%|██████▎   | 6340/10000 [00:42<00:24, 151.09it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:42<00:23, 152.07it/s]Running 10000 simulations.:  64%|██████▎   | 6372/10000 [00:42<00:23, 152.66it/s]Running 10000 simulations.:  64%|██████▍   | 6388/10000 [00:42<00:23, 152.77it/s]Running 10000 simulations.:  64%|██████▍   | 6404/10000 [00:42<00:23, 152.00it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:42<00:23, 150.41it/s]Running 10000 simulations.:  64%|██████▍   | 6436/10000 [00:42<00:23, 150.68it/s]Running 10000 simulations.:  65%|██████▍   | 6452/10000 [00:42<00:23, 151.40it/s]Running 10000 simulations.:  65%|██████▍   | 6468/10000 [00:43<00:23, 151.80it/s]Running 10000 simulations.:  65%|██████▍   | 6484/10000 [00:43<00:23, 151.74it/s]Running 10000 simulations.:  65%|██████▌   | 6500/10000 [00:43<00:23, 151.92it/s]Running 10000 simulations.:  65%|██████▌   | 6516/10000 [00:43<00:22, 152.29it/s]Running 10000 simulations.:  65%|██████▌   | 6532/10000 [00:43<00:22, 151.88it/s]Running 10000 simulations.:  65%|██████▌   | 6548/10000 [00:43<00:22, 152.07it/s]Running 10000 simulations.:  66%|██████▌   | 6564/10000 [00:43<00:22, 152.43it/s]Running 10000 simulations.:  66%|██████▌   | 6580/10000 [00:43<00:22, 152.13it/s]Running 10000 simulations.:  66%|██████▌   | 6596/10000 [00:43<00:22, 152.36it/s]Running 10000 simulations.:  66%|██████▌   | 6612/10000 [00:43<00:22, 152.06it/s]Running 10000 simulations.:  66%|██████▋   | 6628/10000 [00:44<00:22, 151.37it/s]Running 10000 simulations.:  66%|██████▋   | 6644/10000 [00:44<00:22, 151.36it/s]Running 10000 simulations.:  67%|██████▋   | 6660/10000 [00:44<00:22, 151.66it/s]Running 10000 simulations.:  67%|██████▋   | 6676/10000 [00:44<00:21, 152.05it/s]Running 10000 simulations.:  67%|██████▋   | 6692/10000 [00:44<00:21, 152.22it/s]Running 10000 simulations.:  67%|██████▋   | 6708/10000 [00:44<00:21, 152.27it/s]Running 10000 simulations.:  67%|██████▋   | 6724/10000 [00:44<00:21, 152.25it/s]Running 10000 simulations.:  67%|██████▋   | 6740/10000 [00:44<00:21, 152.50it/s]Running 10000 simulations.:  68%|██████▊   | 6756/10000 [00:44<00:21, 152.45it/s]Running 10000 simulations.:  68%|██████▊   | 6772/10000 [00:45<00:21, 152.13it/s]Running 10000 simulations.:  68%|██████▊   | 6788/10000 [00:45<00:21, 152.28it/s]Running 10000 simulations.:  68%|██████▊   | 6804/10000 [00:45<00:20, 152.54it/s]Running 10000 simulations.:  68%|██████▊   | 6820/10000 [00:45<00:20, 152.52it/s]Running 10000 simulations.:  68%|██████▊   | 6836/10000 [00:45<00:20, 152.52it/s]Running 10000 simulations.:  69%|██████▊   | 6852/10000 [00:45<00:20, 152.77it/s]Running 10000 simulations.:  69%|██████▊   | 6868/10000 [00:45<00:20, 153.10it/s]Running 10000 simulations.:  69%|██████▉   | 6884/10000 [00:45<00:20, 153.01it/s]Running 10000 simulations.:  69%|██████▉   | 6900/10000 [00:45<00:20, 152.87it/s]Running 10000 simulations.:  69%|██████▉   | 6916/10000 [00:45<00:20, 152.32it/s]Running 10000 simulations.:  69%|██████▉   | 6932/10000 [00:46<00:20, 152.40it/s]Running 10000 simulations.:  69%|██████▉   | 6948/10000 [00:46<00:20, 152.23it/s]Running 10000 simulations.:  70%|██████▉   | 6964/10000 [00:46<00:19, 152.28it/s]Running 10000 simulations.:  70%|██████▉   | 6980/10000 [00:46<00:19, 152.84it/s]Running 10000 simulations.:  70%|██████▉   | 6996/10000 [00:46<00:19, 152.80it/s]Running 10000 simulations.:  70%|███████   | 7012/10000 [00:46<00:19, 152.91it/s]Running 10000 simulations.:  70%|███████   | 7028/10000 [00:46<00:19, 153.11it/s]Running 10000 simulations.:  70%|███████   | 7044/10000 [00:46<00:19, 152.93it/s]Running 10000 simulations.:  71%|███████   | 7060/10000 [00:46<00:19, 153.54it/s]Running 10000 simulations.:  71%|███████   | 7076/10000 [00:47<00:19, 153.59it/s]Running 10000 simulations.:  71%|███████   | 7092/10000 [00:47<00:18, 153.77it/s]Running 10000 simulations.:  71%|███████   | 7108/10000 [00:47<00:18, 154.17it/s]Running 10000 simulations.:  71%|███████   | 7124/10000 [00:47<00:18, 154.51it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:47<00:18, 154.37it/s]Running 10000 simulations.:  72%|███████▏  | 7156/10000 [00:47<00:18, 154.35it/s]Running 10000 simulations.:  72%|███████▏  | 7172/10000 [00:47<00:18, 154.32it/s]Running 10000 simulations.:  72%|███████▏  | 7188/10000 [00:47<00:18, 154.43it/s]Running 10000 simulations.:  72%|███████▏  | 7204/10000 [00:47<00:18, 154.93it/s]Running 10000 simulations.:  72%|███████▏  | 7220/10000 [00:47<00:17, 155.25it/s]Running 10000 simulations.:  72%|███████▏  | 7236/10000 [00:48<00:17, 155.01it/s]Running 10000 simulations.:  73%|███████▎  | 7252/10000 [00:48<00:17, 154.69it/s]Running 10000 simulations.:  73%|███████▎  | 7268/10000 [00:48<00:17, 154.52it/s]Running 10000 simulations.:  73%|███████▎  | 7284/10000 [00:48<00:17, 154.30it/s]Running 10000 simulations.:  73%|███████▎  | 7300/10000 [00:48<00:17, 154.30it/s]Running 10000 simulations.:  73%|███████▎  | 7316/10000 [00:48<00:17, 154.29it/s]Running 10000 simulations.:  73%|███████▎  | 7332/10000 [00:48<00:17, 154.09it/s]Running 10000 simulations.:  73%|███████▎  | 7348/10000 [00:48<00:17, 153.89it/s]Running 10000 simulations.:  74%|███████▎  | 7364/10000 [00:48<00:17, 154.88it/s]Running 10000 simulations.:  74%|███████▍  | 7380/10000 [00:48<00:16, 154.36it/s]Running 10000 simulations.:  74%|███████▍  | 7396/10000 [00:49<00:16, 154.06it/s]Running 10000 simulations.:  74%|███████▍  | 7412/10000 [00:49<00:16, 153.67it/s]Running 10000 simulations.:  74%|███████▍  | 7428/10000 [00:49<00:16, 153.50it/s]Running 10000 simulations.:  74%|███████▍  | 7444/10000 [00:49<00:16, 153.25it/s]Running 10000 simulations.:  75%|███████▍  | 7460/10000 [00:49<00:16, 153.92it/s]Running 10000 simulations.:  75%|███████▍  | 7476/10000 [00:49<00:16, 153.67it/s]Running 10000 simulations.:  75%|███████▍  | 7492/10000 [00:49<00:16, 153.55it/s]Running 10000 simulations.:  75%|███████▌  | 7508/10000 [00:49<00:16, 153.95it/s]Running 10000 simulations.:  75%|███████▌  | 7524/10000 [00:49<00:16, 154.00it/s]Running 10000 simulations.:  75%|███████▌  | 7540/10000 [00:50<00:15, 153.75it/s]Running 10000 simulations.:  76%|███████▌  | 7556/10000 [00:50<00:15, 153.80it/s]Running 10000 simulations.:  76%|███████▌  | 7572/10000 [00:50<00:15, 152.77it/s]Running 10000 simulations.:  76%|███████▌  | 7588/10000 [00:50<00:15, 152.88it/s]Running 10000 simulations.:  76%|███████▌  | 7604/10000 [00:50<00:15, 152.77it/s]Running 10000 simulations.:  76%|███████▌  | 7620/10000 [00:50<00:15, 153.21it/s]Running 10000 simulations.:  76%|███████▋  | 7636/10000 [00:50<00:15, 152.93it/s]Running 10000 simulations.:  77%|███████▋  | 7652/10000 [00:50<00:15, 153.08it/s]Running 10000 simulations.:  77%|███████▋  | 7668/10000 [00:50<00:15, 153.15it/s]Running 10000 simulations.:  77%|███████▋  | 7684/10000 [00:50<00:15, 150.74it/s]Running 10000 simulations.:  77%|███████▋  | 7700/10000 [00:51<00:15, 151.40it/s]Running 10000 simulations.:  77%|███████▋  | 7716/10000 [00:51<00:14, 152.30it/s]Running 10000 simulations.:  77%|███████▋  | 7732/10000 [00:51<00:14, 152.40it/s]Running 10000 simulations.:  77%|███████▋  | 7748/10000 [00:51<00:14, 151.81it/s]Running 10000 simulations.:  78%|███████▊  | 7764/10000 [00:51<00:14, 151.49it/s]Running 10000 simulations.:  78%|███████▊  | 7780/10000 [00:51<00:14, 151.65it/s]Running 10000 simulations.:  78%|███████▊  | 7796/10000 [00:51<00:14, 152.76it/s]Running 10000 simulations.:  78%|███████▊  | 7812/10000 [00:51<00:14, 153.24it/s]Running 10000 simulations.:  78%|███████▊  | 7828/10000 [00:51<00:14, 152.95it/s]Running 10000 simulations.:  78%|███████▊  | 7844/10000 [00:52<00:14, 153.21it/s]Running 10000 simulations.:  79%|███████▊  | 7860/10000 [00:52<00:13, 153.83it/s]Running 10000 simulations.:  79%|███████▉  | 7876/10000 [00:52<00:13, 153.78it/s]Running 10000 simulations.:  79%|███████▉  | 7892/10000 [00:52<00:13, 153.27it/s]Running 10000 simulations.:  79%|███████▉  | 7908/10000 [00:52<00:13, 153.01it/s]Running 10000 simulations.:  79%|███████▉  | 7924/10000 [00:52<00:13, 152.91it/s]Running 10000 simulations.:  79%|███████▉  | 7940/10000 [00:52<00:13, 152.49it/s]Running 10000 simulations.:  80%|███████▉  | 7956/10000 [00:52<00:13, 152.47it/s]Running 10000 simulations.:  80%|███████▉  | 7972/10000 [00:52<00:13, 152.40it/s]Running 10000 simulations.:  80%|███████▉  | 7988/10000 [00:52<00:13, 152.26it/s]Running 10000 simulations.:  80%|████████  | 8004/10000 [00:53<00:13, 152.20it/s]Running 10000 simulations.:  80%|████████  | 8020/10000 [00:53<00:13, 152.12it/s]Running 10000 simulations.:  80%|████████  | 8036/10000 [00:53<00:12, 151.99it/s]Running 10000 simulations.:  81%|████████  | 8052/10000 [00:53<00:12, 151.77it/s]Running 10000 simulations.:  81%|████████  | 8068/10000 [00:53<00:12, 151.82it/s]Running 10000 simulations.:  81%|████████  | 8084/10000 [00:53<00:12, 151.70it/s]Running 10000 simulations.:  81%|████████  | 8100/10000 [00:53<00:12, 152.02it/s]Running 10000 simulations.:  81%|████████  | 8116/10000 [00:53<00:12, 152.01it/s]Running 10000 simulations.:  81%|████████▏ | 8132/10000 [00:53<00:12, 152.29it/s]Running 10000 simulations.:  81%|████████▏ | 8148/10000 [00:54<00:12, 152.24it/s]Running 10000 simulations.:  82%|████████▏ | 8164/10000 [00:54<00:12, 152.22it/s]Running 10000 simulations.:  82%|████████▏ | 8180/10000 [00:54<00:11, 152.30it/s]Running 10000 simulations.:  82%|████████▏ | 8196/10000 [00:54<00:11, 152.12it/s]Running 10000 simulations.:  82%|████████▏ | 8212/10000 [00:54<00:11, 152.23it/s]Running 10000 simulations.:  82%|████████▏ | 8228/10000 [00:54<00:11, 152.54it/s]Running 10000 simulations.:  82%|████████▏ | 8244/10000 [00:54<00:11, 152.72it/s]Running 10000 simulations.:  83%|████████▎ | 8260/10000 [00:54<00:11, 152.36it/s]Running 10000 simulations.:  83%|████████▎ | 8276/10000 [00:54<00:11, 152.33it/s]Running 10000 simulations.:  83%|████████▎ | 8292/10000 [00:54<00:11, 152.60it/s]Running 10000 simulations.:  83%|████████▎ | 8308/10000 [00:55<00:11, 152.76it/s]Running 10000 simulations.:  83%|████████▎ | 8324/10000 [00:55<00:10, 153.01it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:55<00:10, 153.18it/s]Running 10000 simulations.:  84%|████████▎ | 8356/10000 [00:55<00:10, 152.53it/s]Running 10000 simulations.:  84%|████████▎ | 8372/10000 [00:55<00:10, 152.36it/s]Running 10000 simulations.:  84%|████████▍ | 8388/10000 [00:55<00:10, 151.97it/s]Running 10000 simulations.:  84%|████████▍ | 8404/10000 [00:55<00:10, 151.88it/s]Running 10000 simulations.:  84%|████████▍ | 8420/10000 [00:55<00:10, 151.70it/s]Running 10000 simulations.:  84%|████████▍ | 8436/10000 [00:55<00:10, 151.61it/s]Running 10000 simulations.:  85%|████████▍ | 8452/10000 [00:56<00:10, 151.53it/s]Running 10000 simulations.:  85%|████████▍ | 8468/10000 [00:56<00:10, 151.70it/s]Running 10000 simulations.:  85%|████████▍ | 8484/10000 [00:56<00:10, 151.56it/s]Running 10000 simulations.:  85%|████████▌ | 8500/10000 [00:56<00:09, 151.64it/s]Running 10000 simulations.:  85%|████████▌ | 8516/10000 [00:56<00:09, 150.94it/s]Running 10000 simulations.:  85%|████████▌ | 8532/10000 [00:56<00:09, 151.01it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:56<00:09, 150.99it/s]Running 10000 simulations.:  86%|████████▌ | 8564/10000 [00:56<00:09, 150.76it/s]Running 10000 simulations.:  86%|████████▌ | 8580/10000 [00:56<00:09, 150.60it/s]Running 10000 simulations.:  86%|████████▌ | 8596/10000 [00:56<00:09, 150.74it/s]Running 10000 simulations.:  86%|████████▌ | 8612/10000 [00:57<00:09, 150.81it/s]Running 10000 simulations.:  86%|████████▋ | 8628/10000 [00:57<00:09, 150.94it/s]Running 10000 simulations.:  86%|████████▋ | 8644/10000 [00:57<00:08, 151.07it/s]Running 10000 simulations.:  87%|████████▋ | 8660/10000 [00:57<00:08, 151.74it/s]Running 10000 simulations.:  87%|████████▋ | 8676/10000 [00:57<00:08, 152.04it/s]Running 10000 simulations.:  87%|████████▋ | 8692/10000 [00:57<00:08, 151.27it/s]Running 10000 simulations.:  87%|████████▋ | 8708/10000 [00:57<00:08, 151.07it/s]Running 10000 simulations.:  87%|████████▋ | 8724/10000 [00:57<00:08, 151.08it/s]Running 10000 simulations.:  87%|████████▋ | 8740/10000 [00:57<00:08, 152.34it/s]Running 10000 simulations.:  88%|████████▊ | 8756/10000 [00:58<00:08, 151.41it/s]Running 10000 simulations.:  88%|████████▊ | 8772/10000 [00:58<00:08, 150.81it/s]Running 10000 simulations.:  88%|████████▊ | 8788/10000 [00:58<00:08, 149.43it/s]Running 10000 simulations.:  88%|████████▊ | 8803/10000 [00:58<00:08, 149.07it/s]Running 10000 simulations.:  88%|████████▊ | 8818/10000 [00:58<00:07, 148.67it/s]Running 10000 simulations.:  88%|████████▊ | 8833/10000 [00:58<00:07, 148.69it/s]Running 10000 simulations.:  88%|████████▊ | 8848/10000 [00:58<00:07, 148.81it/s]Running 10000 simulations.:  89%|████████▊ | 8863/10000 [00:58<00:07, 148.90it/s]Running 10000 simulations.:  89%|████████▉ | 8878/10000 [00:58<00:07, 148.58it/s]Running 10000 simulations.:  89%|████████▉ | 8893/10000 [00:58<00:07, 148.66it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:59<00:07, 148.99it/s]Running 10000 simulations.:  89%|████████▉ | 8923/10000 [00:59<00:07, 149.21it/s]Running 10000 simulations.:  89%|████████▉ | 8938/10000 [00:59<00:07, 149.19it/s]Running 10000 simulations.:  90%|████████▉ | 8953/10000 [00:59<00:07, 147.79it/s]Running 10000 simulations.:  90%|████████▉ | 8968/10000 [00:59<00:06, 147.60it/s]Running 10000 simulations.:  90%|████████▉ | 8984/10000 [00:59<00:06, 148.65it/s]Running 10000 simulations.:  90%|█████████ | 9000/10000 [00:59<00:06, 149.32it/s]Running 10000 simulations.:  90%|█████████ | 9015/10000 [00:59<00:06, 149.06it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:59<00:06, 148.76it/s]Running 10000 simulations.:  90%|█████████ | 9045/10000 [00:59<00:06, 147.66it/s]Running 10000 simulations.:  91%|█████████ | 9060/10000 [01:00<00:06, 148.10it/s]Running 10000 simulations.:  91%|█████████ | 9075/10000 [01:00<00:06, 148.46it/s]Running 10000 simulations.:  91%|█████████ | 9090/10000 [01:00<00:06, 148.71it/s]Running 10000 simulations.:  91%|█████████ | 9105/10000 [01:00<00:06, 148.88it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [01:00<00:05, 148.83it/s]Running 10000 simulations.:  91%|█████████▏| 9135/10000 [01:00<00:05, 149.07it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [01:00<00:05, 149.33it/s]Running 10000 simulations.:  92%|█████████▏| 9165/10000 [01:00<00:05, 149.19it/s]Running 10000 simulations.:  92%|█████████▏| 9180/10000 [01:00<00:05, 148.93it/s]Running 10000 simulations.:  92%|█████████▏| 9195/10000 [01:00<00:05, 148.61it/s]Running 10000 simulations.:  92%|█████████▏| 9211/10000 [01:01<00:05, 151.77it/s]Running 10000 simulations.:  92%|█████████▏| 9228/10000 [01:01<00:04, 154.54it/s]Running 10000 simulations.:  92%|█████████▏| 9244/10000 [01:01<00:04, 155.61it/s]Running 10000 simulations.:  93%|█████████▎| 9260/10000 [01:01<00:04, 153.16it/s]Running 10000 simulations.:  93%|█████████▎| 9276/10000 [01:01<00:04, 151.68it/s]Running 10000 simulations.:  93%|█████████▎| 9292/10000 [01:01<00:04, 150.76it/s]Running 10000 simulations.:  93%|█████████▎| 9308/10000 [01:01<00:04, 149.60it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [01:01<00:04, 149.06it/s]Running 10000 simulations.:  93%|█████████▎| 9338/10000 [01:01<00:04, 149.33it/s]Running 10000 simulations.:  94%|█████████▎| 9353/10000 [01:02<00:04, 149.48it/s]Running 10000 simulations.:  94%|█████████▎| 9368/10000 [01:02<00:04, 149.62it/s]Running 10000 simulations.:  94%|█████████▍| 9384/10000 [01:02<00:04, 150.46it/s]Running 10000 simulations.:  94%|█████████▍| 9400/10000 [01:02<00:03, 150.52it/s]Running 10000 simulations.:  94%|█████████▍| 9416/10000 [01:02<00:03, 150.40it/s]Running 10000 simulations.:  94%|█████████▍| 9432/10000 [01:02<00:03, 150.46it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [01:02<00:03, 150.23it/s]Running 10000 simulations.:  95%|█████████▍| 9464/10000 [01:02<00:03, 149.91it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [01:02<00:03, 149.67it/s]Running 10000 simulations.:  95%|█████████▍| 9495/10000 [01:02<00:03, 150.00it/s]Running 10000 simulations.:  95%|█████████▌| 9511/10000 [01:03<00:03, 150.41it/s]Running 10000 simulations.:  95%|█████████▌| 9527/10000 [01:03<00:03, 150.46it/s]Running 10000 simulations.:  95%|█████████▌| 9543/10000 [01:03<00:03, 150.42it/s]Running 10000 simulations.:  96%|█████████▌| 9559/10000 [01:03<00:02, 150.02it/s]Running 10000 simulations.:  96%|█████████▌| 9575/10000 [01:03<00:02, 149.98it/s]Running 10000 simulations.:  96%|█████████▌| 9591/10000 [01:03<00:02, 150.10it/s]Running 10000 simulations.:  96%|█████████▌| 9607/10000 [01:03<00:02, 150.10it/s]Running 10000 simulations.:  96%|█████████▌| 9623/10000 [01:03<00:02, 150.24it/s]Running 10000 simulations.:  96%|█████████▋| 9639/10000 [01:03<00:02, 149.21it/s]Running 10000 simulations.:  97%|█████████▋| 9654/10000 [01:04<00:02, 149.07it/s]Running 10000 simulations.:  97%|█████████▋| 9670/10000 [01:04<00:02, 149.44it/s]Running 10000 simulations.:  97%|█████████▋| 9685/10000 [01:04<00:02, 149.60it/s]Running 10000 simulations.:  97%|█████████▋| 9701/10000 [01:04<00:01, 149.77it/s]Running 10000 simulations.:  97%|█████████▋| 9717/10000 [01:04<00:01, 149.89it/s]Running 10000 simulations.:  97%|█████████▋| 9732/10000 [01:04<00:01, 149.83it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [01:04<00:01, 149.89it/s]Running 10000 simulations.:  98%|█████████▊| 9764/10000 [01:04<00:01, 150.00it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [01:04<00:01, 150.01it/s]Running 10000 simulations.:  98%|█████████▊| 9796/10000 [01:04<00:01, 149.97it/s]Running 10000 simulations.:  98%|█████████▊| 9812/10000 [01:05<00:01, 150.22it/s]Running 10000 simulations.:  98%|█████████▊| 9828/10000 [01:05<00:01, 150.14it/s]Running 10000 simulations.:  98%|█████████▊| 9844/10000 [01:05<00:01, 149.96it/s]Running 10000 simulations.:  99%|█████████▊| 9860/10000 [01:05<00:00, 150.07it/s]Running 10000 simulations.:  99%|█████████▉| 9876/10000 [01:05<00:00, 150.01it/s]Running 10000 simulations.:  99%|█████████▉| 9892/10000 [01:05<00:00, 150.04it/s]Running 10000 simulations.:  99%|█████████▉| 9908/10000 [01:05<00:00, 149.96it/s]Running 10000 simulations.:  99%|█████████▉| 9924/10000 [01:05<00:00, 150.04it/s]Running 10000 simulations.:  99%|█████████▉| 9940/10000 [01:05<00:00, 150.56it/s]Running 10000 simulations.: 100%|█████████▉| 9956/10000 [01:06<00:00, 150.60it/s]Running 10000 simulations.: 100%|█████████▉| 9972/10000 [01:06<00:00, 150.23it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [01:06<00:00, 146.15it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:06<00:00, 150.75it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 16/10000 [00:00<01:04, 155.71it/s]Running 10000 simulations.:   0%|          | 32/10000 [00:00<01:03, 156.07it/s]Running 10000 simulations.:   0%|          | 48/10000 [00:00<01:03, 156.11it/s]Running 10000 simulations.:   1%|          | 64/10000 [00:00<01:03, 156.37it/s]Running 10000 simulations.:   1%|          | 80/10000 [00:00<01:03, 156.72it/s]Running 10000 simulations.:   1%|          | 96/10000 [00:00<01:03, 155.97it/s]Running 10000 simulations.:   1%|          | 112/10000 [00:00<01:03, 156.04it/s]Running 10000 simulations.:   1%|▏         | 128/10000 [00:00<01:03, 156.02it/s]Running 10000 simulations.:   1%|▏         | 144/10000 [00:00<01:03, 156.24it/s]Running 10000 simulations.:   2%|▏         | 160/10000 [00:01<01:03, 155.89it/s]Running 10000 simulations.:   2%|▏         | 176/10000 [00:01<01:03, 155.33it/s]Running 10000 simulations.:   2%|▏         | 192/10000 [00:01<01:03, 155.65it/s]Running 10000 simulations.:   2%|▏         | 208/10000 [00:01<01:02, 156.11it/s]Running 10000 simulations.:   2%|▏         | 224/10000 [00:01<01:02, 155.57it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:01<01:02, 155.64it/s]Running 10000 simulations.:   3%|▎         | 256/10000 [00:01<01:02, 155.44it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<01:02, 154.84it/s]Running 10000 simulations.:   3%|▎         | 288/10000 [00:01<01:02, 154.27it/s]Running 10000 simulations.:   3%|▎         | 304/10000 [00:01<01:03, 153.20it/s]Running 10000 simulations.:   3%|▎         | 320/10000 [00:02<01:02, 154.19it/s]Running 10000 simulations.:   3%|▎         | 336/10000 [00:02<01:02, 155.04it/s]Running 10000 simulations.:   4%|▎         | 352/10000 [00:02<01:02, 154.72it/s]Running 10000 simulations.:   4%|▎         | 368/10000 [00:02<01:02, 154.14it/s]Running 10000 simulations.:   4%|▍         | 384/10000 [00:02<01:02, 153.85it/s]Running 10000 simulations.:   4%|▍         | 400/10000 [00:02<01:02, 153.95it/s]Running 10000 simulations.:   4%|▍         | 416/10000 [00:02<01:02, 154.51it/s]Running 10000 simulations.:   4%|▍         | 432/10000 [00:02<01:01, 154.35it/s]Running 10000 simulations.:   4%|▍         | 448/10000 [00:02<01:01, 154.50it/s]Running 10000 simulations.:   5%|▍         | 464/10000 [00:02<01:01, 154.10it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:03<01:01, 154.58it/s]Running 10000 simulations.:   5%|▍         | 496/10000 [00:03<01:01, 154.93it/s]Running 10000 simulations.:   5%|▌         | 512/10000 [00:03<01:01, 155.13it/s]Running 10000 simulations.:   5%|▌         | 528/10000 [00:03<01:01, 155.14it/s]Running 10000 simulations.:   5%|▌         | 544/10000 [00:03<01:01, 154.65it/s]Running 10000 simulations.:   6%|▌         | 560/10000 [00:03<01:01, 154.67it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:03<01:00, 154.88it/s]Running 10000 simulations.:   6%|▌         | 592/10000 [00:03<01:00, 155.20it/s]Running 10000 simulations.:   6%|▌         | 608/10000 [00:03<01:00, 154.95it/s]Running 10000 simulations.:   6%|▌         | 624/10000 [00:04<01:00, 154.93it/s]Running 10000 simulations.:   6%|▋         | 640/10000 [00:04<01:01, 153.29it/s]Running 10000 simulations.:   7%|▋         | 656/10000 [00:04<01:00, 153.59it/s]Running 10000 simulations.:   7%|▋         | 672/10000 [00:04<01:00, 153.91it/s]Running 10000 simulations.:   7%|▋         | 688/10000 [00:04<01:00, 154.35it/s]Running 10000 simulations.:   7%|▋         | 704/10000 [00:04<01:00, 153.69it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:04<01:00, 152.98it/s]Running 10000 simulations.:   7%|▋         | 736/10000 [00:04<01:00, 153.01it/s]Running 10000 simulations.:   8%|▊         | 752/10000 [00:04<01:00, 153.28it/s]Running 10000 simulations.:   8%|▊         | 768/10000 [00:04<01:00, 152.63it/s]Running 10000 simulations.:   8%|▊         | 784/10000 [00:05<01:00, 152.23it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:05<01:00, 151.85it/s]Running 10000 simulations.:   8%|▊         | 816/10000 [00:05<01:00, 151.66it/s]Running 10000 simulations.:   8%|▊         | 832/10000 [00:05<01:00, 152.38it/s]Running 10000 simulations.:   8%|▊         | 848/10000 [00:05<00:59, 153.01it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:05<00:59, 153.47it/s]Running 10000 simulations.:   9%|▉         | 880/10000 [00:05<00:59, 153.04it/s]Running 10000 simulations.:   9%|▉         | 896/10000 [00:05<00:59, 152.63it/s]Running 10000 simulations.:   9%|▉         | 912/10000 [00:05<00:59, 152.84it/s]Running 10000 simulations.:   9%|▉         | 928/10000 [00:06<00:59, 152.73it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:06<00:59, 152.45it/s]Running 10000 simulations.:  10%|▉         | 960/10000 [00:06<00:59, 152.64it/s]Running 10000 simulations.:  10%|▉         | 976/10000 [00:06<00:59, 152.19it/s]Running 10000 simulations.:  10%|▉         | 992/10000 [00:06<01:02, 144.16it/s]Running 10000 simulations.:  10%|█         | 1008/10000 [00:06<01:01, 146.64it/s]Running 10000 simulations.:  10%|█         | 1024/10000 [00:06<01:00, 148.65it/s]Running 10000 simulations.:  10%|█         | 1040/10000 [00:06<00:59, 150.40it/s]Running 10000 simulations.:  11%|█         | 1056/10000 [00:06<00:59, 151.07it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:06<00:58, 152.09it/s]Running 10000 simulations.:  11%|█         | 1088/10000 [00:07<00:58, 152.80it/s]Running 10000 simulations.:  11%|█         | 1104/10000 [00:07<00:58, 153.15it/s]Running 10000 simulations.:  11%|█         | 1120/10000 [00:07<00:57, 153.34it/s]Running 10000 simulations.:  11%|█▏        | 1136/10000 [00:07<00:58, 152.72it/s]Running 10000 simulations.:  12%|█▏        | 1152/10000 [00:07<00:58, 152.50it/s]Running 10000 simulations.:  12%|█▏        | 1168/10000 [00:07<00:57, 152.97it/s]Running 10000 simulations.:  12%|█▏        | 1184/10000 [00:07<00:57, 153.41it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:07<00:57, 153.67it/s]Running 10000 simulations.:  12%|█▏        | 1216/10000 [00:07<00:57, 153.01it/s]Running 10000 simulations.:  12%|█▏        | 1232/10000 [00:08<00:57, 153.06it/s]Running 10000 simulations.:  12%|█▏        | 1248/10000 [00:08<00:57, 153.13it/s]Running 10000 simulations.:  13%|█▎        | 1264/10000 [00:08<00:58, 149.27it/s]Running 10000 simulations.:  13%|█▎        | 1280/10000 [00:08<00:58, 150.08it/s]Running 10000 simulations.:  13%|█▎        | 1296/10000 [00:08<00:57, 151.49it/s]Running 10000 simulations.:  13%|█▎        | 1312/10000 [00:08<00:56, 152.54it/s]Running 10000 simulations.:  13%|█▎        | 1328/10000 [00:08<00:56, 153.22it/s]Running 10000 simulations.:  13%|█▎        | 1344/10000 [00:08<00:56, 153.68it/s]Running 10000 simulations.:  14%|█▎        | 1360/10000 [00:08<00:56, 154.03it/s]Running 10000 simulations.:  14%|█▍        | 1376/10000 [00:08<00:55, 154.08it/s]Running 10000 simulations.:  14%|█▍        | 1392/10000 [00:09<00:55, 154.10it/s]Running 10000 simulations.:  14%|█▍        | 1408/10000 [00:09<00:56, 152.97it/s]Running 10000 simulations.:  14%|█▍        | 1424/10000 [00:09<00:56, 152.61it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:09<00:55, 154.04it/s]Running 10000 simulations.:  15%|█▍        | 1457/10000 [00:09<00:53, 158.39it/s]Running 10000 simulations.:  15%|█▍        | 1475/10000 [00:09<00:52, 162.14it/s]Running 10000 simulations.:  15%|█▍        | 1492/10000 [00:09<00:53, 159.84it/s]Running 10000 simulations.:  15%|█▌        | 1509/10000 [00:09<00:53, 158.18it/s]Running 10000 simulations.:  15%|█▌        | 1525/10000 [00:09<00:54, 155.86it/s]Running 10000 simulations.:  15%|█▌        | 1541/10000 [00:10<00:54, 154.52it/s]Running 10000 simulations.:  16%|█▌        | 1557/10000 [00:10<00:54, 153.59it/s]Running 10000 simulations.:  16%|█▌        | 1573/10000 [00:10<00:55, 152.86it/s]Running 10000 simulations.:  16%|█▌        | 1589/10000 [00:10<00:55, 152.25it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:10<00:55, 152.01it/s]Running 10000 simulations.:  16%|█▌        | 1621/10000 [00:10<00:55, 152.01it/s]Running 10000 simulations.:  16%|█▋        | 1637/10000 [00:10<00:54, 152.42it/s]Running 10000 simulations.:  17%|█▋        | 1653/10000 [00:10<00:54, 152.82it/s]Running 10000 simulations.:  17%|█▋        | 1669/10000 [00:10<00:54, 153.16it/s]Running 10000 simulations.:  17%|█▋        | 1685/10000 [00:10<00:54, 153.00it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:11<00:54, 152.67it/s]Running 10000 simulations.:  17%|█▋        | 1717/10000 [00:11<00:54, 152.86it/s]Running 10000 simulations.:  17%|█▋        | 1733/10000 [00:11<00:54, 152.77it/s]Running 10000 simulations.:  17%|█▋        | 1749/10000 [00:11<00:53, 152.94it/s]Running 10000 simulations.:  18%|█▊        | 1765/10000 [00:11<00:53, 153.14it/s]Running 10000 simulations.:  18%|█▊        | 1781/10000 [00:11<00:53, 153.33it/s]Running 10000 simulations.:  18%|█▊        | 1797/10000 [00:11<00:53, 153.32it/s]Running 10000 simulations.:  18%|█▊        | 1813/10000 [00:11<00:53, 152.70it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:11<00:54, 150.95it/s]Running 10000 simulations.:  18%|█▊        | 1845/10000 [00:12<00:54, 150.92it/s]Running 10000 simulations.:  19%|█▊        | 1861/10000 [00:12<00:53, 150.93it/s]Running 10000 simulations.:  19%|█▉        | 1877/10000 [00:12<00:53, 151.03it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:12<00:53, 150.99it/s]Running 10000 simulations.:  19%|█▉        | 1909/10000 [00:12<00:54, 149.58it/s]Running 10000 simulations.:  19%|█▉        | 1924/10000 [00:12<00:53, 149.61it/s]Running 10000 simulations.:  19%|█▉        | 1940/10000 [00:12<00:53, 150.34it/s]Running 10000 simulations.:  20%|█▉        | 1956/10000 [00:12<00:53, 151.23it/s]Running 10000 simulations.:  20%|█▉        | 1972/10000 [00:12<00:53, 151.31it/s]Running 10000 simulations.:  20%|█▉        | 1988/10000 [00:12<00:52, 151.34it/s]Running 10000 simulations.:  20%|██        | 2004/10000 [00:13<00:52, 151.48it/s]Running 10000 simulations.:  20%|██        | 2020/10000 [00:13<00:52, 151.79it/s]Running 10000 simulations.:  20%|██        | 2036/10000 [00:13<00:52, 151.44it/s]Running 10000 simulations.:  21%|██        | 2052/10000 [00:13<00:52, 151.50it/s]Running 10000 simulations.:  21%|██        | 2068/10000 [00:13<00:52, 151.32it/s]Running 10000 simulations.:  21%|██        | 2084/10000 [00:13<00:52, 150.98it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:13<00:52, 151.61it/s]Running 10000 simulations.:  21%|██        | 2116/10000 [00:13<00:51, 152.51it/s]Running 10000 simulations.:  21%|██▏       | 2132/10000 [00:13<00:51, 151.78it/s]Running 10000 simulations.:  21%|██▏       | 2148/10000 [00:14<00:51, 151.31it/s]Running 10000 simulations.:  22%|██▏       | 2164/10000 [00:14<00:51, 151.57it/s]Running 10000 simulations.:  22%|██▏       | 2180/10000 [00:14<00:51, 151.92it/s]Running 10000 simulations.:  22%|██▏       | 2196/10000 [00:14<00:51, 152.00it/s]Running 10000 simulations.:  22%|██▏       | 2212/10000 [00:14<00:51, 151.72it/s]Running 10000 simulations.:  22%|██▏       | 2228/10000 [00:14<00:51, 152.27it/s]Running 10000 simulations.:  22%|██▏       | 2244/10000 [00:14<00:50, 152.76it/s]Running 10000 simulations.:  23%|██▎       | 2260/10000 [00:14<00:50, 152.35it/s]Running 10000 simulations.:  23%|██▎       | 2276/10000 [00:14<00:50, 151.98it/s]Running 10000 simulations.:  23%|██▎       | 2292/10000 [00:14<00:50, 151.93it/s]Running 10000 simulations.:  23%|██▎       | 2308/10000 [00:15<00:50, 152.12it/s]Running 10000 simulations.:  23%|██▎       | 2324/10000 [00:15<00:50, 152.15it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:15<00:50, 152.28it/s]Running 10000 simulations.:  24%|██▎       | 2356/10000 [00:15<00:50, 150.82it/s]Running 10000 simulations.:  24%|██▎       | 2372/10000 [00:15<00:50, 149.58it/s]Running 10000 simulations.:  24%|██▍       | 2388/10000 [00:15<00:50, 149.88it/s]Running 10000 simulations.:  24%|██▍       | 2403/10000 [00:15<00:50, 149.76it/s]Running 10000 simulations.:  24%|██▍       | 2418/10000 [00:15<00:50, 149.72it/s]Running 10000 simulations.:  24%|██▍       | 2434/10000 [00:15<00:50, 150.06it/s]Running 10000 simulations.:  24%|██▍       | 2450/10000 [00:16<00:50, 150.36it/s]Running 10000 simulations.:  25%|██▍       | 2466/10000 [00:16<00:50, 150.18it/s]Running 10000 simulations.:  25%|██▍       | 2482/10000 [00:16<00:50, 150.08it/s]Running 10000 simulations.:  25%|██▍       | 2498/10000 [00:16<00:50, 150.01it/s]Running 10000 simulations.:  25%|██▌       | 2514/10000 [00:16<00:49, 149.80it/s]Running 10000 simulations.:  25%|██▌       | 2529/10000 [00:16<00:49, 149.55it/s]Running 10000 simulations.:  25%|██▌       | 2544/10000 [00:16<00:49, 149.41it/s]Running 10000 simulations.:  26%|██▌       | 2559/10000 [00:16<00:49, 149.43it/s]Running 10000 simulations.:  26%|██▌       | 2574/10000 [00:16<00:49, 149.40it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:16<00:49, 149.79it/s]Running 10000 simulations.:  26%|██▌       | 2606/10000 [00:17<00:49, 149.90it/s]Running 10000 simulations.:  26%|██▌       | 2622/10000 [00:17<00:48, 150.67it/s]Running 10000 simulations.:  26%|██▋       | 2638/10000 [00:17<00:48, 150.77it/s]Running 10000 simulations.:  27%|██▋       | 2654/10000 [00:17<00:48, 150.26it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:17<00:49, 149.17it/s]Running 10000 simulations.:  27%|██▋       | 2685/10000 [00:17<00:48, 149.33it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:17<00:48, 149.08it/s]Running 10000 simulations.:  27%|██▋       | 2715/10000 [00:17<00:48, 148.84it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:17<00:48, 148.72it/s]Running 10000 simulations.:  27%|██▋       | 2746/10000 [00:17<00:48, 149.25it/s]Running 10000 simulations.:  28%|██▊       | 2762/10000 [00:18<00:48, 149.64it/s]Running 10000 simulations.:  28%|██▊       | 2778/10000 [00:18<00:48, 150.13it/s]Running 10000 simulations.:  28%|██▊       | 2794/10000 [00:18<00:47, 150.48it/s]Running 10000 simulations.:  28%|██▊       | 2810/10000 [00:18<00:47, 150.42it/s]Running 10000 simulations.:  28%|██▊       | 2826/10000 [00:18<00:47, 150.16it/s]Running 10000 simulations.:  28%|██▊       | 2842/10000 [00:18<00:47, 149.50it/s]Running 10000 simulations.:  29%|██▊       | 2857/10000 [00:18<00:47, 148.96it/s]Running 10000 simulations.:  29%|██▊       | 2872/10000 [00:18<00:47, 148.67it/s]Running 10000 simulations.:  29%|██▉       | 2887/10000 [00:18<00:47, 148.94it/s]Running 10000 simulations.:  29%|██▉       | 2902/10000 [00:19<00:47, 149.04it/s]Running 10000 simulations.:  29%|██▉       | 2917/10000 [00:19<00:47, 149.31it/s]Running 10000 simulations.:  29%|██▉       | 2933/10000 [00:19<00:47, 149.62it/s]Running 10000 simulations.:  29%|██▉       | 2948/10000 [00:19<00:47, 149.36it/s]Running 10000 simulations.:  30%|██▉       | 2963/10000 [00:19<00:47, 149.10it/s]Running 10000 simulations.:  30%|██▉       | 2978/10000 [00:19<00:47, 149.30it/s]Running 10000 simulations.:  30%|██▉       | 2994/10000 [00:19<00:46, 149.71it/s]Running 10000 simulations.:  30%|███       | 3010/10000 [00:19<00:46, 149.95it/s]Running 10000 simulations.:  30%|███       | 3026/10000 [00:19<00:46, 150.46it/s]Running 10000 simulations.:  30%|███       | 3042/10000 [00:19<00:46, 149.92it/s]Running 10000 simulations.:  31%|███       | 3057/10000 [00:20<00:46, 148.75it/s]Running 10000 simulations.:  31%|███       | 3072/10000 [00:20<00:46, 148.91it/s]Running 10000 simulations.:  31%|███       | 3087/10000 [00:20<00:46, 148.71it/s]Running 10000 simulations.:  31%|███       | 3102/10000 [00:20<00:46, 148.93it/s]Running 10000 simulations.:  31%|███       | 3117/10000 [00:20<00:46, 149.08it/s]Running 10000 simulations.:  31%|███▏      | 3132/10000 [00:20<00:46, 148.92it/s]Running 10000 simulations.:  31%|███▏      | 3147/10000 [00:20<00:46, 148.98it/s]Running 10000 simulations.:  32%|███▏      | 3163/10000 [00:20<00:45, 149.44it/s]Running 10000 simulations.:  32%|███▏      | 3178/10000 [00:20<00:45, 149.20it/s]Running 10000 simulations.:  32%|███▏      | 3193/10000 [00:20<00:45, 149.18it/s]Running 10000 simulations.:  32%|███▏      | 3209/10000 [00:21<00:45, 149.44it/s]Running 10000 simulations.:  32%|███▏      | 3224/10000 [00:21<00:45, 149.33it/s]Running 10000 simulations.:  32%|███▏      | 3239/10000 [00:21<00:45, 149.18it/s]Running 10000 simulations.:  33%|███▎      | 3254/10000 [00:21<00:45, 149.17it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:21<00:45, 149.53it/s]Running 10000 simulations.:  33%|███▎      | 3286/10000 [00:21<00:44, 150.02it/s]Running 10000 simulations.:  33%|███▎      | 3302/10000 [00:21<00:44, 149.93it/s]Running 10000 simulations.:  33%|███▎      | 3317/10000 [00:21<00:44, 149.81it/s]Running 10000 simulations.:  33%|███▎      | 3332/10000 [00:21<00:44, 148.41it/s]Running 10000 simulations.:  33%|███▎      | 3347/10000 [00:22<00:44, 148.35it/s]Running 10000 simulations.:  34%|███▎      | 3362/10000 [00:22<00:44, 148.46it/s]Running 10000 simulations.:  34%|███▍      | 3378/10000 [00:22<00:44, 149.20it/s]Running 10000 simulations.:  34%|███▍      | 3394/10000 [00:22<00:44, 149.65it/s]Running 10000 simulations.:  34%|███▍      | 3410/10000 [00:22<00:43, 150.10it/s]Running 10000 simulations.:  34%|███▍      | 3426/10000 [00:22<00:43, 149.99it/s]Running 10000 simulations.:  34%|███▍      | 3442/10000 [00:22<00:43, 150.31it/s]Running 10000 simulations.:  35%|███▍      | 3458/10000 [00:22<00:43, 150.21it/s]Running 10000 simulations.:  35%|███▍      | 3474/10000 [00:22<00:43, 150.29it/s]Running 10000 simulations.:  35%|███▍      | 3490/10000 [00:22<00:43, 150.62it/s]Running 10000 simulations.:  35%|███▌      | 3506/10000 [00:23<00:43, 150.43it/s]Running 10000 simulations.:  35%|███▌      | 3522/10000 [00:23<00:43, 149.81it/s]Running 10000 simulations.:  35%|███▌      | 3537/10000 [00:23<00:43, 149.48it/s]Running 10000 simulations.:  36%|███▌      | 3553/10000 [00:23<00:43, 149.89it/s]Running 10000 simulations.:  36%|███▌      | 3568/10000 [00:23<00:43, 149.43it/s]Running 10000 simulations.:  36%|███▌      | 3584/10000 [00:23<00:42, 149.84it/s]Running 10000 simulations.:  36%|███▌      | 3599/10000 [00:23<00:42, 149.58it/s]Running 10000 simulations.:  36%|███▌      | 3614/10000 [00:23<00:42, 149.58it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:23<00:42, 149.80it/s]Running 10000 simulations.:  36%|███▋      | 3646/10000 [00:24<00:42, 150.03it/s]Running 10000 simulations.:  37%|███▋      | 3662/10000 [00:24<00:42, 150.01it/s]Running 10000 simulations.:  37%|███▋      | 3678/10000 [00:24<00:42, 150.01it/s]Running 10000 simulations.:  37%|███▋      | 3694/10000 [00:24<00:42, 149.80it/s]Running 10000 simulations.:  37%|███▋      | 3709/10000 [00:24<00:42, 149.69it/s]Running 10000 simulations.:  37%|███▋      | 3725/10000 [00:24<00:41, 149.97it/s]Running 10000 simulations.:  37%|███▋      | 3740/10000 [00:24<00:41, 149.63it/s]Running 10000 simulations.:  38%|███▊      | 3756/10000 [00:24<00:41, 150.17it/s]Running 10000 simulations.:  38%|███▊      | 3772/10000 [00:24<00:41, 150.38it/s]Running 10000 simulations.:  38%|███▊      | 3788/10000 [00:24<00:41, 150.15it/s]Running 10000 simulations.:  38%|███▊      | 3804/10000 [00:25<00:41, 149.64it/s]Running 10000 simulations.:  38%|███▊      | 3819/10000 [00:25<00:41, 149.63it/s]Running 10000 simulations.:  38%|███▊      | 3834/10000 [00:25<00:41, 149.52it/s]Running 10000 simulations.:  38%|███▊      | 3849/10000 [00:25<00:41, 149.08it/s]Running 10000 simulations.:  39%|███▊      | 3864/10000 [00:25<00:41, 148.91it/s]Running 10000 simulations.:  39%|███▉      | 3879/10000 [00:25<00:41, 149.01it/s]Running 10000 simulations.:  39%|███▉      | 3896/10000 [00:25<00:39, 152.63it/s]Running 10000 simulations.:  39%|███▉      | 3913/10000 [00:25<00:39, 155.98it/s]Running 10000 simulations.:  39%|███▉      | 3929/10000 [00:25<00:39, 155.61it/s]Running 10000 simulations.:  39%|███▉      | 3945/10000 [00:25<00:39, 154.37it/s]Running 10000 simulations.:  40%|███▉      | 3961/10000 [00:26<00:39, 153.60it/s]Running 10000 simulations.:  40%|███▉      | 3977/10000 [00:26<00:39, 152.86it/s]Running 10000 simulations.:  40%|███▉      | 3993/10000 [00:26<00:39, 151.51it/s]Running 10000 simulations.:  40%|████      | 4009/10000 [00:26<00:39, 150.69it/s]Running 10000 simulations.:  40%|████      | 4025/10000 [00:26<00:39, 150.66it/s]Running 10000 simulations.:  40%|████      | 4041/10000 [00:26<00:39, 150.72it/s]Running 10000 simulations.:  41%|████      | 4057/10000 [00:26<00:39, 150.60it/s]Running 10000 simulations.:  41%|████      | 4073/10000 [00:26<00:39, 150.30it/s]Running 10000 simulations.:  41%|████      | 4089/10000 [00:26<00:39, 150.19it/s]Running 10000 simulations.:  41%|████      | 4105/10000 [00:27<00:39, 150.10it/s]Running 10000 simulations.:  41%|████      | 4121/10000 [00:27<00:39, 149.79it/s]Running 10000 simulations.:  41%|████▏     | 4137/10000 [00:27<00:39, 150.01it/s]Running 10000 simulations.:  42%|████▏     | 4153/10000 [00:27<00:39, 149.80it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:27<00:38, 149.63it/s]Running 10000 simulations.:  42%|████▏     | 4183/10000 [00:27<00:38, 149.37it/s]Running 10000 simulations.:  42%|████▏     | 4198/10000 [00:27<00:38, 148.93it/s]Running 10000 simulations.:  42%|████▏     | 4214/10000 [00:27<00:38, 149.36it/s]Running 10000 simulations.:  42%|████▏     | 4229/10000 [00:27<00:38, 149.40it/s]Running 10000 simulations.:  42%|████▏     | 4244/10000 [00:27<00:38, 148.81it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:28<00:38, 148.84it/s]Running 10000 simulations.:  43%|████▎     | 4274/10000 [00:28<00:38, 148.70it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:28<00:38, 149.21it/s]Running 10000 simulations.:  43%|████▎     | 4306/10000 [00:28<00:38, 149.68it/s]Running 10000 simulations.:  43%|████▎     | 4321/10000 [00:28<00:37, 149.63it/s]Running 10000 simulations.:  43%|████▎     | 4337/10000 [00:28<00:37, 150.07it/s]Running 10000 simulations.:  44%|████▎     | 4353/10000 [00:28<00:37, 150.64it/s]Running 10000 simulations.:  44%|████▎     | 4369/10000 [00:28<00:37, 150.23it/s]Running 10000 simulations.:  44%|████▍     | 4385/10000 [00:28<00:37, 150.43it/s]Running 10000 simulations.:  44%|████▍     | 4401/10000 [00:29<00:37, 150.66it/s]Running 10000 simulations.:  44%|████▍     | 4417/10000 [00:29<00:36, 151.06it/s]Running 10000 simulations.:  44%|████▍     | 4433/10000 [00:29<00:36, 151.37it/s]Running 10000 simulations.:  44%|████▍     | 4449/10000 [00:29<00:36, 151.23it/s]Running 10000 simulations.:  45%|████▍     | 4465/10000 [00:29<00:36, 151.15it/s]Running 10000 simulations.:  45%|████▍     | 4481/10000 [00:29<00:36, 151.19it/s]Running 10000 simulations.:  45%|████▍     | 4497/10000 [00:29<00:36, 151.23it/s]Running 10000 simulations.:  45%|████▌     | 4513/10000 [00:29<00:36, 151.29it/s]Running 10000 simulations.:  45%|████▌     | 4529/10000 [00:29<00:36, 151.35it/s]Running 10000 simulations.:  45%|████▌     | 4545/10000 [00:29<00:36, 151.23it/s]Running 10000 simulations.:  46%|████▌     | 4561/10000 [00:30<00:36, 150.42it/s]Running 10000 simulations.:  46%|████▌     | 4577/10000 [00:30<00:36, 149.82it/s]Running 10000 simulations.:  46%|████▌     | 4592/10000 [00:30<00:36, 149.13it/s]Running 10000 simulations.:  46%|████▌     | 4607/10000 [00:30<00:36, 148.67it/s]Running 10000 simulations.:  46%|████▌     | 4623/10000 [00:30<00:36, 149.25it/s]Running 10000 simulations.:  46%|████▋     | 4638/10000 [00:30<00:35, 149.31it/s]Running 10000 simulations.:  47%|████▋     | 4653/10000 [00:30<00:35, 148.78it/s]Running 10000 simulations.:  47%|████▋     | 4668/10000 [00:30<00:35, 148.82it/s]Running 10000 simulations.:  47%|████▋     | 4684/10000 [00:30<00:35, 149.32it/s]Running 10000 simulations.:  47%|████▋     | 4700/10000 [00:31<00:35, 149.94it/s]Running 10000 simulations.:  47%|████▋     | 4716/10000 [00:31<00:35, 150.19it/s]Running 10000 simulations.:  47%|████▋     | 4732/10000 [00:31<00:35, 150.03it/s]Running 10000 simulations.:  47%|████▋     | 4748/10000 [00:31<00:34, 150.22it/s]Running 10000 simulations.:  48%|████▊     | 4764/10000 [00:31<00:34, 149.91it/s]Running 10000 simulations.:  48%|████▊     | 4780/10000 [00:31<00:34, 150.01it/s]Running 10000 simulations.:  48%|████▊     | 4796/10000 [00:31<00:34, 150.24it/s]Running 10000 simulations.:  48%|████▊     | 4812/10000 [00:31<00:34, 150.42it/s]Running 10000 simulations.:  48%|████▊     | 4828/10000 [00:31<00:34, 150.15it/s]Running 10000 simulations.:  48%|████▊     | 4844/10000 [00:31<00:34, 149.61it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:32<00:34, 149.15it/s]Running 10000 simulations.:  49%|████▊     | 4874/10000 [00:32<00:34, 148.79it/s]Running 10000 simulations.:  49%|████▉     | 4889/10000 [00:32<00:34, 148.75it/s]Running 10000 simulations.:  49%|████▉     | 4904/10000 [00:32<00:34, 148.69it/s]Running 10000 simulations.:  49%|████▉     | 4919/10000 [00:32<00:34, 148.71it/s]Running 10000 simulations.:  49%|████▉     | 4934/10000 [00:32<00:34, 148.71it/s]Running 10000 simulations.:  49%|████▉     | 4949/10000 [00:32<00:33, 148.59it/s]Running 10000 simulations.:  50%|████▉     | 4964/10000 [00:32<00:33, 148.67it/s]Running 10000 simulations.:  50%|████▉     | 4979/10000 [00:32<00:33, 148.88it/s]Running 10000 simulations.:  50%|████▉     | 4994/10000 [00:32<00:33, 148.93it/s]Running 10000 simulations.:  50%|█████     | 5009/10000 [00:33<00:33, 148.63it/s]Running 10000 simulations.:  50%|█████     | 5025/10000 [00:33<00:33, 149.46it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:33<00:33, 149.33it/s]Running 10000 simulations.:  51%|█████     | 5055/10000 [00:33<00:33, 149.48it/s]Running 10000 simulations.:  51%|█████     | 5070/10000 [00:33<00:33, 149.29it/s]Running 10000 simulations.:  51%|█████     | 5085/10000 [00:33<00:32, 149.05it/s]Running 10000 simulations.:  51%|█████     | 5100/10000 [00:33<00:32, 149.32it/s]Running 10000 simulations.:  51%|█████     | 5116/10000 [00:33<00:32, 149.80it/s]Running 10000 simulations.:  51%|█████▏    | 5132/10000 [00:33<00:32, 149.97it/s]Running 10000 simulations.:  51%|█████▏    | 5147/10000 [00:34<00:32, 149.63it/s]Running 10000 simulations.:  52%|█████▏    | 5163/10000 [00:34<00:32, 149.85it/s]Running 10000 simulations.:  52%|█████▏    | 5179/10000 [00:34<00:32, 150.17it/s]Running 10000 simulations.:  52%|█████▏    | 5195/10000 [00:34<00:31, 150.29it/s]Running 10000 simulations.:  52%|█████▏    | 5211/10000 [00:34<00:31, 150.41it/s]Running 10000 simulations.:  52%|█████▏    | 5227/10000 [00:34<00:31, 150.24it/s]Running 10000 simulations.:  52%|█████▏    | 5243/10000 [00:34<00:31, 150.25it/s]Running 10000 simulations.:  53%|█████▎    | 5259/10000 [00:34<00:31, 150.55it/s]Running 10000 simulations.:  53%|█████▎    | 5275/10000 [00:34<00:31, 150.27it/s]Running 10000 simulations.:  53%|█████▎    | 5291/10000 [00:34<00:31, 150.20it/s]Running 10000 simulations.:  53%|█████▎    | 5307/10000 [00:35<00:31, 150.17it/s]Running 10000 simulations.:  53%|█████▎    | 5323/10000 [00:35<00:31, 149.85it/s]Running 10000 simulations.:  53%|█████▎    | 5339/10000 [00:35<00:31, 150.09it/s]Running 10000 simulations.:  54%|█████▎    | 5355/10000 [00:35<00:31, 149.78it/s]Running 10000 simulations.:  54%|█████▎    | 5370/10000 [00:35<00:30, 149.82it/s]Running 10000 simulations.:  54%|█████▍    | 5385/10000 [00:35<00:30, 149.47it/s]Running 10000 simulations.:  54%|█████▍    | 5401/10000 [00:35<00:30, 149.99it/s]Running 10000 simulations.:  54%|█████▍    | 5416/10000 [00:35<00:30, 149.57it/s]Running 10000 simulations.:  54%|█████▍    | 5431/10000 [00:35<00:30, 149.16it/s]Running 10000 simulations.:  54%|█████▍    | 5446/10000 [00:36<00:30, 149.17it/s]Running 10000 simulations.:  55%|█████▍    | 5462/10000 [00:36<00:30, 150.01it/s]Running 10000 simulations.:  55%|█████▍    | 5478/10000 [00:36<00:30, 150.48it/s]Running 10000 simulations.:  55%|█████▍    | 5494/10000 [00:36<00:29, 150.46it/s]Running 10000 simulations.:  55%|█████▌    | 5510/10000 [00:36<00:31, 142.92it/s]Running 10000 simulations.:  55%|█████▌    | 5526/10000 [00:36<00:30, 145.63it/s]Running 10000 simulations.:  55%|█████▌    | 5542/10000 [00:36<00:30, 147.05it/s]Running 10000 simulations.:  56%|█████▌    | 5558/10000 [00:36<00:30, 147.94it/s]Running 10000 simulations.:  56%|█████▌    | 5574/10000 [00:36<00:29, 148.82it/s]Running 10000 simulations.:  56%|█████▌    | 5590/10000 [00:36<00:29, 149.61it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:37<00:29, 150.02it/s]Running 10000 simulations.:  56%|█████▌    | 5622/10000 [00:37<00:29, 150.92it/s]Running 10000 simulations.:  56%|█████▋    | 5638/10000 [00:37<00:28, 151.01it/s]Running 10000 simulations.:  57%|█████▋    | 5654/10000 [00:37<00:28, 150.79it/s]Running 10000 simulations.:  57%|█████▋    | 5670/10000 [00:37<00:28, 150.18it/s]Running 10000 simulations.:  57%|█████▋    | 5686/10000 [00:37<00:28, 149.82it/s]Running 10000 simulations.:  57%|█████▋    | 5702/10000 [00:37<00:28, 150.64it/s]Running 10000 simulations.:  57%|█████▋    | 5718/10000 [00:37<00:28, 150.96it/s]Running 10000 simulations.:  57%|█████▋    | 5734/10000 [00:37<00:28, 151.03it/s]Running 10000 simulations.:  57%|█████▊    | 5750/10000 [00:38<00:28, 151.10it/s]Running 10000 simulations.:  58%|█████▊    | 5766/10000 [00:38<00:28, 151.06it/s]Running 10000 simulations.:  58%|█████▊    | 5782/10000 [00:38<00:27, 151.61it/s]Running 10000 simulations.:  58%|█████▊    | 5798/10000 [00:38<00:27, 151.76it/s]Running 10000 simulations.:  58%|█████▊    | 5814/10000 [00:38<00:27, 151.92it/s]Running 10000 simulations.:  58%|█████▊    | 5830/10000 [00:38<00:27, 151.37it/s]Running 10000 simulations.:  58%|█████▊    | 5846/10000 [00:38<00:27, 151.32it/s]Running 10000 simulations.:  59%|█████▊    | 5862/10000 [00:38<00:27, 151.49it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:38<00:27, 151.95it/s]Running 10000 simulations.:  59%|█████▉    | 5894/10000 [00:38<00:26, 152.38it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:39<00:26, 152.44it/s]Running 10000 simulations.:  59%|█████▉    | 5926/10000 [00:39<00:26, 152.61it/s]Running 10000 simulations.:  59%|█████▉    | 5942/10000 [00:39<00:26, 152.93it/s]Running 10000 simulations.:  60%|█████▉    | 5958/10000 [00:39<00:26, 152.96it/s]Running 10000 simulations.:  60%|█████▉    | 5974/10000 [00:39<00:26, 152.61it/s]Running 10000 simulations.:  60%|█████▉    | 5990/10000 [00:39<00:26, 152.41it/s]Running 10000 simulations.:  60%|██████    | 6006/10000 [00:39<00:26, 152.26it/s]Running 10000 simulations.:  60%|██████    | 6022/10000 [00:39<00:26, 152.66it/s]Running 10000 simulations.:  60%|██████    | 6038/10000 [00:39<00:25, 152.95it/s]Running 10000 simulations.:  61%|██████    | 6054/10000 [00:40<00:26, 151.25it/s]Running 10000 simulations.:  61%|██████    | 6070/10000 [00:40<00:25, 151.35it/s]Running 10000 simulations.:  61%|██████    | 6086/10000 [00:40<00:25, 152.15it/s]Running 10000 simulations.:  61%|██████    | 6102/10000 [00:40<00:25, 153.05it/s]Running 10000 simulations.:  61%|██████    | 6118/10000 [00:40<00:25, 154.65it/s]Running 10000 simulations.:  61%|██████▏   | 6135/10000 [00:40<00:24, 158.48it/s]Running 10000 simulations.:  62%|██████▏   | 6152/10000 [00:40<00:23, 161.05it/s]Running 10000 simulations.:  62%|██████▏   | 6169/10000 [00:40<00:24, 158.48it/s]Running 10000 simulations.:  62%|██████▏   | 6185/10000 [00:40<00:24, 156.04it/s]Running 10000 simulations.:  62%|██████▏   | 6201/10000 [00:40<00:24, 154.92it/s]Running 10000 simulations.:  62%|██████▏   | 6217/10000 [00:41<00:24, 154.45it/s]Running 10000 simulations.:  62%|██████▏   | 6233/10000 [00:41<00:24, 154.18it/s]Running 10000 simulations.:  62%|██████▏   | 6249/10000 [00:41<00:24, 154.13it/s]Running 10000 simulations.:  63%|██████▎   | 6265/10000 [00:41<00:24, 154.04it/s]Running 10000 simulations.:  63%|██████▎   | 6281/10000 [00:41<00:24, 153.71it/s]Running 10000 simulations.:  63%|██████▎   | 6297/10000 [00:41<00:24, 153.15it/s]Running 10000 simulations.:  63%|██████▎   | 6313/10000 [00:41<00:24, 152.97it/s]Running 10000 simulations.:  63%|██████▎   | 6329/10000 [00:41<00:24, 152.51it/s]Running 10000 simulations.:  63%|██████▎   | 6345/10000 [00:41<00:24, 151.94it/s]Running 10000 simulations.:  64%|██████▎   | 6361/10000 [00:42<00:24, 151.46it/s]Running 10000 simulations.:  64%|██████▍   | 6377/10000 [00:42<00:23, 151.69it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:42<00:23, 151.54it/s]Running 10000 simulations.:  64%|██████▍   | 6409/10000 [00:42<00:23, 151.16it/s]Running 10000 simulations.:  64%|██████▍   | 6425/10000 [00:42<00:23, 151.06it/s]Running 10000 simulations.:  64%|██████▍   | 6441/10000 [00:42<00:23, 150.79it/s]Running 10000 simulations.:  65%|██████▍   | 6457/10000 [00:42<00:23, 150.93it/s]Running 10000 simulations.:  65%|██████▍   | 6473/10000 [00:42<00:23, 151.16it/s]Running 10000 simulations.:  65%|██████▍   | 6489/10000 [00:42<00:23, 151.23it/s]Running 10000 simulations.:  65%|██████▌   | 6505/10000 [00:42<00:23, 151.62it/s]Running 10000 simulations.:  65%|██████▌   | 6521/10000 [00:43<00:22, 151.70it/s]Running 10000 simulations.:  65%|██████▌   | 6537/10000 [00:43<00:22, 151.92it/s]Running 10000 simulations.:  66%|██████▌   | 6553/10000 [00:43<00:22, 151.59it/s]Running 10000 simulations.:  66%|██████▌   | 6569/10000 [00:43<00:22, 151.28it/s]Running 10000 simulations.:  66%|██████▌   | 6585/10000 [00:43<00:22, 151.56it/s]Running 10000 simulations.:  66%|██████▌   | 6601/10000 [00:43<00:22, 152.03it/s]Running 10000 simulations.:  66%|██████▌   | 6617/10000 [00:43<00:22, 152.38it/s]Running 10000 simulations.:  66%|██████▋   | 6633/10000 [00:43<00:22, 152.35it/s]Running 10000 simulations.:  66%|██████▋   | 6649/10000 [00:43<00:21, 152.52it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:44<00:21, 152.80it/s]Running 10000 simulations.:  67%|██████▋   | 6681/10000 [00:44<00:21, 152.55it/s]Running 10000 simulations.:  67%|██████▋   | 6697/10000 [00:44<00:21, 152.15it/s]Running 10000 simulations.:  67%|██████▋   | 6713/10000 [00:44<00:21, 151.95it/s]Running 10000 simulations.:  67%|██████▋   | 6729/10000 [00:44<00:21, 152.31it/s]Running 10000 simulations.:  67%|██████▋   | 6745/10000 [00:44<00:21, 152.84it/s]Running 10000 simulations.:  68%|██████▊   | 6761/10000 [00:44<00:21, 153.09it/s]Running 10000 simulations.:  68%|██████▊   | 6777/10000 [00:44<00:21, 152.77it/s]Running 10000 simulations.:  68%|██████▊   | 6793/10000 [00:44<00:21, 152.55it/s]Running 10000 simulations.:  68%|██████▊   | 6809/10000 [00:44<00:20, 152.44it/s]Running 10000 simulations.:  68%|██████▊   | 6825/10000 [00:45<00:20, 151.85it/s]Running 10000 simulations.:  68%|██████▊   | 6841/10000 [00:45<00:20, 152.30it/s]Running 10000 simulations.:  69%|██████▊   | 6857/10000 [00:45<00:20, 152.60it/s]Running 10000 simulations.:  69%|██████▊   | 6873/10000 [00:45<00:20, 151.97it/s]Running 10000 simulations.:  69%|██████▉   | 6889/10000 [00:45<00:20, 152.15it/s]Running 10000 simulations.:  69%|██████▉   | 6905/10000 [00:45<00:20, 152.52it/s]Running 10000 simulations.:  69%|██████▉   | 6921/10000 [00:45<00:20, 152.55it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:45<00:20, 151.81it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:45<00:20, 151.51it/s]Running 10000 simulations.:  70%|██████▉   | 6969/10000 [00:46<00:19, 151.90it/s]Running 10000 simulations.:  70%|██████▉   | 6985/10000 [00:46<00:19, 151.69it/s]Running 10000 simulations.:  70%|███████   | 7001/10000 [00:46<00:19, 151.54it/s]Running 10000 simulations.:  70%|███████   | 7017/10000 [00:46<00:19, 151.59it/s]Running 10000 simulations.:  70%|███████   | 7033/10000 [00:46<00:19, 152.16it/s]Running 10000 simulations.:  70%|███████   | 7049/10000 [00:46<00:19, 152.43it/s]Running 10000 simulations.:  71%|███████   | 7065/10000 [00:46<00:19, 152.38it/s]Running 10000 simulations.:  71%|███████   | 7081/10000 [00:46<00:19, 152.77it/s]Running 10000 simulations.:  71%|███████   | 7097/10000 [00:46<00:19, 152.25it/s]Running 10000 simulations.:  71%|███████   | 7113/10000 [00:46<00:19, 151.88it/s]Running 10000 simulations.:  71%|███████▏  | 7129/10000 [00:47<00:18, 152.28it/s]Running 10000 simulations.:  71%|███████▏  | 7145/10000 [00:47<00:18, 152.01it/s]Running 10000 simulations.:  72%|███████▏  | 7161/10000 [00:47<00:18, 152.29it/s]Running 10000 simulations.:  72%|███████▏  | 7177/10000 [00:47<00:18, 151.94it/s]Running 10000 simulations.:  72%|███████▏  | 7193/10000 [00:47<00:18, 151.70it/s]Running 10000 simulations.:  72%|███████▏  | 7209/10000 [00:47<00:18, 151.38it/s]Running 10000 simulations.:  72%|███████▏  | 7225/10000 [00:47<00:18, 151.15it/s]Running 10000 simulations.:  72%|███████▏  | 7241/10000 [00:47<00:18, 151.37it/s]Running 10000 simulations.:  73%|███████▎  | 7257/10000 [00:47<00:18, 151.42it/s]Running 10000 simulations.:  73%|███████▎  | 7273/10000 [00:48<00:18, 151.31it/s]Running 10000 simulations.:  73%|███████▎  | 7289/10000 [00:48<00:17, 151.38it/s]Running 10000 simulations.:  73%|███████▎  | 7305/10000 [00:48<00:17, 151.90it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:48<00:17, 151.14it/s]Running 10000 simulations.:  73%|███████▎  | 7337/10000 [00:48<00:17, 150.77it/s]Running 10000 simulations.:  74%|███████▎  | 7353/10000 [00:48<00:17, 149.59it/s]Running 10000 simulations.:  74%|███████▎  | 7368/10000 [00:48<00:17, 149.67it/s]Running 10000 simulations.:  74%|███████▍  | 7384/10000 [00:48<00:17, 150.17it/s]Running 10000 simulations.:  74%|███████▍  | 7400/10000 [00:48<00:17, 150.99it/s]Running 10000 simulations.:  74%|███████▍  | 7416/10000 [00:48<00:17, 151.07it/s]Running 10000 simulations.:  74%|███████▍  | 7432/10000 [00:49<00:16, 151.46it/s]Running 10000 simulations.:  74%|███████▍  | 7448/10000 [00:49<00:16, 151.44it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:49<00:16, 150.71it/s]Running 10000 simulations.:  75%|███████▍  | 7480/10000 [00:49<00:16, 151.41it/s]Running 10000 simulations.:  75%|███████▍  | 7496/10000 [00:49<00:16, 151.55it/s]Running 10000 simulations.:  75%|███████▌  | 7512/10000 [00:49<00:16, 151.69it/s]Running 10000 simulations.:  75%|███████▌  | 7528/10000 [00:49<00:16, 151.73it/s]Running 10000 simulations.:  75%|███████▌  | 7544/10000 [00:49<00:16, 151.65it/s]Running 10000 simulations.:  76%|███████▌  | 7560/10000 [00:49<00:16, 151.81it/s]Running 10000 simulations.:  76%|███████▌  | 7576/10000 [00:50<00:16, 151.48it/s]Running 10000 simulations.:  76%|███████▌  | 7592/10000 [00:50<00:15, 151.26it/s]Running 10000 simulations.:  76%|███████▌  | 7608/10000 [00:50<00:15, 150.96it/s]Running 10000 simulations.:  76%|███████▌  | 7624/10000 [00:50<00:15, 151.52it/s]Running 10000 simulations.:  76%|███████▋  | 7640/10000 [00:50<00:15, 151.28it/s]Running 10000 simulations.:  77%|███████▋  | 7656/10000 [00:50<00:15, 151.18it/s]Running 10000 simulations.:  77%|███████▋  | 7672/10000 [00:50<00:15, 150.98it/s]Running 10000 simulations.:  77%|███████▋  | 7688/10000 [00:50<00:15, 151.32it/s]Running 10000 simulations.:  77%|███████▋  | 7704/10000 [00:50<00:15, 151.17it/s]Running 10000 simulations.:  77%|███████▋  | 7720/10000 [00:50<00:15, 151.22it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:51<00:14, 151.38it/s]Running 10000 simulations.:  78%|███████▊  | 7752/10000 [00:51<00:14, 151.73it/s]Running 10000 simulations.:  78%|███████▊  | 7768/10000 [00:51<00:14, 151.42it/s]Running 10000 simulations.:  78%|███████▊  | 7784/10000 [00:51<00:14, 151.29it/s]Running 10000 simulations.:  78%|███████▊  | 7800/10000 [00:51<00:14, 150.91it/s]Running 10000 simulations.:  78%|███████▊  | 7816/10000 [00:51<00:14, 150.56it/s]Running 10000 simulations.:  78%|███████▊  | 7832/10000 [00:51<00:14, 150.62it/s]Running 10000 simulations.:  78%|███████▊  | 7848/10000 [00:51<00:14, 150.48it/s]Running 10000 simulations.:  79%|███████▊  | 7864/10000 [00:51<00:14, 150.68it/s]Running 10000 simulations.:  79%|███████▉  | 7880/10000 [00:52<00:14, 150.56it/s]Running 10000 simulations.:  79%|███████▉  | 7896/10000 [00:52<00:13, 150.36it/s]Running 10000 simulations.:  79%|███████▉  | 7912/10000 [00:52<00:13, 151.06it/s]Running 10000 simulations.:  79%|███████▉  | 7928/10000 [00:52<00:13, 151.38it/s]Running 10000 simulations.:  79%|███████▉  | 7944/10000 [00:52<00:13, 151.51it/s]Running 10000 simulations.:  80%|███████▉  | 7960/10000 [00:52<00:13, 151.16it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:52<00:13, 151.04it/s]Running 10000 simulations.:  80%|███████▉  | 7992/10000 [00:52<00:13, 151.06it/s]Running 10000 simulations.:  80%|████████  | 8008/10000 [00:52<00:13, 150.71it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:53<00:13, 150.90it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:53<00:12, 151.48it/s]Running 10000 simulations.:  81%|████████  | 8056/10000 [00:53<00:12, 151.24it/s]Running 10000 simulations.:  81%|████████  | 8072/10000 [00:53<00:12, 151.48it/s]Running 10000 simulations.:  81%|████████  | 8088/10000 [00:53<00:12, 151.61it/s]Running 10000 simulations.:  81%|████████  | 8104/10000 [00:53<00:12, 151.16it/s]Running 10000 simulations.:  81%|████████  | 8120/10000 [00:53<00:12, 151.35it/s]Running 10000 simulations.:  81%|████████▏ | 8136/10000 [00:53<00:12, 151.73it/s]Running 10000 simulations.:  82%|████████▏ | 8152/10000 [00:53<00:12, 151.49it/s]Running 10000 simulations.:  82%|████████▏ | 8168/10000 [00:53<00:12, 151.51it/s]Running 10000 simulations.:  82%|████████▏ | 8184/10000 [00:54<00:11, 151.97it/s]Running 10000 simulations.:  82%|████████▏ | 8200/10000 [00:54<00:11, 152.35it/s]Running 10000 simulations.:  82%|████████▏ | 8216/10000 [00:54<00:11, 152.34it/s]Running 10000 simulations.:  82%|████████▏ | 8232/10000 [00:54<00:11, 151.89it/s]Running 10000 simulations.:  82%|████████▏ | 8248/10000 [00:54<00:11, 151.45it/s]Running 10000 simulations.:  83%|████████▎ | 8264/10000 [00:54<00:11, 150.90it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:54<00:11, 150.75it/s]Running 10000 simulations.:  83%|████████▎ | 8296/10000 [00:54<00:11, 150.71it/s]Running 10000 simulations.:  83%|████████▎ | 8312/10000 [00:54<00:11, 151.16it/s]Running 10000 simulations.:  83%|████████▎ | 8328/10000 [00:55<00:11, 151.08it/s]Running 10000 simulations.:  83%|████████▎ | 8344/10000 [00:55<00:11, 149.75it/s]Running 10000 simulations.:  84%|████████▎ | 8359/10000 [00:55<00:10, 149.79it/s]Running 10000 simulations.:  84%|████████▍ | 8375/10000 [00:55<00:10, 150.45it/s]Running 10000 simulations.:  84%|████████▍ | 8391/10000 [00:55<00:10, 150.99it/s]Running 10000 simulations.:  84%|████████▍ | 8407/10000 [00:55<00:10, 151.59it/s]Running 10000 simulations.:  84%|████████▍ | 8423/10000 [00:55<00:10, 151.90it/s]Running 10000 simulations.:  84%|████████▍ | 8439/10000 [00:55<00:10, 151.87it/s]Running 10000 simulations.:  85%|████████▍ | 8455/10000 [00:55<00:10, 151.60it/s]Running 10000 simulations.:  85%|████████▍ | 8471/10000 [00:55<00:10, 151.53it/s]Running 10000 simulations.:  85%|████████▍ | 8487/10000 [00:56<00:09, 151.78it/s]Running 10000 simulations.:  85%|████████▌ | 8503/10000 [00:56<00:09, 151.69it/s]Running 10000 simulations.:  85%|████████▌ | 8519/10000 [00:56<00:09, 152.75it/s]Running 10000 simulations.:  85%|████████▌ | 8536/10000 [00:56<00:09, 157.31it/s]Running 10000 simulations.:  86%|████████▌ | 8553/10000 [00:56<00:09, 159.99it/s]Running 10000 simulations.:  86%|████████▌ | 8570/10000 [00:56<00:09, 157.26it/s]Running 10000 simulations.:  86%|████████▌ | 8586/10000 [00:56<00:09, 155.22it/s]Running 10000 simulations.:  86%|████████▌ | 8602/10000 [00:56<00:09, 153.91it/s]Running 10000 simulations.:  86%|████████▌ | 8618/10000 [00:56<00:09, 152.88it/s]Running 10000 simulations.:  86%|████████▋ | 8634/10000 [00:57<00:08, 152.40it/s]Running 10000 simulations.:  86%|████████▋ | 8650/10000 [00:57<00:08, 151.50it/s]Running 10000 simulations.:  87%|████████▋ | 8666/10000 [00:57<00:08, 151.37it/s]Running 10000 simulations.:  87%|████████▋ | 8682/10000 [00:57<00:08, 151.36it/s]Running 10000 simulations.:  87%|████████▋ | 8698/10000 [00:57<00:08, 151.21it/s]Running 10000 simulations.:  87%|████████▋ | 8714/10000 [00:57<00:08, 150.30it/s]Running 10000 simulations.:  87%|████████▋ | 8730/10000 [00:57<00:08, 150.84it/s]Running 10000 simulations.:  87%|████████▋ | 8746/10000 [00:57<00:08, 151.50it/s]Running 10000 simulations.:  88%|████████▊ | 8762/10000 [00:57<00:08, 151.80it/s]Running 10000 simulations.:  88%|████████▊ | 8778/10000 [00:57<00:08, 151.88it/s]Running 10000 simulations.:  88%|████████▊ | 8794/10000 [00:58<00:07, 152.24it/s]Running 10000 simulations.:  88%|████████▊ | 8810/10000 [00:58<00:07, 152.27it/s]Running 10000 simulations.:  88%|████████▊ | 8826/10000 [00:58<00:07, 152.15it/s]Running 10000 simulations.:  88%|████████▊ | 8842/10000 [00:58<00:07, 151.40it/s]Running 10000 simulations.:  89%|████████▊ | 8858/10000 [00:58<00:07, 151.30it/s]Running 10000 simulations.:  89%|████████▊ | 8874/10000 [00:58<00:07, 151.03it/s]Running 10000 simulations.:  89%|████████▉ | 8890/10000 [00:58<00:07, 151.05it/s]Running 10000 simulations.:  89%|████████▉ | 8906/10000 [00:58<00:07, 150.84it/s]Running 10000 simulations.:  89%|████████▉ | 8922/10000 [00:58<00:07, 150.68it/s]Running 10000 simulations.:  89%|████████▉ | 8938/10000 [00:59<00:07, 151.24it/s]Running 10000 simulations.:  90%|████████▉ | 8954/10000 [00:59<00:06, 151.41it/s]Running 10000 simulations.:  90%|████████▉ | 8970/10000 [00:59<00:06, 151.52it/s]Running 10000 simulations.:  90%|████████▉ | 8986/10000 [00:59<00:06, 151.34it/s]Running 10000 simulations.:  90%|█████████ | 9002/10000 [00:59<00:06, 150.72it/s]Running 10000 simulations.:  90%|█████████ | 9018/10000 [00:59<00:06, 150.58it/s]Running 10000 simulations.:  90%|█████████ | 9034/10000 [00:59<00:06, 150.68it/s]Running 10000 simulations.:  90%|█████████ | 9050/10000 [00:59<00:06, 150.24it/s]Running 10000 simulations.:  91%|█████████ | 9066/10000 [00:59<00:06, 149.88it/s]Running 10000 simulations.:  91%|█████████ | 9082/10000 [00:59<00:06, 150.10it/s]Running 10000 simulations.:  91%|█████████ | 9098/10000 [01:00<00:06, 150.17it/s]Running 10000 simulations.:  91%|█████████ | 9114/10000 [01:00<00:05, 149.68it/s]Running 10000 simulations.:  91%|█████████▏| 9130/10000 [01:00<00:05, 149.87it/s]Running 10000 simulations.:  91%|█████████▏| 9145/10000 [01:00<00:05, 149.61it/s]Running 10000 simulations.:  92%|█████████▏| 9160/10000 [01:00<00:05, 149.27it/s]Running 10000 simulations.:  92%|█████████▏| 9175/10000 [01:00<00:05, 149.13it/s]Running 10000 simulations.:  92%|█████████▏| 9190/10000 [01:00<00:05, 148.94it/s]Running 10000 simulations.:  92%|█████████▏| 9205/10000 [01:00<00:05, 148.98it/s]Running 10000 simulations.:  92%|█████████▏| 9220/10000 [01:00<00:05, 148.95it/s]Running 10000 simulations.:  92%|█████████▏| 9235/10000 [01:00<00:05, 149.02it/s]Running 10000 simulations.:  92%|█████████▎| 9250/10000 [01:01<00:05, 149.27it/s]Running 10000 simulations.:  93%|█████████▎| 9266/10000 [01:01<00:04, 149.52it/s]Running 10000 simulations.:  93%|█████████▎| 9282/10000 [01:01<00:04, 150.16it/s]Running 10000 simulations.:  93%|█████████▎| 9298/10000 [01:01<00:04, 150.41it/s]Running 10000 simulations.:  93%|█████████▎| 9314/10000 [01:01<00:04, 150.71it/s]Running 10000 simulations.:  93%|█████████▎| 9330/10000 [01:01<00:04, 150.86it/s]Running 10000 simulations.:  93%|█████████▎| 9346/10000 [01:01<00:04, 151.12it/s]Running 10000 simulations.:  94%|█████████▎| 9362/10000 [01:01<00:04, 151.04it/s]Running 10000 simulations.:  94%|█████████▍| 9378/10000 [01:01<00:04, 151.21it/s]Running 10000 simulations.:  94%|█████████▍| 9394/10000 [01:02<00:04, 151.38it/s]Running 10000 simulations.:  94%|█████████▍| 9410/10000 [01:02<00:03, 151.39it/s]Running 10000 simulations.:  94%|█████████▍| 9426/10000 [01:02<00:03, 151.12it/s]Running 10000 simulations.:  94%|█████████▍| 9442/10000 [01:02<00:03, 150.42it/s]Running 10000 simulations.:  95%|█████████▍| 9458/10000 [01:02<00:03, 150.56it/s]Running 10000 simulations.:  95%|█████████▍| 9474/10000 [01:02<00:03, 150.75it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [01:02<00:03, 150.87it/s]Running 10000 simulations.:  95%|█████████▌| 9506/10000 [01:02<00:03, 150.42it/s]Running 10000 simulations.:  95%|█████████▌| 9522/10000 [01:02<00:03, 150.12it/s]Running 10000 simulations.:  95%|█████████▌| 9538/10000 [01:03<00:03, 149.97it/s]Running 10000 simulations.:  96%|█████████▌| 9554/10000 [01:03<00:02, 150.24it/s]Running 10000 simulations.:  96%|█████████▌| 9570/10000 [01:03<00:02, 150.58it/s]Running 10000 simulations.:  96%|█████████▌| 9586/10000 [01:03<00:02, 151.03it/s]Running 10000 simulations.:  96%|█████████▌| 9602/10000 [01:03<00:02, 151.12it/s]Running 10000 simulations.:  96%|█████████▌| 9618/10000 [01:03<00:02, 151.33it/s]Running 10000 simulations.:  96%|█████████▋| 9634/10000 [01:03<00:02, 150.93it/s]Running 10000 simulations.:  96%|█████████▋| 9650/10000 [01:03<00:02, 150.63it/s]Running 10000 simulations.:  97%|█████████▋| 9666/10000 [01:03<00:02, 149.99it/s]Running 10000 simulations.:  97%|█████████▋| 9682/10000 [01:03<00:02, 149.49it/s]Running 10000 simulations.:  97%|█████████▋| 9697/10000 [01:04<00:02, 149.42it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [01:04<00:01, 149.48it/s]Running 10000 simulations.:  97%|█████████▋| 9727/10000 [01:04<00:01, 149.52it/s]Running 10000 simulations.:  97%|█████████▋| 9742/10000 [01:04<00:01, 149.27it/s]Running 10000 simulations.:  98%|█████████▊| 9758/10000 [01:04<00:01, 149.79it/s]Running 10000 simulations.:  98%|█████████▊| 9774/10000 [01:04<00:01, 150.05it/s]Running 10000 simulations.:  98%|█████████▊| 9790/10000 [01:04<00:01, 149.76it/s]Running 10000 simulations.:  98%|█████████▊| 9806/10000 [01:04<00:01, 149.92it/s]Running 10000 simulations.:  98%|█████████▊| 9821/10000 [01:04<00:01, 149.05it/s]Running 10000 simulations.:  98%|█████████▊| 9836/10000 [01:04<00:01, 148.61it/s]Running 10000 simulations.:  99%|█████████▊| 9851/10000 [01:05<00:01, 148.84it/s]Running 10000 simulations.:  99%|█████████▊| 9866/10000 [01:05<00:00, 148.68it/s]Running 10000 simulations.:  99%|█████████▉| 9881/10000 [01:05<00:00, 148.33it/s]Running 10000 simulations.:  99%|█████████▉| 9896/10000 [01:05<00:00, 148.70it/s]Running 10000 simulations.:  99%|█████████▉| 9911/10000 [01:05<00:00, 148.48it/s]Running 10000 simulations.:  99%|█████████▉| 9926/10000 [01:05<00:00, 148.16it/s]Running 10000 simulations.:  99%|█████████▉| 9941/10000 [01:05<00:00, 148.24it/s]Running 10000 simulations.: 100%|█████████▉| 9956/10000 [01:05<00:00, 148.05it/s]Running 10000 simulations.: 100%|█████████▉| 9971/10000 [01:05<00:00, 147.92it/s]Running 10000 simulations.: 100%|█████████▉| 9986/10000 [01:06<00:00, 147.75it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:06<00:00, 151.26it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 16/10000 [00:00<01:03, 156.37it/s]Running 10000 simulations.:   0%|          | 33/10000 [00:00<01:03, 158.13it/s]Running 10000 simulations.:   0%|          | 50/10000 [00:00<01:02, 159.10it/s]Running 10000 simulations.:   1%|          | 67/10000 [00:00<01:02, 160.04it/s]Running 10000 simulations.:   1%|          | 83/10000 [00:00<01:02, 159.21it/s]Running 10000 simulations.:   1%|          | 99/10000 [00:00<01:03, 156.93it/s]Running 10000 simulations.:   1%|          | 115/10000 [00:00<01:03, 156.33it/s]Running 10000 simulations.:   1%|▏         | 131/10000 [00:00<01:02, 156.69it/s]Running 10000 simulations.:   1%|▏         | 147/10000 [00:00<01:02, 157.33it/s]Running 10000 simulations.:   2%|▏         | 163/10000 [00:01<01:02, 157.79it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:01<01:01, 158.79it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:01<01:01, 159.69it/s]Running 10000 simulations.:   2%|▏         | 213/10000 [00:01<01:01, 158.10it/s]Running 10000 simulations.:   2%|▏         | 229/10000 [00:01<01:02, 157.09it/s]Running 10000 simulations.:   2%|▏         | 245/10000 [00:01<01:01, 157.66it/s]Running 10000 simulations.:   3%|▎         | 261/10000 [00:01<01:01, 157.91it/s]Running 10000 simulations.:   3%|▎         | 277/10000 [00:01<01:01, 158.28it/s]Running 10000 simulations.:   3%|▎         | 294/10000 [00:01<01:00, 159.19it/s]Running 10000 simulations.:   3%|▎         | 310/10000 [00:01<01:01, 158.23it/s]Running 10000 simulations.:   3%|▎         | 326/10000 [00:02<01:01, 156.33it/s]Running 10000 simulations.:   3%|▎         | 342/10000 [00:02<01:01, 156.82it/s]Running 10000 simulations.:   4%|▎         | 358/10000 [00:02<01:01, 157.46it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:02<01:00, 157.88it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:02<01:00, 158.02it/s]Running 10000 simulations.:   4%|▍         | 406/10000 [00:02<01:00, 157.89it/s]Running 10000 simulations.:   4%|▍         | 422/10000 [00:02<01:01, 155.97it/s]Running 10000 simulations.:   4%|▍         | 438/10000 [00:02<01:01, 155.42it/s]Running 10000 simulations.:   5%|▍         | 454/10000 [00:02<01:01, 156.17it/s]Running 10000 simulations.:   5%|▍         | 470/10000 [00:02<01:00, 157.27it/s]Running 10000 simulations.:   5%|▍         | 486/10000 [00:03<01:00, 156.78it/s]Running 10000 simulations.:   5%|▌         | 502/10000 [00:03<01:00, 156.39it/s]Running 10000 simulations.:   5%|▌         | 518/10000 [00:03<01:00, 156.73it/s]Running 10000 simulations.:   5%|▌         | 535/10000 [00:03<01:00, 157.59it/s]Running 10000 simulations.:   6%|▌         | 551/10000 [00:03<01:00, 156.03it/s]Running 10000 simulations.:   6%|▌         | 567/10000 [00:03<01:00, 155.17it/s]Running 10000 simulations.:   6%|▌         | 583/10000 [00:03<01:00, 156.16it/s]Running 10000 simulations.:   6%|▌         | 599/10000 [00:03<00:59, 157.01it/s]Running 10000 simulations.:   6%|▌         | 615/10000 [00:03<00:59, 157.68it/s]Running 10000 simulations.:   6%|▋         | 632/10000 [00:04<00:59, 158.48it/s]Running 10000 simulations.:   6%|▋         | 648/10000 [00:04<00:59, 158.02it/s]Running 10000 simulations.:   7%|▋         | 664/10000 [00:04<00:59, 155.96it/s]Running 10000 simulations.:   7%|▋         | 680/10000 [00:04<01:01, 152.65it/s]Running 10000 simulations.:   7%|▋         | 696/10000 [00:04<01:01, 151.76it/s]Running 10000 simulations.:   7%|▋         | 713/10000 [00:04<00:59, 155.23it/s]Running 10000 simulations.:   7%|▋         | 731/10000 [00:04<00:57, 160.58it/s]Running 10000 simulations.:   7%|▋         | 749/10000 [00:04<00:56, 163.17it/s]Running 10000 simulations.:   8%|▊         | 766/10000 [00:04<00:57, 160.47it/s]Running 10000 simulations.:   8%|▊         | 783/10000 [00:04<00:59, 155.97it/s]Running 10000 simulations.:   8%|▊         | 799/10000 [00:05<00:59, 153.42it/s]Running 10000 simulations.:   8%|▊         | 815/10000 [00:05<00:59, 153.42it/s]Running 10000 simulations.:   8%|▊         | 831/10000 [00:05<00:59, 153.40it/s]Running 10000 simulations.:   8%|▊         | 847/10000 [00:05<00:59, 154.47it/s]Running 10000 simulations.:   9%|▊         | 863/10000 [00:05<00:58, 155.47it/s]Running 10000 simulations.:   9%|▉         | 879/10000 [00:05<00:59, 153.83it/s]Running 10000 simulations.:   9%|▉         | 895/10000 [00:05<00:59, 151.92it/s]Running 10000 simulations.:   9%|▉         | 911/10000 [00:05<00:59, 152.72it/s]Running 10000 simulations.:   9%|▉         | 927/10000 [00:05<00:59, 153.51it/s]Running 10000 simulations.:   9%|▉         | 943/10000 [00:06<00:58, 154.20it/s]Running 10000 simulations.:  10%|▉         | 959/10000 [00:06<00:58, 154.49it/s]Running 10000 simulations.:  10%|▉         | 975/10000 [00:06<00:58, 153.26it/s]Running 10000 simulations.:  10%|▉         | 991/10000 [00:06<00:59, 151.90it/s]Running 10000 simulations.:  10%|█         | 1007/10000 [00:06<00:59, 152.29it/s]Running 10000 simulations.:  10%|█         | 1023/10000 [00:06<00:58, 152.89it/s]Running 10000 simulations.:  10%|█         | 1039/10000 [00:06<00:58, 154.01it/s]Running 10000 simulations.:  11%|█         | 1055/10000 [00:06<00:57, 154.25it/s]Running 10000 simulations.:  11%|█         | 1071/10000 [00:06<00:57, 154.77it/s]Running 10000 simulations.:  11%|█         | 1087/10000 [00:06<00:58, 152.19it/s]Running 10000 simulations.:  11%|█         | 1103/10000 [00:07<00:58, 152.00it/s]Running 10000 simulations.:  11%|█         | 1119/10000 [00:07<00:58, 152.37it/s]Running 10000 simulations.:  11%|█▏        | 1135/10000 [00:07<00:57, 152.86it/s]Running 10000 simulations.:  12%|█▏        | 1151/10000 [00:07<00:57, 153.66it/s]Running 10000 simulations.:  12%|█▏        | 1167/10000 [00:07<00:57, 153.78it/s]Running 10000 simulations.:  12%|█▏        | 1183/10000 [00:07<00:57, 152.35it/s]Running 10000 simulations.:  12%|█▏        | 1199/10000 [00:07<00:58, 150.10it/s]Running 10000 simulations.:  12%|█▏        | 1215/10000 [00:07<00:58, 150.15it/s]Running 10000 simulations.:  12%|█▏        | 1231/10000 [00:07<00:58, 151.19it/s]Running 10000 simulations.:  12%|█▏        | 1247/10000 [00:08<00:57, 152.01it/s]Running 10000 simulations.:  13%|█▎        | 1263/10000 [00:08<00:57, 153.12it/s]Running 10000 simulations.:  13%|█▎        | 1279/10000 [00:08<00:57, 152.15it/s]Running 10000 simulations.:  13%|█▎        | 1295/10000 [00:08<00:57, 152.21it/s]Running 10000 simulations.:  13%|█▎        | 1311/10000 [00:08<00:56, 152.57it/s]Running 10000 simulations.:  13%|█▎        | 1327/10000 [00:08<00:56, 153.26it/s]Running 10000 simulations.:  13%|█▎        | 1343/10000 [00:08<00:57, 150.80it/s]Running 10000 simulations.:  14%|█▎        | 1359/10000 [00:08<00:57, 150.97it/s]Running 10000 simulations.:  14%|█▍        | 1375/10000 [00:08<00:56, 151.60it/s]Running 10000 simulations.:  14%|█▍        | 1391/10000 [00:08<00:56, 152.59it/s]Running 10000 simulations.:  14%|█▍        | 1407/10000 [00:09<00:55, 153.64it/s]Running 10000 simulations.:  14%|█▍        | 1423/10000 [00:09<00:55, 153.85it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:09<00:56, 150.64it/s]Running 10000 simulations.:  15%|█▍        | 1455/10000 [00:09<00:57, 148.99it/s]Running 10000 simulations.:  15%|█▍        | 1471/10000 [00:09<00:56, 150.25it/s]Running 10000 simulations.:  15%|█▍        | 1487/10000 [00:09<00:56, 150.84it/s]Running 10000 simulations.:  15%|█▌        | 1503/10000 [00:09<00:56, 151.56it/s]Running 10000 simulations.:  15%|█▌        | 1519/10000 [00:09<00:55, 152.80it/s]Running 10000 simulations.:  15%|█▌        | 1535/10000 [00:09<00:55, 151.68it/s]Running 10000 simulations.:  16%|█▌        | 1551/10000 [00:10<00:57, 148.15it/s]Running 10000 simulations.:  16%|█▌        | 1566/10000 [00:10<00:56, 148.52it/s]Running 10000 simulations.:  16%|█▌        | 1582/10000 [00:10<00:56, 149.66it/s]Running 10000 simulations.:  16%|█▌        | 1598/10000 [00:10<00:55, 150.11it/s]Running 10000 simulations.:  16%|█▌        | 1614/10000 [00:10<00:55, 151.38it/s]Running 10000 simulations.:  16%|█▋        | 1630/10000 [00:10<00:54, 153.06it/s]Running 10000 simulations.:  16%|█▋        | 1646/10000 [00:10<00:54, 153.91it/s]Running 10000 simulations.:  17%|█▋        | 1662/10000 [00:10<00:55, 150.74it/s]Running 10000 simulations.:  17%|█▋        | 1678/10000 [00:10<00:55, 151.10it/s]Running 10000 simulations.:  17%|█▋        | 1694/10000 [00:10<00:54, 152.33it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:11<00:54, 153.49it/s]Running 10000 simulations.:  17%|█▋        | 1726/10000 [00:11<00:53, 154.30it/s]Running 10000 simulations.:  17%|█▋        | 1742/10000 [00:11<00:53, 155.28it/s]Running 10000 simulations.:  18%|█▊        | 1758/10000 [00:11<00:53, 153.76it/s]Running 10000 simulations.:  18%|█▊        | 1774/10000 [00:11<00:53, 152.41it/s]Running 10000 simulations.:  18%|█▊        | 1790/10000 [00:11<00:53, 152.64it/s]Running 10000 simulations.:  18%|█▊        | 1806/10000 [00:11<00:53, 153.22it/s]Running 10000 simulations.:  18%|█▊        | 1822/10000 [00:11<00:53, 153.70it/s]Running 10000 simulations.:  18%|█▊        | 1838/10000 [00:11<00:52, 154.33it/s]Running 10000 simulations.:  19%|█▊        | 1854/10000 [00:12<00:53, 153.03it/s]Running 10000 simulations.:  19%|█▊        | 1870/10000 [00:12<00:54, 150.12it/s]Running 10000 simulations.:  19%|█▉        | 1886/10000 [00:12<00:53, 151.01it/s]Running 10000 simulations.:  19%|█▉        | 1902/10000 [00:12<00:53, 151.40it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:12<00:53, 152.49it/s]Running 10000 simulations.:  19%|█▉        | 1934/10000 [00:12<00:52, 153.26it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:12<00:52, 153.44it/s]Running 10000 simulations.:  20%|█▉        | 1966/10000 [00:12<00:53, 150.08it/s]Running 10000 simulations.:  20%|█▉        | 1982/10000 [00:12<00:53, 150.47it/s]Running 10000 simulations.:  20%|█▉        | 1998/10000 [00:12<00:53, 149.94it/s]Running 10000 simulations.:  20%|██        | 2014/10000 [00:13<00:52, 150.91it/s]Running 10000 simulations.:  20%|██        | 2030/10000 [00:13<00:52, 151.71it/s]Running 10000 simulations.:  20%|██        | 2046/10000 [00:13<00:52, 152.51it/s]Running 10000 simulations.:  21%|██        | 2062/10000 [00:13<00:52, 150.83it/s]Running 10000 simulations.:  21%|██        | 2078/10000 [00:13<00:52, 150.60it/s]Running 10000 simulations.:  21%|██        | 2094/10000 [00:13<00:52, 151.52it/s]Running 10000 simulations.:  21%|██        | 2110/10000 [00:13<00:51, 152.28it/s]Running 10000 simulations.:  21%|██▏       | 2126/10000 [00:13<00:51, 152.03it/s]Running 10000 simulations.:  21%|██▏       | 2142/10000 [00:13<00:51, 152.65it/s]Running 10000 simulations.:  22%|██▏       | 2158/10000 [00:14<00:51, 153.65it/s]Running 10000 simulations.:  22%|██▏       | 2174/10000 [00:14<00:50, 154.78it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:14<00:50, 153.64it/s]Running 10000 simulations.:  22%|██▏       | 2206/10000 [00:14<00:51, 151.87it/s]Running 10000 simulations.:  22%|██▏       | 2222/10000 [00:14<00:51, 151.49it/s]Running 10000 simulations.:  22%|██▏       | 2238/10000 [00:14<00:51, 152.00it/s]Running 10000 simulations.:  23%|██▎       | 2254/10000 [00:14<00:50, 152.82it/s]Running 10000 simulations.:  23%|██▎       | 2270/10000 [00:14<00:50, 153.98it/s]Running 10000 simulations.:  23%|██▎       | 2286/10000 [00:14<00:50, 153.93it/s]Running 10000 simulations.:  23%|██▎       | 2302/10000 [00:14<00:50, 151.32it/s]Running 10000 simulations.:  23%|██▎       | 2318/10000 [00:15<00:51, 150.52it/s]Running 10000 simulations.:  23%|██▎       | 2334/10000 [00:15<00:50, 151.29it/s]Running 10000 simulations.:  24%|██▎       | 2350/10000 [00:15<00:50, 152.23it/s]Running 10000 simulations.:  24%|██▎       | 2366/10000 [00:15<00:49, 152.82it/s]Running 10000 simulations.:  24%|██▍       | 2382/10000 [00:15<00:49, 152.99it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:15<00:50, 150.74it/s]Running 10000 simulations.:  24%|██▍       | 2414/10000 [00:15<00:50, 149.64it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:15<00:50, 150.54it/s]Running 10000 simulations.:  24%|██▍       | 2446/10000 [00:15<00:50, 151.00it/s]Running 10000 simulations.:  25%|██▍       | 2462/10000 [00:16<00:49, 151.97it/s]Running 10000 simulations.:  25%|██▍       | 2478/10000 [00:16<00:49, 152.42it/s]Running 10000 simulations.:  25%|██▍       | 2494/10000 [00:16<00:49, 150.74it/s]Running 10000 simulations.:  25%|██▌       | 2510/10000 [00:16<00:49, 149.88it/s]Running 10000 simulations.:  25%|██▌       | 2526/10000 [00:16<00:49, 150.31it/s]Running 10000 simulations.:  25%|██▌       | 2542/10000 [00:16<00:49, 150.77it/s]Running 10000 simulations.:  26%|██▌       | 2558/10000 [00:16<00:48, 151.91it/s]Running 10000 simulations.:  26%|██▌       | 2574/10000 [00:16<00:48, 152.89it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:16<00:48, 151.30it/s]Running 10000 simulations.:  26%|██▌       | 2606/10000 [00:16<00:49, 149.06it/s]Running 10000 simulations.:  26%|██▌       | 2622/10000 [00:17<00:49, 149.61it/s]Running 10000 simulations.:  26%|██▋       | 2638/10000 [00:17<00:48, 150.28it/s]Running 10000 simulations.:  27%|██▋       | 2654/10000 [00:17<00:48, 151.26it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:17<00:48, 152.24it/s]Running 10000 simulations.:  27%|██▋       | 2686/10000 [00:17<00:48, 151.20it/s]Running 10000 simulations.:  27%|██▋       | 2702/10000 [00:17<00:48, 149.06it/s]Running 10000 simulations.:  27%|██▋       | 2717/10000 [00:17<00:49, 148.37it/s]Running 10000 simulations.:  27%|██▋       | 2732/10000 [00:17<00:49, 147.63it/s]Running 10000 simulations.:  27%|██▋       | 2748/10000 [00:17<00:48, 148.50it/s]Running 10000 simulations.:  28%|██▊       | 2764/10000 [00:18<00:48, 149.73it/s]Running 10000 simulations.:  28%|██▊       | 2780/10000 [00:18<00:47, 150.47it/s]Running 10000 simulations.:  28%|██▊       | 2796/10000 [00:18<00:47, 151.37it/s]Running 10000 simulations.:  28%|██▊       | 2812/10000 [00:18<00:47, 149.94it/s]Running 10000 simulations.:  28%|██▊       | 2828/10000 [00:18<00:48, 147.78it/s]Running 10000 simulations.:  28%|██▊       | 2843/10000 [00:18<00:48, 148.11it/s]Running 10000 simulations.:  29%|██▊       | 2859/10000 [00:18<00:47, 150.41it/s]Running 10000 simulations.:  29%|██▉       | 2877/10000 [00:18<00:45, 156.48it/s]Running 10000 simulations.:  29%|██▉       | 2894/10000 [00:18<00:44, 158.95it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:18<00:45, 155.42it/s]Running 10000 simulations.:  29%|██▉       | 2926/10000 [00:19<00:46, 153.74it/s]Running 10000 simulations.:  29%|██▉       | 2942/10000 [00:19<00:45, 153.67it/s]Running 10000 simulations.:  30%|██▉       | 2958/10000 [00:19<00:46, 152.86it/s]Running 10000 simulations.:  30%|██▉       | 2974/10000 [00:19<00:46, 150.03it/s]Running 10000 simulations.:  30%|██▉       | 2990/10000 [00:19<00:47, 148.61it/s]Running 10000 simulations.:  30%|███       | 3005/10000 [00:19<00:47, 148.75it/s]Running 10000 simulations.:  30%|███       | 3021/10000 [00:19<00:46, 149.39it/s]Running 10000 simulations.:  30%|███       | 3037/10000 [00:19<00:46, 150.78it/s]Running 10000 simulations.:  31%|███       | 3053/10000 [00:19<00:45, 151.47it/s]Running 10000 simulations.:  31%|███       | 3069/10000 [00:20<00:45, 151.96it/s]Running 10000 simulations.:  31%|███       | 3085/10000 [00:20<00:46, 150.26it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:20<00:46, 148.52it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:20<00:46, 146.89it/s]Running 10000 simulations.:  31%|███▏      | 3132/10000 [00:20<00:46, 148.73it/s]Running 10000 simulations.:  31%|███▏      | 3148/10000 [00:20<00:45, 150.47it/s]Running 10000 simulations.:  32%|███▏      | 3164/10000 [00:20<00:44, 152.18it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:20<00:44, 152.95it/s]Running 10000 simulations.:  32%|███▏      | 3196/10000 [00:20<00:44, 153.11it/s]Running 10000 simulations.:  32%|███▏      | 3212/10000 [00:20<00:45, 150.28it/s]Running 10000 simulations.:  32%|███▏      | 3228/10000 [00:21<00:45, 148.29it/s]Running 10000 simulations.:  32%|███▏      | 3243/10000 [00:21<00:45, 148.20it/s]Running 10000 simulations.:  33%|███▎      | 3258/10000 [00:21<00:47, 141.44it/s]Running 10000 simulations.:  33%|███▎      | 3274/10000 [00:21<00:46, 145.25it/s]Running 10000 simulations.:  33%|███▎      | 3290/10000 [00:21<00:45, 147.87it/s]Running 10000 simulations.:  33%|███▎      | 3306/10000 [00:21<00:44, 150.19it/s]Running 10000 simulations.:  33%|███▎      | 3322/10000 [00:21<00:44, 149.00it/s]Running 10000 simulations.:  33%|███▎      | 3337/10000 [00:21<00:45, 147.52it/s]Running 10000 simulations.:  34%|███▎      | 3352/10000 [00:21<00:45, 146.79it/s]Running 10000 simulations.:  34%|███▎      | 3368/10000 [00:22<00:44, 147.81it/s]Running 10000 simulations.:  34%|███▍      | 3384/10000 [00:22<00:44, 148.68it/s]Running 10000 simulations.:  34%|███▍      | 3400/10000 [00:22<00:43, 150.70it/s]Running 10000 simulations.:  34%|███▍      | 3416/10000 [00:22<00:43, 152.33it/s]Running 10000 simulations.:  34%|███▍      | 3432/10000 [00:22<00:42, 153.27it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:22<00:43, 151.04it/s]Running 10000 simulations.:  35%|███▍      | 3464/10000 [00:22<00:43, 148.58it/s]Running 10000 simulations.:  35%|███▍      | 3479/10000 [00:22<00:44, 148.07it/s]Running 10000 simulations.:  35%|███▍      | 3495/10000 [00:22<00:43, 149.58it/s]Running 10000 simulations.:  35%|███▌      | 3511/10000 [00:22<00:43, 150.71it/s]Running 10000 simulations.:  35%|███▌      | 3527/10000 [00:23<00:42, 152.07it/s]Running 10000 simulations.:  35%|███▌      | 3543/10000 [00:23<00:42, 153.14it/s]Running 10000 simulations.:  36%|███▌      | 3559/10000 [00:23<00:42, 152.11it/s]Running 10000 simulations.:  36%|███▌      | 3575/10000 [00:23<00:42, 149.90it/s]Running 10000 simulations.:  36%|███▌      | 3591/10000 [00:23<00:43, 148.25it/s]Running 10000 simulations.:  36%|███▌      | 3607/10000 [00:23<00:42, 149.11it/s]Running 10000 simulations.:  36%|███▌      | 3623/10000 [00:23<00:42, 149.99it/s]Running 10000 simulations.:  36%|███▋      | 3639/10000 [00:23<00:41, 151.67it/s]Running 10000 simulations.:  37%|███▋      | 3655/10000 [00:23<00:41, 152.78it/s]Running 10000 simulations.:  37%|███▋      | 3671/10000 [00:24<00:41, 152.84it/s]Running 10000 simulations.:  37%|███▋      | 3687/10000 [00:24<00:42, 149.42it/s]Running 10000 simulations.:  37%|███▋      | 3702/10000 [00:24<00:42, 147.49it/s]Running 10000 simulations.:  37%|███▋      | 3717/10000 [00:24<00:42, 147.04it/s]Running 10000 simulations.:  37%|███▋      | 3733/10000 [00:24<00:42, 148.46it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:24<00:41, 149.63it/s]Running 10000 simulations.:  38%|███▊      | 3765/10000 [00:24<00:41, 150.50it/s]Running 10000 simulations.:  38%|███▊      | 3781/10000 [00:24<00:40, 152.07it/s]Running 10000 simulations.:  38%|███▊      | 3797/10000 [00:24<00:41, 150.72it/s]Running 10000 simulations.:  38%|███▊      | 3813/10000 [00:25<00:41, 148.90it/s]Running 10000 simulations.:  38%|███▊      | 3828/10000 [00:25<00:41, 147.97it/s]Running 10000 simulations.:  38%|███▊      | 3844/10000 [00:25<00:41, 148.63it/s]Running 10000 simulations.:  39%|███▊      | 3860/10000 [00:25<00:40, 150.40it/s]Running 10000 simulations.:  39%|███▉      | 3876/10000 [00:25<00:40, 149.55it/s]Running 10000 simulations.:  39%|███▉      | 3891/10000 [00:25<00:40, 149.33it/s]Running 10000 simulations.:  39%|███▉      | 3907/10000 [00:25<00:40, 150.18it/s]Running 10000 simulations.:  39%|███▉      | 3923/10000 [00:25<00:40, 151.44it/s]Running 10000 simulations.:  39%|███▉      | 3939/10000 [00:25<00:40, 151.17it/s]Running 10000 simulations.:  40%|███▉      | 3955/10000 [00:25<00:40, 149.78it/s]Running 10000 simulations.:  40%|███▉      | 3970/10000 [00:26<00:40, 149.09it/s]Running 10000 simulations.:  40%|███▉      | 3985/10000 [00:26<00:40, 149.35it/s]Running 10000 simulations.:  40%|████      | 4001/10000 [00:26<00:39, 149.99it/s]Running 10000 simulations.:  40%|████      | 4017/10000 [00:26<00:39, 150.29it/s]Running 10000 simulations.:  40%|████      | 4033/10000 [00:26<00:39, 151.30it/s]Running 10000 simulations.:  40%|████      | 4049/10000 [00:26<00:39, 151.36it/s]Running 10000 simulations.:  41%|████      | 4065/10000 [00:26<00:39, 149.50it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:26<00:40, 147.97it/s]Running 10000 simulations.:  41%|████      | 4095/10000 [00:26<00:40, 147.31it/s]Running 10000 simulations.:  41%|████      | 4111/10000 [00:26<00:39, 148.16it/s]Running 10000 simulations.:  41%|████▏     | 4126/10000 [00:27<00:39, 148.47it/s]Running 10000 simulations.:  41%|████▏     | 4142/10000 [00:27<00:39, 149.48it/s]Running 10000 simulations.:  42%|████▏     | 4158/10000 [00:27<00:38, 150.75it/s]Running 10000 simulations.:  42%|████▏     | 4174/10000 [00:27<00:38, 150.93it/s]Running 10000 simulations.:  42%|████▏     | 4190/10000 [00:27<00:38, 149.05it/s]Running 10000 simulations.:  42%|████▏     | 4205/10000 [00:27<00:39, 148.36it/s]Running 10000 simulations.:  42%|████▏     | 4220/10000 [00:27<00:38, 148.71it/s]Running 10000 simulations.:  42%|████▏     | 4236/10000 [00:27<00:38, 149.69it/s]Running 10000 simulations.:  43%|████▎     | 4252/10000 [00:27<00:38, 150.71it/s]Running 10000 simulations.:  43%|████▎     | 4268/10000 [00:28<00:37, 151.43it/s]Running 10000 simulations.:  43%|████▎     | 4284/10000 [00:28<00:37, 152.52it/s]Running 10000 simulations.:  43%|████▎     | 4300/10000 [00:28<00:37, 150.44it/s]Running 10000 simulations.:  43%|████▎     | 4316/10000 [00:28<00:38, 148.29it/s]Running 10000 simulations.:  43%|████▎     | 4331/10000 [00:28<00:38, 147.81it/s]Running 10000 simulations.:  43%|████▎     | 4347/10000 [00:28<00:38, 148.57it/s]Running 10000 simulations.:  44%|████▎     | 4363/10000 [00:28<00:37, 150.12it/s]Running 10000 simulations.:  44%|████▍     | 4379/10000 [00:28<00:37, 151.38it/s]Running 10000 simulations.:  44%|████▍     | 4395/10000 [00:28<00:36, 153.25it/s]Running 10000 simulations.:  44%|████▍     | 4411/10000 [00:28<00:36, 153.26it/s]Running 10000 simulations.:  44%|████▍     | 4427/10000 [00:29<00:37, 148.63it/s]Running 10000 simulations.:  44%|████▍     | 4442/10000 [00:29<00:37, 147.90it/s]Running 10000 simulations.:  45%|████▍     | 4457/10000 [00:29<00:37, 147.97it/s]Running 10000 simulations.:  45%|████▍     | 4473/10000 [00:29<00:37, 149.03it/s]Running 10000 simulations.:  45%|████▍     | 4489/10000 [00:29<00:36, 150.22it/s]Running 10000 simulations.:  45%|████▌     | 4505/10000 [00:29<00:36, 151.07it/s]Running 10000 simulations.:  45%|████▌     | 4521/10000 [00:29<00:36, 151.63it/s]Running 10000 simulations.:  45%|████▌     | 4537/10000 [00:29<00:36, 150.67it/s]Running 10000 simulations.:  46%|████▌     | 4553/10000 [00:29<00:36, 147.94it/s]Running 10000 simulations.:  46%|████▌     | 4568/10000 [00:30<00:36, 146.90it/s]Running 10000 simulations.:  46%|████▌     | 4584/10000 [00:30<00:36, 147.91it/s]Running 10000 simulations.:  46%|████▌     | 4600/10000 [00:30<00:36, 148.72it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:30<00:35, 149.95it/s]Running 10000 simulations.:  46%|████▋     | 4632/10000 [00:30<00:35, 151.14it/s]Running 10000 simulations.:  46%|████▋     | 4648/10000 [00:30<00:35, 150.86it/s]Running 10000 simulations.:  47%|████▋     | 4664/10000 [00:30<00:35, 148.50it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:30<00:36, 147.46it/s]Running 10000 simulations.:  47%|████▋     | 4694/10000 [00:30<00:35, 148.02it/s]Running 10000 simulations.:  47%|████▋     | 4710/10000 [00:30<00:35, 149.19it/s]Running 10000 simulations.:  47%|████▋     | 4726/10000 [00:31<00:35, 150.48it/s]Running 10000 simulations.:  47%|████▋     | 4742/10000 [00:31<00:34, 150.46it/s]Running 10000 simulations.:  48%|████▊     | 4758/10000 [00:31<00:34, 150.44it/s]Running 10000 simulations.:  48%|████▊     | 4774/10000 [00:31<00:34, 151.41it/s]Running 10000 simulations.:  48%|████▊     | 4790/10000 [00:31<00:34, 152.20it/s]Running 10000 simulations.:  48%|████▊     | 4806/10000 [00:31<00:34, 150.18it/s]Running 10000 simulations.:  48%|████▊     | 4822/10000 [00:31<00:35, 147.87it/s]Running 10000 simulations.:  48%|████▊     | 4837/10000 [00:31<00:35, 147.39it/s]Running 10000 simulations.:  49%|████▊     | 4854/10000 [00:31<00:33, 153.13it/s]Running 10000 simulations.:  49%|████▊     | 4872/10000 [00:32<00:32, 158.91it/s]Running 10000 simulations.:  49%|████▉     | 4888/10000 [00:32<00:32, 156.63it/s]Running 10000 simulations.:  49%|████▉     | 4904/10000 [00:32<00:32, 156.13it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:32<00:32, 154.74it/s]Running 10000 simulations.:  49%|████▉     | 4936/10000 [00:32<00:33, 151.73it/s]Running 10000 simulations.:  50%|████▉     | 4952/10000 [00:32<00:33, 149.42it/s]Running 10000 simulations.:  50%|████▉     | 4967/10000 [00:32<00:33, 149.16it/s]Running 10000 simulations.:  50%|████▉     | 4983/10000 [00:32<00:33, 150.27it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:32<00:33, 150.89it/s]Running 10000 simulations.:  50%|█████     | 5015/10000 [00:33<00:32, 151.21it/s]Running 10000 simulations.:  50%|█████     | 5031/10000 [00:33<00:32, 151.58it/s]Running 10000 simulations.:  50%|█████     | 5047/10000 [00:33<00:33, 149.95it/s]Running 10000 simulations.:  51%|█████     | 5063/10000 [00:33<00:33, 147.92it/s]Running 10000 simulations.:  51%|█████     | 5078/10000 [00:33<00:33, 146.82it/s]Running 10000 simulations.:  51%|█████     | 5094/10000 [00:33<00:33, 148.44it/s]Running 10000 simulations.:  51%|█████     | 5110/10000 [00:33<00:32, 149.70it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:33<00:32, 151.15it/s]Running 10000 simulations.:  51%|█████▏    | 5142/10000 [00:33<00:31, 152.36it/s]Running 10000 simulations.:  52%|█████▏    | 5158/10000 [00:33<00:32, 151.09it/s]Running 10000 simulations.:  52%|█████▏    | 5174/10000 [00:34<00:32, 149.09it/s]Running 10000 simulations.:  52%|█████▏    | 5189/10000 [00:34<00:32, 148.30it/s]Running 10000 simulations.:  52%|█████▏    | 5204/10000 [00:34<00:32, 148.57it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:34<00:32, 149.34it/s]Running 10000 simulations.:  52%|█████▏    | 5236/10000 [00:34<00:31, 150.48it/s]Running 10000 simulations.:  53%|█████▎    | 5252/10000 [00:34<00:31, 151.84it/s]Running 10000 simulations.:  53%|█████▎    | 5268/10000 [00:34<00:31, 152.50it/s]Running 10000 simulations.:  53%|█████▎    | 5284/10000 [00:34<00:31, 151.14it/s]Running 10000 simulations.:  53%|█████▎    | 5300/10000 [00:34<00:31, 149.43it/s]Running 10000 simulations.:  53%|█████▎    | 5315/10000 [00:35<00:31, 148.16it/s]Running 10000 simulations.:  53%|█████▎    | 5331/10000 [00:35<00:31, 149.18it/s]Running 10000 simulations.:  53%|█████▎    | 5347/10000 [00:35<00:31, 149.44it/s]Running 10000 simulations.:  54%|█████▎    | 5363/10000 [00:35<00:30, 150.21it/s]Running 10000 simulations.:  54%|█████▍    | 5379/10000 [00:35<00:30, 150.73it/s]Running 10000 simulations.:  54%|█████▍    | 5395/10000 [00:35<00:30, 150.29it/s]Running 10000 simulations.:  54%|█████▍    | 5411/10000 [00:35<00:31, 147.97it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:35<00:31, 146.47it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:35<00:31, 147.05it/s]Running 10000 simulations.:  55%|█████▍    | 5457/10000 [00:35<00:30, 148.22it/s]Running 10000 simulations.:  55%|█████▍    | 5473/10000 [00:36<00:30, 149.33it/s]Running 10000 simulations.:  55%|█████▍    | 5489/10000 [00:36<00:30, 150.21it/s]Running 10000 simulations.:  55%|█████▌    | 5505/10000 [00:36<00:29, 151.02it/s]Running 10000 simulations.:  55%|█████▌    | 5521/10000 [00:36<00:30, 149.04it/s]Running 10000 simulations.:  55%|█████▌    | 5536/10000 [00:36<00:30, 147.49it/s]Running 10000 simulations.:  56%|█████▌    | 5551/10000 [00:36<00:30, 146.70it/s]Running 10000 simulations.:  56%|█████▌    | 5567/10000 [00:36<00:29, 148.10it/s]Running 10000 simulations.:  56%|█████▌    | 5583/10000 [00:36<00:29, 149.01it/s]Running 10000 simulations.:  56%|█████▌    | 5599/10000 [00:36<00:29, 149.87it/s]Running 10000 simulations.:  56%|█████▌    | 5615/10000 [00:37<00:29, 150.86it/s]Running 10000 simulations.:  56%|█████▋    | 5631/10000 [00:37<00:29, 150.10it/s]Running 10000 simulations.:  56%|█████▋    | 5647/10000 [00:37<00:29, 148.19it/s]Running 10000 simulations.:  57%|█████▋    | 5662/10000 [00:37<00:29, 147.71it/s]Running 10000 simulations.:  57%|█████▋    | 5678/10000 [00:37<00:29, 148.64it/s]Running 10000 simulations.:  57%|█████▋    | 5694/10000 [00:37<00:28, 150.09it/s]Running 10000 simulations.:  57%|█████▋    | 5710/10000 [00:37<00:28, 151.28it/s]Running 10000 simulations.:  57%|█████▋    | 5726/10000 [00:37<00:28, 151.49it/s]Running 10000 simulations.:  57%|█████▋    | 5742/10000 [00:37<00:28, 151.59it/s]Running 10000 simulations.:  58%|█████▊    | 5758/10000 [00:37<00:27, 151.78it/s]Running 10000 simulations.:  58%|█████▊    | 5774/10000 [00:38<00:27, 151.85it/s]Running 10000 simulations.:  58%|█████▊    | 5790/10000 [00:38<00:28, 149.03it/s]Running 10000 simulations.:  58%|█████▊    | 5805/10000 [00:38<00:28, 147.50it/s]Running 10000 simulations.:  58%|█████▊    | 5820/10000 [00:38<00:28, 147.11it/s]Running 10000 simulations.:  58%|█████▊    | 5836/10000 [00:38<00:28, 148.09it/s]Running 10000 simulations.:  59%|█████▊    | 5852/10000 [00:38<00:27, 148.98it/s]Running 10000 simulations.:  59%|█████▊    | 5868/10000 [00:38<00:27, 150.45it/s]Running 10000 simulations.:  59%|█████▉    | 5884/10000 [00:38<00:27, 151.69it/s]Running 10000 simulations.:  59%|█████▉    | 5900/10000 [00:38<00:27, 151.72it/s]Running 10000 simulations.:  59%|█████▉    | 5916/10000 [00:39<00:27, 149.21it/s]Running 10000 simulations.:  59%|█████▉    | 5931/10000 [00:39<00:27, 147.51it/s]Running 10000 simulations.:  59%|█████▉    | 5946/10000 [00:39<00:27, 147.76it/s]Running 10000 simulations.:  60%|█████▉    | 5962/10000 [00:39<00:27, 148.92it/s]Running 10000 simulations.:  60%|█████▉    | 5978/10000 [00:39<00:26, 150.34it/s]Running 10000 simulations.:  60%|█████▉    | 5994/10000 [00:39<00:26, 151.81it/s]Running 10000 simulations.:  60%|██████    | 6010/10000 [00:39<00:26, 152.65it/s]Running 10000 simulations.:  60%|██████    | 6026/10000 [00:39<00:26, 150.37it/s]Running 10000 simulations.:  60%|██████    | 6042/10000 [00:39<00:26, 146.86it/s]Running 10000 simulations.:  61%|██████    | 6057/10000 [00:39<00:26, 146.21it/s]Running 10000 simulations.:  61%|██████    | 6073/10000 [00:40<00:26, 147.73it/s]Running 10000 simulations.:  61%|██████    | 6089/10000 [00:40<00:26, 148.94it/s]Running 10000 simulations.:  61%|██████    | 6105/10000 [00:40<00:25, 150.12it/s]Running 10000 simulations.:  61%|██████    | 6121/10000 [00:40<00:25, 151.13it/s]Running 10000 simulations.:  61%|██████▏   | 6137/10000 [00:40<00:25, 149.99it/s]Running 10000 simulations.:  62%|██████▏   | 6153/10000 [00:40<00:26, 147.22it/s]Running 10000 simulations.:  62%|██████▏   | 6168/10000 [00:40<00:26, 145.08it/s]Running 10000 simulations.:  62%|██████▏   | 6183/10000 [00:40<00:26, 144.27it/s]Running 10000 simulations.:  62%|██████▏   | 6198/10000 [00:40<00:26, 145.46it/s]Running 10000 simulations.:  62%|██████▏   | 6214/10000 [00:41<00:25, 147.49it/s]Running 10000 simulations.:  62%|██████▏   | 6230/10000 [00:41<00:25, 149.64it/s]Running 10000 simulations.:  62%|██████▏   | 6246/10000 [00:41<00:24, 151.25it/s]Running 10000 simulations.:  63%|██████▎   | 6262/10000 [00:41<00:25, 148.80it/s]Running 10000 simulations.:  63%|██████▎   | 6277/10000 [00:41<00:25, 146.50it/s]Running 10000 simulations.:  63%|██████▎   | 6292/10000 [00:41<00:25, 144.79it/s]Running 10000 simulations.:  63%|██████▎   | 6307/10000 [00:41<00:25, 144.97it/s]Running 10000 simulations.:  63%|██████▎   | 6323/10000 [00:41<00:25, 146.82it/s]Running 10000 simulations.:  63%|██████▎   | 6339/10000 [00:41<00:24, 148.59it/s]Running 10000 simulations.:  64%|██████▎   | 6355/10000 [00:41<00:24, 150.45it/s]Running 10000 simulations.:  64%|██████▎   | 6371/10000 [00:42<00:24, 150.86it/s]Running 10000 simulations.:  64%|██████▍   | 6387/10000 [00:42<00:24, 147.33it/s]Running 10000 simulations.:  64%|██████▍   | 6402/10000 [00:42<00:24, 145.51it/s]Running 10000 simulations.:  64%|██████▍   | 6417/10000 [00:42<00:24, 145.97it/s]Running 10000 simulations.:  64%|██████▍   | 6433/10000 [00:42<00:24, 147.86it/s]Running 10000 simulations.:  64%|██████▍   | 6449/10000 [00:42<00:23, 148.95it/s]Running 10000 simulations.:  65%|██████▍   | 6465/10000 [00:42<00:23, 150.01it/s]Running 10000 simulations.:  65%|██████▍   | 6481/10000 [00:42<00:23, 150.57it/s]Running 10000 simulations.:  65%|██████▍   | 6497/10000 [00:42<00:23, 150.12it/s]Running 10000 simulations.:  65%|██████▌   | 6513/10000 [00:43<00:23, 148.04it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:43<00:23, 148.09it/s]Running 10000 simulations.:  65%|██████▌   | 6544/10000 [00:43<00:23, 148.80it/s]Running 10000 simulations.:  66%|██████▌   | 6560/10000 [00:43<00:23, 149.51it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:43<00:22, 150.67it/s]Running 10000 simulations.:  66%|██████▌   | 6592/10000 [00:43<00:22, 150.90it/s]Running 10000 simulations.:  66%|██████▌   | 6608/10000 [00:43<00:22, 148.70it/s]Running 10000 simulations.:  66%|██████▌   | 6623/10000 [00:43<00:22, 147.86it/s]Running 10000 simulations.:  66%|██████▋   | 6638/10000 [00:43<00:22, 147.71it/s]Running 10000 simulations.:  67%|██████▋   | 6654/10000 [00:43<00:22, 148.64it/s]Running 10000 simulations.:  67%|██████▋   | 6670/10000 [00:44<00:22, 149.39it/s]Running 10000 simulations.:  67%|██████▋   | 6685/10000 [00:44<00:22, 148.88it/s]Running 10000 simulations.:  67%|██████▋   | 6701/10000 [00:44<00:21, 150.23it/s]Running 10000 simulations.:  67%|██████▋   | 6717/10000 [00:44<00:21, 151.42it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:44<00:21, 152.61it/s]Running 10000 simulations.:  67%|██████▋   | 6749/10000 [00:44<00:21, 151.95it/s]Running 10000 simulations.:  68%|██████▊   | 6765/10000 [00:44<00:21, 149.22it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:44<00:21, 149.41it/s]Running 10000 simulations.:  68%|██████▊   | 6796/10000 [00:44<00:21, 150.39it/s]Running 10000 simulations.:  68%|██████▊   | 6812/10000 [00:45<00:21, 150.88it/s]Running 10000 simulations.:  68%|██████▊   | 6828/10000 [00:45<00:20, 151.73it/s]Running 10000 simulations.:  68%|██████▊   | 6844/10000 [00:45<00:20, 152.38it/s]Running 10000 simulations.:  69%|██████▊   | 6860/10000 [00:45<00:20, 150.62it/s]Running 10000 simulations.:  69%|██████▉   | 6876/10000 [00:45<00:20, 149.62it/s]Running 10000 simulations.:  69%|██████▉   | 6892/10000 [00:45<00:20, 149.82it/s]Running 10000 simulations.:  69%|██████▉   | 6908/10000 [00:45<00:20, 150.58it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:45<00:20, 150.93it/s]Running 10000 simulations.:  69%|██████▉   | 6940/10000 [00:45<00:20, 151.30it/s]Running 10000 simulations.:  70%|██████▉   | 6956/10000 [00:46<00:20, 149.71it/s]Running 10000 simulations.:  70%|██████▉   | 6971/10000 [00:46<00:20, 148.49it/s]Running 10000 simulations.:  70%|██████▉   | 6986/10000 [00:46<00:20, 147.26it/s]Running 10000 simulations.:  70%|███████   | 7002/10000 [00:46<00:20, 148.34it/s]Running 10000 simulations.:  70%|███████   | 7018/10000 [00:46<00:19, 149.19it/s]Running 10000 simulations.:  70%|███████   | 7034/10000 [00:46<00:19, 149.97it/s]Running 10000 simulations.:  70%|███████   | 7050/10000 [00:46<00:19, 150.91it/s]Running 10000 simulations.:  71%|███████   | 7066/10000 [00:46<00:19, 151.15it/s]Running 10000 simulations.:  71%|███████   | 7082/10000 [00:46<00:19, 148.73it/s]Running 10000 simulations.:  71%|███████   | 7097/10000 [00:46<00:19, 147.55it/s]Running 10000 simulations.:  71%|███████   | 7112/10000 [00:47<00:19, 147.69it/s]Running 10000 simulations.:  71%|███████▏  | 7128/10000 [00:47<00:19, 148.98it/s]Running 10000 simulations.:  71%|███████▏  | 7144/10000 [00:47<00:19, 150.14it/s]Running 10000 simulations.:  72%|███████▏  | 7160/10000 [00:47<00:18, 151.41it/s]Running 10000 simulations.:  72%|███████▏  | 7176/10000 [00:47<00:18, 151.91it/s]Running 10000 simulations.:  72%|███████▏  | 7192/10000 [00:47<00:18, 149.77it/s]Running 10000 simulations.:  72%|███████▏  | 7207/10000 [00:47<00:18, 149.08it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:47<00:18, 150.03it/s]Running 10000 simulations.:  72%|███████▏  | 7239/10000 [00:47<00:18, 151.10it/s]Running 10000 simulations.:  73%|███████▎  | 7255/10000 [00:47<00:18, 151.71it/s]Running 10000 simulations.:  73%|███████▎  | 7271/10000 [00:48<00:17, 152.78it/s]Running 10000 simulations.:  73%|███████▎  | 7287/10000 [00:48<00:17, 151.93it/s]Running 10000 simulations.:  73%|███████▎  | 7303/10000 [00:48<00:17, 150.26it/s]Running 10000 simulations.:  73%|███████▎  | 7321/10000 [00:48<00:17, 156.03it/s]Running 10000 simulations.:  73%|███████▎  | 7338/10000 [00:48<00:16, 158.90it/s]Running 10000 simulations.:  74%|███████▎  | 7354/10000 [00:48<00:16, 157.07it/s]Running 10000 simulations.:  74%|███████▎  | 7370/10000 [00:48<00:16, 156.44it/s]Running 10000 simulations.:  74%|███████▍  | 7386/10000 [00:48<00:16, 155.55it/s]Running 10000 simulations.:  74%|███████▍  | 7402/10000 [00:48<00:17, 152.28it/s]Running 10000 simulations.:  74%|███████▍  | 7418/10000 [00:49<00:17, 151.33it/s]Running 10000 simulations.:  74%|███████▍  | 7434/10000 [00:49<00:16, 151.97it/s]Running 10000 simulations.:  74%|███████▍  | 7450/10000 [00:49<00:16, 152.42it/s]Running 10000 simulations.:  75%|███████▍  | 7466/10000 [00:49<00:16, 152.01it/s]Running 10000 simulations.:  75%|███████▍  | 7482/10000 [00:49<00:16, 151.40it/s]Running 10000 simulations.:  75%|███████▍  | 7498/10000 [00:49<00:16, 152.06it/s]Running 10000 simulations.:  75%|███████▌  | 7514/10000 [00:49<00:16, 153.06it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:49<00:16, 151.11it/s]Running 10000 simulations.:  75%|███████▌  | 7546/10000 [00:49<00:16, 149.00it/s]Running 10000 simulations.:  76%|███████▌  | 7562/10000 [00:50<00:16, 149.40it/s]Running 10000 simulations.:  76%|███████▌  | 7578/10000 [00:50<00:16, 150.23it/s]Running 10000 simulations.:  76%|███████▌  | 7594/10000 [00:50<00:15, 150.86it/s]Running 10000 simulations.:  76%|███████▌  | 7610/10000 [00:50<00:15, 151.88it/s]Running 10000 simulations.:  76%|███████▋  | 7626/10000 [00:50<00:15, 151.16it/s]Running 10000 simulations.:  76%|███████▋  | 7642/10000 [00:50<00:15, 149.33it/s]Running 10000 simulations.:  77%|███████▋  | 7657/10000 [00:50<00:15, 148.43it/s]Running 10000 simulations.:  77%|███████▋  | 7673/10000 [00:50<00:15, 148.92it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:50<00:15, 149.51it/s]Running 10000 simulations.:  77%|███████▋  | 7705/10000 [00:50<00:15, 150.22it/s]Running 10000 simulations.:  77%|███████▋  | 7721/10000 [00:51<00:15, 150.93it/s]Running 10000 simulations.:  77%|███████▋  | 7737/10000 [00:51<00:14, 151.05it/s]Running 10000 simulations.:  78%|███████▊  | 7753/10000 [00:51<00:15, 140.77it/s]Running 10000 simulations.:  78%|███████▊  | 7768/10000 [00:51<00:15, 142.51it/s]Running 10000 simulations.:  78%|███████▊  | 7784/10000 [00:51<00:15, 145.28it/s]Running 10000 simulations.:  78%|███████▊  | 7800/10000 [00:51<00:14, 147.76it/s]Running 10000 simulations.:  78%|███████▊  | 7816/10000 [00:51<00:14, 149.77it/s]Running 10000 simulations.:  78%|███████▊  | 7832/10000 [00:51<00:14, 150.87it/s]Running 10000 simulations.:  78%|███████▊  | 7848/10000 [00:51<00:14, 149.42it/s]Running 10000 simulations.:  79%|███████▊  | 7863/10000 [00:52<00:14, 148.86it/s]Running 10000 simulations.:  79%|███████▉  | 7879/10000 [00:52<00:14, 149.74it/s]Running 10000 simulations.:  79%|███████▉  | 7895/10000 [00:52<00:14, 150.17it/s]Running 10000 simulations.:  79%|███████▉  | 7911/10000 [00:52<00:13, 150.54it/s]Running 10000 simulations.:  79%|███████▉  | 7927/10000 [00:52<00:13, 151.57it/s]Running 10000 simulations.:  79%|███████▉  | 7943/10000 [00:52<00:13, 151.38it/s]Running 10000 simulations.:  80%|███████▉  | 7959/10000 [00:52<00:13, 149.21it/s]Running 10000 simulations.:  80%|███████▉  | 7974/10000 [00:52<00:13, 149.25it/s]Running 10000 simulations.:  80%|███████▉  | 7990/10000 [00:52<00:13, 149.59it/s]Running 10000 simulations.:  80%|████████  | 8006/10000 [00:52<00:13, 150.20it/s]Running 10000 simulations.:  80%|████████  | 8022/10000 [00:53<00:13, 150.98it/s]Running 10000 simulations.:  80%|████████  | 8038/10000 [00:53<00:12, 151.30it/s]Running 10000 simulations.:  81%|████████  | 8054/10000 [00:53<00:13, 149.24it/s]Running 10000 simulations.:  81%|████████  | 8069/10000 [00:53<00:13, 148.35it/s]Running 10000 simulations.:  81%|████████  | 8085/10000 [00:53<00:12, 149.50it/s]Running 10000 simulations.:  81%|████████  | 8101/10000 [00:53<00:12, 150.02it/s]Running 10000 simulations.:  81%|████████  | 8117/10000 [00:53<00:12, 150.73it/s]Running 10000 simulations.:  81%|████████▏ | 8133/10000 [00:53<00:12, 151.49it/s]Running 10000 simulations.:  81%|████████▏ | 8149/10000 [00:53<00:12, 150.07it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:54<00:12, 148.45it/s]Running 10000 simulations.:  82%|████████▏ | 8180/10000 [00:54<00:12, 147.79it/s]Running 10000 simulations.:  82%|████████▏ | 8196/10000 [00:54<00:12, 148.75it/s]Running 10000 simulations.:  82%|████████▏ | 8212/10000 [00:54<00:11, 149.90it/s]Running 10000 simulations.:  82%|████████▏ | 8228/10000 [00:54<00:11, 150.75it/s]Running 10000 simulations.:  82%|████████▏ | 8244/10000 [00:54<00:11, 152.12it/s]Running 10000 simulations.:  83%|████████▎ | 8260/10000 [00:54<00:11, 152.20it/s]Running 10000 simulations.:  83%|████████▎ | 8276/10000 [00:54<00:11, 149.94it/s]Running 10000 simulations.:  83%|████████▎ | 8292/10000 [00:54<00:11, 150.25it/s]Running 10000 simulations.:  83%|████████▎ | 8308/10000 [00:54<00:11, 151.35it/s]Running 10000 simulations.:  83%|████████▎ | 8324/10000 [00:55<00:11, 151.63it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:55<00:10, 151.31it/s]Running 10000 simulations.:  84%|████████▎ | 8356/10000 [00:55<00:10, 152.48it/s]Running 10000 simulations.:  84%|████████▎ | 8372/10000 [00:55<00:10, 152.59it/s]Running 10000 simulations.:  84%|████████▍ | 8388/10000 [00:55<00:10, 152.38it/s]Running 10000 simulations.:  84%|████████▍ | 8404/10000 [00:55<00:10, 149.88it/s]Running 10000 simulations.:  84%|████████▍ | 8419/10000 [00:55<00:10, 148.55it/s]Running 10000 simulations.:  84%|████████▍ | 8435/10000 [00:55<00:10, 149.26it/s]Running 10000 simulations.:  85%|████████▍ | 8451/10000 [00:55<00:10, 150.22it/s]Running 10000 simulations.:  85%|████████▍ | 8467/10000 [00:56<00:10, 150.60it/s]Running 10000 simulations.:  85%|████████▍ | 8483/10000 [00:56<00:10, 151.11it/s]Running 10000 simulations.:  85%|████████▍ | 8499/10000 [00:56<00:10, 149.68it/s]Running 10000 simulations.:  85%|████████▌ | 8514/10000 [00:56<00:10, 147.89it/s]Running 10000 simulations.:  85%|████████▌ | 8529/10000 [00:56<00:09, 147.46it/s]Running 10000 simulations.:  85%|████████▌ | 8545/10000 [00:56<00:09, 148.34it/s]Running 10000 simulations.:  86%|████████▌ | 8560/10000 [00:56<00:09, 148.78it/s]Running 10000 simulations.:  86%|████████▌ | 8576/10000 [00:56<00:09, 149.51it/s]Running 10000 simulations.:  86%|████████▌ | 8592/10000 [00:56<00:09, 150.56it/s]Running 10000 simulations.:  86%|████████▌ | 8608/10000 [00:56<00:09, 150.93it/s]Running 10000 simulations.:  86%|████████▌ | 8624/10000 [00:57<00:09, 149.46it/s]Running 10000 simulations.:  86%|████████▋ | 8639/10000 [00:57<00:09, 148.95it/s]Running 10000 simulations.:  87%|████████▋ | 8654/10000 [00:57<00:09, 149.13it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [00:57<00:08, 149.69it/s]Running 10000 simulations.:  87%|████████▋ | 8686/10000 [00:57<00:08, 150.80it/s]Running 10000 simulations.:  87%|████████▋ | 8702/10000 [00:57<00:08, 151.14it/s]Running 10000 simulations.:  87%|████████▋ | 8718/10000 [00:57<00:08, 149.04it/s]Running 10000 simulations.:  87%|████████▋ | 8733/10000 [00:57<00:08, 148.22it/s]Running 10000 simulations.:  87%|████████▋ | 8749/10000 [00:57<00:08, 148.88it/s]Running 10000 simulations.:  88%|████████▊ | 8765/10000 [00:58<00:08, 149.55it/s]Running 10000 simulations.:  88%|████████▊ | 8781/10000 [00:58<00:08, 151.09it/s]Running 10000 simulations.:  88%|████████▊ | 8797/10000 [00:58<00:07, 151.50it/s]Running 10000 simulations.:  88%|████████▊ | 8813/10000 [00:58<00:07, 149.93it/s]Running 10000 simulations.:  88%|████████▊ | 8829/10000 [00:58<00:07, 148.38it/s]Running 10000 simulations.:  88%|████████▊ | 8845/10000 [00:58<00:07, 149.36it/s]Running 10000 simulations.:  89%|████████▊ | 8861/10000 [00:58<00:07, 150.36it/s]Running 10000 simulations.:  89%|████████▉ | 8877/10000 [00:58<00:07, 150.74it/s]Running 10000 simulations.:  89%|████████▉ | 8893/10000 [00:58<00:07, 151.24it/s]Running 10000 simulations.:  89%|████████▉ | 8909/10000 [00:58<00:07, 150.44it/s]Running 10000 simulations.:  89%|████████▉ | 8925/10000 [00:59<00:07, 148.28it/s]Running 10000 simulations.:  89%|████████▉ | 8940/10000 [00:59<00:07, 147.60it/s]Running 10000 simulations.:  90%|████████▉ | 8956/10000 [00:59<00:07, 148.37it/s]Running 10000 simulations.:  90%|████████▉ | 8971/10000 [00:59<00:06, 148.79it/s]Running 10000 simulations.:  90%|████████▉ | 8987/10000 [00:59<00:06, 149.84it/s]Running 10000 simulations.:  90%|█████████ | 9003/10000 [00:59<00:06, 150.38it/s]Running 10000 simulations.:  90%|█████████ | 9019/10000 [00:59<00:06, 148.36it/s]Running 10000 simulations.:  90%|█████████ | 9034/10000 [00:59<00:06, 147.63it/s]Running 10000 simulations.:  90%|█████████ | 9049/10000 [00:59<00:06, 148.07it/s]Running 10000 simulations.:  91%|█████████ | 9065/10000 [01:00<00:06, 148.78it/s]Running 10000 simulations.:  91%|█████████ | 9081/10000 [01:00<00:06, 149.50it/s]Running 10000 simulations.:  91%|█████████ | 9096/10000 [01:00<00:06, 148.45it/s]Running 10000 simulations.:  91%|█████████ | 9112/10000 [01:00<00:05, 149.22it/s]Running 10000 simulations.:  91%|█████████▏| 9128/10000 [01:00<00:05, 150.22it/s]Running 10000 simulations.:  91%|█████████▏| 9144/10000 [01:00<00:05, 149.01it/s]Running 10000 simulations.:  92%|█████████▏| 9159/10000 [01:00<00:05, 145.02it/s]Running 10000 simulations.:  92%|█████████▏| 9174/10000 [01:00<00:05, 145.35it/s]Running 10000 simulations.:  92%|█████████▏| 9190/10000 [01:00<00:05, 147.07it/s]Running 10000 simulations.:  92%|█████████▏| 9206/10000 [01:00<00:05, 148.68it/s]Running 10000 simulations.:  92%|█████████▏| 9222/10000 [01:01<00:05, 150.12it/s]Running 10000 simulations.:  92%|█████████▏| 9238/10000 [01:01<00:05, 150.73it/s]Running 10000 simulations.:  93%|█████████▎| 9254/10000 [01:01<00:05, 148.17it/s]Running 10000 simulations.:  93%|█████████▎| 9269/10000 [01:01<00:04, 146.86it/s]Running 10000 simulations.:  93%|█████████▎| 9285/10000 [01:01<00:04, 147.99it/s]Running 10000 simulations.:  93%|█████████▎| 9301/10000 [01:01<00:04, 149.24it/s]Running 10000 simulations.:  93%|█████████▎| 9317/10000 [01:01<00:04, 150.04it/s]Running 10000 simulations.:  93%|█████████▎| 9333/10000 [01:01<00:04, 150.58it/s]Running 10000 simulations.:  93%|█████████▎| 9349/10000 [01:01<00:04, 148.45it/s]Running 10000 simulations.:  94%|█████████▎| 9364/10000 [01:02<00:04, 146.03it/s]Running 10000 simulations.:  94%|█████████▍| 9379/10000 [01:02<00:04, 146.88it/s]Running 10000 simulations.:  94%|█████████▍| 9394/10000 [01:02<00:04, 147.67it/s]Running 10000 simulations.:  94%|█████████▍| 9409/10000 [01:02<00:03, 148.22it/s]Running 10000 simulations.:  94%|█████████▍| 9425/10000 [01:02<00:03, 149.34it/s]Running 10000 simulations.:  94%|█████████▍| 9440/10000 [01:02<00:03, 148.88it/s]Running 10000 simulations.:  95%|█████████▍| 9455/10000 [01:02<00:03, 146.35it/s]Running 10000 simulations.:  95%|█████████▍| 9470/10000 [01:02<00:03, 145.85it/s]Running 10000 simulations.:  95%|█████████▍| 9485/10000 [01:02<00:03, 146.81it/s]Running 10000 simulations.:  95%|█████████▌| 9500/10000 [01:02<00:03, 147.63it/s]Running 10000 simulations.:  95%|█████████▌| 9516/10000 [01:03<00:03, 148.40it/s]Running 10000 simulations.:  95%|█████████▌| 9532/10000 [01:03<00:03, 150.93it/s]Running 10000 simulations.:  95%|█████████▌| 9549/10000 [01:03<00:02, 154.58it/s]Running 10000 simulations.:  96%|█████████▌| 9565/10000 [01:03<00:02, 153.79it/s]Running 10000 simulations.:  96%|█████████▌| 9581/10000 [01:03<00:02, 151.98it/s]Running 10000 simulations.:  96%|█████████▌| 9597/10000 [01:03<00:02, 150.82it/s]Running 10000 simulations.:  96%|█████████▌| 9613/10000 [01:03<00:02, 151.13it/s]Running 10000 simulations.:  96%|█████████▋| 9629/10000 [01:03<00:02, 151.72it/s]Running 10000 simulations.:  96%|█████████▋| 9645/10000 [01:03<00:02, 151.02it/s]Running 10000 simulations.:  97%|█████████▋| 9661/10000 [01:04<00:02, 148.44it/s]Running 10000 simulations.:  97%|█████████▋| 9676/10000 [01:04<00:02, 146.75it/s]Running 10000 simulations.:  97%|█████████▋| 9691/10000 [01:04<00:02, 145.91it/s]Running 10000 simulations.:  97%|█████████▋| 9706/10000 [01:04<00:02, 146.95it/s]Running 10000 simulations.:  97%|█████████▋| 9721/10000 [01:04<00:01, 147.29it/s]Running 10000 simulations.:  97%|█████████▋| 9736/10000 [01:04<00:01, 148.02it/s]Running 10000 simulations.:  98%|█████████▊| 9752/10000 [01:04<00:01, 149.17it/s]Running 10000 simulations.:  98%|█████████▊| 9767/10000 [01:04<00:01, 148.85it/s]Running 10000 simulations.:  98%|█████████▊| 9782/10000 [01:04<00:01, 146.51it/s]Running 10000 simulations.:  98%|█████████▊| 9797/10000 [01:04<00:01, 146.61it/s]Running 10000 simulations.:  98%|█████████▊| 9813/10000 [01:05<00:01, 147.72it/s]Running 10000 simulations.:  98%|█████████▊| 9829/10000 [01:05<00:01, 148.64it/s]Running 10000 simulations.:  98%|█████████▊| 9845/10000 [01:05<00:01, 149.14it/s]Running 10000 simulations.:  99%|█████████▊| 9861/10000 [01:05<00:00, 149.63it/s]Running 10000 simulations.:  99%|█████████▉| 9876/10000 [01:05<00:00, 147.08it/s]Running 10000 simulations.:  99%|█████████▉| 9891/10000 [01:05<00:00, 145.34it/s]Running 10000 simulations.:  99%|█████████▉| 9906/10000 [01:05<00:00, 144.74it/s]Running 10000 simulations.:  99%|█████████▉| 9922/10000 [01:05<00:00, 146.43it/s]Running 10000 simulations.:  99%|█████████▉| 9938/10000 [01:05<00:00, 147.90it/s]Running 10000 simulations.: 100%|█████████▉| 9953/10000 [01:06<00:00, 147.57it/s]Running 10000 simulations.: 100%|█████████▉| 9968/10000 [01:06<00:00, 147.92it/s]Running 10000 simulations.: 100%|█████████▉| 9984/10000 [01:06<00:00, 148.92it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:06<00:00, 149.87it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:06<00:00, 150.74it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 16/10000 [00:00<01:02, 159.75it/s]Running 10000 simulations.:   0%|          | 32/10000 [00:00<01:02, 159.65it/s]Running 10000 simulations.:   0%|          | 49/10000 [00:00<01:02, 160.00it/s]Running 10000 simulations.:   1%|          | 66/10000 [00:00<01:02, 160.01it/s]Running 10000 simulations.:   1%|          | 83/10000 [00:00<01:01, 160.10it/s]Running 10000 simulations.:   1%|          | 100/10000 [00:00<01:01, 160.23it/s]Running 10000 simulations.:   1%|          | 116/10000 [00:00<01:01, 159.84it/s]Running 10000 simulations.:   1%|▏         | 132/10000 [00:00<01:01, 159.79it/s]Running 10000 simulations.:   1%|▏         | 149/10000 [00:00<01:01, 159.81it/s]Running 10000 simulations.:   2%|▏         | 165/10000 [00:01<01:01, 159.39it/s]Running 10000 simulations.:   2%|▏         | 181/10000 [00:01<01:01, 159.51it/s]Running 10000 simulations.:   2%|▏         | 197/10000 [00:01<01:01, 159.10it/s]Running 10000 simulations.:   2%|▏         | 214/10000 [00:01<01:01, 159.44it/s]Running 10000 simulations.:   2%|▏         | 230/10000 [00:01<01:01, 159.34it/s]Running 10000 simulations.:   2%|▏         | 246/10000 [00:01<01:01, 159.03it/s]Running 10000 simulations.:   3%|▎         | 262/10000 [00:01<01:01, 159.00it/s]Running 10000 simulations.:   3%|▎         | 279/10000 [00:01<01:00, 159.41it/s]Running 10000 simulations.:   3%|▎         | 295/10000 [00:01<01:01, 159.09it/s]Running 10000 simulations.:   3%|▎         | 313/10000 [00:01<00:58, 164.27it/s]Running 10000 simulations.:   3%|▎         | 331/10000 [00:02<00:57, 167.61it/s]Running 10000 simulations.:   3%|▎         | 348/10000 [00:02<00:58, 164.92it/s]Running 10000 simulations.:   4%|▎         | 365/10000 [00:02<00:58, 163.31it/s]Running 10000 simulations.:   4%|▍         | 382/10000 [00:02<00:59, 161.79it/s]Running 10000 simulations.:   4%|▍         | 399/10000 [00:02<00:59, 160.70it/s]Running 10000 simulations.:   4%|▍         | 416/10000 [00:02<00:59, 160.31it/s]Running 10000 simulations.:   4%|▍         | 433/10000 [00:02<00:59, 160.11it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:02<00:59, 159.58it/s]Running 10000 simulations.:   5%|▍         | 466/10000 [00:02<00:59, 159.15it/s]Running 10000 simulations.:   5%|▍         | 482/10000 [00:03<00:59, 159.30it/s]Running 10000 simulations.:   5%|▍         | 498/10000 [00:03<00:59, 159.48it/s]Running 10000 simulations.:   5%|▌         | 514/10000 [00:03<00:59, 159.56it/s]Running 10000 simulations.:   5%|▌         | 530/10000 [00:03<00:59, 159.44it/s]Running 10000 simulations.:   5%|▌         | 546/10000 [00:03<00:59, 159.15it/s]Running 10000 simulations.:   6%|▌         | 562/10000 [00:03<00:59, 159.39it/s]Running 10000 simulations.:   6%|▌         | 578/10000 [00:03<00:59, 159.04it/s]Running 10000 simulations.:   6%|▌         | 594/10000 [00:03<00:59, 159.03it/s]Running 10000 simulations.:   6%|▌         | 610/10000 [00:03<00:59, 158.91it/s]Running 10000 simulations.:   6%|▋         | 626/10000 [00:03<00:59, 158.36it/s]Running 10000 simulations.:   6%|▋         | 642/10000 [00:04<00:59, 158.28it/s]Running 10000 simulations.:   7%|▋         | 658/10000 [00:04<00:59, 158.00it/s]Running 10000 simulations.:   7%|▋         | 674/10000 [00:04<00:59, 157.93it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:04<00:58, 157.83it/s]Running 10000 simulations.:   7%|▋         | 706/10000 [00:04<00:58, 157.77it/s]Running 10000 simulations.:   7%|▋         | 723/10000 [00:04<00:58, 158.36it/s]Running 10000 simulations.:   7%|▋         | 739/10000 [00:04<00:58, 158.52it/s]Running 10000 simulations.:   8%|▊         | 755/10000 [00:04<00:58, 158.50it/s]Running 10000 simulations.:   8%|▊         | 771/10000 [00:04<00:58, 158.25it/s]Running 10000 simulations.:   8%|▊         | 787/10000 [00:04<00:58, 157.86it/s]Running 10000 simulations.:   8%|▊         | 803/10000 [00:05<00:58, 157.83it/s]Running 10000 simulations.:   8%|▊         | 819/10000 [00:05<00:58, 157.28it/s]Running 10000 simulations.:   8%|▊         | 835/10000 [00:05<00:58, 157.04it/s]Running 10000 simulations.:   9%|▊         | 851/10000 [00:05<00:58, 157.25it/s]Running 10000 simulations.:   9%|▊         | 867/10000 [00:05<00:58, 157.29it/s]Running 10000 simulations.:   9%|▉         | 883/10000 [00:05<00:57, 157.27it/s]Running 10000 simulations.:   9%|▉         | 899/10000 [00:05<00:57, 157.86it/s]Running 10000 simulations.:   9%|▉         | 915/10000 [00:05<00:57, 158.27it/s]Running 10000 simulations.:   9%|▉         | 931/10000 [00:05<00:57, 158.08it/s]Running 10000 simulations.:   9%|▉         | 947/10000 [00:05<00:57, 158.35it/s]Running 10000 simulations.:  10%|▉         | 963/10000 [00:06<00:57, 158.47it/s]Running 10000 simulations.:  10%|▉         | 979/10000 [00:06<00:56, 158.70it/s]Running 10000 simulations.:  10%|▉         | 995/10000 [00:06<00:56, 158.65it/s]Running 10000 simulations.:  10%|█         | 1011/10000 [00:06<00:56, 158.65it/s]Running 10000 simulations.:  10%|█         | 1027/10000 [00:06<00:56, 158.87it/s]Running 10000 simulations.:  10%|█         | 1043/10000 [00:06<00:56, 158.87it/s]Running 10000 simulations.:  11%|█         | 1059/10000 [00:06<00:56, 158.75it/s]Running 10000 simulations.:  11%|█         | 1076/10000 [00:06<00:56, 159.22it/s]Running 10000 simulations.:  11%|█         | 1092/10000 [00:06<00:55, 159.18it/s]Running 10000 simulations.:  11%|█         | 1109/10000 [00:06<00:55, 159.51it/s]Running 10000 simulations.:  11%|█▏        | 1125/10000 [00:07<00:55, 159.61it/s]Running 10000 simulations.:  11%|█▏        | 1141/10000 [00:07<00:55, 159.60it/s]Running 10000 simulations.:  12%|█▏        | 1157/10000 [00:07<00:55, 159.30it/s]Running 10000 simulations.:  12%|█▏        | 1173/10000 [00:07<00:55, 158.19it/s]Running 10000 simulations.:  12%|█▏        | 1189/10000 [00:07<00:56, 156.96it/s]Running 10000 simulations.:  12%|█▏        | 1205/10000 [00:07<00:55, 157.42it/s]Running 10000 simulations.:  12%|█▏        | 1221/10000 [00:07<00:55, 157.50it/s]Running 10000 simulations.:  12%|█▏        | 1237/10000 [00:07<00:55, 157.67it/s]Running 10000 simulations.:  13%|█▎        | 1253/10000 [00:07<00:55, 158.18it/s]Running 10000 simulations.:  13%|█▎        | 1269/10000 [00:07<00:55, 158.35it/s]Running 10000 simulations.:  13%|█▎        | 1285/10000 [00:08<00:55, 158.06it/s]Running 10000 simulations.:  13%|█▎        | 1301/10000 [00:08<00:58, 149.52it/s]Running 10000 simulations.:  13%|█▎        | 1317/10000 [00:08<01:23, 103.52it/s]Running 10000 simulations.:  13%|█▎        | 1333/10000 [00:08<01:15, 115.34it/s]Running 10000 simulations.:  13%|█▎        | 1349/10000 [00:08<01:08, 125.53it/s]Running 10000 simulations.:  14%|█▎        | 1365/10000 [00:08<01:04, 133.68it/s]Running 10000 simulations.:  14%|█▍        | 1381/10000 [00:08<01:01, 140.29it/s]Running 10000 simulations.:  14%|█▍        | 1397/10000 [00:08<00:59, 145.19it/s]Running 10000 simulations.:  14%|█▍        | 1413/10000 [00:09<00:57, 149.00it/s]Running 10000 simulations.:  14%|█▍        | 1429/10000 [00:09<00:56, 151.87it/s]Running 10000 simulations.:  14%|█▍        | 1445/10000 [00:09<00:55, 153.86it/s]Running 10000 simulations.:  15%|█▍        | 1461/10000 [00:09<00:55, 155.14it/s]Running 10000 simulations.:  15%|█▍        | 1477/10000 [00:09<00:54, 156.13it/s]Running 10000 simulations.:  15%|█▍        | 1493/10000 [00:09<00:54, 156.82it/s]Running 10000 simulations.:  15%|█▌        | 1509/10000 [00:09<00:53, 157.39it/s]Running 10000 simulations.:  15%|█▌        | 1525/10000 [00:09<00:53, 157.63it/s]Running 10000 simulations.:  15%|█▌        | 1541/10000 [00:09<00:53, 157.41it/s]Running 10000 simulations.:  16%|█▌        | 1557/10000 [00:09<00:53, 157.54it/s]Running 10000 simulations.:  16%|█▌        | 1573/10000 [00:10<00:53, 157.67it/s]Running 10000 simulations.:  16%|█▌        | 1589/10000 [00:10<00:53, 158.10it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:10<00:53, 158.31it/s]Running 10000 simulations.:  16%|█▌        | 1621/10000 [00:10<00:53, 157.88it/s]Running 10000 simulations.:  16%|█▋        | 1637/10000 [00:10<00:52, 157.99it/s]Running 10000 simulations.:  17%|█▋        | 1653/10000 [00:10<00:52, 158.16it/s]Running 10000 simulations.:  17%|█▋        | 1669/10000 [00:10<00:52, 158.46it/s]Running 10000 simulations.:  17%|█▋        | 1685/10000 [00:10<00:52, 158.57it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:10<00:52, 158.38it/s]Running 10000 simulations.:  17%|█▋        | 1717/10000 [00:10<00:52, 158.32it/s]Running 10000 simulations.:  17%|█▋        | 1733/10000 [00:11<00:52, 158.21it/s]Running 10000 simulations.:  17%|█▋        | 1749/10000 [00:11<00:52, 158.21it/s]Running 10000 simulations.:  18%|█▊        | 1765/10000 [00:11<00:52, 158.09it/s]Running 10000 simulations.:  18%|█▊        | 1781/10000 [00:11<00:51, 158.29it/s]Running 10000 simulations.:  18%|█▊        | 1797/10000 [00:11<00:51, 158.23it/s]Running 10000 simulations.:  18%|█▊        | 1813/10000 [00:11<00:51, 158.43it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:11<00:51, 158.29it/s]Running 10000 simulations.:  18%|█▊        | 1845/10000 [00:11<00:51, 158.13it/s]Running 10000 simulations.:  19%|█▊        | 1861/10000 [00:11<00:51, 157.83it/s]Running 10000 simulations.:  19%|█▉        | 1877/10000 [00:12<00:51, 157.88it/s]Running 10000 simulations.:  19%|█▉        | 1893/10000 [00:12<00:51, 157.95it/s]Running 10000 simulations.:  19%|█▉        | 1910/10000 [00:12<00:50, 158.74it/s]Running 10000 simulations.:  19%|█▉        | 1926/10000 [00:12<00:50, 158.42it/s]Running 10000 simulations.:  19%|█▉        | 1942/10000 [00:12<00:50, 158.27it/s]Running 10000 simulations.:  20%|█▉        | 1958/10000 [00:12<00:50, 158.20it/s]Running 10000 simulations.:  20%|█▉        | 1974/10000 [00:12<00:50, 158.17it/s]Running 10000 simulations.:  20%|█▉        | 1990/10000 [00:12<00:50, 158.26it/s]Running 10000 simulations.:  20%|██        | 2006/10000 [00:12<00:50, 157.91it/s]Running 10000 simulations.:  20%|██        | 2022/10000 [00:12<00:50, 158.06it/s]Running 10000 simulations.:  20%|██        | 2038/10000 [00:13<00:50, 158.35it/s]Running 10000 simulations.:  21%|██        | 2054/10000 [00:13<00:50, 158.26it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:13<00:50, 158.18it/s]Running 10000 simulations.:  21%|██        | 2086/10000 [00:13<00:50, 158.04it/s]Running 10000 simulations.:  21%|██        | 2102/10000 [00:13<00:49, 158.25it/s]Running 10000 simulations.:  21%|██        | 2118/10000 [00:13<00:49, 158.34it/s]Running 10000 simulations.:  21%|██▏       | 2134/10000 [00:13<00:49, 158.32it/s]Running 10000 simulations.:  22%|██▏       | 2150/10000 [00:13<00:49, 158.22it/s]Running 10000 simulations.:  22%|██▏       | 2166/10000 [00:13<00:49, 158.10it/s]Running 10000 simulations.:  22%|██▏       | 2182/10000 [00:13<00:49, 158.01it/s]Running 10000 simulations.:  22%|██▏       | 2198/10000 [00:14<00:49, 157.83it/s]Running 10000 simulations.:  22%|██▏       | 2214/10000 [00:14<00:49, 157.83it/s]Running 10000 simulations.:  22%|██▏       | 2230/10000 [00:14<00:49, 158.04it/s]Running 10000 simulations.:  22%|██▏       | 2246/10000 [00:14<00:49, 157.98it/s]Running 10000 simulations.:  23%|██▎       | 2262/10000 [00:14<00:48, 158.08it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:14<00:48, 158.00it/s]Running 10000 simulations.:  23%|██▎       | 2294/10000 [00:14<00:48, 157.92it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:14<00:48, 158.13it/s]Running 10000 simulations.:  23%|██▎       | 2326/10000 [00:14<00:48, 158.33it/s]Running 10000 simulations.:  23%|██▎       | 2342/10000 [00:14<00:48, 158.32it/s]Running 10000 simulations.:  24%|██▎       | 2358/10000 [00:15<00:48, 158.33it/s]Running 10000 simulations.:  24%|██▍       | 2376/10000 [00:15<00:46, 162.62it/s]Running 10000 simulations.:  24%|██▍       | 2394/10000 [00:15<00:45, 167.07it/s]Running 10000 simulations.:  24%|██▍       | 2411/10000 [00:15<00:46, 164.52it/s]Running 10000 simulations.:  24%|██▍       | 2428/10000 [00:15<00:46, 162.44it/s]Running 10000 simulations.:  24%|██▍       | 2445/10000 [00:15<00:46, 161.27it/s]Running 10000 simulations.:  25%|██▍       | 2462/10000 [00:15<00:46, 160.40it/s]Running 10000 simulations.:  25%|██▍       | 2479/10000 [00:15<00:47, 159.72it/s]Running 10000 simulations.:  25%|██▍       | 2495/10000 [00:15<00:47, 157.95it/s]Running 10000 simulations.:  25%|██▌       | 2511/10000 [00:15<00:47, 156.46it/s]Running 10000 simulations.:  25%|██▌       | 2527/10000 [00:16<00:47, 156.89it/s]Running 10000 simulations.:  25%|██▌       | 2543/10000 [00:16<00:47, 157.29it/s]Running 10000 simulations.:  26%|██▌       | 2559/10000 [00:16<00:47, 157.48it/s]Running 10000 simulations.:  26%|██▌       | 2575/10000 [00:16<00:48, 154.62it/s]Running 10000 simulations.:  26%|██▌       | 2591/10000 [00:16<00:47, 155.44it/s]Running 10000 simulations.:  26%|██▌       | 2607/10000 [00:16<00:47, 156.18it/s]Running 10000 simulations.:  26%|██▌       | 2623/10000 [00:16<00:47, 156.77it/s]Running 10000 simulations.:  26%|██▋       | 2639/10000 [00:16<00:46, 157.36it/s]Running 10000 simulations.:  27%|██▋       | 2655/10000 [00:16<00:46, 157.75it/s]Running 10000 simulations.:  27%|██▋       | 2671/10000 [00:17<00:46, 158.13it/s]Running 10000 simulations.:  27%|██▋       | 2687/10000 [00:17<00:46, 158.19it/s]Running 10000 simulations.:  27%|██▋       | 2703/10000 [00:17<00:46, 158.12it/s]Running 10000 simulations.:  27%|██▋       | 2719/10000 [00:17<00:46, 158.06it/s]Running 10000 simulations.:  27%|██▋       | 2735/10000 [00:17<00:45, 158.04it/s]Running 10000 simulations.:  28%|██▊       | 2751/10000 [00:17<00:45, 157.75it/s]Running 10000 simulations.:  28%|██▊       | 2767/10000 [00:17<00:45, 157.91it/s]Running 10000 simulations.:  28%|██▊       | 2783/10000 [00:17<00:45, 157.88it/s]Running 10000 simulations.:  28%|██▊       | 2799/10000 [00:17<00:45, 158.16it/s]Running 10000 simulations.:  28%|██▊       | 2815/10000 [00:17<00:45, 158.01it/s]Running 10000 simulations.:  28%|██▊       | 2831/10000 [00:18<00:45, 157.87it/s]Running 10000 simulations.:  28%|██▊       | 2847/10000 [00:18<00:45, 158.02it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:18<00:45, 158.08it/s]Running 10000 simulations.:  29%|██▉       | 2879/10000 [00:18<00:45, 157.98it/s]Running 10000 simulations.:  29%|██▉       | 2895/10000 [00:18<00:44, 158.09it/s]Running 10000 simulations.:  29%|██▉       | 2911/10000 [00:18<00:44, 157.68it/s]Running 10000 simulations.:  29%|██▉       | 2927/10000 [00:18<00:44, 157.97it/s]Running 10000 simulations.:  29%|██▉       | 2943/10000 [00:18<00:44, 157.84it/s]Running 10000 simulations.:  30%|██▉       | 2959/10000 [00:18<00:44, 157.99it/s]Running 10000 simulations.:  30%|██▉       | 2975/10000 [00:18<00:44, 157.97it/s]Running 10000 simulations.:  30%|██▉       | 2991/10000 [00:19<00:44, 157.96it/s]Running 10000 simulations.:  30%|███       | 3007/10000 [00:19<00:44, 157.70it/s]Running 10000 simulations.:  30%|███       | 3023/10000 [00:19<00:44, 157.84it/s]Running 10000 simulations.:  30%|███       | 3039/10000 [00:19<00:44, 157.89it/s]Running 10000 simulations.:  31%|███       | 3055/10000 [00:19<00:44, 157.79it/s]Running 10000 simulations.:  31%|███       | 3071/10000 [00:19<00:43, 157.83it/s]Running 10000 simulations.:  31%|███       | 3087/10000 [00:19<00:43, 157.93it/s]Running 10000 simulations.:  31%|███       | 3103/10000 [00:19<00:43, 157.97it/s]Running 10000 simulations.:  31%|███       | 3119/10000 [00:19<00:43, 158.08it/s]Running 10000 simulations.:  31%|███▏      | 3135/10000 [00:19<00:43, 158.05it/s]Running 10000 simulations.:  32%|███▏      | 3151/10000 [00:20<00:43, 158.10it/s]Running 10000 simulations.:  32%|███▏      | 3167/10000 [00:20<00:43, 157.85it/s]Running 10000 simulations.:  32%|███▏      | 3183/10000 [00:20<00:43, 157.72it/s]Running 10000 simulations.:  32%|███▏      | 3199/10000 [00:20<00:43, 158.16it/s]Running 10000 simulations.:  32%|███▏      | 3215/10000 [00:20<00:42, 157.82it/s]Running 10000 simulations.:  32%|███▏      | 3231/10000 [00:20<00:42, 157.50it/s]Running 10000 simulations.:  32%|███▏      | 3247/10000 [00:20<00:42, 157.73it/s]Running 10000 simulations.:  33%|███▎      | 3263/10000 [00:20<00:42, 157.89it/s]Running 10000 simulations.:  33%|███▎      | 3279/10000 [00:20<00:42, 157.56it/s]Running 10000 simulations.:  33%|███▎      | 3295/10000 [00:20<00:42, 157.60it/s]Running 10000 simulations.:  33%|███▎      | 3311/10000 [00:21<00:42, 157.75it/s]Running 10000 simulations.:  33%|███▎      | 3327/10000 [00:21<00:42, 157.87it/s]Running 10000 simulations.:  33%|███▎      | 3343/10000 [00:21<00:42, 157.74it/s]Running 10000 simulations.:  34%|███▎      | 3359/10000 [00:21<00:42, 157.45it/s]Running 10000 simulations.:  34%|███▍      | 3375/10000 [00:21<00:42, 157.38it/s]Running 10000 simulations.:  34%|███▍      | 3391/10000 [00:21<00:41, 157.50it/s]Running 10000 simulations.:  34%|███▍      | 3407/10000 [00:21<00:41, 157.73it/s]Running 10000 simulations.:  34%|███▍      | 3423/10000 [00:21<00:41, 157.54it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:21<00:41, 157.69it/s]Running 10000 simulations.:  35%|███▍      | 3455/10000 [00:21<00:41, 157.76it/s]Running 10000 simulations.:  35%|███▍      | 3471/10000 [00:22<00:41, 157.27it/s]Running 10000 simulations.:  35%|███▍      | 3487/10000 [00:22<00:41, 157.18it/s]Running 10000 simulations.:  35%|███▌      | 3503/10000 [00:22<00:41, 157.03it/s]Running 10000 simulations.:  35%|███▌      | 3519/10000 [00:22<00:41, 156.80it/s]Running 10000 simulations.:  35%|███▌      | 3535/10000 [00:22<00:41, 156.70it/s]Running 10000 simulations.:  36%|███▌      | 3551/10000 [00:22<00:41, 156.44it/s]Running 10000 simulations.:  36%|███▌      | 3567/10000 [00:22<00:41, 156.81it/s]Running 10000 simulations.:  36%|███▌      | 3583/10000 [00:22<00:40, 156.65it/s]Running 10000 simulations.:  36%|███▌      | 3599/10000 [00:22<00:40, 156.65it/s]Running 10000 simulations.:  36%|███▌      | 3615/10000 [00:22<00:40, 157.08it/s]Running 10000 simulations.:  36%|███▋      | 3631/10000 [00:23<00:40, 156.73it/s]Running 10000 simulations.:  36%|███▋      | 3647/10000 [00:23<00:40, 156.66it/s]Running 10000 simulations.:  37%|███▋      | 3663/10000 [00:23<00:40, 156.95it/s]Running 10000 simulations.:  37%|███▋      | 3679/10000 [00:23<00:40, 157.14it/s]Running 10000 simulations.:  37%|███▋      | 3695/10000 [00:23<00:40, 157.22it/s]Running 10000 simulations.:  37%|███▋      | 3711/10000 [00:23<00:40, 157.13it/s]Running 10000 simulations.:  37%|███▋      | 3727/10000 [00:23<00:40, 154.97it/s]Running 10000 simulations.:  37%|███▋      | 3743/10000 [00:23<00:40, 155.49it/s]Running 10000 simulations.:  38%|███▊      | 3759/10000 [00:23<00:39, 156.07it/s]Running 10000 simulations.:  38%|███▊      | 3775/10000 [00:24<00:39, 156.60it/s]Running 10000 simulations.:  38%|███▊      | 3791/10000 [00:24<00:39, 156.89it/s]Running 10000 simulations.:  38%|███▊      | 3807/10000 [00:24<00:39, 156.97it/s]Running 10000 simulations.:  38%|███▊      | 3823/10000 [00:24<00:39, 156.85it/s]Running 10000 simulations.:  38%|███▊      | 3839/10000 [00:24<00:39, 156.87it/s]Running 10000 simulations.:  39%|███▊      | 3855/10000 [00:24<00:39, 156.91it/s]Running 10000 simulations.:  39%|███▊      | 3871/10000 [00:24<00:38, 157.62it/s]Running 10000 simulations.:  39%|███▉      | 3887/10000 [00:24<00:38, 157.83it/s]Running 10000 simulations.:  39%|███▉      | 3903/10000 [00:24<00:38, 157.66it/s]Running 10000 simulations.:  39%|███▉      | 3919/10000 [00:24<00:38, 157.61it/s]Running 10000 simulations.:  39%|███▉      | 3935/10000 [00:25<00:38, 157.92it/s]Running 10000 simulations.:  40%|███▉      | 3951/10000 [00:25<00:38, 157.46it/s]Running 10000 simulations.:  40%|███▉      | 3967/10000 [00:25<00:38, 157.43it/s]Running 10000 simulations.:  40%|███▉      | 3983/10000 [00:25<00:38, 157.39it/s]Running 10000 simulations.:  40%|███▉      | 3999/10000 [00:25<00:38, 157.48it/s]Running 10000 simulations.:  40%|████      | 4015/10000 [00:25<00:37, 157.63it/s]Running 10000 simulations.:  40%|████      | 4031/10000 [00:25<00:37, 157.56it/s]Running 10000 simulations.:  40%|████      | 4047/10000 [00:25<00:37, 157.65it/s]Running 10000 simulations.:  41%|████      | 4063/10000 [00:25<00:37, 157.42it/s]Running 10000 simulations.:  41%|████      | 4079/10000 [00:25<00:37, 157.30it/s]Running 10000 simulations.:  41%|████      | 4095/10000 [00:26<00:37, 157.36it/s]Running 10000 simulations.:  41%|████      | 4111/10000 [00:26<00:37, 157.23it/s]Running 10000 simulations.:  41%|████▏     | 4127/10000 [00:26<00:37, 157.34it/s]Running 10000 simulations.:  41%|████▏     | 4143/10000 [00:26<00:37, 157.48it/s]Running 10000 simulations.:  42%|████▏     | 4159/10000 [00:26<00:37, 157.31it/s]Running 10000 simulations.:  42%|████▏     | 4175/10000 [00:26<00:37, 157.22it/s]Running 10000 simulations.:  42%|████▏     | 4191/10000 [00:26<00:36, 157.25it/s]Running 10000 simulations.:  42%|████▏     | 4207/10000 [00:26<00:36, 157.36it/s]Running 10000 simulations.:  42%|████▏     | 4223/10000 [00:26<00:36, 157.31it/s]Running 10000 simulations.:  42%|████▏     | 4239/10000 [00:26<00:36, 157.20it/s]Running 10000 simulations.:  43%|████▎     | 4255/10000 [00:27<00:36, 157.02it/s]Running 10000 simulations.:  43%|████▎     | 4271/10000 [00:27<00:36, 156.84it/s]Running 10000 simulations.:  43%|████▎     | 4287/10000 [00:27<00:36, 156.98it/s]Running 10000 simulations.:  43%|████▎     | 4303/10000 [00:27<00:36, 157.17it/s]Running 10000 simulations.:  43%|████▎     | 4319/10000 [00:27<00:36, 157.07it/s]Running 10000 simulations.:  43%|████▎     | 4335/10000 [00:27<00:35, 157.51it/s]Running 10000 simulations.:  44%|████▎     | 4351/10000 [00:27<00:35, 157.23it/s]Running 10000 simulations.:  44%|████▎     | 4367/10000 [00:27<00:35, 157.33it/s]Running 10000 simulations.:  44%|████▍     | 4383/10000 [00:27<00:35, 157.39it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:27<00:35, 157.14it/s]Running 10000 simulations.:  44%|████▍     | 4415/10000 [00:28<00:35, 156.98it/s]Running 10000 simulations.:  44%|████▍     | 4431/10000 [00:28<00:35, 157.01it/s]Running 10000 simulations.:  44%|████▍     | 4447/10000 [00:28<00:35, 156.84it/s]Running 10000 simulations.:  45%|████▍     | 4463/10000 [00:28<00:35, 156.79it/s]Running 10000 simulations.:  45%|████▍     | 4479/10000 [00:28<00:35, 157.04it/s]Running 10000 simulations.:  45%|████▍     | 4495/10000 [00:28<00:35, 157.07it/s]Running 10000 simulations.:  45%|████▌     | 4511/10000 [00:28<00:34, 157.13it/s]Running 10000 simulations.:  45%|████▌     | 4527/10000 [00:28<00:34, 157.51it/s]Running 10000 simulations.:  45%|████▌     | 4543/10000 [00:28<00:34, 157.43it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:29<00:34, 157.38it/s]Running 10000 simulations.:  46%|████▌     | 4575/10000 [00:29<00:34, 157.02it/s]Running 10000 simulations.:  46%|████▌     | 4591/10000 [00:29<00:34, 157.07it/s]Running 10000 simulations.:  46%|████▌     | 4607/10000 [00:29<00:34, 157.20it/s]Running 10000 simulations.:  46%|████▌     | 4623/10000 [00:29<00:34, 157.34it/s]Running 10000 simulations.:  46%|████▋     | 4639/10000 [00:29<00:34, 157.66it/s]Running 10000 simulations.:  47%|████▋     | 4656/10000 [00:29<00:33, 159.47it/s]Running 10000 simulations.:  47%|████▋     | 4675/10000 [00:29<00:32, 165.55it/s]Running 10000 simulations.:  47%|████▋     | 4692/10000 [00:29<00:32, 162.98it/s]Running 10000 simulations.:  47%|████▋     | 4709/10000 [00:29<00:32, 161.10it/s]Running 10000 simulations.:  47%|████▋     | 4726/10000 [00:30<00:32, 159.84it/s]Running 10000 simulations.:  47%|████▋     | 4743/10000 [00:30<00:33, 159.06it/s]Running 10000 simulations.:  48%|████▊     | 4759/10000 [00:30<00:32, 158.93it/s]Running 10000 simulations.:  48%|████▊     | 4775/10000 [00:30<00:32, 158.44it/s]Running 10000 simulations.:  48%|████▊     | 4791/10000 [00:30<00:32, 158.34it/s]Running 10000 simulations.:  48%|████▊     | 4807/10000 [00:30<00:32, 158.17it/s]Running 10000 simulations.:  48%|████▊     | 4823/10000 [00:30<00:32, 157.81it/s]Running 10000 simulations.:  48%|████▊     | 4839/10000 [00:30<00:32, 158.01it/s]Running 10000 simulations.:  49%|████▊     | 4855/10000 [00:30<00:32, 158.09it/s]Running 10000 simulations.:  49%|████▊     | 4871/10000 [00:30<00:32, 157.92it/s]Running 10000 simulations.:  49%|████▉     | 4887/10000 [00:31<00:32, 158.02it/s]Running 10000 simulations.:  49%|████▉     | 4903/10000 [00:31<00:32, 157.96it/s]Running 10000 simulations.:  49%|████▉     | 4919/10000 [00:31<00:32, 157.96it/s]Running 10000 simulations.:  49%|████▉     | 4935/10000 [00:31<00:32, 158.17it/s]Running 10000 simulations.:  50%|████▉     | 4951/10000 [00:31<00:31, 158.00it/s]Running 10000 simulations.:  50%|████▉     | 4967/10000 [00:31<00:31, 157.77it/s]Running 10000 simulations.:  50%|████▉     | 4983/10000 [00:31<00:31, 157.67it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:31<00:31, 157.40it/s]Running 10000 simulations.:  50%|█████     | 5015/10000 [00:31<00:31, 157.27it/s]Running 10000 simulations.:  50%|█████     | 5031/10000 [00:31<00:31, 157.05it/s]Running 10000 simulations.:  50%|█████     | 5047/10000 [00:32<00:31, 156.93it/s]Running 10000 simulations.:  51%|█████     | 5063/10000 [00:32<00:31, 155.75it/s]Running 10000 simulations.:  51%|█████     | 5079/10000 [00:32<00:31, 155.18it/s]Running 10000 simulations.:  51%|█████     | 5095/10000 [00:32<00:31, 155.68it/s]Running 10000 simulations.:  51%|█████     | 5111/10000 [00:32<00:31, 155.98it/s]Running 10000 simulations.:  51%|█████▏    | 5127/10000 [00:32<00:31, 156.16it/s]Running 10000 simulations.:  51%|█████▏    | 5143/10000 [00:32<00:31, 156.60it/s]Running 10000 simulations.:  52%|█████▏    | 5159/10000 [00:32<00:30, 156.61it/s]Running 10000 simulations.:  52%|█████▏    | 5175/10000 [00:32<00:30, 156.85it/s]Running 10000 simulations.:  52%|█████▏    | 5191/10000 [00:33<00:30, 156.96it/s]Running 10000 simulations.:  52%|█████▏    | 5207/10000 [00:33<00:30, 157.03it/s]Running 10000 simulations.:  52%|█████▏    | 5223/10000 [00:33<00:30, 157.00it/s]Running 10000 simulations.:  52%|█████▏    | 5239/10000 [00:33<00:30, 156.90it/s]Running 10000 simulations.:  53%|█████▎    | 5255/10000 [00:33<00:30, 156.82it/s]Running 10000 simulations.:  53%|█████▎    | 5271/10000 [00:33<00:30, 156.86it/s]Running 10000 simulations.:  53%|█████▎    | 5287/10000 [00:33<00:30, 156.90it/s]Running 10000 simulations.:  53%|█████▎    | 5303/10000 [00:33<00:29, 156.93it/s]Running 10000 simulations.:  53%|█████▎    | 5319/10000 [00:33<00:29, 156.81it/s]Running 10000 simulations.:  53%|█████▎    | 5335/10000 [00:33<00:29, 156.91it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:34<00:29, 157.35it/s]Running 10000 simulations.:  54%|█████▎    | 5367/10000 [00:34<00:29, 157.37it/s]Running 10000 simulations.:  54%|█████▍    | 5383/10000 [00:34<00:29, 157.35it/s]Running 10000 simulations.:  54%|█████▍    | 5399/10000 [00:34<00:29, 157.39it/s]Running 10000 simulations.:  54%|█████▍    | 5415/10000 [00:34<00:29, 157.52it/s]Running 10000 simulations.:  54%|█████▍    | 5431/10000 [00:34<00:28, 157.65it/s]Running 10000 simulations.:  54%|█████▍    | 5447/10000 [00:34<00:28, 157.53it/s]Running 10000 simulations.:  55%|█████▍    | 5463/10000 [00:34<00:28, 157.37it/s]Running 10000 simulations.:  55%|█████▍    | 5479/10000 [00:34<00:28, 157.22it/s]Running 10000 simulations.:  55%|█████▍    | 5495/10000 [00:34<00:28, 157.19it/s]Running 10000 simulations.:  55%|█████▌    | 5511/10000 [00:35<00:28, 156.90it/s]Running 10000 simulations.:  55%|█████▌    | 5527/10000 [00:35<00:28, 156.60it/s]Running 10000 simulations.:  55%|█████▌    | 5543/10000 [00:35<00:28, 156.56it/s]Running 10000 simulations.:  56%|█████▌    | 5559/10000 [00:35<00:28, 156.50it/s]Running 10000 simulations.:  56%|█████▌    | 5575/10000 [00:35<00:28, 156.44it/s]Running 10000 simulations.:  56%|█████▌    | 5591/10000 [00:35<00:28, 155.89it/s]Running 10000 simulations.:  56%|█████▌    | 5607/10000 [00:35<00:28, 156.36it/s]Running 10000 simulations.:  56%|█████▌    | 5623/10000 [00:35<00:27, 156.38it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:35<00:27, 156.23it/s]Running 10000 simulations.:  57%|█████▋    | 5655/10000 [00:35<00:27, 156.36it/s]Running 10000 simulations.:  57%|█████▋    | 5671/10000 [00:36<00:27, 156.42it/s]Running 10000 simulations.:  57%|█████▋    | 5687/10000 [00:36<00:27, 156.32it/s]Running 10000 simulations.:  57%|█████▋    | 5703/10000 [00:36<00:27, 156.79it/s]Running 10000 simulations.:  57%|█████▋    | 5719/10000 [00:36<00:27, 157.18it/s]Running 10000 simulations.:  57%|█████▋    | 5735/10000 [00:36<00:27, 156.92it/s]Running 10000 simulations.:  58%|█████▊    | 5751/10000 [00:36<00:27, 156.97it/s]Running 10000 simulations.:  58%|█████▊    | 5767/10000 [00:36<00:26, 157.34it/s]Running 10000 simulations.:  58%|█████▊    | 5783/10000 [00:36<00:26, 157.13it/s]Running 10000 simulations.:  58%|█████▊    | 5799/10000 [00:36<00:26, 156.70it/s]Running 10000 simulations.:  58%|█████▊    | 5815/10000 [00:36<00:26, 156.82it/s]Running 10000 simulations.:  58%|█████▊    | 5831/10000 [00:37<00:26, 157.08it/s]Running 10000 simulations.:  58%|█████▊    | 5847/10000 [00:37<00:26, 157.13it/s]Running 10000 simulations.:  59%|█████▊    | 5863/10000 [00:37<00:26, 157.18it/s]Running 10000 simulations.:  59%|█████▉    | 5879/10000 [00:37<00:26, 157.09it/s]Running 10000 simulations.:  59%|█████▉    | 5895/10000 [00:37<00:26, 156.91it/s]Running 10000 simulations.:  59%|█████▉    | 5911/10000 [00:37<00:26, 156.57it/s]Running 10000 simulations.:  59%|█████▉    | 5927/10000 [00:37<00:25, 156.73it/s]Running 10000 simulations.:  59%|█████▉    | 5943/10000 [00:37<00:25, 156.76it/s]Running 10000 simulations.:  60%|█████▉    | 5959/10000 [00:37<00:25, 156.96it/s]Running 10000 simulations.:  60%|█████▉    | 5975/10000 [00:38<00:25, 157.08it/s]Running 10000 simulations.:  60%|█████▉    | 5991/10000 [00:38<00:25, 157.02it/s]Running 10000 simulations.:  60%|██████    | 6007/10000 [00:38<00:26, 148.22it/s]Running 10000 simulations.:  60%|██████    | 6023/10000 [00:38<00:26, 150.63it/s]Running 10000 simulations.:  60%|██████    | 6039/10000 [00:38<00:25, 152.37it/s]Running 10000 simulations.:  61%|██████    | 6055/10000 [00:38<00:25, 153.90it/s]Running 10000 simulations.:  61%|██████    | 6071/10000 [00:38<00:25, 154.89it/s]Running 10000 simulations.:  61%|██████    | 6087/10000 [00:38<00:25, 155.81it/s]Running 10000 simulations.:  61%|██████    | 6103/10000 [00:38<00:24, 156.27it/s]Running 10000 simulations.:  61%|██████    | 6119/10000 [00:38<00:24, 156.50it/s]Running 10000 simulations.:  61%|██████▏   | 6135/10000 [00:39<00:24, 156.71it/s]Running 10000 simulations.:  62%|██████▏   | 6151/10000 [00:39<00:24, 156.53it/s]Running 10000 simulations.:  62%|██████▏   | 6167/10000 [00:39<00:24, 156.50it/s]Running 10000 simulations.:  62%|██████▏   | 6183/10000 [00:39<00:24, 156.54it/s]Running 10000 simulations.:  62%|██████▏   | 6199/10000 [00:39<00:24, 156.56it/s]Running 10000 simulations.:  62%|██████▏   | 6215/10000 [00:39<00:24, 156.53it/s]Running 10000 simulations.:  62%|██████▏   | 6231/10000 [00:39<00:24, 156.61it/s]Running 10000 simulations.:  62%|██████▏   | 6247/10000 [00:39<00:23, 156.58it/s]Running 10000 simulations.:  63%|██████▎   | 6263/10000 [00:39<00:23, 156.61it/s]Running 10000 simulations.:  63%|██████▎   | 6279/10000 [00:39<00:24, 154.53it/s]Running 10000 simulations.:  63%|██████▎   | 6295/10000 [00:40<00:23, 154.74it/s]Running 10000 simulations.:  63%|██████▎   | 6311/10000 [00:40<00:23, 155.20it/s]Running 10000 simulations.:  63%|██████▎   | 6327/10000 [00:40<00:23, 155.46it/s]Running 10000 simulations.:  63%|██████▎   | 6343/10000 [00:40<00:23, 155.90it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:40<00:23, 156.13it/s]Running 10000 simulations.:  64%|██████▍   | 6375/10000 [00:40<00:23, 156.03it/s]Running 10000 simulations.:  64%|██████▍   | 6391/10000 [00:40<00:23, 156.02it/s]Running 10000 simulations.:  64%|██████▍   | 6407/10000 [00:40<00:23, 155.99it/s]Running 10000 simulations.:  64%|██████▍   | 6423/10000 [00:40<00:22, 156.23it/s]Running 10000 simulations.:  64%|██████▍   | 6439/10000 [00:40<00:22, 156.29it/s]Running 10000 simulations.:  65%|██████▍   | 6455/10000 [00:41<00:22, 156.37it/s]Running 10000 simulations.:  65%|██████▍   | 6471/10000 [00:41<00:22, 156.59it/s]Running 10000 simulations.:  65%|██████▍   | 6487/10000 [00:41<00:22, 156.61it/s]Running 10000 simulations.:  65%|██████▌   | 6503/10000 [00:41<00:22, 156.60it/s]Running 10000 simulations.:  65%|██████▌   | 6519/10000 [00:41<00:22, 156.31it/s]Running 10000 simulations.:  65%|██████▌   | 6535/10000 [00:41<00:22, 156.18it/s]Running 10000 simulations.:  66%|██████▌   | 6551/10000 [00:41<00:22, 156.38it/s]Running 10000 simulations.:  66%|██████▌   | 6567/10000 [00:41<00:21, 156.45it/s]Running 10000 simulations.:  66%|██████▌   | 6583/10000 [00:41<00:21, 156.76it/s]Running 10000 simulations.:  66%|██████▌   | 6599/10000 [00:42<00:21, 156.90it/s]Running 10000 simulations.:  66%|██████▌   | 6615/10000 [00:42<00:21, 156.95it/s]Running 10000 simulations.:  66%|██████▋   | 6632/10000 [00:42<00:21, 157.86it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:42<00:21, 157.45it/s]Running 10000 simulations.:  67%|██████▋   | 6664/10000 [00:42<00:21, 157.20it/s]Running 10000 simulations.:  67%|██████▋   | 6680/10000 [00:42<00:21, 157.51it/s]Running 10000 simulations.:  67%|██████▋   | 6696/10000 [00:42<00:20, 157.66it/s]Running 10000 simulations.:  67%|██████▋   | 6712/10000 [00:42<00:20, 157.91it/s]Running 10000 simulations.:  67%|██████▋   | 6730/10000 [00:42<00:20, 161.58it/s]Running 10000 simulations.:  67%|██████▋   | 6749/10000 [00:42<00:19, 167.77it/s]Running 10000 simulations.:  68%|██████▊   | 6766/10000 [00:43<00:19, 165.05it/s]Running 10000 simulations.:  68%|██████▊   | 6783/10000 [00:43<00:19, 161.88it/s]Running 10000 simulations.:  68%|██████▊   | 6800/10000 [00:43<00:20, 159.78it/s]Running 10000 simulations.:  68%|██████▊   | 6817/10000 [00:43<00:20, 158.88it/s]Running 10000 simulations.:  68%|██████▊   | 6833/10000 [00:43<00:19, 158.43it/s]Running 10000 simulations.:  68%|██████▊   | 6849/10000 [00:43<00:19, 157.55it/s]Running 10000 simulations.:  69%|██████▊   | 6865/10000 [00:43<00:19, 157.00it/s]Running 10000 simulations.:  69%|██████▉   | 6881/10000 [00:43<00:19, 156.56it/s]Running 10000 simulations.:  69%|██████▉   | 6897/10000 [00:43<00:19, 156.12it/s]Running 10000 simulations.:  69%|██████▉   | 6913/10000 [00:43<00:19, 155.85it/s]Running 10000 simulations.:  69%|██████▉   | 6929/10000 [00:44<00:19, 155.80it/s]Running 10000 simulations.:  69%|██████▉   | 6945/10000 [00:44<00:19, 155.76it/s]Running 10000 simulations.:  70%|██████▉   | 6961/10000 [00:44<00:19, 155.93it/s]Running 10000 simulations.:  70%|██████▉   | 6977/10000 [00:44<00:19, 156.47it/s]Running 10000 simulations.:  70%|██████▉   | 6993/10000 [00:44<00:19, 156.62it/s]Running 10000 simulations.:  70%|███████   | 7009/10000 [00:44<00:19, 156.32it/s]Running 10000 simulations.:  70%|███████   | 7025/10000 [00:44<00:19, 156.45it/s]Running 10000 simulations.:  70%|███████   | 7041/10000 [00:44<00:18, 156.82it/s]Running 10000 simulations.:  71%|███████   | 7057/10000 [00:44<00:18, 156.84it/s]Running 10000 simulations.:  71%|███████   | 7073/10000 [00:45<00:18, 156.42it/s]Running 10000 simulations.:  71%|███████   | 7089/10000 [00:45<00:18, 156.44it/s]Running 10000 simulations.:  71%|███████   | 7105/10000 [00:45<00:18, 156.85it/s]Running 10000 simulations.:  71%|███████   | 7121/10000 [00:45<00:18, 156.90it/s]Running 10000 simulations.:  71%|███████▏  | 7137/10000 [00:45<00:18, 156.68it/s]Running 10000 simulations.:  72%|███████▏  | 7153/10000 [00:45<00:18, 156.93it/s]Running 10000 simulations.:  72%|███████▏  | 7169/10000 [00:45<00:18, 156.63it/s]Running 10000 simulations.:  72%|███████▏  | 7185/10000 [00:45<00:18, 156.28it/s]Running 10000 simulations.:  72%|███████▏  | 7201/10000 [00:45<00:17, 156.39it/s]Running 10000 simulations.:  72%|███████▏  | 7217/10000 [00:45<00:17, 156.87it/s]Running 10000 simulations.:  72%|███████▏  | 7233/10000 [00:46<00:17, 157.14it/s]Running 10000 simulations.:  72%|███████▏  | 7249/10000 [00:46<00:17, 156.44it/s]Running 10000 simulations.:  73%|███████▎  | 7265/10000 [00:46<00:17, 156.63it/s]Running 10000 simulations.:  73%|███████▎  | 7281/10000 [00:46<00:17, 156.41it/s]Running 10000 simulations.:  73%|███████▎  | 7297/10000 [00:46<00:17, 156.43it/s]Running 10000 simulations.:  73%|███████▎  | 7313/10000 [00:46<00:17, 156.61it/s]Running 10000 simulations.:  73%|███████▎  | 7329/10000 [00:46<00:17, 156.70it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:46<00:17, 155.70it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:46<00:16, 155.45it/s]Running 10000 simulations.:  74%|███████▍  | 7377/10000 [00:46<00:16, 155.87it/s]Running 10000 simulations.:  74%|███████▍  | 7393/10000 [00:47<00:16, 156.18it/s]Running 10000 simulations.:  74%|███████▍  | 7409/10000 [00:47<00:16, 156.38it/s]Running 10000 simulations.:  74%|███████▍  | 7425/10000 [00:47<00:16, 156.14it/s]Running 10000 simulations.:  74%|███████▍  | 7441/10000 [00:47<00:16, 156.55it/s]Running 10000 simulations.:  75%|███████▍  | 7457/10000 [00:47<00:16, 156.60it/s]Running 10000 simulations.:  75%|███████▍  | 7473/10000 [00:47<00:16, 156.52it/s]Running 10000 simulations.:  75%|███████▍  | 7489/10000 [00:47<00:16, 156.27it/s]Running 10000 simulations.:  75%|███████▌  | 7505/10000 [00:47<00:15, 156.11it/s]Running 10000 simulations.:  75%|███████▌  | 7521/10000 [00:47<00:15, 155.90it/s]Running 10000 simulations.:  75%|███████▌  | 7537/10000 [00:47<00:15, 155.85it/s]Running 10000 simulations.:  76%|███████▌  | 7553/10000 [00:48<00:15, 155.79it/s]Running 10000 simulations.:  76%|███████▌  | 7569/10000 [00:48<00:15, 156.07it/s]Running 10000 simulations.:  76%|███████▌  | 7585/10000 [00:48<00:15, 156.06it/s]Running 10000 simulations.:  76%|███████▌  | 7601/10000 [00:48<00:15, 156.02it/s]Running 10000 simulations.:  76%|███████▌  | 7617/10000 [00:48<00:15, 153.99it/s]Running 10000 simulations.:  76%|███████▋  | 7633/10000 [00:48<00:15, 154.64it/s]Running 10000 simulations.:  76%|███████▋  | 7649/10000 [00:48<00:15, 155.36it/s]Running 10000 simulations.:  77%|███████▋  | 7665/10000 [00:48<00:14, 155.67it/s]Running 10000 simulations.:  77%|███████▋  | 7681/10000 [00:48<00:14, 155.85it/s]Running 10000 simulations.:  77%|███████▋  | 7697/10000 [00:49<00:14, 155.68it/s]Running 10000 simulations.:  77%|███████▋  | 7713/10000 [00:49<00:14, 155.69it/s]Running 10000 simulations.:  77%|███████▋  | 7729/10000 [00:49<00:14, 155.66it/s]Running 10000 simulations.:  77%|███████▋  | 7745/10000 [00:49<00:14, 156.01it/s]Running 10000 simulations.:  78%|███████▊  | 7761/10000 [00:49<00:14, 156.18it/s]Running 10000 simulations.:  78%|███████▊  | 7777/10000 [00:49<00:14, 156.33it/s]Running 10000 simulations.:  78%|███████▊  | 7793/10000 [00:49<00:14, 156.73it/s]Running 10000 simulations.:  78%|███████▊  | 7809/10000 [00:49<00:13, 156.75it/s]Running 10000 simulations.:  78%|███████▊  | 7825/10000 [00:49<00:13, 157.05it/s]Running 10000 simulations.:  78%|███████▊  | 7841/10000 [00:49<00:13, 157.15it/s]Running 10000 simulations.:  79%|███████▊  | 7857/10000 [00:50<00:13, 157.06it/s]Running 10000 simulations.:  79%|███████▊  | 7873/10000 [00:50<00:13, 156.87it/s]Running 10000 simulations.:  79%|███████▉  | 7889/10000 [00:50<00:13, 156.99it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:50<00:13, 157.08it/s]Running 10000 simulations.:  79%|███████▉  | 7921/10000 [00:50<00:13, 157.16it/s]Running 10000 simulations.:  79%|███████▉  | 7937/10000 [00:50<00:13, 157.17it/s]Running 10000 simulations.:  80%|███████▉  | 7953/10000 [00:50<00:13, 157.01it/s]Running 10000 simulations.:  80%|███████▉  | 7969/10000 [00:50<00:12, 157.39it/s]Running 10000 simulations.:  80%|███████▉  | 7985/10000 [00:50<00:12, 157.20it/s]Running 10000 simulations.:  80%|████████  | 8001/10000 [00:50<00:12, 157.14it/s]Running 10000 simulations.:  80%|████████  | 8017/10000 [00:51<00:12, 157.42it/s]Running 10000 simulations.:  80%|████████  | 8033/10000 [00:51<00:12, 157.31it/s]Running 10000 simulations.:  80%|████████  | 8049/10000 [00:51<00:12, 157.50it/s]Running 10000 simulations.:  81%|████████  | 8065/10000 [00:51<00:12, 157.55it/s]Running 10000 simulations.:  81%|████████  | 8081/10000 [00:51<00:12, 157.61it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:51<00:12, 157.44it/s]Running 10000 simulations.:  81%|████████  | 8113/10000 [00:51<00:12, 156.69it/s]Running 10000 simulations.:  81%|████████▏ | 8129/10000 [00:51<00:11, 157.04it/s]Running 10000 simulations.:  81%|████████▏ | 8145/10000 [00:51<00:11, 157.08it/s]Running 10000 simulations.:  82%|████████▏ | 8161/10000 [00:51<00:11, 157.07it/s]Running 10000 simulations.:  82%|████████▏ | 8177/10000 [00:52<00:11, 157.05it/s]Running 10000 simulations.:  82%|████████▏ | 8193/10000 [00:52<00:11, 156.85it/s]Running 10000 simulations.:  82%|████████▏ | 8209/10000 [00:52<00:11, 156.96it/s]Running 10000 simulations.:  82%|████████▏ | 8225/10000 [00:52<00:11, 156.58it/s]Running 10000 simulations.:  82%|████████▏ | 8241/10000 [00:52<00:11, 156.65it/s]Running 10000 simulations.:  83%|████████▎ | 8257/10000 [00:52<00:11, 157.02it/s]Running 10000 simulations.:  83%|████████▎ | 8273/10000 [00:52<00:11, 156.93it/s]Running 10000 simulations.:  83%|████████▎ | 8289/10000 [00:52<00:10, 157.28it/s]Running 10000 simulations.:  83%|████████▎ | 8305/10000 [00:52<00:10, 157.37it/s]Running 10000 simulations.:  83%|████████▎ | 8321/10000 [00:52<00:10, 157.28it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:53<00:10, 157.30it/s]Running 10000 simulations.:  84%|████████▎ | 8353/10000 [00:53<00:10, 157.65it/s]Running 10000 simulations.:  84%|████████▎ | 8369/10000 [00:53<00:10, 157.73it/s]Running 10000 simulations.:  84%|████████▍ | 8385/10000 [00:53<00:10, 157.46it/s]Running 10000 simulations.:  84%|████████▍ | 8401/10000 [00:53<00:10, 157.61it/s]Running 10000 simulations.:  84%|████████▍ | 8417/10000 [00:53<00:10, 157.60it/s]Running 10000 simulations.:  84%|████████▍ | 8433/10000 [00:53<00:09, 157.02it/s]Running 10000 simulations.:  84%|████████▍ | 8449/10000 [00:53<00:09, 157.05it/s]Running 10000 simulations.:  85%|████████▍ | 8465/10000 [00:53<00:09, 157.26it/s]Running 10000 simulations.:  85%|████████▍ | 8481/10000 [00:53<00:09, 157.17it/s]Running 10000 simulations.:  85%|████████▍ | 8497/10000 [00:54<00:09, 156.89it/s]Running 10000 simulations.:  85%|████████▌ | 8513/10000 [00:54<00:09, 156.53it/s]Running 10000 simulations.:  85%|████████▌ | 8529/10000 [00:54<00:09, 156.41it/s]Running 10000 simulations.:  85%|████████▌ | 8545/10000 [00:54<00:09, 156.40it/s]Running 10000 simulations.:  86%|████████▌ | 8561/10000 [00:54<00:09, 156.71it/s]Running 10000 simulations.:  86%|████████▌ | 8577/10000 [00:54<00:09, 156.80it/s]Running 10000 simulations.:  86%|████████▌ | 8593/10000 [00:54<00:08, 156.98it/s]Running 10000 simulations.:  86%|████████▌ | 8609/10000 [00:54<00:08, 157.19it/s]Running 10000 simulations.:  86%|████████▋ | 8625/10000 [00:54<00:08, 157.20it/s]Running 10000 simulations.:  86%|████████▋ | 8641/10000 [00:55<00:08, 156.93it/s]Running 10000 simulations.:  87%|████████▋ | 8657/10000 [00:55<00:08, 157.07it/s]Running 10000 simulations.:  87%|████████▋ | 8673/10000 [00:55<00:08, 156.83it/s]Running 10000 simulations.:  87%|████████▋ | 8689/10000 [00:55<00:08, 156.86it/s]Running 10000 simulations.:  87%|████████▋ | 8705/10000 [00:55<00:08, 156.78it/s]Running 10000 simulations.:  87%|████████▋ | 8721/10000 [00:55<00:08, 157.10it/s]Running 10000 simulations.:  87%|████████▋ | 8737/10000 [00:55<00:08, 156.91it/s]Running 10000 simulations.:  88%|████████▊ | 8753/10000 [00:55<00:07, 156.85it/s]Running 10000 simulations.:  88%|████████▊ | 8769/10000 [00:55<00:07, 156.88it/s]Running 10000 simulations.:  88%|████████▊ | 8785/10000 [00:55<00:07, 156.62it/s]Running 10000 simulations.:  88%|████████▊ | 8801/10000 [00:56<00:07, 157.18it/s]Running 10000 simulations.:  88%|████████▊ | 8817/10000 [00:56<00:07, 156.86it/s]Running 10000 simulations.:  88%|████████▊ | 8833/10000 [00:56<00:07, 154.91it/s]Running 10000 simulations.:  88%|████████▊ | 8849/10000 [00:56<00:07, 155.72it/s]Running 10000 simulations.:  89%|████████▊ | 8865/10000 [00:56<00:07, 156.26it/s]Running 10000 simulations.:  89%|████████▉ | 8881/10000 [00:56<00:07, 156.81it/s]Running 10000 simulations.:  89%|████████▉ | 8897/10000 [00:56<00:07, 156.91it/s]Running 10000 simulations.:  89%|████████▉ | 8913/10000 [00:56<00:06, 157.13it/s]Running 10000 simulations.:  89%|████████▉ | 8929/10000 [00:56<00:06, 157.40it/s]Running 10000 simulations.:  89%|████████▉ | 8945/10000 [00:56<00:06, 157.71it/s]Running 10000 simulations.:  90%|████████▉ | 8961/10000 [00:57<00:06, 157.62it/s]Running 10000 simulations.:  90%|████████▉ | 8977/10000 [00:57<00:06, 157.88it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [00:57<00:06, 157.78it/s]Running 10000 simulations.:  90%|█████████ | 9011/10000 [00:57<00:06, 161.61it/s]Running 10000 simulations.:  90%|█████████ | 9029/10000 [00:57<00:05, 165.64it/s]Running 10000 simulations.:  90%|█████████ | 9046/10000 [00:57<00:05, 163.48it/s]Running 10000 simulations.:  91%|█████████ | 9063/10000 [00:57<00:05, 162.11it/s]Running 10000 simulations.:  91%|█████████ | 9080/10000 [00:57<00:05, 160.97it/s]Running 10000 simulations.:  91%|█████████ | 9097/10000 [00:57<00:05, 160.56it/s]Running 10000 simulations.:  91%|█████████ | 9114/10000 [00:58<00:05, 159.64it/s]Running 10000 simulations.:  91%|█████████▏| 9130/10000 [00:58<00:05, 158.81it/s]Running 10000 simulations.:  91%|█████████▏| 9146/10000 [00:58<00:05, 158.35it/s]Running 10000 simulations.:  92%|█████████▏| 9162/10000 [00:58<00:05, 158.45it/s]Running 10000 simulations.:  92%|█████████▏| 9178/10000 [00:58<00:05, 158.33it/s]Running 10000 simulations.:  92%|█████████▏| 9194/10000 [00:58<00:05, 158.14it/s]Running 10000 simulations.:  92%|█████████▏| 9210/10000 [00:58<00:05, 157.77it/s]Running 10000 simulations.:  92%|█████████▏| 9226/10000 [00:58<00:04, 157.98it/s]Running 10000 simulations.:  92%|█████████▏| 9242/10000 [00:58<00:04, 157.94it/s]Running 10000 simulations.:  93%|█████████▎| 9258/10000 [00:58<00:04, 157.93it/s]Running 10000 simulations.:  93%|█████████▎| 9274/10000 [00:59<00:04, 157.87it/s]Running 10000 simulations.:  93%|█████████▎| 9290/10000 [00:59<00:04, 157.86it/s]Running 10000 simulations.:  93%|█████████▎| 9306/10000 [00:59<00:04, 158.04it/s]Running 10000 simulations.:  93%|█████████▎| 9322/10000 [00:59<00:04, 155.42it/s]Running 10000 simulations.:  93%|█████████▎| 9338/10000 [00:59<00:04, 156.29it/s]Running 10000 simulations.:  94%|█████████▎| 9354/10000 [00:59<00:04, 156.91it/s]Running 10000 simulations.:  94%|█████████▎| 9370/10000 [00:59<00:04, 157.05it/s]Running 10000 simulations.:  94%|█████████▍| 9386/10000 [00:59<00:03, 157.36it/s]Running 10000 simulations.:  94%|█████████▍| 9402/10000 [00:59<00:03, 157.33it/s]Running 10000 simulations.:  94%|█████████▍| 9418/10000 [00:59<00:03, 157.30it/s]Running 10000 simulations.:  94%|█████████▍| 9434/10000 [01:00<00:03, 157.11it/s]Running 10000 simulations.:  94%|█████████▍| 9450/10000 [01:00<00:03, 157.02it/s]Running 10000 simulations.:  95%|█████████▍| 9466/10000 [01:00<00:03, 157.29it/s]Running 10000 simulations.:  95%|█████████▍| 9482/10000 [01:00<00:03, 157.23it/s]Running 10000 simulations.:  95%|█████████▍| 9498/10000 [01:00<00:03, 156.82it/s]Running 10000 simulations.:  95%|█████████▌| 9514/10000 [01:00<00:03, 156.82it/s]Running 10000 simulations.:  95%|█████████▌| 9530/10000 [01:00<00:03, 156.48it/s]Running 10000 simulations.:  95%|█████████▌| 9546/10000 [01:00<00:02, 156.63it/s]Running 10000 simulations.:  96%|█████████▌| 9562/10000 [01:00<00:02, 156.70it/s]Running 10000 simulations.:  96%|█████████▌| 9578/10000 [01:00<00:02, 156.55it/s]Running 10000 simulations.:  96%|█████████▌| 9594/10000 [01:01<00:02, 156.26it/s]Running 10000 simulations.:  96%|█████████▌| 9610/10000 [01:01<00:02, 156.18it/s]Running 10000 simulations.:  96%|█████████▋| 9626/10000 [01:01<00:02, 155.87it/s]Running 10000 simulations.:  96%|█████████▋| 9642/10000 [01:01<00:02, 156.06it/s]Running 10000 simulations.:  97%|█████████▋| 9658/10000 [01:01<00:02, 155.70it/s]Running 10000 simulations.:  97%|█████████▋| 9674/10000 [01:01<00:02, 155.78it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [01:01<00:01, 156.03it/s]Running 10000 simulations.:  97%|█████████▋| 9706/10000 [01:01<00:01, 156.01it/s]Running 10000 simulations.:  97%|█████████▋| 9722/10000 [01:01<00:01, 156.15it/s]Running 10000 simulations.:  97%|█████████▋| 9738/10000 [01:01<00:01, 156.18it/s]Running 10000 simulations.:  98%|█████████▊| 9754/10000 [01:02<00:01, 156.06it/s]Running 10000 simulations.:  98%|█████████▊| 9770/10000 [01:02<00:01, 155.93it/s]Running 10000 simulations.:  98%|█████████▊| 9786/10000 [01:02<00:01, 155.83it/s]Running 10000 simulations.:  98%|█████████▊| 9802/10000 [01:02<00:01, 155.77it/s]Running 10000 simulations.:  98%|█████████▊| 9818/10000 [01:02<00:01, 155.99it/s]Running 10000 simulations.:  98%|█████████▊| 9834/10000 [01:02<00:01, 155.97it/s]Running 10000 simulations.:  98%|█████████▊| 9850/10000 [01:02<00:00, 156.31it/s]Running 10000 simulations.:  99%|█████████▊| 9866/10000 [01:02<00:00, 156.81it/s]Running 10000 simulations.:  99%|█████████▉| 9882/10000 [01:02<00:00, 156.71it/s]Running 10000 simulations.:  99%|█████████▉| 9898/10000 [01:03<00:00, 157.63it/s]Running 10000 simulations.:  99%|█████████▉| 9914/10000 [01:03<00:00, 157.17it/s]Running 10000 simulations.:  99%|█████████▉| 9930/10000 [01:03<00:00, 157.26it/s]Running 10000 simulations.:  99%|█████████▉| 9946/10000 [01:03<00:00, 157.18it/s]Running 10000 simulations.: 100%|█████████▉| 9962/10000 [01:03<00:00, 157.17it/s]Running 10000 simulations.: 100%|█████████▉| 9978/10000 [01:03<00:00, 157.17it/s]Running 10000 simulations.: 100%|█████████▉| 9994/10000 [01:03<00:00, 157.44it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:03<00:00, 157.11it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 17/10000 [00:00<00:59, 167.40it/s]Running 10000 simulations.:   0%|          | 34/10000 [00:00<00:59, 167.00it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<00:59, 166.44it/s]Running 10000 simulations.:   1%|          | 68/10000 [00:00<00:59, 166.20it/s]Running 10000 simulations.:   1%|          | 85/10000 [00:00<00:59, 167.00it/s]Running 10000 simulations.:   1%|          | 102/10000 [00:00<00:59, 167.39it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<00:59, 166.78it/s]Running 10000 simulations.:   1%|▏         | 136/10000 [00:00<00:59, 167.03it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:58, 166.95it/s]Running 10000 simulations.:   2%|▏         | 170/10000 [00:01<00:58, 167.00it/s]Running 10000 simulations.:   2%|▏         | 187/10000 [00:01<00:58, 167.41it/s]Running 10000 simulations.:   2%|▏         | 204/10000 [00:01<00:58, 167.85it/s]Running 10000 simulations.:   2%|▏         | 221/10000 [00:01<00:58, 168.20it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:01<00:57, 168.33it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<00:58, 167.65it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<00:58, 167.38it/s]Running 10000 simulations.:   3%|▎         | 289/10000 [00:01<00:57, 167.46it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:57, 167.77it/s]Running 10000 simulations.:   3%|▎         | 324/10000 [00:01<00:57, 168.48it/s]Running 10000 simulations.:   3%|▎         | 341/10000 [00:02<00:57, 167.81it/s]Running 10000 simulations.:   4%|▎         | 358/10000 [00:02<00:57, 167.08it/s]Running 10000 simulations.:   4%|▍         | 375/10000 [00:02<00:57, 166.53it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:02<00:57, 166.43it/s]Running 10000 simulations.:   4%|▍         | 409/10000 [00:02<00:57, 166.04it/s]Running 10000 simulations.:   4%|▍         | 426/10000 [00:02<00:57, 165.74it/s]Running 10000 simulations.:   4%|▍         | 443/10000 [00:02<00:57, 165.71it/s]Running 10000 simulations.:   5%|▍         | 460/10000 [00:02<00:57, 166.51it/s]Running 10000 simulations.:   5%|▍         | 477/10000 [00:02<00:56, 167.25it/s]Running 10000 simulations.:   5%|▍         | 494/10000 [00:02<00:56, 166.91it/s]Running 10000 simulations.:   5%|▌         | 511/10000 [00:03<00:57, 166.47it/s]Running 10000 simulations.:   5%|▌         | 528/10000 [00:03<00:56, 166.35it/s]Running 10000 simulations.:   5%|▌         | 545/10000 [00:03<00:56, 166.51it/s]Running 10000 simulations.:   6%|▌         | 562/10000 [00:03<00:56, 166.63it/s]Running 10000 simulations.:   6%|▌         | 579/10000 [00:03<00:56, 166.77it/s]Running 10000 simulations.:   6%|▌         | 596/10000 [00:03<00:56, 166.89it/s]Running 10000 simulations.:   6%|▌         | 613/10000 [00:03<00:56, 166.32it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:03<00:56, 165.88it/s]Running 10000 simulations.:   6%|▋         | 647/10000 [00:03<00:56, 166.00it/s]Running 10000 simulations.:   7%|▋         | 664/10000 [00:03<00:55, 166.78it/s]Running 10000 simulations.:   7%|▋         | 681/10000 [00:04<00:55, 167.26it/s]Running 10000 simulations.:   7%|▋         | 698/10000 [00:04<00:55, 166.57it/s]Running 10000 simulations.:   7%|▋         | 715/10000 [00:04<00:55, 166.63it/s]Running 10000 simulations.:   7%|▋         | 732/10000 [00:04<00:55, 167.10it/s]Running 10000 simulations.:   7%|▋         | 749/10000 [00:04<00:55, 166.73it/s]Running 10000 simulations.:   8%|▊         | 766/10000 [00:04<00:55, 166.40it/s]Running 10000 simulations.:   8%|▊         | 783/10000 [00:04<00:55, 166.49it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:04<00:55, 166.90it/s]Running 10000 simulations.:   8%|▊         | 817/10000 [00:04<00:54, 167.01it/s]Running 10000 simulations.:   8%|▊         | 834/10000 [00:04<00:55, 166.34it/s]Running 10000 simulations.:   9%|▊         | 851/10000 [00:05<00:54, 166.47it/s]Running 10000 simulations.:   9%|▊         | 868/10000 [00:05<00:54, 166.13it/s]Running 10000 simulations.:   9%|▉         | 885/10000 [00:05<00:54, 166.05it/s]Running 10000 simulations.:   9%|▉         | 902/10000 [00:05<00:54, 165.50it/s]Running 10000 simulations.:   9%|▉         | 919/10000 [00:05<00:55, 165.07it/s]Running 10000 simulations.:   9%|▉         | 936/10000 [00:05<00:54, 165.39it/s]Running 10000 simulations.:  10%|▉         | 953/10000 [00:05<00:54, 165.11it/s]Running 10000 simulations.:  10%|▉         | 970/10000 [00:05<00:54, 165.92it/s]Running 10000 simulations.:  10%|▉         | 987/10000 [00:05<00:54, 166.60it/s]Running 10000 simulations.:  10%|█         | 1004/10000 [00:06<00:53, 166.80it/s]Running 10000 simulations.:  10%|█         | 1021/10000 [00:06<00:53, 166.49it/s]Running 10000 simulations.:  10%|█         | 1038/10000 [00:06<00:54, 165.62it/s]Running 10000 simulations.:  11%|█         | 1055/10000 [00:06<00:54, 165.01it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:06<00:54, 164.74it/s]Running 10000 simulations.:  11%|█         | 1089/10000 [00:06<00:54, 164.69it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:06<00:54, 164.61it/s]Running 10000 simulations.:  11%|█         | 1123/10000 [00:06<00:53, 164.92it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:06<00:53, 165.81it/s]Running 10000 simulations.:  12%|█▏        | 1157/10000 [00:06<00:53, 165.48it/s]Running 10000 simulations.:  12%|█▏        | 1174/10000 [00:07<00:53, 166.05it/s]Running 10000 simulations.:  12%|█▏        | 1191/10000 [00:07<00:53, 166.01it/s]Running 10000 simulations.:  12%|█▏        | 1208/10000 [00:07<00:53, 165.42it/s]Running 10000 simulations.:  12%|█▏        | 1225/10000 [00:07<00:53, 164.80it/s]Running 10000 simulations.:  12%|█▏        | 1242/10000 [00:07<00:53, 164.35it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:07<00:53, 164.16it/s]Running 10000 simulations.:  13%|█▎        | 1276/10000 [00:07<00:53, 164.01it/s]Running 10000 simulations.:  13%|█▎        | 1293/10000 [00:07<00:53, 164.02it/s]Running 10000 simulations.:  13%|█▎        | 1310/10000 [00:07<00:53, 163.82it/s]Running 10000 simulations.:  13%|█▎        | 1327/10000 [00:07<00:52, 163.94it/s]Running 10000 simulations.:  13%|█▎        | 1344/10000 [00:08<00:52, 164.42it/s]Running 10000 simulations.:  14%|█▎        | 1361/10000 [00:08<00:52, 164.26it/s]Running 10000 simulations.:  14%|█▍        | 1378/10000 [00:08<00:52, 164.09it/s]Running 10000 simulations.:  14%|█▍        | 1395/10000 [00:08<00:52, 163.81it/s]Running 10000 simulations.:  14%|█▍        | 1412/10000 [00:08<00:52, 164.30it/s]Running 10000 simulations.:  14%|█▍        | 1429/10000 [00:08<00:52, 164.69it/s]Running 10000 simulations.:  14%|█▍        | 1446/10000 [00:08<00:52, 164.45it/s]Running 10000 simulations.:  15%|█▍        | 1463/10000 [00:08<00:51, 164.28it/s]Running 10000 simulations.:  15%|█▍        | 1480/10000 [00:08<00:51, 164.04it/s]Running 10000 simulations.:  15%|█▍        | 1497/10000 [00:09<00:51, 163.97it/s]Running 10000 simulations.:  15%|█▌        | 1514/10000 [00:09<00:51, 163.95it/s]Running 10000 simulations.:  15%|█▌        | 1531/10000 [00:09<00:51, 164.04it/s]Running 10000 simulations.:  15%|█▌        | 1548/10000 [00:09<00:51, 164.29it/s]Running 10000 simulations.:  16%|█▌        | 1565/10000 [00:09<00:51, 164.15it/s]Running 10000 simulations.:  16%|█▌        | 1582/10000 [00:09<00:51, 164.04it/s]Running 10000 simulations.:  16%|█▌        | 1599/10000 [00:09<00:51, 163.78it/s]Running 10000 simulations.:  16%|█▌        | 1616/10000 [00:09<00:51, 163.76it/s]Running 10000 simulations.:  16%|█▋        | 1633/10000 [00:09<00:50, 164.29it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:09<00:50, 165.19it/s]Running 10000 simulations.:  17%|█▋        | 1667/10000 [00:10<00:50, 165.76it/s]Running 10000 simulations.:  17%|█▋        | 1684/10000 [00:10<00:49, 166.36it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:10<00:49, 166.76it/s]Running 10000 simulations.:  17%|█▋        | 1718/10000 [00:10<00:49, 166.27it/s]Running 10000 simulations.:  17%|█▋        | 1735/10000 [00:10<00:49, 165.87it/s]Running 10000 simulations.:  18%|█▊        | 1752/10000 [00:10<00:49, 166.11it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:10<00:49, 166.59it/s]Running 10000 simulations.:  18%|█▊        | 1786/10000 [00:10<00:49, 166.45it/s]Running 10000 simulations.:  18%|█▊        | 1803/10000 [00:10<00:49, 166.58it/s]Running 10000 simulations.:  18%|█▊        | 1820/10000 [00:10<00:49, 166.18it/s]Running 10000 simulations.:  18%|█▊        | 1837/10000 [00:11<00:49, 166.39it/s]Running 10000 simulations.:  19%|█▊        | 1854/10000 [00:11<00:49, 165.74it/s]Running 10000 simulations.:  19%|█▊        | 1871/10000 [00:11<00:49, 165.65it/s]Running 10000 simulations.:  19%|█▉        | 1888/10000 [00:11<00:48, 166.08it/s]Running 10000 simulations.:  19%|█▉        | 1905/10000 [00:11<00:48, 166.29it/s]Running 10000 simulations.:  19%|█▉        | 1922/10000 [00:11<00:48, 165.52it/s]Running 10000 simulations.:  19%|█▉        | 1939/10000 [00:11<00:48, 166.00it/s]Running 10000 simulations.:  20%|█▉        | 1956/10000 [00:11<00:48, 166.40it/s]Running 10000 simulations.:  20%|█▉        | 1973/10000 [00:11<00:48, 165.89it/s]Running 10000 simulations.:  20%|█▉        | 1990/10000 [00:11<00:48, 165.54it/s]Running 10000 simulations.:  20%|██        | 2007/10000 [00:12<00:48, 165.42it/s]Running 10000 simulations.:  20%|██        | 2024/10000 [00:12<00:48, 165.16it/s]Running 10000 simulations.:  20%|██        | 2041/10000 [00:12<00:48, 165.15it/s]Running 10000 simulations.:  21%|██        | 2058/10000 [00:12<00:47, 165.74it/s]Running 10000 simulations.:  21%|██        | 2075/10000 [00:12<00:47, 165.77it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:12<00:47, 165.62it/s]Running 10000 simulations.:  21%|██        | 2109/10000 [00:12<00:47, 165.72it/s]Running 10000 simulations.:  21%|██▏       | 2126/10000 [00:12<00:47, 165.63it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:12<00:47, 165.05it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:13<00:47, 164.64it/s]Running 10000 simulations.:  22%|██▏       | 2177/10000 [00:13<00:47, 165.77it/s]Running 10000 simulations.:  22%|██▏       | 2196/10000 [00:13<00:45, 171.75it/s]Running 10000 simulations.:  22%|██▏       | 2214/10000 [00:13<00:45, 170.27it/s]Running 10000 simulations.:  22%|██▏       | 2232/10000 [00:13<00:46, 168.33it/s]Running 10000 simulations.:  22%|██▏       | 2249/10000 [00:13<00:46, 166.82it/s]Running 10000 simulations.:  23%|██▎       | 2266/10000 [00:13<00:46, 165.67it/s]Running 10000 simulations.:  23%|██▎       | 2283/10000 [00:13<00:46, 165.12it/s]Running 10000 simulations.:  23%|██▎       | 2300/10000 [00:13<00:46, 164.65it/s]Running 10000 simulations.:  23%|██▎       | 2317/10000 [00:13<00:46, 164.30it/s]Running 10000 simulations.:  23%|██▎       | 2334/10000 [00:14<00:46, 164.15it/s]Running 10000 simulations.:  24%|██▎       | 2351/10000 [00:14<00:46, 163.91it/s]Running 10000 simulations.:  24%|██▎       | 2368/10000 [00:14<00:46, 163.81it/s]Running 10000 simulations.:  24%|██▍       | 2385/10000 [00:14<00:46, 163.88it/s]Running 10000 simulations.:  24%|██▍       | 2402/10000 [00:14<00:46, 164.84it/s]Running 10000 simulations.:  24%|██▍       | 2419/10000 [00:14<00:45, 165.72it/s]Running 10000 simulations.:  24%|██▍       | 2436/10000 [00:14<00:45, 166.25it/s]Running 10000 simulations.:  25%|██▍       | 2453/10000 [00:14<00:45, 165.70it/s]Running 10000 simulations.:  25%|██▍       | 2470/10000 [00:14<00:45, 165.09it/s]Running 10000 simulations.:  25%|██▍       | 2487/10000 [00:14<00:45, 165.61it/s]Running 10000 simulations.:  25%|██▌       | 2504/10000 [00:15<00:45, 165.43it/s]Running 10000 simulations.:  25%|██▌       | 2521/10000 [00:15<00:45, 164.82it/s]Running 10000 simulations.:  25%|██▌       | 2538/10000 [00:15<00:45, 164.54it/s]Running 10000 simulations.:  26%|██▌       | 2555/10000 [00:15<00:45, 164.59it/s]Running 10000 simulations.:  26%|██▌       | 2572/10000 [00:15<00:44, 165.35it/s]Running 10000 simulations.:  26%|██▌       | 2589/10000 [00:15<00:44, 165.80it/s]Running 10000 simulations.:  26%|██▌       | 2606/10000 [00:15<00:44, 166.25it/s]Running 10000 simulations.:  26%|██▌       | 2623/10000 [00:15<00:44, 166.66it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:15<00:44, 166.90it/s]Running 10000 simulations.:  27%|██▋       | 2657/10000 [00:16<00:43, 166.94it/s]Running 10000 simulations.:  27%|██▋       | 2674/10000 [00:16<00:43, 166.90it/s]Running 10000 simulations.:  27%|██▋       | 2691/10000 [00:16<00:43, 166.91it/s]Running 10000 simulations.:  27%|██▋       | 2708/10000 [00:16<00:43, 167.00it/s]Running 10000 simulations.:  27%|██▋       | 2725/10000 [00:16<00:43, 166.43it/s]Running 10000 simulations.:  27%|██▋       | 2742/10000 [00:16<00:43, 166.60it/s]Running 10000 simulations.:  28%|██▊       | 2759/10000 [00:16<00:43, 166.55it/s]Running 10000 simulations.:  28%|██▊       | 2776/10000 [00:16<00:43, 165.93it/s]Running 10000 simulations.:  28%|██▊       | 2793/10000 [00:16<00:43, 165.65it/s]Running 10000 simulations.:  28%|██▊       | 2810/10000 [00:16<00:43, 165.08it/s]Running 10000 simulations.:  28%|██▊       | 2827/10000 [00:17<00:43, 164.96it/s]Running 10000 simulations.:  28%|██▊       | 2844/10000 [00:17<00:43, 164.41it/s]Running 10000 simulations.:  29%|██▊       | 2861/10000 [00:17<00:43, 164.17it/s]Running 10000 simulations.:  29%|██▉       | 2878/10000 [00:17<00:43, 163.96it/s]Running 10000 simulations.:  29%|██▉       | 2895/10000 [00:17<00:43, 163.94it/s]Running 10000 simulations.:  29%|██▉       | 2912/10000 [00:17<00:43, 164.21it/s]Running 10000 simulations.:  29%|██▉       | 2929/10000 [00:17<00:42, 164.97it/s]Running 10000 simulations.:  29%|██▉       | 2946/10000 [00:17<00:42, 165.48it/s]Running 10000 simulations.:  30%|██▉       | 2963/10000 [00:17<00:42, 164.84it/s]Running 10000 simulations.:  30%|██▉       | 2980/10000 [00:17<00:42, 164.83it/s]Running 10000 simulations.:  30%|██▉       | 2997/10000 [00:18<00:42, 164.59it/s]Running 10000 simulations.:  30%|███       | 3014/10000 [00:18<00:42, 165.04it/s]Running 10000 simulations.:  30%|███       | 3031/10000 [00:18<00:42, 165.39it/s]Running 10000 simulations.:  30%|███       | 3048/10000 [00:18<00:42, 164.97it/s]Running 10000 simulations.:  31%|███       | 3065/10000 [00:18<00:42, 164.78it/s]Running 10000 simulations.:  31%|███       | 3082/10000 [00:18<00:41, 165.21it/s]Running 10000 simulations.:  31%|███       | 3099/10000 [00:18<00:41, 164.74it/s]Running 10000 simulations.:  31%|███       | 3116/10000 [00:18<00:41, 164.44it/s]Running 10000 simulations.:  31%|███▏      | 3133/10000 [00:18<00:41, 164.07it/s]Running 10000 simulations.:  32%|███▏      | 3150/10000 [00:19<00:41, 163.86it/s]Running 10000 simulations.:  32%|███▏      | 3167/10000 [00:19<00:41, 163.79it/s]Running 10000 simulations.:  32%|███▏      | 3184/10000 [00:19<00:41, 164.22it/s]Running 10000 simulations.:  32%|███▏      | 3201/10000 [00:19<00:41, 164.08it/s]Running 10000 simulations.:  32%|███▏      | 3218/10000 [00:19<00:41, 163.92it/s]Running 10000 simulations.:  32%|███▏      | 3235/10000 [00:19<00:41, 164.12it/s]Running 10000 simulations.:  33%|███▎      | 3252/10000 [00:19<00:41, 163.81it/s]Running 10000 simulations.:  33%|███▎      | 3269/10000 [00:19<00:41, 163.70it/s]Running 10000 simulations.:  33%|███▎      | 3286/10000 [00:19<00:40, 163.78it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:19<00:40, 163.64it/s]Running 10000 simulations.:  33%|███▎      | 3320/10000 [00:20<00:40, 163.58it/s]Running 10000 simulations.:  33%|███▎      | 3337/10000 [00:20<00:40, 164.50it/s]Running 10000 simulations.:  34%|███▎      | 3354/10000 [00:20<00:40, 165.03it/s]Running 10000 simulations.:  34%|███▎      | 3371/10000 [00:20<00:40, 165.49it/s]Running 10000 simulations.:  34%|███▍      | 3388/10000 [00:20<00:39, 165.47it/s]Running 10000 simulations.:  34%|███▍      | 3405/10000 [00:20<00:39, 165.50it/s]Running 10000 simulations.:  34%|███▍      | 3422/10000 [00:20<00:39, 165.19it/s]Running 10000 simulations.:  34%|███▍      | 3439/10000 [00:20<00:39, 165.17it/s]Running 10000 simulations.:  35%|███▍      | 3456/10000 [00:20<00:39, 165.64it/s]Running 10000 simulations.:  35%|███▍      | 3473/10000 [00:20<00:39, 165.43it/s]Running 10000 simulations.:  35%|███▍      | 3490/10000 [00:21<00:39, 165.36it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:21<00:39, 165.33it/s]Running 10000 simulations.:  35%|███▌      | 3524/10000 [00:21<00:39, 165.34it/s]Running 10000 simulations.:  35%|███▌      | 3541/10000 [00:21<00:38, 165.70it/s]Running 10000 simulations.:  36%|███▌      | 3558/10000 [00:21<00:38, 166.11it/s]Running 10000 simulations.:  36%|███▌      | 3575/10000 [00:21<00:38, 166.23it/s]Running 10000 simulations.:  36%|███▌      | 3592/10000 [00:21<00:38, 165.97it/s]Running 10000 simulations.:  36%|███▌      | 3609/10000 [00:21<00:38, 165.76it/s]Running 10000 simulations.:  36%|███▋      | 3626/10000 [00:21<00:38, 165.32it/s]Running 10000 simulations.:  36%|███▋      | 3643/10000 [00:21<00:38, 165.44it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:22<00:38, 165.00it/s]Running 10000 simulations.:  37%|███▋      | 3677/10000 [00:22<00:38, 164.12it/s]Running 10000 simulations.:  37%|███▋      | 3694/10000 [00:22<00:38, 163.81it/s]Running 10000 simulations.:  37%|███▋      | 3711/10000 [00:22<00:38, 163.46it/s]Running 10000 simulations.:  37%|███▋      | 3728/10000 [00:22<00:38, 163.67it/s]Running 10000 simulations.:  37%|███▋      | 3745/10000 [00:22<00:38, 163.86it/s]Running 10000 simulations.:  38%|███▊      | 3762/10000 [00:22<00:37, 164.69it/s]Running 10000 simulations.:  38%|███▊      | 3779/10000 [00:22<00:37, 164.48it/s]Running 10000 simulations.:  38%|███▊      | 3796/10000 [00:22<00:37, 164.36it/s]Running 10000 simulations.:  38%|███▊      | 3813/10000 [00:23<00:37, 164.83it/s]Running 10000 simulations.:  38%|███▊      | 3830/10000 [00:23<00:37, 165.05it/s]Running 10000 simulations.:  38%|███▊      | 3847/10000 [00:23<00:37, 165.64it/s]Running 10000 simulations.:  39%|███▊      | 3864/10000 [00:23<00:36, 166.06it/s]Running 10000 simulations.:  39%|███▉      | 3881/10000 [00:23<00:36, 166.08it/s]Running 10000 simulations.:  39%|███▉      | 3898/10000 [00:23<00:36, 166.23it/s]Running 10000 simulations.:  39%|███▉      | 3915/10000 [00:23<00:36, 165.77it/s]Running 10000 simulations.:  39%|███▉      | 3932/10000 [00:23<00:36, 165.13it/s]Running 10000 simulations.:  39%|███▉      | 3949/10000 [00:23<00:36, 165.28it/s]Running 10000 simulations.:  40%|███▉      | 3966/10000 [00:23<00:36, 165.48it/s]Running 10000 simulations.:  40%|███▉      | 3983/10000 [00:24<00:36, 164.83it/s]Running 10000 simulations.:  40%|████      | 4000/10000 [00:24<00:36, 164.50it/s]Running 10000 simulations.:  40%|████      | 4017/10000 [00:24<00:36, 164.25it/s]Running 10000 simulations.:  40%|████      | 4034/10000 [00:24<00:36, 164.64it/s]Running 10000 simulations.:  41%|████      | 4051/10000 [00:24<00:36, 164.87it/s]Running 10000 simulations.:  41%|████      | 4068/10000 [00:24<00:35, 165.05it/s]Running 10000 simulations.:  41%|████      | 4085/10000 [00:24<00:35, 165.19it/s]Running 10000 simulations.:  41%|████      | 4102/10000 [00:24<00:35, 164.84it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:24<00:35, 165.26it/s]Running 10000 simulations.:  41%|████▏     | 4136/10000 [00:24<00:35, 165.17it/s]Running 10000 simulations.:  42%|████▏     | 4153/10000 [00:25<00:35, 165.69it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:25<00:35, 165.79it/s]Running 10000 simulations.:  42%|████▏     | 4187/10000 [00:25<00:35, 166.00it/s]Running 10000 simulations.:  42%|████▏     | 4204/10000 [00:25<00:34, 165.66it/s]Running 10000 simulations.:  42%|████▏     | 4221/10000 [00:25<00:34, 165.14it/s]Running 10000 simulations.:  42%|████▏     | 4238/10000 [00:25<00:34, 165.08it/s]Running 10000 simulations.:  43%|████▎     | 4255/10000 [00:25<00:34, 164.96it/s]Running 10000 simulations.:  43%|████▎     | 4273/10000 [00:25<00:34, 167.25it/s]Running 10000 simulations.:  43%|████▎     | 4293/10000 [00:25<00:32, 174.99it/s]Running 10000 simulations.:  43%|████▎     | 4311/10000 [00:26<00:32, 173.43it/s]Running 10000 simulations.:  43%|████▎     | 4329/10000 [00:26<00:33, 171.41it/s]Running 10000 simulations.:  43%|████▎     | 4347/10000 [00:26<00:33, 169.81it/s]Running 10000 simulations.:  44%|████▎     | 4365/10000 [00:26<00:33, 168.82it/s]Running 10000 simulations.:  44%|████▍     | 4382/10000 [00:26<00:33, 168.06it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:26<00:33, 167.33it/s]Running 10000 simulations.:  44%|████▍     | 4416/10000 [00:26<00:33, 166.97it/s]Running 10000 simulations.:  44%|████▍     | 4433/10000 [00:26<00:33, 166.84it/s]Running 10000 simulations.:  44%|████▍     | 4450/10000 [00:26<00:33, 166.23it/s]Running 10000 simulations.:  45%|████▍     | 4467/10000 [00:26<00:33, 165.63it/s]Running 10000 simulations.:  45%|████▍     | 4484/10000 [00:27<00:33, 165.49it/s]Running 10000 simulations.:  45%|████▌     | 4501/10000 [00:27<00:33, 166.25it/s]Running 10000 simulations.:  45%|████▌     | 4518/10000 [00:27<00:32, 166.15it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:27<00:32, 165.75it/s]Running 10000 simulations.:  46%|████▌     | 4552/10000 [00:27<00:32, 165.53it/s]Running 10000 simulations.:  46%|████▌     | 4569/10000 [00:27<00:32, 164.86it/s]Running 10000 simulations.:  46%|████▌     | 4586/10000 [00:27<00:32, 164.40it/s]Running 10000 simulations.:  46%|████▌     | 4603/10000 [00:27<00:32, 164.08it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:27<00:34, 157.30it/s]Running 10000 simulations.:  46%|████▋     | 4637/10000 [00:28<00:33, 159.21it/s]Running 10000 simulations.:  47%|████▋     | 4654/10000 [00:28<00:33, 161.41it/s]Running 10000 simulations.:  47%|████▋     | 4671/10000 [00:28<00:32, 162.14it/s]Running 10000 simulations.:  47%|████▋     | 4688/10000 [00:28<00:32, 163.20it/s]Running 10000 simulations.:  47%|████▋     | 4705/10000 [00:28<00:32, 163.72it/s]Running 10000 simulations.:  47%|████▋     | 4722/10000 [00:28<00:32, 163.51it/s]Running 10000 simulations.:  47%|████▋     | 4739/10000 [00:28<00:32, 163.74it/s]Running 10000 simulations.:  48%|████▊     | 4756/10000 [00:28<00:31, 164.40it/s]Running 10000 simulations.:  48%|████▊     | 4773/10000 [00:28<00:31, 164.55it/s]Running 10000 simulations.:  48%|████▊     | 4790/10000 [00:28<00:31, 164.13it/s]Running 10000 simulations.:  48%|████▊     | 4807/10000 [00:29<00:31, 163.78it/s]Running 10000 simulations.:  48%|████▊     | 4824/10000 [00:29<00:31, 163.80it/s]Running 10000 simulations.:  48%|████▊     | 4841/10000 [00:29<00:31, 163.68it/s]Running 10000 simulations.:  49%|████▊     | 4858/10000 [00:29<00:31, 163.54it/s]Running 10000 simulations.:  49%|████▉     | 4875/10000 [00:29<00:31, 163.57it/s]Running 10000 simulations.:  49%|████▉     | 4892/10000 [00:29<00:31, 163.42it/s]Running 10000 simulations.:  49%|████▉     | 4909/10000 [00:29<00:31, 164.22it/s]Running 10000 simulations.:  49%|████▉     | 4926/10000 [00:29<00:30, 164.09it/s]Running 10000 simulations.:  49%|████▉     | 4943/10000 [00:29<00:30, 163.77it/s]Running 10000 simulations.:  50%|████▉     | 4960/10000 [00:29<00:30, 163.59it/s]Running 10000 simulations.:  50%|████▉     | 4977/10000 [00:30<00:30, 163.35it/s]Running 10000 simulations.:  50%|████▉     | 4994/10000 [00:30<00:30, 163.27it/s]Running 10000 simulations.:  50%|█████     | 5011/10000 [00:30<00:30, 163.31it/s]Running 10000 simulations.:  50%|█████     | 5028/10000 [00:30<00:30, 164.05it/s]Running 10000 simulations.:  50%|█████     | 5045/10000 [00:30<00:30, 164.84it/s]Running 10000 simulations.:  51%|█████     | 5062/10000 [00:30<00:29, 165.45it/s]Running 10000 simulations.:  51%|█████     | 5079/10000 [00:30<00:29, 165.02it/s]Running 10000 simulations.:  51%|█████     | 5096/10000 [00:30<00:29, 165.23it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:30<00:29, 165.66it/s]Running 10000 simulations.:  51%|█████▏    | 5130/10000 [00:31<00:29, 165.29it/s]Running 10000 simulations.:  51%|█████▏    | 5147/10000 [00:31<00:29, 164.74it/s]Running 10000 simulations.:  52%|█████▏    | 5164/10000 [00:31<00:29, 165.04it/s]Running 10000 simulations.:  52%|█████▏    | 5181/10000 [00:31<00:29, 165.46it/s]Running 10000 simulations.:  52%|█████▏    | 5198/10000 [00:31<00:28, 165.73it/s]Running 10000 simulations.:  52%|█████▏    | 5215/10000 [00:31<00:28, 166.12it/s]Running 10000 simulations.:  52%|█████▏    | 5232/10000 [00:31<00:28, 165.71it/s]Running 10000 simulations.:  52%|█████▏    | 5249/10000 [00:31<00:28, 165.79it/s]Running 10000 simulations.:  53%|█████▎    | 5266/10000 [00:31<00:28, 165.55it/s]Running 10000 simulations.:  53%|█████▎    | 5283/10000 [00:31<00:28, 165.90it/s]Running 10000 simulations.:  53%|█████▎    | 5300/10000 [00:32<00:28, 165.16it/s]Running 10000 simulations.:  53%|█████▎    | 5317/10000 [00:32<00:28, 164.55it/s]Running 10000 simulations.:  53%|█████▎    | 5334/10000 [00:32<00:28, 164.35it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:32<00:28, 164.57it/s]Running 10000 simulations.:  54%|█████▎    | 5368/10000 [00:32<00:28, 164.68it/s]Running 10000 simulations.:  54%|█████▍    | 5385/10000 [00:32<00:28, 164.23it/s]Running 10000 simulations.:  54%|█████▍    | 5402/10000 [00:32<00:27, 164.50it/s]Running 10000 simulations.:  54%|█████▍    | 5419/10000 [00:32<00:27, 164.01it/s]Running 10000 simulations.:  54%|█████▍    | 5436/10000 [00:32<00:27, 163.86it/s]Running 10000 simulations.:  55%|█████▍    | 5453/10000 [00:32<00:27, 163.61it/s]Running 10000 simulations.:  55%|█████▍    | 5470/10000 [00:33<00:27, 163.81it/s]Running 10000 simulations.:  55%|█████▍    | 5487/10000 [00:33<00:27, 163.99it/s]Running 10000 simulations.:  55%|█████▌    | 5504/10000 [00:33<00:27, 164.06it/s]Running 10000 simulations.:  55%|█████▌    | 5521/10000 [00:33<00:27, 164.29it/s]Running 10000 simulations.:  55%|█████▌    | 5538/10000 [00:33<00:27, 164.93it/s]Running 10000 simulations.:  56%|█████▌    | 5555/10000 [00:33<00:26, 164.93it/s]Running 10000 simulations.:  56%|█████▌    | 5572/10000 [00:33<00:26, 164.40it/s]Running 10000 simulations.:  56%|█████▌    | 5589/10000 [00:33<00:26, 164.08it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:33<00:26, 163.90it/s]Running 10000 simulations.:  56%|█████▌    | 5623/10000 [00:33<00:26, 164.24it/s]Running 10000 simulations.:  56%|█████▋    | 5640/10000 [00:34<00:26, 164.48it/s]Running 10000 simulations.:  57%|█████▋    | 5657/10000 [00:34<00:26, 164.06it/s]Running 10000 simulations.:  57%|█████▋    | 5674/10000 [00:34<00:26, 163.73it/s]Running 10000 simulations.:  57%|█████▋    | 5691/10000 [00:34<00:26, 163.58it/s]Running 10000 simulations.:  57%|█████▋    | 5708/10000 [00:34<00:26, 163.75it/s]Running 10000 simulations.:  57%|█████▋    | 5725/10000 [00:34<00:26, 164.05it/s]Running 10000 simulations.:  57%|█████▋    | 5742/10000 [00:34<00:25, 164.31it/s]Running 10000 simulations.:  58%|█████▊    | 5759/10000 [00:34<00:25, 164.01it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:34<00:25, 164.54it/s]Running 10000 simulations.:  58%|█████▊    | 5793/10000 [00:35<00:25, 164.11it/s]Running 10000 simulations.:  58%|█████▊    | 5810/10000 [00:35<00:25, 164.10it/s]Running 10000 simulations.:  58%|█████▊    | 5827/10000 [00:35<00:25, 164.00it/s]Running 10000 simulations.:  58%|█████▊    | 5844/10000 [00:35<00:25, 164.71it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:35<00:25, 165.39it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:35<00:24, 165.30it/s]Running 10000 simulations.:  59%|█████▉    | 5895/10000 [00:35<00:24, 165.19it/s]Running 10000 simulations.:  59%|█████▉    | 5912/10000 [00:35<00:24, 165.52it/s]Running 10000 simulations.:  59%|█████▉    | 5929/10000 [00:35<00:24, 165.88it/s]Running 10000 simulations.:  59%|█████▉    | 5946/10000 [00:35<00:24, 166.46it/s]Running 10000 simulations.:  60%|█████▉    | 5963/10000 [00:36<00:24, 166.44it/s]Running 10000 simulations.:  60%|█████▉    | 5980/10000 [00:36<00:24, 166.53it/s]Running 10000 simulations.:  60%|█████▉    | 5997/10000 [00:36<00:24, 165.89it/s]Running 10000 simulations.:  60%|██████    | 6014/10000 [00:36<00:24, 165.28it/s]Running 10000 simulations.:  60%|██████    | 6031/10000 [00:36<00:24, 165.34it/s]Running 10000 simulations.:  60%|██████    | 6048/10000 [00:36<00:23, 164.73it/s]Running 10000 simulations.:  61%|██████    | 6065/10000 [00:36<00:23, 164.18it/s]Running 10000 simulations.:  61%|██████    | 6082/10000 [00:36<00:23, 164.15it/s]Running 10000 simulations.:  61%|██████    | 6099/10000 [00:36<00:23, 164.16it/s]Running 10000 simulations.:  61%|██████    | 6116/10000 [00:36<00:23, 164.81it/s]Running 10000 simulations.:  61%|██████▏   | 6133/10000 [00:37<00:23, 165.40it/s]Running 10000 simulations.:  62%|██████▏   | 6150/10000 [00:37<00:23, 166.03it/s]Running 10000 simulations.:  62%|██████▏   | 6167/10000 [00:37<00:23, 166.08it/s]Running 10000 simulations.:  62%|██████▏   | 6184/10000 [00:37<00:23, 165.52it/s]Running 10000 simulations.:  62%|██████▏   | 6201/10000 [00:37<00:22, 165.31it/s]Running 10000 simulations.:  62%|██████▏   | 6218/10000 [00:37<00:22, 165.48it/s]Running 10000 simulations.:  62%|██████▏   | 6235/10000 [00:37<00:22, 164.89it/s]Running 10000 simulations.:  63%|██████▎   | 6252/10000 [00:37<00:22, 164.35it/s]Running 10000 simulations.:  63%|██████▎   | 6269/10000 [00:37<00:22, 165.01it/s]Running 10000 simulations.:  63%|██████▎   | 6286/10000 [00:38<00:22, 164.80it/s]Running 10000 simulations.:  63%|██████▎   | 6303/10000 [00:38<00:22, 164.30it/s]Running 10000 simulations.:  63%|██████▎   | 6320/10000 [00:38<00:22, 164.19it/s]Running 10000 simulations.:  63%|██████▎   | 6337/10000 [00:38<00:22, 164.70it/s]Running 10000 simulations.:  64%|██████▎   | 6354/10000 [00:38<00:22, 165.29it/s]Running 10000 simulations.:  64%|██████▎   | 6371/10000 [00:38<00:21, 165.18it/s]Running 10000 simulations.:  64%|██████▍   | 6388/10000 [00:38<00:21, 165.53it/s]Running 10000 simulations.:  64%|██████▍   | 6405/10000 [00:38<00:21, 165.77it/s]Running 10000 simulations.:  64%|██████▍   | 6422/10000 [00:38<00:21, 166.00it/s]Running 10000 simulations.:  64%|██████▍   | 6439/10000 [00:38<00:21, 166.12it/s]Running 10000 simulations.:  65%|██████▍   | 6456/10000 [00:39<00:21, 165.94it/s]Running 10000 simulations.:  65%|██████▍   | 6473/10000 [00:39<00:21, 165.47it/s]Running 10000 simulations.:  65%|██████▍   | 6490/10000 [00:39<00:21, 165.05it/s]Running 10000 simulations.:  65%|██████▌   | 6507/10000 [00:39<00:21, 164.74it/s]Running 10000 simulations.:  65%|██████▌   | 6524/10000 [00:39<00:21, 164.54it/s]Running 10000 simulations.:  65%|██████▌   | 6541/10000 [00:39<00:20, 164.75it/s]Running 10000 simulations.:  66%|██████▌   | 6558/10000 [00:39<00:20, 164.49it/s]Running 10000 simulations.:  66%|██████▌   | 6576/10000 [00:39<00:20, 167.43it/s]Running 10000 simulations.:  66%|██████▌   | 6595/10000 [00:39<00:19, 171.92it/s]Running 10000 simulations.:  66%|██████▌   | 6613/10000 [00:39<00:19, 169.93it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:40<00:19, 168.93it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:40<00:19, 167.74it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:40<00:20, 166.42it/s]Running 10000 simulations.:  67%|██████▋   | 6682/10000 [00:40<00:20, 165.64it/s]Running 10000 simulations.:  67%|██████▋   | 6699/10000 [00:40<00:20, 164.99it/s]Running 10000 simulations.:  67%|██████▋   | 6716/10000 [00:40<00:19, 165.17it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:40<00:19, 164.77it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:40<00:19, 164.95it/s]Running 10000 simulations.:  68%|██████▊   | 6767/10000 [00:40<00:19, 164.34it/s]Running 10000 simulations.:  68%|██████▊   | 6784/10000 [00:41<00:19, 164.23it/s]Running 10000 simulations.:  68%|██████▊   | 6801/10000 [00:41<00:19, 164.75it/s]Running 10000 simulations.:  68%|██████▊   | 6818/10000 [00:41<00:19, 164.55it/s]Running 10000 simulations.:  68%|██████▊   | 6835/10000 [00:41<00:19, 165.20it/s]Running 10000 simulations.:  69%|██████▊   | 6852/10000 [00:41<00:19, 164.75it/s]Running 10000 simulations.:  69%|██████▊   | 6869/10000 [00:41<00:19, 164.43it/s]Running 10000 simulations.:  69%|██████▉   | 6886/10000 [00:41<00:18, 164.31it/s]Running 10000 simulations.:  69%|██████▉   | 6903/10000 [00:41<00:18, 164.41it/s]Running 10000 simulations.:  69%|██████▉   | 6920/10000 [00:41<00:18, 165.16it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:41<00:18, 165.49it/s]Running 10000 simulations.:  70%|██████▉   | 6954/10000 [00:42<00:18, 165.21it/s]Running 10000 simulations.:  70%|██████▉   | 6971/10000 [00:42<00:18, 164.81it/s]Running 10000 simulations.:  70%|██████▉   | 6988/10000 [00:42<00:18, 164.89it/s]Running 10000 simulations.:  70%|███████   | 7005/10000 [00:42<00:18, 164.81it/s]Running 10000 simulations.:  70%|███████   | 7022/10000 [00:42<00:18, 164.33it/s]Running 10000 simulations.:  70%|███████   | 7039/10000 [00:42<00:18, 164.34it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:42<00:17, 164.69it/s]Running 10000 simulations.:  71%|███████   | 7073/10000 [00:42<00:17, 164.69it/s]Running 10000 simulations.:  71%|███████   | 7090/10000 [00:42<00:17, 165.34it/s]Running 10000 simulations.:  71%|███████   | 7107/10000 [00:42<00:17, 165.33it/s]Running 10000 simulations.:  71%|███████   | 7124/10000 [00:43<00:17, 165.60it/s]Running 10000 simulations.:  71%|███████▏  | 7141/10000 [00:43<00:17, 164.83it/s]Running 10000 simulations.:  72%|███████▏  | 7158/10000 [00:43<00:17, 165.18it/s]Running 10000 simulations.:  72%|███████▏  | 7175/10000 [00:43<00:17, 165.53it/s]Running 10000 simulations.:  72%|███████▏  | 7192/10000 [00:43<00:17, 165.12it/s]Running 10000 simulations.:  72%|███████▏  | 7209/10000 [00:43<00:16, 164.95it/s]Running 10000 simulations.:  72%|███████▏  | 7226/10000 [00:43<00:16, 164.48it/s]Running 10000 simulations.:  72%|███████▏  | 7243/10000 [00:43<00:16, 164.47it/s]Running 10000 simulations.:  73%|███████▎  | 7260/10000 [00:43<00:16, 164.80it/s]Running 10000 simulations.:  73%|███████▎  | 7277/10000 [00:44<00:16, 165.39it/s]Running 10000 simulations.:  73%|███████▎  | 7294/10000 [00:44<00:16, 164.78it/s]Running 10000 simulations.:  73%|███████▎  | 7311/10000 [00:44<00:16, 164.36it/s]Running 10000 simulations.:  73%|███████▎  | 7328/10000 [00:44<00:16, 164.06it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:44<00:16, 164.15it/s]Running 10000 simulations.:  74%|███████▎  | 7362/10000 [00:44<00:16, 164.61it/s]Running 10000 simulations.:  74%|███████▍  | 7379/10000 [00:44<00:15, 164.94it/s]Running 10000 simulations.:  74%|███████▍  | 7396/10000 [00:44<00:15, 164.77it/s]Running 10000 simulations.:  74%|███████▍  | 7413/10000 [00:44<00:15, 164.83it/s]Running 10000 simulations.:  74%|███████▍  | 7430/10000 [00:44<00:15, 164.63it/s]Running 10000 simulations.:  74%|███████▍  | 7447/10000 [00:45<00:15, 164.36it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:45<00:15, 164.96it/s]Running 10000 simulations.:  75%|███████▍  | 7481/10000 [00:45<00:15, 164.81it/s]Running 10000 simulations.:  75%|███████▍  | 7498/10000 [00:45<00:15, 164.61it/s]Running 10000 simulations.:  75%|███████▌  | 7515/10000 [00:45<00:15, 164.79it/s]Running 10000 simulations.:  75%|███████▌  | 7532/10000 [00:45<00:14, 165.28it/s]Running 10000 simulations.:  75%|███████▌  | 7549/10000 [00:45<00:14, 165.00it/s]Running 10000 simulations.:  76%|███████▌  | 7566/10000 [00:45<00:14, 165.42it/s]Running 10000 simulations.:  76%|███████▌  | 7583/10000 [00:45<00:14, 165.55it/s]Running 10000 simulations.:  76%|███████▌  | 7600/10000 [00:45<00:14, 165.65it/s]Running 10000 simulations.:  76%|███████▌  | 7617/10000 [00:46<00:14, 166.19it/s]Running 10000 simulations.:  76%|███████▋  | 7634/10000 [00:46<00:14, 166.32it/s]Running 10000 simulations.:  77%|███████▋  | 7651/10000 [00:46<00:14, 166.51it/s]Running 10000 simulations.:  77%|███████▋  | 7668/10000 [00:46<00:14, 165.90it/s]Running 10000 simulations.:  77%|███████▋  | 7685/10000 [00:46<00:14, 165.36it/s]Running 10000 simulations.:  77%|███████▋  | 7702/10000 [00:46<00:13, 165.66it/s]Running 10000 simulations.:  77%|███████▋  | 7719/10000 [00:46<00:13, 165.97it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:46<00:13, 165.19it/s]Running 10000 simulations.:  78%|███████▊  | 7753/10000 [00:46<00:13, 164.78it/s]Running 10000 simulations.:  78%|███████▊  | 7770/10000 [00:46<00:13, 164.41it/s]Running 10000 simulations.:  78%|███████▊  | 7787/10000 [00:47<00:13, 163.95it/s]Running 10000 simulations.:  78%|███████▊  | 7804/10000 [00:47<00:13, 163.77it/s]Running 10000 simulations.:  78%|███████▊  | 7821/10000 [00:47<00:13, 163.73it/s]Running 10000 simulations.:  78%|███████▊  | 7838/10000 [00:47<00:13, 163.66it/s]Running 10000 simulations.:  79%|███████▊  | 7855/10000 [00:47<00:13, 163.65it/s]Running 10000 simulations.:  79%|███████▊  | 7872/10000 [00:47<00:13, 163.51it/s]Running 10000 simulations.:  79%|███████▉  | 7889/10000 [00:47<00:12, 163.61it/s]Running 10000 simulations.:  79%|███████▉  | 7906/10000 [00:47<00:12, 163.78it/s]Running 10000 simulations.:  79%|███████▉  | 7923/10000 [00:47<00:12, 163.69it/s]Running 10000 simulations.:  79%|███████▉  | 7940/10000 [00:48<00:12, 163.50it/s]Running 10000 simulations.:  80%|███████▉  | 7957/10000 [00:48<00:12, 163.48it/s]Running 10000 simulations.:  80%|███████▉  | 7974/10000 [00:48<00:12, 163.40it/s]Running 10000 simulations.:  80%|███████▉  | 7991/10000 [00:48<00:12, 163.42it/s]Running 10000 simulations.:  80%|████████  | 8008/10000 [00:48<00:12, 163.49it/s]Running 10000 simulations.:  80%|████████  | 8025/10000 [00:48<00:12, 163.62it/s]Running 10000 simulations.:  80%|████████  | 8042/10000 [00:48<00:11, 164.39it/s]Running 10000 simulations.:  81%|████████  | 8059/10000 [00:48<00:11, 164.43it/s]Running 10000 simulations.:  81%|████████  | 8076/10000 [00:48<00:11, 165.14it/s]Running 10000 simulations.:  81%|████████  | 8093/10000 [00:48<00:11, 165.70it/s]Running 10000 simulations.:  81%|████████  | 8110/10000 [00:49<00:11, 165.17it/s]Running 10000 simulations.:  81%|████████▏ | 8127/10000 [00:49<00:11, 164.63it/s]Running 10000 simulations.:  81%|████████▏ | 8144/10000 [00:49<00:11, 164.59it/s]Running 10000 simulations.:  82%|████████▏ | 8161/10000 [00:49<00:11, 164.22it/s]Running 10000 simulations.:  82%|████████▏ | 8178/10000 [00:49<00:11, 164.64it/s]Running 10000 simulations.:  82%|████████▏ | 8195/10000 [00:49<00:10, 165.31it/s]Running 10000 simulations.:  82%|████████▏ | 8212/10000 [00:49<00:10, 165.80it/s]Running 10000 simulations.:  82%|████████▏ | 8229/10000 [00:49<00:10, 166.26it/s]Running 10000 simulations.:  82%|████████▏ | 8246/10000 [00:49<00:10, 165.65it/s]Running 10000 simulations.:  83%|████████▎ | 8263/10000 [00:49<00:10, 165.08it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:50<00:10, 164.74it/s]Running 10000 simulations.:  83%|████████▎ | 8297/10000 [00:50<00:10, 164.66it/s]Running 10000 simulations.:  83%|████████▎ | 8314/10000 [00:50<00:10, 164.72it/s]Running 10000 simulations.:  83%|████████▎ | 8331/10000 [00:50<00:10, 164.96it/s]Running 10000 simulations.:  83%|████████▎ | 8348/10000 [00:50<00:09, 165.52it/s]Running 10000 simulations.:  84%|████████▎ | 8365/10000 [00:50<00:09, 166.00it/s]Running 10000 simulations.:  84%|████████▍ | 8382/10000 [00:50<00:09, 165.55it/s]Running 10000 simulations.:  84%|████████▍ | 8399/10000 [00:50<00:09, 165.46it/s]Running 10000 simulations.:  84%|████████▍ | 8416/10000 [00:50<00:09, 164.75it/s]Running 10000 simulations.:  84%|████████▍ | 8433/10000 [00:51<00:09, 164.62it/s]Running 10000 simulations.:  84%|████████▍ | 8450/10000 [00:51<00:09, 164.33it/s]Running 10000 simulations.:  85%|████████▍ | 8467/10000 [00:51<00:09, 164.42it/s]Running 10000 simulations.:  85%|████████▍ | 8484/10000 [00:51<00:09, 164.27it/s]Running 10000 simulations.:  85%|████████▌ | 8501/10000 [00:51<00:09, 163.97it/s]Running 10000 simulations.:  85%|████████▌ | 8518/10000 [00:51<00:09, 163.78it/s]Running 10000 simulations.:  85%|████████▌ | 8535/10000 [00:51<00:08, 164.02it/s]Running 10000 simulations.:  86%|████████▌ | 8552/10000 [00:51<00:08, 164.38it/s]Running 10000 simulations.:  86%|████████▌ | 8569/10000 [00:51<00:08, 164.97it/s]Running 10000 simulations.:  86%|████████▌ | 8586/10000 [00:51<00:08, 165.53it/s]Running 10000 simulations.:  86%|████████▌ | 8603/10000 [00:52<00:08, 165.09it/s]Running 10000 simulations.:  86%|████████▌ | 8620/10000 [00:52<00:08, 164.47it/s]Running 10000 simulations.:  86%|████████▋ | 8637/10000 [00:52<00:08, 164.77it/s]Running 10000 simulations.:  87%|████████▋ | 8655/10000 [00:52<00:08, 167.41it/s]Running 10000 simulations.:  87%|████████▋ | 8674/10000 [00:52<00:07, 171.22it/s]Running 10000 simulations.:  87%|████████▋ | 8692/10000 [00:52<00:07, 168.78it/s]Running 10000 simulations.:  87%|████████▋ | 8709/10000 [00:52<00:07, 167.68it/s]Running 10000 simulations.:  87%|████████▋ | 8726/10000 [00:52<00:07, 166.99it/s]Running 10000 simulations.:  87%|████████▋ | 8743/10000 [00:52<00:07, 165.96it/s]Running 10000 simulations.:  88%|████████▊ | 8760/10000 [00:52<00:07, 165.51it/s]Running 10000 simulations.:  88%|████████▊ | 8777/10000 [00:53<00:07, 165.79it/s]Running 10000 simulations.:  88%|████████▊ | 8794/10000 [00:53<00:07, 165.98it/s]Running 10000 simulations.:  88%|████████▊ | 8811/10000 [00:53<00:07, 166.13it/s]Running 10000 simulations.:  88%|████████▊ | 8828/10000 [00:53<00:07, 165.31it/s]Running 10000 simulations.:  88%|████████▊ | 8845/10000 [00:53<00:07, 164.87it/s]Running 10000 simulations.:  89%|████████▊ | 8862/10000 [00:53<00:06, 164.52it/s]Running 10000 simulations.:  89%|████████▉ | 8879/10000 [00:53<00:06, 165.47it/s]Running 10000 simulations.:  89%|████████▉ | 8896/10000 [00:53<00:06, 165.81it/s]Running 10000 simulations.:  89%|████████▉ | 8913/10000 [00:53<00:06, 165.96it/s]Running 10000 simulations.:  89%|████████▉ | 8930/10000 [00:54<00:06, 165.78it/s]Running 10000 simulations.:  89%|████████▉ | 8947/10000 [00:54<00:06, 165.89it/s]Running 10000 simulations.:  90%|████████▉ | 8964/10000 [00:54<00:06, 165.47it/s]Running 10000 simulations.:  90%|████████▉ | 8981/10000 [00:54<00:06, 165.30it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:54<00:06, 164.77it/s]Running 10000 simulations.:  90%|█████████ | 9015/10000 [00:54<00:05, 164.94it/s]Running 10000 simulations.:  90%|█████████ | 9032/10000 [00:54<00:05, 165.17it/s]Running 10000 simulations.:  90%|█████████ | 9049/10000 [00:54<00:05, 165.59it/s]Running 10000 simulations.:  91%|█████████ | 9066/10000 [00:54<00:05, 164.95it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [00:54<00:05, 165.58it/s]Running 10000 simulations.:  91%|█████████ | 9100/10000 [00:55<00:05, 165.19it/s]Running 10000 simulations.:  91%|█████████ | 9117/10000 [00:55<00:05, 164.86it/s]Running 10000 simulations.:  91%|█████████▏| 9134/10000 [00:55<00:05, 164.40it/s]Running 10000 simulations.:  92%|█████████▏| 9151/10000 [00:55<00:05, 164.17it/s]Running 10000 simulations.:  92%|█████████▏| 9168/10000 [00:55<00:05, 163.93it/s]Running 10000 simulations.:  92%|█████████▏| 9185/10000 [00:55<00:04, 163.62it/s]Running 10000 simulations.:  92%|█████████▏| 9202/10000 [00:55<00:04, 163.57it/s]Running 10000 simulations.:  92%|█████████▏| 9219/10000 [00:55<00:04, 163.46it/s]Running 10000 simulations.:  92%|█████████▏| 9236/10000 [00:55<00:04, 163.32it/s]Running 10000 simulations.:  93%|█████████▎| 9253/10000 [00:55<00:04, 163.62it/s]Running 10000 simulations.:  93%|█████████▎| 9270/10000 [00:56<00:04, 163.94it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [00:56<00:04, 164.51it/s]Running 10000 simulations.:  93%|█████████▎| 9304/10000 [00:56<00:04, 164.99it/s]Running 10000 simulations.:  93%|█████████▎| 9321/10000 [00:56<00:04, 164.80it/s]Running 10000 simulations.:  93%|█████████▎| 9338/10000 [00:56<00:04, 164.83it/s]Running 10000 simulations.:  94%|█████████▎| 9355/10000 [00:56<00:03, 164.79it/s]Running 10000 simulations.:  94%|█████████▎| 9372/10000 [00:56<00:03, 164.49it/s]Running 10000 simulations.:  94%|█████████▍| 9389/10000 [00:56<00:03, 164.55it/s]Running 10000 simulations.:  94%|█████████▍| 9406/10000 [00:56<00:03, 164.58it/s]Running 10000 simulations.:  94%|█████████▍| 9423/10000 [00:57<00:03, 164.45it/s]Running 10000 simulations.:  94%|█████████▍| 9440/10000 [00:57<00:03, 164.82it/s]Running 10000 simulations.:  95%|█████████▍| 9457/10000 [00:57<00:03, 164.89it/s]Running 10000 simulations.:  95%|█████████▍| 9474/10000 [00:57<00:03, 165.39it/s]Running 10000 simulations.:  95%|█████████▍| 9491/10000 [00:57<00:03, 165.01it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [00:57<00:02, 164.47it/s]Running 10000 simulations.:  95%|█████████▌| 9525/10000 [00:57<00:02, 164.12it/s]Running 10000 simulations.:  95%|█████████▌| 9542/10000 [00:57<00:02, 164.53it/s]Running 10000 simulations.:  96%|█████████▌| 9559/10000 [00:57<00:02, 164.52it/s]Running 10000 simulations.:  96%|█████████▌| 9576/10000 [00:57<00:02, 158.02it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:58<00:02, 160.40it/s]Running 10000 simulations.:  96%|█████████▌| 9610/10000 [00:58<00:02, 161.75it/s]Running 10000 simulations.:  96%|█████████▋| 9627/10000 [00:58<00:02, 162.17it/s]Running 10000 simulations.:  96%|█████████▋| 9644/10000 [00:58<00:02, 162.55it/s]Running 10000 simulations.:  97%|█████████▋| 9661/10000 [00:58<00:02, 162.88it/s]Running 10000 simulations.:  97%|█████████▋| 9678/10000 [00:58<00:01, 163.45it/s]Running 10000 simulations.:  97%|█████████▋| 9695/10000 [00:58<00:01, 164.04it/s]Running 10000 simulations.:  97%|█████████▋| 9712/10000 [00:58<00:01, 163.58it/s]Running 10000 simulations.:  97%|█████████▋| 9729/10000 [00:58<00:01, 163.71it/s]Running 10000 simulations.:  97%|█████████▋| 9746/10000 [00:58<00:01, 163.83it/s]Running 10000 simulations.:  98%|█████████▊| 9763/10000 [00:59<00:01, 163.72it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [00:59<00:01, 164.01it/s]Running 10000 simulations.:  98%|█████████▊| 9797/10000 [00:59<00:01, 163.45it/s]Running 10000 simulations.:  98%|█████████▊| 9814/10000 [00:59<00:01, 163.32it/s]Running 10000 simulations.:  98%|█████████▊| 9831/10000 [00:59<00:01, 163.25it/s]Running 10000 simulations.:  98%|█████████▊| 9848/10000 [00:59<00:00, 163.25it/s]Running 10000 simulations.:  99%|█████████▊| 9865/10000 [00:59<00:00, 163.53it/s]Running 10000 simulations.:  99%|█████████▉| 9882/10000 [00:59<00:00, 164.32it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:59<00:00, 164.59it/s]Running 10000 simulations.:  99%|█████████▉| 9916/10000 [01:00<00:00, 164.00it/s]Running 10000 simulations.:  99%|█████████▉| 9933/10000 [01:00<00:00, 164.16it/s]Running 10000 simulations.: 100%|█████████▉| 9950/10000 [01:00<00:00, 163.88it/s]Running 10000 simulations.: 100%|█████████▉| 9967/10000 [01:00<00:00, 163.84it/s]Running 10000 simulations.: 100%|█████████▉| 9984/10000 [01:00<00:00, 164.17it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:00<00:00, 165.15it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 17/10000 [00:00<00:59, 168.77it/s]Running 10000 simulations.:   0%|          | 34/10000 [00:00<00:59, 168.68it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<00:59, 167.90it/s]Running 10000 simulations.:   1%|          | 68/10000 [00:00<00:59, 168.00it/s]Running 10000 simulations.:   1%|          | 85/10000 [00:00<00:58, 168.36it/s]Running 10000 simulations.:   1%|          | 102/10000 [00:00<00:58, 168.62it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<00:58, 168.18it/s]Running 10000 simulations.:   1%|▏         | 136/10000 [00:00<00:58, 167.99it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:58, 167.68it/s]Running 10000 simulations.:   2%|▏         | 170/10000 [00:01<00:58, 167.67it/s]Running 10000 simulations.:   2%|▏         | 187/10000 [00:01<00:58, 167.63it/s]Running 10000 simulations.:   2%|▏         | 204/10000 [00:01<00:58, 167.65it/s]Running 10000 simulations.:   2%|▏         | 221/10000 [00:01<00:58, 167.83it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:01<00:58, 168.10it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<00:58, 167.60it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<00:58, 167.26it/s]Running 10000 simulations.:   3%|▎         | 289/10000 [00:01<00:58, 166.86it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:58, 166.84it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:58, 166.80it/s]Running 10000 simulations.:   3%|▎         | 340/10000 [00:02<00:57, 166.68it/s]Running 10000 simulations.:   4%|▎         | 357/10000 [00:02<00:57, 166.71it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:02<00:57, 166.71it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:02<00:57, 167.17it/s]Running 10000 simulations.:   4%|▍         | 408/10000 [00:02<00:57, 167.23it/s]Running 10000 simulations.:   4%|▍         | 425/10000 [00:02<00:57, 167.23it/s]Running 10000 simulations.:   4%|▍         | 442/10000 [00:02<00:57, 167.09it/s]Running 10000 simulations.:   5%|▍         | 459/10000 [00:02<00:57, 166.94it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:02<00:57, 167.05it/s]Running 10000 simulations.:   5%|▍         | 493/10000 [00:02<00:57, 166.75it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:03<00:56, 166.59it/s]Running 10000 simulations.:   5%|▌         | 527/10000 [00:03<00:56, 166.55it/s]Running 10000 simulations.:   5%|▌         | 544/10000 [00:03<00:56, 166.46it/s]Running 10000 simulations.:   6%|▌         | 561/10000 [00:03<00:56, 166.22it/s]Running 10000 simulations.:   6%|▌         | 578/10000 [00:03<00:56, 166.20it/s]Running 10000 simulations.:   6%|▌         | 595/10000 [00:03<00:56, 166.84it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:03<00:56, 167.11it/s]Running 10000 simulations.:   6%|▋         | 629/10000 [00:03<00:56, 166.66it/s]Running 10000 simulations.:   6%|▋         | 646/10000 [00:03<00:56, 166.60it/s]Running 10000 simulations.:   7%|▋         | 663/10000 [00:03<00:56, 166.60it/s]Running 10000 simulations.:   7%|▋         | 680/10000 [00:04<00:55, 166.48it/s]Running 10000 simulations.:   7%|▋         | 697/10000 [00:04<00:55, 166.63it/s]Running 10000 simulations.:   7%|▋         | 714/10000 [00:04<00:55, 166.37it/s]Running 10000 simulations.:   7%|▋         | 731/10000 [00:04<00:55, 166.58it/s]Running 10000 simulations.:   7%|▋         | 748/10000 [00:04<00:55, 166.73it/s]Running 10000 simulations.:   8%|▊         | 765/10000 [00:04<00:55, 167.34it/s]Running 10000 simulations.:   8%|▊         | 782/10000 [00:04<00:55, 167.20it/s]Running 10000 simulations.:   8%|▊         | 799/10000 [00:04<00:55, 166.92it/s]Running 10000 simulations.:   8%|▊         | 816/10000 [00:04<00:55, 166.36it/s]Running 10000 simulations.:   8%|▊         | 833/10000 [00:04<00:55, 166.19it/s]Running 10000 simulations.:   8%|▊         | 850/10000 [00:05<00:55, 166.08it/s]Running 10000 simulations.:   9%|▊         | 867/10000 [00:05<00:54, 166.71it/s]Running 10000 simulations.:   9%|▉         | 884/10000 [00:05<00:54, 166.52it/s]Running 10000 simulations.:   9%|▉         | 901/10000 [00:05<00:54, 166.58it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:05<00:54, 166.78it/s]Running 10000 simulations.:   9%|▉         | 935/10000 [00:05<00:54, 166.39it/s]Running 10000 simulations.:  10%|▉         | 952/10000 [00:05<00:54, 166.59it/s]Running 10000 simulations.:  10%|▉         | 969/10000 [00:05<00:54, 166.62it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:05<00:54, 166.43it/s]Running 10000 simulations.:  10%|█         | 1003/10000 [00:06<00:54, 166.11it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:06<00:53, 166.71it/s]Running 10000 simulations.:  10%|█         | 1037/10000 [00:06<00:53, 166.31it/s]Running 10000 simulations.:  11%|█         | 1054/10000 [00:06<00:53, 166.20it/s]Running 10000 simulations.:  11%|█         | 1071/10000 [00:06<00:53, 166.34it/s]Running 10000 simulations.:  11%|█         | 1088/10000 [00:06<00:53, 166.02it/s]Running 10000 simulations.:  11%|█         | 1105/10000 [00:06<00:53, 165.74it/s]Running 10000 simulations.:  11%|█         | 1122/10000 [00:06<00:53, 166.02it/s]Running 10000 simulations.:  11%|█▏        | 1139/10000 [00:06<00:53, 166.23it/s]Running 10000 simulations.:  12%|█▏        | 1156/10000 [00:06<00:53, 166.18it/s]Running 10000 simulations.:  12%|█▏        | 1173/10000 [00:07<00:53, 165.87it/s]Running 10000 simulations.:  12%|█▏        | 1190/10000 [00:07<00:53, 165.92it/s]Running 10000 simulations.:  12%|█▏        | 1207/10000 [00:07<00:53, 165.69it/s]Running 10000 simulations.:  12%|█▏        | 1224/10000 [00:07<00:52, 165.98it/s]Running 10000 simulations.:  12%|█▏        | 1241/10000 [00:07<00:52, 165.82it/s]Running 10000 simulations.:  13%|█▎        | 1258/10000 [00:07<00:52, 165.87it/s]Running 10000 simulations.:  13%|█▎        | 1275/10000 [00:07<00:52, 166.40it/s]Running 10000 simulations.:  13%|█▎        | 1292/10000 [00:07<00:52, 165.99it/s]Running 10000 simulations.:  13%|█▎        | 1309/10000 [00:07<00:52, 166.01it/s]Running 10000 simulations.:  13%|█▎        | 1326/10000 [00:07<00:52, 166.02it/s]Running 10000 simulations.:  13%|█▎        | 1343/10000 [00:08<00:52, 165.77it/s]Running 10000 simulations.:  14%|█▎        | 1360/10000 [00:08<00:52, 165.84it/s]Running 10000 simulations.:  14%|█▍        | 1377/10000 [00:08<00:51, 165.95it/s]Running 10000 simulations.:  14%|█▍        | 1394/10000 [00:08<00:51, 165.93it/s]Running 10000 simulations.:  14%|█▍        | 1411/10000 [00:08<00:51, 166.13it/s]Running 10000 simulations.:  14%|█▍        | 1428/10000 [00:08<00:51, 166.35it/s]Running 10000 simulations.:  14%|█▍        | 1445/10000 [00:08<00:51, 165.97it/s]Running 10000 simulations.:  15%|█▍        | 1462/10000 [00:08<00:51, 165.77it/s]Running 10000 simulations.:  15%|█▍        | 1479/10000 [00:08<00:51, 165.77it/s]Running 10000 simulations.:  15%|█▍        | 1498/10000 [00:08<00:49, 170.27it/s]Running 10000 simulations.:  15%|█▌        | 1517/10000 [00:09<00:48, 174.43it/s]Running 10000 simulations.:  15%|█▌        | 1535/10000 [00:09<00:49, 171.98it/s]Running 10000 simulations.:  16%|█▌        | 1553/10000 [00:09<00:49, 170.33it/s]Running 10000 simulations.:  16%|█▌        | 1571/10000 [00:09<00:49, 168.66it/s]Running 10000 simulations.:  16%|█▌        | 1588/10000 [00:09<00:50, 167.64it/s]Running 10000 simulations.:  16%|█▌        | 1605/10000 [00:09<00:50, 166.88it/s]Running 10000 simulations.:  16%|█▌        | 1622/10000 [00:09<00:50, 166.37it/s]Running 10000 simulations.:  16%|█▋        | 1639/10000 [00:09<00:50, 166.01it/s]Running 10000 simulations.:  17%|█▋        | 1656/10000 [00:09<00:50, 166.00it/s]Running 10000 simulations.:  17%|█▋        | 1673/10000 [00:10<00:50, 165.68it/s]Running 10000 simulations.:  17%|█▋        | 1690/10000 [00:10<00:50, 165.85it/s]Running 10000 simulations.:  17%|█▋        | 1707/10000 [00:10<00:49, 165.90it/s]Running 10000 simulations.:  17%|█▋        | 1724/10000 [00:10<00:49, 165.89it/s]Running 10000 simulations.:  17%|█▋        | 1741/10000 [00:10<00:49, 165.96it/s]Running 10000 simulations.:  18%|█▊        | 1758/10000 [00:10<00:49, 165.97it/s]Running 10000 simulations.:  18%|█▊        | 1775/10000 [00:10<00:49, 166.06it/s]Running 10000 simulations.:  18%|█▊        | 1792/10000 [00:10<00:49, 166.34it/s]Running 10000 simulations.:  18%|█▊        | 1809/10000 [00:10<00:49, 166.32it/s]Running 10000 simulations.:  18%|█▊        | 1826/10000 [00:10<00:49, 166.19it/s]Running 10000 simulations.:  18%|█▊        | 1843/10000 [00:11<00:51, 159.10it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:11<00:50, 160.92it/s]Running 10000 simulations.:  19%|█▉        | 1877/10000 [00:11<00:50, 162.25it/s]Running 10000 simulations.:  19%|█▉        | 1894/10000 [00:11<00:49, 163.55it/s]Running 10000 simulations.:  19%|█▉        | 1911/10000 [00:11<00:49, 164.32it/s]Running 10000 simulations.:  19%|█▉        | 1928/10000 [00:11<00:48, 164.77it/s]Running 10000 simulations.:  19%|█▉        | 1945/10000 [00:11<00:48, 164.86it/s]Running 10000 simulations.:  20%|█▉        | 1962/10000 [00:11<00:48, 165.16it/s]Running 10000 simulations.:  20%|█▉        | 1979/10000 [00:11<00:48, 165.03it/s]Running 10000 simulations.:  20%|█▉        | 1996/10000 [00:11<00:48, 165.48it/s]Running 10000 simulations.:  20%|██        | 2013/10000 [00:12<00:48, 165.78it/s]Running 10000 simulations.:  20%|██        | 2030/10000 [00:12<00:48, 165.89it/s]Running 10000 simulations.:  20%|██        | 2047/10000 [00:12<00:47, 165.87it/s]Running 10000 simulations.:  21%|██        | 2064/10000 [00:12<00:47, 165.97it/s]Running 10000 simulations.:  21%|██        | 2081/10000 [00:12<00:47, 166.35it/s]Running 10000 simulations.:  21%|██        | 2098/10000 [00:12<00:47, 166.38it/s]Running 10000 simulations.:  21%|██        | 2115/10000 [00:12<00:47, 166.13it/s]Running 10000 simulations.:  21%|██▏       | 2132/10000 [00:12<00:47, 166.36it/s]Running 10000 simulations.:  21%|██▏       | 2149/10000 [00:12<00:47, 166.02it/s]Running 10000 simulations.:  22%|██▏       | 2166/10000 [00:13<00:47, 165.70it/s]Running 10000 simulations.:  22%|██▏       | 2183/10000 [00:13<00:47, 165.79it/s]Running 10000 simulations.:  22%|██▏       | 2200/10000 [00:13<00:46, 166.15it/s]Running 10000 simulations.:  22%|██▏       | 2217/10000 [00:13<00:46, 166.66it/s]Running 10000 simulations.:  22%|██▏       | 2234/10000 [00:13<00:46, 166.63it/s]Running 10000 simulations.:  23%|██▎       | 2251/10000 [00:13<00:46, 166.52it/s]Running 10000 simulations.:  23%|██▎       | 2268/10000 [00:13<00:46, 166.18it/s]Running 10000 simulations.:  23%|██▎       | 2285/10000 [00:13<00:46, 165.81it/s]Running 10000 simulations.:  23%|██▎       | 2302/10000 [00:13<00:46, 165.37it/s]Running 10000 simulations.:  23%|██▎       | 2319/10000 [00:13<00:46, 165.38it/s]Running 10000 simulations.:  23%|██▎       | 2336/10000 [00:14<00:46, 165.96it/s]Running 10000 simulations.:  24%|██▎       | 2353/10000 [00:14<00:46, 165.97it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:14<00:46, 165.61it/s]Running 10000 simulations.:  24%|██▍       | 2387/10000 [00:14<00:45, 165.52it/s]Running 10000 simulations.:  24%|██▍       | 2404/10000 [00:14<00:45, 165.62it/s]Running 10000 simulations.:  24%|██▍       | 2421/10000 [00:14<00:45, 165.25it/s]Running 10000 simulations.:  24%|██▍       | 2438/10000 [00:14<00:45, 165.03it/s]Running 10000 simulations.:  25%|██▍       | 2455/10000 [00:14<00:45, 165.11it/s]Running 10000 simulations.:  25%|██▍       | 2472/10000 [00:14<00:45, 165.55it/s]Running 10000 simulations.:  25%|██▍       | 2489/10000 [00:14<00:45, 166.02it/s]Running 10000 simulations.:  25%|██▌       | 2506/10000 [00:15<00:45, 165.82it/s]Running 10000 simulations.:  25%|██▌       | 2523/10000 [00:15<00:45, 165.86it/s]Running 10000 simulations.:  25%|██▌       | 2540/10000 [00:15<00:44, 165.92it/s]Running 10000 simulations.:  26%|██▌       | 2557/10000 [00:15<00:44, 165.85it/s]Running 10000 simulations.:  26%|██▌       | 2574/10000 [00:15<00:44, 165.77it/s]Running 10000 simulations.:  26%|██▌       | 2591/10000 [00:15<00:44, 165.84it/s]Running 10000 simulations.:  26%|██▌       | 2608/10000 [00:15<00:44, 165.70it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:15<00:44, 165.35it/s]Running 10000 simulations.:  26%|██▋       | 2642/10000 [00:15<00:44, 165.87it/s]Running 10000 simulations.:  27%|██▋       | 2659/10000 [00:15<00:44, 165.75it/s]Running 10000 simulations.:  27%|██▋       | 2676/10000 [00:16<00:44, 165.24it/s]Running 10000 simulations.:  27%|██▋       | 2693/10000 [00:16<00:44, 165.02it/s]Running 10000 simulations.:  27%|██▋       | 2710/10000 [00:16<00:44, 164.65it/s]Running 10000 simulations.:  27%|██▋       | 2727/10000 [00:16<00:44, 164.70it/s]Running 10000 simulations.:  27%|██▋       | 2744/10000 [00:16<00:44, 164.83it/s]Running 10000 simulations.:  28%|██▊       | 2761/10000 [00:16<00:43, 164.92it/s]Running 10000 simulations.:  28%|██▊       | 2778/10000 [00:16<00:43, 164.78it/s]Running 10000 simulations.:  28%|██▊       | 2795/10000 [00:16<00:43, 164.77it/s]Running 10000 simulations.:  28%|██▊       | 2812/10000 [00:16<00:43, 164.90it/s]Running 10000 simulations.:  28%|██▊       | 2829/10000 [00:17<00:43, 165.10it/s]Running 10000 simulations.:  28%|██▊       | 2846/10000 [00:17<00:43, 164.80it/s]Running 10000 simulations.:  29%|██▊       | 2863/10000 [00:17<00:43, 165.13it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:17<00:43, 165.20it/s]Running 10000 simulations.:  29%|██▉       | 2897/10000 [00:17<00:42, 165.25it/s]Running 10000 simulations.:  29%|██▉       | 2914/10000 [00:17<00:42, 165.96it/s]Running 10000 simulations.:  29%|██▉       | 2931/10000 [00:17<00:42, 166.17it/s]Running 10000 simulations.:  29%|██▉       | 2948/10000 [00:17<00:42, 166.13it/s]Running 10000 simulations.:  30%|██▉       | 2965/10000 [00:17<00:42, 166.29it/s]Running 10000 simulations.:  30%|██▉       | 2982/10000 [00:17<00:42, 166.76it/s]Running 10000 simulations.:  30%|██▉       | 2999/10000 [00:18<00:42, 166.47it/s]Running 10000 simulations.:  30%|███       | 3016/10000 [00:18<00:42, 166.26it/s]Running 10000 simulations.:  30%|███       | 3033/10000 [00:18<00:42, 165.54it/s]Running 10000 simulations.:  30%|███       | 3050/10000 [00:18<00:42, 165.30it/s]Running 10000 simulations.:  31%|███       | 3067/10000 [00:18<00:42, 165.03it/s]Running 10000 simulations.:  31%|███       | 3084/10000 [00:18<00:41, 165.35it/s]Running 10000 simulations.:  31%|███       | 3101/10000 [00:18<00:41, 165.47it/s]Running 10000 simulations.:  31%|███       | 3118/10000 [00:18<00:41, 165.65it/s]Running 10000 simulations.:  31%|███▏      | 3135/10000 [00:18<00:41, 165.27it/s]Running 10000 simulations.:  32%|███▏      | 3152/10000 [00:18<00:41, 165.18it/s]Running 10000 simulations.:  32%|███▏      | 3169/10000 [00:19<00:41, 165.87it/s]Running 10000 simulations.:  32%|███▏      | 3186/10000 [00:19<00:41, 165.80it/s]Running 10000 simulations.:  32%|███▏      | 3203/10000 [00:19<00:41, 165.28it/s]Running 10000 simulations.:  32%|███▏      | 3220/10000 [00:19<00:41, 165.03it/s]Running 10000 simulations.:  32%|███▏      | 3237/10000 [00:19<00:40, 164.99it/s]Running 10000 simulations.:  33%|███▎      | 3254/10000 [00:19<00:40, 165.18it/s]Running 10000 simulations.:  33%|███▎      | 3271/10000 [00:19<00:40, 165.04it/s]Running 10000 simulations.:  33%|███▎      | 3288/10000 [00:19<00:40, 164.95it/s]Running 10000 simulations.:  33%|███▎      | 3305/10000 [00:19<00:40, 164.88it/s]Running 10000 simulations.:  33%|███▎      | 3322/10000 [00:19<00:40, 164.26it/s]Running 10000 simulations.:  33%|███▎      | 3339/10000 [00:20<00:40, 164.44it/s]Running 10000 simulations.:  34%|███▎      | 3356/10000 [00:20<00:40, 164.28it/s]Running 10000 simulations.:  34%|███▎      | 3373/10000 [00:20<00:40, 164.68it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:20<00:40, 164.43it/s]Running 10000 simulations.:  34%|███▍      | 3407/10000 [00:20<00:39, 165.06it/s]Running 10000 simulations.:  34%|███▍      | 3424/10000 [00:20<00:39, 165.05it/s]Running 10000 simulations.:  34%|███▍      | 3441/10000 [00:20<00:39, 164.77it/s]Running 10000 simulations.:  35%|███▍      | 3458/10000 [00:20<00:39, 164.64it/s]Running 10000 simulations.:  35%|███▍      | 3475/10000 [00:20<00:39, 164.30it/s]Running 10000 simulations.:  35%|███▍      | 3492/10000 [00:21<00:39, 164.57it/s]Running 10000 simulations.:  35%|███▌      | 3509/10000 [00:21<00:39, 165.05it/s]Running 10000 simulations.:  35%|███▌      | 3526/10000 [00:21<00:39, 164.96it/s]Running 10000 simulations.:  35%|███▌      | 3543/10000 [00:21<00:39, 164.77it/s]Running 10000 simulations.:  36%|███▌      | 3560/10000 [00:21<00:39, 164.55it/s]Running 10000 simulations.:  36%|███▌      | 3577/10000 [00:21<00:39, 164.60it/s]Running 10000 simulations.:  36%|███▌      | 3596/10000 [00:21<00:37, 170.03it/s]Running 10000 simulations.:  36%|███▌      | 3615/10000 [00:21<00:36, 173.85it/s]Running 10000 simulations.:  36%|███▋      | 3633/10000 [00:21<00:37, 170.72it/s]Running 10000 simulations.:  37%|███▋      | 3651/10000 [00:21<00:37, 168.74it/s]Running 10000 simulations.:  37%|███▋      | 3668/10000 [00:22<00:37, 167.43it/s]Running 10000 simulations.:  37%|███▋      | 3685/10000 [00:22<00:37, 166.59it/s]Running 10000 simulations.:  37%|███▋      | 3702/10000 [00:22<00:37, 166.25it/s]Running 10000 simulations.:  37%|███▋      | 3719/10000 [00:22<00:37, 165.69it/s]Running 10000 simulations.:  37%|███▋      | 3736/10000 [00:22<00:37, 165.31it/s]Running 10000 simulations.:  38%|███▊      | 3753/10000 [00:22<00:37, 164.88it/s]Running 10000 simulations.:  38%|███▊      | 3770/10000 [00:22<00:37, 164.41it/s]Running 10000 simulations.:  38%|███▊      | 3787/10000 [00:22<00:37, 164.68it/s]Running 10000 simulations.:  38%|███▊      | 3804/10000 [00:22<00:37, 165.19it/s]Running 10000 simulations.:  38%|███▊      | 3821/10000 [00:23<00:37, 165.80it/s]Running 10000 simulations.:  38%|███▊      | 3838/10000 [00:23<00:37, 166.38it/s]Running 10000 simulations.:  39%|███▊      | 3855/10000 [00:23<00:37, 165.91it/s]Running 10000 simulations.:  39%|███▊      | 3872/10000 [00:23<00:36, 165.79it/s]Running 10000 simulations.:  39%|███▉      | 3889/10000 [00:23<00:36, 165.78it/s]Running 10000 simulations.:  39%|███▉      | 3906/10000 [00:23<00:36, 165.83it/s]Running 10000 simulations.:  39%|███▉      | 3923/10000 [00:23<00:36, 165.60it/s]Running 10000 simulations.:  39%|███▉      | 3940/10000 [00:23<00:36, 165.60it/s]Running 10000 simulations.:  40%|███▉      | 3957/10000 [00:23<00:36, 165.55it/s]Running 10000 simulations.:  40%|███▉      | 3974/10000 [00:23<00:36, 165.87it/s]Running 10000 simulations.:  40%|███▉      | 3991/10000 [00:24<00:36, 165.34it/s]Running 10000 simulations.:  40%|████      | 4008/10000 [00:24<00:36, 165.28it/s]Running 10000 simulations.:  40%|████      | 4025/10000 [00:24<00:35, 166.34it/s]Running 10000 simulations.:  40%|████      | 4042/10000 [00:24<00:35, 166.38it/s]Running 10000 simulations.:  41%|████      | 4059/10000 [00:24<00:35, 166.64it/s]Running 10000 simulations.:  41%|████      | 4076/10000 [00:24<00:35, 165.99it/s]Running 10000 simulations.:  41%|████      | 4093/10000 [00:24<00:35, 166.32it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:24<00:35, 166.16it/s]Running 10000 simulations.:  41%|████▏     | 4127/10000 [00:24<00:35, 165.95it/s]Running 10000 simulations.:  41%|████▏     | 4144/10000 [00:24<00:35, 166.37it/s]Running 10000 simulations.:  42%|████▏     | 4161/10000 [00:25<00:35, 166.02it/s]Running 10000 simulations.:  42%|████▏     | 4178/10000 [00:25<00:35, 165.49it/s]Running 10000 simulations.:  42%|████▏     | 4195/10000 [00:25<00:35, 165.41it/s]Running 10000 simulations.:  42%|████▏     | 4212/10000 [00:25<00:34, 165.37it/s]Running 10000 simulations.:  42%|████▏     | 4229/10000 [00:25<00:34, 165.67it/s]Running 10000 simulations.:  42%|████▏     | 4246/10000 [00:25<00:34, 165.36it/s]Running 10000 simulations.:  43%|████▎     | 4263/10000 [00:25<00:34, 165.44it/s]Running 10000 simulations.:  43%|████▎     | 4280/10000 [00:25<00:34, 165.72it/s]Running 10000 simulations.:  43%|████▎     | 4297/10000 [00:25<00:34, 165.00it/s]Running 10000 simulations.:  43%|████▎     | 4314/10000 [00:25<00:34, 164.61it/s]Running 10000 simulations.:  43%|████▎     | 4331/10000 [00:26<00:34, 164.41it/s]Running 10000 simulations.:  43%|████▎     | 4348/10000 [00:26<00:34, 164.65it/s]Running 10000 simulations.:  44%|████▎     | 4365/10000 [00:26<00:34, 164.56it/s]Running 10000 simulations.:  44%|████▍     | 4382/10000 [00:26<00:34, 164.71it/s]Running 10000 simulations.:  44%|████▍     | 4399/10000 [00:26<00:33, 164.82it/s]Running 10000 simulations.:  44%|████▍     | 4416/10000 [00:26<00:33, 164.61it/s]Running 10000 simulations.:  44%|████▍     | 4433/10000 [00:26<00:33, 165.20it/s]Running 10000 simulations.:  44%|████▍     | 4450/10000 [00:26<00:33, 164.94it/s]Running 10000 simulations.:  45%|████▍     | 4467/10000 [00:26<00:33, 164.86it/s]Running 10000 simulations.:  45%|████▍     | 4484/10000 [00:27<00:33, 164.70it/s]Running 10000 simulations.:  45%|████▌     | 4501/10000 [00:27<00:33, 165.04it/s]Running 10000 simulations.:  45%|████▌     | 4518/10000 [00:27<00:33, 164.79it/s]Running 10000 simulations.:  45%|████▌     | 4535/10000 [00:27<00:33, 164.55it/s]Running 10000 simulations.:  46%|████▌     | 4552/10000 [00:27<00:33, 163.90it/s]Running 10000 simulations.:  46%|████▌     | 4569/10000 [00:27<00:33, 164.38it/s]Running 10000 simulations.:  46%|████▌     | 4586/10000 [00:27<00:32, 164.59it/s]Running 10000 simulations.:  46%|████▌     | 4603/10000 [00:27<00:32, 165.14it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:27<00:32, 165.10it/s]Running 10000 simulations.:  46%|████▋     | 4637/10000 [00:27<00:32, 165.36it/s]Running 10000 simulations.:  47%|████▋     | 4654/10000 [00:28<00:32, 165.01it/s]Running 10000 simulations.:  47%|████▋     | 4671/10000 [00:28<00:32, 165.22it/s]Running 10000 simulations.:  47%|████▋     | 4688/10000 [00:28<00:32, 165.36it/s]Running 10000 simulations.:  47%|████▋     | 4705/10000 [00:28<00:31, 165.65it/s]Running 10000 simulations.:  47%|████▋     | 4722/10000 [00:28<00:31, 166.23it/s]Running 10000 simulations.:  47%|████▋     | 4739/10000 [00:28<00:31, 166.41it/s]Running 10000 simulations.:  48%|████▊     | 4756/10000 [00:28<00:31, 166.48it/s]Running 10000 simulations.:  48%|████▊     | 4773/10000 [00:28<00:31, 166.67it/s]Running 10000 simulations.:  48%|████▊     | 4790/10000 [00:28<00:31, 166.37it/s]Running 10000 simulations.:  48%|████▊     | 4807/10000 [00:28<00:31, 165.86it/s]Running 10000 simulations.:  48%|████▊     | 4824/10000 [00:29<00:31, 165.27it/s]Running 10000 simulations.:  48%|████▊     | 4841/10000 [00:29<00:31, 165.42it/s]Running 10000 simulations.:  49%|████▊     | 4858/10000 [00:29<00:31, 165.19it/s]Running 10000 simulations.:  49%|████▉     | 4875/10000 [00:29<00:31, 164.90it/s]Running 10000 simulations.:  49%|████▉     | 4892/10000 [00:29<00:30, 165.00it/s]Running 10000 simulations.:  49%|████▉     | 4909/10000 [00:29<00:30, 165.26it/s]Running 10000 simulations.:  49%|████▉     | 4926/10000 [00:29<00:30, 165.45it/s]Running 10000 simulations.:  49%|████▉     | 4943/10000 [00:29<00:30, 165.18it/s]Running 10000 simulations.:  50%|████▉     | 4960/10000 [00:29<00:30, 164.99it/s]Running 10000 simulations.:  50%|████▉     | 4977/10000 [00:29<00:30, 165.47it/s]Running 10000 simulations.:  50%|████▉     | 4994/10000 [00:30<00:30, 165.95it/s]Running 10000 simulations.:  50%|█████     | 5011/10000 [00:30<00:30, 165.38it/s]Running 10000 simulations.:  50%|█████     | 5028/10000 [00:30<00:30, 165.08it/s]Running 10000 simulations.:  50%|█████     | 5045/10000 [00:30<00:29, 165.46it/s]Running 10000 simulations.:  51%|█████     | 5062/10000 [00:30<00:29, 164.99it/s]Running 10000 simulations.:  51%|█████     | 5079/10000 [00:30<00:29, 164.86it/s]Running 10000 simulations.:  51%|█████     | 5096/10000 [00:30<00:29, 164.90it/s]Running 10000 simulations.:  51%|█████     | 5113/10000 [00:30<00:29, 164.72it/s]Running 10000 simulations.:  51%|█████▏    | 5130/10000 [00:30<00:29, 165.37it/s]Running 10000 simulations.:  51%|█████▏    | 5147/10000 [00:31<00:29, 165.17it/s]Running 10000 simulations.:  52%|█████▏    | 5164/10000 [00:31<00:29, 165.43it/s]Running 10000 simulations.:  52%|█████▏    | 5181/10000 [00:31<00:29, 165.58it/s]Running 10000 simulations.:  52%|█████▏    | 5198/10000 [00:31<00:28, 165.59it/s]Running 10000 simulations.:  52%|█████▏    | 5215/10000 [00:31<00:28, 165.41it/s]Running 10000 simulations.:  52%|█████▏    | 5232/10000 [00:31<00:28, 165.65it/s]Running 10000 simulations.:  52%|█████▏    | 5249/10000 [00:31<00:28, 165.77it/s]Running 10000 simulations.:  53%|█████▎    | 5266/10000 [00:31<00:28, 165.61it/s]Running 10000 simulations.:  53%|█████▎    | 5283/10000 [00:31<00:28, 165.93it/s]Running 10000 simulations.:  53%|█████▎    | 5300/10000 [00:31<00:28, 166.18it/s]Running 10000 simulations.:  53%|█████▎    | 5317/10000 [00:32<00:28, 165.97it/s]Running 10000 simulations.:  53%|█████▎    | 5334/10000 [00:32<00:28, 165.49it/s]Running 10000 simulations.:  54%|█████▎    | 5351/10000 [00:32<00:28, 165.08it/s]Running 10000 simulations.:  54%|█████▎    | 5368/10000 [00:32<00:28, 165.21it/s]Running 10000 simulations.:  54%|█████▍    | 5385/10000 [00:32<00:27, 165.66it/s]Running 10000 simulations.:  54%|█████▍    | 5402/10000 [00:32<00:28, 163.76it/s]Running 10000 simulations.:  54%|█████▍    | 5419/10000 [00:32<00:27, 164.02it/s]Running 10000 simulations.:  54%|█████▍    | 5436/10000 [00:32<00:27, 164.26it/s]Running 10000 simulations.:  55%|█████▍    | 5453/10000 [00:32<00:27, 164.37it/s]Running 10000 simulations.:  55%|█████▍    | 5470/10000 [00:32<00:27, 164.67it/s]Running 10000 simulations.:  55%|█████▍    | 5487/10000 [00:33<00:27, 165.18it/s]Running 10000 simulations.:  55%|█████▌    | 5504/10000 [00:33<00:27, 164.50it/s]Running 10000 simulations.:  55%|█████▌    | 5521/10000 [00:33<00:27, 164.45it/s]Running 10000 simulations.:  55%|█████▌    | 5538/10000 [00:33<00:27, 164.03it/s]Running 10000 simulations.:  56%|█████▌    | 5555/10000 [00:33<00:27, 163.85it/s]Running 10000 simulations.:  56%|█████▌    | 5572/10000 [00:33<00:27, 163.97it/s]Running 10000 simulations.:  56%|█████▌    | 5589/10000 [00:33<00:26, 164.34it/s]Running 10000 simulations.:  56%|█████▌    | 5606/10000 [00:33<00:26, 164.42it/s]Running 10000 simulations.:  56%|█████▌    | 5623/10000 [00:33<00:26, 164.25it/s]Running 10000 simulations.:  56%|█████▋    | 5640/10000 [00:34<00:26, 164.60it/s]Running 10000 simulations.:  57%|█████▋    | 5657/10000 [00:34<00:26, 165.28it/s]Running 10000 simulations.:  57%|█████▋    | 5674/10000 [00:34<00:26, 165.71it/s]Running 10000 simulations.:  57%|█████▋    | 5691/10000 [00:34<00:25, 165.88it/s]Running 10000 simulations.:  57%|█████▋    | 5708/10000 [00:34<00:25, 166.07it/s]Running 10000 simulations.:  57%|█████▋    | 5725/10000 [00:34<00:25, 165.30it/s]Running 10000 simulations.:  57%|█████▋    | 5742/10000 [00:34<00:25, 165.13it/s]Running 10000 simulations.:  58%|█████▊    | 5759/10000 [00:34<00:25, 165.03it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:34<00:25, 165.30it/s]Running 10000 simulations.:  58%|█████▊    | 5793/10000 [00:34<00:25, 165.52it/s]Running 10000 simulations.:  58%|█████▊    | 5810/10000 [00:35<00:25, 165.09it/s]Running 10000 simulations.:  58%|█████▊    | 5827/10000 [00:35<00:25, 164.86it/s]Running 10000 simulations.:  58%|█████▊    | 5844/10000 [00:35<00:25, 165.11it/s]Running 10000 simulations.:  59%|█████▊    | 5861/10000 [00:35<00:25, 164.90it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:35<00:24, 166.10it/s]Running 10000 simulations.:  59%|█████▉    | 5897/10000 [00:35<00:23, 172.02it/s]Running 10000 simulations.:  59%|█████▉    | 5915/10000 [00:35<00:23, 170.47it/s]Running 10000 simulations.:  59%|█████▉    | 5933/10000 [00:35<00:24, 168.78it/s]Running 10000 simulations.:  60%|█████▉    | 5950/10000 [00:35<00:24, 167.97it/s]Running 10000 simulations.:  60%|█████▉    | 5967/10000 [00:35<00:24, 167.09it/s]Running 10000 simulations.:  60%|█████▉    | 5984/10000 [00:36<00:24, 165.84it/s]Running 10000 simulations.:  60%|██████    | 6001/10000 [00:36<00:24, 165.96it/s]Running 10000 simulations.:  60%|██████    | 6018/10000 [00:36<00:24, 165.68it/s]Running 10000 simulations.:  60%|██████    | 6035/10000 [00:36<00:23, 165.56it/s]Running 10000 simulations.:  61%|██████    | 6052/10000 [00:36<00:23, 165.08it/s]Running 10000 simulations.:  61%|██████    | 6069/10000 [00:36<00:23, 164.98it/s]Running 10000 simulations.:  61%|██████    | 6086/10000 [00:36<00:23, 164.79it/s]Running 10000 simulations.:  61%|██████    | 6103/10000 [00:36<00:23, 165.31it/s]Running 10000 simulations.:  61%|██████    | 6120/10000 [00:36<00:23, 165.14it/s]Running 10000 simulations.:  61%|██████▏   | 6137/10000 [00:37<00:23, 165.60it/s]Running 10000 simulations.:  62%|██████▏   | 6154/10000 [00:37<00:23, 165.16it/s]Running 10000 simulations.:  62%|██████▏   | 6171/10000 [00:37<00:23, 165.10it/s]Running 10000 simulations.:  62%|██████▏   | 6188/10000 [00:37<00:23, 165.13it/s]Running 10000 simulations.:  62%|██████▏   | 6205/10000 [00:37<00:23, 164.94it/s]Running 10000 simulations.:  62%|██████▏   | 6222/10000 [00:37<00:22, 165.25it/s]Running 10000 simulations.:  62%|██████▏   | 6239/10000 [00:37<00:22, 165.19it/s]Running 10000 simulations.:  63%|██████▎   | 6256/10000 [00:37<00:22, 164.73it/s]Running 10000 simulations.:  63%|██████▎   | 6273/10000 [00:37<00:22, 164.33it/s]Running 10000 simulations.:  63%|██████▎   | 6290/10000 [00:37<00:22, 164.14it/s]Running 10000 simulations.:  63%|██████▎   | 6307/10000 [00:38<00:22, 164.33it/s]Running 10000 simulations.:  63%|██████▎   | 6324/10000 [00:38<00:22, 165.02it/s]Running 10000 simulations.:  63%|██████▎   | 6341/10000 [00:38<00:22, 164.48it/s]Running 10000 simulations.:  64%|██████▎   | 6358/10000 [00:38<00:22, 164.51it/s]Running 10000 simulations.:  64%|██████▍   | 6375/10000 [00:38<00:22, 164.53it/s]Running 10000 simulations.:  64%|██████▍   | 6392/10000 [00:38<00:21, 164.43it/s]Running 10000 simulations.:  64%|██████▍   | 6409/10000 [00:38<00:21, 164.88it/s]Running 10000 simulations.:  64%|██████▍   | 6426/10000 [00:38<00:21, 164.32it/s]Running 10000 simulations.:  64%|██████▍   | 6443/10000 [00:38<00:21, 164.54it/s]Running 10000 simulations.:  65%|██████▍   | 6460/10000 [00:38<00:21, 165.10it/s]Running 10000 simulations.:  65%|██████▍   | 6477/10000 [00:39<00:21, 164.40it/s]Running 10000 simulations.:  65%|██████▍   | 6494/10000 [00:39<00:21, 164.07it/s]Running 10000 simulations.:  65%|██████▌   | 6511/10000 [00:39<00:21, 164.09it/s]Running 10000 simulations.:  65%|██████▌   | 6528/10000 [00:39<00:21, 163.81it/s]Running 10000 simulations.:  65%|██████▌   | 6545/10000 [00:39<00:21, 164.15it/s]Running 10000 simulations.:  66%|██████▌   | 6562/10000 [00:39<00:20, 164.01it/s]Running 10000 simulations.:  66%|██████▌   | 6579/10000 [00:39<00:20, 164.01it/s]Running 10000 simulations.:  66%|██████▌   | 6596/10000 [00:39<00:20, 164.22it/s]Running 10000 simulations.:  66%|██████▌   | 6613/10000 [00:39<00:20, 163.97it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:39<00:20, 164.01it/s]Running 10000 simulations.:  66%|██████▋   | 6647/10000 [00:40<00:20, 163.70it/s]Running 10000 simulations.:  67%|██████▋   | 6664/10000 [00:40<00:20, 164.09it/s]Running 10000 simulations.:  67%|██████▋   | 6681/10000 [00:40<00:20, 164.62it/s]Running 10000 simulations.:  67%|██████▋   | 6698/10000 [00:40<00:20, 164.95it/s]Running 10000 simulations.:  67%|██████▋   | 6715/10000 [00:40<00:19, 165.05it/s]Running 10000 simulations.:  67%|██████▋   | 6732/10000 [00:40<00:19, 164.60it/s]Running 10000 simulations.:  67%|██████▋   | 6749/10000 [00:40<00:19, 164.25it/s]Running 10000 simulations.:  68%|██████▊   | 6766/10000 [00:40<00:19, 163.86it/s]Running 10000 simulations.:  68%|██████▊   | 6783/10000 [00:40<00:19, 163.52it/s]Running 10000 simulations.:  68%|██████▊   | 6800/10000 [00:41<00:20, 156.95it/s]Running 10000 simulations.:  68%|██████▊   | 6817/10000 [00:41<00:20, 159.15it/s]Running 10000 simulations.:  68%|██████▊   | 6834/10000 [00:41<00:19, 160.44it/s]Running 10000 simulations.:  69%|██████▊   | 6851/10000 [00:41<00:19, 161.55it/s]Running 10000 simulations.:  69%|██████▊   | 6868/10000 [00:41<00:19, 162.72it/s]Running 10000 simulations.:  69%|██████▉   | 6885/10000 [00:41<00:19, 163.65it/s]Running 10000 simulations.:  69%|██████▉   | 6902/10000 [00:41<00:18, 163.84it/s]Running 10000 simulations.:  69%|██████▉   | 6919/10000 [00:41<00:18, 163.95it/s]Running 10000 simulations.:  69%|██████▉   | 6936/10000 [00:41<00:18, 164.09it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:41<00:18, 164.04it/s]Running 10000 simulations.:  70%|██████▉   | 6970/10000 [00:42<00:18, 164.38it/s]Running 10000 simulations.:  70%|██████▉   | 6987/10000 [00:42<00:18, 165.19it/s]Running 10000 simulations.:  70%|███████   | 7004/10000 [00:42<00:18, 165.21it/s]Running 10000 simulations.:  70%|███████   | 7021/10000 [00:42<00:18, 164.95it/s]Running 10000 simulations.:  70%|███████   | 7038/10000 [00:42<00:17, 164.89it/s]Running 10000 simulations.:  71%|███████   | 7055/10000 [00:42<00:17, 164.50it/s]Running 10000 simulations.:  71%|███████   | 7072/10000 [00:42<00:17, 164.63it/s]Running 10000 simulations.:  71%|███████   | 7089/10000 [00:42<00:17, 164.61it/s]Running 10000 simulations.:  71%|███████   | 7106/10000 [00:42<00:17, 164.92it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:43<00:17, 165.78it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:43<00:17, 166.18it/s]Running 10000 simulations.:  72%|███████▏  | 7157/10000 [00:43<00:17, 166.31it/s]Running 10000 simulations.:  72%|███████▏  | 7174/10000 [00:43<00:17, 165.82it/s]Running 10000 simulations.:  72%|███████▏  | 7191/10000 [00:43<00:16, 165.69it/s]Running 10000 simulations.:  72%|███████▏  | 7208/10000 [00:43<00:16, 165.59it/s]Running 10000 simulations.:  72%|███████▏  | 7225/10000 [00:43<00:16, 165.82it/s]Running 10000 simulations.:  72%|███████▏  | 7242/10000 [00:43<00:16, 165.26it/s]Running 10000 simulations.:  73%|███████▎  | 7259/10000 [00:43<00:16, 164.65it/s]Running 10000 simulations.:  73%|███████▎  | 7276/10000 [00:43<00:16, 164.30it/s]Running 10000 simulations.:  73%|███████▎  | 7293/10000 [00:44<00:16, 164.44it/s]Running 10000 simulations.:  73%|███████▎  | 7310/10000 [00:44<00:16, 164.60it/s]Running 10000 simulations.:  73%|███████▎  | 7327/10000 [00:44<00:16, 164.72it/s]Running 10000 simulations.:  73%|███████▎  | 7344/10000 [00:44<00:16, 164.86it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:44<00:16, 164.92it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:44<00:15, 164.95it/s]Running 10000 simulations.:  74%|███████▍  | 7395/10000 [00:44<00:15, 164.75it/s]Running 10000 simulations.:  74%|███████▍  | 7412/10000 [00:44<00:15, 164.30it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:44<00:15, 164.07it/s]Running 10000 simulations.:  74%|███████▍  | 7446/10000 [00:44<00:15, 164.29it/s]Running 10000 simulations.:  75%|███████▍  | 7463/10000 [00:45<00:15, 164.34it/s]Running 10000 simulations.:  75%|███████▍  | 7480/10000 [00:45<00:15, 164.41it/s]Running 10000 simulations.:  75%|███████▍  | 7497/10000 [00:45<00:15, 164.62it/s]Running 10000 simulations.:  75%|███████▌  | 7514/10000 [00:45<00:15, 164.29it/s]Running 10000 simulations.:  75%|███████▌  | 7531/10000 [00:45<00:15, 164.50it/s]Running 10000 simulations.:  75%|███████▌  | 7548/10000 [00:45<00:14, 164.82it/s]Running 10000 simulations.:  76%|███████▌  | 7565/10000 [00:45<00:14, 165.17it/s]Running 10000 simulations.:  76%|███████▌  | 7582/10000 [00:45<00:14, 165.18it/s]Running 10000 simulations.:  76%|███████▌  | 7599/10000 [00:45<00:14, 165.17it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:45<00:14, 165.30it/s]Running 10000 simulations.:  76%|███████▋  | 7633/10000 [00:46<00:14, 165.64it/s]Running 10000 simulations.:  76%|███████▋  | 7650/10000 [00:46<00:14, 165.39it/s]Running 10000 simulations.:  77%|███████▋  | 7667/10000 [00:46<00:14, 164.85it/s]Running 10000 simulations.:  77%|███████▋  | 7684/10000 [00:46<00:14, 164.99it/s]Running 10000 simulations.:  77%|███████▋  | 7701/10000 [00:46<00:13, 165.13it/s]Running 10000 simulations.:  77%|███████▋  | 7718/10000 [00:46<00:13, 165.23it/s]Running 10000 simulations.:  77%|███████▋  | 7735/10000 [00:46<00:13, 165.37it/s]Running 10000 simulations.:  78%|███████▊  | 7752/10000 [00:46<00:13, 165.34it/s]Running 10000 simulations.:  78%|███████▊  | 7769/10000 [00:46<00:13, 165.38it/s]Running 10000 simulations.:  78%|███████▊  | 7786/10000 [00:47<00:13, 165.09it/s]Running 10000 simulations.:  78%|███████▊  | 7803/10000 [00:47<00:13, 164.54it/s]Running 10000 simulations.:  78%|███████▊  | 7820/10000 [00:47<00:13, 164.72it/s]Running 10000 simulations.:  78%|███████▊  | 7837/10000 [00:47<00:13, 164.90it/s]Running 10000 simulations.:  79%|███████▊  | 7854/10000 [00:47<00:13, 164.56it/s]Running 10000 simulations.:  79%|███████▊  | 7871/10000 [00:47<00:12, 164.63it/s]Running 10000 simulations.:  79%|███████▉  | 7888/10000 [00:47<00:12, 164.49it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:47<00:12, 164.82it/s]Running 10000 simulations.:  79%|███████▉  | 7922/10000 [00:47<00:12, 164.85it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:47<00:12, 164.50it/s]Running 10000 simulations.:  80%|███████▉  | 7956/10000 [00:48<00:12, 165.32it/s]Running 10000 simulations.:  80%|███████▉  | 7976/10000 [00:48<00:11, 172.24it/s]Running 10000 simulations.:  80%|███████▉  | 7994/10000 [00:48<00:11, 173.88it/s]Running 10000 simulations.:  80%|████████  | 8012/10000 [00:48<00:11, 171.41it/s]Running 10000 simulations.:  80%|████████  | 8030/10000 [00:48<00:11, 169.91it/s]Running 10000 simulations.:  80%|████████  | 8048/10000 [00:48<00:11, 168.94it/s]Running 10000 simulations.:  81%|████████  | 8065/10000 [00:48<00:11, 168.04it/s]Running 10000 simulations.:  81%|████████  | 8082/10000 [00:48<00:11, 167.80it/s]Running 10000 simulations.:  81%|████████  | 8099/10000 [00:48<00:11, 167.15it/s]Running 10000 simulations.:  81%|████████  | 8116/10000 [00:48<00:11, 166.94it/s]Running 10000 simulations.:  81%|████████▏ | 8133/10000 [00:49<00:11, 166.05it/s]Running 10000 simulations.:  82%|████████▏ | 8150/10000 [00:49<00:11, 165.73it/s]Running 10000 simulations.:  82%|████████▏ | 8167/10000 [00:49<00:11, 165.89it/s]Running 10000 simulations.:  82%|████████▏ | 8184/10000 [00:49<00:10, 166.46it/s]Running 10000 simulations.:  82%|████████▏ | 8201/10000 [00:49<00:10, 166.20it/s]Running 10000 simulations.:  82%|████████▏ | 8218/10000 [00:49<00:10, 165.96it/s]Running 10000 simulations.:  82%|████████▏ | 8235/10000 [00:49<00:10, 166.32it/s]Running 10000 simulations.:  83%|████████▎ | 8252/10000 [00:49<00:10, 166.37it/s]Running 10000 simulations.:  83%|████████▎ | 8269/10000 [00:49<00:10, 165.98it/s]Running 10000 simulations.:  83%|████████▎ | 8286/10000 [00:50<00:10, 165.69it/s]Running 10000 simulations.:  83%|████████▎ | 8303/10000 [00:50<00:10, 165.55it/s]Running 10000 simulations.:  83%|████████▎ | 8320/10000 [00:50<00:10, 165.31it/s]Running 10000 simulations.:  83%|████████▎ | 8337/10000 [00:50<00:10, 165.60it/s]Running 10000 simulations.:  84%|████████▎ | 8354/10000 [00:50<00:09, 165.65it/s]Running 10000 simulations.:  84%|████████▎ | 8371/10000 [00:50<00:09, 165.76it/s]Running 10000 simulations.:  84%|████████▍ | 8388/10000 [00:50<00:09, 165.90it/s]Running 10000 simulations.:  84%|████████▍ | 8405/10000 [00:50<00:09, 166.07it/s]Running 10000 simulations.:  84%|████████▍ | 8422/10000 [00:50<00:09, 165.50it/s]Running 10000 simulations.:  84%|████████▍ | 8439/10000 [00:50<00:09, 165.40it/s]Running 10000 simulations.:  85%|████████▍ | 8456/10000 [00:51<00:09, 165.51it/s]Running 10000 simulations.:  85%|████████▍ | 8473/10000 [00:51<00:09, 165.71it/s]Running 10000 simulations.:  85%|████████▍ | 8490/10000 [00:51<00:09, 165.81it/s]Running 10000 simulations.:  85%|████████▌ | 8507/10000 [00:51<00:08, 166.05it/s]Running 10000 simulations.:  85%|████████▌ | 8524/10000 [00:51<00:08, 166.41it/s]Running 10000 simulations.:  85%|████████▌ | 8541/10000 [00:51<00:08, 166.22it/s]Running 10000 simulations.:  86%|████████▌ | 8558/10000 [00:51<00:08, 165.86it/s]Running 10000 simulations.:  86%|████████▌ | 8575/10000 [00:51<00:08, 165.55it/s]Running 10000 simulations.:  86%|████████▌ | 8592/10000 [00:51<00:08, 166.08it/s]Running 10000 simulations.:  86%|████████▌ | 8609/10000 [00:51<00:08, 165.91it/s]Running 10000 simulations.:  86%|████████▋ | 8626/10000 [00:52<00:08, 165.73it/s]Running 10000 simulations.:  86%|████████▋ | 8643/10000 [00:52<00:08, 165.46it/s]Running 10000 simulations.:  87%|████████▋ | 8660/10000 [00:52<00:08, 165.26it/s]Running 10000 simulations.:  87%|████████▋ | 8677/10000 [00:52<00:07, 165.66it/s]Running 10000 simulations.:  87%|████████▋ | 8694/10000 [00:52<00:07, 165.39it/s]Running 10000 simulations.:  87%|████████▋ | 8711/10000 [00:52<00:07, 165.49it/s]Running 10000 simulations.:  87%|████████▋ | 8728/10000 [00:52<00:07, 165.01it/s]Running 10000 simulations.:  87%|████████▋ | 8745/10000 [00:52<00:07, 164.62it/s]Running 10000 simulations.:  88%|████████▊ | 8762/10000 [00:52<00:07, 165.15it/s]Running 10000 simulations.:  88%|████████▊ | 8779/10000 [00:53<00:07, 165.60it/s]Running 10000 simulations.:  88%|████████▊ | 8796/10000 [00:53<00:07, 165.45it/s]Running 10000 simulations.:  88%|████████▊ | 8813/10000 [00:53<00:07, 165.54it/s]Running 10000 simulations.:  88%|████████▊ | 8830/10000 [00:53<00:07, 165.81it/s]Running 10000 simulations.:  88%|████████▊ | 8847/10000 [00:53<00:06, 165.42it/s]Running 10000 simulations.:  89%|████████▊ | 8864/10000 [00:53<00:06, 165.95it/s]Running 10000 simulations.:  89%|████████▉ | 8881/10000 [00:53<00:06, 166.21it/s]Running 10000 simulations.:  89%|████████▉ | 8898/10000 [00:53<00:06, 166.46it/s]Running 10000 simulations.:  89%|████████▉ | 8915/10000 [00:53<00:06, 166.01it/s]Running 10000 simulations.:  89%|████████▉ | 8932/10000 [00:53<00:06, 165.17it/s]Running 10000 simulations.:  89%|████████▉ | 8949/10000 [00:54<00:06, 164.63it/s]Running 10000 simulations.:  90%|████████▉ | 8966/10000 [00:54<00:06, 164.38it/s]Running 10000 simulations.:  90%|████████▉ | 8983/10000 [00:54<00:06, 164.95it/s]Running 10000 simulations.:  90%|█████████ | 9000/10000 [00:54<00:06, 165.36it/s]Running 10000 simulations.:  90%|█████████ | 9017/10000 [00:54<00:05, 165.37it/s]Running 10000 simulations.:  90%|█████████ | 9034/10000 [00:54<00:05, 165.30it/s]Running 10000 simulations.:  91%|█████████ | 9051/10000 [00:54<00:05, 165.19it/s]Running 10000 simulations.:  91%|█████████ | 9068/10000 [00:54<00:05, 165.27it/s]Running 10000 simulations.:  91%|█████████ | 9085/10000 [00:54<00:05, 165.39it/s]Running 10000 simulations.:  91%|█████████ | 9102/10000 [00:54<00:05, 165.24it/s]Running 10000 simulations.:  91%|█████████ | 9119/10000 [00:55<00:05, 165.36it/s]Running 10000 simulations.:  91%|█████████▏| 9136/10000 [00:55<00:05, 165.68it/s]Running 10000 simulations.:  92%|█████████▏| 9153/10000 [00:55<00:05, 166.10it/s]Running 10000 simulations.:  92%|█████████▏| 9170/10000 [00:55<00:04, 166.18it/s]Running 10000 simulations.:  92%|█████████▏| 9187/10000 [00:55<00:04, 165.76it/s]Running 10000 simulations.:  92%|█████████▏| 9204/10000 [00:55<00:04, 165.71it/s]Running 10000 simulations.:  92%|█████████▏| 9221/10000 [00:55<00:04, 165.77it/s]Running 10000 simulations.:  92%|█████████▏| 9238/10000 [00:55<00:04, 165.64it/s]Running 10000 simulations.:  93%|█████████▎| 9255/10000 [00:55<00:04, 165.32it/s]Running 10000 simulations.:  93%|█████████▎| 9272/10000 [00:55<00:04, 165.16it/s]Running 10000 simulations.:  93%|█████████▎| 9289/10000 [00:56<00:04, 165.38it/s]Running 10000 simulations.:  93%|█████████▎| 9306/10000 [00:56<00:04, 165.97it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [00:56<00:04, 165.56it/s]Running 10000 simulations.:  93%|█████████▎| 9340/10000 [00:56<00:03, 165.30it/s]Running 10000 simulations.:  94%|█████████▎| 9357/10000 [00:56<00:03, 165.14it/s]Running 10000 simulations.:  94%|█████████▎| 9374/10000 [00:56<00:03, 165.02it/s]Running 10000 simulations.:  94%|█████████▍| 9391/10000 [00:56<00:03, 165.80it/s]Running 10000 simulations.:  94%|█████████▍| 9408/10000 [00:56<00:03, 166.07it/s]Running 10000 simulations.:  94%|█████████▍| 9425/10000 [00:56<00:03, 166.73it/s]Running 10000 simulations.:  94%|█████████▍| 9442/10000 [00:57<00:03, 166.36it/s]Running 10000 simulations.:  95%|█████████▍| 9459/10000 [00:57<00:03, 165.91it/s]Running 10000 simulations.:  95%|█████████▍| 9476/10000 [00:57<00:03, 165.52it/s]Running 10000 simulations.:  95%|█████████▍| 9493/10000 [00:57<00:03, 165.04it/s]Running 10000 simulations.:  95%|█████████▌| 9510/10000 [00:57<00:02, 165.53it/s]Running 10000 simulations.:  95%|█████████▌| 9527/10000 [00:57<00:02, 165.81it/s]Running 10000 simulations.:  95%|█████████▌| 9544/10000 [00:57<00:02, 165.60it/s]Running 10000 simulations.:  96%|█████████▌| 9561/10000 [00:57<00:02, 165.18it/s]Running 10000 simulations.:  96%|█████████▌| 9578/10000 [00:57<00:02, 165.34it/s]Running 10000 simulations.:  96%|█████████▌| 9595/10000 [00:57<00:02, 165.04it/s]Running 10000 simulations.:  96%|█████████▌| 9612/10000 [00:58<00:02, 164.88it/s]Running 10000 simulations.:  96%|█████████▋| 9629/10000 [00:58<00:02, 165.77it/s]Running 10000 simulations.:  96%|█████████▋| 9646/10000 [00:58<00:02, 165.70it/s]Running 10000 simulations.:  97%|█████████▋| 9663/10000 [00:58<00:02, 166.12it/s]Running 10000 simulations.:  97%|█████████▋| 9680/10000 [00:58<00:01, 166.30it/s]Running 10000 simulations.:  97%|█████████▋| 9697/10000 [00:58<00:01, 166.50it/s]Running 10000 simulations.:  97%|█████████▋| 9714/10000 [00:58<00:01, 166.37it/s]Running 10000 simulations.:  97%|█████████▋| 9731/10000 [00:58<00:01, 166.13it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [00:58<00:01, 166.09it/s]Running 10000 simulations.:  98%|█████████▊| 9765/10000 [00:58<00:01, 165.24it/s]Running 10000 simulations.:  98%|█████████▊| 9782/10000 [00:59<00:01, 164.79it/s]Running 10000 simulations.:  98%|█████████▊| 9799/10000 [00:59<00:01, 164.55it/s]Running 10000 simulations.:  98%|█████████▊| 9816/10000 [00:59<00:01, 164.26it/s]Running 10000 simulations.:  98%|█████████▊| 9833/10000 [00:59<00:01, 164.43it/s]Running 10000 simulations.:  98%|█████████▊| 9850/10000 [00:59<00:00, 164.73it/s]Running 10000 simulations.:  99%|█████████▊| 9867/10000 [00:59<00:00, 165.14it/s]Running 10000 simulations.:  99%|█████████▉| 9884/10000 [00:59<00:00, 164.78it/s]Running 10000 simulations.:  99%|█████████▉| 9901/10000 [00:59<00:00, 164.79it/s]Running 10000 simulations.:  99%|█████████▉| 9918/10000 [00:59<00:00, 165.54it/s]Running 10000 simulations.:  99%|█████████▉| 9935/10000 [00:59<00:00, 164.91it/s]Running 10000 simulations.: 100%|█████████▉| 9952/10000 [01:00<00:00, 164.51it/s]Running 10000 simulations.: 100%|█████████▉| 9969/10000 [01:00<00:00, 164.45it/s]Running 10000 simulations.: 100%|█████████▉| 9986/10000 [01:00<00:00, 164.26it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:00<00:00, 165.61it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 18/10000 [00:00<00:56, 176.65it/s]Running 10000 simulations.:   0%|          | 36/10000 [00:00<00:56, 175.64it/s]Running 10000 simulations.:   1%|          | 54/10000 [00:00<00:56, 175.66it/s]Running 10000 simulations.:   1%|          | 72/10000 [00:00<00:56, 175.78it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<00:56, 176.00it/s]Running 10000 simulations.:   1%|          | 108/10000 [00:00<00:56, 176.34it/s]Running 10000 simulations.:   1%|▏         | 126/10000 [00:00<00:56, 175.70it/s]Running 10000 simulations.:   1%|▏         | 144/10000 [00:00<00:56, 175.97it/s]Running 10000 simulations.:   2%|▏         | 162/10000 [00:00<00:55, 175.97it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:01<00:55, 175.83it/s]Running 10000 simulations.:   2%|▏         | 198/10000 [00:01<00:55, 175.54it/s]Running 10000 simulations.:   2%|▏         | 216/10000 [00:01<00:55, 175.22it/s]Running 10000 simulations.:   2%|▏         | 234/10000 [00:01<00:55, 175.71it/s]Running 10000 simulations.:   3%|▎         | 252/10000 [00:01<00:55, 175.71it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:01<00:55, 175.16it/s]Running 10000 simulations.:   3%|▎         | 288/10000 [00:01<00:55, 174.18it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:55, 174.44it/s]Running 10000 simulations.:   3%|▎         | 324/10000 [00:01<00:55, 174.07it/s]Running 10000 simulations.:   3%|▎         | 342/10000 [00:01<00:55, 174.47it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:02<00:55, 174.48it/s]Running 10000 simulations.:   4%|▍         | 378/10000 [00:02<00:54, 175.03it/s]Running 10000 simulations.:   4%|▍         | 396/10000 [00:02<00:57, 167.70it/s]Running 10000 simulations.:   4%|▍         | 414/10000 [00:02<00:56, 169.71it/s]Running 10000 simulations.:   4%|▍         | 432/10000 [00:02<00:56, 170.67it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:02<00:55, 171.58it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:02<00:55, 171.18it/s]Running 10000 simulations.:   5%|▍         | 486/10000 [00:02<00:55, 171.28it/s]Running 10000 simulations.:   5%|▌         | 504/10000 [00:02<00:54, 172.92it/s]Running 10000 simulations.:   5%|▌         | 522/10000 [00:03<00:54, 173.50it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:03<00:54, 173.59it/s]Running 10000 simulations.:   6%|▌         | 558/10000 [00:03<00:54, 173.87it/s]Running 10000 simulations.:   6%|▌         | 576/10000 [00:03<00:54, 173.39it/s]Running 10000 simulations.:   6%|▌         | 594/10000 [00:03<00:54, 172.84it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:03<00:54, 172.11it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:03<00:54, 172.03it/s]Running 10000 simulations.:   6%|▋         | 648/10000 [00:03<00:54, 172.36it/s]Running 10000 simulations.:   7%|▋         | 666/10000 [00:03<00:53, 174.14it/s]Running 10000 simulations.:   7%|▋         | 684/10000 [00:03<00:53, 175.24it/s]Running 10000 simulations.:   7%|▋         | 702/10000 [00:04<00:53, 175.17it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:04<00:53, 173.88it/s]Running 10000 simulations.:   7%|▋         | 738/10000 [00:04<00:53, 173.62it/s]Running 10000 simulations.:   8%|▊         | 756/10000 [00:04<00:53, 173.14it/s]Running 10000 simulations.:   8%|▊         | 774/10000 [00:04<00:53, 173.36it/s]Running 10000 simulations.:   8%|▊         | 792/10000 [00:04<00:53, 173.68it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:04<00:52, 174.24it/s]Running 10000 simulations.:   8%|▊         | 828/10000 [00:04<00:52, 173.92it/s]Running 10000 simulations.:   8%|▊         | 846/10000 [00:04<00:52, 173.28it/s]Running 10000 simulations.:   9%|▊         | 864/10000 [00:04<00:52, 172.43it/s]Running 10000 simulations.:   9%|▉         | 882/10000 [00:05<00:52, 173.16it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:05<00:52, 172.56it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:05<00:52, 173.19it/s]Running 10000 simulations.:   9%|▉         | 936/10000 [00:05<00:52, 172.87it/s]Running 10000 simulations.:  10%|▉         | 954/10000 [00:05<00:52, 173.42it/s]Running 10000 simulations.:  10%|▉         | 972/10000 [00:05<00:51, 173.70it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:05<00:51, 173.50it/s]Running 10000 simulations.:  10%|█         | 1008/10000 [00:05<00:51, 172.96it/s]Running 10000 simulations.:  10%|█         | 1026/10000 [00:05<00:51, 172.92it/s]Running 10000 simulations.:  10%|█         | 1044/10000 [00:06<00:51, 172.90it/s]Running 10000 simulations.:  11%|█         | 1062/10000 [00:06<00:51, 171.90it/s]Running 10000 simulations.:  11%|█         | 1080/10000 [00:06<00:51, 172.96it/s]Running 10000 simulations.:  11%|█         | 1098/10000 [00:06<00:51, 173.16it/s]Running 10000 simulations.:  11%|█         | 1116/10000 [00:06<00:51, 173.06it/s]Running 10000 simulations.:  11%|█▏        | 1134/10000 [00:06<00:51, 173.20it/s]Running 10000 simulations.:  12%|█▏        | 1152/10000 [00:06<00:51, 173.17it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:06<00:51, 172.83it/s]Running 10000 simulations.:  12%|█▏        | 1188/10000 [00:06<00:50, 173.33it/s]Running 10000 simulations.:  12%|█▏        | 1206/10000 [00:06<00:50, 173.34it/s]Running 10000 simulations.:  12%|█▏        | 1224/10000 [00:07<00:50, 173.10it/s]Running 10000 simulations.:  12%|█▏        | 1242/10000 [00:07<00:50, 172.81it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:07<00:50, 172.91it/s]Running 10000 simulations.:  13%|█▎        | 1278/10000 [00:07<00:50, 173.45it/s]Running 10000 simulations.:  13%|█▎        | 1296/10000 [00:07<00:50, 173.52it/s]Running 10000 simulations.:  13%|█▎        | 1314/10000 [00:07<00:50, 173.16it/s]Running 10000 simulations.:  13%|█▎        | 1332/10000 [00:07<00:49, 173.60it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:07<00:49, 173.36it/s]Running 10000 simulations.:  14%|█▎        | 1368/10000 [00:07<00:49, 173.47it/s]Running 10000 simulations.:  14%|█▍        | 1386/10000 [00:07<00:49, 173.39it/s]Running 10000 simulations.:  14%|█▍        | 1404/10000 [00:08<00:49, 173.01it/s]Running 10000 simulations.:  14%|█▍        | 1422/10000 [00:08<00:49, 172.67it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:08<00:49, 172.77it/s]Running 10000 simulations.:  15%|█▍        | 1458/10000 [00:08<00:49, 172.46it/s]Running 10000 simulations.:  15%|█▍        | 1476/10000 [00:08<00:49, 172.40it/s]Running 10000 simulations.:  15%|█▍        | 1494/10000 [00:08<00:49, 172.70it/s]Running 10000 simulations.:  15%|█▌        | 1512/10000 [00:08<00:49, 172.77it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:08<00:48, 173.05it/s]Running 10000 simulations.:  15%|█▌        | 1548/10000 [00:08<00:48, 173.62it/s]Running 10000 simulations.:  16%|█▌        | 1566/10000 [00:09<00:48, 172.88it/s]Running 10000 simulations.:  16%|█▌        | 1584/10000 [00:09<00:48, 172.61it/s]Running 10000 simulations.:  16%|█▌        | 1602/10000 [00:09<00:48, 173.07it/s]Running 10000 simulations.:  16%|█▌        | 1620/10000 [00:09<00:48, 173.70it/s]Running 10000 simulations.:  16%|█▋        | 1638/10000 [00:09<00:48, 174.07it/s]Running 10000 simulations.:  17%|█▋        | 1656/10000 [00:09<00:47, 173.96it/s]Running 10000 simulations.:  17%|█▋        | 1674/10000 [00:09<00:47, 173.88it/s]Running 10000 simulations.:  17%|█▋        | 1692/10000 [00:09<00:47, 174.26it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:09<00:47, 173.27it/s]Running 10000 simulations.:  17%|█▋        | 1728/10000 [00:09<00:47, 173.33it/s]Running 10000 simulations.:  17%|█▋        | 1746/10000 [00:10<00:47, 173.00it/s]Running 10000 simulations.:  18%|█▊        | 1764/10000 [00:10<00:47, 173.47it/s]Running 10000 simulations.:  18%|█▊        | 1782/10000 [00:10<00:47, 173.32it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:10<00:47, 172.64it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:10<00:47, 172.03it/s]Running 10000 simulations.:  18%|█▊        | 1836/10000 [00:10<00:47, 172.47it/s]Running 10000 simulations.:  19%|█▊        | 1854/10000 [00:10<00:47, 172.23it/s]Running 10000 simulations.:  19%|█▊        | 1872/10000 [00:10<00:47, 170.89it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:10<00:47, 171.34it/s]Running 10000 simulations.:  19%|█▉        | 1908/10000 [00:11<00:47, 170.91it/s]Running 10000 simulations.:  19%|█▉        | 1926/10000 [00:11<00:47, 170.88it/s]Running 10000 simulations.:  19%|█▉        | 1944/10000 [00:11<00:47, 170.53it/s]Running 10000 simulations.:  20%|█▉        | 1962/10000 [00:11<00:46, 171.28it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:11<00:46, 171.82it/s]Running 10000 simulations.:  20%|█▉        | 1998/10000 [00:11<00:46, 171.94it/s]Running 10000 simulations.:  20%|██        | 2016/10000 [00:11<00:46, 171.45it/s]Running 10000 simulations.:  20%|██        | 2034/10000 [00:11<00:46, 171.71it/s]Running 10000 simulations.:  21%|██        | 2052/10000 [00:11<00:46, 171.61it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:11<00:46, 172.01it/s]Running 10000 simulations.:  21%|██        | 2088/10000 [00:12<00:46, 171.85it/s]Running 10000 simulations.:  21%|██        | 2106/10000 [00:12<00:46, 170.90it/s]Running 10000 simulations.:  21%|██        | 2124/10000 [00:12<00:46, 171.07it/s]Running 10000 simulations.:  21%|██▏       | 2142/10000 [00:12<00:46, 170.46it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:12<00:46, 170.40it/s]Running 10000 simulations.:  22%|██▏       | 2178/10000 [00:12<00:46, 169.81it/s]Running 10000 simulations.:  22%|██▏       | 2196/10000 [00:12<00:45, 169.97it/s]Running 10000 simulations.:  22%|██▏       | 2214/10000 [00:12<00:45, 170.09it/s]Running 10000 simulations.:  22%|██▏       | 2232/10000 [00:12<00:45, 170.42it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:13<00:45, 170.23it/s]Running 10000 simulations.:  23%|██▎       | 2268/10000 [00:13<00:45, 170.02it/s]Running 10000 simulations.:  23%|██▎       | 2286/10000 [00:13<00:45, 170.73it/s]Running 10000 simulations.:  23%|██▎       | 2304/10000 [00:13<00:45, 170.57it/s]Running 10000 simulations.:  23%|██▎       | 2322/10000 [00:13<00:45, 169.99it/s]Running 10000 simulations.:  23%|██▎       | 2339/10000 [00:13<00:45, 169.18it/s]Running 10000 simulations.:  24%|██▎       | 2357/10000 [00:13<00:45, 169.55it/s]Running 10000 simulations.:  24%|██▎       | 2374/10000 [00:13<00:44, 169.47it/s]Running 10000 simulations.:  24%|██▍       | 2392/10000 [00:13<00:44, 170.03it/s]Running 10000 simulations.:  24%|██▍       | 2410/10000 [00:13<00:44, 170.10it/s]Running 10000 simulations.:  24%|██▍       | 2428/10000 [00:14<00:44, 170.75it/s]Running 10000 simulations.:  24%|██▍       | 2446/10000 [00:14<00:44, 170.92it/s]Running 10000 simulations.:  25%|██▍       | 2464/10000 [00:14<00:44, 171.17it/s]Running 10000 simulations.:  25%|██▍       | 2482/10000 [00:14<00:43, 171.10it/s]Running 10000 simulations.:  25%|██▌       | 2500/10000 [00:14<00:43, 171.24it/s]Running 10000 simulations.:  25%|██▌       | 2518/10000 [00:14<00:43, 170.43it/s]Running 10000 simulations.:  25%|██▌       | 2536/10000 [00:14<00:43, 169.93it/s]Running 10000 simulations.:  26%|██▌       | 2554/10000 [00:14<00:43, 170.19it/s]Running 10000 simulations.:  26%|██▌       | 2572/10000 [00:14<00:43, 170.21it/s]Running 10000 simulations.:  26%|██▌       | 2590/10000 [00:15<00:43, 170.28it/s]Running 10000 simulations.:  26%|██▌       | 2608/10000 [00:15<00:43, 169.99it/s]Running 10000 simulations.:  26%|██▋       | 2625/10000 [00:15<00:43, 169.73it/s]Running 10000 simulations.:  26%|██▋       | 2643/10000 [00:15<00:43, 170.41it/s]Running 10000 simulations.:  27%|██▋       | 2661/10000 [00:15<00:43, 170.25it/s]Running 10000 simulations.:  27%|██▋       | 2679/10000 [00:15<00:43, 170.14it/s]Running 10000 simulations.:  27%|██▋       | 2697/10000 [00:15<00:42, 171.23it/s]Running 10000 simulations.:  27%|██▋       | 2715/10000 [00:15<00:42, 171.65it/s]Running 10000 simulations.:  27%|██▋       | 2733/10000 [00:15<00:42, 172.00it/s]Running 10000 simulations.:  28%|██▊       | 2751/10000 [00:15<00:41, 172.91it/s]Running 10000 simulations.:  28%|██▊       | 2769/10000 [00:16<00:41, 173.42it/s]Running 10000 simulations.:  28%|██▊       | 2787/10000 [00:16<00:41, 173.61it/s]Running 10000 simulations.:  28%|██▊       | 2805/10000 [00:16<00:41, 173.37it/s]Running 10000 simulations.:  28%|██▊       | 2823/10000 [00:16<00:41, 173.38it/s]Running 10000 simulations.:  28%|██▊       | 2841/10000 [00:16<00:41, 173.02it/s]Running 10000 simulations.:  29%|██▊       | 2859/10000 [00:16<00:41, 172.87it/s]Running 10000 simulations.:  29%|██▉       | 2877/10000 [00:16<00:41, 172.80it/s]Running 10000 simulations.:  29%|██▉       | 2895/10000 [00:16<00:41, 172.92it/s]Running 10000 simulations.:  29%|██▉       | 2913/10000 [00:16<00:40, 172.98it/s]Running 10000 simulations.:  29%|██▉       | 2931/10000 [00:16<00:40, 172.86it/s]Running 10000 simulations.:  29%|██▉       | 2949/10000 [00:17<00:40, 172.45it/s]Running 10000 simulations.:  30%|██▉       | 2967/10000 [00:17<00:40, 173.29it/s]Running 10000 simulations.:  30%|██▉       | 2985/10000 [00:17<00:40, 173.31it/s]Running 10000 simulations.:  30%|███       | 3003/10000 [00:17<00:40, 173.58it/s]Running 10000 simulations.:  30%|███       | 3021/10000 [00:17<00:40, 172.99it/s]Running 10000 simulations.:  30%|███       | 3039/10000 [00:17<00:40, 171.70it/s]Running 10000 simulations.:  31%|███       | 3057/10000 [00:17<00:40, 170.78it/s]Running 10000 simulations.:  31%|███       | 3075/10000 [00:17<00:40, 170.39it/s]Running 10000 simulations.:  31%|███       | 3093/10000 [00:17<00:40, 169.62it/s]Running 10000 simulations.:  31%|███       | 3111/10000 [00:18<00:40, 170.12it/s]Running 10000 simulations.:  31%|███▏      | 3129/10000 [00:18<00:40, 170.33it/s]Running 10000 simulations.:  31%|███▏      | 3147/10000 [00:18<00:40, 170.65it/s]Running 10000 simulations.:  32%|███▏      | 3165/10000 [00:18<00:39, 171.60it/s]Running 10000 simulations.:  32%|███▏      | 3183/10000 [00:18<00:39, 172.33it/s]Running 10000 simulations.:  32%|███▏      | 3201/10000 [00:18<00:39, 172.76it/s]Running 10000 simulations.:  32%|███▏      | 3219/10000 [00:18<00:39, 172.96it/s]Running 10000 simulations.:  32%|███▏      | 3237/10000 [00:18<00:39, 172.69it/s]Running 10000 simulations.:  33%|███▎      | 3255/10000 [00:18<00:38, 173.26it/s]Running 10000 simulations.:  33%|███▎      | 3273/10000 [00:18<00:38, 173.19it/s]Running 10000 simulations.:  33%|███▎      | 3291/10000 [00:19<00:38, 172.62it/s]Running 10000 simulations.:  33%|███▎      | 3309/10000 [00:19<00:38, 172.47it/s]Running 10000 simulations.:  33%|███▎      | 3327/10000 [00:19<00:38, 173.11it/s]Running 10000 simulations.:  33%|███▎      | 3345/10000 [00:19<00:38, 173.64it/s]Running 10000 simulations.:  34%|███▎      | 3363/10000 [00:19<00:38, 171.54it/s]Running 10000 simulations.:  34%|███▍      | 3381/10000 [00:19<00:38, 170.06it/s]Running 10000 simulations.:  34%|███▍      | 3399/10000 [00:19<00:38, 171.32it/s]Running 10000 simulations.:  34%|███▍      | 3417/10000 [00:19<00:38, 172.03it/s]Running 10000 simulations.:  34%|███▍      | 3435/10000 [00:19<00:38, 172.33it/s]Running 10000 simulations.:  35%|███▍      | 3453/10000 [00:20<00:37, 172.79it/s]Running 10000 simulations.:  35%|███▍      | 3471/10000 [00:20<00:37, 173.01it/s]Running 10000 simulations.:  35%|███▍      | 3489/10000 [00:20<00:37, 173.04it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:20<00:37, 173.04it/s]Running 10000 simulations.:  35%|███▌      | 3525/10000 [00:20<00:37, 172.89it/s]Running 10000 simulations.:  35%|███▌      | 3543/10000 [00:20<00:37, 173.31it/s]Running 10000 simulations.:  36%|███▌      | 3561/10000 [00:20<00:37, 173.27it/s]Running 10000 simulations.:  36%|███▌      | 3579/10000 [00:20<00:37, 173.14it/s]Running 10000 simulations.:  36%|███▌      | 3597/10000 [00:20<00:37, 172.52it/s]Running 10000 simulations.:  36%|███▌      | 3615/10000 [00:20<00:36, 173.07it/s]Running 10000 simulations.:  36%|███▋      | 3633/10000 [00:21<00:36, 172.46it/s]Running 10000 simulations.:  37%|███▋      | 3651/10000 [00:21<00:36, 172.94it/s]Running 10000 simulations.:  37%|███▋      | 3669/10000 [00:21<00:36, 172.85it/s]Running 10000 simulations.:  37%|███▋      | 3687/10000 [00:21<00:36, 173.15it/s]Running 10000 simulations.:  37%|███▋      | 3705/10000 [00:21<00:36, 173.24it/s]Running 10000 simulations.:  37%|███▋      | 3723/10000 [00:21<00:36, 173.04it/s]Running 10000 simulations.:  37%|███▋      | 3741/10000 [00:21<00:36, 173.30it/s]Running 10000 simulations.:  38%|███▊      | 3759/10000 [00:21<00:36, 173.28it/s]Running 10000 simulations.:  38%|███▊      | 3777/10000 [00:21<00:35, 173.32it/s]Running 10000 simulations.:  38%|███▊      | 3795/10000 [00:21<00:35, 173.10it/s]Running 10000 simulations.:  38%|███▊      | 3813/10000 [00:22<00:35, 172.76it/s]Running 10000 simulations.:  38%|███▊      | 3831/10000 [00:22<00:35, 172.68it/s]Running 10000 simulations.:  38%|███▊      | 3849/10000 [00:22<00:35, 172.39it/s]Running 10000 simulations.:  39%|███▊      | 3867/10000 [00:22<00:35, 172.21it/s]Running 10000 simulations.:  39%|███▉      | 3885/10000 [00:22<00:35, 172.54it/s]Running 10000 simulations.:  39%|███▉      | 3903/10000 [00:22<00:35, 173.01it/s]Running 10000 simulations.:  39%|███▉      | 3921/10000 [00:22<00:35, 172.77it/s]Running 10000 simulations.:  39%|███▉      | 3939/10000 [00:22<00:35, 173.02it/s]Running 10000 simulations.:  40%|███▉      | 3957/10000 [00:22<00:35, 172.58it/s]Running 10000 simulations.:  40%|███▉      | 3975/10000 [00:23<00:35, 172.04it/s]Running 10000 simulations.:  40%|███▉      | 3993/10000 [00:23<00:34, 171.70it/s]Running 10000 simulations.:  40%|████      | 4011/10000 [00:23<00:34, 172.18it/s]Running 10000 simulations.:  40%|████      | 4029/10000 [00:23<00:34, 172.03it/s]Running 10000 simulations.:  40%|████      | 4047/10000 [00:23<00:34, 170.68it/s]Running 10000 simulations.:  41%|████      | 4065/10000 [00:23<00:34, 170.12it/s]Running 10000 simulations.:  41%|████      | 4083/10000 [00:23<00:34, 171.12it/s]Running 10000 simulations.:  41%|████      | 4101/10000 [00:23<00:34, 171.94it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:23<00:34, 172.51it/s]Running 10000 simulations.:  41%|████▏     | 4137/10000 [00:23<00:33, 172.90it/s]Running 10000 simulations.:  42%|████▏     | 4155/10000 [00:24<00:33, 172.75it/s]Running 10000 simulations.:  42%|████▏     | 4173/10000 [00:24<00:33, 172.73it/s]Running 10000 simulations.:  42%|████▏     | 4191/10000 [00:24<00:33, 172.25it/s]Running 10000 simulations.:  42%|████▏     | 4209/10000 [00:24<00:33, 170.99it/s]Running 10000 simulations.:  42%|████▏     | 4227/10000 [00:24<00:33, 171.44it/s]Running 10000 simulations.:  42%|████▏     | 4245/10000 [00:24<00:33, 171.78it/s]Running 10000 simulations.:  43%|████▎     | 4263/10000 [00:24<00:33, 172.16it/s]Running 10000 simulations.:  43%|████▎     | 4281/10000 [00:24<00:33, 172.54it/s]Running 10000 simulations.:  43%|████▎     | 4299/10000 [00:24<00:33, 172.48it/s]Running 10000 simulations.:  43%|████▎     | 4317/10000 [00:25<00:32, 172.78it/s]Running 10000 simulations.:  43%|████▎     | 4335/10000 [00:25<00:32, 172.10it/s]Running 10000 simulations.:  44%|████▎     | 4353/10000 [00:25<00:32, 172.51it/s]Running 10000 simulations.:  44%|████▎     | 4371/10000 [00:25<00:32, 172.78it/s]Running 10000 simulations.:  44%|████▍     | 4389/10000 [00:25<00:32, 172.68it/s]Running 10000 simulations.:  44%|████▍     | 4407/10000 [00:25<00:32, 172.46it/s]Running 10000 simulations.:  44%|████▍     | 4425/10000 [00:25<00:32, 172.56it/s]Running 10000 simulations.:  44%|████▍     | 4443/10000 [00:25<00:32, 172.65it/s]Running 10000 simulations.:  45%|████▍     | 4461/10000 [00:25<00:32, 171.48it/s]Running 10000 simulations.:  45%|████▍     | 4479/10000 [00:25<00:32, 172.03it/s]Running 10000 simulations.:  45%|████▍     | 4497/10000 [00:26<00:31, 172.39it/s]Running 10000 simulations.:  45%|████▌     | 4515/10000 [00:26<00:31, 172.70it/s]Running 10000 simulations.:  45%|████▌     | 4533/10000 [00:26<00:31, 173.16it/s]Running 10000 simulations.:  46%|████▌     | 4551/10000 [00:26<00:31, 173.36it/s]Running 10000 simulations.:  46%|████▌     | 4569/10000 [00:26<00:31, 173.69it/s]Running 10000 simulations.:  46%|████▌     | 4587/10000 [00:26<00:31, 172.51it/s]Running 10000 simulations.:  46%|████▌     | 4605/10000 [00:26<00:31, 173.09it/s]Running 10000 simulations.:  46%|████▌     | 4623/10000 [00:26<00:31, 173.21it/s]Running 10000 simulations.:  46%|████▋     | 4641/10000 [00:26<00:30, 173.44it/s]Running 10000 simulations.:  47%|████▋     | 4659/10000 [00:27<00:30, 173.82it/s]Running 10000 simulations.:  47%|████▋     | 4677/10000 [00:27<00:30, 173.83it/s]Running 10000 simulations.:  47%|████▋     | 4695/10000 [00:27<00:30, 172.55it/s]Running 10000 simulations.:  47%|████▋     | 4713/10000 [00:27<00:30, 171.52it/s]Running 10000 simulations.:  47%|████▋     | 4731/10000 [00:27<00:30, 172.05it/s]Running 10000 simulations.:  47%|████▋     | 4749/10000 [00:27<00:30, 172.68it/s]Running 10000 simulations.:  48%|████▊     | 4767/10000 [00:27<00:30, 172.77it/s]Running 10000 simulations.:  48%|████▊     | 4785/10000 [00:27<00:30, 172.76it/s]Running 10000 simulations.:  48%|████▊     | 4803/10000 [00:27<00:30, 172.35it/s]Running 10000 simulations.:  48%|████▊     | 4821/10000 [00:27<00:30, 172.59it/s]Running 10000 simulations.:  48%|████▊     | 4839/10000 [00:28<00:29, 172.97it/s]Running 10000 simulations.:  49%|████▊     | 4857/10000 [00:28<00:29, 173.09it/s]Running 10000 simulations.:  49%|████▉     | 4875/10000 [00:28<00:29, 172.83it/s]Running 10000 simulations.:  49%|████▉     | 4893/10000 [00:28<00:29, 172.53it/s]Running 10000 simulations.:  49%|████▉     | 4911/10000 [00:28<00:29, 171.88it/s]Running 10000 simulations.:  49%|████▉     | 4929/10000 [00:28<00:29, 172.94it/s]Running 10000 simulations.:  49%|████▉     | 4947/10000 [00:28<00:29, 173.09it/s]Running 10000 simulations.:  50%|████▉     | 4965/10000 [00:28<00:29, 173.45it/s]Running 10000 simulations.:  50%|████▉     | 4983/10000 [00:28<00:28, 173.60it/s]Running 10000 simulations.:  50%|█████     | 5001/10000 [00:28<00:28, 173.46it/s]Running 10000 simulations.:  50%|█████     | 5019/10000 [00:29<00:28, 173.21it/s]Running 10000 simulations.:  50%|█████     | 5037/10000 [00:29<00:28, 172.88it/s]Running 10000 simulations.:  51%|█████     | 5055/10000 [00:29<00:28, 172.51it/s]Running 10000 simulations.:  51%|█████     | 5073/10000 [00:29<00:28, 172.28it/s]Running 10000 simulations.:  51%|█████     | 5091/10000 [00:29<00:28, 172.30it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:29<00:28, 172.66it/s]Running 10000 simulations.:  51%|█████▏    | 5127/10000 [00:29<00:28, 172.75it/s]Running 10000 simulations.:  51%|█████▏    | 5145/10000 [00:29<00:28, 172.61it/s]Running 10000 simulations.:  52%|█████▏    | 5163/10000 [00:29<00:28, 172.62it/s]Running 10000 simulations.:  52%|█████▏    | 5181/10000 [00:30<00:27, 173.00it/s]Running 10000 simulations.:  52%|█████▏    | 5199/10000 [00:30<00:27, 172.89it/s]Running 10000 simulations.:  52%|█████▏    | 5217/10000 [00:30<00:27, 172.94it/s]Running 10000 simulations.:  52%|█████▏    | 5235/10000 [00:30<00:27, 172.92it/s]Running 10000 simulations.:  53%|█████▎    | 5253/10000 [00:30<00:27, 172.73it/s]Running 10000 simulations.:  53%|█████▎    | 5271/10000 [00:30<00:27, 172.81it/s]Running 10000 simulations.:  53%|█████▎    | 5289/10000 [00:30<00:27, 172.58it/s]Running 10000 simulations.:  53%|█████▎    | 5307/10000 [00:30<00:27, 172.71it/s]Running 10000 simulations.:  53%|█████▎    | 5325/10000 [00:30<00:27, 172.60it/s]Running 10000 simulations.:  53%|█████▎    | 5343/10000 [00:30<00:27, 172.22it/s]Running 10000 simulations.:  54%|█████▎    | 5361/10000 [00:31<00:26, 172.08it/s]Running 10000 simulations.:  54%|█████▍    | 5379/10000 [00:31<00:26, 172.60it/s]Running 10000 simulations.:  54%|█████▍    | 5397/10000 [00:31<00:26, 172.72it/s]Running 10000 simulations.:  54%|█████▍    | 5415/10000 [00:31<00:26, 173.13it/s]Running 10000 simulations.:  54%|█████▍    | 5433/10000 [00:31<00:26, 173.11it/s]Running 10000 simulations.:  55%|█████▍    | 5451/10000 [00:31<00:26, 172.86it/s]Running 10000 simulations.:  55%|█████▍    | 5469/10000 [00:31<00:26, 173.02it/s]Running 10000 simulations.:  55%|█████▍    | 5487/10000 [00:31<00:26, 172.92it/s]Running 10000 simulations.:  55%|█████▌    | 5505/10000 [00:31<00:26, 172.72it/s]Running 10000 simulations.:  55%|█████▌    | 5523/10000 [00:32<00:25, 172.40it/s]Running 10000 simulations.:  55%|█████▌    | 5541/10000 [00:32<00:25, 172.72it/s]Running 10000 simulations.:  56%|█████▌    | 5559/10000 [00:32<00:25, 172.34it/s]Running 10000 simulations.:  56%|█████▌    | 5577/10000 [00:32<00:26, 165.71it/s]Running 10000 simulations.:  56%|█████▌    | 5595/10000 [00:32<00:26, 167.48it/s]Running 10000 simulations.:  56%|█████▌    | 5613/10000 [00:32<00:25, 169.27it/s]Running 10000 simulations.:  56%|█████▋    | 5631/10000 [00:32<00:25, 170.38it/s]Running 10000 simulations.:  56%|█████▋    | 5649/10000 [00:32<00:25, 170.78it/s]Running 10000 simulations.:  57%|█████▋    | 5667/10000 [00:32<00:25, 171.53it/s]Running 10000 simulations.:  57%|█████▋    | 5685/10000 [00:32<00:25, 171.96it/s]Running 10000 simulations.:  57%|█████▋    | 5703/10000 [00:33<00:24, 172.26it/s]Running 10000 simulations.:  57%|█████▋    | 5721/10000 [00:33<00:24, 172.84it/s]Running 10000 simulations.:  57%|█████▋    | 5739/10000 [00:33<00:24, 172.86it/s]Running 10000 simulations.:  58%|█████▊    | 5757/10000 [00:33<00:24, 172.56it/s]Running 10000 simulations.:  58%|█████▊    | 5775/10000 [00:33<00:24, 172.80it/s]Running 10000 simulations.:  58%|█████▊    | 5793/10000 [00:33<00:24, 172.81it/s]Running 10000 simulations.:  58%|█████▊    | 5811/10000 [00:33<00:24, 173.29it/s]Running 10000 simulations.:  58%|█████▊    | 5829/10000 [00:33<00:24, 170.77it/s]Running 10000 simulations.:  58%|█████▊    | 5847/10000 [00:33<00:24, 168.71it/s]Running 10000 simulations.:  59%|█████▊    | 5864/10000 [00:34<00:24, 167.48it/s]Running 10000 simulations.:  59%|█████▉    | 5881/10000 [00:34<00:24, 166.65it/s]Running 10000 simulations.:  59%|█████▉    | 5898/10000 [00:34<00:24, 166.22it/s]Running 10000 simulations.:  59%|█████▉    | 5915/10000 [00:34<00:24, 166.15it/s]Running 10000 simulations.:  59%|█████▉    | 5932/10000 [00:34<00:24, 165.82it/s]Running 10000 simulations.:  59%|█████▉    | 5949/10000 [00:34<00:24, 165.69it/s]Running 10000 simulations.:  60%|█████▉    | 5966/10000 [00:34<00:24, 165.38it/s]Running 10000 simulations.:  60%|█████▉    | 5983/10000 [00:34<00:24, 165.28it/s]Running 10000 simulations.:  60%|██████    | 6000/10000 [00:34<00:24, 165.26it/s]Running 10000 simulations.:  60%|██████    | 6017/10000 [00:34<00:24, 165.02it/s]Running 10000 simulations.:  60%|██████    | 6034/10000 [00:35<00:24, 164.71it/s]Running 10000 simulations.:  61%|██████    | 6051/10000 [00:35<00:23, 165.22it/s]Running 10000 simulations.:  61%|██████    | 6068/10000 [00:35<00:23, 165.04it/s]Running 10000 simulations.:  61%|██████    | 6085/10000 [00:35<00:23, 164.83it/s]Running 10000 simulations.:  61%|██████    | 6102/10000 [00:35<00:23, 164.61it/s]Running 10000 simulations.:  61%|██████    | 6119/10000 [00:35<00:23, 164.76it/s]Running 10000 simulations.:  61%|██████▏   | 6136/10000 [00:35<00:23, 164.74it/s]Running 10000 simulations.:  62%|██████▏   | 6153/10000 [00:35<00:23, 164.81it/s]Running 10000 simulations.:  62%|██████▏   | 6170/10000 [00:35<00:23, 165.08it/s]Running 10000 simulations.:  62%|██████▏   | 6187/10000 [00:35<00:23, 164.77it/s]Running 10000 simulations.:  62%|██████▏   | 6204/10000 [00:36<00:23, 164.71it/s]Running 10000 simulations.:  62%|██████▏   | 6221/10000 [00:36<00:22, 164.60it/s]Running 10000 simulations.:  62%|██████▏   | 6238/10000 [00:36<00:22, 165.16it/s]Running 10000 simulations.:  63%|██████▎   | 6255/10000 [00:36<00:22, 165.03it/s]Running 10000 simulations.:  63%|██████▎   | 6274/10000 [00:36<00:21, 171.63it/s]Running 10000 simulations.:  63%|██████▎   | 6293/10000 [00:36<00:21, 174.02it/s]Running 10000 simulations.:  63%|██████▎   | 6311/10000 [00:36<00:21, 171.00it/s]Running 10000 simulations.:  63%|██████▎   | 6329/10000 [00:36<00:21, 168.84it/s]Running 10000 simulations.:  63%|██████▎   | 6346/10000 [00:36<00:21, 167.49it/s]Running 10000 simulations.:  64%|██████▎   | 6363/10000 [00:37<00:21, 166.69it/s]Running 10000 simulations.:  64%|██████▍   | 6380/10000 [00:37<00:21, 165.79it/s]Running 10000 simulations.:  64%|██████▍   | 6397/10000 [00:37<00:21, 165.58it/s]Running 10000 simulations.:  64%|██████▍   | 6414/10000 [00:37<00:21, 165.48it/s]Running 10000 simulations.:  64%|██████▍   | 6431/10000 [00:37<00:21, 165.44it/s]Running 10000 simulations.:  64%|██████▍   | 6448/10000 [00:37<00:21, 164.92it/s]Running 10000 simulations.:  65%|██████▍   | 6465/10000 [00:37<00:21, 164.75it/s]Running 10000 simulations.:  65%|██████▍   | 6482/10000 [00:37<00:21, 164.84it/s]Running 10000 simulations.:  65%|██████▍   | 6499/10000 [00:37<00:21, 164.75it/s]Running 10000 simulations.:  65%|██████▌   | 6516/10000 [00:37<00:21, 164.69it/s]Running 10000 simulations.:  65%|██████▌   | 6533/10000 [00:38<00:21, 164.40it/s]Running 10000 simulations.:  66%|██████▌   | 6550/10000 [00:38<00:21, 164.18it/s]Running 10000 simulations.:  66%|██████▌   | 6567/10000 [00:38<00:20, 164.48it/s]Running 10000 simulations.:  66%|██████▌   | 6584/10000 [00:38<00:20, 164.36it/s]Running 10000 simulations.:  66%|██████▌   | 6601/10000 [00:38<00:20, 164.46it/s]Running 10000 simulations.:  66%|██████▌   | 6618/10000 [00:38<00:20, 164.57it/s]Running 10000 simulations.:  66%|██████▋   | 6635/10000 [00:38<00:20, 164.61it/s]Running 10000 simulations.:  67%|██████▋   | 6652/10000 [00:38<00:20, 164.70it/s]Running 10000 simulations.:  67%|██████▋   | 6669/10000 [00:38<00:20, 164.86it/s]Running 10000 simulations.:  67%|██████▋   | 6686/10000 [00:38<00:20, 165.15it/s]Running 10000 simulations.:  67%|██████▋   | 6703/10000 [00:39<00:19, 165.36it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:39<00:19, 165.36it/s]Running 10000 simulations.:  67%|██████▋   | 6737/10000 [00:39<00:19, 165.29it/s]Running 10000 simulations.:  68%|██████▊   | 6754/10000 [00:39<00:19, 164.90it/s]Running 10000 simulations.:  68%|██████▊   | 6771/10000 [00:39<00:19, 164.91it/s]Running 10000 simulations.:  68%|██████▊   | 6788/10000 [00:39<00:19, 164.90it/s]Running 10000 simulations.:  68%|██████▊   | 6805/10000 [00:39<00:19, 165.14it/s]Running 10000 simulations.:  68%|██████▊   | 6822/10000 [00:39<00:19, 164.84it/s]Running 10000 simulations.:  68%|██████▊   | 6839/10000 [00:39<00:19, 164.70it/s]Running 10000 simulations.:  69%|██████▊   | 6856/10000 [00:40<00:19, 164.42it/s]Running 10000 simulations.:  69%|██████▊   | 6873/10000 [00:40<00:19, 164.55it/s]Running 10000 simulations.:  69%|██████▉   | 6890/10000 [00:40<00:18, 164.78it/s]Running 10000 simulations.:  69%|██████▉   | 6907/10000 [00:40<00:18, 165.22it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:40<00:18, 165.15it/s]Running 10000 simulations.:  69%|██████▉   | 6941/10000 [00:40<00:18, 165.05it/s]Running 10000 simulations.:  70%|██████▉   | 6958/10000 [00:40<00:18, 165.29it/s]Running 10000 simulations.:  70%|██████▉   | 6975/10000 [00:40<00:18, 165.21it/s]Running 10000 simulations.:  70%|██████▉   | 6992/10000 [00:40<00:18, 165.35it/s]Running 10000 simulations.:  70%|███████   | 7009/10000 [00:40<00:18, 165.55it/s]Running 10000 simulations.:  70%|███████   | 7026/10000 [00:41<00:17, 165.56it/s]Running 10000 simulations.:  70%|███████   | 7043/10000 [00:41<00:17, 165.57it/s]Running 10000 simulations.:  71%|███████   | 7060/10000 [00:41<00:17, 165.31it/s]Running 10000 simulations.:  71%|███████   | 7077/10000 [00:41<00:17, 164.92it/s]Running 10000 simulations.:  71%|███████   | 7094/10000 [00:41<00:17, 164.98it/s]Running 10000 simulations.:  71%|███████   | 7111/10000 [00:41<00:17, 165.08it/s]Running 10000 simulations.:  71%|███████▏  | 7128/10000 [00:41<00:17, 165.29it/s]Running 10000 simulations.:  71%|███████▏  | 7145/10000 [00:41<00:17, 165.49it/s]Running 10000 simulations.:  72%|███████▏  | 7162/10000 [00:41<00:17, 165.51it/s]Running 10000 simulations.:  72%|███████▏  | 7179/10000 [00:41<00:17, 165.48it/s]Running 10000 simulations.:  72%|███████▏  | 7196/10000 [00:42<00:16, 165.43it/s]Running 10000 simulations.:  72%|███████▏  | 7213/10000 [00:42<00:16, 165.52it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:42<00:16, 165.33it/s]Running 10000 simulations.:  72%|███████▏  | 7247/10000 [00:42<00:16, 165.46it/s]Running 10000 simulations.:  73%|███████▎  | 7264/10000 [00:42<00:16, 165.56it/s]Running 10000 simulations.:  73%|███████▎  | 7281/10000 [00:42<00:16, 165.26it/s]Running 10000 simulations.:  73%|███████▎  | 7298/10000 [00:42<00:16, 165.02it/s]Running 10000 simulations.:  73%|███████▎  | 7315/10000 [00:42<00:16, 165.03it/s]Running 10000 simulations.:  73%|███████▎  | 7332/10000 [00:42<00:16, 165.17it/s]Running 10000 simulations.:  73%|███████▎  | 7349/10000 [00:42<00:16, 164.91it/s]Running 10000 simulations.:  74%|███████▎  | 7366/10000 [00:43<00:15, 164.90it/s]Running 10000 simulations.:  74%|███████▍  | 7383/10000 [00:43<00:15, 164.82it/s]Running 10000 simulations.:  74%|███████▍  | 7400/10000 [00:43<00:15, 164.67it/s]Running 10000 simulations.:  74%|███████▍  | 7417/10000 [00:43<00:15, 164.31it/s]Running 10000 simulations.:  74%|███████▍  | 7434/10000 [00:43<00:15, 164.62it/s]Running 10000 simulations.:  75%|███████▍  | 7451/10000 [00:43<00:15, 164.63it/s]Running 10000 simulations.:  75%|███████▍  | 7468/10000 [00:43<00:15, 164.69it/s]Running 10000 simulations.:  75%|███████▍  | 7485/10000 [00:43<00:15, 164.62it/s]Running 10000 simulations.:  75%|███████▌  | 7502/10000 [00:43<00:15, 164.89it/s]Running 10000 simulations.:  75%|███████▌  | 7519/10000 [00:44<00:15, 165.24it/s]Running 10000 simulations.:  75%|███████▌  | 7536/10000 [00:44<00:14, 165.16it/s]Running 10000 simulations.:  76%|███████▌  | 7553/10000 [00:44<00:14, 164.70it/s]Running 10000 simulations.:  76%|███████▌  | 7570/10000 [00:44<00:14, 164.67it/s]Running 10000 simulations.:  76%|███████▌  | 7587/10000 [00:44<00:14, 164.66it/s]Running 10000 simulations.:  76%|███████▌  | 7604/10000 [00:44<00:14, 164.38it/s]Running 10000 simulations.:  76%|███████▌  | 7621/10000 [00:44<00:14, 164.49it/s]Running 10000 simulations.:  76%|███████▋  | 7638/10000 [00:44<00:14, 164.37it/s]Running 10000 simulations.:  77%|███████▋  | 7655/10000 [00:44<00:14, 164.64it/s]Running 10000 simulations.:  77%|███████▋  | 7672/10000 [00:44<00:14, 164.30it/s]Running 10000 simulations.:  77%|███████▋  | 7689/10000 [00:45<00:14, 164.34it/s]Running 10000 simulations.:  77%|███████▋  | 7706/10000 [00:45<00:13, 164.56it/s]Running 10000 simulations.:  77%|███████▋  | 7723/10000 [00:45<00:13, 164.82it/s]Running 10000 simulations.:  77%|███████▋  | 7740/10000 [00:45<00:13, 164.38it/s]Running 10000 simulations.:  78%|███████▊  | 7757/10000 [00:45<00:13, 164.31it/s]Running 10000 simulations.:  78%|███████▊  | 7774/10000 [00:45<00:13, 164.30it/s]Running 10000 simulations.:  78%|███████▊  | 7791/10000 [00:45<00:13, 164.42it/s]Running 10000 simulations.:  78%|███████▊  | 7808/10000 [00:45<00:13, 164.31it/s]Running 10000 simulations.:  78%|███████▊  | 7825/10000 [00:45<00:13, 164.62it/s]Running 10000 simulations.:  78%|███████▊  | 7842/10000 [00:45<00:13, 164.46it/s]Running 10000 simulations.:  79%|███████▊  | 7859/10000 [00:46<00:12, 165.01it/s]Running 10000 simulations.:  79%|███████▉  | 7876/10000 [00:46<00:12, 164.87it/s]Running 10000 simulations.:  79%|███████▉  | 7893/10000 [00:46<00:12, 164.45it/s]Running 10000 simulations.:  79%|███████▉  | 7910/10000 [00:46<00:12, 164.61it/s]Running 10000 simulations.:  79%|███████▉  | 7927/10000 [00:46<00:12, 164.84it/s]Running 10000 simulations.:  79%|███████▉  | 7944/10000 [00:46<00:12, 164.82it/s]Running 10000 simulations.:  80%|███████▉  | 7961/10000 [00:46<00:12, 164.69it/s]Running 10000 simulations.:  80%|███████▉  | 7978/10000 [00:46<00:12, 164.79it/s]Running 10000 simulations.:  80%|███████▉  | 7995/10000 [00:46<00:12, 164.68it/s]Running 10000 simulations.:  80%|████████  | 8012/10000 [00:47<00:12, 164.40it/s]Running 10000 simulations.:  80%|████████  | 8029/10000 [00:47<00:11, 164.37it/s]Running 10000 simulations.:  80%|████████  | 8046/10000 [00:47<00:11, 164.31it/s]Running 10000 simulations.:  81%|████████  | 8063/10000 [00:47<00:11, 164.03it/s]Running 10000 simulations.:  81%|████████  | 8080/10000 [00:47<00:11, 164.58it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:47<00:11, 164.32it/s]Running 10000 simulations.:  81%|████████  | 8114/10000 [00:47<00:11, 164.26it/s]Running 10000 simulations.:  81%|████████▏ | 8131/10000 [00:47<00:11, 164.48it/s]Running 10000 simulations.:  81%|████████▏ | 8148/10000 [00:47<00:11, 164.50it/s]Running 10000 simulations.:  82%|████████▏ | 8165/10000 [00:47<00:11, 164.30it/s]Running 10000 simulations.:  82%|████████▏ | 8182/10000 [00:48<00:11, 164.49it/s]Running 10000 simulations.:  82%|████████▏ | 8199/10000 [00:48<00:10, 164.48it/s]Running 10000 simulations.:  82%|████████▏ | 8216/10000 [00:48<00:10, 164.47it/s]Running 10000 simulations.:  82%|████████▏ | 8233/10000 [00:48<00:10, 164.52it/s]Running 10000 simulations.:  82%|████████▎ | 8250/10000 [00:48<00:10, 164.33it/s]Running 10000 simulations.:  83%|████████▎ | 8267/10000 [00:48<00:10, 164.71it/s]Running 10000 simulations.:  83%|████████▎ | 8284/10000 [00:48<00:10, 164.78it/s]Running 10000 simulations.:  83%|████████▎ | 8301/10000 [00:48<00:10, 164.64it/s]Running 10000 simulations.:  83%|████████▎ | 8318/10000 [00:48<00:10, 164.89it/s]Running 10000 simulations.:  83%|████████▎ | 8335/10000 [00:48<00:10, 165.86it/s]Running 10000 simulations.:  84%|████████▎ | 8354/10000 [00:49<00:09, 171.36it/s]Running 10000 simulations.:  84%|████████▎ | 8372/10000 [00:49<00:09, 171.56it/s]Running 10000 simulations.:  84%|████████▍ | 8390/10000 [00:49<00:09, 169.48it/s]Running 10000 simulations.:  84%|████████▍ | 8407/10000 [00:49<00:09, 167.89it/s]Running 10000 simulations.:  84%|████████▍ | 8424/10000 [00:49<00:09, 166.93it/s]Running 10000 simulations.:  84%|████████▍ | 8441/10000 [00:49<00:09, 166.35it/s]Running 10000 simulations.:  85%|████████▍ | 8458/10000 [00:49<00:09, 166.04it/s]Running 10000 simulations.:  85%|████████▍ | 8475/10000 [00:49<00:09, 165.69it/s]Running 10000 simulations.:  85%|████████▍ | 8492/10000 [00:49<00:09, 165.12it/s]Running 10000 simulations.:  85%|████████▌ | 8509/10000 [00:50<00:09, 164.75it/s]Running 10000 simulations.:  85%|████████▌ | 8526/10000 [00:50<00:08, 164.49it/s]Running 10000 simulations.:  85%|████████▌ | 8543/10000 [00:50<00:08, 164.01it/s]Running 10000 simulations.:  86%|████████▌ | 8560/10000 [00:50<00:08, 164.27it/s]Running 10000 simulations.:  86%|████████▌ | 8577/10000 [00:50<00:08, 164.36it/s]Running 10000 simulations.:  86%|████████▌ | 8594/10000 [00:50<00:08, 164.67it/s]Running 10000 simulations.:  86%|████████▌ | 8611/10000 [00:50<00:08, 165.00it/s]Running 10000 simulations.:  86%|████████▋ | 8628/10000 [00:50<00:08, 164.80it/s]Running 10000 simulations.:  86%|████████▋ | 8645/10000 [00:50<00:08, 165.15it/s]Running 10000 simulations.:  87%|████████▋ | 8662/10000 [00:50<00:08, 165.22it/s]Running 10000 simulations.:  87%|████████▋ | 8679/10000 [00:51<00:07, 165.26it/s]Running 10000 simulations.:  87%|████████▋ | 8696/10000 [00:51<00:07, 165.44it/s]Running 10000 simulations.:  87%|████████▋ | 8713/10000 [00:51<00:07, 165.47it/s]Running 10000 simulations.:  87%|████████▋ | 8730/10000 [00:51<00:07, 165.68it/s]Running 10000 simulations.:  87%|████████▋ | 8747/10000 [00:51<00:07, 165.36it/s]Running 10000 simulations.:  88%|████████▊ | 8764/10000 [00:51<00:07, 165.70it/s]Running 10000 simulations.:  88%|████████▊ | 8781/10000 [00:51<00:07, 165.82it/s]Running 10000 simulations.:  88%|████████▊ | 8798/10000 [00:51<00:07, 165.75it/s]Running 10000 simulations.:  88%|████████▊ | 8815/10000 [00:51<00:07, 165.74it/s]Running 10000 simulations.:  88%|████████▊ | 8832/10000 [00:51<00:07, 165.53it/s]Running 10000 simulations.:  88%|████████▊ | 8849/10000 [00:52<00:06, 165.32it/s]Running 10000 simulations.:  89%|████████▊ | 8866/10000 [00:52<00:06, 165.52it/s]Running 10000 simulations.:  89%|████████▉ | 8883/10000 [00:52<00:06, 165.50it/s]Running 10000 simulations.:  89%|████████▉ | 8900/10000 [00:52<00:06, 165.22it/s]Running 10000 simulations.:  89%|████████▉ | 8917/10000 [00:52<00:06, 165.29it/s]Running 10000 simulations.:  89%|████████▉ | 8934/10000 [00:52<00:06, 165.37it/s]Running 10000 simulations.:  90%|████████▉ | 8951/10000 [00:52<00:06, 165.49it/s]Running 10000 simulations.:  90%|████████▉ | 8968/10000 [00:52<00:06, 165.65it/s]Running 10000 simulations.:  90%|████████▉ | 8985/10000 [00:52<00:06, 165.32it/s]Running 10000 simulations.:  90%|█████████ | 9002/10000 [00:53<00:06, 165.29it/s]Running 10000 simulations.:  90%|█████████ | 9019/10000 [00:53<00:05, 165.54it/s]Running 10000 simulations.:  90%|█████████ | 9036/10000 [00:53<00:05, 165.59it/s]Running 10000 simulations.:  91%|█████████ | 9053/10000 [00:53<00:05, 165.48it/s]Running 10000 simulations.:  91%|█████████ | 9070/10000 [00:53<00:05, 165.19it/s]Running 10000 simulations.:  91%|█████████ | 9087/10000 [00:53<00:05, 165.23it/s]Running 10000 simulations.:  91%|█████████ | 9104/10000 [00:53<00:05, 165.27it/s]Running 10000 simulations.:  91%|█████████ | 9121/10000 [00:53<00:05, 165.50it/s]Running 10000 simulations.:  91%|█████████▏| 9138/10000 [00:53<00:05, 165.33it/s]Running 10000 simulations.:  92%|█████████▏| 9155/10000 [00:53<00:05, 165.47it/s]Running 10000 simulations.:  92%|█████████▏| 9172/10000 [00:54<00:04, 165.82it/s]Running 10000 simulations.:  92%|█████████▏| 9189/10000 [00:54<00:04, 165.77it/s]Running 10000 simulations.:  92%|█████████▏| 9206/10000 [00:54<00:04, 165.50it/s]Running 10000 simulations.:  92%|█████████▏| 9223/10000 [00:54<00:04, 165.61it/s]Running 10000 simulations.:  92%|█████████▏| 9240/10000 [00:54<00:04, 165.63it/s]Running 10000 simulations.:  93%|█████████▎| 9257/10000 [00:54<00:04, 165.48it/s]Running 10000 simulations.:  93%|█████████▎| 9274/10000 [00:54<00:04, 165.40it/s]Running 10000 simulations.:  93%|█████████▎| 9291/10000 [00:54<00:04, 165.22it/s]Running 10000 simulations.:  93%|█████████▎| 9308/10000 [00:54<00:04, 165.35it/s]Running 10000 simulations.:  93%|█████████▎| 9325/10000 [00:54<00:04, 164.96it/s]Running 10000 simulations.:  93%|█████████▎| 9342/10000 [00:55<00:03, 165.27it/s]Running 10000 simulations.:  94%|█████████▎| 9359/10000 [00:55<00:03, 165.30it/s]Running 10000 simulations.:  94%|█████████▍| 9376/10000 [00:55<00:03, 165.37it/s]Running 10000 simulations.:  94%|█████████▍| 9393/10000 [00:55<00:03, 165.38it/s]Running 10000 simulations.:  94%|█████████▍| 9410/10000 [00:55<00:03, 165.37it/s]Running 10000 simulations.:  94%|█████████▍| 9427/10000 [00:55<00:03, 165.10it/s]Running 10000 simulations.:  94%|█████████▍| 9444/10000 [00:55<00:03, 165.31it/s]Running 10000 simulations.:  95%|█████████▍| 9461/10000 [00:55<00:03, 165.32it/s]Running 10000 simulations.:  95%|█████████▍| 9478/10000 [00:55<00:03, 165.39it/s]Running 10000 simulations.:  95%|█████████▍| 9495/10000 [00:55<00:03, 165.55it/s]Running 10000 simulations.:  95%|█████████▌| 9512/10000 [00:56<00:02, 165.77it/s]Running 10000 simulations.:  95%|█████████▌| 9529/10000 [00:56<00:02, 165.76it/s]Running 10000 simulations.:  95%|█████████▌| 9546/10000 [00:56<00:02, 165.80it/s]Running 10000 simulations.:  96%|█████████▌| 9563/10000 [00:56<00:02, 165.39it/s]Running 10000 simulations.:  96%|█████████▌| 9580/10000 [00:56<00:02, 165.27it/s]Running 10000 simulations.:  96%|█████████▌| 9597/10000 [00:56<00:02, 165.74it/s]Running 10000 simulations.:  96%|█████████▌| 9614/10000 [00:56<00:02, 165.70it/s]Running 10000 simulations.:  96%|█████████▋| 9631/10000 [00:56<00:02, 165.82it/s]Running 10000 simulations.:  96%|█████████▋| 9648/10000 [00:56<00:02, 165.76it/s]Running 10000 simulations.:  97%|█████████▋| 9665/10000 [00:57<00:02, 165.77it/s]Running 10000 simulations.:  97%|█████████▋| 9682/10000 [00:57<00:01, 165.50it/s]Running 10000 simulations.:  97%|█████████▋| 9699/10000 [00:57<00:01, 165.58it/s]Running 10000 simulations.:  97%|█████████▋| 9716/10000 [00:57<00:01, 165.41it/s]Running 10000 simulations.:  97%|█████████▋| 9733/10000 [00:57<00:01, 165.24it/s]Running 10000 simulations.:  98%|█████████▊| 9750/10000 [00:57<00:01, 165.26it/s]Running 10000 simulations.:  98%|█████████▊| 9767/10000 [00:57<00:01, 165.63it/s]Running 10000 simulations.:  98%|█████████▊| 9784/10000 [00:57<00:01, 165.42it/s]Running 10000 simulations.:  98%|█████████▊| 9801/10000 [00:57<00:01, 165.59it/s]Running 10000 simulations.:  98%|█████████▊| 9818/10000 [00:57<00:01, 165.22it/s]Running 10000 simulations.:  98%|█████████▊| 9835/10000 [00:58<00:00, 165.06it/s]Running 10000 simulations.:  99%|█████████▊| 9852/10000 [00:58<00:00, 165.43it/s]Running 10000 simulations.:  99%|█████████▊| 9869/10000 [00:58<00:00, 165.51it/s]Running 10000 simulations.:  99%|█████████▉| 9886/10000 [00:58<00:00, 165.35it/s]Running 10000 simulations.:  99%|█████████▉| 9903/10000 [00:58<00:00, 165.53it/s]Running 10000 simulations.:  99%|█████████▉| 9920/10000 [00:58<00:00, 165.51it/s]Running 10000 simulations.:  99%|█████████▉| 9937/10000 [00:58<00:00, 165.62it/s]Running 10000 simulations.: 100%|█████████▉| 9954/10000 [00:58<00:00, 165.49it/s]Running 10000 simulations.: 100%|█████████▉| 9971/10000 [00:58<00:00, 165.53it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [00:58<00:00, 165.59it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:59<00:00, 169.39it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31304/50000 [00:00<00:00, 303725.70it/s]Drawing 50000 posterior samples: 54887it [00:00, 304231.33it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  28%|██▊       | 14119/50000 [00:00<00:00, 134469.70it/s]Drawing 50000 posterior samples:  56%|█████▋    | 28250/50000 [00:00<00:00, 134828.45it/s]Drawing 50000 posterior samples:  85%|████████▍ | 42368/50000 [00:00<00:00, 134936.76it/s]Drawing 50000 posterior samples: 52731it [00:00, 134523.35it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  57%|█████▋    | 28615/50000 [00:00<00:00, 275672.95it/s]Drawing 50000 posterior samples: 50099it [00:00, 274696.47it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36707/50000 [00:00<00:00, 352794.71it/s]Drawing 50000 posterior samples: 55048it [00:00, 350403.76it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  56%|█████▌    | 27770/50000 [00:00<00:00, 268464.69it/s]Drawing 50000 posterior samples: 55446it [00:00, 267456.22it/s]                           Drawing 50000 posterior samples: 55446it [00:00, 266214.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  42%|████▏     | 20847/50000 [00:00<00:00, 200622.84it/s]Drawing 50000 posterior samples:  84%|████████▎ | 41776/50000 [00:00<00:00, 200937.41it/s]Drawing 50000 posterior samples: 52173it [00:00, 200709.38it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████   | 35272/50000 [00:00<00:00, 339350.37it/s]Drawing 50000 posterior samples: 53018it [00:00, 338878.26it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  28%|██▊       | 14124/50000 [00:00<00:00, 134402.87it/s]Drawing 50000 posterior samples:  57%|█████▋    | 28285/50000 [00:00<00:00, 134706.07it/s]Drawing 50000 posterior samples:  85%|████████▍ | 42350/50000 [00:00<00:00, 134640.94it/s]Drawing 50000 posterior samples: 52812it [00:00, 134484.60it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32092/50000 [00:00<00:00, 304701.25it/s]Drawing 50000 posterior samples: 56216it [00:00, 304763.12it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  18%|█▊        | 9054/50000 [00:00<00:00, 86824.14it/s]Drawing 50000 posterior samples:  36%|███▋      | 18187/50000 [00:00<00:00, 87027.96it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27278/50000 [00:00<00:00, 86928.61it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36404/50000 [00:00<00:00, 87059.30it/s]Drawing 50000 posterior samples:  91%|█████████ | 45430/50000 [00:00<00:00, 87128.46it/s]Drawing 50000 posterior samples: 52164it [00:00, 86991.87it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  12%|█▏        | 5987/50000 [00:00<00:00, 58207.23it/s]Drawing 50000 posterior samples:  24%|██▍       | 11932/50000 [00:00<00:00, 58230.82it/s]Drawing 50000 posterior samples:  36%|███▌      | 17871/50000 [00:00<00:00, 58125.81it/s]Drawing 50000 posterior samples:  48%|████▊     | 23780/50000 [00:00<00:00, 58024.03it/s]Drawing 50000 posterior samples:  59%|█████▉    | 29623/50000 [00:00<00:00, 57394.96it/s]Drawing 50000 posterior samples:  71%|███████   | 35495/50000 [00:00<00:00, 57106.17it/s]Drawing 50000 posterior samples:  83%|████████▎ | 41406/50000 [00:00<00:00, 57042.39it/s]Drawing 50000 posterior samples:  95%|█████████▍| 47303/50000 [00:00<00:00, 56994.29it/s]Drawing 50000 posterior samples: 50227it [00:00, 57242.60it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  45%|████▍     | 22492/50000 [00:00<00:00, 217712.44it/s]Drawing 50000 posterior samples:  90%|████████▉ | 44893/50000 [00:00<00:00, 216941.65it/s]Drawing 50000 posterior samples: 50574it [00:00, 216000.59it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  61%|██████    | 30451/50000 [00:00<00:00, 288421.98it/s]Drawing 50000 posterior samples: 53161it [00:00, 288250.26it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36684/50000 [00:00<00:00, 353149.02it/s]Drawing 50000 posterior samples: 55120it [00:00, 352996.38it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26552/50000 [00:00<00:00, 260724.48it/s]Drawing 50000 posterior samples: 53311it [00:00, 260586.29it/s]                           Drawing 50000 posterior samples: 53311it [00:00, 259926.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  32%|███▏      | 15833/50000 [00:00<00:00, 152076.39it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31703/50000 [00:00<00:00, 152979.22it/s]Drawing 50000 posterior samples:  95%|█████████▌| 47623/50000 [00:00<00:00, 153647.29it/s]Drawing 50000 posterior samples: 51558it [00:00, 153748.97it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33493/50000 [00:00<00:00, 320348.41it/s]Drawing 50000 posterior samples: 50333it [00:00, 319180.28it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31469/50000 [00:00<00:00, 300182.52it/s]Drawing 50000 posterior samples: 55168it [00:00, 300584.00it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27513/50000 [00:00<00:00, 264848.39it/s]Drawing 50000 posterior samples: 55004it [00:00, 264266.69it/s]                           Drawing 50000 posterior samples: 55004it [00:00, 263293.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▎   | 31825/50000 [00:00<00:00, 305282.20it/s]Drawing 50000 posterior samples: 55696it [00:00, 306008.88it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  59%|█████▉    | 29545/50000 [00:00<00:00, 286237.29it/s]Drawing 50000 posterior samples: 51727it [00:00, 284856.99it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  34%|███▍      | 17035/50000 [00:00<00:00, 164723.87it/s]Drawing 50000 posterior samples:  68%|██████▊   | 34093/50000 [00:00<00:00, 164769.70it/s]Drawing 50000 posterior samples: 51299it [00:00, 165089.29it/s]                           Drawing 50000 posterior samples: 51299it [00:00, 164904.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  61%|██████    | 30466/50000 [00:00<00:00, 290570.63it/s]Drawing 50000 posterior samples: 53433it [00:00, 290799.52it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  19%|█▊        | 9306/50000 [00:00<00:00, 90124.69it/s]Drawing 50000 posterior samples:  38%|███▊      | 18846/50000 [00:00<00:00, 90842.01it/s]Drawing 50000 posterior samples:  57%|█████▋    | 28279/50000 [00:00<00:00, 91330.50it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37666/50000 [00:00<00:00, 91377.04it/s]Drawing 50000 posterior samples:  94%|█████████▍| 47070/50000 [00:00<00:00, 91142.27it/s]Drawing 50000 posterior samples: 51843it [00:00, 91479.31it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  65%|██████▍   | 32455/50000 [00:00<00:00, 314478.57it/s]Drawing 50000 posterior samples: 56885it [00:00, 313567.22it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32172/50000 [00:00<00:00, 308189.31it/s]Drawing 50000 posterior samples: 56238it [00:00, 308596.28it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   9%|▉         | 4502/50000 [00:00<00:01, 43333.52it/s]Drawing 50000 posterior samples:  18%|█▊        | 9032/50000 [00:00<00:00, 43436.60it/s]Drawing 50000 posterior samples:  27%|██▋       | 13628/50000 [00:00<00:00, 43771.33it/s]Drawing 50000 posterior samples:  36%|███▌      | 18050/50000 [00:00<00:00, 43504.89it/s]Drawing 50000 posterior samples:  45%|████▌     | 22534/50000 [00:00<00:00, 43643.03it/s]Drawing 50000 posterior samples:  54%|█████▍    | 26944/50000 [00:00<00:00, 43524.36it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31529/50000 [00:00<00:00, 43997.67it/s]Drawing 50000 posterior samples:  72%|███████▏  | 35918/50000 [00:00<00:00, 43698.48it/s]Drawing 50000 posterior samples:  81%|████████  | 40376/50000 [00:00<00:00, 43706.18it/s]Drawing 50000 posterior samples:  90%|████████▉ | 44781/50000 [00:01<00:00, 43597.80it/s]Drawing 50000 posterior samples: 50405it [00:01, 44667.76it/s]                           Drawing 50000 posterior samples: 50405it [00:01, 44054.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  12%|█▏        | 5788/50000 [00:00<00:00, 56093.46it/s]Drawing 50000 posterior samples:  23%|██▎       | 11435/50000 [00:00<00:00, 55542.80it/s]Drawing 50000 posterior samples:  35%|███▍      | 17263/50000 [00:00<00:00, 55636.26it/s]Drawing 50000 posterior samples:  47%|████▋     | 23252/50000 [00:00<00:00, 56128.53it/s]Drawing 50000 posterior samples:  58%|█████▊    | 29203/50000 [00:00<00:00, 56391.37it/s]Drawing 50000 posterior samples:  70%|███████   | 35104/50000 [00:00<00:00, 56647.32it/s]Drawing 50000 posterior samples:  82%|████████▏ | 40985/50000 [00:00<00:00, 56550.55it/s]Drawing 50000 posterior samples:  94%|█████████▎| 46844/50000 [00:00<00:00, 56538.45it/s]Drawing 50000 posterior samples: 51201it [00:00, 56317.77it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18607/50000 [00:00<00:00, 181800.30it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37553/50000 [00:00<00:00, 181941.91it/s]Drawing 50000 posterior samples: 51794it [00:00, 181991.64it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36740/50000 [00:00<00:00, 349151.54it/s]Drawing 50000 posterior samples: 55073it [00:00, 347478.98it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  62%|██████▏   | 30920/50000 [00:00<00:00, 300342.47it/s]Drawing 50000 posterior samples: 54121it [00:00, 300076.31it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  27%|██▋       | 13748/50000 [00:00<00:00, 131653.45it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27499/50000 [00:00<00:00, 131987.29it/s]Drawing 50000 posterior samples:  82%|████████▏ | 41172/50000 [00:00<00:00, 132131.24it/s]Drawing 50000 posterior samples: 51406it [00:00, 132083.06it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36550/50000 [00:00<00:00, 348704.85it/s]Drawing 50000 posterior samples: 54804it [00:00, 347107.48it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36563/50000 [00:00<00:00, 351581.51it/s]Drawing 50000 posterior samples: 54923it [00:00, 352332.44it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  33%|███▎      | 16371/50000 [00:00<00:00, 157832.32it/s]Drawing 50000 posterior samples:  65%|██████▌   | 32610/50000 [00:00<00:00, 157074.31it/s]Drawing 50000 posterior samples:  98%|█████████▊| 48823/50000 [00:00<00:00, 157518.06it/s]Drawing 50000 posterior samples: 52797it [00:00, 156727.47it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  14%|█▍        | 6896/50000 [00:00<00:00, 66499.41it/s]Drawing 50000 posterior samples:  28%|██▊       | 13848/50000 [00:00<00:00, 66556.11it/s]Drawing 50000 posterior samples:  42%|████▏     | 20950/50000 [00:00<00:00, 67333.56it/s]Drawing 50000 posterior samples:  56%|█████▌    | 27908/50000 [00:00<00:00, 67552.47it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34792/50000 [00:00<00:00, 67104.21it/s]Drawing 50000 posterior samples:  84%|████████▎ | 41829/50000 [00:00<00:00, 67482.78it/s]Drawing 50000 posterior samples:  97%|█████████▋| 48741/50000 [00:00<00:00, 67434.01it/s]Drawing 50000 posterior samples: 50525it [00:00, 67489.47it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████   | 35271/50000 [00:00<00:00, 337092.97it/s]Drawing 50000 posterior samples: 52859it [00:00, 337180.63it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  27%|██▋       | 13520/50000 [00:00<00:00, 132190.91it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27022/50000 [00:00<00:00, 131939.68it/s]Drawing 50000 posterior samples:  81%|████████▏ | 40669/50000 [00:00<00:00, 131444.31it/s]Drawing 50000 posterior samples: 50996it [00:00, 131588.88it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36081/50000 [00:00<00:00, 347612.94it/s]Drawing 50000 posterior samples: 54111it [00:00, 347568.92it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  18%|█▊        | 9034/50000 [00:00<00:00, 86926.89it/s]Drawing 50000 posterior samples:  36%|███▌      | 18057/50000 [00:00<00:00, 87100.05it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27256/50000 [00:00<00:00, 87873.21it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36356/50000 [00:00<00:00, 88130.81it/s]Drawing 50000 posterior samples:  91%|█████████ | 45398/50000 [00:00<00:00, 88020.42it/s]Drawing 50000 posterior samples: 52176it [00:00, 88118.74it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  11%|█         | 5572/50000 [00:00<00:00, 54251.59it/s]Drawing 50000 posterior samples:  22%|██▏       | 11035/50000 [00:00<00:00, 53870.59it/s]Drawing 50000 posterior samples:  33%|███▎      | 16483/50000 [00:00<00:00, 53500.76it/s]Drawing 50000 posterior samples:  44%|████▍     | 21930/50000 [00:00<00:00, 53334.66it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27360/50000 [00:00<00:00, 53113.68it/s]Drawing 50000 posterior samples:  66%|██████▌   | 32780/50000 [00:00<00:00, 52734.51it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38324/50000 [00:00<00:00, 52905.62it/s]Drawing 50000 posterior samples:  88%|████████▊ | 43790/50000 [00:00<00:00, 52998.67it/s]Drawing 50000 posterior samples:  98%|█████████▊| 49236/50000 [00:00<00:00, 53049.75it/s]Drawing 50000 posterior samples: 50625it [00:00, 53014.98it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  44%|████▍     | 22054/50000 [00:00<00:00, 212047.78it/s]Drawing 50000 posterior samples:  88%|████████▊ | 44071/50000 [00:00<00:00, 212082.87it/s]Drawing 50000 posterior samples: 55185it [00:00, 212444.82it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33426/50000 [00:00<00:00, 320329.21it/s]Drawing 50000 posterior samples: 50054it [00:00, 318379.05it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36491/50000 [00:00<00:00, 354901.22it/s]Drawing 50000 posterior samples: 54645it [00:00, 351027.43it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36527/50000 [00:00<00:00, 349846.99it/s]Drawing 50000 posterior samples: 54816it [00:00, 350280.97it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  29%|██▉       | 14514/50000 [00:00<00:00, 139459.42it/s]Drawing 50000 posterior samples:  58%|█████▊    | 28995/50000 [00:00<00:00, 139537.90it/s]Drawing 50000 posterior samples:  87%|████████▋ | 43374/50000 [00:00<00:00, 139102.12it/s]Drawing 50000 posterior samples: 50678it [00:00, 139389.95it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36451/50000 [00:00<00:00, 351669.54it/s]Drawing 50000 posterior samples: 54676it [00:00, 349720.95it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29934/50000 [00:00<00:00, 286301.33it/s]Drawing 50000 posterior samples: 52581it [00:00, 286893.78it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36758/50000 [00:00<00:00, 351148.54it/s]Drawing 50000 posterior samples: 55010it [00:00, 348774.02it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31586/50000 [00:00<00:00, 305468.28it/s]Drawing 50000 posterior samples: 55182it [00:00, 304181.37it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36483/50000 [00:00<00:00, 349650.72it/s]Drawing 50000 posterior samples: 54704it [00:00, 349073.87it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  20%|██        | 10192/50000 [00:00<00:00, 97545.29it/s]Drawing 50000 posterior samples:  41%|████      | 20347/50000 [00:00<00:00, 97215.68it/s]Drawing 50000 posterior samples:  61%|██████    | 30447/50000 [00:00<00:00, 96936.03it/s]Drawing 50000 posterior samples:  81%|████████  | 40622/50000 [00:00<00:00, 97156.15it/s]Drawing 50000 posterior samples: 50737it [00:00, 97074.06it/s]                           Drawing 50000 posterior samples: 50737it [00:00, 96879.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27662/50000 [00:00<00:00, 267637.13it/s]Drawing 50000 posterior samples: 55582it [00:00, 268507.41it/s]                           Drawing 50000 posterior samples: 55582it [00:00, 268412.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  19%|█▉        | 9509/50000 [00:00<00:00, 91945.66it/s]Drawing 50000 posterior samples:  37%|███▋      | 18735/50000 [00:00<00:00, 90775.78it/s]Drawing 50000 posterior samples:  56%|█████▌    | 28000/50000 [00:00<00:00, 90313.84it/s]Drawing 50000 posterior samples:  75%|███████▍  | 37282/50000 [00:00<00:00, 89829.42it/s]Drawing 50000 posterior samples:  93%|█████████▎| 46656/50000 [00:00<00:00, 89661.07it/s]Drawing 50000 posterior samples: 51324it [00:00, 89271.45it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36091/50000 [00:00<00:00, 342763.33it/s]Drawing 50000 posterior samples: 54137it [00:00, 341460.35it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 31911/50000 [00:00<00:00, 306794.07it/s]Drawing 50000 posterior samples: 55809it [00:00, 305634.43it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   6%|▌         | 2872/50000 [00:00<00:01, 27644.51it/s]Drawing 50000 posterior samples:  12%|█▏        | 5800/50000 [00:00<00:01, 27796.53it/s]Drawing 50000 posterior samples:  17%|█▋        | 8714/50000 [00:00<00:01, 27916.11it/s]Drawing 50000 posterior samples:  23%|██▎       | 11697/50000 [00:00<00:01, 28136.37it/s]Drawing 50000 posterior samples:  29%|██▉       | 14650/50000 [00:00<00:01, 28271.86it/s]Drawing 50000 posterior samples:  35%|███▌      | 17639/50000 [00:00<00:01, 28469.74it/s]Drawing 50000 posterior samples:  41%|████      | 20546/50000 [00:00<00:01, 28380.73it/s]Drawing 50000 posterior samples:  47%|████▋     | 23540/50000 [00:00<00:00, 28577.59it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26473/50000 [00:00<00:00, 28511.46it/s]Drawing 50000 posterior samples:  59%|█████▊    | 29360/50000 [00:01<00:00, 28234.96it/s]Drawing 50000 posterior samples:  65%|██████▍   | 32377/50000 [00:01<00:00, 28506.85it/s]Drawing 50000 posterior samples:  71%|███████   | 35360/50000 [00:01<00:00, 28556.08it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38258/50000 [00:01<00:00, 28309.47it/s]Drawing 50000 posterior samples:  82%|████████▏ | 41148/50000 [00:01<00:00, 28210.14it/s]Drawing 50000 posterior samples:  88%|████████▊ | 44095/50000 [00:01<00:00, 28206.80it/s]Drawing 50000 posterior samples:  94%|█████████▍| 47031/50000 [00:01<00:00, 28183.30it/s]Drawing 50000 posterior samples: 100%|█████████▉| 49949/50000 [00:01<00:00, 28439.50it/s]Drawing 50000 posterior samples: 50701it [00:01, 28390.23it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  11%|█         | 5268/50000 [00:00<00:00, 51020.25it/s]Drawing 50000 posterior samples:  21%|██        | 10583/50000 [00:00<00:00, 51067.96it/s]Drawing 50000 posterior samples:  32%|███▏      | 15952/50000 [00:00<00:00, 51115.03it/s]Drawing 50000 posterior samples:  42%|████▏     | 21227/50000 [00:00<00:00, 51067.76it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26496/50000 [00:00<00:00, 51142.22it/s]Drawing 50000 posterior samples:  64%|██████▍   | 31885/50000 [00:00<00:00, 51277.15it/s]Drawing 50000 posterior samples:  74%|███████▍  | 37200/50000 [00:00<00:00, 51391.15it/s]Drawing 50000 posterior samples:  85%|████████▌ | 42534/50000 [00:00<00:00, 51210.78it/s]Drawing 50000 posterior samples:  96%|█████████▌| 47895/50000 [00:00<00:00, 51197.79it/s]Drawing 50000 posterior samples: 50565it [00:00, 51195.07it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  25%|██▍       | 12258/50000 [00:00<00:00, 119139.69it/s]Drawing 50000 posterior samples:  49%|████▉     | 24543/50000 [00:00<00:00, 118825.12it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36841/50000 [00:00<00:00, 118708.24it/s]Drawing 50000 posterior samples:  98%|█████████▊| 49243/50000 [00:00<00:00, 119164.32it/s]Drawing 50000 posterior samples: 52357it [00:00, 118954.49it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36576/50000 [00:00<00:00, 350245.12it/s]Drawing 50000 posterior samples: 54885it [00:00, 348804.02it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▍  | 37436/50000 [00:00<00:00, 359104.23it/s]Drawing 50000 posterior samples: 56201it [00:00, 357169.60it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 35799/50000 [00:00<00:00, 347823.41it/s]Drawing 50000 posterior samples: 53756it [00:00, 345341.55it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39667/50000 [00:00<00:00, 375633.20it/s]Drawing 50000 posterior samples: 59527it [00:00, 332473.55it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████   | 35601/50000 [00:00<00:00, 342941.24it/s]Drawing 50000 posterior samples: 53477it [00:00, 343792.99it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31272/50000 [00:00<00:00, 300437.89it/s]Drawing 50000 posterior samples: 54832it [00:00, 301275.25it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  56%|█████▌    | 27891/50000 [00:00<00:00, 266414.94it/s]Drawing 50000 posterior samples: 55822it [00:00, 266196.78it/s]                           Drawing 50000 posterior samples: 55822it [00:00, 265458.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37669/50000 [00:00<00:00, 361162.52it/s]Drawing 50000 posterior samples: 56513it [00:00, 360129.18it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████   | 35587/50000 [00:00<00:00, 342770.17it/s]Drawing 50000 posterior samples: 53390it [00:00, 341868.14it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39998/50000 [00:00<00:00, 385606.22it/s]Drawing 50000 posterior samples: 59996it [00:00, 385458.93it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  76%|███████▌  | 37865/50000 [00:00<00:00, 360967.33it/s]Drawing 50000 posterior samples: 56809it [00:00, 359339.18it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  68%|██████▊   | 34154/50000 [00:00<00:00, 325778.41it/s]Drawing 50000 posterior samples: 51181it [00:00, 324486.14it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37584/50000 [00:00<00:00, 362683.01it/s]Drawing 50000 posterior samples: 56406it [00:00, 362019.78it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 387787.88it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 385775.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39786/50000 [00:00<00:00, 380721.86it/s]Drawing 50000 posterior samples: 59677it [00:00, 380338.58it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  69%|██████▉   | 34477/50000 [00:00<00:00, 335137.22it/s]Drawing 50000 posterior samples: 51762it [00:00, 333506.76it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  68%|██████▊   | 33856/50000 [00:00<00:00, 326277.93it/s]Drawing 50000 posterior samples: 50767it [00:00, 326385.44it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39674/50000 [00:00<00:00, 381604.66it/s]Drawing 50000 posterior samples: 59500it [00:00, 381831.84it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39983/50000 [00:00<00:00, 386336.29it/s]Drawing 50000 posterior samples: 59959it [00:00, 382666.14it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36179/50000 [00:00<00:00, 349497.96it/s]Drawing 50000 posterior samples: 54288it [00:00, 347458.05it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▍  | 37441/50000 [00:00<00:00, 361206.67it/s]Drawing 50000 posterior samples: 56193it [00:00, 359912.54it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 385100.61it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 383652.50it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  78%|███████▊  | 38966/50000 [00:00<00:00, 374545.67it/s]Drawing 50000 posterior samples: 58466it [00:00, 373484.85it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 387962.74it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 385958.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  76%|███████▌  | 38124/50000 [00:00<00:00, 366789.34it/s]Drawing 50000 posterior samples: 57193it [00:00, 366270.49it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 386083.41it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 384174.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▍  | 37442/50000 [00:00<00:00, 357349.90it/s]Drawing 50000 posterior samples: 56180it [00:00, 356673.51it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27409/50000 [00:00<00:00, 263802.45it/s]Drawing 50000 posterior samples: 54768it [00:00, 263998.18it/s]                           Drawing 50000 posterior samples: 54768it [00:00, 263524.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  68%|██████▊   | 33837/50000 [00:00<00:00, 325165.40it/s]Drawing 50000 posterior samples: 50733it [00:00, 324053.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39997/50000 [00:00<00:00, 380408.07it/s]Drawing 50000 posterior samples: 59994it [00:00, 380038.62it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▍  | 37397/50000 [00:00<00:00, 356513.98it/s]Drawing 50000 posterior samples: 56029it [00:00, 354158.62it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  59%|█████▉    | 29741/50000 [00:00<00:00, 285817.58it/s]Drawing 50000 posterior samples: 52056it [00:00, 284961.19it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▌       | 12809/50000 [00:00<00:00, 122896.27it/s]Drawing 50000 posterior samples:  51%|█████▏    | 25632/50000 [00:00<00:00, 122857.68it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38392/50000 [00:00<00:00, 122686.45it/s]Drawing 50000 posterior samples: 51291it [00:00, 123004.98it/s]                           Drawing 50000 posterior samples: 51291it [00:00, 122788.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36198/50000 [00:00<00:00, 349645.27it/s]Drawing 50000 posterior samples: 54238it [00:00, 347912.61it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36635/50000 [00:00<00:00, 353135.25it/s]Drawing 50000 posterior samples: 54882it [00:00, 351546.27it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  48%|████▊     | 24066/50000 [00:00<00:00, 228569.37it/s]Drawing 50000 posterior samples:  97%|█████████▋| 48280/50000 [00:00<00:00, 229208.64it/s]Drawing 50000 posterior samples: 54336it [00:00, 229510.11it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  27%|██▋       | 13414/50000 [00:00<00:00, 129299.30it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26668/50000 [00:00<00:00, 129014.01it/s]Drawing 50000 posterior samples:  80%|████████  | 40077/50000 [00:00<00:00, 129380.28it/s]Drawing 50000 posterior samples: 50161it [00:00, 129146.81it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33589/50000 [00:00<00:00, 319570.10it/s]Drawing 50000 posterior samples: 50404it [00:00, 318142.79it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  25%|██▌       | 12564/50000 [00:00<00:00, 121700.94it/s]Drawing 50000 posterior samples:  51%|█████     | 25340/50000 [00:00<00:00, 122082.68it/s]Drawing 50000 posterior samples:  76%|███████▋  | 38200/50000 [00:00<00:00, 122743.13it/s]Drawing 50000 posterior samples: 51145it [00:00, 123221.20it/s]                           Drawing 50000 posterior samples: 51145it [00:00, 123205.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36703/50000 [00:00<00:00, 339506.70it/s]Drawing 50000 posterior samples: 55063it [00:00, 343984.67it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  17%|█▋        | 8314/50000 [00:00<00:00, 79337.13it/s]Drawing 50000 posterior samples:  33%|███▎      | 16716/50000 [00:00<00:00, 79714.39it/s]Drawing 50000 posterior samples:  50%|█████     | 25102/50000 [00:00<00:00, 79843.92it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33623/50000 [00:00<00:00, 80519.14it/s]Drawing 50000 posterior samples:  84%|████████▍ | 41969/50000 [00:00<00:00, 80522.06it/s]Drawing 50000 posterior samples: 50334it [00:00, 80489.22it/s]                           Drawing 50000 posterior samples: 50334it [00:00, 80468.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  14%|█▎        | 6838/50000 [00:00<00:00, 66233.09it/s]Drawing 50000 posterior samples:  27%|██▋       | 13604/50000 [00:00<00:00, 65737.90it/s]Drawing 50000 posterior samples:  41%|████      | 20367/50000 [00:00<00:00, 65589.09it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27131/50000 [00:00<00:00, 65575.38it/s]Drawing 50000 posterior samples:  68%|██████▊   | 33874/50000 [00:00<00:00, 65361.19it/s]Drawing 50000 posterior samples:  81%|████████▏ | 40663/50000 [00:00<00:00, 65286.79it/s]Drawing 50000 posterior samples:  95%|█████████▍| 47456/50000 [00:00<00:00, 65198.65it/s]Drawing 50000 posterior samples: 50668it [00:00, 64873.47it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  42%|████▏     | 20829/50000 [00:00<00:00, 202969.53it/s]Drawing 50000 posterior samples:  83%|████████▎ | 41661/50000 [00:00<00:00, 202516.49it/s]Drawing 50000 posterior samples: 51994it [00:00, 201196.45it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33508/50000 [00:00<00:00, 318532.83it/s]Drawing 50000 posterior samples: 50252it [00:00, 319271.95it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36698/50000 [00:00<00:00, 347359.35it/s]Drawing 50000 posterior samples: 55001it [00:00, 345394.80it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36564/50000 [00:00<00:00, 353247.26it/s]Drawing 50000 posterior samples: 54816it [00:00, 352480.03it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  34%|███▍      | 17201/50000 [00:00<00:00, 165639.77it/s]Drawing 50000 posterior samples:  69%|██████▉   | 34389/50000 [00:00<00:00, 165568.08it/s]Drawing 50000 posterior samples: 51618it [00:00, 165570.12it/s]                           Drawing 50000 posterior samples: 51618it [00:00, 165294.76it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36264/50000 [00:00<00:00, 351091.32it/s]Drawing 50000 posterior samples: 54463it [00:00, 349345.20it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34864/50000 [00:00<00:00, 334034.34it/s]Drawing 50000 posterior samples: 52337it [00:00, 333792.99it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36476/50000 [00:00<00:00, 353605.79it/s]Drawing 50000 posterior samples: 54635it [00:00, 350129.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30113/50000 [00:00<00:00, 291537.49it/s]Drawing 50000 posterior samples: 52669it [00:00, 291741.79it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████   | 35362/50000 [00:00<00:00, 336540.94it/s]Drawing 50000 posterior samples: 53141it [00:00, 336861.57it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  28%|██▊       | 14020/50000 [00:00<00:00, 134743.01it/s]Drawing 50000 posterior samples:  56%|█████▌    | 28039/50000 [00:00<00:00, 134857.87it/s]Drawing 50000 posterior samples:  84%|████████▍ | 42148/50000 [00:00<00:00, 135382.97it/s]Drawing 50000 posterior samples: 52699it [00:00, 135476.43it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29773/50000 [00:00<00:00, 288352.29it/s]Drawing 50000 posterior samples: 52106it [00:00, 287250.74it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  17%|█▋        | 8511/50000 [00:00<00:00, 82168.37it/s]Drawing 50000 posterior samples:  34%|███▍      | 17090/50000 [00:00<00:00, 82087.06it/s]Drawing 50000 posterior samples:  51%|█████▏    | 25684/50000 [00:00<00:00, 82062.52it/s]Drawing 50000 posterior samples:  68%|██████▊   | 34186/50000 [00:00<00:00, 82026.25it/s]Drawing 50000 posterior samples:  86%|████████▌ | 42760/50000 [00:00<00:00, 82385.42it/s]Drawing 50000 posterior samples: 51256it [00:00, 82355.42it/s]                           Drawing 50000 posterior samples: 51256it [00:00, 82182.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36488/50000 [00:00<00:00, 348436.71it/s]Drawing 50000 posterior samples: 54795it [00:00, 349039.10it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  61%|██████    | 30568/50000 [00:00<00:00, 291967.04it/s]Drawing 50000 posterior samples: 53509it [00:00, 290860.64it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  12%|█▏        | 5864/50000 [00:00<00:00, 55943.77it/s]Drawing 50000 posterior samples:  23%|██▎       | 11612/50000 [00:00<00:00, 55738.05it/s]Drawing 50000 posterior samples:  35%|███▍      | 17388/50000 [00:00<00:00, 55708.70it/s]Drawing 50000 posterior samples:  46%|████▋     | 23183/50000 [00:00<00:00, 55771.78it/s]Drawing 50000 posterior samples:  58%|█████▊    | 28897/50000 [00:00<00:00, 55350.90it/s]Drawing 50000 posterior samples:  69%|██████▉   | 34638/50000 [00:00<00:00, 55190.80it/s]Drawing 50000 posterior samples:  81%|████████  | 40484/50000 [00:00<00:00, 55277.03it/s]Drawing 50000 posterior samples:  92%|█████████▏| 46208/50000 [00:00<00:00, 55321.39it/s]Drawing 50000 posterior samples: 50497it [00:00, 55355.14it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  13%|█▎        | 6631/50000 [00:00<00:00, 64472.11it/s]Drawing 50000 posterior samples:  27%|██▋       | 13366/50000 [00:00<00:00, 64714.65it/s]Drawing 50000 posterior samples:  40%|████      | 20224/50000 [00:00<00:00, 65189.56it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27075/50000 [00:00<00:00, 65456.01it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33675/50000 [00:00<00:00, 64783.65it/s]Drawing 50000 posterior samples:  81%|████████  | 40280/50000 [00:00<00:00, 64687.32it/s]Drawing 50000 posterior samples:  94%|█████████▍| 47025/50000 [00:00<00:00, 65022.58it/s]Drawing 50000 posterior samples: 50525it [00:00, 65275.89it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  29%|██▉       | 14402/50000 [00:00<00:00, 139650.46it/s]Drawing 50000 posterior samples:  58%|█████▊    | 28813/50000 [00:00<00:00, 139304.82it/s]Drawing 50000 posterior samples:  87%|████████▋ | 43435/50000 [00:00<00:00, 139523.90it/s]Drawing 50000 posterior samples: 50520it [00:00, 138814.91it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36684/50000 [00:00<00:00, 356521.19it/s]Drawing 50000 posterior samples: 55082it [00:00, 356508.43it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  76%|███████▌  | 37900/50000 [00:00<00:00, 368281.11it/s]Drawing 50000 posterior samples: 56842it [00:00, 367186.91it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36868/50000 [00:00<00:00, 350260.03it/s]Drawing 50000 posterior samples: 55295it [00:00, 350531.17it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39604/50000 [00:00<00:00, 384874.85it/s]Drawing 50000 posterior samples: 59375it [00:00, 382663.16it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████▏  | 35702/50000 [00:00<00:00, 346252.93it/s]Drawing 50000 posterior samples: 53612it [00:00, 345643.62it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32247/50000 [00:00<00:00, 314772.66it/s]Drawing 50000 posterior samples: 56472it [00:00, 313495.70it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33702/50000 [00:00<00:00, 320886.12it/s]Drawing 50000 posterior samples: 50550it [00:00, 321125.86it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36292/50000 [00:00<00:00, 350622.68it/s]Drawing 50000 posterior samples: 54393it [00:00, 349974.12it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  74%|███████▍  | 36876/50000 [00:00<00:00, 352281.41it/s]Drawing 50000 posterior samples: 55290it [00:00, 351058.18it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39980/50000 [00:00<00:00, 390027.15it/s]Drawing 50000 posterior samples: 59967it [00:00, 387249.68it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▍  | 37432/50000 [00:00<00:00, 354919.64it/s]Drawing 50000 posterior samples: 56105it [00:00, 355623.53it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████▏  | 35721/50000 [00:00<00:00, 344072.69it/s]Drawing 50000 posterior samples: 53595it [00:00, 344094.32it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36069/50000 [00:00<00:00, 347892.88it/s]Drawing 50000 posterior samples: 54073it [00:00, 346970.95it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 381238.85it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 379827.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39572/50000 [00:00<00:00, 375847.75it/s]Drawing 50000 posterior samples: 59366it [00:00, 374335.59it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  68%|██████▊   | 33792/50000 [00:00<00:00, 325454.76it/s]Drawing 50000 posterior samples: 50665it [00:00, 324563.05it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38540/50000 [00:00<00:00, 373404.90it/s]Drawing 50000 posterior samples: 57771it [00:00, 372460.11it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▍  | 37401/50000 [00:00<00:00, 361414.32it/s]Drawing 50000 posterior samples: 56039it [00:00, 360006.99it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39653/50000 [00:00<00:00, 378413.14it/s]Drawing 50000 posterior samples: 59496it [00:00, 377464.90it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36358/50000 [00:00<00:00, 353731.56it/s]Drawing 50000 posterior samples: 54483it [00:00, 356404.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37677/50000 [00:00<00:00, 360713.15it/s]Drawing 50000 posterior samples: 56515it [00:00, 358595.71it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 387083.75it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 386117.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39513/50000 [00:00<00:00, 378671.01it/s]Drawing 50000 posterior samples: 59246it [00:00, 377984.55it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 390273.10it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 387349.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  74%|███████▍  | 37230/50000 [00:00<00:00, 360553.55it/s]Drawing 50000 posterior samples: 55829it [00:00, 358597.48it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39991/50000 [00:00<00:00, 380509.76it/s]Drawing 50000 posterior samples: 59982it [00:00, 380182.52it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37541/50000 [00:00<00:00, 365520.06it/s]Drawing 50000 posterior samples: 56237it [00:00, 361083.20it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  65%|██████▌   | 32523/50000 [00:00<00:00, 314091.85it/s]Drawing 50000 posterior samples: 57065it [00:00, 314175.44it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████▏  | 35678/50000 [00:00<00:00, 342362.00it/s]Drawing 50000 posterior samples: 53476it [00:00, 341398.32it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39996/50000 [00:00<00:00, 383164.12it/s]Drawing 50000 posterior samples: 59992it [00:00, 383740.93it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37570/50000 [00:00<00:00, 361415.39it/s]Drawing 50000 posterior samples: 56324it [00:00, 357958.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  56%|█████▌    | 27839/50000 [00:00<00:00, 267815.69it/s]Drawing 50000 posterior samples: 55622it [00:00, 268901.02it/s]                           Drawing 50000 posterior samples: 55622it [00:00, 268973.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▋       | 13245/50000 [00:00<00:00, 127076.57it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26255/50000 [00:00<00:00, 126483.25it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39480/50000 [00:00<00:00, 126964.97it/s]Drawing 50000 posterior samples: 52647it [00:00, 127250.08it/s]                           Drawing 50000 posterior samples: 52647it [00:00, 126905.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  56%|█████▌    | 27962/50000 [00:00<00:00, 270507.26it/s]Drawing 50000 posterior samples: 55561it [00:00, 269064.56it/s]                           Drawing 50000 posterior samples: 55561it [00:00, 267552.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32036/50000 [00:00<00:00, 306845.86it/s]Drawing 50000 posterior samples: 56012it [00:00, 305115.56it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▎   | 31833/50000 [00:00<00:00, 304724.05it/s]Drawing 50000 posterior samples: 55720it [00:00, 303545.84it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  22%|██▏       | 10885/50000 [00:00<00:00, 104409.89it/s]Drawing 50000 posterior samples:  43%|████▎     | 21732/50000 [00:00<00:00, 104697.32it/s]Drawing 50000 posterior samples:  66%|██████▌   | 32823/50000 [00:00<00:00, 105666.48it/s]Drawing 50000 posterior samples:  88%|████████▊ | 43943/50000 [00:00<00:00, 106433.71it/s]Drawing 50000 posterior samples: 52137it [00:00, 106450.05it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  62%|██████▏   | 31203/50000 [00:00<00:00, 293791.19it/s]Drawing 50000 posterior samples: 54636it [00:00, 294068.57it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▌       | 12932/50000 [00:00<00:00, 123980.25it/s]Drawing 50000 posterior samples:  52%|█████▏    | 25949/50000 [00:00<00:00, 124130.40it/s]Drawing 50000 posterior samples:  78%|███████▊  | 39039/50000 [00:00<00:00, 124750.50it/s]Drawing 50000 posterior samples: 52134it [00:00, 124983.34it/s]                           Drawing 50000 posterior samples: 52134it [00:00, 124910.01it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▎   | 31827/50000 [00:00<00:00, 301917.26it/s]Drawing 50000 posterior samples: 55863it [00:00, 301138.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  16%|█▋        | 8237/50000 [00:00<00:00, 79271.09it/s]Drawing 50000 posterior samples:  33%|███▎      | 16286/50000 [00:00<00:00, 78608.53it/s]Drawing 50000 posterior samples:  49%|████▉     | 24457/50000 [00:00<00:00, 78296.53it/s]Drawing 50000 posterior samples:  65%|██████▌   | 32608/50000 [00:00<00:00, 77952.14it/s]Drawing 50000 posterior samples:  81%|████████▏ | 40747/50000 [00:00<00:00, 77841.08it/s]Drawing 50000 posterior samples:  98%|█████████▊| 49063/50000 [00:00<00:00, 78306.17it/s]Drawing 50000 posterior samples: 51115it [00:00, 77986.05it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  11%|█         | 5407/50000 [00:00<00:00, 52639.45it/s]Drawing 50000 posterior samples:  21%|██▏       | 10718/50000 [00:00<00:00, 52222.69it/s]Drawing 50000 posterior samples:  32%|███▏      | 16007/50000 [00:00<00:00, 51847.30it/s]Drawing 50000 posterior samples:  42%|████▏     | 21200/50000 [00:00<00:00, 51195.71it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26540/50000 [00:00<00:00, 51299.71it/s]Drawing 50000 posterior samples:  64%|██████▎   | 31789/50000 [00:00<00:00, 51202.51it/s]Drawing 50000 posterior samples:  74%|███████▍  | 37149/50000 [00:00<00:00, 51264.92it/s]Drawing 50000 posterior samples:  85%|████████▍ | 42436/50000 [00:00<00:00, 51163.21it/s]Drawing 50000 posterior samples:  95%|█████████▌| 47725/50000 [00:00<00:00, 51085.39it/s]Drawing 50000 posterior samples: 50409it [00:00, 51122.27it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  40%|████      | 20133/50000 [00:00<00:00, 192874.49it/s]Drawing 50000 posterior samples:  80%|████████  | 40088/50000 [00:00<00:00, 192242.16it/s]Drawing 50000 posterior samples: 50048it [00:00, 191955.45it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30148/50000 [00:00<00:00, 287233.33it/s]Drawing 50000 posterior samples: 52626it [00:00, 286410.17it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  66%|██████▌   | 33007/50000 [00:00<00:00, 318926.19it/s]Drawing 50000 posterior samples: 57857it [00:00, 319105.09it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  52%|█████▏    | 26016/50000 [00:00<00:00, 247769.70it/s]Drawing 50000 posterior samples: 52015it [00:00, 247322.82it/s]                           Drawing 50000 posterior samples: 52015it [00:00, 246436.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 19114/50000 [00:00<00:00, 184380.49it/s]Drawing 50000 posterior samples:  76%|███████▋  | 38235/50000 [00:00<00:00, 184172.45it/s]Drawing 50000 posterior samples: 52593it [00:00, 183856.19it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36733/50000 [00:00<00:00, 350022.42it/s]Drawing 50000 posterior samples: 55109it [00:00, 348093.60it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  69%|██████▉   | 34742/50000 [00:00<00:00, 336202.36it/s]Drawing 50000 posterior samples: 52164it [00:00, 335816.25it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  54%|█████▎    | 26861/50000 [00:00<00:00, 256794.51it/s]Drawing 50000 posterior samples: 53844it [00:00, 256840.61it/s]                           Drawing 50000 posterior samples: 53844it [00:00, 256236.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  56%|█████▌    | 28052/50000 [00:00<00:00, 274334.77it/s]Drawing 50000 posterior samples: 56415it [00:00, 274954.86it/s]                           Drawing 50000 posterior samples: 56415it [00:00, 274752.34it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  58%|█████▊    | 28778/50000 [00:00<00:00, 279128.83it/s]Drawing 50000 posterior samples: 50334it [00:00, 275632.95it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  29%|██▉       | 14720/50000 [00:00<00:00, 142209.60it/s]Drawing 50000 posterior samples:  59%|█████▉    | 29553/50000 [00:00<00:00, 142384.84it/s]Drawing 50000 posterior samples:  89%|████████▊ | 44252/50000 [00:00<00:00, 141920.34it/s]Drawing 50000 posterior samples: 51575it [00:00, 141676.17it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  78%|███████▊  | 38771/50000 [00:00<00:00, 310371.64it/s]Drawing 50000 posterior samples: 54276it [00:00, 305117.97it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  17%|█▋        | 8466/50000 [00:00<00:00, 80847.75it/s]Drawing 50000 posterior samples:  34%|███▍      | 17000/50000 [00:00<00:00, 81107.31it/s]Drawing 50000 posterior samples:  51%|█████     | 25539/50000 [00:00<00:00, 81463.81it/s]Drawing 50000 posterior samples:  68%|██████▊   | 33784/50000 [00:00<00:00, 80891.29it/s]Drawing 50000 posterior samples:  84%|████████▍ | 42187/50000 [00:00<00:00, 80625.71it/s]Drawing 50000 posterior samples: 50556it [00:00, 80576.54it/s]                           Drawing 50000 posterior samples: 50556it [00:00, 80746.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32022/50000 [00:00<00:00, 306414.38it/s]Drawing 50000 posterior samples: 56023it [00:00, 307455.52it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  57%|█████▋    | 28450/50000 [00:00<00:00, 275833.26it/s]Drawing 50000 posterior samples: 50028it [00:00, 276776.23it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   6%|▋         | 3231/50000 [00:00<00:01, 31258.11it/s]Drawing 50000 posterior samples:  13%|█▎        | 6582/50000 [00:00<00:01, 31575.93it/s]Drawing 50000 posterior samples:  20%|█▉        | 9872/50000 [00:00<00:01, 31747.65it/s]Drawing 50000 posterior samples:  27%|██▋       | 13273/50000 [00:00<00:01, 32088.58it/s]Drawing 50000 posterior samples:  33%|███▎      | 16544/50000 [00:00<00:01, 31577.38it/s]Drawing 50000 posterior samples:  40%|███▉      | 19926/50000 [00:00<00:00, 31914.37it/s]Drawing 50000 posterior samples:  46%|████▋     | 23200/50000 [00:00<00:00, 31954.43it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26608/50000 [00:00<00:00, 32371.22it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29981/50000 [00:00<00:00, 32504.54it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33341/50000 [00:01<00:00, 32479.86it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36692/50000 [00:01<00:00, 32562.55it/s]Drawing 50000 posterior samples:  80%|████████  | 40027/50000 [00:01<00:00, 32510.00it/s]Drawing 50000 posterior samples:  87%|████████▋ | 43426/50000 [00:01<00:00, 32554.56it/s]Drawing 50000 posterior samples:  94%|█████████▎| 46852/50000 [00:01<00:00, 32841.43it/s]Drawing 50000 posterior samples: 50158it [00:01, 32697.36it/s]                           Drawing 50000 posterior samples: 50158it [00:01, 32395.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  10%|█         | 5242/50000 [00:00<00:00, 50555.28it/s]Drawing 50000 posterior samples:  21%|██        | 10519/50000 [00:00<00:00, 50747.12it/s]Drawing 50000 posterior samples:  32%|███▏      | 15830/50000 [00:00<00:00, 50986.82it/s]Drawing 50000 posterior samples:  42%|████▏     | 21037/50000 [00:00<00:00, 50840.33it/s]Drawing 50000 posterior samples:  52%|█████▏    | 26163/50000 [00:00<00:00, 50606.89it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31463/50000 [00:00<00:00, 50919.27it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36708/50000 [00:00<00:00, 50892.17it/s]Drawing 50000 posterior samples:  84%|████████▍ | 42005/50000 [00:00<00:00, 50940.02it/s]Drawing 50000 posterior samples:  95%|█████████▍| 47307/50000 [00:00<00:00, 51020.12it/s]Drawing 50000 posterior samples: 51214it [00:01, 50911.04it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 18982/50000 [00:00<00:00, 186280.05it/s]Drawing 50000 posterior samples:  76%|███████▌  | 37938/50000 [00:00<00:00, 185636.07it/s]Drawing 50000 posterior samples: 52232it [00:00, 184347.01it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32218/50000 [00:00<00:00, 312006.96it/s]Drawing 50000 posterior samples: 56567it [00:00, 311751.62it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37555/50000 [00:00<00:00, 365274.80it/s]Drawing 50000 posterior samples: 56299it [00:00, 363809.25it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36316/50000 [00:00<00:00, 352030.30it/s]Drawing 50000 posterior samples: 54450it [00:00, 350874.81it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  78%|███████▊  | 39069/50000 [00:00<00:00, 374683.06it/s]Drawing 50000 posterior samples: 58588it [00:00, 375766.50it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36394/50000 [00:00<00:00, 350751.72it/s]Drawing 50000 posterior samples: 54556it [00:00, 349162.13it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  50%|████▉     | 24922/50000 [00:00<00:00, 242231.04it/s]Drawing 50000 posterior samples: 100%|█████████▉| 49885/50000 [00:00<00:00, 242068.06it/s]Drawing 50000 posterior samples: 56230it [00:00, 241401.82it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36645/50000 [00:00<00:00, 352606.05it/s]Drawing 50000 posterior samples: 54949it [00:00, 351411.39it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  74%|███████▍  | 37190/50000 [00:00<00:00, 359571.72it/s]Drawing 50000 posterior samples: 55768it [00:00, 359414.36it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36437/50000 [00:00<00:00, 353890.24it/s]Drawing 50000 posterior samples: 54579it [00:00, 352285.75it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39623/50000 [00:00<00:00, 383074.00it/s]Drawing 50000 posterior samples: 59399it [00:00, 382572.70it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38501/50000 [00:00<00:00, 372699.03it/s]Drawing 50000 posterior samples: 57734it [00:00, 371845.46it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  68%|██████▊   | 33794/50000 [00:00<00:00, 324272.23it/s]Drawing 50000 posterior samples: 50797it [00:00, 325055.66it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  68%|██████▊   | 33903/50000 [00:00<00:00, 328138.53it/s]Drawing 50000 posterior samples: 50882it [00:00, 327205.04it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 381575.27it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 380698.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39709/50000 [00:00<00:00, 375918.89it/s]Drawing 50000 posterior samples: 59566it [00:00, 377596.58it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  71%|███████   | 35348/50000 [00:00<00:00, 341068.10it/s]Drawing 50000 posterior samples: 52918it [00:00, 337476.91it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  78%|███████▊  | 39002/50000 [00:00<00:00, 374938.10it/s]Drawing 50000 posterior samples: 58529it [00:00, 374627.90it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  76%|███████▌  | 37946/50000 [00:00<00:00, 362997.68it/s]Drawing 50000 posterior samples: 56946it [00:00, 362908.87it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  78%|███████▊  | 39099/50000 [00:00<00:00, 374092.31it/s]Drawing 50000 posterior samples: 58592it [00:00, 373251.71it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 35987/50000 [00:00<00:00, 345205.51it/s]Drawing 50000 posterior samples: 53996it [00:00, 345907.98it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37683/50000 [00:00<00:00, 357500.79it/s]Drawing 50000 posterior samples: 56525it [00:00, 357455.98it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 384668.84it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 383745.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39527/50000 [00:00<00:00, 378394.50it/s]Drawing 50000 posterior samples: 59291it [00:00, 377740.16it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|████████  | 40000/50000 [00:00<00:00, 386923.95it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 384723.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38635/50000 [00:00<00:00, 370233.05it/s]Drawing 50000 posterior samples: 57928it [00:00, 367483.57it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39746/50000 [00:00<00:00, 381667.01it/s]Drawing 50000 posterior samples: 59608it [00:00, 380766.11it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37664/50000 [00:00<00:00, 360822.59it/s]Drawing 50000 posterior samples: 56428it [00:00, 359161.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27042/50000 [00:00<00:00, 262058.60it/s]Drawing 50000 posterior samples: 54145it [00:00, 262228.04it/s]                           Drawing 50000 posterior samples: 54145it [00:00, 261788.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33713/50000 [00:00<00:00, 324218.18it/s]Drawing 50000 posterior samples: 50490it [00:00, 323589.27it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39923/50000 [00:00<00:00, 385046.02it/s]Drawing 50000 posterior samples: 59883it [00:00, 385034.31it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37562/50000 [00:00<00:00, 363947.79it/s]Drawing 50000 posterior samples: 56326it [00:00, 361326.09it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  61%|██████    | 30520/50000 [00:00<00:00, 290523.46it/s]Drawing 50000 posterior samples: 53336it [00:00, 290624.58it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▋       | 13199/50000 [00:00<00:00, 126972.73it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26437/50000 [00:00<00:00, 127075.80it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39665/50000 [00:00<00:00, 126713.74it/s]Drawing 50000 posterior samples: 52816it [00:00, 126020.71it/s]                           Drawing 50000 posterior samples: 52816it [00:00, 125991.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36438/50000 [00:00<00:00, 352547.24it/s]Drawing 50000 posterior samples: 54604it [00:00, 348815.72it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36695/50000 [00:00<00:00, 357733.86it/s]Drawing 50000 posterior samples: 55055it [00:00, 355897.07it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27015/50000 [00:00<00:00, 260896.38it/s]Drawing 50000 posterior samples: 54030it [00:00, 260679.22it/s]                           Drawing 50000 posterior samples: 54030it [00:00, 259826.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  56%|█████▋    | 28213/50000 [00:00<00:00, 274074.59it/s]Drawing 50000 posterior samples: 56552it [00:00, 274308.41it/s]                           Drawing 50000 posterior samples: 56552it [00:00, 273818.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  69%|██████▉   | 34487/50000 [00:00<00:00, 327612.17it/s]Drawing 50000 posterior samples: 51645it [00:00, 326294.97it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▌       | 13011/50000 [00:00<00:00, 126406.50it/s]Drawing 50000 posterior samples:  52%|█████▏    | 26198/50000 [00:00<00:00, 127001.74it/s]Drawing 50000 posterior samples:  79%|███████▊  | 39277/50000 [00:00<00:00, 126717.14it/s]Drawing 50000 posterior samples: 52370it [00:00, 126041.11it/s]                           Drawing 50000 posterior samples: 52370it [00:00, 126184.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  62%|██████▏   | 31093/50000 [00:00<00:00, 295897.33it/s]Drawing 50000 posterior samples: 54594it [00:00, 295119.15it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  17%|█▋        | 8440/50000 [00:00<00:00, 80473.03it/s]Drawing 50000 posterior samples:  34%|███▍      | 17036/50000 [00:00<00:00, 80883.88it/s]Drawing 50000 posterior samples:  47%|████▋     | 23348/50000 [00:00<00:00, 74323.67it/s]Drawing 50000 posterior samples:  64%|██████▎   | 31829/50000 [00:00<00:00, 76216.66it/s]Drawing 50000 posterior samples:  81%|████████▏ | 40640/50000 [00:00<00:00, 78735.03it/s]Drawing 50000 posterior samples:  98%|█████████▊| 49231/50000 [00:00<00:00, 80098.15it/s]Drawing 50000 posterior samples: 51394it [00:00, 79336.51it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  11%|█         | 5556/50000 [00:00<00:00, 54352.31it/s]Drawing 50000 posterior samples:  22%|██▏       | 11087/50000 [00:00<00:00, 54316.15it/s]Drawing 50000 posterior samples:  34%|███▎      | 16795/50000 [00:00<00:00, 54802.84it/s]Drawing 50000 posterior samples:  45%|████▍     | 22318/50000 [00:00<00:00, 54641.15it/s]Drawing 50000 posterior samples:  56%|█████▌    | 27963/50000 [00:00<00:00, 54913.56it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33689/50000 [00:00<00:00, 55298.40it/s]Drawing 50000 posterior samples:  78%|███████▊  | 39178/50000 [00:00<00:00, 54763.06it/s]Drawing 50000 posterior samples:  90%|████████▉ | 44774/50000 [00:00<00:00, 54668.92it/s]Drawing 50000 posterior samples: 50320it [00:00, 54550.99it/s]                           Drawing 50000 posterior samples: 50320it [00:00, 54734.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  41%|████      | 20316/50000 [00:00<00:00, 194660.98it/s]Drawing 50000 posterior samples:  81%|████████  | 40555/50000 [00:00<00:00, 194907.68it/s]Drawing 50000 posterior samples: 50823it [00:00, 195940.06it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36603/50000 [00:00<00:00, 349829.58it/s]Drawing 50000 posterior samples: 54893it [00:00, 349400.68it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36333/50000 [00:00<00:00, 344875.80it/s]Drawing 50000 posterior samples: 54501it [00:00, 343269.44it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36660/50000 [00:00<00:00, 352718.82it/s]Drawing 50000 posterior samples: 55031it [00:00, 352877.38it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  52%|█████▏    | 26186/50000 [00:00<00:00, 249773.82it/s]Drawing 50000 posterior samples: 52296it [00:00, 249082.01it/s]                           Drawing 50000 posterior samples: 52296it [00:00, 248091.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36050/50000 [00:00<00:00, 344398.37it/s]Drawing 50000 posterior samples: 54085it [00:00, 342573.78it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27134/50000 [00:00<00:00, 261340.97it/s]Drawing 50000 posterior samples: 54455it [00:00, 262150.28it/s]                           Drawing 50000 posterior samples: 54455it [00:00, 262098.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36619/50000 [00:00<00:00, 354624.04it/s]Drawing 50000 posterior samples: 54985it [00:00, 354147.14it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  62%|██████▏   | 31132/50000 [00:00<00:00, 295094.10it/s]Drawing 50000 posterior samples: 54332it [00:00, 292911.59it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36431/50000 [00:00<00:00, 353410.51it/s]Drawing 50000 posterior samples: 54646it [00:00, 352685.10it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26267/50000 [00:00<00:00, 251210.28it/s]Drawing 50000 posterior samples: 52444it [00:00, 251805.07it/s]                           Drawing 50000 posterior samples: 52444it [00:00, 251617.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  65%|██████▌   | 32622/50000 [00:00<00:00, 314426.05it/s]Drawing 50000 posterior samples: 57005it [00:00, 314651.73it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  18%|█▊        | 8819/50000 [00:00<00:00, 84308.82it/s]Drawing 50000 posterior samples:  35%|███▌      | 17542/50000 [00:00<00:00, 84167.20it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26447/50000 [00:00<00:00, 84450.71it/s]Drawing 50000 posterior samples:  70%|███████   | 35088/50000 [00:00<00:00, 84132.91it/s]Drawing 50000 posterior samples:  88%|████████▊ | 43927/50000 [00:00<00:00, 84755.66it/s]Drawing 50000 posterior samples: 50506it [00:00, 84589.68it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  62%|██████▏   | 31026/50000 [00:00<00:00, 299489.72it/s]Drawing 50000 posterior samples: 54420it [00:00, 299339.72it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31391/50000 [00:00<00:00, 301470.67it/s]Drawing 50000 posterior samples: 54924it [00:00, 299613.40it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  14%|█▍        | 7031/50000 [00:00<00:00, 68347.78it/s]Drawing 50000 posterior samples:  28%|██▊       | 14097/50000 [00:00<00:00, 68361.91it/s]Drawing 50000 posterior samples:  42%|████▏     | 21118/50000 [00:00<00:00, 68231.29it/s]Drawing 50000 posterior samples:  56%|█████▋    | 28132/50000 [00:00<00:00, 68227.19it/s]Drawing 50000 posterior samples:  70%|███████   | 35207/50000 [00:00<00:00, 68489.73it/s]Drawing 50000 posterior samples:  84%|████████▍ | 42249/50000 [00:00<00:00, 68512.58it/s]Drawing 50000 posterior samples:  99%|█████████▊| 49338/50000 [00:00<00:00, 68552.95it/s]Drawing 50000 posterior samples: 51141it [00:00, 68457.24it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  11%|█         | 5524/50000 [00:00<00:00, 54202.98it/s]Drawing 50000 posterior samples:  22%|██▏       | 11058/50000 [00:00<00:00, 54178.38it/s]Drawing 50000 posterior samples:  33%|███▎      | 16686/50000 [00:00<00:00, 54408.19it/s]Drawing 50000 posterior samples:  44%|████▍     | 22239/50000 [00:00<00:00, 54348.94it/s]Drawing 50000 posterior samples:  56%|█████▌    | 27815/50000 [00:00<00:00, 54323.83it/s]Drawing 50000 posterior samples:  67%|██████▋   | 33386/50000 [00:00<00:00, 54148.74it/s]Drawing 50000 posterior samples:  78%|███████▊  | 38948/50000 [00:00<00:00, 53777.37it/s]Drawing 50000 posterior samples:  89%|████████▉ | 44617/50000 [00:00<00:00, 53817.68it/s]Drawing 50000 posterior samples: 50230it [00:00, 53763.54it/s]                           Drawing 50000 posterior samples: 50230it [00:00, 53965.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  48%|████▊     | 24072/50000 [00:00<00:00, 229166.04it/s]Drawing 50000 posterior samples:  96%|█████████▋| 48167/50000 [00:00<00:00, 229943.46it/s]Drawing 50000 posterior samples: 54271it [00:00, 230502.05it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36604/50000 [00:00<00:00, 347925.31it/s]Drawing 50000 posterior samples: 54918it [00:00, 346730.51it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30087/50000 [00:00<00:00, 290807.84it/s]Drawing 50000 posterior samples: 52576it [00:00, 288426.97it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▌       | 12834/50000 [00:00<00:00, 121897.51it/s]Drawing 50000 posterior samples:  52%|█████▏    | 25808/50000 [00:00<00:00, 122148.22it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38706/50000 [00:00<00:00, 122075.55it/s]Drawing 50000 posterior samples: 51646it [00:00, 122392.18it/s]                           Drawing 50000 posterior samples: 51646it [00:00, 122263.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34912/50000 [00:00<00:00, 329979.88it/s]Drawing 50000 posterior samples: 52284it [00:00, 328925.05it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 35803/50000 [00:00<00:00, 344892.63it/s]Drawing 50000 posterior samples: 53681it [00:00, 342273.10it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  51%|█████▏    | 25638/50000 [00:00<00:00, 243433.46it/s]Drawing 50000 posterior samples: 51334it [00:00, 243470.96it/s]                           Drawing 50000 posterior samples: 51334it [00:00, 242894.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  36%|███▌      | 18104/50000 [00:00<00:00, 171912.34it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36589/50000 [00:00<00:00, 173488.36it/s]Drawing 50000 posterior samples: 50217it [00:00, 174655.14it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  69%|██████▉   | 34570/50000 [00:00<00:00, 333817.78it/s]Drawing 50000 posterior samples: 51855it [00:00, 333511.67it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▌       | 12913/50000 [00:00<00:00, 123946.83it/s]Drawing 50000 posterior samples:  52%|█████▏    | 25772/50000 [00:00<00:00, 123311.74it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38713/50000 [00:00<00:00, 123391.38it/s]Drawing 50000 posterior samples: 51548it [00:00, 123215.71it/s]                           Drawing 50000 posterior samples: 51548it [00:00, 122908.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29755/50000 [00:00<00:00, 281826.51it/s]Drawing 50000 posterior samples: 52028it [00:00, 281855.84it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  15%|█▌        | 7521/50000 [00:00<00:00, 72092.64it/s]Drawing 50000 posterior samples:  30%|███       | 15018/50000 [00:00<00:00, 71972.48it/s]Drawing 50000 posterior samples:  45%|████▌     | 22546/50000 [00:00<00:00, 71864.05it/s]Drawing 50000 posterior samples:  60%|██████    | 30160/50000 [00:00<00:00, 72191.00it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37564/50000 [00:00<00:00, 71869.48it/s]Drawing 50000 posterior samples:  90%|█████████ | 45136/50000 [00:00<00:00, 72087.90it/s]Drawing 50000 posterior samples: 50779it [00:00, 71965.21it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   9%|▉         | 4525/50000 [00:00<00:01, 43644.65it/s]Drawing 50000 posterior samples:  18%|█▊        | 9054/50000 [00:00<00:00, 43651.13it/s]Drawing 50000 posterior samples:  27%|██▋       | 13557/50000 [00:00<00:00, 43498.99it/s]Drawing 50000 posterior samples:  36%|███▌      | 18118/50000 [00:00<00:00, 43555.69it/s]Drawing 50000 posterior samples:  45%|████▌     | 22646/50000 [00:00<00:00, 43467.62it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27135/50000 [00:00<00:00, 43386.38it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31709/50000 [00:00<00:00, 43652.59it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36235/50000 [00:00<00:00, 43627.31it/s]Drawing 50000 posterior samples:  82%|████████▏ | 40784/50000 [00:00<00:00, 43594.00it/s]Drawing 50000 posterior samples:  93%|█████████▎| 46467/50000 [00:01<00:00, 44509.59it/s]Drawing 50000 posterior samples: 51084it [00:01, 44365.93it/s]                           Drawing 50000 posterior samples: 51084it [00:01, 43916.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  41%|████▏     | 20647/50000 [00:00<00:00, 198926.33it/s]Drawing 50000 posterior samples:  82%|████████▏ | 40968/50000 [00:00<00:00, 198393.11it/s]Drawing 50000 posterior samples: 51162it [00:00, 197834.02it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29958/50000 [00:00<00:00, 287294.76it/s]Drawing 50000 posterior samples: 52407it [00:00, 285198.31it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36072/50000 [00:00<00:00, 348917.56it/s]Drawing 50000 posterior samples: 54126it [00:00, 346867.93it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  69%|██████▉   | 34480/50000 [00:00<00:00, 335539.65it/s]Drawing 50000 posterior samples: 51653it [00:00, 334424.76it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  28%|██▊       | 14215/50000 [00:00<00:00, 136749.35it/s]Drawing 50000 posterior samples:  57%|█████▋    | 28679/50000 [00:00<00:00, 137196.36it/s]Drawing 50000 posterior samples:  85%|████████▌ | 42745/50000 [00:00<00:00, 136423.66it/s]Drawing 50000 posterior samples: 53398it [00:00, 136515.57it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36347/50000 [00:00<00:00, 349217.08it/s]Drawing 50000 posterior samples: 54569it [00:00, 347557.80it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29881/50000 [00:00<00:00, 284563.45it/s]Drawing 50000 posterior samples: 52250it [00:00, 284385.24it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  69%|██████▉   | 34629/50000 [00:00<00:00, 336095.21it/s]Drawing 50000 posterior samples: 51945it [00:00, 334456.19it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  61%|██████▏   | 30719/50000 [00:00<00:00, 292834.47it/s]Drawing 50000 posterior samples: 53564it [00:00, 291179.60it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30154/50000 [00:00<00:00, 290365.41it/s]Drawing 50000 posterior samples: 52785it [00:00, 289361.59it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  38%|███▊      | 18895/50000 [00:00<00:00, 180390.21it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37676/50000 [00:00<00:00, 180924.85it/s]Drawing 50000 posterior samples: 51689it [00:00, 183544.12it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  61%|██████    | 30559/50000 [00:00<00:00, 291788.71it/s]Drawing 50000 posterior samples: 53448it [00:00, 292714.12it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  16%|█▌        | 7909/50000 [00:00<00:00, 77433.52it/s]Drawing 50000 posterior samples:  32%|███▏      | 15787/50000 [00:00<00:00, 77264.63it/s]Drawing 50000 posterior samples:  47%|████▋     | 23668/50000 [00:00<00:00, 77224.25it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31583/50000 [00:00<00:00, 77036.30it/s]Drawing 50000 posterior samples:  79%|███████▊  | 39257/50000 [00:00<00:00, 75926.51it/s]Drawing 50000 posterior samples:  94%|█████████▍| 47072/50000 [00:00<00:00, 75519.50it/s]Drawing 50000 posterior samples: 50898it [00:00, 75754.17it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29914/50000 [00:00<00:00, 285844.75it/s]Drawing 50000 posterior samples: 52312it [00:00, 283955.15it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  62%|██████▏   | 31084/50000 [00:00<00:00, 297560.29it/s]Drawing 50000 posterior samples: 54405it [00:00, 296274.37it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   4%|▍         | 2165/50000 [00:00<00:02, 21072.16it/s]Drawing 50000 posterior samples:   9%|▉         | 4413/50000 [00:00<00:02, 21227.69it/s]Drawing 50000 posterior samples:  13%|█▎        | 6632/50000 [00:00<00:02, 21269.16it/s]Drawing 50000 posterior samples:  18%|█▊        | 8857/50000 [00:00<00:01, 21313.99it/s]Drawing 50000 posterior samples:  22%|██▏       | 11052/50000 [00:00<00:01, 21235.53it/s]Drawing 50000 posterior samples:  27%|██▋       | 13291/50000 [00:00<00:01, 21383.21it/s]Drawing 50000 posterior samples:  31%|███       | 15512/50000 [00:00<00:01, 21461.72it/s]Drawing 50000 posterior samples:  35%|███▌      | 17687/50000 [00:00<00:01, 21259.73it/s]Drawing 50000 posterior samples:  40%|███▉      | 19884/50000 [00:00<00:01, 21217.75it/s]Drawing 50000 posterior samples:  44%|████▍     | 22038/50000 [00:01<00:01, 21043.92it/s]Drawing 50000 posterior samples:  48%|████▊     | 24215/50000 [00:01<00:01, 21021.90it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26396/50000 [00:01<00:01, 21004.72it/s]Drawing 50000 posterior samples:  57%|█████▋    | 28694/50000 [00:01<00:00, 21460.95it/s]Drawing 50000 posterior samples:  62%|██████▏   | 30894/50000 [00:01<00:00, 21500.65it/s]Drawing 50000 posterior samples:  66%|██████▌   | 33122/50000 [00:01<00:00, 21577.86it/s]Drawing 50000 posterior samples:  71%|███████   | 35335/50000 [00:01<00:00, 21461.86it/s]Drawing 50000 posterior samples:  75%|███████▌  | 37586/50000 [00:01<00:00, 21491.77it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39877/50000 [00:01<00:00, 21656.18it/s]Drawing 50000 posterior samples:  84%|████████▍ | 42073/50000 [00:01<00:00, 21433.05it/s]Drawing 50000 posterior samples:  88%|████████▊ | 44223/50000 [00:02<00:00, 19891.66it/s]Drawing 50000 posterior samples:  93%|█████████▎| 46444/50000 [00:02<00:00, 20299.07it/s]Drawing 50000 posterior samples:  97%|█████████▋| 48624/50000 [00:02<00:00, 20518.64it/s]Drawing 50000 posterior samples: 50274it [00:02, 21112.74it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   9%|▉         | 4388/50000 [00:00<00:01, 43098.79it/s]Drawing 50000 posterior samples:  17%|█▋        | 8636/50000 [00:00<00:00, 42603.98it/s]Drawing 50000 posterior samples:  26%|██▋       | 13173/50000 [00:00<00:00, 43167.40it/s]Drawing 50000 posterior samples:  35%|███▌      | 17577/50000 [00:00<00:00, 43090.06it/s]Drawing 50000 posterior samples:  44%|████▍     | 22038/50000 [00:00<00:00, 43255.69it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26439/50000 [00:00<00:00, 43274.14it/s]Drawing 50000 posterior samples:  62%|██████▏   | 30896/50000 [00:00<00:00, 43394.79it/s]Drawing 50000 posterior samples:  70%|███████   | 35188/50000 [00:00<00:00, 42961.12it/s]Drawing 50000 posterior samples:  79%|███████▉  | 39662/50000 [00:00<00:00, 43130.91it/s]Drawing 50000 posterior samples:  88%|████████▊ | 44039/50000 [00:01<00:00, 42915.83it/s]Drawing 50000 posterior samples:  97%|█████████▋| 48474/50000 [00:01<00:00, 42929.17it/s]Drawing 50000 posterior samples: 50737it [00:01, 43068.74it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  39%|███▊      | 19345/50000 [00:00<00:00, 185028.76it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38501/50000 [00:00<00:00, 184590.28it/s]Drawing 50000 posterior samples: 52911it [00:00, 184011.46it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 35964/50000 [00:00<00:00, 342250.78it/s]Drawing 50000 posterior samples: 53908it [00:00, 340727.67it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  62%|██████▏   | 30872/50000 [00:00<00:00, 298596.23it/s]Drawing 50000 posterior samples: 54309it [00:00, 300387.64it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▌       | 13091/50000 [00:00<00:00, 125105.68it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26264/50000 [00:00<00:00, 125278.11it/s]Drawing 50000 posterior samples:  79%|███████▊  | 39303/50000 [00:00<00:00, 125140.94it/s]Drawing 50000 posterior samples: 52462it [00:00, 125525.97it/s]                           Drawing 50000 posterior samples: 52462it [00:00, 125370.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  49%|████▉     | 24584/50000 [00:00<00:00, 233616.62it/s]Drawing 50000 posterior samples:  98%|█████████▊| 48897/50000 [00:00<00:00, 233900.75it/s]Drawing 50000 posterior samples: 54942it [00:00, 233723.76it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36728/50000 [00:00<00:00, 355599.97it/s]Drawing 50000 posterior samples: 55111it [00:00, 354397.60it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  48%|████▊     | 23950/50000 [00:00<00:00, 231684.61it/s]Drawing 50000 posterior samples:  96%|█████████▌| 47937/50000 [00:00<00:00, 232231.83it/s]Drawing 50000 posterior samples: 53886it [00:00, 231770.76it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  16%|█▌        | 7967/50000 [00:00<00:00, 77111.28it/s]Drawing 50000 posterior samples:  32%|███▏      | 15910/50000 [00:00<00:00, 76443.98it/s]Drawing 50000 posterior samples:  48%|████▊     | 23819/50000 [00:00<00:00, 76567.23it/s]Drawing 50000 posterior samples:  64%|██████▎   | 31849/50000 [00:00<00:00, 77016.98it/s]Drawing 50000 posterior samples:  80%|███████▉  | 39848/50000 [00:00<00:00, 77067.10it/s]Drawing 50000 posterior samples:  96%|█████████▌| 47815/50000 [00:00<00:00, 77249.00it/s]Drawing 50000 posterior samples: 51723it [00:00, 76846.04it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  70%|██████▉   | 34821/50000 [00:00<00:00, 339247.68it/s]Drawing 50000 posterior samples: 52275it [00:00, 338669.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  26%|██▌       | 13068/50000 [00:00<00:00, 125603.35it/s]Drawing 50000 posterior samples:  52%|█████▏    | 25986/50000 [00:00<00:00, 124550.32it/s]Drawing 50000 posterior samples:  78%|███████▊  | 38965/50000 [00:00<00:00, 124074.63it/s]Drawing 50000 posterior samples: 51940it [00:00, 123973.79it/s]                           Drawing 50000 posterior samples: 51940it [00:00, 123459.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32218/50000 [00:00<00:00, 311705.41it/s]Drawing 50000 posterior samples: 56283it [00:00, 310534.49it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  16%|█▌        | 7774/50000 [00:00<00:00, 74040.94it/s]Drawing 50000 posterior samples:  31%|███       | 15481/50000 [00:00<00:00, 73274.39it/s]Drawing 50000 posterior samples:  47%|████▋     | 23261/50000 [00:00<00:00, 72977.92it/s]Drawing 50000 posterior samples:  62%|██████▏   | 30927/50000 [00:00<00:00, 72136.17it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38718/50000 [00:00<00:00, 71768.82it/s]Drawing 50000 posterior samples:  93%|█████████▎| 46521/50000 [00:00<00:00, 71600.00it/s]Drawing 50000 posterior samples: 50343it [00:00, 71547.40it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   9%|▉         | 4583/50000 [00:00<00:01, 44398.06it/s]Drawing 50000 posterior samples:  18%|█▊        | 9070/50000 [00:00<00:00, 44090.38it/s]Drawing 50000 posterior samples:  27%|██▋       | 13707/50000 [00:00<00:00, 44457.97it/s]Drawing 50000 posterior samples:  37%|███▋      | 18325/50000 [00:00<00:00, 44612.78it/s]Drawing 50000 posterior samples:  46%|████▌     | 23001/50000 [00:00<00:00, 44936.66it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27637/50000 [00:00<00:00, 44989.79it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32148/50000 [00:00<00:00, 44692.69it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36730/50000 [00:00<00:00, 44714.28it/s]Drawing 50000 posterior samples:  83%|████████▎ | 41394/50000 [00:00<00:00, 45007.76it/s]Drawing 50000 posterior samples:  92%|█████████▏| 45890/50000 [00:01<00:00, 44723.09it/s]Drawing 50000 posterior samples: 50352it [00:01, 44378.61it/s]                           Drawing 50000 posterior samples: 50352it [00:01, 44624.21it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  42%|████▏     | 21152/50000 [00:00<00:00, 207210.30it/s]Drawing 50000 posterior samples:  85%|████████▍ | 42342/50000 [00:00<00:00, 206926.08it/s]Drawing 50000 posterior samples: 52941it [00:00, 206193.16it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27340/50000 [00:00<00:00, 264896.27it/s]Drawing 50000 posterior samples: 54649it [00:00, 264604.22it/s]                           Drawing 50000 posterior samples: 54649it [00:00, 263810.65it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36588/50000 [00:00<00:00, 341368.52it/s]Drawing 50000 posterior samples: 54802it [00:00, 340643.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  42%|████▏     | 21080/50000 [00:00<00:00, 201507.68it/s]Drawing 50000 posterior samples:  84%|████████▍ | 42236/50000 [00:00<00:00, 201288.81it/s]Drawing 50000 posterior samples: 52762it [00:00, 200944.77it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  24%|██▍       | 12132/50000 [00:00<00:00, 116261.68it/s]Drawing 50000 posterior samples:  48%|████▊     | 24118/50000 [00:00<00:00, 115653.62it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36267/50000 [00:00<00:00, 116454.62it/s]Drawing 50000 posterior samples:  97%|█████████▋| 48340/50000 [00:00<00:00, 116153.05it/s]Drawing 50000 posterior samples: 51292it [00:00, 115765.46it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  72%|███████▏  | 36183/50000 [00:00<00:00, 346420.13it/s]Drawing 50000 posterior samples: 54198it [00:00, 345860.27it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  62%|██████▏   | 30799/50000 [00:00<00:00, 299014.79it/s]Drawing 50000 posterior samples: 53810it [00:00, 297305.36it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  46%|████▌     | 22892/50000 [00:00<00:00, 223082.41it/s]Drawing 50000 posterior samples:  91%|█████████ | 45585/50000 [00:00<00:00, 222301.58it/s]Drawing 50000 posterior samples: 51282it [00:00, 221385.40it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  63%|██████▎   | 31442/50000 [00:00<00:00, 303760.47it/s]Drawing 50000 posterior samples: 54871it [00:00, 301267.34it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26571/50000 [00:00<00:00, 252877.95it/s]Drawing 50000 posterior samples: 53075it [00:00, 253188.05it/s]                           Drawing 50000 posterior samples: 53075it [00:00, 252820.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  24%|██▍       | 12247/50000 [00:00<00:00, 117860.83it/s]Drawing 50000 posterior samples:  49%|████▉     | 24551/50000 [00:00<00:00, 118243.58it/s]Drawing 50000 posterior samples:  74%|███████▍  | 36875/50000 [00:00<00:00, 118382.39it/s]Drawing 50000 posterior samples:  98%|█████████▊| 49163/50000 [00:00<00:00, 118409.11it/s]Drawing 50000 posterior samples: 52154it [00:00, 118143.79it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  52%|█████▏    | 26117/50000 [00:00<00:00, 253784.76it/s]Drawing 50000 posterior samples: 51980it [00:00, 252195.46it/s]                           Drawing 50000 posterior samples: 51980it [00:00, 250600.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  16%|█▌        | 7989/50000 [00:00<00:00, 76411.72it/s]Drawing 50000 posterior samples:  32%|███▏      | 15904/50000 [00:00<00:00, 76197.52it/s]Drawing 50000 posterior samples:  48%|████▊     | 23917/50000 [00:00<00:00, 76204.72it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32021/50000 [00:00<00:00, 76616.59it/s]Drawing 50000 posterior samples:  80%|████████  | 40081/50000 [00:00<00:00, 76612.59it/s]Drawing 50000 posterior samples:  96%|█████████▌| 48013/50000 [00:00<00:00, 76491.66it/s]Drawing 50000 posterior samples: 52019it [00:00, 76395.99it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 32178/50000 [00:00<00:00, 311350.01it/s]Drawing 50000 posterior samples: 56392it [00:00, 310235.22it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  64%|██████▍   | 31921/50000 [00:00<00:00, 308782.11it/s]Drawing 50000 posterior samples: 55897it [00:00, 309003.94it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   5%|▍         | 2388/50000 [00:00<00:02, 22826.09it/s]Drawing 50000 posterior samples:   9%|▉         | 4716/50000 [00:00<00:01, 22721.26it/s]Drawing 50000 posterior samples:  14%|█▍        | 6972/50000 [00:00<00:01, 22473.43it/s]Drawing 50000 posterior samples:  18%|█▊        | 9234/50000 [00:00<00:01, 22319.44it/s]Drawing 50000 posterior samples:  23%|██▎       | 11452/50000 [00:00<00:01, 22007.31it/s]Drawing 50000 posterior samples:  28%|██▊       | 13808/50000 [00:00<00:01, 22166.66it/s]Drawing 50000 posterior samples:  32%|███▏      | 16011/50000 [00:00<00:01, 21857.72it/s]Drawing 50000 posterior samples:  37%|███▋      | 18280/50000 [00:00<00:01, 21811.88it/s]Drawing 50000 posterior samples:  41%|████      | 20530/50000 [00:00<00:01, 21778.67it/s]Drawing 50000 posterior samples:  46%|████▌     | 22874/50000 [00:01<00:01, 22061.15it/s]Drawing 50000 posterior samples:  50%|█████     | 25113/50000 [00:01<00:01, 21982.52it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27394/50000 [00:01<00:01, 22073.31it/s]Drawing 50000 posterior samples:  59%|█████▉    | 29653/50000 [00:01<00:00, 22043.01it/s]Drawing 50000 posterior samples:  64%|██████▍   | 31947/50000 [00:01<00:00, 22156.37it/s]Drawing 50000 posterior samples:  68%|██████▊   | 34240/50000 [00:01<00:00, 22206.20it/s]Drawing 50000 posterior samples:  73%|███████▎  | 36469/50000 [00:01<00:00, 22093.12it/s]Drawing 50000 posterior samples:  77%|███████▋  | 38728/50000 [00:01<00:00, 22081.62it/s]Drawing 50000 posterior samples:  82%|████████▏ | 40989/50000 [00:01<00:00, 22067.20it/s]Drawing 50000 posterior samples:  87%|████████▋ | 43305/50000 [00:01<00:00, 22122.29it/s]Drawing 50000 posterior samples:  91%|█████████▏| 45665/50000 [00:02<00:00, 22232.36it/s]Drawing 50000 posterior samples:  96%|█████████▌| 48053/50000 [00:02<00:00, 22392.55it/s]Drawing 50000 posterior samples: 50357it [00:02, 22289.42it/s]                           Drawing 50000 posterior samples: 50357it [00:02, 22117.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:   9%|▉         | 4508/50000 [00:00<00:01, 43328.73it/s]Drawing 50000 posterior samples:  18%|█▊        | 8970/50000 [00:00<00:00, 43170.51it/s]Drawing 50000 posterior samples:  27%|██▋       | 13386/50000 [00:00<00:00, 42864.22it/s]Drawing 50000 posterior samples:  35%|███▌      | 17730/50000 [00:00<00:00, 42496.08it/s]Drawing 50000 posterior samples:  45%|████▍     | 22268/50000 [00:00<00:00, 42759.49it/s]Drawing 50000 posterior samples:  54%|█████▎    | 26766/50000 [00:00<00:00, 42882.90it/s]Drawing 50000 posterior samples:  62%|██████▏   | 31198/50000 [00:00<00:00, 42952.24it/s]Drawing 50000 posterior samples:  71%|███████▏  | 35745/50000 [00:00<00:00, 43081.46it/s]Drawing 50000 posterior samples:  80%|████████  | 40204/50000 [00:00<00:00, 42879.40it/s]Drawing 50000 posterior samples:  89%|████████▉ | 44602/50000 [00:01<00:00, 42661.72it/s]Drawing 50000 posterior samples:  98%|█████████▊| 49046/50000 [00:01<00:00, 42668.01it/s]Drawing 50000 posterior samples: 50188it [00:01, 42754.24it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  37%|███▋      | 18419/50000 [00:00<00:00, 175754.24it/s]Drawing 50000 posterior samples:  74%|███████▍  | 37019/50000 [00:00<00:00, 176461.53it/s]Drawing 50000 posterior samples: 50928it [00:00, 176944.59it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  74%|███████▎  | 36764/50000 [00:00<00:00, 356377.12it/s]Drawing 50000 posterior samples: 55080it [00:00, 355270.20it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
30
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Neural network successfully converged after 186 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Neural network successfully converged after 207 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Neural network successfully converged after 371 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Neural network successfully converged after 187 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Neural network successfully converged after 303 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Neural network successfully converged after 254 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Neural network successfully converged after 361 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Neural network successfully converged after 234 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Neural network successfully converged after 249 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Neural network successfully converged after 362 epochs.
log prob true 3.3394768
log prob true 3.268328
log prob true 3.053334
log prob true 2.4346423
log prob true 2.9391572
log prob true 2.1164894
log prob true 2.220201
log prob true 3.5408862
log prob true 3.004475
log prob true 4.164752
log prob true 4.2448373
log prob true 3.369949
log prob true 2.5146673
log prob true 2.9709086
log prob true 2.217454
log prob true 3.4101167
log prob true 3.164788
log prob true 3.4204805
log prob true 1.3051597
log prob true 3.4154966
log prob true 0.55371654
log prob true 1.368463
log prob true 2.9820802
log prob true 3.2243612
log prob true 3.9230208
log prob true 2.9932742
log prob true 3.4446828
log prob true 3.7770152
log prob true 3.0648706
log prob true 1.7999359
log prob true 3.1770673
log prob true 3.1730464
log prob true 2.8366752
log prob true 2.5610693
log prob true 3.7712545
log prob true 3.0462718
log prob true 2.3480945
log prob true 3.4958842
log prob true 3.2653935
log prob true 4.2156224
log prob true 4.2103367
log prob true 3.134406
log prob true 2.4145107
log prob true 3.1267414
log prob true 2.0107832
log prob true 3.5896113
log prob true 3.4526212
log prob true 3.7127235
log prob true 1.2419343
log prob true 3.128547
log prob true -0.08380824
log prob true 1.407424
log prob true 2.9597287
log prob true 3.186857
log prob true 3.8313587
log prob true 2.873195
log prob true 3.983092
log prob true 3.832566
log prob true 3.549964
log prob true 1.9447107
log prob true 4.178068
log prob true 4.4204216
log prob true 3.8185656
log prob true 4.423228
log prob true 3.7397285
log prob true 4.261937
log prob true 4.05568
log prob true 4.7367845
log prob true 4.5505967
log prob true 4.6493573
log prob true 4.3509207
log prob true 4.432599
log prob true 4.014972
log prob true 4.0923934
log prob true 3.7718558
log prob true 5.027447
log prob true 5.1461396
log prob true 4.0553765
log prob true 4.038116
log prob true 4.392311
log prob true 0.9334277
log prob true 2.4366891
log prob true 4.590109
log prob true 3.8098912
log prob true 3.6943471
log prob true 4.2601056
log prob true 4.4234343
log prob true 4.4882026
log prob true 4.6810718
log prob true 3.9174626
log prob true 3.1855938
log prob true 3.3608248
log prob true 2.4126434
log prob true 2.2696555
log prob true 3.1844206
log prob true 2.532162
log prob true 2.305216
log prob true 3.538414
log prob true 2.9487672
log prob true 3.8569298
log prob true 3.6260457
log prob true 3.3936405
log prob true 2.6038218
log prob true 2.981606
log prob true 1.6518704
log prob true 3.0369632
log prob true 3.2878926
log prob true 2.9209325
log prob true 1.1655511
log prob true 3.3048346
log prob true 0.3494542
log prob true 1.0562136
log prob true 2.6254132
log prob true 3.2746658
log prob true 3.635638
log prob true 2.8189886
log prob true 3.2743802
log prob true 3.5010939
log prob true 3.260882
log prob true 1.7176918
log prob true 4.2326126
log prob true 4.310169
log prob true 3.8020625
log prob true 4.512425
log prob true 3.7899811
log prob true 4.162138
log prob true 4.078848
log prob true 4.6790347
log prob true 4.381908
log prob true 4.7991405
log prob true 4.665926
log prob true 4.5344243
log prob true 4.0054445
log prob true 4.3589916
log prob true 3.86257
log prob true 4.9057035
log prob true 5.037301
log prob true 3.5464172
log prob true 3.875303
log prob true 4.4394855
log prob true 1.5466393
log prob true 2.7290125
log prob true 4.4763646
log prob true 3.913122
log prob true 3.7717977
log prob true 4.2556863
log prob true 3.9988976
log prob true 4.3912416
log prob true 4.4435034
log prob true 3.8104792
log prob true 3.3921025
log prob true 3.490101
log prob true 2.8152206
log prob true 2.6857414
log prob true 3.0715928
log prob true 2.8860517
log prob true 2.584151
log prob true 3.4381962
log prob true 3.2591703
log prob true 4.0375185
log prob true 4.055388
log prob true 3.6501546
log prob true 2.6246595
log prob true 3.2958343
log prob true 1.9570385
log prob true 3.1584926
log prob true 3.517166
log prob true 3.6630046
log prob true 1.3645766
log prob true 3.5698383
log prob true 0.5281305
log prob true 1.4500958
log prob true 2.7442262
log prob true 3.5351088
log prob true 4.0085645
log prob true 3.287672
log prob true 3.7842255
log prob true 3.8167536
log prob true 2.9371157
log prob true 1.7220755
log prob true 4.0580897
log prob true 4.125842
log prob true 3.6694868
log prob true 4.4637704
log prob true 4.152136
log prob true 4.104015
log prob true 4.1135197
log prob true 5.021391
log prob true 4.6078954
log prob true 4.864414
log prob true 4.6180086
log prob true 4.52066
log prob true 4.2056465
log prob true 4.4171324
log prob true 4.127326
log prob true 4.6177697
log prob true 5.0530157
log prob true 4.266227
log prob true 3.86038
log prob true 4.500807
log prob true 1.9440367
log prob true 3.231103
log prob true 4.389578
log prob true 4.1863403
log prob true 3.782747
log prob true 4.2570467
log prob true 4.6636057
log prob true 4.6167407
log prob true 4.5865803
log prob true 3.8307996
log prob true 3.120489
log prob true 3.6393278
log prob true 2.849681
log prob true 2.5289562
log prob true 3.0459166
log prob true 1.6951865
log prob true 2.2821774
log prob true 3.6251934
log prob true 3.6340184
log prob true 4.0548477
log prob true 4.014051
log prob true 3.6363227
log prob true 2.5996573
log prob true 3.0630965
log prob true 2.098657
log prob true 3.0445476
log prob true 3.5317233
log prob true 4.141932
log prob true 1.2238677
log prob true 3.3912208
log prob true 0.23990372
log prob true 0.6060458
log prob true 2.6988008
log prob true 3.5441616
log prob true 4.1555486
log prob true 3.083257
log prob true 3.1946511
log prob true 3.7676113
log prob true 2.8193445
log prob true 1.7140876
log prob true 3.3121579
log prob true 3.4510646
log prob true 2.7888167
log prob true 2.4467506
log prob true 3.3762105
log prob true 2.2257159
log prob true 2.4546773
log prob true 3.6281283
log prob true 3.285653
log prob true 4.128812
log prob true 4.2731643
log prob true 3.5057793
log prob true 2.5344694
log prob true 3.12283
log prob true 2.093159
log prob true 3.4122312
log prob true 3.3882945
log prob true 3.426844
log prob true 1.1391947
log prob true 3.3869255
log prob true 0.708913
log prob true 1.1453474
log prob true 2.66722
log prob true 3.5073957
log prob true 4.056938
log prob true 3.0355885
log prob true 4.1944714
log prob true 4.0504217
log prob true 2.8964002
log prob true 1.8149055
log prob true 3.3853056
log prob true 3.5527408
log prob true 3.6456218
log prob true 2.4563901
log prob true 3.426222
log prob true 2.859951
log prob true 2.305839
log prob true 3.850194
log prob true 3.2807999
log prob true 4.4477887
log prob true 4.7518573
log prob true 3.5896788
log prob true 2.7112453
log prob true 3.0647297
log prob true 2.4584424
log prob true 3.8203156
log prob true 3.4822185
log prob true 3.9194036
log prob true 1.5576296
log prob true 3.6587243
log prob true -0.6043027
log prob true 1.5854971
log prob true 3.2519994
log prob true 3.7135804
log prob true 4.004414
log prob true 3.1394155
log prob true 4.18887
log prob true 4.1777883
log prob true 3.017019
log prob true 1.563156
script complete
