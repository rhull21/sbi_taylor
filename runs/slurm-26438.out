Loading parflow-ml/latest
  Loading requirement: openmpi/gcc/4.1.0 parflow/3.9.0 gdal/3.2.1
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/05_utils/sbiutils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(y_out)
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<00:34, 292.91it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<00:34, 292.34it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<00:33, 292.86it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<00:33, 293.41it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:33, 293.73it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:00<00:33, 294.71it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:00<00:33, 295.39it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:00<00:32, 296.10it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:00<00:32, 294.94it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:01<00:33, 293.78it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:01<00:32, 293.42it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:01<00:32, 293.80it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:32, 294.80it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:32, 295.31it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:01<00:32, 294.23it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:01<00:32, 295.01it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:01<00:32, 294.43it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:01<00:32, 295.21it/s]Running 10000 simulations.:   6%|▌         | 570/10000 [00:01<00:32, 292.26it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:02<00:32, 292.83it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:02<00:31, 293.54it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:02<00:31, 293.95it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:02<00:31, 293.85it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:02<00:31, 294.13it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:02<00:31, 293.91it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:02<00:31, 293.57it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:02<00:31, 292.94it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:02<00:31, 292.77it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:02<00:31, 293.62it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:31, 293.08it/s]Running 10000 simulations.:   9%|▉         | 930/10000 [00:03<00:31, 292.53it/s]Running 10000 simulations.:  10%|▉         | 960/10000 [00:03<00:31, 291.49it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:03<00:30, 291.96it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:03<00:30, 292.92it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:03<00:30, 292.79it/s]Running 10000 simulations.:  11%|█         | 1080/10000 [00:03<00:30, 292.47it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:03<00:30, 292.92it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:03<00:30, 293.43it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:03<00:30, 293.48it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:29, 293.67it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:04<00:29, 293.88it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:04<00:29, 293.77it/s]Running 10000 simulations.:  13%|█▎        | 1290/10000 [00:04<00:29, 294.68it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:04<00:29, 294.10it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:04<00:29, 293.60it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:04<00:29, 293.34it/s]Running 10000 simulations.:  14%|█▍        | 1410/10000 [00:04<00:29, 293.76it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:04<00:29, 293.31it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:05<00:29, 292.00it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:05<00:29, 292.41it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:05<00:28, 293.04it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:05<00:28, 293.44it/s]Running 10000 simulations.:  16%|█▌        | 1590/10000 [00:05<00:28, 294.21it/s]Running 10000 simulations.:  16%|█▌        | 1620/10000 [00:05<00:28, 294.82it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:05<00:28, 295.13it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:05<00:28, 294.72it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:05<00:28, 295.09it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:05<00:27, 295.12it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:06<00:27, 295.31it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:06<00:27, 295.01it/s]Running 10000 simulations.:  18%|█▊        | 1830/10000 [00:06<00:27, 294.12it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:06<00:27, 295.09it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:06<00:27, 295.15it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:06<00:27, 294.83it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:06<00:27, 295.30it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:06<00:27, 295.38it/s]Running 10000 simulations.:  20%|██        | 2010/10000 [00:06<00:27, 294.11it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:06<00:27, 293.64it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:07<00:27, 293.58it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:07<00:27, 292.28it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:07<00:26, 292.39it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:07<00:26, 293.59it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:07<00:26, 293.81it/s]Running 10000 simulations.:  22%|██▏       | 2220/10000 [00:07<00:26, 294.00it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:07<00:26, 294.78it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:07<00:26, 294.50it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:07<00:26, 294.07it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:07<00:26, 293.83it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:08<00:26, 293.22it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:08<00:25, 293.20it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:08<00:25, 293.07it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:08<00:25, 293.20it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:08<00:25, 293.75it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:08<00:25, 294.40it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:08<00:25, 294.75it/s]Running 10000 simulations.:  26%|██▌       | 2580/10000 [00:08<00:25, 294.93it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:08<00:25, 294.50it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:08<00:25, 294.15it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:09<00:24, 293.80it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:09<00:24, 294.36it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:09<00:24, 294.61it/s]Running 10000 simulations.:  28%|██▊       | 2760/10000 [00:09<00:24, 294.84it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:09<00:24, 294.66it/s]Running 10000 simulations.:  28%|██▊       | 2820/10000 [00:09<00:24, 295.15it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:09<00:24, 294.75it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:09<00:24, 294.43it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:09<00:24, 294.55it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:10<00:23, 294.24it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:10<00:23, 293.47it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:10<00:23, 293.60it/s]Running 10000 simulations.:  30%|███       | 3030/10000 [00:10<00:23, 293.39it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:10<00:23, 293.96it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:10<00:23, 294.40it/s]Running 10000 simulations.:  31%|███       | 3120/10000 [00:10<00:23, 294.55it/s]Running 10000 simulations.:  32%|███▏      | 3150/10000 [00:10<00:23, 293.79it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:10<00:23, 294.01it/s]Running 10000 simulations.:  32%|███▏      | 3210/10000 [00:10<00:23, 294.01it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:11<00:22, 293.97it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:11<00:22, 294.56it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:11<00:22, 294.92it/s]Running 10000 simulations.:  33%|███▎      | 3330/10000 [00:11<00:22, 294.73it/s]Running 10000 simulations.:  34%|███▎      | 3360/10000 [00:11<00:22, 294.26it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:11<00:22, 292.96it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:11<00:22, 292.82it/s]Running 10000 simulations.:  34%|███▍      | 3450/10000 [00:11<00:22, 293.30it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:11<00:22, 292.90it/s]Running 10000 simulations.:  35%|███▌      | 3510/10000 [00:11<00:22, 292.32it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:12<00:22, 292.38it/s]Running 10000 simulations.:  36%|███▌      | 3570/10000 [00:12<00:21, 292.87it/s]Running 10000 simulations.:  36%|███▌      | 3600/10000 [00:12<00:21, 292.49it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:12<00:21, 292.13it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:12<00:21, 292.10it/s]Running 10000 simulations.:  37%|███▋      | 3690/10000 [00:12<00:21, 292.67it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:12<00:21, 292.89it/s]Running 10000 simulations.:  38%|███▊      | 3750/10000 [00:12<00:21, 293.18it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:12<00:21, 293.68it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:12<00:21, 291.48it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:13<00:21, 292.10it/s]Running 10000 simulations.:  39%|███▊      | 3870/10000 [00:13<00:20, 292.74it/s]Running 10000 simulations.:  39%|███▉      | 3900/10000 [00:13<00:20, 292.39it/s]Running 10000 simulations.:  39%|███▉      | 3930/10000 [00:13<00:20, 291.86it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:13<00:20, 292.36it/s]Running 10000 simulations.:  40%|███▉      | 3990/10000 [00:13<00:20, 292.75it/s]Running 10000 simulations.:  40%|████      | 4020/10000 [00:13<00:20, 292.44it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:13<00:20, 291.91it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:13<00:20, 292.40it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:13<00:20, 292.80it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:14<00:19, 293.27it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:14<00:19, 292.84it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:14<00:19, 293.45it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:14<00:19, 293.24it/s]Running 10000 simulations.:  43%|████▎     | 4260/10000 [00:14<00:19, 293.56it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:14<00:19, 293.15it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:14<00:19, 292.98it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:14<00:19, 293.65it/s]Running 10000 simulations.:  44%|████▍     | 4380/10000 [00:14<00:19, 293.30it/s]Running 10000 simulations.:  44%|████▍     | 4410/10000 [00:15<00:19, 293.40it/s]Running 10000 simulations.:  44%|████▍     | 4440/10000 [00:15<00:18, 292.81it/s]Running 10000 simulations.:  45%|████▍     | 4470/10000 [00:15<00:18, 292.37it/s]Running 10000 simulations.:  45%|████▌     | 4500/10000 [00:15<00:18, 292.87it/s]Running 10000 simulations.:  45%|████▌     | 4530/10000 [00:15<00:18, 292.65it/s]Running 10000 simulations.:  46%|████▌     | 4560/10000 [00:15<00:18, 292.15it/s]Running 10000 simulations.:  46%|████▌     | 4590/10000 [00:15<00:18, 291.48it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:15<00:18, 292.22it/s]Running 10000 simulations.:  46%|████▋     | 4650/10000 [00:15<00:18, 292.78it/s]Running 10000 simulations.:  47%|████▋     | 4680/10000 [00:15<00:18, 292.45it/s]Running 10000 simulations.:  47%|████▋     | 4710/10000 [00:16<00:18, 292.79it/s]Running 10000 simulations.:  47%|████▋     | 4740/10000 [00:16<00:17, 293.07it/s]Running 10000 simulations.:  48%|████▊     | 4770/10000 [00:16<00:17, 293.58it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:16<00:17, 293.41it/s]Running 10000 simulations.:  48%|████▊     | 4830/10000 [00:16<00:17, 293.92it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:16<00:17, 293.98it/s]Running 10000 simulations.:  49%|████▉     | 4890/10000 [00:16<00:17, 291.75it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:16<00:17, 292.14it/s]Running 10000 simulations.:  50%|████▉     | 4950/10000 [00:16<00:17, 292.33it/s]Running 10000 simulations.:  50%|████▉     | 4980/10000 [00:16<00:17, 292.28it/s]Running 10000 simulations.:  50%|█████     | 5010/10000 [00:17<00:17, 293.07it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:17<00:16, 294.06it/s]Running 10000 simulations.:  51%|█████     | 5070/10000 [00:17<00:16, 294.32it/s]Running 10000 simulations.:  51%|█████     | 5100/10000 [00:17<00:16, 293.41it/s]Running 10000 simulations.:  51%|█████▏    | 5130/10000 [00:17<00:16, 293.13it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:17<00:16, 292.38it/s]Running 10000 simulations.:  52%|█████▏    | 5190/10000 [00:17<00:16, 293.37it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:17<00:16, 293.75it/s]Running 10000 simulations.:  52%|█████▎    | 5250/10000 [00:17<00:16, 294.29it/s]Running 10000 simulations.:  53%|█████▎    | 5280/10000 [00:17<00:16, 294.67it/s]Running 10000 simulations.:  53%|█████▎    | 5310/10000 [00:18<00:15, 294.76it/s]Running 10000 simulations.:  53%|█████▎    | 5340/10000 [00:18<00:15, 293.85it/s]Running 10000 simulations.:  54%|█████▎    | 5370/10000 [00:18<00:15, 293.67it/s]Running 10000 simulations.:  54%|█████▍    | 5400/10000 [00:18<00:15, 294.15it/s]Running 10000 simulations.:  54%|█████▍    | 5430/10000 [00:18<00:15, 293.62it/s]Running 10000 simulations.:  55%|█████▍    | 5460/10000 [00:18<00:15, 293.25it/s]Running 10000 simulations.:  55%|█████▍    | 5490/10000 [00:18<00:15, 293.84it/s]Running 10000 simulations.:  55%|█████▌    | 5520/10000 [00:18<00:15, 294.12it/s]Running 10000 simulations.:  56%|█████▌    | 5550/10000 [00:18<00:15, 293.79it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:19<00:15, 294.27it/s]Running 10000 simulations.:  56%|█████▌    | 5610/10000 [00:19<00:14, 294.43it/s]Running 10000 simulations.:  56%|█████▋    | 5640/10000 [00:19<00:14, 294.54it/s]Running 10000 simulations.:  57%|█████▋    | 5670/10000 [00:19<00:14, 293.77it/s]Running 10000 simulations.:  57%|█████▋    | 5700/10000 [00:19<00:14, 293.36it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:19<00:14, 293.21it/s]Running 10000 simulations.:  58%|█████▊    | 5760/10000 [00:19<00:14, 293.03it/s]Running 10000 simulations.:  58%|█████▊    | 5790/10000 [00:19<00:14, 293.05it/s]Running 10000 simulations.:  58%|█████▊    | 5820/10000 [00:19<00:14, 292.28it/s]Running 10000 simulations.:  58%|█████▊    | 5850/10000 [00:19<00:14, 292.31it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:20<00:14, 292.56it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:20<00:13, 292.18it/s]Running 10000 simulations.:  59%|█████▉    | 5940/10000 [00:20<00:13, 292.24it/s]Running 10000 simulations.:  60%|█████▉    | 5970/10000 [00:20<00:13, 292.12it/s]Running 10000 simulations.:  60%|██████    | 6000/10000 [00:20<00:13, 292.65it/s]Running 10000 simulations.:  60%|██████    | 6030/10000 [00:20<00:13, 292.14it/s]Running 10000 simulations.:  61%|██████    | 6060/10000 [00:20<00:13, 292.53it/s]Running 10000 simulations.:  61%|██████    | 6090/10000 [00:20<00:13, 292.39it/s]Running 10000 simulations.:  61%|██████    | 6120/10000 [00:20<00:13, 292.66it/s]Running 10000 simulations.:  62%|██████▏   | 6150/10000 [00:20<00:13, 293.00it/s]Running 10000 simulations.:  62%|██████▏   | 6180/10000 [00:21<00:13, 293.74it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:21<00:12, 293.86it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:21<00:12, 294.03it/s]Running 10000 simulations.:  63%|██████▎   | 6270/10000 [00:21<00:12, 293.83it/s]Running 10000 simulations.:  63%|██████▎   | 6300/10000 [00:21<00:12, 293.35it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:21<00:12, 290.26it/s]Running 10000 simulations.:  64%|██████▎   | 6360/10000 [00:21<00:12, 291.16it/s]Running 10000 simulations.:  64%|██████▍   | 6390/10000 [00:21<00:12, 291.67it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:21<00:12, 291.98it/s]Running 10000 simulations.:  64%|██████▍   | 6450/10000 [00:21<00:12, 292.78it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:22<00:12, 292.72it/s]Running 10000 simulations.:  65%|██████▌   | 6510/10000 [00:22<00:11, 292.73it/s]Running 10000 simulations.:  65%|██████▌   | 6540/10000 [00:22<00:11, 292.30it/s]Running 10000 simulations.:  66%|██████▌   | 6570/10000 [00:22<00:11, 292.36it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:22<00:11, 292.29it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:22<00:11, 292.93it/s]Running 10000 simulations.:  67%|██████▋   | 6660/10000 [00:22<00:11, 293.69it/s]Running 10000 simulations.:  67%|██████▋   | 6690/10000 [00:22<00:11, 293.59it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:22<00:11, 293.53it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:23<00:11, 293.59it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:23<00:10, 294.29it/s]Running 10000 simulations.:  68%|██████▊   | 6810/10000 [00:23<00:10, 294.70it/s]Running 10000 simulations.:  68%|██████▊   | 6840/10000 [00:23<00:10, 294.20it/s]Running 10000 simulations.:  69%|██████▊   | 6870/10000 [00:23<00:10, 293.07it/s]Running 10000 simulations.:  69%|██████▉   | 6900/10000 [00:23<00:10, 292.55it/s]Running 10000 simulations.:  69%|██████▉   | 6930/10000 [00:23<00:10, 293.21it/s]Running 10000 simulations.:  70%|██████▉   | 6960/10000 [00:23<00:10, 293.68it/s]Running 10000 simulations.:  70%|██████▉   | 6990/10000 [00:23<00:10, 293.54it/s]Running 10000 simulations.:  70%|███████   | 7020/10000 [00:23<00:10, 293.09it/s]Running 10000 simulations.:  70%|███████   | 7050/10000 [00:24<00:10, 292.67it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:24<00:09, 292.59it/s]Running 10000 simulations.:  71%|███████   | 7110/10000 [00:24<00:09, 293.25it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:24<00:09, 293.60it/s]Running 10000 simulations.:  72%|███████▏  | 7170/10000 [00:24<00:09, 294.39it/s]Running 10000 simulations.:  72%|███████▏  | 7200/10000 [00:24<00:09, 294.30it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:24<00:09, 293.52it/s]Running 10000 simulations.:  73%|███████▎  | 7260/10000 [00:24<00:09, 292.98it/s]Running 10000 simulations.:  73%|███████▎  | 7290/10000 [00:24<00:09, 292.43it/s]Running 10000 simulations.:  73%|███████▎  | 7320/10000 [00:24<00:09, 293.04it/s]Running 10000 simulations.:  74%|███████▎  | 7350/10000 [00:25<00:09, 292.49it/s]Running 10000 simulations.:  74%|███████▍  | 7380/10000 [00:25<00:08, 292.23it/s]Running 10000 simulations.:  74%|███████▍  | 7410/10000 [00:25<00:08, 292.43it/s]Running 10000 simulations.:  74%|███████▍  | 7440/10000 [00:25<00:08, 293.54it/s]Running 10000 simulations.:  75%|███████▍  | 7470/10000 [00:25<00:08, 293.81it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:25<00:08, 293.45it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:25<00:08, 292.92it/s]Running 10000 simulations.:  76%|███████▌  | 7560/10000 [00:25<00:08, 292.29it/s]Running 10000 simulations.:  76%|███████▌  | 7590/10000 [00:25<00:08, 292.40it/s]Running 10000 simulations.:  76%|███████▌  | 7620/10000 [00:25<00:08, 292.64it/s]Running 10000 simulations.:  76%|███████▋  | 7650/10000 [00:26<00:08, 293.27it/s]Running 10000 simulations.:  77%|███████▋  | 7680/10000 [00:26<00:07, 293.27it/s]Running 10000 simulations.:  77%|███████▋  | 7710/10000 [00:26<00:07, 293.61it/s]Running 10000 simulations.:  77%|███████▋  | 7740/10000 [00:26<00:07, 294.43it/s]Running 10000 simulations.:  78%|███████▊  | 7770/10000 [00:26<00:07, 293.73it/s]Running 10000 simulations.:  78%|███████▊  | 7800/10000 [00:26<00:07, 293.40it/s]Running 10000 simulations.:  78%|███████▊  | 7830/10000 [00:26<00:07, 292.60it/s]Running 10000 simulations.:  79%|███████▊  | 7860/10000 [00:26<00:07, 293.66it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:26<00:07, 294.23it/s]Running 10000 simulations.:  79%|███████▉  | 7920/10000 [00:26<00:07, 294.30it/s]Running 10000 simulations.:  80%|███████▉  | 7950/10000 [00:27<00:06, 294.01it/s]Running 10000 simulations.:  80%|███████▉  | 7980/10000 [00:27<00:06, 294.81it/s]Running 10000 simulations.:  80%|████████  | 8010/10000 [00:27<00:06, 295.02it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:27<00:06, 292.14it/s]Running 10000 simulations.:  81%|████████  | 8070/10000 [00:27<00:06, 292.53it/s]Running 10000 simulations.:  81%|████████  | 8100/10000 [00:27<00:06, 293.19it/s]Running 10000 simulations.:  81%|████████▏ | 8130/10000 [00:27<00:06, 293.65it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:27<00:06, 293.19it/s]Running 10000 simulations.:  82%|████████▏ | 8190/10000 [00:27<00:06, 284.25it/s]Running 10000 simulations.:  82%|████████▏ | 8220/10000 [00:28<00:06, 286.75it/s]Running 10000 simulations.:  82%|████████▎ | 8250/10000 [00:28<00:06, 288.89it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:28<00:05, 289.74it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:28<00:05, 291.20it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:28<00:05, 290.54it/s]Running 10000 simulations.:  84%|████████▎ | 8370/10000 [00:28<00:05, 291.76it/s]Running 10000 simulations.:  84%|████████▍ | 8400/10000 [00:28<00:05, 292.64it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:28<00:05, 293.56it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:28<00:05, 293.39it/s]Running 10000 simulations.:  85%|████████▍ | 8490/10000 [00:28<00:05, 293.95it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:29<00:05, 294.48it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:29<00:04, 294.74it/s]Running 10000 simulations.:  86%|████████▌ | 8580/10000 [00:29<00:04, 294.12it/s]Running 10000 simulations.:  86%|████████▌ | 8610/10000 [00:29<00:04, 293.21it/s]Running 10000 simulations.:  86%|████████▋ | 8640/10000 [00:29<00:04, 292.41it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [00:29<00:04, 292.67it/s]Running 10000 simulations.:  87%|████████▋ | 8700/10000 [00:29<00:04, 292.90it/s]Running 10000 simulations.:  87%|████████▋ | 8730/10000 [00:29<00:04, 292.47it/s]Running 10000 simulations.:  88%|████████▊ | 8760/10000 [00:29<00:04, 292.34it/s]Running 10000 simulations.:  88%|████████▊ | 8790/10000 [00:29<00:04, 291.82it/s]Running 10000 simulations.:  88%|████████▊ | 8820/10000 [00:30<00:04, 291.80it/s]Running 10000 simulations.:  88%|████████▊ | 8850/10000 [00:30<00:03, 292.18it/s]Running 10000 simulations.:  89%|████████▉ | 8880/10000 [00:30<00:03, 291.79it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [00:30<00:03, 291.93it/s]Running 10000 simulations.:  89%|████████▉ | 8940/10000 [00:30<00:03, 291.65it/s]Running 10000 simulations.:  90%|████████▉ | 8970/10000 [00:30<00:03, 292.13it/s]Running 10000 simulations.:  90%|█████████ | 9000/10000 [00:30<00:03, 292.35it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:30<00:04, 239.08it/s]Running 10000 simulations.:  91%|█████████ | 9059/10000 [00:30<00:03, 252.02it/s]Running 10000 simulations.:  91%|█████████ | 9089/10000 [00:31<00:03, 262.73it/s]Running 10000 simulations.:  91%|█████████ | 9119/10000 [00:31<00:03, 271.71it/s]Running 10000 simulations.:  91%|█████████▏| 9149/10000 [00:31<00:03, 277.33it/s]Running 10000 simulations.:  92%|█████████▏| 9179/10000 [00:31<00:02, 281.32it/s]Running 10000 simulations.:  92%|█████████▏| 9209/10000 [00:31<00:02, 285.13it/s]Running 10000 simulations.:  92%|█████████▏| 9239/10000 [00:31<00:02, 287.88it/s]Running 10000 simulations.:  93%|█████████▎| 9269/10000 [00:31<00:02, 289.79it/s]Running 10000 simulations.:  93%|█████████▎| 9299/10000 [00:31<00:02, 291.04it/s]Running 10000 simulations.:  93%|█████████▎| 9329/10000 [00:31<00:02, 290.93it/s]Running 10000 simulations.:  94%|█████████▎| 9359/10000 [00:31<00:02, 290.99it/s]Running 10000 simulations.:  94%|█████████▍| 9389/10000 [00:32<00:02, 291.18it/s]Running 10000 simulations.:  94%|█████████▍| 9419/10000 [00:32<00:01, 292.13it/s]Running 10000 simulations.:  94%|█████████▍| 9449/10000 [00:32<00:01, 292.39it/s]Running 10000 simulations.:  95%|█████████▍| 9479/10000 [00:32<00:01, 292.33it/s]Running 10000 simulations.:  95%|█████████▌| 9509/10000 [00:32<00:01, 293.36it/s]Running 10000 simulations.:  95%|█████████▌| 9539/10000 [00:32<00:01, 292.65it/s]Running 10000 simulations.:  96%|█████████▌| 9569/10000 [00:32<00:01, 292.87it/s]Running 10000 simulations.:  96%|█████████▌| 9599/10000 [00:32<00:01, 293.21it/s]Running 10000 simulations.:  96%|█████████▋| 9629/10000 [00:32<00:01, 292.75it/s]Running 10000 simulations.:  97%|█████████▋| 9659/10000 [00:33<00:01, 293.06it/s]Running 10000 simulations.:  97%|█████████▋| 9689/10000 [00:33<00:01, 292.90it/s]Running 10000 simulations.:  97%|█████████▋| 9719/10000 [00:33<00:00, 293.01it/s]Running 10000 simulations.:  97%|█████████▋| 9749/10000 [00:33<00:00, 293.25it/s]Running 10000 simulations.:  98%|█████████▊| 9779/10000 [00:33<00:00, 294.02it/s]Running 10000 simulations.:  98%|█████████▊| 9809/10000 [00:33<00:00, 293.57it/s]Running 10000 simulations.:  98%|█████████▊| 9839/10000 [00:33<00:00, 293.79it/s]Running 10000 simulations.:  99%|█████████▊| 9869/10000 [00:33<00:00, 293.80it/s]Running 10000 simulations.:  99%|█████████▉| 9899/10000 [00:33<00:00, 293.66it/s]Running 10000 simulations.:  99%|█████████▉| 9929/10000 [00:33<00:00, 293.88it/s]Running 10000 simulations.: 100%|█████████▉| 9959/10000 [00:34<00:00, 293.84it/s]Running 10000 simulations.: 100%|█████████▉| 9989/10000 [00:34<00:00, 294.37it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:34<00:00, 292.60it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<00:33, 296.17it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<00:33, 296.35it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<00:33, 296.04it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<00:33, 295.64it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:33, 295.84it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:00<00:33, 295.74it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:00<00:33, 295.13it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:00<00:33, 295.75it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:00<00:32, 295.72it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:01<00:32, 294.26it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:01<00:32, 293.15it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:01<00:32, 292.48it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:32, 292.87it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:32, 292.37it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:01<00:32, 292.65it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:01<00:32, 293.04it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:01<00:32, 292.73it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:01<00:32, 293.51it/s]Running 10000 simulations.:   6%|▌         | 570/10000 [00:01<00:32, 293.61it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:02<00:31, 293.88it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:02<00:31, 294.51it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:02<00:31, 295.07it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:02<00:31, 295.49it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:02<00:31, 295.85it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:02<00:31, 296.18it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:02<00:31, 295.56it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:02<00:31, 294.76it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:02<00:31, 294.55it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:02<00:31, 293.26it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:31, 292.97it/s]Running 10000 simulations.:   9%|▉         | 930/10000 [00:03<00:30, 293.06it/s]Running 10000 simulations.:  10%|▉         | 960/10000 [00:03<00:30, 293.58it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:03<00:30, 294.42it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:03<00:30, 295.19it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:03<00:30, 295.82it/s]Running 10000 simulations.:  11%|█         | 1080/10000 [00:03<00:30, 296.21it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:03<00:29, 296.54it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:03<00:29, 296.62it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:03<00:29, 296.69it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:29, 296.78it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:04<00:29, 295.94it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:04<00:29, 296.01it/s]Running 10000 simulations.:  13%|█▎        | 1290/10000 [00:04<00:29, 296.23it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:04<00:29, 296.36it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:04<00:29, 296.59it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:04<00:29, 296.28it/s]Running 10000 simulations.:  14%|█▍        | 1410/10000 [00:04<00:28, 296.32it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:04<00:28, 295.82it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:04<00:28, 295.36it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:05<00:28, 294.60it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:05<00:28, 294.69it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:05<00:28, 294.46it/s]Running 10000 simulations.:  16%|█▌        | 1590/10000 [00:05<00:28, 293.17it/s]Running 10000 simulations.:  16%|█▌        | 1620/10000 [00:05<00:28, 292.28it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:05<00:28, 292.28it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:05<00:28, 292.23it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:05<00:28, 293.17it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:05<00:28, 293.67it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:06<00:27, 294.32it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:06<00:27, 294.77it/s]Running 10000 simulations.:  18%|█▊        | 1830/10000 [00:06<00:27, 293.51it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:06<00:27, 293.88it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:06<00:27, 294.25it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:06<00:27, 294.41it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:06<00:27, 295.04it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:06<00:27, 294.80it/s]Running 10000 simulations.:  20%|██        | 2010/10000 [00:06<00:27, 295.10it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:06<00:27, 293.73it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:07<00:27, 292.42it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:07<00:26, 292.94it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:07<00:26, 293.92it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:07<00:26, 294.51it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:07<00:26, 294.39it/s]Running 10000 simulations.:  22%|██▏       | 2220/10000 [00:07<00:26, 295.02it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:07<00:26, 295.49it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:07<00:26, 295.71it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:07<00:26, 295.59it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:07<00:25, 295.82it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:08<00:25, 295.97it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:08<00:25, 296.04it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:08<00:25, 296.12it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:08<00:25, 296.21it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:08<00:25, 296.20it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:08<00:25, 295.92it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:08<00:25, 296.15it/s]Running 10000 simulations.:  26%|██▌       | 2580/10000 [00:08<00:25, 296.19it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:08<00:25, 294.60it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:08<00:24, 295.12it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:09<00:24, 295.62it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:09<00:24, 295.58it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:09<00:24, 294.17it/s]Running 10000 simulations.:  28%|██▊       | 2760/10000 [00:09<00:24, 294.44it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:09<00:24, 293.21it/s]Running 10000 simulations.:  28%|██▊       | 2820/10000 [00:09<00:24, 293.79it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:09<00:24, 292.55it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:09<00:24, 292.29it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:09<00:24, 291.63it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:09<00:24, 291.82it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:10<00:24, 292.06it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:10<00:24, 291.18it/s]Running 10000 simulations.:  30%|███       | 3030/10000 [00:10<00:23, 290.69it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:10<00:23, 290.86it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:10<00:23, 291.68it/s]Running 10000 simulations.:  31%|███       | 3120/10000 [00:10<00:23, 292.93it/s]Running 10000 simulations.:  32%|███▏      | 3150/10000 [00:10<00:23, 293.62it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:10<00:23, 294.12it/s]Running 10000 simulations.:  32%|███▏      | 3210/10000 [00:10<00:23, 294.78it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:11<00:22, 295.29it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:11<00:22, 295.36it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:11<00:22, 293.69it/s]Running 10000 simulations.:  33%|███▎      | 3330/10000 [00:11<00:22, 293.69it/s]Running 10000 simulations.:  34%|███▎      | 3360/10000 [00:11<00:22, 293.64it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:11<00:22, 294.03it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:11<00:22, 294.25it/s]Running 10000 simulations.:  34%|███▍      | 3450/10000 [00:11<00:22, 294.84it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:11<00:22, 295.27it/s]Running 10000 simulations.:  35%|███▌      | 3510/10000 [00:11<00:21, 295.56it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:12<00:21, 295.83it/s]Running 10000 simulations.:  36%|███▌      | 3570/10000 [00:12<00:21, 295.68it/s]Running 10000 simulations.:  36%|███▌      | 3600/10000 [00:12<00:21, 294.92it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:12<00:21, 294.10it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:12<00:21, 293.48it/s]Running 10000 simulations.:  37%|███▋      | 3690/10000 [00:12<00:21, 293.81it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:12<00:21, 294.45it/s]Running 10000 simulations.:  38%|███▊      | 3750/10000 [00:12<00:21, 295.04it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:12<00:21, 295.09it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:12<00:20, 295.23it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:13<00:20, 295.17it/s]Running 10000 simulations.:  39%|███▊      | 3870/10000 [00:13<00:20, 295.19it/s]Running 10000 simulations.:  39%|███▉      | 3900/10000 [00:13<00:20, 293.30it/s]Running 10000 simulations.:  39%|███▉      | 3930/10000 [00:13<00:20, 292.74it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:13<00:20, 291.65it/s]Running 10000 simulations.:  40%|███▉      | 3990/10000 [00:13<00:20, 291.18it/s]Running 10000 simulations.:  40%|████      | 4020/10000 [00:13<00:20, 291.72it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:13<00:20, 292.61it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:13<00:20, 292.87it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:13<00:20, 293.08it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:14<00:19, 293.96it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:14<00:19, 294.25it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:14<00:19, 293.85it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:14<00:19, 294.65it/s]Running 10000 simulations.:  43%|████▎     | 4260/10000 [00:14<00:19, 295.09it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:14<00:19, 295.63it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:14<00:19, 295.94it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:14<00:19, 296.20it/s]Running 10000 simulations.:  44%|████▍     | 4380/10000 [00:14<00:18, 296.20it/s]Running 10000 simulations.:  44%|████▍     | 4410/10000 [00:14<00:18, 294.83it/s]Running 10000 simulations.:  44%|████▍     | 4440/10000 [00:15<00:18, 294.41it/s]Running 10000 simulations.:  45%|████▍     | 4470/10000 [00:15<00:18, 294.93it/s]Running 10000 simulations.:  45%|████▌     | 4500/10000 [00:15<00:18, 295.26it/s]Running 10000 simulations.:  45%|████▌     | 4530/10000 [00:15<00:18, 294.80it/s]Running 10000 simulations.:  46%|████▌     | 4560/10000 [00:15<00:18, 295.39it/s]Running 10000 simulations.:  46%|████▌     | 4590/10000 [00:15<00:18, 295.88it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:15<00:18, 295.12it/s]Running 10000 simulations.:  46%|████▋     | 4650/10000 [00:15<00:18, 294.46it/s]Running 10000 simulations.:  47%|████▋     | 4680/10000 [00:15<00:18, 294.31it/s]Running 10000 simulations.:  47%|████▋     | 4710/10000 [00:15<00:17, 294.90it/s]Running 10000 simulations.:  47%|████▋     | 4740/10000 [00:16<00:17, 295.28it/s]Running 10000 simulations.:  48%|████▊     | 4770/10000 [00:16<00:17, 295.37it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:16<00:17, 295.60it/s]Running 10000 simulations.:  48%|████▊     | 4830/10000 [00:16<00:17, 295.68it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:16<00:17, 294.89it/s]Running 10000 simulations.:  49%|████▉     | 4890/10000 [00:16<00:17, 293.95it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:16<00:17, 293.99it/s]Running 10000 simulations.:  50%|████▉     | 4950/10000 [00:16<00:17, 293.71it/s]Running 10000 simulations.:  50%|████▉     | 4980/10000 [00:16<00:17, 294.39it/s]Running 10000 simulations.:  50%|█████     | 5010/10000 [00:17<00:17, 291.85it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:17<00:16, 291.79it/s]Running 10000 simulations.:  51%|█████     | 5070/10000 [00:17<00:16, 292.26it/s]Running 10000 simulations.:  51%|█████     | 5100/10000 [00:17<00:16, 291.40it/s]Running 10000 simulations.:  51%|█████▏    | 5130/10000 [00:17<00:16, 291.25it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:17<00:16, 291.70it/s]Running 10000 simulations.:  52%|█████▏    | 5190/10000 [00:17<00:16, 291.95it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:17<00:16, 292.53it/s]Running 10000 simulations.:  52%|█████▎    | 5250/10000 [00:17<00:16, 292.89it/s]Running 10000 simulations.:  53%|█████▎    | 5280/10000 [00:17<00:16, 292.83it/s]Running 10000 simulations.:  53%|█████▎    | 5310/10000 [00:18<00:16, 292.03it/s]Running 10000 simulations.:  53%|█████▎    | 5340/10000 [00:18<00:15, 292.09it/s]Running 10000 simulations.:  54%|█████▎    | 5370/10000 [00:18<00:15, 292.57it/s]Running 10000 simulations.:  54%|█████▍    | 5400/10000 [00:18<00:15, 293.02it/s]Running 10000 simulations.:  54%|█████▍    | 5430/10000 [00:18<00:15, 294.01it/s]Running 10000 simulations.:  55%|█████▍    | 5460/10000 [00:18<00:15, 293.75it/s]Running 10000 simulations.:  55%|█████▍    | 5490/10000 [00:18<00:15, 294.08it/s]Running 10000 simulations.:  55%|█████▌    | 5520/10000 [00:18<00:15, 294.89it/s]Running 10000 simulations.:  56%|█████▌    | 5550/10000 [00:18<00:15, 295.34it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:18<00:14, 295.73it/s]Running 10000 simulations.:  56%|█████▌    | 5610/10000 [00:19<00:14, 295.90it/s]Running 10000 simulations.:  56%|█████▋    | 5640/10000 [00:19<00:14, 296.22it/s]Running 10000 simulations.:  57%|█████▋    | 5670/10000 [00:19<00:14, 296.24it/s]Running 10000 simulations.:  57%|█████▋    | 5700/10000 [00:19<00:14, 296.36it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:19<00:14, 295.13it/s]Running 10000 simulations.:  58%|█████▊    | 5760/10000 [00:19<00:14, 294.32it/s]Running 10000 simulations.:  58%|█████▊    | 5790/10000 [00:19<00:14, 294.12it/s]Running 10000 simulations.:  58%|█████▊    | 5820/10000 [00:19<00:14, 294.61it/s]Running 10000 simulations.:  58%|█████▊    | 5850/10000 [00:19<00:14, 295.11it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:19<00:13, 295.49it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:20<00:13, 294.03it/s]Running 10000 simulations.:  59%|█████▉    | 5940/10000 [00:20<00:13, 293.51it/s]Running 10000 simulations.:  60%|█████▉    | 5970/10000 [00:20<00:13, 293.12it/s]Running 10000 simulations.:  60%|██████    | 6000/10000 [00:20<00:13, 293.97it/s]Running 10000 simulations.:  60%|██████    | 6030/10000 [00:20<00:13, 293.47it/s]Running 10000 simulations.:  61%|██████    | 6060/10000 [00:20<00:13, 294.15it/s]Running 10000 simulations.:  61%|██████    | 6090/10000 [00:20<00:13, 294.34it/s]Running 10000 simulations.:  61%|██████    | 6120/10000 [00:20<00:13, 294.53it/s]Running 10000 simulations.:  62%|██████▏   | 6150/10000 [00:20<00:13, 293.71it/s]Running 10000 simulations.:  62%|██████▏   | 6180/10000 [00:20<00:12, 294.47it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:21<00:12, 294.48it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:21<00:12, 293.83it/s]Running 10000 simulations.:  63%|██████▎   | 6270/10000 [00:21<00:12, 293.44it/s]Running 10000 simulations.:  63%|██████▎   | 6300/10000 [00:21<00:12, 292.56it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:21<00:12, 292.64it/s]Running 10000 simulations.:  64%|██████▎   | 6360/10000 [00:21<00:12, 292.62it/s]Running 10000 simulations.:  64%|██████▍   | 6390/10000 [00:21<00:12, 293.65it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:21<00:12, 293.90it/s]Running 10000 simulations.:  64%|██████▍   | 6450/10000 [00:21<00:12, 293.53it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:22<00:11, 294.36it/s]Running 10000 simulations.:  65%|██████▌   | 6510/10000 [00:22<00:11, 294.91it/s]Running 10000 simulations.:  65%|██████▌   | 6540/10000 [00:22<00:11, 293.53it/s]Running 10000 simulations.:  66%|██████▌   | 6570/10000 [00:22<00:11, 294.00it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:22<00:11, 294.47it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:22<00:11, 295.06it/s]Running 10000 simulations.:  67%|██████▋   | 6660/10000 [00:22<00:11, 295.51it/s]Running 10000 simulations.:  67%|██████▋   | 6690/10000 [00:22<00:11, 295.57it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:22<00:11, 295.97it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:22<00:10, 296.10it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:23<00:10, 296.35it/s]Running 10000 simulations.:  68%|██████▊   | 6810/10000 [00:23<00:10, 296.28it/s]Running 10000 simulations.:  68%|██████▊   | 6840/10000 [00:23<00:10, 294.97it/s]Running 10000 simulations.:  69%|██████▊   | 6870/10000 [00:23<00:10, 294.79it/s]Running 10000 simulations.:  69%|██████▉   | 6900/10000 [00:23<00:10, 295.16it/s]Running 10000 simulations.:  69%|██████▉   | 6930/10000 [00:23<00:10, 295.34it/s]Running 10000 simulations.:  70%|██████▉   | 6960/10000 [00:23<00:10, 295.74it/s]Running 10000 simulations.:  70%|██████▉   | 6990/10000 [00:23<00:10, 295.91it/s]Running 10000 simulations.:  70%|███████   | 7020/10000 [00:23<00:10, 294.88it/s]Running 10000 simulations.:  70%|███████   | 7050/10000 [00:23<00:10, 293.80it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:24<00:09, 293.86it/s]Running 10000 simulations.:  71%|███████   | 7110/10000 [00:24<00:09, 294.25it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:24<00:09, 294.21it/s]Running 10000 simulations.:  72%|███████▏  | 7170/10000 [00:24<00:09, 294.69it/s]Running 10000 simulations.:  72%|███████▏  | 7200/10000 [00:24<00:09, 294.39it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:24<00:09, 294.83it/s]Running 10000 simulations.:  73%|███████▎  | 7260/10000 [00:24<00:09, 294.72it/s]Running 10000 simulations.:  73%|███████▎  | 7290/10000 [00:24<00:09, 294.55it/s]Running 10000 simulations.:  73%|███████▎  | 7320/10000 [00:24<00:09, 293.26it/s]Running 10000 simulations.:  74%|███████▎  | 7350/10000 [00:24<00:09, 293.08it/s]Running 10000 simulations.:  74%|███████▍  | 7380/10000 [00:25<00:08, 293.89it/s]Running 10000 simulations.:  74%|███████▍  | 7410/10000 [00:25<00:08, 294.51it/s]Running 10000 simulations.:  74%|███████▍  | 7440/10000 [00:25<00:08, 293.24it/s]Running 10000 simulations.:  75%|███████▍  | 7470/10000 [00:25<00:08, 293.01it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:25<00:08, 292.65it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:25<00:08, 292.33it/s]Running 10000 simulations.:  76%|███████▌  | 7560/10000 [00:25<00:08, 292.80it/s]Running 10000 simulations.:  76%|███████▌  | 7590/10000 [00:25<00:08, 293.60it/s]Running 10000 simulations.:  76%|███████▌  | 7620/10000 [00:25<00:08, 292.55it/s]Running 10000 simulations.:  76%|███████▋  | 7650/10000 [00:25<00:08, 292.40it/s]Running 10000 simulations.:  77%|███████▋  | 7680/10000 [00:26<00:07, 292.48it/s]Running 10000 simulations.:  77%|███████▋  | 7710/10000 [00:26<00:07, 292.65it/s]Running 10000 simulations.:  77%|███████▋  | 7740/10000 [00:26<00:07, 293.58it/s]Running 10000 simulations.:  78%|███████▊  | 7770/10000 [00:26<00:07, 294.22it/s]Running 10000 simulations.:  78%|███████▊  | 7800/10000 [00:26<00:07, 293.99it/s]Running 10000 simulations.:  78%|███████▊  | 7830/10000 [00:26<00:07, 294.86it/s]Running 10000 simulations.:  79%|███████▊  | 7860/10000 [00:26<00:07, 295.13it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:26<00:07, 295.53it/s]Running 10000 simulations.:  79%|███████▉  | 7920/10000 [00:26<00:07, 295.22it/s]Running 10000 simulations.:  80%|███████▉  | 7950/10000 [00:27<00:06, 295.44it/s]Running 10000 simulations.:  80%|███████▉  | 7980/10000 [00:27<00:06, 294.70it/s]Running 10000 simulations.:  80%|████████  | 8010/10000 [00:27<00:06, 295.17it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:27<00:06, 294.06it/s]Running 10000 simulations.:  81%|████████  | 8070/10000 [00:27<00:06, 294.22it/s]Running 10000 simulations.:  81%|████████  | 8100/10000 [00:27<00:06, 294.79it/s]Running 10000 simulations.:  81%|████████▏ | 8130/10000 [00:27<00:06, 295.36it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:27<00:06, 295.63it/s]Running 10000 simulations.:  82%|████████▏ | 8190/10000 [00:27<00:06, 295.83it/s]Running 10000 simulations.:  82%|████████▏ | 8220/10000 [00:27<00:06, 295.85it/s]Running 10000 simulations.:  82%|████████▎ | 8250/10000 [00:28<00:05, 295.81it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:28<00:05, 295.66it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:28<00:05, 295.83it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:28<00:05, 295.68it/s]Running 10000 simulations.:  84%|████████▎ | 8370/10000 [00:28<00:05, 295.86it/s]Running 10000 simulations.:  84%|████████▍ | 8400/10000 [00:28<00:05, 295.63it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:28<00:05, 295.86it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:28<00:05, 295.93it/s]Running 10000 simulations.:  85%|████████▍ | 8490/10000 [00:28<00:05, 296.06it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:28<00:05, 295.55it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:29<00:04, 295.84it/s]Running 10000 simulations.:  86%|████████▌ | 8580/10000 [00:29<00:04, 296.04it/s]Running 10000 simulations.:  86%|████████▌ | 8610/10000 [00:29<00:04, 286.33it/s]Running 10000 simulations.:  86%|████████▋ | 8639/10000 [00:29<00:04, 287.24it/s]Running 10000 simulations.:  87%|████████▋ | 8668/10000 [00:29<00:04, 287.70it/s]Running 10000 simulations.:  87%|████████▋ | 8698/10000 [00:29<00:04, 288.54it/s]Running 10000 simulations.:  87%|████████▋ | 8728/10000 [00:29<00:04, 289.64it/s]Running 10000 simulations.:  88%|████████▊ | 8758/10000 [00:29<00:04, 291.19it/s]Running 10000 simulations.:  88%|████████▊ | 8788/10000 [00:29<00:04, 291.26it/s]Running 10000 simulations.:  88%|████████▊ | 8818/10000 [00:29<00:04, 292.45it/s]Running 10000 simulations.:  88%|████████▊ | 8848/10000 [00:30<00:03, 293.08it/s]Running 10000 simulations.:  89%|████████▉ | 8878/10000 [00:30<00:03, 293.01it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:30<00:03, 293.85it/s]Running 10000 simulations.:  89%|████████▉ | 8938/10000 [00:30<00:03, 294.44it/s]Running 10000 simulations.:  90%|████████▉ | 8968/10000 [00:30<00:03, 294.67it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:30<00:03, 295.24it/s]Running 10000 simulations.:  90%|█████████ | 9028/10000 [00:30<00:03, 295.29it/s]Running 10000 simulations.:  91%|█████████ | 9058/10000 [00:30<00:03, 295.35it/s]Running 10000 simulations.:  91%|█████████ | 9088/10000 [00:30<00:03, 295.63it/s]Running 10000 simulations.:  91%|█████████ | 9118/10000 [00:30<00:02, 295.95it/s]Running 10000 simulations.:  91%|█████████▏| 9148/10000 [00:31<00:02, 294.96it/s]Running 10000 simulations.:  92%|█████████▏| 9178/10000 [00:31<00:02, 293.52it/s]Running 10000 simulations.:  92%|█████████▏| 9208/10000 [00:31<00:02, 293.30it/s]Running 10000 simulations.:  92%|█████████▏| 9238/10000 [00:31<00:02, 293.84it/s]Running 10000 simulations.:  93%|█████████▎| 9268/10000 [00:31<00:02, 294.40it/s]Running 10000 simulations.:  93%|█████████▎| 9298/10000 [00:31<00:02, 294.92it/s]Running 10000 simulations.:  93%|█████████▎| 9328/10000 [00:31<00:02, 294.24it/s]Running 10000 simulations.:  94%|█████████▎| 9358/10000 [00:31<00:02, 294.44it/s]Running 10000 simulations.:  94%|█████████▍| 9388/10000 [00:31<00:02, 293.06it/s]Running 10000 simulations.:  94%|█████████▍| 9418/10000 [00:32<00:01, 292.70it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [00:32<00:01, 292.73it/s]Running 10000 simulations.:  95%|█████████▍| 9478/10000 [00:32<00:01, 293.40it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [00:32<00:01, 294.38it/s]Running 10000 simulations.:  95%|█████████▌| 9538/10000 [00:32<00:01, 295.00it/s]Running 10000 simulations.:  96%|█████████▌| 9568/10000 [00:32<00:01, 295.30it/s]Running 10000 simulations.:  96%|█████████▌| 9598/10000 [00:32<00:01, 295.47it/s]Running 10000 simulations.:  96%|█████████▋| 9628/10000 [00:32<00:01, 295.75it/s]Running 10000 simulations.:  97%|█████████▋| 9658/10000 [00:32<00:01, 295.90it/s]Running 10000 simulations.:  97%|█████████▋| 9688/10000 [00:32<00:01, 296.02it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [00:33<00:00, 296.30it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [00:33<00:00, 296.30it/s]Running 10000 simulations.:  98%|█████████▊| 9778/10000 [00:33<00:00, 295.24it/s]Running 10000 simulations.:  98%|█████████▊| 9808/10000 [00:33<00:00, 293.84it/s]Running 10000 simulations.:  98%|█████████▊| 9838/10000 [00:33<00:00, 293.66it/s]Running 10000 simulations.:  99%|█████████▊| 9868/10000 [00:33<00:00, 293.86it/s]Running 10000 simulations.:  99%|█████████▉| 9898/10000 [00:33<00:00, 294.69it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [00:33<00:00, 295.37it/s]Running 10000 simulations.: 100%|█████████▉| 9958/10000 [00:33<00:00, 295.35it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [00:33<00:00, 294.48it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:33<00:00, 294.29it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<00:33, 295.59it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<00:33, 296.10it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<00:33, 296.32it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<00:33, 294.35it/s]Running 10000 simulations.:   1%|▏         | 149/10000 [00:00<00:33, 293.03it/s]Running 10000 simulations.:   2%|▏         | 179/10000 [00:00<00:33, 293.00it/s]Running 10000 simulations.:   2%|▏         | 209/10000 [00:00<00:33, 293.73it/s]Running 10000 simulations.:   2%|▏         | 239/10000 [00:00<00:33, 292.65it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:00<00:33, 292.92it/s]Running 10000 simulations.:   3%|▎         | 299/10000 [00:01<00:32, 294.06it/s]Running 10000 simulations.:   3%|▎         | 329/10000 [00:01<00:32, 294.65it/s]Running 10000 simulations.:   4%|▎         | 359/10000 [00:01<00:32, 293.35it/s]Running 10000 simulations.:   4%|▍         | 389/10000 [00:01<00:32, 294.06it/s]Running 10000 simulations.:   4%|▍         | 419/10000 [00:01<00:32, 294.78it/s]Running 10000 simulations.:   4%|▍         | 449/10000 [00:01<00:32, 294.99it/s]Running 10000 simulations.:   5%|▍         | 479/10000 [00:01<00:32, 294.42it/s]Running 10000 simulations.:   5%|▌         | 509/10000 [00:01<00:32, 295.15it/s]Running 10000 simulations.:   5%|▌         | 539/10000 [00:01<00:32, 295.48it/s]Running 10000 simulations.:   6%|▌         | 569/10000 [00:01<00:32, 293.92it/s]Running 10000 simulations.:   6%|▌         | 599/10000 [00:02<00:32, 293.03it/s]Running 10000 simulations.:   6%|▋         | 629/10000 [00:02<00:32, 292.20it/s]Running 10000 simulations.:   7%|▋         | 659/10000 [00:02<00:31, 293.05it/s]Running 10000 simulations.:   7%|▋         | 689/10000 [00:02<00:31, 293.72it/s]Running 10000 simulations.:   7%|▋         | 719/10000 [00:02<00:31, 294.16it/s]Running 10000 simulations.:   7%|▋         | 749/10000 [00:02<00:31, 293.60it/s]Running 10000 simulations.:   8%|▊         | 779/10000 [00:02<00:31, 293.03it/s]Running 10000 simulations.:   8%|▊         | 809/10000 [00:02<00:31, 293.49it/s]Running 10000 simulations.:   8%|▊         | 839/10000 [00:02<00:31, 294.01it/s]Running 10000 simulations.:   9%|▊         | 869/10000 [00:02<00:31, 292.84it/s]Running 10000 simulations.:   9%|▉         | 899/10000 [00:03<00:31, 292.28it/s]Running 10000 simulations.:   9%|▉         | 929/10000 [00:03<00:30, 292.95it/s]Running 10000 simulations.:  10%|▉         | 959/10000 [00:03<00:30, 293.56it/s]Running 10000 simulations.:  10%|▉         | 989/10000 [00:03<00:30, 293.89it/s]Running 10000 simulations.:  10%|█         | 1019/10000 [00:03<00:30, 294.17it/s]Running 10000 simulations.:  10%|█         | 1049/10000 [00:03<00:30, 294.90it/s]Running 10000 simulations.:  11%|█         | 1079/10000 [00:03<00:30, 295.22it/s]Running 10000 simulations.:  11%|█         | 1109/10000 [00:03<00:30, 295.03it/s]Running 10000 simulations.:  11%|█▏        | 1139/10000 [00:03<00:30, 294.28it/s]Running 10000 simulations.:  12%|█▏        | 1169/10000 [00:03<00:30, 292.87it/s]Running 10000 simulations.:  12%|█▏        | 1199/10000 [00:04<00:30, 292.63it/s]Running 10000 simulations.:  12%|█▏        | 1229/10000 [00:04<00:29, 292.37it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:04<00:29, 292.69it/s]Running 10000 simulations.:  13%|█▎        | 1289/10000 [00:04<00:29, 293.82it/s]Running 10000 simulations.:  13%|█▎        | 1319/10000 [00:04<00:29, 294.20it/s]Running 10000 simulations.:  13%|█▎        | 1349/10000 [00:04<00:29, 294.70it/s]Running 10000 simulations.:  14%|█▍        | 1379/10000 [00:04<00:29, 294.92it/s]Running 10000 simulations.:  14%|█▍        | 1409/10000 [00:04<00:29, 294.37it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:04<00:29, 293.56it/s]Running 10000 simulations.:  15%|█▍        | 1469/10000 [00:04<00:28, 294.28it/s]Running 10000 simulations.:  15%|█▍        | 1499/10000 [00:05<00:28, 295.05it/s]Running 10000 simulations.:  15%|█▌        | 1529/10000 [00:05<00:28, 295.21it/s]Running 10000 simulations.:  16%|█▌        | 1559/10000 [00:05<00:28, 295.14it/s]Running 10000 simulations.:  16%|█▌        | 1589/10000 [00:05<00:28, 295.48it/s]Running 10000 simulations.:  16%|█▌        | 1619/10000 [00:05<00:28, 295.86it/s]Running 10000 simulations.:  16%|█▋        | 1649/10000 [00:05<00:28, 296.21it/s]Running 10000 simulations.:  17%|█▋        | 1679/10000 [00:05<00:28, 296.21it/s]Running 10000 simulations.:  17%|█▋        | 1709/10000 [00:05<00:27, 296.33it/s]Running 10000 simulations.:  17%|█▋        | 1739/10000 [00:05<00:28, 286.52it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:06<00:28, 287.72it/s]Running 10000 simulations.:  18%|█▊        | 1798/10000 [00:06<00:28, 287.98it/s]Running 10000 simulations.:  18%|█▊        | 1828/10000 [00:06<00:28, 289.59it/s]Running 10000 simulations.:  19%|█▊        | 1858/10000 [00:06<00:27, 291.00it/s]Running 10000 simulations.:  19%|█▉        | 1888/10000 [00:06<00:27, 292.28it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:06<00:27, 293.18it/s]Running 10000 simulations.:  19%|█▉        | 1948/10000 [00:06<00:27, 292.79it/s]Running 10000 simulations.:  20%|█▉        | 1978/10000 [00:06<00:27, 293.07it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:06<00:27, 293.43it/s]Running 10000 simulations.:  20%|██        | 2038/10000 [00:06<00:27, 293.10it/s]Running 10000 simulations.:  21%|██        | 2068/10000 [00:07<00:26, 294.20it/s]Running 10000 simulations.:  21%|██        | 2098/10000 [00:07<00:26, 295.07it/s]Running 10000 simulations.:  21%|██▏       | 2128/10000 [00:07<00:26, 295.33it/s]Running 10000 simulations.:  22%|██▏       | 2158/10000 [00:07<00:26, 295.66it/s]Running 10000 simulations.:  22%|██▏       | 2188/10000 [00:07<00:26, 295.52it/s]Running 10000 simulations.:  22%|██▏       | 2218/10000 [00:07<00:26, 295.88it/s]Running 10000 simulations.:  22%|██▏       | 2248/10000 [00:07<00:26, 295.86it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:07<00:26, 295.61it/s]Running 10000 simulations.:  23%|██▎       | 2308/10000 [00:07<00:26, 293.63it/s]Running 10000 simulations.:  23%|██▎       | 2338/10000 [00:07<00:26, 293.15it/s]Running 10000 simulations.:  24%|██▎       | 2368/10000 [00:08<00:25, 293.79it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:08<00:25, 294.48it/s]Running 10000 simulations.:  24%|██▍       | 2428/10000 [00:08<00:25, 295.17it/s]Running 10000 simulations.:  25%|██▍       | 2458/10000 [00:08<00:25, 295.40it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:08<00:25, 295.77it/s]Running 10000 simulations.:  25%|██▌       | 2518/10000 [00:08<00:25, 295.97it/s]Running 10000 simulations.:  25%|██▌       | 2548/10000 [00:08<00:25, 295.69it/s]Running 10000 simulations.:  26%|██▌       | 2578/10000 [00:08<00:25, 295.13it/s]Running 10000 simulations.:  26%|██▌       | 2608/10000 [00:08<00:25, 294.75it/s]Running 10000 simulations.:  26%|██▋       | 2638/10000 [00:08<00:25, 293.29it/s]Running 10000 simulations.:  27%|██▋       | 2668/10000 [00:09<00:25, 292.43it/s]Running 10000 simulations.:  27%|██▋       | 2698/10000 [00:09<00:29, 249.66it/s]Running 10000 simulations.:  27%|██▋       | 2728/10000 [00:09<00:27, 260.72it/s]Running 10000 simulations.:  28%|██▊       | 2758/10000 [00:09<00:26, 269.68it/s]Running 10000 simulations.:  28%|██▊       | 2788/10000 [00:09<00:26, 276.91it/s]Running 10000 simulations.:  28%|██▊       | 2818/10000 [00:09<00:25, 282.13it/s]Running 10000 simulations.:  28%|██▊       | 2848/10000 [00:09<00:25, 286.07it/s]Running 10000 simulations.:  29%|██▉       | 2878/10000 [00:09<00:24, 288.32it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:09<00:24, 289.26it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:10<00:24, 289.58it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:10<00:24, 289.53it/s]Running 10000 simulations.:  30%|██▉       | 2998/10000 [00:10<00:24, 290.14it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:10<00:24, 290.42it/s]Running 10000 simulations.:  31%|███       | 3058/10000 [00:10<00:23, 291.22it/s]Running 10000 simulations.:  31%|███       | 3088/10000 [00:10<00:23, 291.98it/s]Running 10000 simulations.:  31%|███       | 3118/10000 [00:10<00:23, 292.74it/s]Running 10000 simulations.:  31%|███▏      | 3148/10000 [00:10<00:23, 293.66it/s]Running 10000 simulations.:  32%|███▏      | 3178/10000 [00:10<00:23, 293.66it/s]Running 10000 simulations.:  32%|███▏      | 3208/10000 [00:10<00:23, 293.64it/s]Running 10000 simulations.:  32%|███▏      | 3238/10000 [00:11<00:22, 294.37it/s]Running 10000 simulations.:  33%|███▎      | 3268/10000 [00:11<00:22, 294.82it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:11<00:22, 295.29it/s]Running 10000 simulations.:  33%|███▎      | 3328/10000 [00:11<00:22, 295.34it/s]Running 10000 simulations.:  34%|███▎      | 3358/10000 [00:11<00:22, 294.83it/s]Running 10000 simulations.:  34%|███▍      | 3388/10000 [00:11<00:22, 295.23it/s]Running 10000 simulations.:  34%|███▍      | 3418/10000 [00:11<00:22, 295.36it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:11<00:22, 295.08it/s]Running 10000 simulations.:  35%|███▍      | 3478/10000 [00:11<00:22, 294.37it/s]Running 10000 simulations.:  35%|███▌      | 3508/10000 [00:11<00:22, 293.85it/s]Running 10000 simulations.:  35%|███▌      | 3538/10000 [00:12<00:21, 293.94it/s]Running 10000 simulations.:  36%|███▌      | 3568/10000 [00:12<00:21, 294.46it/s]Running 10000 simulations.:  36%|███▌      | 3598/10000 [00:12<00:21, 294.95it/s]Running 10000 simulations.:  36%|███▋      | 3628/10000 [00:12<00:21, 295.18it/s]Running 10000 simulations.:  37%|███▋      | 3658/10000 [00:12<00:21, 295.32it/s]Running 10000 simulations.:  37%|███▋      | 3688/10000 [00:12<00:21, 295.36it/s]Running 10000 simulations.:  37%|███▋      | 3718/10000 [00:12<00:21, 295.46it/s]Running 10000 simulations.:  37%|███▋      | 3748/10000 [00:12<00:21, 295.72it/s]Running 10000 simulations.:  38%|███▊      | 3778/10000 [00:12<00:21, 295.45it/s]Running 10000 simulations.:  38%|███▊      | 3808/10000 [00:13<00:20, 295.60it/s]Running 10000 simulations.:  38%|███▊      | 3838/10000 [00:13<00:20, 295.90it/s]Running 10000 simulations.:  39%|███▊      | 3868/10000 [00:13<00:20, 296.09it/s]Running 10000 simulations.:  39%|███▉      | 3898/10000 [00:13<00:20, 295.51it/s]Running 10000 simulations.:  39%|███▉      | 3928/10000 [00:13<00:20, 294.44it/s]Running 10000 simulations.:  40%|███▉      | 3958/10000 [00:13<00:20, 292.58it/s]Running 10000 simulations.:  40%|███▉      | 3988/10000 [00:13<00:20, 292.92it/s]Running 10000 simulations.:  40%|████      | 4018/10000 [00:13<00:20, 293.09it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:13<00:20, 293.48it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:13<00:20, 292.95it/s]Running 10000 simulations.:  41%|████      | 4108/10000 [00:14<00:20, 292.93it/s]Running 10000 simulations.:  41%|████▏     | 4138/10000 [00:14<00:20, 293.02it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:14<00:19, 292.77it/s]Running 10000 simulations.:  42%|████▏     | 4198/10000 [00:14<00:19, 292.52it/s]Running 10000 simulations.:  42%|████▏     | 4228/10000 [00:14<00:19, 291.97it/s]Running 10000 simulations.:  43%|████▎     | 4258/10000 [00:14<00:19, 291.12it/s]Running 10000 simulations.:  43%|████▎     | 4288/10000 [00:14<00:19, 290.70it/s]Running 10000 simulations.:  43%|████▎     | 4318/10000 [00:14<00:19, 291.56it/s]Running 10000 simulations.:  43%|████▎     | 4348/10000 [00:14<00:19, 289.91it/s]Running 10000 simulations.:  44%|████▍     | 4378/10000 [00:14<00:19, 291.10it/s]Running 10000 simulations.:  44%|████▍     | 4408/10000 [00:15<00:19, 292.24it/s]Running 10000 simulations.:  44%|████▍     | 4438/10000 [00:15<00:18, 293.47it/s]Running 10000 simulations.:  45%|████▍     | 4468/10000 [00:15<00:18, 294.36it/s]Running 10000 simulations.:  45%|████▍     | 4498/10000 [00:15<00:18, 294.22it/s]Running 10000 simulations.:  45%|████▌     | 4528/10000 [00:15<00:18, 294.92it/s]Running 10000 simulations.:  46%|████▌     | 4558/10000 [00:15<00:18, 295.39it/s]Running 10000 simulations.:  46%|████▌     | 4588/10000 [00:15<00:18, 295.58it/s]Running 10000 simulations.:  46%|████▌     | 4618/10000 [00:15<00:18, 295.67it/s]Running 10000 simulations.:  46%|████▋     | 4648/10000 [00:15<00:18, 295.78it/s]Running 10000 simulations.:  47%|████▋     | 4678/10000 [00:15<00:17, 295.83it/s]Running 10000 simulations.:  47%|████▋     | 4708/10000 [00:16<00:17, 295.63it/s]Running 10000 simulations.:  47%|████▋     | 4738/10000 [00:16<00:17, 295.53it/s]Running 10000 simulations.:  48%|████▊     | 4768/10000 [00:16<00:17, 294.47it/s]Running 10000 simulations.:  48%|████▊     | 4798/10000 [00:16<00:17, 294.91it/s]Running 10000 simulations.:  48%|████▊     | 4828/10000 [00:16<00:17, 294.71it/s]Running 10000 simulations.:  49%|████▊     | 4858/10000 [00:16<00:17, 294.58it/s]Running 10000 simulations.:  49%|████▉     | 4888/10000 [00:16<00:17, 295.14it/s]Running 10000 simulations.:  49%|████▉     | 4918/10000 [00:16<00:17, 294.75it/s]Running 10000 simulations.:  49%|████▉     | 4948/10000 [00:16<00:17, 295.02it/s]Running 10000 simulations.:  50%|████▉     | 4978/10000 [00:16<00:17, 295.36it/s]Running 10000 simulations.:  50%|█████     | 5008/10000 [00:17<00:16, 295.37it/s]Running 10000 simulations.:  50%|█████     | 5038/10000 [00:17<00:16, 295.62it/s]Running 10000 simulations.:  51%|█████     | 5068/10000 [00:17<00:16, 295.59it/s]Running 10000 simulations.:  51%|█████     | 5098/10000 [00:17<00:16, 295.52it/s]Running 10000 simulations.:  51%|█████▏    | 5128/10000 [00:17<00:16, 295.30it/s]Running 10000 simulations.:  52%|█████▏    | 5158/10000 [00:17<00:16, 295.62it/s]Running 10000 simulations.:  52%|█████▏    | 5188/10000 [00:17<00:16, 295.82it/s]Running 10000 simulations.:  52%|█████▏    | 5218/10000 [00:17<00:16, 294.47it/s]Running 10000 simulations.:  52%|█████▏    | 5248/10000 [00:17<00:16, 293.40it/s]Running 10000 simulations.:  53%|█████▎    | 5278/10000 [00:18<00:16, 292.16it/s]Running 10000 simulations.:  53%|█████▎    | 5308/10000 [00:18<00:16, 291.31it/s]Running 10000 simulations.:  53%|█████▎    | 5338/10000 [00:18<00:16, 291.27it/s]Running 10000 simulations.:  54%|█████▎    | 5368/10000 [00:18<00:15, 290.77it/s]Running 10000 simulations.:  54%|█████▍    | 5398/10000 [00:18<00:15, 291.60it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:18<00:15, 291.39it/s]Running 10000 simulations.:  55%|█████▍    | 5458/10000 [00:18<00:15, 292.14it/s]Running 10000 simulations.:  55%|█████▍    | 5488/10000 [00:18<00:15, 292.70it/s]Running 10000 simulations.:  55%|█████▌    | 5518/10000 [00:18<00:15, 292.88it/s]Running 10000 simulations.:  55%|█████▌    | 5548/10000 [00:18<00:15, 293.03it/s]Running 10000 simulations.:  56%|█████▌    | 5578/10000 [00:19<00:15, 291.99it/s]Running 10000 simulations.:  56%|█████▌    | 5608/10000 [00:19<00:15, 291.44it/s]Running 10000 simulations.:  56%|█████▋    | 5638/10000 [00:19<00:14, 291.93it/s]Running 10000 simulations.:  57%|█████▋    | 5668/10000 [00:19<00:14, 292.61it/s]Running 10000 simulations.:  57%|█████▋    | 5698/10000 [00:19<00:14, 292.22it/s]Running 10000 simulations.:  57%|█████▋    | 5728/10000 [00:19<00:14, 293.06it/s]Running 10000 simulations.:  58%|█████▊    | 5758/10000 [00:19<00:14, 293.78it/s]Running 10000 simulations.:  58%|█████▊    | 5788/10000 [00:19<00:14, 293.37it/s]Running 10000 simulations.:  58%|█████▊    | 5818/10000 [00:19<00:14, 293.60it/s]Running 10000 simulations.:  58%|█████▊    | 5848/10000 [00:19<00:14, 294.17it/s]Running 10000 simulations.:  59%|█████▉    | 5878/10000 [00:20<00:14, 292.71it/s]Running 10000 simulations.:  59%|█████▉    | 5908/10000 [00:20<00:13, 293.00it/s]Running 10000 simulations.:  59%|█████▉    | 5938/10000 [00:20<00:13, 292.87it/s]Running 10000 simulations.:  60%|█████▉    | 5968/10000 [00:20<00:13, 293.73it/s]Running 10000 simulations.:  60%|█████▉    | 5998/10000 [00:20<00:13, 294.35it/s]Running 10000 simulations.:  60%|██████    | 6028/10000 [00:20<00:13, 294.59it/s]Running 10000 simulations.:  61%|██████    | 6058/10000 [00:20<00:13, 294.75it/s]Running 10000 simulations.:  61%|██████    | 6088/10000 [00:20<00:13, 294.38it/s]Running 10000 simulations.:  61%|██████    | 6118/10000 [00:20<00:13, 294.66it/s]Running 10000 simulations.:  61%|██████▏   | 6148/10000 [00:20<00:13, 295.10it/s]Running 10000 simulations.:  62%|██████▏   | 6178/10000 [00:21<00:12, 295.41it/s]Running 10000 simulations.:  62%|██████▏   | 6208/10000 [00:21<00:12, 295.04it/s]Running 10000 simulations.:  62%|██████▏   | 6238/10000 [00:21<00:12, 293.95it/s]Running 10000 simulations.:  63%|██████▎   | 6268/10000 [00:21<00:12, 293.69it/s]Running 10000 simulations.:  63%|██████▎   | 6298/10000 [00:21<00:12, 293.31it/s]Running 10000 simulations.:  63%|██████▎   | 6328/10000 [00:21<00:12, 293.82it/s]Running 10000 simulations.:  64%|██████▎   | 6358/10000 [00:21<00:12, 294.55it/s]Running 10000 simulations.:  64%|██████▍   | 6388/10000 [00:21<00:12, 293.86it/s]Running 10000 simulations.:  64%|██████▍   | 6418/10000 [00:21<00:12, 293.46it/s]Running 10000 simulations.:  64%|██████▍   | 6448/10000 [00:22<00:12, 292.49it/s]Running 10000 simulations.:  65%|██████▍   | 6478/10000 [00:22<00:12, 292.33it/s]Running 10000 simulations.:  65%|██████▌   | 6508/10000 [00:22<00:11, 292.93it/s]Running 10000 simulations.:  65%|██████▌   | 6538/10000 [00:22<00:11, 292.75it/s]Running 10000 simulations.:  66%|██████▌   | 6568/10000 [00:22<00:11, 292.35it/s]Running 10000 simulations.:  66%|██████▌   | 6598/10000 [00:22<00:11, 291.41it/s]Running 10000 simulations.:  66%|██████▋   | 6628/10000 [00:22<00:11, 291.25it/s]Running 10000 simulations.:  67%|██████▋   | 6658/10000 [00:22<00:11, 291.02it/s]Running 10000 simulations.:  67%|██████▋   | 6688/10000 [00:22<00:11, 291.60it/s]Running 10000 simulations.:  67%|██████▋   | 6718/10000 [00:22<00:11, 291.87it/s]Running 10000 simulations.:  67%|██████▋   | 6748/10000 [00:23<00:11, 292.06it/s]Running 10000 simulations.:  68%|██████▊   | 6778/10000 [00:23<00:10, 293.02it/s]Running 10000 simulations.:  68%|██████▊   | 6808/10000 [00:23<00:10, 294.05it/s]Running 10000 simulations.:  68%|██████▊   | 6838/10000 [00:23<00:10, 294.05it/s]Running 10000 simulations.:  69%|██████▊   | 6868/10000 [00:23<00:10, 294.05it/s]Running 10000 simulations.:  69%|██████▉   | 6898/10000 [00:23<00:10, 293.96it/s]Running 10000 simulations.:  69%|██████▉   | 6928/10000 [00:23<00:10, 292.67it/s]Running 10000 simulations.:  70%|██████▉   | 6958/10000 [00:23<00:10, 291.84it/s]Running 10000 simulations.:  70%|██████▉   | 6988/10000 [00:23<00:10, 291.96it/s]Running 10000 simulations.:  70%|███████   | 7018/10000 [00:23<00:10, 292.32it/s]Running 10000 simulations.:  70%|███████   | 7048/10000 [00:24<00:10, 291.53it/s]Running 10000 simulations.:  71%|███████   | 7078/10000 [00:24<00:09, 292.34it/s]Running 10000 simulations.:  71%|███████   | 7108/10000 [00:24<00:09, 293.58it/s]Running 10000 simulations.:  71%|███████▏  | 7138/10000 [00:24<00:09, 294.42it/s]Running 10000 simulations.:  72%|███████▏  | 7168/10000 [00:24<00:09, 294.98it/s]Running 10000 simulations.:  72%|███████▏  | 7198/10000 [00:24<00:09, 293.56it/s]Running 10000 simulations.:  72%|███████▏  | 7228/10000 [00:24<00:09, 293.11it/s]Running 10000 simulations.:  73%|███████▎  | 7258/10000 [00:24<00:09, 293.30it/s]Running 10000 simulations.:  73%|███████▎  | 7288/10000 [00:24<00:09, 294.08it/s]Running 10000 simulations.:  73%|███████▎  | 7318/10000 [00:24<00:09, 294.37it/s]Running 10000 simulations.:  73%|███████▎  | 7348/10000 [00:25<00:09, 293.05it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:25<00:08, 292.85it/s]Running 10000 simulations.:  74%|███████▍  | 7408/10000 [00:25<00:08, 293.25it/s]Running 10000 simulations.:  74%|███████▍  | 7438/10000 [00:25<00:08, 293.66it/s]Running 10000 simulations.:  75%|███████▍  | 7468/10000 [00:25<00:08, 293.21it/s]Running 10000 simulations.:  75%|███████▍  | 7498/10000 [00:25<00:08, 293.38it/s]Running 10000 simulations.:  75%|███████▌  | 7528/10000 [00:25<00:08, 294.09it/s]Running 10000 simulations.:  76%|███████▌  | 7558/10000 [00:25<00:08, 294.94it/s]Running 10000 simulations.:  76%|███████▌  | 7588/10000 [00:25<00:08, 294.23it/s]Running 10000 simulations.:  76%|███████▌  | 7618/10000 [00:25<00:08, 293.76it/s]Running 10000 simulations.:  76%|███████▋  | 7648/10000 [00:26<00:08, 292.48it/s]Running 10000 simulations.:  77%|███████▋  | 7678/10000 [00:26<00:07, 291.51it/s]Running 10000 simulations.:  77%|███████▋  | 7708/10000 [00:26<00:07, 292.31it/s]Running 10000 simulations.:  77%|███████▋  | 7738/10000 [00:26<00:07, 293.43it/s]Running 10000 simulations.:  78%|███████▊  | 7768/10000 [00:26<00:07, 293.68it/s]Running 10000 simulations.:  78%|███████▊  | 7798/10000 [00:26<00:07, 294.12it/s]Running 10000 simulations.:  78%|███████▊  | 7828/10000 [00:26<00:07, 294.23it/s]Running 10000 simulations.:  79%|███████▊  | 7858/10000 [00:26<00:07, 294.44it/s]Running 10000 simulations.:  79%|███████▉  | 7888/10000 [00:26<00:07, 294.44it/s]Running 10000 simulations.:  79%|███████▉  | 7918/10000 [00:27<00:07, 293.83it/s]Running 10000 simulations.:  79%|███████▉  | 7948/10000 [00:27<00:06, 293.51it/s]Running 10000 simulations.:  80%|███████▉  | 7978/10000 [00:27<00:06, 293.77it/s]Running 10000 simulations.:  80%|████████  | 8008/10000 [00:27<00:06, 294.49it/s]Running 10000 simulations.:  80%|████████  | 8038/10000 [00:27<00:06, 295.18it/s]Running 10000 simulations.:  81%|████████  | 8068/10000 [00:27<00:06, 295.52it/s]Running 10000 simulations.:  81%|████████  | 8098/10000 [00:27<00:06, 295.80it/s]Running 10000 simulations.:  81%|████████▏ | 8128/10000 [00:27<00:06, 295.97it/s]Running 10000 simulations.:  82%|████████▏ | 8158/10000 [00:27<00:06, 294.91it/s]Running 10000 simulations.:  82%|████████▏ | 8188/10000 [00:27<00:06, 295.23it/s]Running 10000 simulations.:  82%|████████▏ | 8218/10000 [00:28<00:06, 295.62it/s]Running 10000 simulations.:  82%|████████▏ | 8248/10000 [00:28<00:05, 295.78it/s]Running 10000 simulations.:  83%|████████▎ | 8278/10000 [00:28<00:05, 295.82it/s]Running 10000 simulations.:  83%|████████▎ | 8308/10000 [00:28<00:05, 294.75it/s]Running 10000 simulations.:  83%|████████▎ | 8338/10000 [00:28<00:05, 294.44it/s]Running 10000 simulations.:  84%|████████▎ | 8368/10000 [00:28<00:05, 294.97it/s]Running 10000 simulations.:  84%|████████▍ | 8398/10000 [00:28<00:05, 295.47it/s]Running 10000 simulations.:  84%|████████▍ | 8428/10000 [00:28<00:05, 295.78it/s]Running 10000 simulations.:  85%|████████▍ | 8458/10000 [00:28<00:05, 295.44it/s]Running 10000 simulations.:  85%|████████▍ | 8488/10000 [00:28<00:05, 295.29it/s]Running 10000 simulations.:  85%|████████▌ | 8518/10000 [00:29<00:05, 295.03it/s]Running 10000 simulations.:  85%|████████▌ | 8548/10000 [00:29<00:04, 294.74it/s]Running 10000 simulations.:  86%|████████▌ | 8578/10000 [00:29<00:04, 294.81it/s]Running 10000 simulations.:  86%|████████▌ | 8608/10000 [00:29<00:04, 295.07it/s]Running 10000 simulations.:  86%|████████▋ | 8638/10000 [00:29<00:04, 295.37it/s]Running 10000 simulations.:  87%|████████▋ | 8668/10000 [00:29<00:04, 295.41it/s]Running 10000 simulations.:  87%|████████▋ | 8698/10000 [00:29<00:04, 295.69it/s]Running 10000 simulations.:  87%|████████▋ | 8728/10000 [00:29<00:04, 295.92it/s]Running 10000 simulations.:  88%|████████▊ | 8758/10000 [00:29<00:04, 295.37it/s]Running 10000 simulations.:  88%|████████▊ | 8788/10000 [00:29<00:04, 293.94it/s]Running 10000 simulations.:  88%|████████▊ | 8818/10000 [00:30<00:04, 292.13it/s]Running 10000 simulations.:  88%|████████▊ | 8848/10000 [00:30<00:03, 291.60it/s]Running 10000 simulations.:  89%|████████▉ | 8878/10000 [00:30<00:03, 292.29it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:30<00:03, 291.91it/s]Running 10000 simulations.:  89%|████████▉ | 8938/10000 [00:30<00:03, 291.29it/s]Running 10000 simulations.:  90%|████████▉ | 8968/10000 [00:30<00:03, 291.94it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:30<00:03, 293.11it/s]Running 10000 simulations.:  90%|█████████ | 9028/10000 [00:30<00:03, 293.95it/s]Running 10000 simulations.:  91%|█████████ | 9058/10000 [00:30<00:03, 293.07it/s]Running 10000 simulations.:  91%|█████████ | 9088/10000 [00:30<00:03, 292.79it/s]Running 10000 simulations.:  91%|█████████ | 9118/10000 [00:31<00:03, 292.86it/s]Running 10000 simulations.:  91%|█████████▏| 9148/10000 [00:31<00:02, 292.51it/s]Running 10000 simulations.:  92%|█████████▏| 9178/10000 [00:31<00:02, 292.03it/s]Running 10000 simulations.:  92%|█████████▏| 9208/10000 [00:31<00:02, 292.19it/s]Running 10000 simulations.:  92%|█████████▏| 9238/10000 [00:31<00:02, 291.36it/s]Running 10000 simulations.:  93%|█████████▎| 9268/10000 [00:31<00:02, 291.91it/s]Running 10000 simulations.:  93%|█████████▎| 9298/10000 [00:31<00:02, 292.29it/s]Running 10000 simulations.:  93%|█████████▎| 9328/10000 [00:31<00:02, 292.98it/s]Running 10000 simulations.:  94%|█████████▎| 9358/10000 [00:31<00:02, 293.51it/s]Running 10000 simulations.:  94%|█████████▍| 9388/10000 [00:32<00:02, 294.00it/s]Running 10000 simulations.:  94%|█████████▍| 9418/10000 [00:32<00:01, 294.47it/s]Running 10000 simulations.:  94%|█████████▍| 9448/10000 [00:32<00:01, 293.91it/s]Running 10000 simulations.:  95%|█████████▍| 9478/10000 [00:32<00:01, 294.10it/s]Running 10000 simulations.:  95%|█████████▌| 9508/10000 [00:32<00:01, 293.84it/s]Running 10000 simulations.:  95%|█████████▌| 9538/10000 [00:32<00:01, 293.10it/s]Running 10000 simulations.:  96%|█████████▌| 9568/10000 [00:32<00:01, 293.73it/s]Running 10000 simulations.:  96%|█████████▌| 9598/10000 [00:32<00:01, 294.68it/s]Running 10000 simulations.:  96%|█████████▋| 9628/10000 [00:32<00:01, 295.17it/s]Running 10000 simulations.:  97%|█████████▋| 9658/10000 [00:32<00:01, 295.41it/s]Running 10000 simulations.:  97%|█████████▋| 9688/10000 [00:33<00:01, 295.67it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [00:33<00:00, 295.72it/s]Running 10000 simulations.:  97%|█████████▋| 9748/10000 [00:33<00:00, 295.93it/s]Running 10000 simulations.:  98%|█████████▊| 9778/10000 [00:33<00:00, 295.86it/s]Running 10000 simulations.:  98%|█████████▊| 9808/10000 [00:33<00:00, 295.96it/s]Running 10000 simulations.:  98%|█████████▊| 9838/10000 [00:33<00:00, 295.69it/s]Running 10000 simulations.:  99%|█████████▊| 9868/10000 [00:33<00:00, 295.79it/s]Running 10000 simulations.:  99%|█████████▉| 9898/10000 [00:33<00:00, 295.44it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [00:33<00:00, 295.07it/s]Running 10000 simulations.: 100%|█████████▉| 9958/10000 [00:33<00:00, 293.84it/s]Running 10000 simulations.: 100%|█████████▉| 9988/10000 [00:34<00:00, 293.11it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:34<00:00, 293.30it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 29/10000 [00:00<00:34, 288.71it/s]Running 10000 simulations.:   1%|          | 59/10000 [00:00<00:34, 289.13it/s]Running 10000 simulations.:   1%|          | 89/10000 [00:00<00:34, 289.37it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<00:34, 289.74it/s]Running 10000 simulations.:   1%|▏         | 149/10000 [00:00<00:33, 291.71it/s]Running 10000 simulations.:   2%|▏         | 179/10000 [00:00<00:33, 292.25it/s]Running 10000 simulations.:   2%|▏         | 209/10000 [00:00<00:33, 292.31it/s]Running 10000 simulations.:   2%|▏         | 239/10000 [00:00<00:33, 292.17it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:00<00:33, 292.19it/s]Running 10000 simulations.:   3%|▎         | 299/10000 [00:01<00:33, 291.95it/s]Running 10000 simulations.:   3%|▎         | 329/10000 [00:01<00:33, 291.78it/s]Running 10000 simulations.:   4%|▎         | 359/10000 [00:01<00:33, 291.71it/s]Running 10000 simulations.:   4%|▍         | 389/10000 [00:01<00:32, 291.97it/s]Running 10000 simulations.:   4%|▍         | 419/10000 [00:01<00:32, 293.04it/s]Running 10000 simulations.:   4%|▍         | 449/10000 [00:01<00:32, 292.90it/s]Running 10000 simulations.:   5%|▍         | 479/10000 [00:01<00:32, 292.45it/s]Running 10000 simulations.:   5%|▌         | 509/10000 [00:01<00:32, 291.98it/s]Running 10000 simulations.:   5%|▌         | 539/10000 [00:01<00:32, 292.09it/s]Running 10000 simulations.:   6%|▌         | 569/10000 [00:01<00:32, 292.13it/s]Running 10000 simulations.:   6%|▌         | 599/10000 [00:02<00:32, 292.18it/s]Running 10000 simulations.:   6%|▋         | 629/10000 [00:02<00:32, 291.66it/s]Running 10000 simulations.:   7%|▋         | 659/10000 [00:02<00:32, 291.48it/s]Running 10000 simulations.:   7%|▋         | 689/10000 [00:02<00:31, 291.40it/s]Running 10000 simulations.:   7%|▋         | 719/10000 [00:02<00:31, 290.88it/s]Running 10000 simulations.:   7%|▋         | 749/10000 [00:02<00:31, 291.52it/s]Running 10000 simulations.:   8%|▊         | 779/10000 [00:02<00:31, 293.05it/s]Running 10000 simulations.:   8%|▊         | 809/10000 [00:02<00:31, 293.26it/s]Running 10000 simulations.:   8%|▊         | 839/10000 [00:02<00:31, 293.75it/s]Running 10000 simulations.:   9%|▊         | 869/10000 [00:02<00:31, 293.18it/s]Running 10000 simulations.:   9%|▉         | 899/10000 [00:03<00:31, 292.45it/s]Running 10000 simulations.:   9%|▉         | 929/10000 [00:03<00:31, 292.15it/s]Running 10000 simulations.:  10%|▉         | 959/10000 [00:03<00:30, 292.82it/s]Running 10000 simulations.:  10%|▉         | 989/10000 [00:03<00:30, 292.82it/s]Running 10000 simulations.:  10%|█         | 1019/10000 [00:03<00:30, 293.70it/s]Running 10000 simulations.:  10%|█         | 1049/10000 [00:03<00:30, 293.63it/s]Running 10000 simulations.:  11%|█         | 1079/10000 [00:03<00:30, 292.69it/s]Running 10000 simulations.:  11%|█         | 1109/10000 [00:03<00:30, 292.45it/s]Running 10000 simulations.:  11%|█▏        | 1139/10000 [00:03<00:30, 292.43it/s]Running 10000 simulations.:  12%|█▏        | 1169/10000 [00:04<00:30, 292.28it/s]Running 10000 simulations.:  12%|█▏        | 1199/10000 [00:04<00:30, 293.11it/s]Running 10000 simulations.:  12%|█▏        | 1229/10000 [00:04<00:29, 294.13it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:04<00:29, 294.54it/s]Running 10000 simulations.:  13%|█▎        | 1289/10000 [00:04<00:29, 294.55it/s]Running 10000 simulations.:  13%|█▎        | 1319/10000 [00:04<00:29, 294.36it/s]Running 10000 simulations.:  13%|█▎        | 1349/10000 [00:04<00:29, 294.74it/s]Running 10000 simulations.:  14%|█▍        | 1379/10000 [00:04<00:29, 294.83it/s]Running 10000 simulations.:  14%|█▍        | 1409/10000 [00:04<00:29, 295.24it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:04<00:29, 294.82it/s]Running 10000 simulations.:  15%|█▍        | 1469/10000 [00:05<00:29, 293.82it/s]Running 10000 simulations.:  15%|█▍        | 1499/10000 [00:05<00:29, 292.89it/s]Running 10000 simulations.:  15%|█▌        | 1529/10000 [00:05<00:29, 291.94it/s]Running 10000 simulations.:  16%|█▌        | 1559/10000 [00:05<00:28, 291.35it/s]Running 10000 simulations.:  16%|█▌        | 1589/10000 [00:05<00:28, 291.17it/s]Running 10000 simulations.:  16%|█▌        | 1619/10000 [00:05<00:28, 291.21it/s]Running 10000 simulations.:  16%|█▋        | 1649/10000 [00:05<00:28, 291.21it/s]Running 10000 simulations.:  17%|█▋        | 1679/10000 [00:05<00:28, 292.19it/s]Running 10000 simulations.:  17%|█▋        | 1709/10000 [00:05<00:28, 291.54it/s]Running 10000 simulations.:  17%|█▋        | 1739/10000 [00:05<00:28, 291.35it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:06<00:28, 291.70it/s]Running 10000 simulations.:  18%|█▊        | 1799/10000 [00:06<00:28, 292.40it/s]Running 10000 simulations.:  18%|█▊        | 1829/10000 [00:06<00:27, 293.42it/s]Running 10000 simulations.:  19%|█▊        | 1859/10000 [00:06<00:27, 293.36it/s]Running 10000 simulations.:  19%|█▉        | 1889/10000 [00:06<00:27, 292.49it/s]Running 10000 simulations.:  19%|█▉        | 1919/10000 [00:06<00:27, 291.77it/s]Running 10000 simulations.:  19%|█▉        | 1949/10000 [00:06<00:27, 291.01it/s]Running 10000 simulations.:  20%|█▉        | 1979/10000 [00:06<00:27, 291.78it/s]Running 10000 simulations.:  20%|██        | 2009/10000 [00:06<00:27, 292.76it/s]Running 10000 simulations.:  20%|██        | 2039/10000 [00:06<00:27, 293.84it/s]Running 10000 simulations.:  21%|██        | 2069/10000 [00:07<00:26, 294.51it/s]Running 10000 simulations.:  21%|██        | 2099/10000 [00:07<00:26, 294.26it/s]Running 10000 simulations.:  21%|██▏       | 2129/10000 [00:07<00:26, 293.25it/s]Running 10000 simulations.:  22%|██▏       | 2159/10000 [00:07<00:26, 292.23it/s]Running 10000 simulations.:  22%|██▏       | 2189/10000 [00:07<00:26, 291.73it/s]Running 10000 simulations.:  22%|██▏       | 2219/10000 [00:07<00:26, 292.41it/s]Running 10000 simulations.:  22%|██▏       | 2249/10000 [00:07<00:26, 293.01it/s]Running 10000 simulations.:  23%|██▎       | 2279/10000 [00:07<00:26, 292.83it/s]Running 10000 simulations.:  23%|██▎       | 2309/10000 [00:07<00:26, 292.23it/s]Running 10000 simulations.:  23%|██▎       | 2339/10000 [00:07<00:26, 292.03it/s]Running 10000 simulations.:  24%|██▎       | 2369/10000 [00:08<00:26, 291.74it/s]Running 10000 simulations.:  24%|██▍       | 2399/10000 [00:08<00:26, 291.08it/s]Running 10000 simulations.:  24%|██▍       | 2429/10000 [00:08<00:26, 291.12it/s]Running 10000 simulations.:  25%|██▍       | 2459/10000 [00:08<00:25, 291.30it/s]Running 10000 simulations.:  25%|██▍       | 2489/10000 [00:08<00:25, 291.67it/s]Running 10000 simulations.:  25%|██▌       | 2519/10000 [00:08<00:25, 292.22it/s]Running 10000 simulations.:  25%|██▌       | 2549/10000 [00:08<00:25, 292.35it/s]Running 10000 simulations.:  26%|██▌       | 2579/10000 [00:08<00:25, 292.25it/s]Running 10000 simulations.:  26%|██▌       | 2609/10000 [00:08<00:25, 291.67it/s]Running 10000 simulations.:  26%|██▋       | 2639/10000 [00:09<00:25, 292.27it/s]Running 10000 simulations.:  27%|██▋       | 2669/10000 [00:09<00:24, 293.38it/s]Running 10000 simulations.:  27%|██▋       | 2699/10000 [00:09<00:24, 293.59it/s]Running 10000 simulations.:  27%|██▋       | 2729/10000 [00:09<00:24, 292.95it/s]Running 10000 simulations.:  28%|██▊       | 2759/10000 [00:09<00:24, 292.55it/s]Running 10000 simulations.:  28%|██▊       | 2789/10000 [00:09<00:24, 291.97it/s]Running 10000 simulations.:  28%|██▊       | 2819/10000 [00:09<00:24, 292.89it/s]Running 10000 simulations.:  28%|██▊       | 2849/10000 [00:09<00:24, 291.91it/s]Running 10000 simulations.:  29%|██▉       | 2879/10000 [00:09<00:24, 292.30it/s]Running 10000 simulations.:  29%|██▉       | 2909/10000 [00:09<00:24, 291.71it/s]Running 10000 simulations.:  29%|██▉       | 2939/10000 [00:10<00:24, 291.57it/s]Running 10000 simulations.:  30%|██▉       | 2969/10000 [00:10<00:24, 292.10it/s]Running 10000 simulations.:  30%|██▉       | 2999/10000 [00:10<00:23, 292.76it/s]Running 10000 simulations.:  30%|███       | 3029/10000 [00:10<00:23, 291.99it/s]Running 10000 simulations.:  31%|███       | 3059/10000 [00:10<00:23, 291.86it/s]Running 10000 simulations.:  31%|███       | 3089/10000 [00:10<00:23, 292.22it/s]Running 10000 simulations.:  31%|███       | 3119/10000 [00:10<00:23, 291.49it/s]Running 10000 simulations.:  31%|███▏      | 3149/10000 [00:10<00:23, 291.27it/s]Running 10000 simulations.:  32%|███▏      | 3179/10000 [00:10<00:23, 290.85it/s]Running 10000 simulations.:  32%|███▏      | 3209/10000 [00:10<00:23, 291.18it/s]Running 10000 simulations.:  32%|███▏      | 3239/10000 [00:11<00:23, 292.22it/s]Running 10000 simulations.:  33%|███▎      | 3269/10000 [00:11<00:22, 293.46it/s]Running 10000 simulations.:  33%|███▎      | 3299/10000 [00:11<00:22, 294.07it/s]Running 10000 simulations.:  33%|███▎      | 3329/10000 [00:11<00:22, 294.65it/s]Running 10000 simulations.:  34%|███▎      | 3359/10000 [00:11<00:22, 295.12it/s]Running 10000 simulations.:  34%|███▍      | 3389/10000 [00:11<00:22, 294.86it/s]Running 10000 simulations.:  34%|███▍      | 3419/10000 [00:11<00:22, 295.02it/s]Running 10000 simulations.:  34%|███▍      | 3449/10000 [00:11<00:22, 294.64it/s]Running 10000 simulations.:  35%|███▍      | 3479/10000 [00:11<00:22, 293.98it/s]Running 10000 simulations.:  35%|███▌      | 3509/10000 [00:11<00:22, 294.25it/s]Running 10000 simulations.:  35%|███▌      | 3539/10000 [00:12<00:21, 294.69it/s]Running 10000 simulations.:  36%|███▌      | 3569/10000 [00:12<00:21, 294.98it/s]Running 10000 simulations.:  36%|███▌      | 3599/10000 [00:12<00:21, 295.00it/s]Running 10000 simulations.:  36%|███▋      | 3629/10000 [00:12<00:21, 294.95it/s]Running 10000 simulations.:  37%|███▋      | 3659/10000 [00:12<00:21, 295.18it/s]Running 10000 simulations.:  37%|███▋      | 3689/10000 [00:12<00:21, 294.99it/s]Running 10000 simulations.:  37%|███▋      | 3719/10000 [00:12<00:21, 294.39it/s]Running 10000 simulations.:  37%|███▋      | 3749/10000 [00:12<00:21, 294.43it/s]Running 10000 simulations.:  38%|███▊      | 3779/10000 [00:12<00:21, 292.96it/s]Running 10000 simulations.:  38%|███▊      | 3809/10000 [00:13<00:21, 291.73it/s]Running 10000 simulations.:  38%|███▊      | 3839/10000 [00:13<00:21, 291.95it/s]Running 10000 simulations.:  39%|███▊      | 3869/10000 [00:13<00:20, 292.05it/s]Running 10000 simulations.:  39%|███▉      | 3899/10000 [00:13<00:20, 292.11it/s]Running 10000 simulations.:  39%|███▉      | 3929/10000 [00:13<00:20, 291.92it/s]Running 10000 simulations.:  40%|███▉      | 3959/10000 [00:13<00:20, 292.00it/s]Running 10000 simulations.:  40%|███▉      | 3989/10000 [00:13<00:20, 292.06it/s]Running 10000 simulations.:  40%|████      | 4019/10000 [00:13<00:20, 291.92it/s]Running 10000 simulations.:  40%|████      | 4049/10000 [00:13<00:20, 291.66it/s]Running 10000 simulations.:  41%|████      | 4079/10000 [00:13<00:20, 292.40it/s]Running 10000 simulations.:  41%|████      | 4109/10000 [00:14<00:20, 293.13it/s]Running 10000 simulations.:  41%|████▏     | 4139/10000 [00:14<00:19, 293.90it/s]Running 10000 simulations.:  42%|████▏     | 4169/10000 [00:14<00:19, 294.27it/s]Running 10000 simulations.:  42%|████▏     | 4199/10000 [00:14<00:19, 293.26it/s]Running 10000 simulations.:  42%|████▏     | 4229/10000 [00:14<00:19, 292.99it/s]Running 10000 simulations.:  43%|████▎     | 4259/10000 [00:14<00:19, 293.17it/s]Running 10000 simulations.:  43%|████▎     | 4289/10000 [00:14<00:19, 293.30it/s]Running 10000 simulations.:  43%|████▎     | 4319/10000 [00:14<00:19, 293.10it/s]Running 10000 simulations.:  43%|████▎     | 4349/10000 [00:14<00:19, 293.49it/s]Running 10000 simulations.:  44%|████▍     | 4379/10000 [00:14<00:19, 293.52it/s]Running 10000 simulations.:  44%|████▍     | 4409/10000 [00:15<00:19, 293.51it/s]Running 10000 simulations.:  44%|████▍     | 4439/10000 [00:15<00:18, 294.03it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:15<00:18, 294.48it/s]Running 10000 simulations.:  45%|████▍     | 4499/10000 [00:15<00:18, 294.85it/s]Running 10000 simulations.:  45%|████▌     | 4529/10000 [00:15<00:18, 295.14it/s]Running 10000 simulations.:  46%|████▌     | 4559/10000 [00:15<00:18, 295.44it/s]Running 10000 simulations.:  46%|████▌     | 4589/10000 [00:15<00:18, 295.49it/s]Running 10000 simulations.:  46%|████▌     | 4619/10000 [00:15<00:18, 295.49it/s]Running 10000 simulations.:  46%|████▋     | 4649/10000 [00:15<00:18, 294.72it/s]Running 10000 simulations.:  47%|████▋     | 4679/10000 [00:15<00:18, 294.32it/s]Running 10000 simulations.:  47%|████▋     | 4709/10000 [00:16<00:17, 294.42it/s]Running 10000 simulations.:  47%|████▋     | 4739/10000 [00:16<00:17, 294.98it/s]Running 10000 simulations.:  48%|████▊     | 4769/10000 [00:16<00:17, 294.71it/s]Running 10000 simulations.:  48%|████▊     | 4799/10000 [00:16<00:17, 294.14it/s]Running 10000 simulations.:  48%|████▊     | 4829/10000 [00:16<00:17, 293.60it/s]Running 10000 simulations.:  49%|████▊     | 4859/10000 [00:16<00:17, 293.86it/s]Running 10000 simulations.:  49%|████▉     | 4889/10000 [00:16<00:17, 293.33it/s]Running 10000 simulations.:  49%|████▉     | 4919/10000 [00:16<00:17, 294.07it/s]Running 10000 simulations.:  49%|████▉     | 4949/10000 [00:16<00:17, 294.35it/s]Running 10000 simulations.:  50%|████▉     | 4979/10000 [00:16<00:17, 294.78it/s]Running 10000 simulations.:  50%|█████     | 5009/10000 [00:17<00:16, 294.97it/s]Running 10000 simulations.:  50%|█████     | 5039/10000 [00:17<00:16, 295.32it/s]Running 10000 simulations.:  51%|█████     | 5069/10000 [00:17<00:16, 295.10it/s]Running 10000 simulations.:  51%|█████     | 5099/10000 [00:17<00:16, 295.27it/s]Running 10000 simulations.:  51%|█████▏    | 5129/10000 [00:17<00:16, 295.46it/s]Running 10000 simulations.:  52%|█████▏    | 5159/10000 [00:17<00:16, 295.30it/s]Running 10000 simulations.:  52%|█████▏    | 5189/10000 [00:17<00:16, 294.12it/s]Running 10000 simulations.:  52%|█████▏    | 5219/10000 [00:17<00:16, 292.95it/s]Running 10000 simulations.:  52%|█████▏    | 5249/10000 [00:17<00:16, 291.81it/s]Running 10000 simulations.:  53%|█████▎    | 5279/10000 [00:18<00:16, 291.34it/s]Running 10000 simulations.:  53%|█████▎    | 5309/10000 [00:18<00:16, 291.12it/s]Running 10000 simulations.:  53%|█████▎    | 5339/10000 [00:18<00:16, 290.61it/s]Running 10000 simulations.:  54%|█████▎    | 5369/10000 [00:18<00:15, 290.12it/s]Running 10000 simulations.:  54%|█████▍    | 5399/10000 [00:18<00:15, 289.69it/s]Running 10000 simulations.:  54%|█████▍    | 5429/10000 [00:18<00:15, 290.13it/s]Running 10000 simulations.:  55%|█████▍    | 5459/10000 [00:18<00:15, 289.66it/s]Running 10000 simulations.:  55%|█████▍    | 5489/10000 [00:18<00:15, 290.00it/s]Running 10000 simulations.:  55%|█████▌    | 5519/10000 [00:18<00:15, 290.35it/s]Running 10000 simulations.:  55%|█████▌    | 5549/10000 [00:18<00:15, 291.15it/s]Running 10000 simulations.:  56%|█████▌    | 5579/10000 [00:19<00:15, 290.95it/s]Running 10000 simulations.:  56%|█████▌    | 5609/10000 [00:19<00:15, 290.61it/s]Running 10000 simulations.:  56%|█████▋    | 5639/10000 [00:19<00:15, 290.46it/s]Running 10000 simulations.:  57%|█████▋    | 5669/10000 [00:19<00:14, 290.76it/s]Running 10000 simulations.:  57%|█████▋    | 5699/10000 [00:19<00:14, 289.31it/s]Running 10000 simulations.:  57%|█████▋    | 5729/10000 [00:19<00:14, 289.65it/s]Running 10000 simulations.:  58%|█████▊    | 5759/10000 [00:19<00:14, 289.97it/s]Running 10000 simulations.:  58%|█████▊    | 5789/10000 [00:19<00:14, 290.62it/s]Running 10000 simulations.:  58%|█████▊    | 5819/10000 [00:19<00:14, 290.97it/s]Running 10000 simulations.:  58%|█████▊    | 5849/10000 [00:19<00:14, 290.48it/s]Running 10000 simulations.:  59%|█████▉    | 5879/10000 [00:20<00:14, 290.27it/s]Running 10000 simulations.:  59%|█████▉    | 5909/10000 [00:20<00:14, 289.84it/s]Running 10000 simulations.:  59%|█████▉    | 5939/10000 [00:20<00:13, 290.39it/s]Running 10000 simulations.:  60%|█████▉    | 5969/10000 [00:20<00:13, 290.80it/s]Running 10000 simulations.:  60%|█████▉    | 5999/10000 [00:20<00:13, 290.56it/s]Running 10000 simulations.:  60%|██████    | 6029/10000 [00:20<00:13, 290.24it/s]Running 10000 simulations.:  61%|██████    | 6059/10000 [00:20<00:13, 290.48it/s]Running 10000 simulations.:  61%|██████    | 6089/10000 [00:20<00:13, 290.50it/s]Running 10000 simulations.:  61%|██████    | 6119/10000 [00:20<00:13, 290.44it/s]Running 10000 simulations.:  61%|██████▏   | 6149/10000 [00:21<00:16, 238.38it/s]Running 10000 simulations.:  62%|██████▏   | 6179/10000 [00:21<00:15, 251.90it/s]Running 10000 simulations.:  62%|██████▏   | 6208/10000 [00:21<00:14, 262.07it/s]Running 10000 simulations.:  62%|██████▏   | 6237/10000 [00:21<00:13, 269.78it/s]Running 10000 simulations.:  63%|██████▎   | 6267/10000 [00:21<00:13, 276.13it/s]Running 10000 simulations.:  63%|██████▎   | 6296/10000 [00:21<00:13, 280.05it/s]Running 10000 simulations.:  63%|██████▎   | 6326/10000 [00:21<00:12, 283.03it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:21<00:12, 285.78it/s]Running 10000 simulations.:  64%|██████▍   | 6386/10000 [00:21<00:12, 287.46it/s]Running 10000 simulations.:  64%|██████▍   | 6416/10000 [00:22<00:12, 289.34it/s]Running 10000 simulations.:  64%|██████▍   | 6446/10000 [00:22<00:12, 290.64it/s]Running 10000 simulations.:  65%|██████▍   | 6476/10000 [00:22<00:12, 292.23it/s]Running 10000 simulations.:  65%|██████▌   | 6506/10000 [00:22<00:11, 292.50it/s]Running 10000 simulations.:  65%|██████▌   | 6536/10000 [00:22<00:11, 292.63it/s]Running 10000 simulations.:  66%|██████▌   | 6566/10000 [00:22<00:11, 293.62it/s]Running 10000 simulations.:  66%|██████▌   | 6596/10000 [00:22<00:11, 294.14it/s]Running 10000 simulations.:  66%|██████▋   | 6626/10000 [00:22<00:11, 293.98it/s]Running 10000 simulations.:  67%|██████▋   | 6656/10000 [00:22<00:11, 293.27it/s]Running 10000 simulations.:  67%|██████▋   | 6686/10000 [00:22<00:11, 291.93it/s]Running 10000 simulations.:  67%|██████▋   | 6716/10000 [00:23<00:11, 291.69it/s]Running 10000 simulations.:  67%|██████▋   | 6746/10000 [00:23<00:11, 290.77it/s]Running 10000 simulations.:  68%|██████▊   | 6776/10000 [00:23<00:11, 290.32it/s]Running 10000 simulations.:  68%|██████▊   | 6806/10000 [00:23<00:11, 289.69it/s]Running 10000 simulations.:  68%|██████▊   | 6835/10000 [00:23<00:10, 289.40it/s]Running 10000 simulations.:  69%|██████▊   | 6864/10000 [00:23<00:10, 289.52it/s]Running 10000 simulations.:  69%|██████▉   | 6893/10000 [00:23<00:10, 289.39it/s]Running 10000 simulations.:  69%|██████▉   | 6923/10000 [00:23<00:10, 289.89it/s]Running 10000 simulations.:  70%|██████▉   | 6953/10000 [00:23<00:10, 291.32it/s]Running 10000 simulations.:  70%|██████▉   | 6983/10000 [00:23<00:10, 292.91it/s]Running 10000 simulations.:  70%|███████   | 7013/10000 [00:24<00:10, 293.91it/s]Running 10000 simulations.:  70%|███████   | 7043/10000 [00:24<00:10, 294.47it/s]Running 10000 simulations.:  71%|███████   | 7073/10000 [00:24<00:09, 295.13it/s]Running 10000 simulations.:  71%|███████   | 7103/10000 [00:24<00:09, 295.24it/s]Running 10000 simulations.:  71%|███████▏  | 7133/10000 [00:24<00:09, 295.45it/s]Running 10000 simulations.:  72%|███████▏  | 7163/10000 [00:24<00:09, 294.99it/s]Running 10000 simulations.:  72%|███████▏  | 7193/10000 [00:24<00:09, 293.54it/s]Running 10000 simulations.:  72%|███████▏  | 7223/10000 [00:24<00:09, 293.81it/s]Running 10000 simulations.:  73%|███████▎  | 7253/10000 [00:24<00:09, 294.20it/s]Running 10000 simulations.:  73%|███████▎  | 7283/10000 [00:24<00:09, 295.03it/s]Running 10000 simulations.:  73%|███████▎  | 7313/10000 [00:25<00:09, 295.01it/s]Running 10000 simulations.:  73%|███████▎  | 7343/10000 [00:25<00:08, 295.40it/s]Running 10000 simulations.:  74%|███████▎  | 7373/10000 [00:25<00:08, 295.73it/s]Running 10000 simulations.:  74%|███████▍  | 7403/10000 [00:25<00:08, 295.45it/s]Running 10000 simulations.:  74%|███████▍  | 7433/10000 [00:25<00:08, 295.40it/s]Running 10000 simulations.:  75%|███████▍  | 7463/10000 [00:25<00:08, 295.54it/s]Running 10000 simulations.:  75%|███████▍  | 7493/10000 [00:25<00:08, 294.44it/s]Running 10000 simulations.:  75%|███████▌  | 7523/10000 [00:25<00:08, 293.81it/s]Running 10000 simulations.:  76%|███████▌  | 7553/10000 [00:25<00:08, 292.60it/s]Running 10000 simulations.:  76%|███████▌  | 7583/10000 [00:25<00:08, 292.60it/s]Running 10000 simulations.:  76%|███████▌  | 7613/10000 [00:26<00:08, 292.73it/s]Running 10000 simulations.:  76%|███████▋  | 7643/10000 [00:26<00:08, 292.40it/s]Running 10000 simulations.:  77%|███████▋  | 7673/10000 [00:26<00:07, 293.47it/s]Running 10000 simulations.:  77%|███████▋  | 7703/10000 [00:26<00:07, 292.98it/s]Running 10000 simulations.:  77%|███████▋  | 7733/10000 [00:26<00:07, 292.28it/s]Running 10000 simulations.:  78%|███████▊  | 7763/10000 [00:26<00:07, 291.85it/s]Running 10000 simulations.:  78%|███████▊  | 7793/10000 [00:26<00:07, 291.33it/s]Running 10000 simulations.:  78%|███████▊  | 7823/10000 [00:26<00:07, 291.07it/s]Running 10000 simulations.:  79%|███████▊  | 7853/10000 [00:26<00:07, 291.03it/s]Running 10000 simulations.:  79%|███████▉  | 7883/10000 [00:27<00:07, 291.07it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:27<00:07, 290.78it/s]Running 10000 simulations.:  79%|███████▉  | 7943/10000 [00:27<00:07, 290.45it/s]Running 10000 simulations.:  80%|███████▉  | 7973/10000 [00:27<00:06, 290.82it/s]Running 10000 simulations.:  80%|████████  | 8003/10000 [00:27<00:06, 291.65it/s]Running 10000 simulations.:  80%|████████  | 8033/10000 [00:27<00:06, 293.14it/s]Running 10000 simulations.:  81%|████████  | 8063/10000 [00:27<00:06, 294.06it/s]Running 10000 simulations.:  81%|████████  | 8093/10000 [00:27<00:06, 294.78it/s]Running 10000 simulations.:  81%|████████  | 8123/10000 [00:27<00:06, 294.80it/s]Running 10000 simulations.:  82%|████████▏ | 8153/10000 [00:27<00:06, 295.28it/s]Running 10000 simulations.:  82%|████████▏ | 8183/10000 [00:28<00:06, 295.66it/s]Running 10000 simulations.:  82%|████████▏ | 8213/10000 [00:28<00:06, 295.66it/s]Running 10000 simulations.:  82%|████████▏ | 8243/10000 [00:28<00:05, 295.98it/s]Running 10000 simulations.:  83%|████████▎ | 8273/10000 [00:28<00:05, 296.18it/s]Running 10000 simulations.:  83%|████████▎ | 8303/10000 [00:28<00:05, 296.25it/s]Running 10000 simulations.:  83%|████████▎ | 8333/10000 [00:28<00:05, 295.92it/s]Running 10000 simulations.:  84%|████████▎ | 8363/10000 [00:28<00:05, 296.20it/s]Running 10000 simulations.:  84%|████████▍ | 8393/10000 [00:28<00:05, 296.41it/s]Running 10000 simulations.:  84%|████████▍ | 8423/10000 [00:28<00:05, 296.64it/s]Running 10000 simulations.:  85%|████████▍ | 8453/10000 [00:28<00:05, 296.65it/s]Running 10000 simulations.:  85%|████████▍ | 8483/10000 [00:29<00:05, 296.57it/s]Running 10000 simulations.:  85%|████████▌ | 8513/10000 [00:29<00:05, 296.75it/s]Running 10000 simulations.:  85%|████████▌ | 8543/10000 [00:29<00:04, 296.84it/s]Running 10000 simulations.:  86%|████████▌ | 8573/10000 [00:29<00:04, 296.74it/s]Running 10000 simulations.:  86%|████████▌ | 8603/10000 [00:29<00:04, 296.66it/s]Running 10000 simulations.:  86%|████████▋ | 8633/10000 [00:29<00:04, 296.70it/s]Running 10000 simulations.:  87%|████████▋ | 8663/10000 [00:29<00:04, 296.62it/s]Running 10000 simulations.:  87%|████████▋ | 8693/10000 [00:29<00:04, 286.45it/s]Running 10000 simulations.:  87%|████████▋ | 8723/10000 [00:29<00:04, 287.50it/s]Running 10000 simulations.:  88%|████████▊ | 8753/10000 [00:29<00:04, 288.49it/s]Running 10000 simulations.:  88%|████████▊ | 8783/10000 [00:30<00:04, 289.87it/s]Running 10000 simulations.:  88%|████████▊ | 8813/10000 [00:30<00:04, 291.08it/s]Running 10000 simulations.:  88%|████████▊ | 8843/10000 [00:30<00:03, 292.00it/s]Running 10000 simulations.:  89%|████████▊ | 8873/10000 [00:30<00:03, 292.80it/s]Running 10000 simulations.:  89%|████████▉ | 8903/10000 [00:30<00:03, 293.79it/s]Running 10000 simulations.:  89%|████████▉ | 8933/10000 [00:30<00:03, 294.69it/s]Running 10000 simulations.:  90%|████████▉ | 8963/10000 [00:30<00:03, 294.40it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [00:30<00:03, 294.11it/s]Running 10000 simulations.:  90%|█████████ | 9023/10000 [00:30<00:03, 293.99it/s]Running 10000 simulations.:  91%|█████████ | 9053/10000 [00:30<00:03, 294.95it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [00:31<00:03, 295.44it/s]Running 10000 simulations.:  91%|█████████ | 9113/10000 [00:31<00:02, 296.00it/s]Running 10000 simulations.:  91%|█████████▏| 9143/10000 [00:31<00:02, 296.35it/s]Running 10000 simulations.:  92%|█████████▏| 9173/10000 [00:31<00:02, 296.24it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [00:31<00:02, 296.23it/s]Running 10000 simulations.:  92%|█████████▏| 9233/10000 [00:31<00:02, 295.90it/s]Running 10000 simulations.:  93%|█████████▎| 9263/10000 [00:31<00:02, 294.42it/s]Running 10000 simulations.:  93%|█████████▎| 9293/10000 [00:31<00:02, 293.71it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [00:31<00:02, 292.67it/s]Running 10000 simulations.:  94%|█████████▎| 9353/10000 [00:32<00:02, 292.36it/s]Running 10000 simulations.:  94%|█████████▍| 9383/10000 [00:32<00:02, 292.23it/s]Running 10000 simulations.:  94%|█████████▍| 9413/10000 [00:32<00:02, 291.78it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [00:32<00:01, 291.82it/s]Running 10000 simulations.:  95%|█████████▍| 9473/10000 [00:32<00:01, 292.48it/s]Running 10000 simulations.:  95%|█████████▌| 9503/10000 [00:32<00:01, 293.36it/s]Running 10000 simulations.:  95%|█████████▌| 9533/10000 [00:32<00:01, 294.09it/s]Running 10000 simulations.:  96%|█████████▌| 9563/10000 [00:32<00:01, 293.92it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:32<00:01, 293.70it/s]Running 10000 simulations.:  96%|█████████▌| 9623/10000 [00:32<00:01, 293.40it/s]Running 10000 simulations.:  97%|█████████▋| 9653/10000 [00:33<00:01, 293.98it/s]Running 10000 simulations.:  97%|█████████▋| 9683/10000 [00:33<00:01, 293.53it/s]Running 10000 simulations.:  97%|█████████▋| 9713/10000 [00:33<00:00, 292.71it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [00:33<00:00, 292.00it/s]Running 10000 simulations.:  98%|█████████▊| 9773/10000 [00:33<00:00, 291.82it/s]Running 10000 simulations.:  98%|█████████▊| 9803/10000 [00:33<00:00, 291.46it/s]Running 10000 simulations.:  98%|█████████▊| 9833/10000 [00:33<00:00, 291.68it/s]Running 10000 simulations.:  99%|█████████▊| 9863/10000 [00:33<00:00, 292.08it/s]Running 10000 simulations.:  99%|█████████▉| 9893/10000 [00:33<00:00, 291.66it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [00:33<00:00, 292.05it/s]Running 10000 simulations.: 100%|█████████▉| 9953/10000 [00:34<00:00, 293.19it/s]Running 10000 simulations.: 100%|█████████▉| 9983/10000 [00:34<00:00, 292.59it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:34<00:00, 292.21it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<00:34, 291.19it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<00:34, 291.42it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<00:33, 291.53it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<00:33, 291.02it/s]Running 10000 simulations.:   1%|▏         | 149/10000 [00:00<00:33, 291.30it/s]Running 10000 simulations.:   2%|▏         | 179/10000 [00:00<00:33, 291.05it/s]Running 10000 simulations.:   2%|▏         | 209/10000 [00:00<00:33, 292.39it/s]Running 10000 simulations.:   2%|▏         | 239/10000 [00:00<00:33, 292.38it/s]Running 10000 simulations.:   3%|▎         | 269/10000 [00:00<00:33, 292.05it/s]Running 10000 simulations.:   3%|▎         | 299/10000 [00:01<00:33, 292.32it/s]Running 10000 simulations.:   3%|▎         | 329/10000 [00:01<00:33, 292.02it/s]Running 10000 simulations.:   4%|▎         | 358/10000 [00:01<00:33, 291.23it/s]Running 10000 simulations.:   4%|▍         | 388/10000 [00:01<00:33, 291.17it/s]Running 10000 simulations.:   4%|▍         | 418/10000 [00:01<00:32, 291.92it/s]Running 10000 simulations.:   4%|▍         | 448/10000 [00:01<00:32, 291.73it/s]Running 10000 simulations.:   5%|▍         | 478/10000 [00:01<00:32, 292.08it/s]Running 10000 simulations.:   5%|▌         | 508/10000 [00:01<00:32, 292.36it/s]Running 10000 simulations.:   5%|▌         | 538/10000 [00:01<00:32, 292.01it/s]Running 10000 simulations.:   6%|▌         | 568/10000 [00:01<00:32, 292.91it/s]Running 10000 simulations.:   6%|▌         | 598/10000 [00:02<00:32, 293.50it/s]Running 10000 simulations.:   6%|▋         | 628/10000 [00:02<00:31, 294.12it/s]Running 10000 simulations.:   7%|▋         | 658/10000 [00:02<00:31, 293.73it/s]Running 10000 simulations.:   7%|▋         | 688/10000 [00:02<00:31, 293.03it/s]Running 10000 simulations.:   7%|▋         | 718/10000 [00:02<00:31, 292.57it/s]Running 10000 simulations.:   7%|▋         | 748/10000 [00:02<00:31, 292.51it/s]Running 10000 simulations.:   8%|▊         | 778/10000 [00:02<00:31, 291.80it/s]Running 10000 simulations.:   8%|▊         | 808/10000 [00:02<00:31, 291.45it/s]Running 10000 simulations.:   8%|▊         | 838/10000 [00:02<00:31, 291.20it/s]Running 10000 simulations.:   9%|▊         | 868/10000 [00:02<00:31, 290.93it/s]Running 10000 simulations.:   9%|▉         | 898/10000 [00:03<00:31, 291.07it/s]Running 10000 simulations.:   9%|▉         | 928/10000 [00:03<00:31, 290.93it/s]Running 10000 simulations.:  10%|▉         | 958/10000 [00:03<00:30, 291.83it/s]Running 10000 simulations.:  10%|▉         | 988/10000 [00:03<00:30, 293.12it/s]Running 10000 simulations.:  10%|█         | 1018/10000 [00:03<00:30, 294.23it/s]Running 10000 simulations.:  10%|█         | 1048/10000 [00:03<00:30, 293.36it/s]Running 10000 simulations.:  11%|█         | 1078/10000 [00:03<00:30, 293.12it/s]Running 10000 simulations.:  11%|█         | 1108/10000 [00:03<00:30, 292.96it/s]Running 10000 simulations.:  11%|█▏        | 1138/10000 [00:03<00:30, 292.86it/s]Running 10000 simulations.:  12%|█▏        | 1168/10000 [00:03<00:30, 293.28it/s]Running 10000 simulations.:  12%|█▏        | 1198/10000 [00:04<00:30, 293.10it/s]Running 10000 simulations.:  12%|█▏        | 1228/10000 [00:04<00:29, 293.52it/s]Running 10000 simulations.:  13%|█▎        | 1258/10000 [00:04<00:29, 293.35it/s]Running 10000 simulations.:  13%|█▎        | 1288/10000 [00:04<00:29, 293.78it/s]Running 10000 simulations.:  13%|█▎        | 1318/10000 [00:04<00:29, 294.63it/s]Running 10000 simulations.:  13%|█▎        | 1348/10000 [00:04<00:29, 294.55it/s]Running 10000 simulations.:  14%|█▍        | 1378/10000 [00:04<00:29, 294.99it/s]Running 10000 simulations.:  14%|█▍        | 1408/10000 [00:04<00:29, 294.20it/s]Running 10000 simulations.:  14%|█▍        | 1438/10000 [00:04<00:29, 294.56it/s]Running 10000 simulations.:  15%|█▍        | 1468/10000 [00:05<00:28, 294.64it/s]Running 10000 simulations.:  15%|█▍        | 1498/10000 [00:05<00:28, 294.79it/s]Running 10000 simulations.:  15%|█▌        | 1528/10000 [00:05<00:28, 295.41it/s]Running 10000 simulations.:  16%|█▌        | 1558/10000 [00:05<00:28, 295.65it/s]Running 10000 simulations.:  16%|█▌        | 1588/10000 [00:05<00:28, 295.84it/s]Running 10000 simulations.:  16%|█▌        | 1618/10000 [00:05<00:28, 295.70it/s]Running 10000 simulations.:  16%|█▋        | 1648/10000 [00:05<00:28, 294.91it/s]Running 10000 simulations.:  17%|█▋        | 1678/10000 [00:05<00:28, 293.93it/s]Running 10000 simulations.:  17%|█▋        | 1708/10000 [00:05<00:28, 294.01it/s]Running 10000 simulations.:  17%|█▋        | 1738/10000 [00:05<00:28, 293.86it/s]Running 10000 simulations.:  18%|█▊        | 1768/10000 [00:06<00:28, 293.70it/s]Running 10000 simulations.:  18%|█▊        | 1798/10000 [00:06<00:27, 294.22it/s]Running 10000 simulations.:  18%|█▊        | 1828/10000 [00:06<00:27, 294.46it/s]Running 10000 simulations.:  19%|█▊        | 1858/10000 [00:06<00:27, 294.90it/s]Running 10000 simulations.:  19%|█▉        | 1888/10000 [00:06<00:27, 295.49it/s]Running 10000 simulations.:  19%|█▉        | 1918/10000 [00:06<00:27, 295.39it/s]Running 10000 simulations.:  19%|█▉        | 1948/10000 [00:06<00:27, 295.63it/s]Running 10000 simulations.:  20%|█▉        | 1978/10000 [00:06<00:27, 295.14it/s]Running 10000 simulations.:  20%|██        | 2008/10000 [00:06<00:27, 294.14it/s]Running 10000 simulations.:  20%|██        | 2038/10000 [00:06<00:27, 292.51it/s]Running 10000 simulations.:  21%|██        | 2068/10000 [00:07<00:27, 292.49it/s]Running 10000 simulations.:  21%|██        | 2098/10000 [00:07<00:26, 292.93it/s]Running 10000 simulations.:  21%|██▏       | 2128/10000 [00:07<00:26, 294.06it/s]Running 10000 simulations.:  22%|██▏       | 2158/10000 [00:07<00:26, 294.30it/s]Running 10000 simulations.:  22%|██▏       | 2188/10000 [00:07<00:26, 293.02it/s]Running 10000 simulations.:  22%|██▏       | 2218/10000 [00:07<00:26, 293.93it/s]Running 10000 simulations.:  22%|██▏       | 2248/10000 [00:07<00:26, 294.43it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:07<00:26, 294.29it/s]Running 10000 simulations.:  23%|██▎       | 2308/10000 [00:07<00:26, 292.97it/s]Running 10000 simulations.:  23%|██▎       | 2338/10000 [00:07<00:26, 292.30it/s]Running 10000 simulations.:  24%|██▎       | 2368/10000 [00:08<00:26, 292.14it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:08<00:25, 292.39it/s]Running 10000 simulations.:  24%|██▍       | 2428/10000 [00:08<00:25, 292.26it/s]Running 10000 simulations.:  25%|██▍       | 2458/10000 [00:08<00:25, 292.37it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:08<00:25, 292.88it/s]Running 10000 simulations.:  25%|██▌       | 2518/10000 [00:08<00:25, 293.89it/s]Running 10000 simulations.:  25%|██▌       | 2548/10000 [00:08<00:25, 294.31it/s]Running 10000 simulations.:  26%|██▌       | 2578/10000 [00:08<00:25, 293.21it/s]Running 10000 simulations.:  26%|██▌       | 2608/10000 [00:08<00:25, 293.44it/s]Running 10000 simulations.:  26%|██▋       | 2638/10000 [00:08<00:25, 293.74it/s]Running 10000 simulations.:  27%|██▋       | 2668/10000 [00:09<00:24, 294.46it/s]Running 10000 simulations.:  27%|██▋       | 2698/10000 [00:09<00:24, 294.89it/s]Running 10000 simulations.:  27%|██▋       | 2728/10000 [00:09<00:24, 295.38it/s]Running 10000 simulations.:  28%|██▊       | 2758/10000 [00:09<00:24, 295.79it/s]Running 10000 simulations.:  28%|██▊       | 2788/10000 [00:09<00:24, 295.95it/s]Running 10000 simulations.:  28%|██▊       | 2818/10000 [00:09<00:24, 296.02it/s]Running 10000 simulations.:  28%|██▊       | 2848/10000 [00:09<00:24, 296.10it/s]Running 10000 simulations.:  29%|██▉       | 2878/10000 [00:09<00:24, 296.24it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:09<00:23, 296.22it/s]Running 10000 simulations.:  29%|██▉       | 2938/10000 [00:10<00:23, 295.96it/s]Running 10000 simulations.:  30%|██▉       | 2968/10000 [00:10<00:23, 296.10it/s]Running 10000 simulations.:  30%|██▉       | 2998/10000 [00:10<00:23, 296.13it/s]Running 10000 simulations.:  30%|███       | 3028/10000 [00:10<00:23, 295.79it/s]Running 10000 simulations.:  31%|███       | 3058/10000 [00:10<00:23, 295.53it/s]Running 10000 simulations.:  31%|███       | 3088/10000 [00:10<00:23, 295.75it/s]Running 10000 simulations.:  31%|███       | 3118/10000 [00:10<00:23, 295.85it/s]Running 10000 simulations.:  31%|███▏      | 3148/10000 [00:10<00:23, 295.39it/s]Running 10000 simulations.:  32%|███▏      | 3178/10000 [00:10<00:23, 295.27it/s]Running 10000 simulations.:  32%|███▏      | 3208/10000 [00:10<00:23, 295.13it/s]Running 10000 simulations.:  32%|███▏      | 3238/10000 [00:11<00:22, 294.41it/s]Running 10000 simulations.:  33%|███▎      | 3268/10000 [00:11<00:22, 293.32it/s]Running 10000 simulations.:  33%|███▎      | 3298/10000 [00:11<00:22, 293.54it/s]Running 10000 simulations.:  33%|███▎      | 3328/10000 [00:11<00:22, 294.14it/s]Running 10000 simulations.:  34%|███▎      | 3358/10000 [00:11<00:22, 294.93it/s]Running 10000 simulations.:  34%|███▍      | 3388/10000 [00:11<00:22, 295.24it/s]Running 10000 simulations.:  34%|███▍      | 3418/10000 [00:11<00:22, 294.36it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:11<00:22, 293.74it/s]Running 10000 simulations.:  35%|███▍      | 3478/10000 [00:11<00:22, 293.85it/s]Running 10000 simulations.:  35%|███▌      | 3508/10000 [00:11<00:22, 294.63it/s]Running 10000 simulations.:  35%|███▌      | 3538/10000 [00:12<00:21, 294.71it/s]Running 10000 simulations.:  36%|███▌      | 3568/10000 [00:12<00:21, 293.33it/s]Running 10000 simulations.:  36%|███▌      | 3598/10000 [00:12<00:21, 292.13it/s]Running 10000 simulations.:  36%|███▋      | 3628/10000 [00:12<00:21, 291.37it/s]Running 10000 simulations.:  37%|███▋      | 3658/10000 [00:12<00:21, 292.06it/s]Running 10000 simulations.:  37%|███▋      | 3688/10000 [00:12<00:21, 292.68it/s]Running 10000 simulations.:  37%|███▋      | 3718/10000 [00:12<00:21, 292.79it/s]Running 10000 simulations.:  37%|███▋      | 3748/10000 [00:12<00:21, 291.53it/s]Running 10000 simulations.:  38%|███▊      | 3778/10000 [00:12<00:21, 291.93it/s]Running 10000 simulations.:  38%|███▊      | 3808/10000 [00:12<00:21, 292.60it/s]Running 10000 simulations.:  38%|███▊      | 3838/10000 [00:13<00:21, 292.43it/s]Running 10000 simulations.:  39%|███▊      | 3868/10000 [00:13<00:20, 292.64it/s]Running 10000 simulations.:  39%|███▉      | 3898/10000 [00:13<00:20, 292.72it/s]Running 10000 simulations.:  39%|███▉      | 3928/10000 [00:13<00:20, 292.52it/s]Running 10000 simulations.:  40%|███▉      | 3958/10000 [00:13<00:20, 292.27it/s]Running 10000 simulations.:  40%|███▉      | 3988/10000 [00:13<00:20, 291.33it/s]Running 10000 simulations.:  40%|████      | 4018/10000 [00:13<00:20, 291.30it/s]Running 10000 simulations.:  40%|████      | 4048/10000 [00:13<00:20, 291.66it/s]Running 10000 simulations.:  41%|████      | 4078/10000 [00:13<00:20, 292.37it/s]Running 10000 simulations.:  41%|████      | 4108/10000 [00:13<00:20, 293.49it/s]Running 10000 simulations.:  41%|████▏     | 4138/10000 [00:14<00:20, 292.76it/s]Running 10000 simulations.:  42%|████▏     | 4168/10000 [00:14<00:20, 284.60it/s]Running 10000 simulations.:  42%|████▏     | 4197/10000 [00:14<00:20, 286.06it/s]Running 10000 simulations.:  42%|████▏     | 4227/10000 [00:14<00:20, 287.62it/s]Running 10000 simulations.:  43%|████▎     | 4257/10000 [00:14<00:19, 288.46it/s]Running 10000 simulations.:  43%|████▎     | 4287/10000 [00:14<00:19, 289.30it/s]Running 10000 simulations.:  43%|████▎     | 4317/10000 [00:14<00:19, 289.67it/s]Running 10000 simulations.:  43%|████▎     | 4346/10000 [00:14<00:19, 288.40it/s]Running 10000 simulations.:  44%|████▍     | 4376/10000 [00:14<00:19, 289.39it/s]Running 10000 simulations.:  44%|████▍     | 4406/10000 [00:15<00:19, 290.49it/s]Running 10000 simulations.:  44%|████▍     | 4436/10000 [00:15<00:19, 290.92it/s]Running 10000 simulations.:  45%|████▍     | 4466/10000 [00:15<00:19, 291.18it/s]Running 10000 simulations.:  45%|████▍     | 4496/10000 [00:15<00:18, 291.13it/s]Running 10000 simulations.:  45%|████▌     | 4526/10000 [00:15<00:18, 291.80it/s]Running 10000 simulations.:  46%|████▌     | 4556/10000 [00:15<00:18, 292.74it/s]Running 10000 simulations.:  46%|████▌     | 4586/10000 [00:15<00:18, 293.03it/s]Running 10000 simulations.:  46%|████▌     | 4616/10000 [00:15<00:18, 292.46it/s]Running 10000 simulations.:  46%|████▋     | 4646/10000 [00:15<00:18, 292.53it/s]Running 10000 simulations.:  47%|████▋     | 4676/10000 [00:15<00:18, 292.57it/s]Running 10000 simulations.:  47%|████▋     | 4706/10000 [00:16<00:18, 292.61it/s]Running 10000 simulations.:  47%|████▋     | 4736/10000 [00:16<00:18, 291.74it/s]Running 10000 simulations.:  48%|████▊     | 4766/10000 [00:16<00:17, 291.52it/s]Running 10000 simulations.:  48%|████▊     | 4796/10000 [00:16<00:17, 292.01it/s]Running 10000 simulations.:  48%|████▊     | 4826/10000 [00:16<00:17, 292.38it/s]Running 10000 simulations.:  49%|████▊     | 4856/10000 [00:16<00:17, 292.84it/s]Running 10000 simulations.:  49%|████▉     | 4886/10000 [00:16<00:17, 292.88it/s]Running 10000 simulations.:  49%|████▉     | 4916/10000 [00:16<00:17, 292.02it/s]Running 10000 simulations.:  49%|████▉     | 4946/10000 [00:16<00:17, 292.58it/s]Running 10000 simulations.:  50%|████▉     | 4976/10000 [00:16<00:17, 292.76it/s]Running 10000 simulations.:  50%|█████     | 5006/10000 [00:17<00:17, 293.72it/s]Running 10000 simulations.:  50%|█████     | 5036/10000 [00:17<00:16, 292.90it/s]Running 10000 simulations.:  51%|█████     | 5066/10000 [00:17<00:16, 292.73it/s]Running 10000 simulations.:  51%|█████     | 5096/10000 [00:17<00:16, 292.27it/s]Running 10000 simulations.:  51%|█████▏    | 5126/10000 [00:17<00:16, 291.65it/s]Running 10000 simulations.:  52%|█████▏    | 5156/10000 [00:17<00:16, 291.16it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:17<00:16, 290.56it/s]Running 10000 simulations.:  52%|█████▏    | 5216/10000 [00:17<00:16, 290.62it/s]Running 10000 simulations.:  52%|█████▏    | 5246/10000 [00:17<00:16, 291.05it/s]Running 10000 simulations.:  53%|█████▎    | 5276/10000 [00:18<00:16, 290.98it/s]Running 10000 simulations.:  53%|█████▎    | 5306/10000 [00:18<00:16, 291.07it/s]Running 10000 simulations.:  53%|█████▎    | 5336/10000 [00:18<00:15, 291.98it/s]Running 10000 simulations.:  54%|█████▎    | 5366/10000 [00:18<00:15, 291.37it/s]Running 10000 simulations.:  54%|█████▍    | 5396/10000 [00:18<00:15, 290.76it/s]Running 10000 simulations.:  54%|█████▍    | 5426/10000 [00:18<00:15, 289.85it/s]Running 10000 simulations.:  55%|█████▍    | 5455/10000 [00:18<00:15, 289.56it/s]Running 10000 simulations.:  55%|█████▍    | 5484/10000 [00:18<00:15, 289.34it/s]Running 10000 simulations.:  55%|█████▌    | 5514/10000 [00:18<00:15, 289.61it/s]Running 10000 simulations.:  55%|█████▌    | 5544/10000 [00:18<00:15, 290.30it/s]Running 10000 simulations.:  56%|█████▌    | 5574/10000 [00:19<00:15, 290.43it/s]Running 10000 simulations.:  56%|█████▌    | 5604/10000 [00:19<00:15, 290.47it/s]Running 10000 simulations.:  56%|█████▋    | 5634/10000 [00:19<00:15, 290.46it/s]Running 10000 simulations.:  57%|█████▋    | 5664/10000 [00:19<00:14, 290.75it/s]Running 10000 simulations.:  57%|█████▋    | 5694/10000 [00:19<00:14, 290.61it/s]Running 10000 simulations.:  57%|█████▋    | 5724/10000 [00:19<00:14, 290.98it/s]Running 10000 simulations.:  58%|█████▊    | 5754/10000 [00:19<00:14, 290.61it/s]Running 10000 simulations.:  58%|█████▊    | 5784/10000 [00:19<00:14, 291.13it/s]Running 10000 simulations.:  58%|█████▊    | 5814/10000 [00:19<00:14, 291.64it/s]Running 10000 simulations.:  58%|█████▊    | 5844/10000 [00:19<00:14, 292.21it/s]Running 10000 simulations.:  59%|█████▊    | 5874/10000 [00:20<00:14, 291.94it/s]Running 10000 simulations.:  59%|█████▉    | 5904/10000 [00:20<00:14, 291.10it/s]Running 10000 simulations.:  59%|█████▉    | 5934/10000 [00:20<00:14, 290.36it/s]Running 10000 simulations.:  60%|█████▉    | 5964/10000 [00:20<00:13, 291.29it/s]Running 10000 simulations.:  60%|█████▉    | 5994/10000 [00:20<00:13, 290.67it/s]Running 10000 simulations.:  60%|██████    | 6024/10000 [00:20<00:13, 290.37it/s]Running 10000 simulations.:  61%|██████    | 6054/10000 [00:20<00:13, 291.04it/s]Running 10000 simulations.:  61%|██████    | 6084/10000 [00:20<00:13, 292.20it/s]Running 10000 simulations.:  61%|██████    | 6114/10000 [00:20<00:13, 292.74it/s]Running 10000 simulations.:  61%|██████▏   | 6144/10000 [00:20<00:13, 293.43it/s]Running 10000 simulations.:  62%|██████▏   | 6174/10000 [00:21<00:13, 292.59it/s]Running 10000 simulations.:  62%|██████▏   | 6204/10000 [00:21<00:12, 293.47it/s]Running 10000 simulations.:  62%|██████▏   | 6234/10000 [00:21<00:12, 294.16it/s]Running 10000 simulations.:  63%|██████▎   | 6264/10000 [00:21<00:12, 294.43it/s]Running 10000 simulations.:  63%|██████▎   | 6294/10000 [00:21<00:12, 294.81it/s]Running 10000 simulations.:  63%|██████▎   | 6324/10000 [00:21<00:12, 295.11it/s]Running 10000 simulations.:  64%|██████▎   | 6354/10000 [00:21<00:12, 295.22it/s]Running 10000 simulations.:  64%|██████▍   | 6384/10000 [00:21<00:12, 295.42it/s]Running 10000 simulations.:  64%|██████▍   | 6414/10000 [00:21<00:12, 295.70it/s]Running 10000 simulations.:  64%|██████▍   | 6444/10000 [00:22<00:12, 295.78it/s]Running 10000 simulations.:  65%|██████▍   | 6474/10000 [00:22<00:11, 295.59it/s]Running 10000 simulations.:  65%|██████▌   | 6504/10000 [00:22<00:11, 295.78it/s]Running 10000 simulations.:  65%|██████▌   | 6534/10000 [00:22<00:11, 295.75it/s]Running 10000 simulations.:  66%|██████▌   | 6564/10000 [00:22<00:11, 295.39it/s]Running 10000 simulations.:  66%|██████▌   | 6594/10000 [00:22<00:11, 295.48it/s]Running 10000 simulations.:  66%|██████▌   | 6624/10000 [00:22<00:11, 295.33it/s]Running 10000 simulations.:  67%|██████▋   | 6654/10000 [00:22<00:11, 295.47it/s]Running 10000 simulations.:  67%|██████▋   | 6684/10000 [00:22<00:11, 295.81it/s]Running 10000 simulations.:  67%|██████▋   | 6714/10000 [00:22<00:11, 295.57it/s]Running 10000 simulations.:  67%|██████▋   | 6744/10000 [00:23<00:11, 295.43it/s]Running 10000 simulations.:  68%|██████▊   | 6774/10000 [00:23<00:10, 295.29it/s]Running 10000 simulations.:  68%|██████▊   | 6804/10000 [00:23<00:10, 295.42it/s]Running 10000 simulations.:  68%|██████▊   | 6834/10000 [00:23<00:10, 295.20it/s]Running 10000 simulations.:  69%|██████▊   | 6864/10000 [00:23<00:10, 295.39it/s]Running 10000 simulations.:  69%|██████▉   | 6894/10000 [00:23<00:10, 295.47it/s]Running 10000 simulations.:  69%|██████▉   | 6924/10000 [00:23<00:10, 295.59it/s]Running 10000 simulations.:  70%|██████▉   | 6954/10000 [00:23<00:10, 294.04it/s]Running 10000 simulations.:  70%|██████▉   | 6984/10000 [00:23<00:10, 293.07it/s]Running 10000 simulations.:  70%|███████   | 7014/10000 [00:23<00:10, 291.78it/s]Running 10000 simulations.:  70%|███████   | 7044/10000 [00:24<00:10, 291.80it/s]Running 10000 simulations.:  71%|███████   | 7074/10000 [00:24<00:10, 290.99it/s]Running 10000 simulations.:  71%|███████   | 7104/10000 [00:24<00:09, 291.10it/s]Running 10000 simulations.:  71%|███████▏  | 7134/10000 [00:24<00:09, 290.66it/s]Running 10000 simulations.:  72%|███████▏  | 7164/10000 [00:24<00:09, 291.48it/s]Running 10000 simulations.:  72%|███████▏  | 7194/10000 [00:24<00:09, 292.59it/s]Running 10000 simulations.:  72%|███████▏  | 7224/10000 [00:24<00:09, 293.23it/s]Running 10000 simulations.:  73%|███████▎  | 7254/10000 [00:24<00:09, 292.05it/s]Running 10000 simulations.:  73%|███████▎  | 7284/10000 [00:24<00:09, 291.53it/s]Running 10000 simulations.:  73%|███████▎  | 7314/10000 [00:24<00:09, 292.11it/s]Running 10000 simulations.:  73%|███████▎  | 7344/10000 [00:25<00:09, 292.04it/s]Running 10000 simulations.:  74%|███████▎  | 7374/10000 [00:25<00:09, 291.26it/s]Running 10000 simulations.:  74%|███████▍  | 7404/10000 [00:25<00:08, 290.71it/s]Running 10000 simulations.:  74%|███████▍  | 7434/10000 [00:25<00:08, 290.70it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:25<00:08, 290.33it/s]Running 10000 simulations.:  75%|███████▍  | 7494/10000 [00:25<00:08, 290.00it/s]Running 10000 simulations.:  75%|███████▌  | 7524/10000 [00:25<00:08, 290.32it/s]Running 10000 simulations.:  76%|███████▌  | 7554/10000 [00:25<00:08, 290.41it/s]Running 10000 simulations.:  76%|███████▌  | 7584/10000 [00:25<00:08, 289.90it/s]Running 10000 simulations.:  76%|███████▌  | 7613/10000 [00:25<00:08, 289.68it/s]Running 10000 simulations.:  76%|███████▋  | 7643/10000 [00:26<00:08, 290.87it/s]Running 10000 simulations.:  77%|███████▋  | 7673/10000 [00:26<00:07, 292.38it/s]Running 10000 simulations.:  77%|███████▋  | 7703/10000 [00:26<00:07, 293.65it/s]Running 10000 simulations.:  77%|███████▋  | 7733/10000 [00:26<00:07, 294.44it/s]Running 10000 simulations.:  78%|███████▊  | 7763/10000 [00:26<00:07, 294.40it/s]Running 10000 simulations.:  78%|███████▊  | 7793/10000 [00:26<00:07, 294.82it/s]Running 10000 simulations.:  78%|███████▊  | 7823/10000 [00:26<00:07, 295.04it/s]Running 10000 simulations.:  79%|███████▊  | 7853/10000 [00:26<00:07, 295.27it/s]Running 10000 simulations.:  79%|███████▉  | 7883/10000 [00:26<00:07, 294.95it/s]Running 10000 simulations.:  79%|███████▉  | 7913/10000 [00:27<00:07, 295.29it/s]Running 10000 simulations.:  79%|███████▉  | 7943/10000 [00:27<00:06, 295.37it/s]Running 10000 simulations.:  80%|███████▉  | 7973/10000 [00:27<00:06, 295.46it/s]Running 10000 simulations.:  80%|████████  | 8003/10000 [00:27<00:06, 295.51it/s]Running 10000 simulations.:  80%|████████  | 8033/10000 [00:27<00:06, 295.63it/s]Running 10000 simulations.:  81%|████████  | 8063/10000 [00:27<00:06, 295.32it/s]Running 10000 simulations.:  81%|████████  | 8093/10000 [00:27<00:06, 295.40it/s]Running 10000 simulations.:  81%|████████  | 8123/10000 [00:27<00:06, 295.30it/s]Running 10000 simulations.:  82%|████████▏ | 8153/10000 [00:27<00:06, 294.22it/s]Running 10000 simulations.:  82%|████████▏ | 8183/10000 [00:27<00:06, 293.66it/s]Running 10000 simulations.:  82%|████████▏ | 8213/10000 [00:28<00:06, 292.82it/s]Running 10000 simulations.:  82%|████████▏ | 8243/10000 [00:28<00:06, 292.08it/s]Running 10000 simulations.:  83%|████████▎ | 8273/10000 [00:28<00:05, 291.72it/s]Running 10000 simulations.:  83%|████████▎ | 8303/10000 [00:28<00:05, 292.52it/s]Running 10000 simulations.:  83%|████████▎ | 8333/10000 [00:28<00:05, 292.71it/s]Running 10000 simulations.:  84%|████████▎ | 8363/10000 [00:28<00:05, 292.30it/s]Running 10000 simulations.:  84%|████████▍ | 8393/10000 [00:28<00:05, 292.18it/s]Running 10000 simulations.:  84%|████████▍ | 8423/10000 [00:28<00:05, 292.30it/s]Running 10000 simulations.:  85%|████████▍ | 8453/10000 [00:28<00:05, 292.47it/s]Running 10000 simulations.:  85%|████████▍ | 8483/10000 [00:28<00:05, 292.18it/s]Running 10000 simulations.:  85%|████████▌ | 8513/10000 [00:29<00:05, 292.25it/s]Running 10000 simulations.:  85%|████████▌ | 8543/10000 [00:29<00:04, 292.09it/s]Running 10000 simulations.:  86%|████████▌ | 8573/10000 [00:29<00:04, 291.48it/s]Running 10000 simulations.:  86%|████████▌ | 8603/10000 [00:29<00:04, 291.48it/s]Running 10000 simulations.:  86%|████████▋ | 8633/10000 [00:29<00:04, 291.93it/s]Running 10000 simulations.:  87%|████████▋ | 8663/10000 [00:29<00:04, 291.74it/s]Running 10000 simulations.:  87%|████████▋ | 8693/10000 [00:29<00:04, 292.28it/s]Running 10000 simulations.:  87%|████████▋ | 8723/10000 [00:29<00:04, 292.60it/s]Running 10000 simulations.:  88%|████████▊ | 8753/10000 [00:29<00:04, 292.00it/s]Running 10000 simulations.:  88%|████████▊ | 8783/10000 [00:29<00:04, 291.93it/s]Running 10000 simulations.:  88%|████████▊ | 8813/10000 [00:30<00:04, 291.44it/s]Running 10000 simulations.:  88%|████████▊ | 8843/10000 [00:30<00:03, 291.08it/s]Running 10000 simulations.:  89%|████████▊ | 8873/10000 [00:30<00:03, 292.77it/s]Running 10000 simulations.:  89%|████████▉ | 8903/10000 [00:30<00:03, 292.37it/s]Running 10000 simulations.:  89%|████████▉ | 8933/10000 [00:30<00:03, 292.44it/s]Running 10000 simulations.:  90%|████████▉ | 8963/10000 [00:30<00:03, 292.77it/s]Running 10000 simulations.:  90%|████████▉ | 8993/10000 [00:30<00:03, 291.88it/s]Running 10000 simulations.:  90%|█████████ | 9023/10000 [00:30<00:03, 292.32it/s]Running 10000 simulations.:  91%|█████████ | 9053/10000 [00:30<00:03, 292.81it/s]Running 10000 simulations.:  91%|█████████ | 9083/10000 [00:31<00:03, 293.44it/s]Running 10000 simulations.:  91%|█████████ | 9113/10000 [00:31<00:03, 292.88it/s]Running 10000 simulations.:  91%|█████████▏| 9143/10000 [00:31<00:02, 293.54it/s]Running 10000 simulations.:  92%|█████████▏| 9173/10000 [00:31<00:02, 293.19it/s]Running 10000 simulations.:  92%|█████████▏| 9203/10000 [00:31<00:02, 293.35it/s]Running 10000 simulations.:  92%|█████████▏| 9233/10000 [00:31<00:02, 293.60it/s]Running 10000 simulations.:  93%|█████████▎| 9263/10000 [00:31<00:02, 294.41it/s]Running 10000 simulations.:  93%|█████████▎| 9293/10000 [00:31<00:02, 294.60it/s]Running 10000 simulations.:  93%|█████████▎| 9323/10000 [00:31<00:02, 295.08it/s]Running 10000 simulations.:  94%|█████████▎| 9353/10000 [00:31<00:02, 294.38it/s]Running 10000 simulations.:  94%|█████████▍| 9383/10000 [00:32<00:02, 293.96it/s]Running 10000 simulations.:  94%|█████████▍| 9413/10000 [00:32<00:02, 292.61it/s]Running 10000 simulations.:  94%|█████████▍| 9443/10000 [00:32<00:01, 292.94it/s]Running 10000 simulations.:  95%|█████████▍| 9473/10000 [00:32<00:01, 293.49it/s]Running 10000 simulations.:  95%|█████████▌| 9503/10000 [00:32<00:01, 294.21it/s]Running 10000 simulations.:  95%|█████████▌| 9533/10000 [00:32<00:01, 294.89it/s]Running 10000 simulations.:  96%|█████████▌| 9563/10000 [00:32<00:01, 295.39it/s]Running 10000 simulations.:  96%|█████████▌| 9593/10000 [00:32<00:01, 293.68it/s]Running 10000 simulations.:  96%|█████████▌| 9623/10000 [00:32<00:01, 294.47it/s]Running 10000 simulations.:  97%|█████████▋| 9653/10000 [00:32<00:01, 295.13it/s]Running 10000 simulations.:  97%|█████████▋| 9683/10000 [00:33<00:01, 294.80it/s]Running 10000 simulations.:  97%|█████████▋| 9713/10000 [00:33<00:00, 295.14it/s]Running 10000 simulations.:  97%|█████████▋| 9743/10000 [00:33<00:00, 295.69it/s]Running 10000 simulations.:  98%|█████████▊| 9773/10000 [00:33<00:00, 295.68it/s]Running 10000 simulations.:  98%|█████████▊| 9803/10000 [00:33<00:00, 295.88it/s]Running 10000 simulations.:  98%|█████████▊| 9833/10000 [00:33<00:00, 296.12it/s]Running 10000 simulations.:  99%|█████████▊| 9863/10000 [00:33<00:00, 296.11it/s]Running 10000 simulations.:  99%|█████████▉| 9893/10000 [00:33<00:00, 296.21it/s]Running 10000 simulations.:  99%|█████████▉| 9923/10000 [00:33<00:00, 296.17it/s]Running 10000 simulations.: 100%|█████████▉| 9953/10000 [00:33<00:00, 296.15it/s]Running 10000 simulations.: 100%|█████████▉| 9983/10000 [00:34<00:00, 294.58it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:34<00:00, 293.05it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 17/10000 [00:00<00:59, 166.57it/s]Running 10000 simulations.:   0%|          | 34/10000 [00:00<00:59, 166.25it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<01:00, 165.69it/s]Running 10000 simulations.:   1%|          | 68/10000 [00:00<01:00, 165.12it/s]Running 10000 simulations.:   1%|          | 85/10000 [00:00<00:59, 165.53it/s]Running 10000 simulations.:   1%|          | 102/10000 [00:00<00:59, 165.93it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<00:59, 165.68it/s]Running 10000 simulations.:   1%|▏         | 136/10000 [00:00<00:59, 165.37it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:59, 164.89it/s]Running 10000 simulations.:   2%|▏         | 170/10000 [00:01<00:59, 164.65it/s]Running 10000 simulations.:   2%|▏         | 187/10000 [00:01<00:59, 164.52it/s]Running 10000 simulations.:   2%|▏         | 204/10000 [00:01<00:59, 164.05it/s]Running 10000 simulations.:   2%|▏         | 221/10000 [00:01<00:59, 163.48it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:01<00:59, 163.25it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<00:59, 163.12it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<00:59, 162.76it/s]Running 10000 simulations.:   3%|▎         | 289/10000 [00:01<00:59, 162.53it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:59, 162.21it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:59, 162.08it/s]Running 10000 simulations.:   3%|▎         | 340/10000 [00:02<00:59, 161.93it/s]Running 10000 simulations.:   4%|▎         | 357/10000 [00:02<00:59, 161.79it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:02<00:59, 161.77it/s]Running 10000 simulations.:   4%|▍         | 391/10000 [00:02<00:59, 161.63it/s]Running 10000 simulations.:   4%|▍         | 408/10000 [00:02<00:59, 161.48it/s]Running 10000 simulations.:   4%|▍         | 425/10000 [00:02<00:59, 161.73it/s]Running 10000 simulations.:   4%|▍         | 442/10000 [00:02<00:58, 162.10it/s]Running 10000 simulations.:   5%|▍         | 459/10000 [00:02<00:59, 161.47it/s]Running 10000 simulations.:   5%|▍         | 476/10000 [00:02<00:58, 161.89it/s]Running 10000 simulations.:   5%|▍         | 493/10000 [00:03<00:58, 162.31it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:03<00:58, 162.87it/s]Running 10000 simulations.:   5%|▌         | 527/10000 [00:03<00:58, 162.94it/s]Running 10000 simulations.:   5%|▌         | 544/10000 [00:03<00:58, 162.75it/s]Running 10000 simulations.:   6%|▌         | 561/10000 [00:03<00:57, 163.14it/s]Running 10000 simulations.:   6%|▌         | 578/10000 [00:03<00:57, 163.18it/s]Running 10000 simulations.:   6%|▌         | 595/10000 [00:03<00:57, 163.35it/s]Running 10000 simulations.:   6%|▌         | 612/10000 [00:03<00:57, 163.07it/s]Running 10000 simulations.:   6%|▋         | 629/10000 [00:03<00:57, 162.38it/s]Running 10000 simulations.:   6%|▋         | 646/10000 [00:03<00:57, 161.84it/s]Running 10000 simulations.:   7%|▋         | 663/10000 [00:04<00:57, 161.53it/s]Running 10000 simulations.:   7%|▋         | 680/10000 [00:04<00:57, 161.24it/s]Running 10000 simulations.:   7%|▋         | 697/10000 [00:04<00:57, 161.09it/s]Running 10000 simulations.:   7%|▋         | 714/10000 [00:04<00:57, 161.00it/s]Running 10000 simulations.:   7%|▋         | 731/10000 [00:04<00:57, 160.92it/s]Running 10000 simulations.:   7%|▋         | 748/10000 [00:04<00:57, 161.25it/s]Running 10000 simulations.:   8%|▊         | 765/10000 [00:04<00:57, 161.31it/s]Running 10000 simulations.:   8%|▊         | 782/10000 [00:04<00:57, 161.26it/s]Running 10000 simulations.:   8%|▊         | 799/10000 [00:04<00:56, 161.83it/s]Running 10000 simulations.:   8%|▊         | 816/10000 [00:05<00:56, 162.09it/s]Running 10000 simulations.:   8%|▊         | 833/10000 [00:05<00:56, 162.16it/s]Running 10000 simulations.:   8%|▊         | 850/10000 [00:05<00:56, 162.57it/s]Running 10000 simulations.:   9%|▊         | 867/10000 [00:05<00:56, 162.85it/s]Running 10000 simulations.:   9%|▉         | 884/10000 [00:05<00:56, 162.47it/s]Running 10000 simulations.:   9%|▉         | 901/10000 [00:05<00:56, 161.90it/s]Running 10000 simulations.:   9%|▉         | 918/10000 [00:05<00:56, 161.58it/s]Running 10000 simulations.:   9%|▉         | 935/10000 [00:05<00:56, 161.82it/s]Running 10000 simulations.:  10%|▉         | 952/10000 [00:05<00:55, 162.15it/s]Running 10000 simulations.:  10%|▉         | 969/10000 [00:05<00:55, 162.47it/s]Running 10000 simulations.:  10%|▉         | 986/10000 [00:06<00:55, 162.86it/s]Running 10000 simulations.:  10%|█         | 1003/10000 [00:06<00:55, 163.31it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:06<00:54, 163.58it/s]Running 10000 simulations.:  10%|█         | 1037/10000 [00:06<00:54, 163.80it/s]Running 10000 simulations.:  11%|█         | 1054/10000 [00:06<00:54, 163.87it/s]Running 10000 simulations.:  11%|█         | 1071/10000 [00:06<00:54, 163.35it/s]Running 10000 simulations.:  11%|█         | 1088/10000 [00:06<00:54, 162.48it/s]Running 10000 simulations.:  11%|█         | 1105/10000 [00:06<00:54, 162.43it/s]Running 10000 simulations.:  11%|█         | 1122/10000 [00:06<00:54, 162.11it/s]Running 10000 simulations.:  11%|█▏        | 1139/10000 [00:07<00:54, 161.78it/s]Running 10000 simulations.:  12%|█▏        | 1156/10000 [00:07<00:54, 161.59it/s]Running 10000 simulations.:  12%|█▏        | 1173/10000 [00:07<00:54, 161.80it/s]Running 10000 simulations.:  12%|█▏        | 1190/10000 [00:07<00:54, 161.77it/s]Running 10000 simulations.:  12%|█▏        | 1207/10000 [00:07<00:54, 162.14it/s]Running 10000 simulations.:  12%|█▏        | 1224/10000 [00:07<00:54, 162.01it/s]Running 10000 simulations.:  12%|█▏        | 1241/10000 [00:07<00:54, 162.02it/s]Running 10000 simulations.:  13%|█▎        | 1258/10000 [00:07<00:54, 161.77it/s]Running 10000 simulations.:  13%|█▎        | 1275/10000 [00:07<00:54, 161.21it/s]Running 10000 simulations.:  13%|█▎        | 1292/10000 [00:07<00:54, 160.88it/s]Running 10000 simulations.:  13%|█▎        | 1309/10000 [00:08<00:53, 161.33it/s]Running 10000 simulations.:  13%|█▎        | 1326/10000 [00:08<00:53, 161.37it/s]Running 10000 simulations.:  13%|█▎        | 1343/10000 [00:08<00:53, 160.92it/s]Running 10000 simulations.:  14%|█▎        | 1360/10000 [00:08<00:53, 160.78it/s]Running 10000 simulations.:  14%|█▍        | 1377/10000 [00:08<00:53, 160.57it/s]Running 10000 simulations.:  14%|█▍        | 1394/10000 [00:08<00:53, 160.73it/s]Running 10000 simulations.:  14%|█▍        | 1411/10000 [00:08<00:53, 160.85it/s]Running 10000 simulations.:  14%|█▍        | 1428/10000 [00:08<00:53, 160.67it/s]Running 10000 simulations.:  14%|█▍        | 1445/10000 [00:08<00:53, 160.77it/s]Running 10000 simulations.:  15%|█▍        | 1462/10000 [00:09<00:53, 160.59it/s]Running 10000 simulations.:  15%|█▍        | 1479/10000 [00:09<00:53, 160.52it/s]Running 10000 simulations.:  15%|█▍        | 1496/10000 [00:09<00:52, 160.47it/s]Running 10000 simulations.:  15%|█▌        | 1513/10000 [00:09<00:52, 160.55it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:09<00:52, 160.68it/s]Running 10000 simulations.:  15%|█▌        | 1547/10000 [00:09<00:52, 160.48it/s]Running 10000 simulations.:  16%|█▌        | 1564/10000 [00:09<00:52, 160.40it/s]Running 10000 simulations.:  16%|█▌        | 1581/10000 [00:09<00:52, 160.24it/s]Running 10000 simulations.:  16%|█▌        | 1598/10000 [00:09<00:52, 160.24it/s]Running 10000 simulations.:  16%|█▌        | 1615/10000 [00:09<00:52, 160.36it/s]Running 10000 simulations.:  16%|█▋        | 1632/10000 [00:10<00:51, 160.96it/s]Running 10000 simulations.:  16%|█▋        | 1649/10000 [00:10<00:51, 161.81it/s]Running 10000 simulations.:  17%|█▋        | 1666/10000 [00:10<00:51, 162.37it/s]Running 10000 simulations.:  17%|█▋        | 1683/10000 [00:10<00:51, 162.84it/s]Running 10000 simulations.:  17%|█▋        | 1700/10000 [00:10<00:50, 163.05it/s]Running 10000 simulations.:  17%|█▋        | 1717/10000 [00:10<00:50, 163.32it/s]Running 10000 simulations.:  17%|█▋        | 1734/10000 [00:10<00:50, 163.02it/s]Running 10000 simulations.:  18%|█▊        | 1751/10000 [00:10<00:50, 162.08it/s]Running 10000 simulations.:  18%|█▊        | 1768/10000 [00:10<00:50, 161.88it/s]Running 10000 simulations.:  18%|█▊        | 1785/10000 [00:11<00:50, 161.92it/s]Running 10000 simulations.:  18%|█▊        | 1802/10000 [00:11<00:50, 162.07it/s]Running 10000 simulations.:  18%|█▊        | 1819/10000 [00:11<00:50, 162.47it/s]Running 10000 simulations.:  18%|█▊        | 1836/10000 [00:11<00:50, 162.96it/s]Running 10000 simulations.:  19%|█▊        | 1853/10000 [00:11<00:49, 163.26it/s]Running 10000 simulations.:  19%|█▊        | 1870/10000 [00:11<00:49, 163.37it/s]Running 10000 simulations.:  19%|█▉        | 1887/10000 [00:11<00:49, 162.97it/s]Running 10000 simulations.:  19%|█▉        | 1904/10000 [00:11<00:49, 162.46it/s]Running 10000 simulations.:  19%|█▉        | 1921/10000 [00:11<00:49, 162.08it/s]Running 10000 simulations.:  19%|█▉        | 1938/10000 [00:11<00:49, 161.86it/s]Running 10000 simulations.:  20%|█▉        | 1955/10000 [00:12<00:49, 161.65it/s]Running 10000 simulations.:  20%|█▉        | 1972/10000 [00:12<00:49, 161.78it/s]Running 10000 simulations.:  20%|█▉        | 1989/10000 [00:12<00:49, 161.99it/s]Running 10000 simulations.:  20%|██        | 2006/10000 [00:12<00:49, 162.10it/s]Running 10000 simulations.:  20%|██        | 2023/10000 [00:12<00:49, 162.07it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:12<00:49, 161.79it/s]Running 10000 simulations.:  21%|██        | 2057/10000 [00:12<00:49, 161.27it/s]Running 10000 simulations.:  21%|██        | 2074/10000 [00:12<00:49, 160.78it/s]Running 10000 simulations.:  21%|██        | 2091/10000 [00:12<00:49, 160.55it/s]Running 10000 simulations.:  21%|██        | 2108/10000 [00:13<00:49, 160.32it/s]Running 10000 simulations.:  21%|██▏       | 2125/10000 [00:13<00:49, 160.14it/s]Running 10000 simulations.:  21%|██▏       | 2142/10000 [00:13<00:49, 160.17it/s]Running 10000 simulations.:  22%|██▏       | 2159/10000 [00:13<00:48, 160.11it/s]Running 10000 simulations.:  22%|██▏       | 2176/10000 [00:13<00:48, 160.14it/s]Running 10000 simulations.:  22%|██▏       | 2193/10000 [00:13<00:48, 160.39it/s]Running 10000 simulations.:  22%|██▏       | 2210/10000 [00:13<00:48, 160.70it/s]Running 10000 simulations.:  22%|██▏       | 2227/10000 [00:13<00:48, 160.68it/s]Running 10000 simulations.:  22%|██▏       | 2244/10000 [00:13<00:48, 160.74it/s]Running 10000 simulations.:  23%|██▎       | 2261/10000 [00:13<00:48, 161.09it/s]Running 10000 simulations.:  23%|██▎       | 2278/10000 [00:14<00:47, 161.17it/s]Running 10000 simulations.:  23%|██▎       | 2295/10000 [00:14<00:47, 161.18it/s]Running 10000 simulations.:  23%|██▎       | 2312/10000 [00:14<00:47, 160.84it/s]Running 10000 simulations.:  23%|██▎       | 2329/10000 [00:14<00:47, 160.76it/s]Running 10000 simulations.:  23%|██▎       | 2346/10000 [00:14<00:47, 160.55it/s]Running 10000 simulations.:  24%|██▎       | 2363/10000 [00:14<00:47, 160.57it/s]Running 10000 simulations.:  24%|██▍       | 2380/10000 [00:14<00:47, 160.89it/s]Running 10000 simulations.:  24%|██▍       | 2397/10000 [00:14<00:47, 161.08it/s]Running 10000 simulations.:  24%|██▍       | 2414/10000 [00:14<00:47, 160.93it/s]Running 10000 simulations.:  24%|██▍       | 2431/10000 [00:15<00:47, 160.74it/s]Running 10000 simulations.:  24%|██▍       | 2448/10000 [00:15<00:46, 160.69it/s]Running 10000 simulations.:  25%|██▍       | 2465/10000 [00:15<00:46, 160.49it/s]Running 10000 simulations.:  25%|██▍       | 2482/10000 [00:15<00:46, 160.27it/s]Running 10000 simulations.:  25%|██▍       | 2499/10000 [00:15<00:46, 160.20it/s]Running 10000 simulations.:  25%|██▌       | 2516/10000 [00:15<00:46, 160.07it/s]Running 10000 simulations.:  25%|██▌       | 2533/10000 [00:15<00:46, 160.05it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:15<00:46, 159.92it/s]Running 10000 simulations.:  26%|██▌       | 2566/10000 [00:15<00:46, 159.89it/s]Running 10000 simulations.:  26%|██▌       | 2583/10000 [00:15<00:46, 160.12it/s]Running 10000 simulations.:  26%|██▌       | 2600/10000 [00:16<00:46, 160.26it/s]Running 10000 simulations.:  26%|██▌       | 2617/10000 [00:16<00:45, 160.58it/s]Running 10000 simulations.:  26%|██▋       | 2634/10000 [00:16<00:45, 160.71it/s]Running 10000 simulations.:  27%|██▋       | 2651/10000 [00:16<00:45, 160.81it/s]Running 10000 simulations.:  27%|██▋       | 2668/10000 [00:16<00:45, 160.89it/s]Running 10000 simulations.:  27%|██▋       | 2685/10000 [00:16<00:45, 161.08it/s]Running 10000 simulations.:  27%|██▋       | 2702/10000 [00:16<00:45, 160.26it/s]Running 10000 simulations.:  27%|██▋       | 2719/10000 [00:16<00:45, 160.53it/s]Running 10000 simulations.:  27%|██▋       | 2736/10000 [00:16<00:45, 160.69it/s]Running 10000 simulations.:  28%|██▊       | 2753/10000 [00:17<00:45, 160.31it/s]Running 10000 simulations.:  28%|██▊       | 2770/10000 [00:17<00:45, 160.18it/s]Running 10000 simulations.:  28%|██▊       | 2787/10000 [00:17<00:45, 160.19it/s]Running 10000 simulations.:  28%|██▊       | 2804/10000 [00:17<00:44, 160.18it/s]Running 10000 simulations.:  28%|██▊       | 2821/10000 [00:17<00:44, 160.12it/s]Running 10000 simulations.:  28%|██▊       | 2838/10000 [00:17<00:44, 160.55it/s]Running 10000 simulations.:  29%|██▊       | 2855/10000 [00:17<00:44, 160.43it/s]Running 10000 simulations.:  29%|██▊       | 2872/10000 [00:17<00:44, 160.24it/s]Running 10000 simulations.:  29%|██▉       | 2889/10000 [00:17<00:44, 160.17it/s]Running 10000 simulations.:  29%|██▉       | 2906/10000 [00:17<00:44, 160.28it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:18<00:44, 160.29it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:18<00:44, 160.30it/s]Running 10000 simulations.:  30%|██▉       | 2957/10000 [00:18<00:43, 160.17it/s]Running 10000 simulations.:  30%|██▉       | 2974/10000 [00:18<00:43, 160.14it/s]Running 10000 simulations.:  30%|██▉       | 2991/10000 [00:18<00:43, 159.86it/s]Running 10000 simulations.:  30%|███       | 3007/10000 [00:18<00:43, 159.81it/s]Running 10000 simulations.:  30%|███       | 3024/10000 [00:18<00:43, 160.54it/s]Running 10000 simulations.:  30%|███       | 3041/10000 [00:18<00:43, 160.62it/s]Running 10000 simulations.:  31%|███       | 3058/10000 [00:18<00:43, 160.46it/s]Running 10000 simulations.:  31%|███       | 3075/10000 [00:19<00:43, 160.41it/s]Running 10000 simulations.:  31%|███       | 3092/10000 [00:19<00:43, 160.59it/s]Running 10000 simulations.:  31%|███       | 3109/10000 [00:19<00:42, 160.42it/s]Running 10000 simulations.:  31%|███▏      | 3126/10000 [00:19<00:42, 160.41it/s]Running 10000 simulations.:  31%|███▏      | 3143/10000 [00:19<00:42, 160.20it/s]Running 10000 simulations.:  32%|███▏      | 3160/10000 [00:19<00:42, 160.12it/s]Running 10000 simulations.:  32%|███▏      | 3177/10000 [00:19<00:42, 160.55it/s]Running 10000 simulations.:  32%|███▏      | 3194/10000 [00:19<00:42, 160.62it/s]Running 10000 simulations.:  32%|███▏      | 3211/10000 [00:19<00:42, 160.96it/s]Running 10000 simulations.:  32%|███▏      | 3228/10000 [00:19<00:42, 161.05it/s]Running 10000 simulations.:  32%|███▏      | 3245/10000 [00:20<00:41, 161.17it/s]Running 10000 simulations.:  33%|███▎      | 3262/10000 [00:20<00:41, 161.41it/s]Running 10000 simulations.:  33%|███▎      | 3279/10000 [00:20<00:41, 161.92it/s]Running 10000 simulations.:  33%|███▎      | 3296/10000 [00:20<00:41, 162.43it/s]Running 10000 simulations.:  33%|███▎      | 3313/10000 [00:20<00:41, 162.79it/s]Running 10000 simulations.:  33%|███▎      | 3330/10000 [00:20<00:40, 163.02it/s]Running 10000 simulations.:  33%|███▎      | 3347/10000 [00:20<00:40, 163.15it/s]Running 10000 simulations.:  34%|███▎      | 3364/10000 [00:20<00:42, 156.89it/s]Running 10000 simulations.:  34%|███▍      | 3381/10000 [00:20<00:41, 158.87it/s]Running 10000 simulations.:  34%|███▍      | 3397/10000 [00:21<00:51, 128.97it/s]Running 10000 simulations.:  34%|███▍      | 3414/10000 [00:21<00:47, 137.44it/s]Running 10000 simulations.:  34%|███▍      | 3431/10000 [00:21<00:45, 144.10it/s]Running 10000 simulations.:  34%|███▍      | 3448/10000 [00:21<00:43, 149.00it/s]Running 10000 simulations.:  35%|███▍      | 3465/10000 [00:21<00:42, 152.27it/s]Running 10000 simulations.:  35%|███▍      | 3481/10000 [00:21<00:42, 154.48it/s]Running 10000 simulations.:  35%|███▍      | 3498/10000 [00:21<00:41, 156.27it/s]Running 10000 simulations.:  35%|███▌      | 3515/10000 [00:21<00:41, 157.59it/s]Running 10000 simulations.:  35%|███▌      | 3532/10000 [00:21<00:40, 158.89it/s]Running 10000 simulations.:  35%|███▌      | 3549/10000 [00:22<00:40, 159.66it/s]Running 10000 simulations.:  36%|███▌      | 3566/10000 [00:22<00:40, 160.16it/s]Running 10000 simulations.:  36%|███▌      | 3583/10000 [00:22<00:39, 161.13it/s]Running 10000 simulations.:  36%|███▌      | 3600/10000 [00:22<00:39, 161.80it/s]Running 10000 simulations.:  36%|███▌      | 3617/10000 [00:22<00:39, 162.34it/s]Running 10000 simulations.:  36%|███▋      | 3634/10000 [00:22<00:39, 162.76it/s]Running 10000 simulations.:  37%|███▋      | 3651/10000 [00:22<00:38, 162.81it/s]Running 10000 simulations.:  37%|███▋      | 3668/10000 [00:22<00:38, 162.39it/s]Running 10000 simulations.:  37%|███▋      | 3685/10000 [00:22<00:39, 161.86it/s]Running 10000 simulations.:  37%|███▋      | 3702/10000 [00:23<00:39, 159.72it/s]Running 10000 simulations.:  37%|███▋      | 3718/10000 [00:23<00:39, 159.69it/s]Running 10000 simulations.:  37%|███▋      | 3735/10000 [00:23<00:39, 159.85it/s]Running 10000 simulations.:  38%|███▊      | 3751/10000 [00:23<00:39, 159.89it/s]Running 10000 simulations.:  38%|███▊      | 3768/10000 [00:23<00:38, 160.27it/s]Running 10000 simulations.:  38%|███▊      | 3785/10000 [00:23<00:38, 160.79it/s]Running 10000 simulations.:  38%|███▊      | 3802/10000 [00:23<00:38, 161.19it/s]Running 10000 simulations.:  38%|███▊      | 3819/10000 [00:23<00:38, 160.87it/s]Running 10000 simulations.:  38%|███▊      | 3836/10000 [00:23<00:38, 160.91it/s]Running 10000 simulations.:  39%|███▊      | 3853/10000 [00:23<00:38, 160.71it/s]Running 10000 simulations.:  39%|███▊      | 3870/10000 [00:24<00:38, 160.82it/s]Running 10000 simulations.:  39%|███▉      | 3887/10000 [00:24<00:37, 160.91it/s]Running 10000 simulations.:  39%|███▉      | 3904/10000 [00:24<00:37, 160.57it/s]Running 10000 simulations.:  39%|███▉      | 3921/10000 [00:24<00:37, 160.34it/s]Running 10000 simulations.:  39%|███▉      | 3938/10000 [00:24<00:37, 160.12it/s]Running 10000 simulations.:  40%|███▉      | 3955/10000 [00:24<00:37, 160.16it/s]Running 10000 simulations.:  40%|███▉      | 3972/10000 [00:24<00:37, 160.20it/s]Running 10000 simulations.:  40%|███▉      | 3989/10000 [00:24<00:37, 160.67it/s]Running 10000 simulations.:  40%|████      | 4006/10000 [00:24<00:37, 160.70it/s]Running 10000 simulations.:  40%|████      | 4023/10000 [00:24<00:37, 160.96it/s]Running 10000 simulations.:  40%|████      | 4040/10000 [00:25<00:36, 161.30it/s]Running 10000 simulations.:  41%|████      | 4057/10000 [00:25<00:36, 161.56it/s]Running 10000 simulations.:  41%|████      | 4074/10000 [00:25<00:36, 161.52it/s]Running 10000 simulations.:  41%|████      | 4091/10000 [00:25<00:36, 161.33it/s]Running 10000 simulations.:  41%|████      | 4108/10000 [00:25<00:36, 161.13it/s]Running 10000 simulations.:  41%|████▏     | 4125/10000 [00:25<00:36, 160.94it/s]Running 10000 simulations.:  41%|████▏     | 4142/10000 [00:25<00:36, 160.98it/s]Running 10000 simulations.:  42%|████▏     | 4159/10000 [00:25<00:36, 161.14it/s]Running 10000 simulations.:  42%|████▏     | 4176/10000 [00:25<00:36, 161.25it/s]Running 10000 simulations.:  42%|████▏     | 4193/10000 [00:26<00:35, 161.38it/s]Running 10000 simulations.:  42%|████▏     | 4210/10000 [00:26<00:35, 161.43it/s]Running 10000 simulations.:  42%|████▏     | 4227/10000 [00:26<00:35, 161.92it/s]Running 10000 simulations.:  42%|████▏     | 4244/10000 [00:26<00:35, 162.32it/s]Running 10000 simulations.:  43%|████▎     | 4261/10000 [00:26<00:35, 162.57it/s]Running 10000 simulations.:  43%|████▎     | 4278/10000 [00:26<00:35, 162.71it/s]Running 10000 simulations.:  43%|████▎     | 4295/10000 [00:26<00:35, 162.19it/s]Running 10000 simulations.:  43%|████▎     | 4312/10000 [00:26<00:35, 161.62it/s]Running 10000 simulations.:  43%|████▎     | 4329/10000 [00:26<00:35, 161.60it/s]Running 10000 simulations.:  43%|████▎     | 4346/10000 [00:26<00:35, 161.34it/s]Running 10000 simulations.:  44%|████▎     | 4363/10000 [00:27<00:35, 161.02it/s]Running 10000 simulations.:  44%|████▍     | 4380/10000 [00:27<00:34, 160.69it/s]Running 10000 simulations.:  44%|████▍     | 4397/10000 [00:27<00:34, 160.92it/s]Running 10000 simulations.:  44%|████▍     | 4414/10000 [00:27<00:34, 161.04it/s]Running 10000 simulations.:  44%|████▍     | 4431/10000 [00:27<00:34, 161.64it/s]Running 10000 simulations.:  44%|████▍     | 4448/10000 [00:27<00:34, 161.79it/s]Running 10000 simulations.:  45%|████▍     | 4465/10000 [00:27<00:34, 161.23it/s]Running 10000 simulations.:  45%|████▍     | 4482/10000 [00:27<00:34, 160.73it/s]Running 10000 simulations.:  45%|████▍     | 4499/10000 [00:27<00:34, 160.62it/s]Running 10000 simulations.:  45%|████▌     | 4516/10000 [00:28<00:34, 160.71it/s]Running 10000 simulations.:  45%|████▌     | 4533/10000 [00:28<00:33, 160.91it/s]Running 10000 simulations.:  46%|████▌     | 4550/10000 [00:28<00:33, 160.86it/s]Running 10000 simulations.:  46%|████▌     | 4567/10000 [00:28<00:33, 160.82it/s]Running 10000 simulations.:  46%|████▌     | 4584/10000 [00:28<00:33, 161.24it/s]Running 10000 simulations.:  46%|████▌     | 4601/10000 [00:28<00:33, 161.49it/s]Running 10000 simulations.:  46%|████▌     | 4618/10000 [00:28<00:33, 161.19it/s]Running 10000 simulations.:  46%|████▋     | 4635/10000 [00:28<00:33, 160.71it/s]Running 10000 simulations.:  47%|████▋     | 4652/10000 [00:28<00:33, 160.36it/s]Running 10000 simulations.:  47%|████▋     | 4669/10000 [00:29<00:33, 160.89it/s]Running 10000 simulations.:  47%|████▋     | 4686/10000 [00:29<00:32, 161.65it/s]Running 10000 simulations.:  47%|████▋     | 4703/10000 [00:29<00:32, 161.54it/s]Running 10000 simulations.:  47%|████▋     | 4720/10000 [00:29<00:32, 161.54it/s]Running 10000 simulations.:  47%|████▋     | 4737/10000 [00:29<00:32, 161.87it/s]Running 10000 simulations.:  48%|████▊     | 4754/10000 [00:29<00:32, 162.33it/s]Running 10000 simulations.:  48%|████▊     | 4771/10000 [00:29<00:32, 162.04it/s]Running 10000 simulations.:  48%|████▊     | 4788/10000 [00:29<00:32, 161.78it/s]Running 10000 simulations.:  48%|████▊     | 4805/10000 [00:29<00:32, 161.56it/s]Running 10000 simulations.:  48%|████▊     | 4822/10000 [00:29<00:32, 161.48it/s]Running 10000 simulations.:  48%|████▊     | 4839/10000 [00:30<00:32, 161.04it/s]Running 10000 simulations.:  49%|████▊     | 4856/10000 [00:30<00:31, 161.16it/s]Running 10000 simulations.:  49%|████▊     | 4873/10000 [00:30<00:31, 160.89it/s]Running 10000 simulations.:  49%|████▉     | 4890/10000 [00:30<00:31, 161.53it/s]Running 10000 simulations.:  49%|████▉     | 4907/10000 [00:30<00:31, 161.82it/s]Running 10000 simulations.:  49%|████▉     | 4924/10000 [00:30<00:31, 161.78it/s]Running 10000 simulations.:  49%|████▉     | 4941/10000 [00:30<00:31, 162.23it/s]Running 10000 simulations.:  50%|████▉     | 4960/10000 [00:30<00:30, 167.52it/s]Running 10000 simulations.:  50%|████▉     | 4979/10000 [00:30<00:29, 172.22it/s]Running 10000 simulations.:  50%|████▉     | 4997/10000 [00:30<00:29, 171.59it/s]Running 10000 simulations.:  50%|█████     | 5015/10000 [00:31<00:29, 169.84it/s]Running 10000 simulations.:  50%|█████     | 5033/10000 [00:31<00:29, 167.71it/s]Running 10000 simulations.:  50%|█████     | 5050/10000 [00:31<00:29, 167.16it/s]Running 10000 simulations.:  51%|█████     | 5067/10000 [00:31<00:29, 166.82it/s]Running 10000 simulations.:  51%|█████     | 5084/10000 [00:31<00:29, 166.84it/s]Running 10000 simulations.:  51%|█████     | 5101/10000 [00:31<00:29, 167.18it/s]Running 10000 simulations.:  51%|█████     | 5118/10000 [00:31<00:29, 166.49it/s]Running 10000 simulations.:  51%|█████▏    | 5135/10000 [00:31<00:29, 165.99it/s]Running 10000 simulations.:  52%|█████▏    | 5152/10000 [00:31<00:29, 165.85it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:32<00:29, 166.06it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:32<00:28, 166.47it/s]Running 10000 simulations.:  52%|█████▏    | 5203/10000 [00:32<00:28, 165.90it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:32<00:28, 166.22it/s]Running 10000 simulations.:  52%|█████▏    | 5237/10000 [00:32<00:28, 166.62it/s]Running 10000 simulations.:  53%|█████▎    | 5254/10000 [00:32<00:28, 166.60it/s]Running 10000 simulations.:  53%|█████▎    | 5271/10000 [00:32<00:28, 166.60it/s]Running 10000 simulations.:  53%|█████▎    | 5288/10000 [00:32<00:28, 165.64it/s]Running 10000 simulations.:  53%|█████▎    | 5305/10000 [00:32<00:28, 165.69it/s]Running 10000 simulations.:  53%|█████▎    | 5322/10000 [00:32<00:28, 165.68it/s]Running 10000 simulations.:  53%|█████▎    | 5339/10000 [00:33<00:28, 165.85it/s]Running 10000 simulations.:  54%|█████▎    | 5356/10000 [00:33<00:27, 166.93it/s]Running 10000 simulations.:  54%|█████▎    | 5373/10000 [00:33<00:27, 166.35it/s]Running 10000 simulations.:  54%|█████▍    | 5390/10000 [00:33<00:27, 166.84it/s]Running 10000 simulations.:  54%|█████▍    | 5407/10000 [00:33<00:27, 167.20it/s]Running 10000 simulations.:  54%|█████▍    | 5424/10000 [00:33<00:27, 167.54it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:33<00:27, 168.07it/s]Running 10000 simulations.:  55%|█████▍    | 5458/10000 [00:33<00:27, 167.66it/s]Running 10000 simulations.:  55%|█████▍    | 5475/10000 [00:33<00:27, 167.53it/s]Running 10000 simulations.:  55%|█████▍    | 5492/10000 [00:33<00:27, 166.69it/s]Running 10000 simulations.:  55%|█████▌    | 5509/10000 [00:34<00:26, 167.10it/s]Running 10000 simulations.:  55%|█████▌    | 5526/10000 [00:34<00:26, 167.76it/s]Running 10000 simulations.:  55%|█████▌    | 5543/10000 [00:34<00:26, 167.07it/s]Running 10000 simulations.:  56%|█████▌    | 5560/10000 [00:34<00:26, 166.45it/s]Running 10000 simulations.:  56%|█████▌    | 5577/10000 [00:34<00:26, 166.23it/s]Running 10000 simulations.:  56%|█████▌    | 5594/10000 [00:34<00:26, 165.82it/s]Running 10000 simulations.:  56%|█████▌    | 5611/10000 [00:34<00:26, 165.84it/s]Running 10000 simulations.:  56%|█████▋    | 5628/10000 [00:34<00:26, 166.57it/s]Running 10000 simulations.:  56%|█████▋    | 5645/10000 [00:34<00:26, 165.27it/s]Running 10000 simulations.:  57%|█████▋    | 5662/10000 [00:34<00:26, 165.62it/s]Running 10000 simulations.:  57%|█████▋    | 5679/10000 [00:35<00:26, 166.09it/s]Running 10000 simulations.:  57%|█████▋    | 5696/10000 [00:35<00:25, 166.64it/s]Running 10000 simulations.:  57%|█████▋    | 5713/10000 [00:35<00:25, 166.38it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:35<00:25, 166.70it/s]Running 10000 simulations.:  57%|█████▋    | 5747/10000 [00:35<00:25, 167.41it/s]Running 10000 simulations.:  58%|█████▊    | 5764/10000 [00:35<00:25, 166.91it/s]Running 10000 simulations.:  58%|█████▊    | 5781/10000 [00:35<00:25, 165.86it/s]Running 10000 simulations.:  58%|█████▊    | 5798/10000 [00:35<00:25, 166.08it/s]Running 10000 simulations.:  58%|█████▊    | 5815/10000 [00:35<00:25, 166.36it/s]Running 10000 simulations.:  58%|█████▊    | 5832/10000 [00:36<00:24, 166.81it/s]Running 10000 simulations.:  58%|█████▊    | 5849/10000 [00:36<00:24, 166.97it/s]Running 10000 simulations.:  59%|█████▊    | 5866/10000 [00:36<00:24, 167.07it/s]Running 10000 simulations.:  59%|█████▉    | 5883/10000 [00:36<00:24, 165.62it/s]Running 10000 simulations.:  59%|█████▉    | 5900/10000 [00:36<00:24, 165.27it/s]Running 10000 simulations.:  59%|█████▉    | 5917/10000 [00:36<00:24, 165.46it/s]Running 10000 simulations.:  59%|█████▉    | 5934/10000 [00:36<00:24, 166.21it/s]Running 10000 simulations.:  60%|█████▉    | 5951/10000 [00:36<00:24, 165.56it/s]Running 10000 simulations.:  60%|█████▉    | 5968/10000 [00:36<00:24, 165.65it/s]Running 10000 simulations.:  60%|█████▉    | 5985/10000 [00:36<00:24, 165.64it/s]Running 10000 simulations.:  60%|██████    | 6002/10000 [00:37<00:24, 164.31it/s]Running 10000 simulations.:  60%|██████    | 6019/10000 [00:37<00:24, 163.34it/s]Running 10000 simulations.:  60%|██████    | 6036/10000 [00:37<00:24, 162.76it/s]Running 10000 simulations.:  61%|██████    | 6053/10000 [00:37<00:24, 162.45it/s]Running 10000 simulations.:  61%|██████    | 6070/10000 [00:37<00:24, 162.57it/s]Running 10000 simulations.:  61%|██████    | 6087/10000 [00:37<00:24, 161.97it/s]Running 10000 simulations.:  61%|██████    | 6104/10000 [00:37<00:24, 161.69it/s]Running 10000 simulations.:  61%|██████    | 6121/10000 [00:37<00:23, 161.72it/s]Running 10000 simulations.:  61%|██████▏   | 6138/10000 [00:37<00:23, 161.85it/s]Running 10000 simulations.:  62%|██████▏   | 6155/10000 [00:37<00:23, 162.03it/s]Running 10000 simulations.:  62%|██████▏   | 6172/10000 [00:38<00:23, 162.04it/s]Running 10000 simulations.:  62%|██████▏   | 6189/10000 [00:38<00:23, 162.52it/s]Running 10000 simulations.:  62%|██████▏   | 6206/10000 [00:38<00:23, 162.88it/s]Running 10000 simulations.:  62%|██████▏   | 6223/10000 [00:38<00:23, 163.08it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:38<00:23, 162.32it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:38<00:23, 161.90it/s]Running 10000 simulations.:  63%|██████▎   | 6274/10000 [00:38<00:22, 162.14it/s]Running 10000 simulations.:  63%|██████▎   | 6291/10000 [00:38<00:22, 161.91it/s]Running 10000 simulations.:  63%|██████▎   | 6308/10000 [00:38<00:22, 161.99it/s]Running 10000 simulations.:  63%|██████▎   | 6325/10000 [00:39<00:22, 162.24it/s]Running 10000 simulations.:  63%|██████▎   | 6342/10000 [00:39<00:22, 162.17it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:39<00:22, 161.87it/s]Running 10000 simulations.:  64%|██████▍   | 6376/10000 [00:39<00:22, 162.03it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:39<00:22, 162.54it/s]Running 10000 simulations.:  64%|██████▍   | 6410/10000 [00:39<00:22, 162.61it/s]Running 10000 simulations.:  64%|██████▍   | 6427/10000 [00:39<00:22, 162.17it/s]Running 10000 simulations.:  64%|██████▍   | 6444/10000 [00:39<00:21, 161.99it/s]Running 10000 simulations.:  65%|██████▍   | 6461/10000 [00:39<00:21, 162.31it/s]Running 10000 simulations.:  65%|██████▍   | 6478/10000 [00:39<00:21, 162.27it/s]Running 10000 simulations.:  65%|██████▍   | 6495/10000 [00:40<00:21, 161.68it/s]Running 10000 simulations.:  65%|██████▌   | 6512/10000 [00:40<00:21, 161.49it/s]Running 10000 simulations.:  65%|██████▌   | 6529/10000 [00:40<00:21, 161.67it/s]Running 10000 simulations.:  65%|██████▌   | 6546/10000 [00:40<00:21, 161.85it/s]Running 10000 simulations.:  66%|██████▌   | 6563/10000 [00:40<00:21, 162.27it/s]Running 10000 simulations.:  66%|██████▌   | 6580/10000 [00:40<00:21, 162.60it/s]Running 10000 simulations.:  66%|██████▌   | 6597/10000 [00:40<00:20, 162.65it/s]Running 10000 simulations.:  66%|██████▌   | 6614/10000 [00:40<00:20, 162.91it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:40<00:20, 162.80it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:41<00:20, 162.96it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:41<00:20, 162.62it/s]Running 10000 simulations.:  67%|██████▋   | 6682/10000 [00:41<00:20, 162.46it/s]Running 10000 simulations.:  67%|██████▋   | 6699/10000 [00:41<00:20, 161.70it/s]Running 10000 simulations.:  67%|██████▋   | 6716/10000 [00:41<00:20, 161.18it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:41<00:20, 161.38it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:41<00:20, 161.27it/s]Running 10000 simulations.:  68%|██████▊   | 6767/10000 [00:41<00:20, 161.10it/s]Running 10000 simulations.:  68%|██████▊   | 6784/10000 [00:41<00:19, 161.33it/s]Running 10000 simulations.:  68%|██████▊   | 6801/10000 [00:41<00:19, 161.85it/s]Running 10000 simulations.:  68%|██████▊   | 6818/10000 [00:42<00:19, 162.31it/s]Running 10000 simulations.:  68%|██████▊   | 6835/10000 [00:42<00:19, 162.57it/s]Running 10000 simulations.:  69%|██████▊   | 6852/10000 [00:42<00:19, 162.33it/s]Running 10000 simulations.:  69%|██████▊   | 6869/10000 [00:42<00:19, 161.65it/s]Running 10000 simulations.:  69%|██████▉   | 6886/10000 [00:42<00:19, 161.79it/s]Running 10000 simulations.:  69%|██████▉   | 6903/10000 [00:42<00:19, 161.38it/s]Running 10000 simulations.:  69%|██████▉   | 6920/10000 [00:42<00:19, 160.91it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:42<00:19, 161.08it/s]Running 10000 simulations.:  70%|██████▉   | 6954/10000 [00:42<00:18, 160.77it/s]Running 10000 simulations.:  70%|██████▉   | 6971/10000 [00:43<00:18, 160.86it/s]Running 10000 simulations.:  70%|██████▉   | 6988/10000 [00:43<00:18, 160.16it/s]Running 10000 simulations.:  70%|███████   | 7005/10000 [00:43<00:18, 159.76it/s]Running 10000 simulations.:  70%|███████   | 7021/10000 [00:43<00:18, 159.70it/s]Running 10000 simulations.:  70%|███████   | 7038/10000 [00:43<00:18, 159.99it/s]Running 10000 simulations.:  71%|███████   | 7055/10000 [00:43<00:18, 160.71it/s]Running 10000 simulations.:  71%|███████   | 7072/10000 [00:43<00:18, 160.96it/s]Running 10000 simulations.:  71%|███████   | 7089/10000 [00:43<00:18, 160.90it/s]Running 10000 simulations.:  71%|███████   | 7106/10000 [00:43<00:17, 161.29it/s]Running 10000 simulations.:  71%|███████   | 7123/10000 [00:43<00:17, 161.59it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:44<00:17, 161.72it/s]Running 10000 simulations.:  72%|███████▏  | 7157/10000 [00:44<00:17, 161.78it/s]Running 10000 simulations.:  72%|███████▏  | 7174/10000 [00:44<00:17, 162.00it/s]Running 10000 simulations.:  72%|███████▏  | 7191/10000 [00:44<00:17, 162.27it/s]Running 10000 simulations.:  72%|███████▏  | 7208/10000 [00:44<00:17, 162.53it/s]Running 10000 simulations.:  72%|███████▏  | 7225/10000 [00:44<00:17, 162.57it/s]Running 10000 simulations.:  72%|███████▏  | 7242/10000 [00:44<00:16, 162.77it/s]Running 10000 simulations.:  73%|███████▎  | 7259/10000 [00:44<00:16, 162.63it/s]Running 10000 simulations.:  73%|███████▎  | 7276/10000 [00:44<00:16, 162.85it/s]Running 10000 simulations.:  73%|███████▎  | 7293/10000 [00:45<00:16, 162.48it/s]Running 10000 simulations.:  73%|███████▎  | 7310/10000 [00:45<00:16, 162.45it/s]Running 10000 simulations.:  73%|███████▎  | 7327/10000 [00:45<00:16, 162.37it/s]Running 10000 simulations.:  73%|███████▎  | 7344/10000 [00:45<00:16, 162.43it/s]Running 10000 simulations.:  74%|███████▎  | 7361/10000 [00:45<00:16, 162.53it/s]Running 10000 simulations.:  74%|███████▍  | 7378/10000 [00:45<00:16, 162.70it/s]Running 10000 simulations.:  74%|███████▍  | 7395/10000 [00:45<00:16, 162.78it/s]Running 10000 simulations.:  74%|███████▍  | 7412/10000 [00:45<00:15, 162.59it/s]Running 10000 simulations.:  74%|███████▍  | 7429/10000 [00:45<00:15, 162.03it/s]Running 10000 simulations.:  74%|███████▍  | 7446/10000 [00:45<00:15, 161.49it/s]Running 10000 simulations.:  75%|███████▍  | 7463/10000 [00:46<00:15, 161.26it/s]Running 10000 simulations.:  75%|███████▍  | 7480/10000 [00:46<00:15, 161.39it/s]Running 10000 simulations.:  75%|███████▍  | 7497/10000 [00:46<00:15, 161.43it/s]Running 10000 simulations.:  75%|███████▌  | 7514/10000 [00:46<00:15, 161.50it/s]Running 10000 simulations.:  75%|███████▌  | 7531/10000 [00:46<00:15, 161.29it/s]Running 10000 simulations.:  75%|███████▌  | 7548/10000 [00:46<00:15, 160.71it/s]Running 10000 simulations.:  76%|███████▌  | 7565/10000 [00:46<00:15, 160.77it/s]Running 10000 simulations.:  76%|███████▌  | 7582/10000 [00:46<00:14, 161.25it/s]Running 10000 simulations.:  76%|███████▌  | 7599/10000 [00:46<00:14, 161.34it/s]Running 10000 simulations.:  76%|███████▌  | 7616/10000 [00:47<00:14, 160.93it/s]Running 10000 simulations.:  76%|███████▋  | 7633/10000 [00:47<00:14, 160.68it/s]Running 10000 simulations.:  76%|███████▋  | 7650/10000 [00:47<00:14, 160.64it/s]Running 10000 simulations.:  77%|███████▋  | 7667/10000 [00:47<00:14, 160.51it/s]Running 10000 simulations.:  77%|███████▋  | 7684/10000 [00:47<00:14, 160.85it/s]Running 10000 simulations.:  77%|███████▋  | 7701/10000 [00:47<00:14, 161.92it/s]Running 10000 simulations.:  77%|███████▋  | 7718/10000 [00:47<00:14, 162.32it/s]Running 10000 simulations.:  77%|███████▋  | 7735/10000 [00:47<00:13, 162.56it/s]Running 10000 simulations.:  78%|███████▊  | 7752/10000 [00:47<00:13, 162.46it/s]Running 10000 simulations.:  78%|███████▊  | 7769/10000 [00:47<00:13, 162.07it/s]Running 10000 simulations.:  78%|███████▊  | 7786/10000 [00:48<00:13, 161.82it/s]Running 10000 simulations.:  78%|███████▊  | 7803/10000 [00:48<00:13, 161.78it/s]Running 10000 simulations.:  78%|███████▊  | 7820/10000 [00:48<00:13, 161.73it/s]Running 10000 simulations.:  78%|███████▊  | 7837/10000 [00:48<00:13, 162.21it/s]Running 10000 simulations.:  79%|███████▊  | 7854/10000 [00:48<00:13, 161.74it/s]Running 10000 simulations.:  79%|███████▊  | 7871/10000 [00:48<00:13, 161.18it/s]Running 10000 simulations.:  79%|███████▉  | 7888/10000 [00:48<00:13, 160.90it/s]Running 10000 simulations.:  79%|███████▉  | 7905/10000 [00:48<00:13, 161.05it/s]Running 10000 simulations.:  79%|███████▉  | 7922/10000 [00:48<00:12, 161.19it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:49<00:12, 160.85it/s]Running 10000 simulations.:  80%|███████▉  | 7956/10000 [00:49<00:12, 160.76it/s]Running 10000 simulations.:  80%|███████▉  | 7973/10000 [00:49<00:12, 160.80it/s]Running 10000 simulations.:  80%|███████▉  | 7990/10000 [00:49<00:12, 160.75it/s]Running 10000 simulations.:  80%|████████  | 8007/10000 [00:49<00:12, 160.77it/s]Running 10000 simulations.:  80%|████████  | 8024/10000 [00:49<00:12, 160.96it/s]Running 10000 simulations.:  80%|████████  | 8041/10000 [00:49<00:12, 161.12it/s]Running 10000 simulations.:  81%|████████  | 8058/10000 [00:49<00:12, 161.06it/s]Running 10000 simulations.:  81%|████████  | 8075/10000 [00:49<00:11, 161.12it/s]Running 10000 simulations.:  81%|████████  | 8092/10000 [00:49<00:11, 160.92it/s]Running 10000 simulations.:  81%|████████  | 8109/10000 [00:50<00:11, 160.47it/s]Running 10000 simulations.:  81%|████████▏ | 8126/10000 [00:50<00:11, 160.65it/s]Running 10000 simulations.:  81%|████████▏ | 8143/10000 [00:50<00:11, 161.04it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:50<00:11, 161.33it/s]Running 10000 simulations.:  82%|████████▏ | 8177/10000 [00:50<00:11, 161.47it/s]Running 10000 simulations.:  82%|████████▏ | 8194/10000 [00:50<00:11, 161.40it/s]Running 10000 simulations.:  82%|████████▏ | 8211/10000 [00:50<00:11, 161.54it/s]Running 10000 simulations.:  82%|████████▏ | 8228/10000 [00:50<00:11, 155.32it/s]Running 10000 simulations.:  82%|████████▏ | 8245/10000 [00:50<00:11, 157.08it/s]Running 10000 simulations.:  83%|████████▎ | 8262/10000 [00:51<00:10, 158.11it/s]Running 10000 simulations.:  83%|████████▎ | 8278/10000 [00:51<00:10, 158.57it/s]Running 10000 simulations.:  83%|████████▎ | 8295/10000 [00:51<00:10, 159.06it/s]Running 10000 simulations.:  83%|████████▎ | 8312/10000 [00:51<00:10, 159.74it/s]Running 10000 simulations.:  83%|████████▎ | 8329/10000 [00:51<00:10, 160.11it/s]Running 10000 simulations.:  83%|████████▎ | 8346/10000 [00:51<00:10, 160.45it/s]Running 10000 simulations.:  84%|████████▎ | 8363/10000 [00:51<00:10, 160.42it/s]Running 10000 simulations.:  84%|████████▍ | 8380/10000 [00:51<00:10, 160.85it/s]Running 10000 simulations.:  84%|████████▍ | 8397/10000 [00:51<00:09, 161.05it/s]Running 10000 simulations.:  84%|████████▍ | 8414/10000 [00:51<00:09, 160.73it/s]Running 10000 simulations.:  84%|████████▍ | 8431/10000 [00:52<00:09, 160.70it/s]Running 10000 simulations.:  84%|████████▍ | 8448/10000 [00:52<00:09, 160.86it/s]Running 10000 simulations.:  85%|████████▍ | 8465/10000 [00:52<00:09, 161.09it/s]Running 10000 simulations.:  85%|████████▍ | 8482/10000 [00:52<00:09, 160.83it/s]Running 10000 simulations.:  85%|████████▍ | 8499/10000 [00:52<00:09, 160.56it/s]Running 10000 simulations.:  85%|████████▌ | 8516/10000 [00:52<00:09, 160.83it/s]Running 10000 simulations.:  85%|████████▌ | 8533/10000 [00:52<00:09, 160.63it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:52<00:09, 160.60it/s]Running 10000 simulations.:  86%|████████▌ | 8567/10000 [00:52<00:08, 160.68it/s]Running 10000 simulations.:  86%|████████▌ | 8584/10000 [00:53<00:08, 160.78it/s]Running 10000 simulations.:  86%|████████▌ | 8601/10000 [00:53<00:08, 160.83it/s]Running 10000 simulations.:  86%|████████▌ | 8618/10000 [00:53<00:08, 160.87it/s]Running 10000 simulations.:  86%|████████▋ | 8635/10000 [00:53<00:08, 161.14it/s]Running 10000 simulations.:  87%|████████▋ | 8652/10000 [00:53<00:08, 160.98it/s]Running 10000 simulations.:  87%|████████▋ | 8669/10000 [00:53<00:08, 160.60it/s]Running 10000 simulations.:  87%|████████▋ | 8686/10000 [00:53<00:08, 160.77it/s]Running 10000 simulations.:  87%|████████▋ | 8703/10000 [00:53<00:08, 160.95it/s]Running 10000 simulations.:  87%|████████▋ | 8720/10000 [00:53<00:07, 161.10it/s]Running 10000 simulations.:  87%|████████▋ | 8737/10000 [00:53<00:07, 161.15it/s]Running 10000 simulations.:  88%|████████▊ | 8754/10000 [00:54<00:07, 161.28it/s]Running 10000 simulations.:  88%|████████▊ | 8771/10000 [00:54<00:07, 161.18it/s]Running 10000 simulations.:  88%|████████▊ | 8788/10000 [00:54<00:07, 161.23it/s]Running 10000 simulations.:  88%|████████▊ | 8805/10000 [00:54<00:07, 160.73it/s]Running 10000 simulations.:  88%|████████▊ | 8822/10000 [00:54<00:07, 160.64it/s]Running 10000 simulations.:  88%|████████▊ | 8839/10000 [00:54<00:07, 160.85it/s]Running 10000 simulations.:  89%|████████▊ | 8856/10000 [00:54<00:07, 160.84it/s]Running 10000 simulations.:  89%|████████▊ | 8873/10000 [00:54<00:06, 161.13it/s]Running 10000 simulations.:  89%|████████▉ | 8890/10000 [00:54<00:06, 161.03it/s]Running 10000 simulations.:  89%|████████▉ | 8907/10000 [00:55<00:06, 160.96it/s]Running 10000 simulations.:  89%|████████▉ | 8924/10000 [00:55<00:06, 161.34it/s]Running 10000 simulations.:  89%|████████▉ | 8941/10000 [00:55<00:06, 161.10it/s]Running 10000 simulations.:  90%|████████▉ | 8958/10000 [00:55<00:06, 161.28it/s]Running 10000 simulations.:  90%|████████▉ | 8975/10000 [00:55<00:06, 161.06it/s]Running 10000 simulations.:  90%|████████▉ | 8992/10000 [00:55<00:06, 161.47it/s]Running 10000 simulations.:  90%|█████████ | 9009/10000 [00:55<00:06, 161.94it/s]Running 10000 simulations.:  90%|█████████ | 9026/10000 [00:55<00:06, 161.32it/s]Running 10000 simulations.:  90%|█████████ | 9043/10000 [00:55<00:05, 161.36it/s]Running 10000 simulations.:  91%|█████████ | 9060/10000 [00:55<00:05, 161.26it/s]Running 10000 simulations.:  91%|█████████ | 9077/10000 [00:56<00:05, 161.08it/s]Running 10000 simulations.:  91%|█████████ | 9094/10000 [00:56<00:05, 161.00it/s]Running 10000 simulations.:  91%|█████████ | 9111/10000 [00:56<00:05, 160.77it/s]Running 10000 simulations.:  91%|█████████▏| 9128/10000 [00:56<00:05, 160.83it/s]Running 10000 simulations.:  91%|█████████▏| 9145/10000 [00:56<00:05, 161.11it/s]Running 10000 simulations.:  92%|█████████▏| 9162/10000 [00:56<00:05, 161.32it/s]Running 10000 simulations.:  92%|█████████▏| 9179/10000 [00:56<00:05, 161.66it/s]Running 10000 simulations.:  92%|█████████▏| 9196/10000 [00:56<00:04, 161.77it/s]Running 10000 simulations.:  92%|█████████▏| 9213/10000 [00:56<00:04, 161.52it/s]Running 10000 simulations.:  92%|█████████▏| 9230/10000 [00:57<00:04, 161.10it/s]Running 10000 simulations.:  92%|█████████▏| 9247/10000 [00:57<00:04, 161.02it/s]Running 10000 simulations.:  93%|█████████▎| 9264/10000 [00:57<00:04, 161.04it/s]Running 10000 simulations.:  93%|█████████▎| 9281/10000 [00:57<00:04, 161.18it/s]Running 10000 simulations.:  93%|█████████▎| 9298/10000 [00:57<00:04, 161.26it/s]Running 10000 simulations.:  93%|█████████▎| 9315/10000 [00:57<00:04, 161.49it/s]Running 10000 simulations.:  93%|█████████▎| 9332/10000 [00:57<00:04, 160.82it/s]Running 10000 simulations.:  93%|█████████▎| 9349/10000 [00:57<00:04, 160.95it/s]Running 10000 simulations.:  94%|█████████▎| 9366/10000 [00:57<00:03, 161.26it/s]Running 10000 simulations.:  94%|█████████▍| 9383/10000 [00:58<00:03, 161.30it/s]Running 10000 simulations.:  94%|█████████▍| 9400/10000 [00:58<00:03, 161.10it/s]Running 10000 simulations.:  94%|█████████▍| 9417/10000 [00:58<00:03, 161.38it/s]Running 10000 simulations.:  94%|█████████▍| 9434/10000 [00:58<00:03, 161.10it/s]Running 10000 simulations.:  95%|█████████▍| 9451/10000 [00:58<00:03, 160.81it/s]Running 10000 simulations.:  95%|█████████▍| 9468/10000 [00:58<00:03, 160.99it/s]Running 10000 simulations.:  95%|█████████▍| 9485/10000 [00:58<00:03, 160.65it/s]Running 10000 simulations.:  95%|█████████▌| 9502/10000 [00:58<00:03, 160.67it/s]Running 10000 simulations.:  95%|█████████▌| 9519/10000 [00:58<00:02, 160.58it/s]Running 10000 simulations.:  95%|█████████▌| 9536/10000 [00:58<00:02, 160.63it/s]Running 10000 simulations.:  96%|█████████▌| 9553/10000 [00:59<00:02, 160.41it/s]Running 10000 simulations.:  96%|█████████▌| 9570/10000 [00:59<00:02, 160.01it/s]Running 10000 simulations.:  96%|█████████▌| 9587/10000 [00:59<00:02, 159.74it/s]Running 10000 simulations.:  96%|█████████▌| 9603/10000 [00:59<00:02, 159.81it/s]Running 10000 simulations.:  96%|█████████▌| 9620/10000 [00:59<00:02, 160.35it/s]Running 10000 simulations.:  96%|█████████▋| 9637/10000 [00:59<00:02, 160.76it/s]Running 10000 simulations.:  97%|█████████▋| 9654/10000 [00:59<00:02, 161.08it/s]Running 10000 simulations.:  97%|█████████▋| 9671/10000 [00:59<00:02, 161.05it/s]Running 10000 simulations.:  97%|█████████▋| 9688/10000 [00:59<00:01, 161.28it/s]Running 10000 simulations.:  97%|█████████▋| 9705/10000 [01:00<00:01, 161.29it/s]Running 10000 simulations.:  97%|█████████▋| 9722/10000 [01:00<00:01, 161.23it/s]Running 10000 simulations.:  97%|█████████▋| 9739/10000 [01:00<00:01, 161.52it/s]Running 10000 simulations.:  98%|█████████▊| 9756/10000 [01:00<00:01, 161.65it/s]Running 10000 simulations.:  98%|█████████▊| 9773/10000 [01:00<00:01, 161.87it/s]Running 10000 simulations.:  98%|█████████▊| 9790/10000 [01:00<00:01, 161.77it/s]Running 10000 simulations.:  98%|█████████▊| 9807/10000 [01:00<00:01, 161.56it/s]Running 10000 simulations.:  98%|█████████▊| 9824/10000 [01:00<00:01, 161.01it/s]Running 10000 simulations.:  98%|█████████▊| 9841/10000 [01:00<00:00, 160.82it/s]Running 10000 simulations.:  99%|█████████▊| 9858/10000 [01:00<00:00, 160.78it/s]Running 10000 simulations.:  99%|█████████▉| 9875/10000 [01:01<00:00, 160.69it/s]Running 10000 simulations.:  99%|█████████▉| 9892/10000 [01:01<00:00, 160.93it/s]Running 10000 simulations.:  99%|█████████▉| 9909/10000 [01:01<00:00, 160.87it/s]Running 10000 simulations.:  99%|█████████▉| 9926/10000 [01:01<00:00, 160.97it/s]Running 10000 simulations.:  99%|█████████▉| 9943/10000 [01:01<00:00, 161.18it/s]Running 10000 simulations.: 100%|█████████▉| 9960/10000 [01:01<00:00, 161.23it/s]Running 10000 simulations.: 100%|█████████▉| 9977/10000 [01:01<00:00, 161.37it/s]Running 10000 simulations.: 100%|█████████▉| 9994/10000 [01:01<00:00, 161.42it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:01<00:00, 161.72it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 17/10000 [00:00<01:00, 166.13it/s]Running 10000 simulations.:   0%|          | 34/10000 [00:00<00:59, 166.17it/s]Running 10000 simulations.:   1%|          | 51/10000 [00:00<00:59, 166.33it/s]Running 10000 simulations.:   1%|          | 68/10000 [00:00<00:59, 166.20it/s]Running 10000 simulations.:   1%|          | 85/10000 [00:00<00:59, 166.32it/s]Running 10000 simulations.:   1%|          | 102/10000 [00:00<00:59, 166.25it/s]Running 10000 simulations.:   1%|          | 119/10000 [00:00<00:59, 166.21it/s]Running 10000 simulations.:   1%|▏         | 136/10000 [00:00<00:59, 166.36it/s]Running 10000 simulations.:   2%|▏         | 153/10000 [00:00<00:59, 166.16it/s]Running 10000 simulations.:   2%|▏         | 170/10000 [00:01<00:59, 166.19it/s]Running 10000 simulations.:   2%|▏         | 187/10000 [00:01<00:59, 165.81it/s]Running 10000 simulations.:   2%|▏         | 204/10000 [00:01<00:59, 165.81it/s]Running 10000 simulations.:   2%|▏         | 221/10000 [00:01<00:59, 165.59it/s]Running 10000 simulations.:   2%|▏         | 238/10000 [00:01<00:58, 165.48it/s]Running 10000 simulations.:   3%|▎         | 255/10000 [00:01<00:58, 165.55it/s]Running 10000 simulations.:   3%|▎         | 272/10000 [00:01<00:58, 165.36it/s]Running 10000 simulations.:   3%|▎         | 289/10000 [00:01<00:58, 165.95it/s]Running 10000 simulations.:   3%|▎         | 306/10000 [00:01<00:58, 166.21it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:58, 166.18it/s]Running 10000 simulations.:   3%|▎         | 340/10000 [00:02<00:58, 166.09it/s]Running 10000 simulations.:   4%|▎         | 357/10000 [00:02<00:58, 165.90it/s]Running 10000 simulations.:   4%|▎         | 374/10000 [00:02<00:57, 166.10it/s]Running 10000 simulations.:   4%|▍         | 392/10000 [00:02<00:56, 169.62it/s]Running 10000 simulations.:   4%|▍         | 409/10000 [00:02<00:56, 169.21it/s]Running 10000 simulations.:   4%|▍         | 426/10000 [00:02<00:56, 168.12it/s]Running 10000 simulations.:   4%|▍         | 443/10000 [00:02<00:57, 167.08it/s]Running 10000 simulations.:   5%|▍         | 460/10000 [00:02<00:57, 166.46it/s]Running 10000 simulations.:   5%|▍         | 477/10000 [00:02<00:57, 166.40it/s]Running 10000 simulations.:   5%|▍         | 494/10000 [00:02<00:57, 166.37it/s]Running 10000 simulations.:   5%|▌         | 511/10000 [00:03<00:57, 165.79it/s]Running 10000 simulations.:   5%|▌         | 528/10000 [00:03<00:57, 165.66it/s]Running 10000 simulations.:   5%|▌         | 545/10000 [00:03<00:57, 165.34it/s]Running 10000 simulations.:   6%|▌         | 562/10000 [00:03<00:57, 165.16it/s]Running 10000 simulations.:   6%|▌         | 579/10000 [00:03<00:57, 165.28it/s]Running 10000 simulations.:   6%|▌         | 596/10000 [00:03<00:57, 164.98it/s]Running 10000 simulations.:   6%|▌         | 613/10000 [00:03<00:56, 164.91it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:03<00:56, 164.95it/s]Running 10000 simulations.:   6%|▋         | 647/10000 [00:03<00:56, 165.00it/s]Running 10000 simulations.:   7%|▋         | 664/10000 [00:03<00:56, 164.84it/s]Running 10000 simulations.:   7%|▋         | 681/10000 [00:04<00:56, 164.80it/s]Running 10000 simulations.:   7%|▋         | 698/10000 [00:04<00:56, 164.89it/s]Running 10000 simulations.:   7%|▋         | 715/10000 [00:04<00:57, 162.78it/s]Running 10000 simulations.:   7%|▋         | 732/10000 [00:04<00:56, 163.07it/s]Running 10000 simulations.:   7%|▋         | 749/10000 [00:04<00:56, 163.35it/s]Running 10000 simulations.:   8%|▊         | 766/10000 [00:04<00:56, 163.41it/s]Running 10000 simulations.:   8%|▊         | 783/10000 [00:04<00:56, 163.47it/s]Running 10000 simulations.:   8%|▊         | 800/10000 [00:04<00:56, 163.56it/s]Running 10000 simulations.:   8%|▊         | 817/10000 [00:04<00:56, 163.61it/s]Running 10000 simulations.:   8%|▊         | 834/10000 [00:05<00:56, 163.66it/s]Running 10000 simulations.:   9%|▊         | 851/10000 [00:05<00:55, 164.05it/s]Running 10000 simulations.:   9%|▊         | 868/10000 [00:05<00:55, 164.23it/s]Running 10000 simulations.:   9%|▉         | 885/10000 [00:05<00:55, 164.34it/s]Running 10000 simulations.:   9%|▉         | 902/10000 [00:05<00:55, 164.65it/s]Running 10000 simulations.:   9%|▉         | 919/10000 [00:05<00:55, 164.75it/s]Running 10000 simulations.:   9%|▉         | 936/10000 [00:05<00:55, 164.47it/s]Running 10000 simulations.:  10%|▉         | 953/10000 [00:05<00:55, 164.28it/s]Running 10000 simulations.:  10%|▉         | 970/10000 [00:05<00:55, 164.06it/s]Running 10000 simulations.:  10%|▉         | 987/10000 [00:05<00:54, 164.30it/s]Running 10000 simulations.:  10%|█         | 1004/10000 [00:06<00:54, 164.42it/s]Running 10000 simulations.:  10%|█         | 1021/10000 [00:06<00:54, 164.29it/s]Running 10000 simulations.:  10%|█         | 1038/10000 [00:06<00:54, 163.99it/s]Running 10000 simulations.:  11%|█         | 1055/10000 [00:06<00:54, 164.06it/s]Running 10000 simulations.:  11%|█         | 1072/10000 [00:06<00:54, 164.07it/s]Running 10000 simulations.:  11%|█         | 1089/10000 [00:06<00:54, 164.08it/s]Running 10000 simulations.:  11%|█         | 1106/10000 [00:06<00:54, 164.23it/s]Running 10000 simulations.:  11%|█         | 1123/10000 [00:06<00:53, 164.46it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:06<00:53, 164.28it/s]Running 10000 simulations.:  12%|█▏        | 1157/10000 [00:07<00:53, 164.33it/s]Running 10000 simulations.:  12%|█▏        | 1174/10000 [00:07<00:53, 164.37it/s]Running 10000 simulations.:  12%|█▏        | 1191/10000 [00:07<00:53, 164.60it/s]Running 10000 simulations.:  12%|█▏        | 1208/10000 [00:07<00:53, 164.28it/s]Running 10000 simulations.:  12%|█▏        | 1225/10000 [00:07<00:53, 164.30it/s]Running 10000 simulations.:  12%|█▏        | 1242/10000 [00:07<00:53, 164.50it/s]Running 10000 simulations.:  13%|█▎        | 1259/10000 [00:07<00:53, 164.56it/s]Running 10000 simulations.:  13%|█▎        | 1276/10000 [00:07<00:52, 164.84it/s]Running 10000 simulations.:  13%|█▎        | 1293/10000 [00:07<00:52, 164.62it/s]Running 10000 simulations.:  13%|█▎        | 1310/10000 [00:07<00:52, 164.39it/s]Running 10000 simulations.:  13%|█▎        | 1327/10000 [00:08<00:52, 164.18it/s]Running 10000 simulations.:  13%|█▎        | 1344/10000 [00:08<00:52, 164.16it/s]Running 10000 simulations.:  14%|█▎        | 1361/10000 [00:08<00:52, 164.06it/s]Running 10000 simulations.:  14%|█▍        | 1378/10000 [00:08<00:52, 164.57it/s]Running 10000 simulations.:  14%|█▍        | 1395/10000 [00:08<00:52, 164.37it/s]Running 10000 simulations.:  14%|█▍        | 1412/10000 [00:08<00:52, 164.38it/s]Running 10000 simulations.:  14%|█▍        | 1429/10000 [00:08<00:52, 164.20it/s]Running 10000 simulations.:  14%|█▍        | 1446/10000 [00:08<00:52, 164.10it/s]Running 10000 simulations.:  15%|█▍        | 1463/10000 [00:08<00:52, 164.05it/s]Running 10000 simulations.:  15%|█▍        | 1480/10000 [00:08<00:51, 163.99it/s]Running 10000 simulations.:  15%|█▍        | 1497/10000 [00:09<00:51, 164.06it/s]Running 10000 simulations.:  15%|█▌        | 1514/10000 [00:09<00:51, 164.16it/s]Running 10000 simulations.:  15%|█▌        | 1531/10000 [00:09<00:51, 164.16it/s]Running 10000 simulations.:  15%|█▌        | 1548/10000 [00:09<00:51, 164.33it/s]Running 10000 simulations.:  16%|█▌        | 1565/10000 [00:09<00:51, 164.28it/s]Running 10000 simulations.:  16%|█▌        | 1582/10000 [00:09<00:51, 164.10it/s]Running 10000 simulations.:  16%|█▌        | 1599/10000 [00:09<00:51, 163.83it/s]Running 10000 simulations.:  16%|█▌        | 1616/10000 [00:09<00:51, 163.79it/s]Running 10000 simulations.:  16%|█▋        | 1633/10000 [00:09<00:51, 163.91it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:10<00:50, 164.44it/s]Running 10000 simulations.:  17%|█▋        | 1667/10000 [00:10<00:50, 164.27it/s]Running 10000 simulations.:  17%|█▋        | 1684/10000 [00:10<00:50, 164.16it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:10<00:50, 164.54it/s]Running 10000 simulations.:  17%|█▋        | 1718/10000 [00:10<00:50, 164.61it/s]Running 10000 simulations.:  17%|█▋        | 1735/10000 [00:10<00:50, 164.45it/s]Running 10000 simulations.:  18%|█▊        | 1752/10000 [00:10<00:50, 164.04it/s]Running 10000 simulations.:  18%|█▊        | 1769/10000 [00:10<00:50, 164.10it/s]Running 10000 simulations.:  18%|█▊        | 1786/10000 [00:10<00:50, 164.15it/s]Running 10000 simulations.:  18%|█▊        | 1803/10000 [00:10<00:49, 164.05it/s]Running 10000 simulations.:  18%|█▊        | 1820/10000 [00:11<00:49, 164.34it/s]Running 10000 simulations.:  18%|█▊        | 1837/10000 [00:11<00:49, 164.55it/s]Running 10000 simulations.:  19%|█▊        | 1854/10000 [00:11<00:49, 164.54it/s]Running 10000 simulations.:  19%|█▊        | 1871/10000 [00:11<00:49, 164.78it/s]Running 10000 simulations.:  19%|█▉        | 1888/10000 [00:11<00:49, 164.91it/s]Running 10000 simulations.:  19%|█▉        | 1905/10000 [00:11<00:49, 164.61it/s]Running 10000 simulations.:  19%|█▉        | 1922/10000 [00:11<00:51, 158.30it/s]Running 10000 simulations.:  19%|█▉        | 1939/10000 [00:11<00:50, 160.24it/s]Running 10000 simulations.:  20%|█▉        | 1956/10000 [00:11<00:49, 161.57it/s]Running 10000 simulations.:  20%|█▉        | 1973/10000 [00:11<00:49, 162.12it/s]Running 10000 simulations.:  20%|█▉        | 1990/10000 [00:12<00:49, 162.74it/s]Running 10000 simulations.:  20%|██        | 2007/10000 [00:12<00:48, 163.25it/s]Running 10000 simulations.:  20%|██        | 2024/10000 [00:12<00:48, 163.47it/s]Running 10000 simulations.:  20%|██        | 2041/10000 [00:12<00:48, 163.70it/s]Running 10000 simulations.:  21%|██        | 2058/10000 [00:12<00:48, 164.13it/s]Running 10000 simulations.:  21%|██        | 2075/10000 [00:12<00:48, 164.51it/s]Running 10000 simulations.:  21%|██        | 2092/10000 [00:12<00:48, 164.46it/s]Running 10000 simulations.:  21%|██        | 2109/10000 [00:12<00:47, 164.54it/s]Running 10000 simulations.:  21%|██▏       | 2126/10000 [00:12<00:47, 164.50it/s]Running 10000 simulations.:  21%|██▏       | 2143/10000 [00:13<00:47, 164.50it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:13<00:47, 164.34it/s]Running 10000 simulations.:  22%|██▏       | 2177/10000 [00:13<00:47, 164.11it/s]Running 10000 simulations.:  22%|██▏       | 2194/10000 [00:13<00:47, 164.00it/s]Running 10000 simulations.:  22%|██▏       | 2211/10000 [00:13<00:47, 164.16it/s]Running 10000 simulations.:  22%|██▏       | 2228/10000 [00:13<00:47, 164.42it/s]Running 10000 simulations.:  22%|██▏       | 2245/10000 [00:13<00:47, 164.29it/s]Running 10000 simulations.:  23%|██▎       | 2262/10000 [00:13<00:47, 164.21it/s]Running 10000 simulations.:  23%|██▎       | 2279/10000 [00:13<00:46, 164.37it/s]Running 10000 simulations.:  23%|██▎       | 2296/10000 [00:13<00:46, 164.51it/s]Running 10000 simulations.:  23%|██▎       | 2313/10000 [00:14<00:46, 164.51it/s]Running 10000 simulations.:  23%|██▎       | 2330/10000 [00:14<00:46, 164.54it/s]Running 10000 simulations.:  23%|██▎       | 2347/10000 [00:14<00:46, 164.80it/s]Running 10000 simulations.:  24%|██▎       | 2364/10000 [00:14<00:46, 165.02it/s]Running 10000 simulations.:  24%|██▍       | 2381/10000 [00:14<00:46, 165.03it/s]Running 10000 simulations.:  24%|██▍       | 2398/10000 [00:14<00:46, 164.80it/s]Running 10000 simulations.:  24%|██▍       | 2415/10000 [00:14<00:46, 164.62it/s]Running 10000 simulations.:  24%|██▍       | 2432/10000 [00:14<00:45, 164.54it/s]Running 10000 simulations.:  24%|██▍       | 2449/10000 [00:14<00:45, 164.35it/s]Running 10000 simulations.:  25%|██▍       | 2466/10000 [00:14<00:45, 164.29it/s]Running 10000 simulations.:  25%|██▍       | 2483/10000 [00:15<00:45, 164.11it/s]Running 10000 simulations.:  25%|██▌       | 2500/10000 [00:15<00:45, 164.14it/s]Running 10000 simulations.:  25%|██▌       | 2517/10000 [00:15<00:45, 164.11it/s]Running 10000 simulations.:  25%|██▌       | 2534/10000 [00:15<00:45, 163.96it/s]Running 10000 simulations.:  26%|██▌       | 2551/10000 [00:15<00:45, 164.09it/s]Running 10000 simulations.:  26%|██▌       | 2568/10000 [00:15<00:45, 164.02it/s]Running 10000 simulations.:  26%|██▌       | 2585/10000 [00:15<00:45, 164.28it/s]Running 10000 simulations.:  26%|██▌       | 2602/10000 [00:15<00:45, 164.23it/s]Running 10000 simulations.:  26%|██▌       | 2619/10000 [00:15<00:44, 164.70it/s]Running 10000 simulations.:  26%|██▋       | 2636/10000 [00:16<00:44, 165.02it/s]Running 10000 simulations.:  27%|██▋       | 2653/10000 [00:16<00:44, 164.68it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:16<00:44, 164.44it/s]Running 10000 simulations.:  27%|██▋       | 2687/10000 [00:16<00:44, 164.26it/s]Running 10000 simulations.:  27%|██▋       | 2704/10000 [00:16<00:44, 164.17it/s]Running 10000 simulations.:  27%|██▋       | 2721/10000 [00:16<00:44, 164.68it/s]Running 10000 simulations.:  27%|██▋       | 2738/10000 [00:16<00:44, 164.76it/s]Running 10000 simulations.:  28%|██▊       | 2755/10000 [00:16<00:43, 164.69it/s]Running 10000 simulations.:  28%|██▊       | 2772/10000 [00:16<00:43, 164.64it/s]Running 10000 simulations.:  28%|██▊       | 2789/10000 [00:16<00:43, 164.46it/s]Running 10000 simulations.:  28%|██▊       | 2806/10000 [00:17<00:43, 164.31it/s]Running 10000 simulations.:  28%|██▊       | 2823/10000 [00:17<00:43, 164.32it/s]Running 10000 simulations.:  28%|██▊       | 2840/10000 [00:17<00:43, 164.40it/s]Running 10000 simulations.:  29%|██▊       | 2857/10000 [00:17<00:43, 164.66it/s]Running 10000 simulations.:  29%|██▊       | 2874/10000 [00:17<00:43, 164.38it/s]Running 10000 simulations.:  29%|██▉       | 2891/10000 [00:17<00:43, 164.25it/s]Running 10000 simulations.:  29%|██▉       | 2908/10000 [00:17<00:43, 164.17it/s]Running 10000 simulations.:  29%|██▉       | 2925/10000 [00:17<00:43, 164.12it/s]Running 10000 simulations.:  29%|██▉       | 2942/10000 [00:17<00:43, 163.96it/s]Running 10000 simulations.:  30%|██▉       | 2959/10000 [00:17<00:42, 164.27it/s]Running 10000 simulations.:  30%|██▉       | 2976/10000 [00:18<00:42, 164.43it/s]Running 10000 simulations.:  30%|██▉       | 2993/10000 [00:18<00:42, 164.66it/s]Running 10000 simulations.:  30%|███       | 3010/10000 [00:18<00:42, 164.45it/s]Running 10000 simulations.:  30%|███       | 3027/10000 [00:18<00:42, 164.50it/s]Running 10000 simulations.:  30%|███       | 3044/10000 [00:18<00:42, 164.58it/s]Running 10000 simulations.:  31%|███       | 3061/10000 [00:18<00:42, 164.57it/s]Running 10000 simulations.:  31%|███       | 3078/10000 [00:18<00:42, 164.64it/s]Running 10000 simulations.:  31%|███       | 3095/10000 [00:18<00:41, 164.43it/s]Running 10000 simulations.:  31%|███       | 3112/10000 [00:18<00:41, 164.24it/s]Running 10000 simulations.:  31%|███▏      | 3129/10000 [00:19<00:41, 164.16it/s]Running 10000 simulations.:  31%|███▏      | 3146/10000 [00:19<00:41, 164.16it/s]Running 10000 simulations.:  32%|███▏      | 3163/10000 [00:19<00:41, 164.06it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:19<00:41, 164.31it/s]Running 10000 simulations.:  32%|███▏      | 3197/10000 [00:19<00:41, 164.31it/s]Running 10000 simulations.:  32%|███▏      | 3214/10000 [00:19<00:41, 164.26it/s]Running 10000 simulations.:  32%|███▏      | 3231/10000 [00:19<00:41, 164.48it/s]Running 10000 simulations.:  32%|███▏      | 3248/10000 [00:19<00:41, 164.57it/s]Running 10000 simulations.:  33%|███▎      | 3265/10000 [00:19<00:40, 164.71it/s]Running 10000 simulations.:  33%|███▎      | 3282/10000 [00:19<00:40, 164.48it/s]Running 10000 simulations.:  33%|███▎      | 3299/10000 [00:20<00:40, 164.23it/s]Running 10000 simulations.:  33%|███▎      | 3316/10000 [00:20<00:40, 164.57it/s]Running 10000 simulations.:  33%|███▎      | 3333/10000 [00:20<00:40, 164.81it/s]Running 10000 simulations.:  34%|███▎      | 3350/10000 [00:20<00:40, 164.56it/s]Running 10000 simulations.:  34%|███▎      | 3367/10000 [00:20<00:40, 164.24it/s]Running 10000 simulations.:  34%|███▍      | 3384/10000 [00:20<00:40, 164.15it/s]Running 10000 simulations.:  34%|███▍      | 3401/10000 [00:20<00:40, 163.86it/s]Running 10000 simulations.:  34%|███▍      | 3418/10000 [00:20<00:40, 163.93it/s]Running 10000 simulations.:  34%|███▍      | 3435/10000 [00:20<00:40, 164.07it/s]Running 10000 simulations.:  35%|███▍      | 3452/10000 [00:20<00:39, 163.88it/s]Running 10000 simulations.:  35%|███▍      | 3469/10000 [00:21<00:39, 164.31it/s]Running 10000 simulations.:  35%|███▍      | 3486/10000 [00:21<00:39, 164.39it/s]Running 10000 simulations.:  35%|███▌      | 3503/10000 [00:21<00:39, 164.66it/s]Running 10000 simulations.:  35%|███▌      | 3520/10000 [00:21<00:39, 164.66it/s]Running 10000 simulations.:  35%|███▌      | 3537/10000 [00:21<00:39, 164.37it/s]Running 10000 simulations.:  36%|███▌      | 3554/10000 [00:21<00:39, 164.29it/s]Running 10000 simulations.:  36%|███▌      | 3571/10000 [00:21<00:39, 164.17it/s]Running 10000 simulations.:  36%|███▌      | 3588/10000 [00:21<00:39, 163.98it/s]Running 10000 simulations.:  36%|███▌      | 3605/10000 [00:21<00:39, 163.91it/s]Running 10000 simulations.:  36%|███▌      | 3622/10000 [00:22<00:38, 163.94it/s]Running 10000 simulations.:  36%|███▋      | 3639/10000 [00:22<00:38, 163.95it/s]Running 10000 simulations.:  37%|███▋      | 3656/10000 [00:22<00:38, 163.72it/s]Running 10000 simulations.:  37%|███▋      | 3673/10000 [00:22<00:38, 163.81it/s]Running 10000 simulations.:  37%|███▋      | 3690/10000 [00:22<00:38, 163.97it/s]Running 10000 simulations.:  37%|███▋      | 3707/10000 [00:22<00:38, 163.83it/s]Running 10000 simulations.:  37%|███▋      | 3724/10000 [00:22<00:38, 163.79it/s]Running 10000 simulations.:  37%|███▋      | 3741/10000 [00:22<00:38, 163.94it/s]Running 10000 simulations.:  38%|███▊      | 3758/10000 [00:22<00:38, 163.84it/s]Running 10000 simulations.:  38%|███▊      | 3775/10000 [00:22<00:37, 163.94it/s]Running 10000 simulations.:  38%|███▊      | 3792/10000 [00:23<00:37, 164.05it/s]Running 10000 simulations.:  38%|███▊      | 3809/10000 [00:23<00:37, 164.38it/s]Running 10000 simulations.:  38%|███▊      | 3826/10000 [00:23<00:37, 164.52it/s]Running 10000 simulations.:  38%|███▊      | 3843/10000 [00:23<00:37, 164.40it/s]Running 10000 simulations.:  39%|███▊      | 3860/10000 [00:23<00:37, 164.53it/s]Running 10000 simulations.:  39%|███▉      | 3877/10000 [00:23<00:37, 164.43it/s]Running 10000 simulations.:  39%|███▉      | 3894/10000 [00:23<00:37, 164.50it/s]Running 10000 simulations.:  39%|███▉      | 3911/10000 [00:23<00:36, 164.61it/s]Running 10000 simulations.:  39%|███▉      | 3928/10000 [00:23<00:36, 164.62it/s]Running 10000 simulations.:  39%|███▉      | 3945/10000 [00:23<00:36, 164.61it/s]Running 10000 simulations.:  40%|███▉      | 3962/10000 [00:24<00:36, 164.45it/s]Running 10000 simulations.:  40%|███▉      | 3979/10000 [00:24<00:36, 164.26it/s]Running 10000 simulations.:  40%|███▉      | 3996/10000 [00:24<00:36, 164.00it/s]Running 10000 simulations.:  40%|████      | 4013/10000 [00:24<00:36, 163.89it/s]Running 10000 simulations.:  40%|████      | 4030/10000 [00:24<00:36, 164.00it/s]Running 10000 simulations.:  40%|████      | 4047/10000 [00:24<00:36, 164.09it/s]Running 10000 simulations.:  41%|████      | 4064/10000 [00:24<00:36, 164.16it/s]Running 10000 simulations.:  41%|████      | 4081/10000 [00:24<00:36, 163.41it/s]Running 10000 simulations.:  41%|████      | 4098/10000 [00:24<00:36, 163.69it/s]Running 10000 simulations.:  41%|████      | 4115/10000 [00:25<00:35, 163.73it/s]Running 10000 simulations.:  41%|████▏     | 4132/10000 [00:25<00:35, 163.96it/s]Running 10000 simulations.:  41%|████▏     | 4149/10000 [00:25<00:35, 163.98it/s]Running 10000 simulations.:  42%|████▏     | 4166/10000 [00:25<00:35, 163.88it/s]Running 10000 simulations.:  42%|████▏     | 4183/10000 [00:25<00:35, 163.90it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:25<00:35, 163.86it/s]Running 10000 simulations.:  42%|████▏     | 4217/10000 [00:25<00:35, 163.88it/s]Running 10000 simulations.:  42%|████▏     | 4234/10000 [00:25<00:35, 163.88it/s]Running 10000 simulations.:  43%|████▎     | 4251/10000 [00:25<00:35, 164.00it/s]Running 10000 simulations.:  43%|████▎     | 4268/10000 [00:25<00:34, 164.06it/s]Running 10000 simulations.:  43%|████▎     | 4285/10000 [00:26<00:34, 164.31it/s]Running 10000 simulations.:  43%|████▎     | 4302/10000 [00:26<00:34, 164.05it/s]Running 10000 simulations.:  43%|████▎     | 4319/10000 [00:26<00:34, 164.05it/s]Running 10000 simulations.:  43%|████▎     | 4336/10000 [00:26<00:34, 163.89it/s]Running 10000 simulations.:  44%|████▎     | 4353/10000 [00:26<00:34, 163.70it/s]Running 10000 simulations.:  44%|████▎     | 4370/10000 [00:26<00:34, 163.79it/s]Running 10000 simulations.:  44%|████▍     | 4387/10000 [00:26<00:34, 162.98it/s]Running 10000 simulations.:  44%|████▍     | 4404/10000 [00:26<00:34, 163.43it/s]Running 10000 simulations.:  44%|████▍     | 4421/10000 [00:26<00:34, 163.82it/s]Running 10000 simulations.:  44%|████▍     | 4438/10000 [00:26<00:33, 164.00it/s]Running 10000 simulations.:  45%|████▍     | 4455/10000 [00:27<00:33, 164.17it/s]Running 10000 simulations.:  45%|████▍     | 4472/10000 [00:27<00:33, 164.15it/s]Running 10000 simulations.:  45%|████▍     | 4489/10000 [00:27<00:33, 164.20it/s]Running 10000 simulations.:  45%|████▌     | 4506/10000 [00:27<00:33, 164.36it/s]Running 10000 simulations.:  45%|████▌     | 4523/10000 [00:27<00:33, 164.26it/s]Running 10000 simulations.:  45%|████▌     | 4540/10000 [00:27<00:33, 164.43it/s]Running 10000 simulations.:  46%|████▌     | 4557/10000 [00:27<00:33, 164.58it/s]Running 10000 simulations.:  46%|████▌     | 4574/10000 [00:27<00:33, 164.33it/s]Running 10000 simulations.:  46%|████▌     | 4591/10000 [00:27<00:32, 164.68it/s]Running 10000 simulations.:  46%|████▌     | 4608/10000 [00:28<00:32, 164.55it/s]Running 10000 simulations.:  46%|████▋     | 4625/10000 [00:28<00:32, 164.42it/s]Running 10000 simulations.:  46%|████▋     | 4642/10000 [00:28<00:32, 164.53it/s]Running 10000 simulations.:  47%|████▋     | 4659/10000 [00:28<00:32, 164.67it/s]Running 10000 simulations.:  47%|████▋     | 4676/10000 [00:28<00:32, 164.56it/s]Running 10000 simulations.:  47%|████▋     | 4693/10000 [00:28<00:32, 164.26it/s]Running 10000 simulations.:  47%|████▋     | 4710/10000 [00:28<00:32, 164.16it/s]Running 10000 simulations.:  47%|████▋     | 4727/10000 [00:28<00:32, 164.63it/s]Running 10000 simulations.:  47%|████▋     | 4744/10000 [00:28<00:31, 164.44it/s]Running 10000 simulations.:  48%|████▊     | 4761/10000 [00:28<00:31, 164.35it/s]Running 10000 simulations.:  48%|████▊     | 4778/10000 [00:29<00:31, 164.01it/s]Running 10000 simulations.:  48%|████▊     | 4795/10000 [00:29<00:31, 164.08it/s]Running 10000 simulations.:  48%|████▊     | 4812/10000 [00:29<00:31, 164.09it/s]Running 10000 simulations.:  48%|████▊     | 4829/10000 [00:29<00:31, 164.34it/s]Running 10000 simulations.:  48%|████▊     | 4846/10000 [00:29<00:31, 164.61it/s]Running 10000 simulations.:  49%|████▊     | 4863/10000 [00:29<00:31, 164.80it/s]Running 10000 simulations.:  49%|████▉     | 4880/10000 [00:29<00:31, 164.74it/s]Running 10000 simulations.:  49%|████▉     | 4897/10000 [00:29<00:30, 165.10it/s]Running 10000 simulations.:  49%|████▉     | 4914/10000 [00:29<00:30, 164.68it/s]Running 10000 simulations.:  49%|████▉     | 4931/10000 [00:29<00:30, 164.82it/s]Running 10000 simulations.:  49%|████▉     | 4948/10000 [00:30<00:30, 164.50it/s]Running 10000 simulations.:  50%|████▉     | 4965/10000 [00:30<00:30, 164.86it/s]Running 10000 simulations.:  50%|████▉     | 4982/10000 [00:30<00:30, 164.97it/s]Running 10000 simulations.:  50%|████▉     | 4999/10000 [00:30<00:30, 165.26it/s]Running 10000 simulations.:  50%|█████     | 5016/10000 [00:30<00:30, 165.08it/s]Running 10000 simulations.:  50%|█████     | 5033/10000 [00:30<00:30, 164.66it/s]Running 10000 simulations.:  50%|█████     | 5050/10000 [00:30<00:30, 164.64it/s]Running 10000 simulations.:  51%|█████     | 5067/10000 [00:30<00:29, 164.76it/s]Running 10000 simulations.:  51%|█████     | 5084/10000 [00:30<00:29, 164.56it/s]Running 10000 simulations.:  51%|█████     | 5101/10000 [00:31<00:29, 164.51it/s]Running 10000 simulations.:  51%|█████     | 5118/10000 [00:31<00:29, 164.52it/s]Running 10000 simulations.:  51%|█████▏    | 5135/10000 [00:31<00:29, 164.44it/s]Running 10000 simulations.:  52%|█████▏    | 5152/10000 [00:31<00:29, 164.53it/s]Running 10000 simulations.:  52%|█████▏    | 5169/10000 [00:31<00:29, 164.33it/s]Running 10000 simulations.:  52%|█████▏    | 5186/10000 [00:31<00:29, 164.42it/s]Running 10000 simulations.:  52%|█████▏    | 5203/10000 [00:31<00:29, 164.42it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:31<00:29, 164.37it/s]Running 10000 simulations.:  52%|█████▏    | 5237/10000 [00:31<00:28, 164.54it/s]Running 10000 simulations.:  53%|█████▎    | 5254/10000 [00:31<00:28, 164.68it/s]Running 10000 simulations.:  53%|█████▎    | 5271/10000 [00:32<00:28, 164.52it/s]Running 10000 simulations.:  53%|█████▎    | 5288/10000 [00:32<00:28, 164.32it/s]Running 10000 simulations.:  53%|█████▎    | 5305/10000 [00:32<00:28, 164.33it/s]Running 10000 simulations.:  53%|█████▎    | 5322/10000 [00:32<00:28, 164.10it/s]Running 10000 simulations.:  53%|█████▎    | 5339/10000 [00:32<00:28, 164.05it/s]Running 10000 simulations.:  54%|█████▎    | 5356/10000 [00:32<00:28, 163.86it/s]Running 10000 simulations.:  54%|█████▎    | 5373/10000 [00:32<00:28, 163.81it/s]Running 10000 simulations.:  54%|█████▍    | 5390/10000 [00:32<00:28, 163.85it/s]Running 10000 simulations.:  54%|█████▍    | 5407/10000 [00:32<00:28, 163.80it/s]Running 10000 simulations.:  54%|█████▍    | 5424/10000 [00:32<00:27, 163.87it/s]Running 10000 simulations.:  54%|█████▍    | 5441/10000 [00:33<00:27, 164.07it/s]Running 10000 simulations.:  55%|█████▍    | 5458/10000 [00:33<00:27, 164.11it/s]Running 10000 simulations.:  55%|█████▍    | 5475/10000 [00:33<00:27, 164.35it/s]Running 10000 simulations.:  55%|█████▍    | 5492/10000 [00:33<00:27, 164.41it/s]Running 10000 simulations.:  55%|█████▌    | 5509/10000 [00:33<00:27, 164.77it/s]Running 10000 simulations.:  55%|█████▌    | 5526/10000 [00:33<00:27, 164.60it/s]Running 10000 simulations.:  55%|█████▌    | 5543/10000 [00:33<00:27, 164.60it/s]Running 10000 simulations.:  56%|█████▌    | 5560/10000 [00:33<00:26, 164.57it/s]Running 10000 simulations.:  56%|█████▌    | 5577/10000 [00:33<00:26, 164.40it/s]Running 10000 simulations.:  56%|█████▌    | 5594/10000 [00:34<00:26, 164.43it/s]Running 10000 simulations.:  56%|█████▌    | 5611/10000 [00:34<00:26, 164.47it/s]Running 10000 simulations.:  56%|█████▋    | 5628/10000 [00:34<00:26, 164.43it/s]Running 10000 simulations.:  56%|█████▋    | 5645/10000 [00:34<00:26, 164.36it/s]Running 10000 simulations.:  57%|█████▋    | 5662/10000 [00:34<00:26, 164.33it/s]Running 10000 simulations.:  57%|█████▋    | 5679/10000 [00:34<00:26, 164.32it/s]Running 10000 simulations.:  57%|█████▋    | 5696/10000 [00:34<00:26, 164.32it/s]Running 10000 simulations.:  57%|█████▋    | 5713/10000 [00:34<00:26, 164.42it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:34<00:25, 164.31it/s]Running 10000 simulations.:  57%|█████▋    | 5747/10000 [00:34<00:25, 164.07it/s]Running 10000 simulations.:  58%|█████▊    | 5764/10000 [00:35<00:25, 164.33it/s]Running 10000 simulations.:  58%|█████▊    | 5781/10000 [00:35<00:25, 164.13it/s]Running 10000 simulations.:  58%|█████▊    | 5798/10000 [00:35<00:25, 164.15it/s]Running 10000 simulations.:  58%|█████▊    | 5815/10000 [00:35<00:25, 164.14it/s]Running 10000 simulations.:  58%|█████▊    | 5832/10000 [00:35<00:25, 163.91it/s]Running 10000 simulations.:  58%|█████▊    | 5849/10000 [00:35<00:25, 163.79it/s]Running 10000 simulations.:  59%|█████▊    | 5866/10000 [00:35<00:25, 163.78it/s]Running 10000 simulations.:  59%|█████▉    | 5883/10000 [00:35<00:25, 163.77it/s]Running 10000 simulations.:  59%|█████▉    | 5900/10000 [00:35<00:25, 163.70it/s]Running 10000 simulations.:  59%|█████▉    | 5917/10000 [00:35<00:24, 163.63it/s]Running 10000 simulations.:  59%|█████▉    | 5934/10000 [00:36<00:24, 163.99it/s]Running 10000 simulations.:  60%|█████▉    | 5951/10000 [00:36<00:24, 164.11it/s]Running 10000 simulations.:  60%|█████▉    | 5968/10000 [00:36<00:24, 164.28it/s]Running 10000 simulations.:  60%|█████▉    | 5985/10000 [00:36<00:24, 164.19it/s]Running 10000 simulations.:  60%|██████    | 6002/10000 [00:36<00:24, 164.11it/s]Running 10000 simulations.:  60%|██████    | 6019/10000 [00:36<00:24, 163.97it/s]Running 10000 simulations.:  60%|██████    | 6036/10000 [00:36<00:24, 163.97it/s]Running 10000 simulations.:  61%|██████    | 6053/10000 [00:36<00:24, 163.97it/s]Running 10000 simulations.:  61%|██████    | 6070/10000 [00:36<00:23, 163.88it/s]Running 10000 simulations.:  61%|██████    | 6087/10000 [00:37<00:23, 163.82it/s]Running 10000 simulations.:  61%|██████    | 6104/10000 [00:37<00:23, 163.95it/s]Running 10000 simulations.:  61%|██████    | 6121/10000 [00:37<00:23, 164.27it/s]Running 10000 simulations.:  61%|██████▏   | 6138/10000 [00:37<00:23, 164.22it/s]Running 10000 simulations.:  62%|██████▏   | 6155/10000 [00:37<00:23, 164.44it/s]Running 10000 simulations.:  62%|██████▏   | 6172/10000 [00:37<00:23, 164.43it/s]Running 10000 simulations.:  62%|██████▏   | 6189/10000 [00:37<00:23, 164.44it/s]Running 10000 simulations.:  62%|██████▏   | 6206/10000 [00:37<00:23, 164.86it/s]Running 10000 simulations.:  62%|██████▏   | 6223/10000 [00:37<00:22, 164.69it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:37<00:22, 164.51it/s]Running 10000 simulations.:  63%|██████▎   | 6257/10000 [00:38<00:22, 164.24it/s]Running 10000 simulations.:  63%|██████▎   | 6274/10000 [00:38<00:22, 164.03it/s]Running 10000 simulations.:  63%|██████▎   | 6291/10000 [00:38<00:22, 163.95it/s]Running 10000 simulations.:  63%|██████▎   | 6308/10000 [00:38<00:22, 164.92it/s]Running 10000 simulations.:  63%|██████▎   | 6325/10000 [00:38<00:22, 165.01it/s]Running 10000 simulations.:  63%|██████▎   | 6342/10000 [00:38<00:22, 164.85it/s]Running 10000 simulations.:  64%|██████▎   | 6359/10000 [00:38<00:22, 164.52it/s]Running 10000 simulations.:  64%|██████▍   | 6376/10000 [00:38<00:22, 164.33it/s]Running 10000 simulations.:  64%|██████▍   | 6393/10000 [00:38<00:21, 164.14it/s]Running 10000 simulations.:  64%|██████▍   | 6410/10000 [00:38<00:21, 164.23it/s]Running 10000 simulations.:  64%|██████▍   | 6427/10000 [00:39<00:21, 163.86it/s]Running 10000 simulations.:  64%|██████▍   | 6444/10000 [00:39<00:21, 163.79it/s]Running 10000 simulations.:  65%|██████▍   | 6461/10000 [00:39<00:21, 163.62it/s]Running 10000 simulations.:  65%|██████▍   | 6478/10000 [00:39<00:21, 163.54it/s]Running 10000 simulations.:  65%|██████▍   | 6495/10000 [00:39<00:21, 163.57it/s]Running 10000 simulations.:  65%|██████▌   | 6512/10000 [00:39<00:21, 163.82it/s]Running 10000 simulations.:  65%|██████▌   | 6529/10000 [00:39<00:21, 163.95it/s]Running 10000 simulations.:  65%|██████▌   | 6546/10000 [00:39<00:21, 164.03it/s]Running 10000 simulations.:  66%|██████▌   | 6563/10000 [00:39<00:20, 164.20it/s]Running 10000 simulations.:  66%|██████▌   | 6580/10000 [00:40<00:20, 163.98it/s]Running 10000 simulations.:  66%|██████▌   | 6597/10000 [00:40<00:20, 163.85it/s]Running 10000 simulations.:  66%|██████▌   | 6614/10000 [00:40<00:20, 163.92it/s]Running 10000 simulations.:  66%|██████▋   | 6631/10000 [00:40<00:20, 163.85it/s]Running 10000 simulations.:  66%|██████▋   | 6648/10000 [00:40<00:20, 163.84it/s]Running 10000 simulations.:  67%|██████▋   | 6665/10000 [00:40<00:20, 163.81it/s]Running 10000 simulations.:  67%|██████▋   | 6682/10000 [00:40<00:20, 164.01it/s]Running 10000 simulations.:  67%|██████▋   | 6699/10000 [00:40<00:20, 164.36it/s]Running 10000 simulations.:  67%|██████▋   | 6716/10000 [00:40<00:19, 164.64it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:40<00:19, 164.41it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:41<00:19, 164.28it/s]Running 10000 simulations.:  68%|██████▊   | 6767/10000 [00:41<00:19, 164.28it/s]Running 10000 simulations.:  68%|██████▊   | 6784/10000 [00:41<00:19, 164.32it/s]Running 10000 simulations.:  68%|██████▊   | 6801/10000 [00:41<00:19, 164.34it/s]Running 10000 simulations.:  68%|██████▊   | 6818/10000 [00:41<00:19, 164.29it/s]Running 10000 simulations.:  68%|██████▊   | 6835/10000 [00:41<00:19, 163.91it/s]Running 10000 simulations.:  69%|██████▊   | 6852/10000 [00:41<00:19, 158.01it/s]Running 10000 simulations.:  69%|██████▊   | 6869/10000 [00:41<00:19, 159.84it/s]Running 10000 simulations.:  69%|██████▉   | 6886/10000 [00:41<00:19, 161.21it/s]Running 10000 simulations.:  69%|██████▉   | 6903/10000 [00:42<00:19, 162.54it/s]Running 10000 simulations.:  69%|██████▉   | 6920/10000 [00:42<00:18, 163.33it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:42<00:18, 163.81it/s]Running 10000 simulations.:  70%|██████▉   | 6954/10000 [00:42<00:18, 163.72it/s]Running 10000 simulations.:  70%|██████▉   | 6971/10000 [00:42<00:18, 163.88it/s]Running 10000 simulations.:  70%|██████▉   | 6988/10000 [00:42<00:18, 163.92it/s]Running 10000 simulations.:  70%|███████   | 7005/10000 [00:42<00:18, 163.87it/s]Running 10000 simulations.:  70%|███████   | 7022/10000 [00:42<00:18, 164.19it/s]Running 10000 simulations.:  70%|███████   | 7039/10000 [00:42<00:18, 164.14it/s]Running 10000 simulations.:  71%|███████   | 7056/10000 [00:42<00:17, 164.13it/s]Running 10000 simulations.:  71%|███████   | 7073/10000 [00:43<00:17, 164.03it/s]Running 10000 simulations.:  71%|███████   | 7090/10000 [00:43<00:17, 164.24it/s]Running 10000 simulations.:  71%|███████   | 7107/10000 [00:43<00:17, 164.39it/s]Running 10000 simulations.:  71%|███████   | 7124/10000 [00:43<00:17, 164.42it/s]Running 10000 simulations.:  71%|███████▏  | 7141/10000 [00:43<00:17, 164.45it/s]Running 10000 simulations.:  72%|███████▏  | 7158/10000 [00:43<00:17, 164.23it/s]Running 10000 simulations.:  72%|███████▏  | 7175/10000 [00:43<00:17, 163.95it/s]Running 10000 simulations.:  72%|███████▏  | 7192/10000 [00:43<00:17, 164.00it/s]Running 10000 simulations.:  72%|███████▏  | 7209/10000 [00:43<00:17, 163.93it/s]Running 10000 simulations.:  72%|███████▏  | 7226/10000 [00:43<00:16, 163.94it/s]Running 10000 simulations.:  72%|███████▏  | 7243/10000 [00:44<00:16, 164.02it/s]Running 10000 simulations.:  73%|███████▎  | 7260/10000 [00:44<00:16, 164.19it/s]Running 10000 simulations.:  73%|███████▎  | 7277/10000 [00:44<00:16, 164.16it/s]Running 10000 simulations.:  73%|███████▎  | 7294/10000 [00:44<00:16, 164.28it/s]Running 10000 simulations.:  73%|███████▎  | 7311/10000 [00:44<00:16, 164.17it/s]Running 10000 simulations.:  73%|███████▎  | 7328/10000 [00:44<00:16, 164.12it/s]Running 10000 simulations.:  73%|███████▎  | 7345/10000 [00:44<00:16, 164.38it/s]Running 10000 simulations.:  74%|███████▎  | 7362/10000 [00:44<00:16, 164.37it/s]Running 10000 simulations.:  74%|███████▍  | 7379/10000 [00:44<00:15, 164.41it/s]Running 10000 simulations.:  74%|███████▍  | 7396/10000 [00:45<00:15, 164.46it/s]Running 10000 simulations.:  74%|███████▍  | 7413/10000 [00:45<00:15, 164.24it/s]Running 10000 simulations.:  74%|███████▍  | 7430/10000 [00:45<00:15, 164.11it/s]Running 10000 simulations.:  74%|███████▍  | 7447/10000 [00:45<00:15, 163.95it/s]Running 10000 simulations.:  75%|███████▍  | 7464/10000 [00:45<00:15, 163.93it/s]Running 10000 simulations.:  75%|███████▍  | 7481/10000 [00:45<00:15, 163.99it/s]Running 10000 simulations.:  75%|███████▍  | 7498/10000 [00:45<00:15, 164.25it/s]Running 10000 simulations.:  75%|███████▌  | 7515/10000 [00:45<00:15, 164.45it/s]Running 10000 simulations.:  75%|███████▌  | 7532/10000 [00:45<00:15, 164.25it/s]Running 10000 simulations.:  75%|███████▌  | 7549/10000 [00:45<00:14, 164.25it/s]Running 10000 simulations.:  76%|███████▌  | 7566/10000 [00:46<00:14, 164.29it/s]Running 10000 simulations.:  76%|███████▌  | 7583/10000 [00:46<00:14, 164.84it/s]Running 10000 simulations.:  76%|███████▌  | 7600/10000 [00:46<00:14, 164.60it/s]Running 10000 simulations.:  76%|███████▌  | 7617/10000 [00:46<00:14, 164.58it/s]Running 10000 simulations.:  76%|███████▋  | 7634/10000 [00:46<00:14, 164.56it/s]Running 10000 simulations.:  77%|███████▋  | 7651/10000 [00:46<00:14, 164.68it/s]Running 10000 simulations.:  77%|███████▋  | 7668/10000 [00:46<00:14, 164.64it/s]Running 10000 simulations.:  77%|███████▋  | 7685/10000 [00:46<00:14, 164.60it/s]Running 10000 simulations.:  77%|███████▋  | 7702/10000 [00:46<00:13, 164.47it/s]Running 10000 simulations.:  77%|███████▋  | 7719/10000 [00:46<00:13, 165.06it/s]Running 10000 simulations.:  77%|███████▋  | 7736/10000 [00:47<00:13, 165.18it/s]Running 10000 simulations.:  78%|███████▊  | 7754/10000 [00:47<00:13, 169.24it/s]Running 10000 simulations.:  78%|███████▊  | 7774/10000 [00:47<00:12, 175.35it/s]Running 10000 simulations.:  78%|███████▊  | 7794/10000 [00:47<00:12, 179.50it/s]Running 10000 simulations.:  78%|███████▊  | 7813/10000 [00:47<00:12, 179.25it/s]Running 10000 simulations.:  78%|███████▊  | 7831/10000 [00:47<00:12, 177.98it/s]Running 10000 simulations.:  78%|███████▊  | 7849/10000 [00:47<00:12, 174.44it/s]Running 10000 simulations.:  79%|███████▊  | 7867/10000 [00:47<00:12, 171.28it/s]Running 10000 simulations.:  79%|███████▉  | 7885/10000 [00:47<00:12, 170.40it/s]Running 10000 simulations.:  79%|███████▉  | 7903/10000 [00:48<00:12, 169.75it/s]Running 10000 simulations.:  79%|███████▉  | 7921/10000 [00:48<00:12, 171.39it/s]Running 10000 simulations.:  79%|███████▉  | 7939/10000 [00:48<00:11, 172.68it/s]Running 10000 simulations.:  80%|███████▉  | 7957/10000 [00:48<00:12, 169.32it/s]Running 10000 simulations.:  80%|███████▉  | 7974/10000 [00:48<00:12, 168.09it/s]Running 10000 simulations.:  80%|███████▉  | 7991/10000 [00:48<00:12, 167.38it/s]Running 10000 simulations.:  80%|████████  | 8008/10000 [00:48<00:11, 168.01it/s]Running 10000 simulations.:  80%|████████  | 8026/10000 [00:48<00:11, 169.82it/s]Running 10000 simulations.:  80%|████████  | 8043/10000 [00:48<00:11, 167.81it/s]Running 10000 simulations.:  81%|████████  | 8060/10000 [00:48<00:11, 167.10it/s]Running 10000 simulations.:  81%|████████  | 8077/10000 [00:49<00:11, 166.65it/s]Running 10000 simulations.:  81%|████████  | 8095/10000 [00:49<00:11, 168.17it/s]Running 10000 simulations.:  81%|████████  | 8113/10000 [00:49<00:11, 170.01it/s]Running 10000 simulations.:  81%|████████▏ | 8131/10000 [00:49<00:10, 172.36it/s]Running 10000 simulations.:  81%|████████▏ | 8149/10000 [00:49<00:10, 170.32it/s]Running 10000 simulations.:  82%|████████▏ | 8167/10000 [00:49<00:10, 168.72it/s]Running 10000 simulations.:  82%|████████▏ | 8184/10000 [00:49<00:10, 168.73it/s]Running 10000 simulations.:  82%|████████▏ | 8201/10000 [00:49<00:10, 168.89it/s]Running 10000 simulations.:  82%|████████▏ | 8219/10000 [00:49<00:10, 170.07it/s]Running 10000 simulations.:  82%|████████▏ | 8237/10000 [00:50<00:10, 167.41it/s]Running 10000 simulations.:  83%|████████▎ | 8254/10000 [00:50<00:10, 166.53it/s]Running 10000 simulations.:  83%|████████▎ | 8272/10000 [00:50<00:10, 168.09it/s]Running 10000 simulations.:  83%|████████▎ | 8290/10000 [00:50<00:10, 168.79it/s]Running 10000 simulations.:  83%|████████▎ | 8308/10000 [00:50<00:09, 170.40it/s]Running 10000 simulations.:  83%|████████▎ | 8326/10000 [00:50<00:09, 170.42it/s]Running 10000 simulations.:  83%|████████▎ | 8344/10000 [00:50<00:09, 167.43it/s]Running 10000 simulations.:  84%|████████▎ | 8361/10000 [00:50<00:09, 167.14it/s]Running 10000 simulations.:  84%|████████▍ | 8379/10000 [00:50<00:09, 168.34it/s]Running 10000 simulations.:  84%|████████▍ | 8397/10000 [00:50<00:09, 169.16it/s]Running 10000 simulations.:  84%|████████▍ | 8414/10000 [00:51<00:09, 169.19it/s]Running 10000 simulations.:  84%|████████▍ | 8431/10000 [00:51<00:09, 166.81it/s]Running 10000 simulations.:  84%|████████▍ | 8448/10000 [00:51<00:09, 166.66it/s]Running 10000 simulations.:  85%|████████▍ | 8466/10000 [00:51<00:09, 167.81it/s]Running 10000 simulations.:  85%|████████▍ | 8484/10000 [00:51<00:08, 169.48it/s]Running 10000 simulations.:  85%|████████▌ | 8502/10000 [00:51<00:08, 171.06it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:51<00:08, 169.52it/s]Running 10000 simulations.:  85%|████████▌ | 8537/10000 [00:51<00:08, 167.70it/s]Running 10000 simulations.:  86%|████████▌ | 8554/10000 [00:51<00:08, 167.09it/s]Running 10000 simulations.:  86%|████████▌ | 8571/10000 [00:51<00:08, 167.42it/s]Running 10000 simulations.:  86%|████████▌ | 8589/10000 [00:52<00:08, 170.02it/s]Running 10000 simulations.:  86%|████████▌ | 8607/10000 [00:52<00:08, 168.31it/s]Running 10000 simulations.:  86%|████████▌ | 8624/10000 [00:52<00:08, 166.82it/s]Running 10000 simulations.:  86%|████████▋ | 8641/10000 [00:52<00:08, 166.10it/s]Running 10000 simulations.:  87%|████████▋ | 8658/10000 [00:52<00:08, 166.84it/s]Running 10000 simulations.:  87%|████████▋ | 8676/10000 [00:52<00:07, 169.35it/s]Running 10000 simulations.:  87%|████████▋ | 8694/10000 [00:52<00:07, 170.95it/s]Running 10000 simulations.:  87%|████████▋ | 8712/10000 [00:52<00:07, 172.18it/s]Running 10000 simulations.:  87%|████████▋ | 8730/10000 [00:52<00:07, 168.88it/s]Running 10000 simulations.:  87%|████████▋ | 8747/10000 [00:53<00:07, 167.81it/s]Running 10000 simulations.:  88%|████████▊ | 8764/10000 [00:53<00:07, 168.18it/s]Running 10000 simulations.:  88%|████████▊ | 8782/10000 [00:53<00:07, 168.98it/s]Running 10000 simulations.:  88%|████████▊ | 8800/10000 [00:53<00:07, 170.46it/s]Running 10000 simulations.:  88%|████████▊ | 8818/10000 [00:53<00:06, 171.71it/s]Running 10000 simulations.:  88%|████████▊ | 8836/10000 [00:53<00:06, 172.68it/s]Running 10000 simulations.:  89%|████████▊ | 8854/10000 [00:53<00:06, 173.01it/s]Running 10000 simulations.:  89%|████████▊ | 8872/10000 [00:53<00:06, 173.74it/s]Running 10000 simulations.:  89%|████████▉ | 8890/10000 [00:53<00:06, 170.24it/s]Running 10000 simulations.:  89%|████████▉ | 8908/10000 [00:53<00:06, 171.30it/s]Running 10000 simulations.:  89%|████████▉ | 8926/10000 [00:54<00:06, 172.15it/s]Running 10000 simulations.:  89%|████████▉ | 8944/10000 [00:54<00:06, 171.01it/s]Running 10000 simulations.:  90%|████████▉ | 8962/10000 [00:54<00:06, 171.06it/s]Running 10000 simulations.:  90%|████████▉ | 8980/10000 [00:54<00:05, 172.73it/s]Running 10000 simulations.:  90%|████████▉ | 8998/10000 [00:54<00:05, 170.23it/s]Running 10000 simulations.:  90%|█████████ | 9016/10000 [00:54<00:05, 168.37it/s]Running 10000 simulations.:  90%|█████████ | 9033/10000 [00:54<00:05, 167.69it/s]Running 10000 simulations.:  91%|█████████ | 9051/10000 [00:54<00:05, 168.62it/s]Running 10000 simulations.:  91%|█████████ | 9069/10000 [00:54<00:05, 170.34it/s]Running 10000 simulations.:  91%|█████████ | 9087/10000 [00:55<00:05, 167.89it/s]Running 10000 simulations.:  91%|█████████ | 9104/10000 [00:55<00:05, 167.32it/s]Running 10000 simulations.:  91%|█████████ | 9121/10000 [00:55<00:05, 167.44it/s]Running 10000 simulations.:  91%|█████████▏| 9139/10000 [00:55<00:05, 168.42it/s]Running 10000 simulations.:  92%|█████████▏| 9157/10000 [00:55<00:04, 169.51it/s]Running 10000 simulations.:  92%|█████████▏| 9174/10000 [00:55<00:04, 166.27it/s]Running 10000 simulations.:  92%|█████████▏| 9191/10000 [00:55<00:04, 166.31it/s]Running 10000 simulations.:  92%|█████████▏| 9208/10000 [00:55<00:04, 167.10it/s]Running 10000 simulations.:  92%|█████████▏| 9225/10000 [00:55<00:04, 167.78it/s]Running 10000 simulations.:  92%|█████████▏| 9243/10000 [00:55<00:04, 169.22it/s]Running 10000 simulations.:  93%|█████████▎| 9260/10000 [00:56<00:04, 166.53it/s]Running 10000 simulations.:  93%|█████████▎| 9277/10000 [00:56<00:04, 166.48it/s]Running 10000 simulations.:  93%|█████████▎| 9294/10000 [00:56<00:04, 167.25it/s]Running 10000 simulations.:  93%|█████████▎| 9312/10000 [00:56<00:04, 168.74it/s]Running 10000 simulations.:  93%|█████████▎| 9330/10000 [00:56<00:03, 170.10it/s]Running 10000 simulations.:  93%|█████████▎| 9348/10000 [00:56<00:03, 167.22it/s]Running 10000 simulations.:  94%|█████████▎| 9365/10000 [00:56<00:03, 166.79it/s]Running 10000 simulations.:  94%|█████████▍| 9383/10000 [00:56<00:03, 168.92it/s]Running 10000 simulations.:  94%|█████████▍| 9401/10000 [00:56<00:03, 169.97it/s]Running 10000 simulations.:  94%|█████████▍| 9419/10000 [00:56<00:03, 170.26it/s]Running 10000 simulations.:  94%|█████████▍| 9437/10000 [00:57<00:03, 167.59it/s]Running 10000 simulations.:  95%|█████████▍| 9454/10000 [00:57<00:03, 168.07it/s]Running 10000 simulations.:  95%|█████████▍| 9471/10000 [00:57<00:03, 168.63it/s]Running 10000 simulations.:  95%|█████████▍| 9489/10000 [00:57<00:03, 169.55it/s]Running 10000 simulations.:  95%|█████████▌| 9506/10000 [00:57<00:02, 169.66it/s]Running 10000 simulations.:  95%|█████████▌| 9523/10000 [00:57<00:02, 167.14it/s]Running 10000 simulations.:  95%|█████████▌| 9540/10000 [00:57<00:02, 167.04it/s]Running 10000 simulations.:  96%|█████████▌| 9558/10000 [00:57<00:02, 167.86it/s]Running 10000 simulations.:  96%|█████████▌| 9576/10000 [00:57<00:02, 169.22it/s]Running 10000 simulations.:  96%|█████████▌| 9594/10000 [00:58<00:02, 170.45it/s]Running 10000 simulations.:  96%|█████████▌| 9612/10000 [00:58<00:02, 172.93it/s]Running 10000 simulations.:  96%|█████████▋| 9630/10000 [00:58<00:02, 169.88it/s]Running 10000 simulations.:  96%|█████████▋| 9648/10000 [00:58<00:02, 169.39it/s]Running 10000 simulations.:  97%|█████████▋| 9665/10000 [00:58<00:01, 169.11it/s]Running 10000 simulations.:  97%|█████████▋| 9683/10000 [00:58<00:01, 170.68it/s]Running 10000 simulations.:  97%|█████████▋| 9701/10000 [00:58<00:01, 168.93it/s]Running 10000 simulations.:  97%|█████████▋| 9718/10000 [00:58<00:01, 167.26it/s]Running 10000 simulations.:  97%|█████████▋| 9735/10000 [00:58<00:01, 167.07it/s]Running 10000 simulations.:  98%|█████████▊| 9753/10000 [00:58<00:01, 167.90it/s]Running 10000 simulations.:  98%|█████████▊| 9771/10000 [00:59<00:01, 170.21it/s]Running 10000 simulations.:  98%|█████████▊| 9789/10000 [00:59<00:01, 168.85it/s]Running 10000 simulations.:  98%|█████████▊| 9806/10000 [00:59<00:01, 167.47it/s]Running 10000 simulations.:  98%|█████████▊| 9823/10000 [00:59<00:01, 167.08it/s]Running 10000 simulations.:  98%|█████████▊| 9840/10000 [00:59<00:00, 167.71it/s]Running 10000 simulations.:  99%|█████████▊| 9858/10000 [00:59<00:00, 169.98it/s]Running 10000 simulations.:  99%|█████████▉| 9876/10000 [00:59<00:00, 171.57it/s]Running 10000 simulations.:  99%|█████████▉| 9894/10000 [00:59<00:00, 169.56it/s]Running 10000 simulations.:  99%|█████████▉| 9911/10000 [00:59<00:00, 168.50it/s]Running 10000 simulations.:  99%|█████████▉| 9928/10000 [01:00<00:00, 167.82it/s]Running 10000 simulations.:  99%|█████████▉| 9945/10000 [01:00<00:00, 168.18it/s]Running 10000 simulations.: 100%|█████████▉| 9963/10000 [01:00<00:00, 170.40it/s]Running 10000 simulations.: 100%|█████████▉| 9981/10000 [01:00<00:00, 168.65it/s]Running 10000 simulations.: 100%|█████████▉| 9998/10000 [01:00<00:00, 167.82it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [01:00<00:00, 165.45it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 29/10000 [00:00<00:34, 288.83it/s]Running 10000 simulations.:   1%|          | 58/10000 [00:00<00:34, 288.43it/s]Running 10000 simulations.:   1%|          | 87/10000 [00:00<00:34, 287.78it/s]Running 10000 simulations.:   1%|          | 117/10000 [00:00<00:34, 288.82it/s]Running 10000 simulations.:   1%|▏         | 147/10000 [00:00<00:34, 289.79it/s]Running 10000 simulations.:   2%|▏         | 177/10000 [00:00<00:33, 290.63it/s]Running 10000 simulations.:   2%|▏         | 207/10000 [00:00<00:33, 291.53it/s]Running 10000 simulations.:   2%|▏         | 236/10000 [00:00<00:33, 290.90it/s]Running 10000 simulations.:   3%|▎         | 265/10000 [00:00<00:33, 289.86it/s]Running 10000 simulations.:   3%|▎         | 294/10000 [00:01<00:33, 288.84it/s]Running 10000 simulations.:   3%|▎         | 323/10000 [00:01<00:33, 288.13it/s]Running 10000 simulations.:   4%|▎         | 352/10000 [00:01<00:33, 288.15it/s]Running 10000 simulations.:   4%|▍         | 381/10000 [00:01<00:33, 287.30it/s]Running 10000 simulations.:   4%|▍         | 410/10000 [00:01<00:33, 286.02it/s]Running 10000 simulations.:   4%|▍         | 439/10000 [00:01<00:33, 285.47it/s]Running 10000 simulations.:   5%|▍         | 468/10000 [00:01<00:33, 285.62it/s]Running 10000 simulations.:   5%|▍         | 497/10000 [00:01<00:33, 286.67it/s]Running 10000 simulations.:   5%|▌         | 526/10000 [00:01<00:33, 286.83it/s]Running 10000 simulations.:   6%|▌         | 555/10000 [00:01<00:33, 285.59it/s]Running 10000 simulations.:   6%|▌         | 584/10000 [00:02<00:32, 286.63it/s]Running 10000 simulations.:   6%|▌         | 614/10000 [00:02<00:32, 288.21it/s]Running 10000 simulations.:   6%|▋         | 644/10000 [00:02<00:32, 289.20it/s]Running 10000 simulations.:   7%|▋         | 674/10000 [00:02<00:32, 290.13it/s]Running 10000 simulations.:   7%|▋         | 704/10000 [00:02<00:31, 290.72it/s]Running 10000 simulations.:   7%|▋         | 734/10000 [00:02<00:31, 290.55it/s]Running 10000 simulations.:   8%|▊         | 764/10000 [00:02<00:31, 290.76it/s]Running 10000 simulations.:   8%|▊         | 794/10000 [00:02<00:31, 291.02it/s]Running 10000 simulations.:   8%|▊         | 824/10000 [00:02<00:31, 290.46it/s]Running 10000 simulations.:   9%|▊         | 854/10000 [00:02<00:31, 290.27it/s]Running 10000 simulations.:   9%|▉         | 884/10000 [00:03<00:31, 289.23it/s]Running 10000 simulations.:   9%|▉         | 914/10000 [00:03<00:31, 290.05it/s]Running 10000 simulations.:   9%|▉         | 944/10000 [00:03<00:31, 289.46it/s]Running 10000 simulations.:  10%|▉         | 973/10000 [00:03<00:31, 288.73it/s]Running 10000 simulations.:  10%|█         | 1002/10000 [00:03<00:31, 288.68it/s]Running 10000 simulations.:  10%|█         | 1032/10000 [00:03<00:31, 289.07it/s]Running 10000 simulations.:  11%|█         | 1061/10000 [00:03<00:30, 289.16it/s]Running 10000 simulations.:  11%|█         | 1090/10000 [00:03<00:30, 288.21it/s]Running 10000 simulations.:  11%|█         | 1119/10000 [00:03<00:31, 286.23it/s]Running 10000 simulations.:  11%|█▏        | 1148/10000 [00:03<00:31, 283.06it/s]Running 10000 simulations.:  12%|█▏        | 1177/10000 [00:04<00:31, 284.27it/s]Running 10000 simulations.:  12%|█▏        | 1206/10000 [00:04<00:30, 285.96it/s]Running 10000 simulations.:  12%|█▏        | 1235/10000 [00:04<00:30, 285.38it/s]Running 10000 simulations.:  13%|█▎        | 1264/10000 [00:04<00:30, 286.11it/s]Running 10000 simulations.:  13%|█▎        | 1293/10000 [00:04<00:30, 286.17it/s]Running 10000 simulations.:  13%|█▎        | 1322/10000 [00:04<00:30, 286.34it/s]Running 10000 simulations.:  14%|█▎        | 1351/10000 [00:04<00:30, 286.64it/s]Running 10000 simulations.:  14%|█▍        | 1381/10000 [00:04<00:29, 287.97it/s]Running 10000 simulations.:  14%|█▍        | 1410/10000 [00:04<00:29, 287.24it/s]Running 10000 simulations.:  14%|█▍        | 1439/10000 [00:04<00:29, 286.66it/s]Running 10000 simulations.:  15%|█▍        | 1468/10000 [00:05<00:29, 286.12it/s]Running 10000 simulations.:  15%|█▍        | 1497/10000 [00:05<00:29, 286.05it/s]Running 10000 simulations.:  15%|█▌        | 1526/10000 [00:05<00:29, 286.99it/s]Running 10000 simulations.:  16%|█▌        | 1555/10000 [00:05<00:29, 287.20it/s]Running 10000 simulations.:  16%|█▌        | 1584/10000 [00:05<00:29, 287.92it/s]Running 10000 simulations.:  16%|█▌        | 1614/10000 [00:05<00:29, 288.52it/s]Running 10000 simulations.:  16%|█▋        | 1643/10000 [00:05<00:28, 288.53it/s]Running 10000 simulations.:  17%|█▋        | 1672/10000 [00:05<00:28, 288.65it/s]Running 10000 simulations.:  17%|█▋        | 1701/10000 [00:05<00:28, 288.09it/s]Running 10000 simulations.:  17%|█▋        | 1730/10000 [00:06<00:28, 287.10it/s]Running 10000 simulations.:  18%|█▊        | 1759/10000 [00:06<00:28, 287.70it/s]Running 10000 simulations.:  18%|█▊        | 1788/10000 [00:06<00:28, 288.37it/s]Running 10000 simulations.:  18%|█▊        | 1818/10000 [00:06<00:28, 289.03it/s]Running 10000 simulations.:  18%|█▊        | 1848/10000 [00:06<00:28, 289.37it/s]Running 10000 simulations.:  19%|█▉        | 1877/10000 [00:06<00:28, 288.22it/s]Running 10000 simulations.:  19%|█▉        | 1906/10000 [00:06<00:28, 287.56it/s]Running 10000 simulations.:  19%|█▉        | 1936/10000 [00:06<00:27, 288.57it/s]Running 10000 simulations.:  20%|█▉        | 1965/10000 [00:06<00:27, 288.49it/s]Running 10000 simulations.:  20%|█▉        | 1994/10000 [00:06<00:27, 287.04it/s]Running 10000 simulations.:  20%|██        | 2023/10000 [00:07<00:27, 286.15it/s]Running 10000 simulations.:  21%|██        | 2052/10000 [00:07<00:27, 285.07it/s]Running 10000 simulations.:  21%|██        | 2081/10000 [00:07<00:27, 285.16it/s]Running 10000 simulations.:  21%|██        | 2110/10000 [00:07<00:27, 285.50it/s]Running 10000 simulations.:  21%|██▏       | 2139/10000 [00:07<00:27, 285.36it/s]Running 10000 simulations.:  22%|██▏       | 2168/10000 [00:07<00:27, 285.30it/s]Running 10000 simulations.:  22%|██▏       | 2197/10000 [00:07<00:27, 283.98it/s]Running 10000 simulations.:  22%|██▏       | 2226/10000 [00:07<00:27, 284.80it/s]Running 10000 simulations.:  23%|██▎       | 2255/10000 [00:07<00:27, 286.23it/s]Running 10000 simulations.:  23%|██▎       | 2284/10000 [00:07<00:26, 287.24it/s]Running 10000 simulations.:  23%|██▎       | 2313/10000 [00:08<00:26, 287.69it/s]Running 10000 simulations.:  23%|██▎       | 2342/10000 [00:08<00:26, 286.97it/s]Running 10000 simulations.:  24%|██▎       | 2371/10000 [00:08<00:26, 287.03it/s]Running 10000 simulations.:  24%|██▍       | 2401/10000 [00:08<00:26, 287.95it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:08<00:26, 287.54it/s]Running 10000 simulations.:  25%|██▍       | 2459/10000 [00:08<00:26, 282.47it/s]Running 10000 simulations.:  25%|██▍       | 2488/10000 [00:08<00:26, 283.21it/s]Running 10000 simulations.:  25%|██▌       | 2517/10000 [00:08<00:26, 285.11it/s]Running 10000 simulations.:  25%|██▌       | 2546/10000 [00:08<00:26, 284.12it/s]Running 10000 simulations.:  26%|██▌       | 2575/10000 [00:08<00:26, 283.96it/s]Running 10000 simulations.:  26%|██▌       | 2604/10000 [00:09<00:26, 283.49it/s]Running 10000 simulations.:  26%|██▋       | 2633/10000 [00:09<00:25, 284.03it/s]Running 10000 simulations.:  27%|██▋       | 2662/10000 [00:09<00:25, 283.87it/s]Running 10000 simulations.:  27%|██▋       | 2691/10000 [00:09<00:25, 283.78it/s]Running 10000 simulations.:  27%|██▋       | 2720/10000 [00:09<00:25, 283.11it/s]Running 10000 simulations.:  27%|██▋       | 2749/10000 [00:09<00:25, 283.33it/s]Running 10000 simulations.:  28%|██▊       | 2778/10000 [00:09<00:25, 283.73it/s]Running 10000 simulations.:  28%|██▊       | 2807/10000 [00:09<00:25, 284.42it/s]Running 10000 simulations.:  28%|██▊       | 2836/10000 [00:09<00:25, 285.29it/s]Running 10000 simulations.:  29%|██▊       | 2865/10000 [00:09<00:25, 284.69it/s]Running 10000 simulations.:  29%|██▉       | 2894/10000 [00:10<00:24, 284.66it/s]Running 10000 simulations.:  29%|██▉       | 2923/10000 [00:10<00:24, 285.62it/s]Running 10000 simulations.:  30%|██▉       | 2952/10000 [00:10<00:24, 286.49it/s]Running 10000 simulations.:  30%|██▉       | 2981/10000 [00:10<00:24, 287.31it/s]Running 10000 simulations.:  30%|███       | 3010/10000 [00:10<00:24, 287.33it/s]Running 10000 simulations.:  30%|███       | 3039/10000 [00:10<00:24, 286.73it/s]Running 10000 simulations.:  31%|███       | 3068/10000 [00:10<00:24, 287.41it/s]Running 10000 simulations.:  31%|███       | 3097/10000 [00:10<00:23, 288.01it/s]Running 10000 simulations.:  31%|███▏      | 3126/10000 [00:10<00:23, 288.09it/s]Running 10000 simulations.:  32%|███▏      | 3156/10000 [00:10<00:23, 289.20it/s]Running 10000 simulations.:  32%|███▏      | 3185/10000 [00:11<00:23, 288.82it/s]Running 10000 simulations.:  32%|███▏      | 3214/10000 [00:11<00:23, 288.88it/s]Running 10000 simulations.:  32%|███▏      | 3244/10000 [00:11<00:23, 289.26it/s]Running 10000 simulations.:  33%|███▎      | 3273/10000 [00:11<00:23, 289.34it/s]Running 10000 simulations.:  33%|███▎      | 3303/10000 [00:11<00:23, 289.54it/s]Running 10000 simulations.:  33%|███▎      | 3333/10000 [00:11<00:23, 289.69it/s]Running 10000 simulations.:  34%|███▎      | 3362/10000 [00:11<00:23, 288.45it/s]Running 10000 simulations.:  34%|███▍      | 3391/10000 [00:11<00:22, 287.74it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:11<00:22, 287.97it/s]Running 10000 simulations.:  34%|███▍      | 3449/10000 [00:12<00:22, 288.14it/s]Running 10000 simulations.:  35%|███▍      | 3478/10000 [00:12<00:22, 288.64it/s]Running 10000 simulations.:  35%|███▌      | 3507/10000 [00:12<00:22, 287.41it/s]Running 10000 simulations.:  35%|███▌      | 3536/10000 [00:12<00:22, 288.00it/s]Running 10000 simulations.:  36%|███▌      | 3566/10000 [00:12<00:22, 288.66it/s]Running 10000 simulations.:  36%|███▌      | 3595/10000 [00:12<00:22, 288.89it/s]Running 10000 simulations.:  36%|███▋      | 3625/10000 [00:12<00:22, 289.27it/s]Running 10000 simulations.:  37%|███▋      | 3655/10000 [00:12<00:21, 289.76it/s]Running 10000 simulations.:  37%|███▋      | 3684/10000 [00:12<00:21, 288.93it/s]Running 10000 simulations.:  37%|███▋      | 3713/10000 [00:12<00:21, 288.27it/s]Running 10000 simulations.:  37%|███▋      | 3742/10000 [00:13<00:21, 285.41it/s]Running 10000 simulations.:  38%|███▊      | 3771/10000 [00:13<00:22, 280.88it/s]Running 10000 simulations.:  38%|███▊      | 3800/10000 [00:13<00:22, 281.31it/s]Running 10000 simulations.:  38%|███▊      | 3829/10000 [00:13<00:21, 282.15it/s]Running 10000 simulations.:  39%|███▊      | 3858/10000 [00:13<00:21, 281.65it/s]Running 10000 simulations.:  39%|███▉      | 3887/10000 [00:13<00:21, 283.08it/s]Running 10000 simulations.:  39%|███▉      | 3916/10000 [00:13<00:21, 285.00it/s]Running 10000 simulations.:  39%|███▉      | 3945/10000 [00:13<00:21, 284.99it/s]Running 10000 simulations.:  40%|███▉      | 3974/10000 [00:13<00:21, 285.25it/s]Running 10000 simulations.:  40%|████      | 4003/10000 [00:13<00:21, 284.34it/s]Running 10000 simulations.:  40%|████      | 4032/10000 [00:14<00:21, 283.43it/s]Running 10000 simulations.:  41%|████      | 4061/10000 [00:14<00:20, 283.83it/s]Running 10000 simulations.:  41%|████      | 4090/10000 [00:14<00:20, 283.58it/s]Running 10000 simulations.:  41%|████      | 4119/10000 [00:14<00:20, 283.96it/s]Running 10000 simulations.:  41%|████▏     | 4148/10000 [00:14<00:20, 283.91it/s]Running 10000 simulations.:  42%|████▏     | 4177/10000 [00:14<00:20, 282.62it/s]Running 10000 simulations.:  42%|████▏     | 4206/10000 [00:14<00:20, 283.31it/s]Running 10000 simulations.:  42%|████▏     | 4235/10000 [00:14<00:20, 283.58it/s]Running 10000 simulations.:  43%|████▎     | 4264/10000 [00:14<00:20, 283.77it/s]Running 10000 simulations.:  43%|████▎     | 4293/10000 [00:14<00:20, 283.92it/s]Running 10000 simulations.:  43%|████▎     | 4322/10000 [00:15<00:19, 284.70it/s]Running 10000 simulations.:  44%|████▎     | 4351/10000 [00:15<00:19, 285.60it/s]Running 10000 simulations.:  44%|████▍     | 4380/10000 [00:15<00:19, 286.61it/s]Running 10000 simulations.:  44%|████▍     | 4409/10000 [00:15<00:19, 287.40it/s]Running 10000 simulations.:  44%|████▍     | 4439/10000 [00:15<00:19, 288.36it/s]Running 10000 simulations.:  45%|████▍     | 4469/10000 [00:15<00:19, 289.14it/s]Running 10000 simulations.:  45%|████▍     | 4498/10000 [00:15<00:19, 288.48it/s]Running 10000 simulations.:  45%|████▌     | 4527/10000 [00:15<00:19, 287.58it/s]Running 10000 simulations.:  46%|████▌     | 4556/10000 [00:15<00:18, 288.04it/s]Running 10000 simulations.:  46%|████▌     | 4585/10000 [00:15<00:18, 288.38it/s]Running 10000 simulations.:  46%|████▌     | 4615/10000 [00:16<00:18, 288.97it/s]Running 10000 simulations.:  46%|████▋     | 4644/10000 [00:16<00:18, 288.96it/s]Running 10000 simulations.:  47%|████▋     | 4673/10000 [00:16<00:18, 287.80it/s]Running 10000 simulations.:  47%|████▋     | 4702/10000 [00:16<00:18, 287.56it/s]Running 10000 simulations.:  47%|████▋     | 4731/10000 [00:16<00:18, 285.90it/s]Running 10000 simulations.:  48%|████▊     | 4760/10000 [00:16<00:18, 286.20it/s]Running 10000 simulations.:  48%|████▊     | 4790/10000 [00:16<00:18, 287.49it/s]Running 10000 simulations.:  48%|████▊     | 4819/10000 [00:16<00:18, 287.20it/s]Running 10000 simulations.:  48%|████▊     | 4848/10000 [00:16<00:18, 286.08it/s]Running 10000 simulations.:  49%|████▉     | 4877/10000 [00:17<00:18, 278.46it/s]Running 10000 simulations.:  49%|████▉     | 4906/10000 [00:17<00:18, 279.78it/s]Running 10000 simulations.:  49%|████▉     | 4935/10000 [00:17<00:18, 280.81it/s]Running 10000 simulations.:  50%|████▉     | 4964/10000 [00:17<00:17, 282.19it/s]Running 10000 simulations.:  50%|████▉     | 4993/10000 [00:17<00:17, 281.95it/s]Running 10000 simulations.:  50%|█████     | 5022/10000 [00:17<00:17, 281.90it/s]Running 10000 simulations.:  51%|█████     | 5051/10000 [00:17<00:17, 280.80it/s]Running 10000 simulations.:  51%|█████     | 5080/10000 [00:17<00:17, 277.88it/s]Running 10000 simulations.:  51%|█████     | 5109/10000 [00:17<00:17, 279.10it/s]Running 10000 simulations.:  51%|█████▏    | 5138/10000 [00:17<00:17, 280.26it/s]Running 10000 simulations.:  52%|█████▏    | 5167/10000 [00:18<00:17, 280.02it/s]Running 10000 simulations.:  52%|█████▏    | 5196/10000 [00:18<00:17, 280.62it/s]Running 10000 simulations.:  52%|█████▏    | 5225/10000 [00:18<00:16, 281.04it/s]Running 10000 simulations.:  53%|█████▎    | 5254/10000 [00:18<00:16, 281.16it/s]Running 10000 simulations.:  53%|█████▎    | 5283/10000 [00:18<00:16, 281.27it/s]Running 10000 simulations.:  53%|█████▎    | 5312/10000 [00:18<00:16, 281.85it/s]Running 10000 simulations.:  53%|█████▎    | 5341/10000 [00:18<00:16, 281.55it/s]Running 10000 simulations.:  54%|█████▎    | 5370/10000 [00:18<00:16, 282.65it/s]Running 10000 simulations.:  54%|█████▍    | 5399/10000 [00:18<00:16, 282.61it/s]Running 10000 simulations.:  54%|█████▍    | 5428/10000 [00:18<00:16, 282.33it/s]Running 10000 simulations.:  55%|█████▍    | 5457/10000 [00:19<00:16, 282.66it/s]Running 10000 simulations.:  55%|█████▍    | 5486/10000 [00:19<00:15, 282.26it/s]Running 10000 simulations.:  55%|█████▌    | 5515/10000 [00:19<00:15, 282.93it/s]Running 10000 simulations.:  55%|█████▌    | 5544/10000 [00:19<00:15, 282.71it/s]Running 10000 simulations.:  56%|█████▌    | 5573/10000 [00:19<00:15, 283.05it/s]Running 10000 simulations.:  56%|█████▌    | 5602/10000 [00:19<00:15, 284.30it/s]Running 10000 simulations.:  56%|█████▋    | 5631/10000 [00:19<00:15, 284.02it/s]Running 10000 simulations.:  57%|█████▋    | 5660/10000 [00:19<00:15, 283.66it/s]Running 10000 simulations.:  57%|█████▋    | 5689/10000 [00:19<00:15, 283.17it/s]Running 10000 simulations.:  57%|█████▋    | 5718/10000 [00:19<00:15, 283.08it/s]Running 10000 simulations.:  57%|█████▋    | 5747/10000 [00:20<00:15, 283.03it/s]Running 10000 simulations.:  58%|█████▊    | 5776/10000 [00:20<00:14, 283.71it/s]Running 10000 simulations.:  58%|█████▊    | 5805/10000 [00:20<00:14, 283.43it/s]Running 10000 simulations.:  58%|█████▊    | 5834/10000 [00:20<00:14, 283.69it/s]Running 10000 simulations.:  59%|█████▊    | 5863/10000 [00:20<00:14, 283.72it/s]Running 10000 simulations.:  59%|█████▉    | 5892/10000 [00:20<00:14, 284.16it/s]Running 10000 simulations.:  59%|█████▉    | 5921/10000 [00:20<00:14, 284.63it/s]Running 10000 simulations.:  60%|█████▉    | 5950/10000 [00:20<00:14, 284.18it/s]Running 10000 simulations.:  60%|█████▉    | 5979/10000 [00:20<00:14, 283.90it/s]Running 10000 simulations.:  60%|██████    | 6008/10000 [00:21<00:14, 283.72it/s]Running 10000 simulations.:  60%|██████    | 6037/10000 [00:21<00:13, 283.73it/s]Running 10000 simulations.:  61%|██████    | 6066/10000 [00:21<00:13, 283.85it/s]Running 10000 simulations.:  61%|██████    | 6095/10000 [00:21<00:13, 283.56it/s]Running 10000 simulations.:  61%|██████    | 6124/10000 [00:21<00:13, 282.75it/s]Running 10000 simulations.:  62%|██████▏   | 6153/10000 [00:21<00:13, 282.55it/s]Running 10000 simulations.:  62%|██████▏   | 6182/10000 [00:21<00:13, 282.07it/s]Running 10000 simulations.:  62%|██████▏   | 6211/10000 [00:21<00:13, 278.14it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:21<00:13, 279.04it/s]Running 10000 simulations.:  63%|██████▎   | 6269/10000 [00:21<00:13, 280.21it/s]Running 10000 simulations.:  63%|██████▎   | 6298/10000 [00:22<00:13, 279.28it/s]Running 10000 simulations.:  63%|██████▎   | 6327/10000 [00:22<00:13, 279.99it/s]Running 10000 simulations.:  64%|██████▎   | 6356/10000 [00:22<00:13, 280.27it/s]Running 10000 simulations.:  64%|██████▍   | 6385/10000 [00:22<00:12, 280.72it/s]Running 10000 simulations.:  64%|██████▍   | 6414/10000 [00:22<00:12, 281.64it/s]Running 10000 simulations.:  64%|██████▍   | 6443/10000 [00:22<00:12, 281.39it/s]Running 10000 simulations.:  65%|██████▍   | 6472/10000 [00:22<00:12, 281.93it/s]Running 10000 simulations.:  65%|██████▌   | 6501/10000 [00:22<00:12, 282.06it/s]Running 10000 simulations.:  65%|██████▌   | 6530/10000 [00:22<00:12, 282.70it/s]Running 10000 simulations.:  66%|██████▌   | 6559/10000 [00:22<00:12, 283.50it/s]Running 10000 simulations.:  66%|██████▌   | 6588/10000 [00:23<00:12, 283.17it/s]Running 10000 simulations.:  66%|██████▌   | 6617/10000 [00:23<00:11, 283.75it/s]Running 10000 simulations.:  66%|██████▋   | 6646/10000 [00:23<00:11, 283.92it/s]Running 10000 simulations.:  67%|██████▋   | 6675/10000 [00:23<00:11, 284.72it/s]Running 10000 simulations.:  67%|██████▋   | 6704/10000 [00:23<00:11, 285.78it/s]Running 10000 simulations.:  67%|██████▋   | 6733/10000 [00:23<00:11, 286.93it/s]Running 10000 simulations.:  68%|██████▊   | 6762/10000 [00:23<00:11, 286.84it/s]Running 10000 simulations.:  68%|██████▊   | 6791/10000 [00:23<00:11, 287.44it/s]Running 10000 simulations.:  68%|██████▊   | 6820/10000 [00:23<00:11, 288.00it/s]Running 10000 simulations.:  68%|██████▊   | 6849/10000 [00:23<00:10, 288.13it/s]Running 10000 simulations.:  69%|██████▉   | 6879/10000 [00:24<00:10, 288.88it/s]Running 10000 simulations.:  69%|██████▉   | 6908/10000 [00:24<00:10, 288.22it/s]Running 10000 simulations.:  69%|██████▉   | 6937/10000 [00:24<00:10, 288.29it/s]Running 10000 simulations.:  70%|██████▉   | 6966/10000 [00:24<00:10, 287.14it/s]Running 10000 simulations.:  70%|██████▉   | 6995/10000 [00:24<00:10, 287.20it/s]Running 10000 simulations.:  70%|███████   | 7024/10000 [00:24<00:10, 287.61it/s]Running 10000 simulations.:  71%|███████   | 7053/10000 [00:24<00:10, 288.03it/s]Running 10000 simulations.:  71%|███████   | 7082/10000 [00:24<00:10, 287.73it/s]Running 10000 simulations.:  71%|███████   | 7111/10000 [00:24<00:10, 287.43it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:24<00:09, 286.25it/s]Running 10000 simulations.:  72%|███████▏  | 7169/10000 [00:25<00:09, 285.93it/s]Running 10000 simulations.:  72%|███████▏  | 7198/10000 [00:25<00:09, 286.83it/s]Running 10000 simulations.:  72%|███████▏  | 7227/10000 [00:25<00:09, 284.84it/s]Running 10000 simulations.:  73%|███████▎  | 7256/10000 [00:25<00:09, 284.39it/s]Running 10000 simulations.:  73%|███████▎  | 7285/10000 [00:25<00:09, 284.40it/s]Running 10000 simulations.:  73%|███████▎  | 7314/10000 [00:25<00:09, 283.88it/s]Running 10000 simulations.:  73%|███████▎  | 7343/10000 [00:25<00:09, 284.03it/s]Running 10000 simulations.:  74%|███████▎  | 7372/10000 [00:25<00:09, 282.92it/s]Running 10000 simulations.:  74%|███████▍  | 7401/10000 [00:25<00:09, 282.93it/s]Running 10000 simulations.:  74%|███████▍  | 7430/10000 [00:26<00:09, 280.45it/s]Running 10000 simulations.:  75%|███████▍  | 7459/10000 [00:26<00:09, 279.50it/s]Running 10000 simulations.:  75%|███████▍  | 7488/10000 [00:26<00:08, 281.08it/s]Running 10000 simulations.:  75%|███████▌  | 7517/10000 [00:26<00:08, 283.63it/s]Running 10000 simulations.:  75%|███████▌  | 7546/10000 [00:26<00:08, 284.05it/s]Running 10000 simulations.:  76%|███████▌  | 7575/10000 [00:26<00:08, 285.24it/s]Running 10000 simulations.:  76%|███████▌  | 7604/10000 [00:26<00:08, 285.78it/s]Running 10000 simulations.:  76%|███████▋  | 7633/10000 [00:26<00:08, 285.61it/s]Running 10000 simulations.:  77%|███████▋  | 7662/10000 [00:26<00:08, 285.83it/s]Running 10000 simulations.:  77%|███████▋  | 7691/10000 [00:26<00:08, 285.40it/s]Running 10000 simulations.:  77%|███████▋  | 7720/10000 [00:27<00:08, 283.63it/s]Running 10000 simulations.:  77%|███████▋  | 7749/10000 [00:27<00:07, 282.76it/s]Running 10000 simulations.:  78%|███████▊  | 7778/10000 [00:27<00:07, 282.53it/s]Running 10000 simulations.:  78%|███████▊  | 7807/10000 [00:27<00:07, 282.70it/s]Running 10000 simulations.:  78%|███████▊  | 7836/10000 [00:27<00:07, 283.60it/s]Running 10000 simulations.:  79%|███████▊  | 7865/10000 [00:27<00:07, 282.34it/s]Running 10000 simulations.:  79%|███████▉  | 7894/10000 [00:27<00:07, 283.03it/s]Running 10000 simulations.:  79%|███████▉  | 7923/10000 [00:27<00:07, 283.34it/s]Running 10000 simulations.:  80%|███████▉  | 7952/10000 [00:27<00:07, 283.11it/s]Running 10000 simulations.:  80%|███████▉  | 7981/10000 [00:27<00:07, 284.10it/s]Running 10000 simulations.:  80%|████████  | 8010/10000 [00:28<00:06, 284.61it/s]Running 10000 simulations.:  80%|████████  | 8039/10000 [00:28<00:06, 283.67it/s]Running 10000 simulations.:  81%|████████  | 8068/10000 [00:28<00:06, 283.74it/s]Running 10000 simulations.:  81%|████████  | 8097/10000 [00:28<00:06, 283.96it/s]Running 10000 simulations.:  81%|████████▏ | 8126/10000 [00:28<00:06, 283.96it/s]Running 10000 simulations.:  82%|████████▏ | 8155/10000 [00:28<00:06, 284.26it/s]Running 10000 simulations.:  82%|████████▏ | 8184/10000 [00:28<00:06, 282.93it/s]Running 10000 simulations.:  82%|████████▏ | 8213/10000 [00:28<00:06, 282.94it/s]Running 10000 simulations.:  82%|████████▏ | 8242/10000 [00:28<00:06, 282.81it/s]Running 10000 simulations.:  83%|████████▎ | 8271/10000 [00:28<00:06, 283.29it/s]Running 10000 simulations.:  83%|████████▎ | 8300/10000 [00:29<00:06, 282.93it/s]Running 10000 simulations.:  83%|████████▎ | 8329/10000 [00:29<00:05, 281.99it/s]Running 10000 simulations.:  84%|████████▎ | 8358/10000 [00:29<00:05, 282.20it/s]Running 10000 simulations.:  84%|████████▍ | 8387/10000 [00:29<00:05, 282.50it/s]Running 10000 simulations.:  84%|████████▍ | 8416/10000 [00:29<00:05, 283.41it/s]Running 10000 simulations.:  84%|████████▍ | 8445/10000 [00:29<00:05, 284.25it/s]Running 10000 simulations.:  85%|████████▍ | 8474/10000 [00:29<00:05, 284.82it/s]Running 10000 simulations.:  85%|████████▌ | 8503/10000 [00:29<00:05, 285.14it/s]Running 10000 simulations.:  85%|████████▌ | 8532/10000 [00:29<00:05, 284.07it/s]Running 10000 simulations.:  86%|████████▌ | 8561/10000 [00:30<00:05, 283.75it/s]Running 10000 simulations.:  86%|████████▌ | 8590/10000 [00:30<00:04, 284.13it/s]Running 10000 simulations.:  86%|████████▌ | 8619/10000 [00:30<00:04, 284.12it/s]Running 10000 simulations.:  86%|████████▋ | 8648/10000 [00:30<00:04, 283.42it/s]Running 10000 simulations.:  87%|████████▋ | 8677/10000 [00:30<00:04, 283.53it/s]Running 10000 simulations.:  87%|████████▋ | 8706/10000 [00:30<00:04, 281.26it/s]Running 10000 simulations.:  87%|████████▋ | 8735/10000 [00:30<00:04, 279.58it/s]Running 10000 simulations.:  88%|████████▊ | 8764/10000 [00:30<00:04, 282.42it/s]Running 10000 simulations.:  88%|████████▊ | 8794/10000 [00:30<00:04, 284.97it/s]Running 10000 simulations.:  88%|████████▊ | 8823/10000 [00:30<00:04, 285.08it/s]Running 10000 simulations.:  89%|████████▊ | 8852/10000 [00:31<00:04, 286.15it/s]Running 10000 simulations.:  89%|████████▉ | 8881/10000 [00:31<00:03, 287.00it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [00:31<00:03, 285.30it/s]Running 10000 simulations.:  89%|████████▉ | 8939/10000 [00:31<00:03, 284.50it/s]Running 10000 simulations.:  90%|████████▉ | 8968/10000 [00:31<00:03, 283.73it/s]Running 10000 simulations.:  90%|████████▉ | 8997/10000 [00:31<00:03, 282.97it/s]Running 10000 simulations.:  90%|█████████ | 9026/10000 [00:31<00:03, 283.14it/s]Running 10000 simulations.:  91%|█████████ | 9055/10000 [00:31<00:03, 283.42it/s]Running 10000 simulations.:  91%|█████████ | 9084/10000 [00:31<00:03, 283.94it/s]Running 10000 simulations.:  91%|█████████ | 9113/10000 [00:31<00:03, 284.49it/s]Running 10000 simulations.:  91%|█████████▏| 9142/10000 [00:32<00:03, 284.00it/s]Running 10000 simulations.:  92%|█████████▏| 9171/10000 [00:32<00:02, 284.29it/s]Running 10000 simulations.:  92%|█████████▏| 9200/10000 [00:32<00:02, 284.13it/s]Running 10000 simulations.:  92%|█████████▏| 9229/10000 [00:32<00:02, 284.58it/s]Running 10000 simulations.:  93%|█████████▎| 9258/10000 [00:32<00:02, 284.59it/s]Running 10000 simulations.:  93%|█████████▎| 9287/10000 [00:32<00:02, 284.25it/s]Running 10000 simulations.:  93%|█████████▎| 9316/10000 [00:32<00:02, 283.52it/s]Running 10000 simulations.:  93%|█████████▎| 9345/10000 [00:32<00:02, 283.83it/s]Running 10000 simulations.:  94%|█████████▎| 9374/10000 [00:32<00:02, 284.51it/s]Running 10000 simulations.:  94%|█████████▍| 9403/10000 [00:32<00:02, 285.21it/s]Running 10000 simulations.:  94%|█████████▍| 9432/10000 [00:33<00:01, 285.50it/s]Running 10000 simulations.:  95%|█████████▍| 9461/10000 [00:33<00:01, 285.45it/s]Running 10000 simulations.:  95%|█████████▍| 9490/10000 [00:33<00:01, 285.59it/s]Running 10000 simulations.:  95%|█████████▌| 9519/10000 [00:33<00:01, 285.91it/s]Running 10000 simulations.:  95%|█████████▌| 9548/10000 [00:33<00:01, 285.64it/s]Running 10000 simulations.:  96%|█████████▌| 9577/10000 [00:33<00:01, 286.35it/s]Running 10000 simulations.:  96%|█████████▌| 9606/10000 [00:33<00:01, 285.14it/s]Running 10000 simulations.:  96%|█████████▋| 9635/10000 [00:33<00:01, 285.18it/s]Running 10000 simulations.:  97%|█████████▋| 9664/10000 [00:33<00:01, 284.61it/s]Running 10000 simulations.:  97%|█████████▋| 9693/10000 [00:33<00:01, 284.12it/s]Running 10000 simulations.:  97%|█████████▋| 9722/10000 [00:34<00:00, 284.50it/s]Running 10000 simulations.:  98%|█████████▊| 9751/10000 [00:34<00:00, 285.30it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [00:34<00:00, 285.05it/s]Running 10000 simulations.:  98%|█████████▊| 9809/10000 [00:34<00:00, 285.55it/s]Running 10000 simulations.:  98%|█████████▊| 9838/10000 [00:34<00:00, 284.56it/s]Running 10000 simulations.:  99%|█████████▊| 9867/10000 [00:34<00:00, 284.86it/s]Running 10000 simulations.:  99%|█████████▉| 9896/10000 [00:34<00:00, 285.76it/s]Running 10000 simulations.:  99%|█████████▉| 9925/10000 [00:34<00:00, 285.26it/s]Running 10000 simulations.: 100%|█████████▉| 9954/10000 [00:34<00:00, 285.69it/s]Running 10000 simulations.: 100%|█████████▉| 9983/10000 [00:35<00:00, 285.42it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:35<00:00, 285.20it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<00:33, 295.77it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<00:33, 295.86it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<00:33, 295.00it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<00:33, 294.02it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:33, 293.20it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:00<00:33, 293.88it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:00<00:33, 295.13it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:00<00:32, 295.96it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:00<00:32, 295.02it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:01<00:32, 295.57it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:01<00:32, 295.88it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:01<00:32, 295.41it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:32, 294.27it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:32, 294.08it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:01<00:32, 293.47it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:01<00:32, 293.02it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:01<00:32, 292.92it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:01<00:32, 293.03it/s]Running 10000 simulations.:   6%|▌         | 570/10000 [00:01<00:32, 292.74it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:02<00:32, 293.08it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:02<00:31, 294.53it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:02<00:31, 295.17it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:02<00:31, 295.68it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:02<00:31, 295.80it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:02<00:31, 296.37it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:02<00:31, 296.35it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:02<00:31, 294.93it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:02<00:31, 294.05it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:02<00:31, 293.38it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:31, 292.75it/s]Running 10000 simulations.:   9%|▉         | 930/10000 [00:03<00:30, 292.80it/s]Running 10000 simulations.:  10%|▉         | 960/10000 [00:03<00:30, 294.50it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:03<00:30, 295.94it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:03<00:30, 296.90it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:03<00:30, 297.08it/s]Running 10000 simulations.:  11%|█         | 1080/10000 [00:03<00:29, 297.44it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:03<00:29, 297.77it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:03<00:29, 298.05it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:03<00:29, 298.34it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:29, 298.65it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:04<00:29, 298.49it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:04<00:29, 297.60it/s]Running 10000 simulations.:  13%|█▎        | 1290/10000 [00:04<00:29, 296.77it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:04<00:29, 295.15it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:04<00:29, 294.16it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:04<00:29, 293.69it/s]Running 10000 simulations.:  14%|█▍        | 1410/10000 [00:04<00:29, 293.39it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:04<00:29, 293.51it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:04<00:29, 292.96it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:05<00:29, 292.70it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:05<00:28, 292.92it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:05<00:28, 292.45it/s]Running 10000 simulations.:  16%|█▌        | 1590/10000 [00:05<00:28, 292.23it/s]Running 10000 simulations.:  16%|█▌        | 1620/10000 [00:05<00:28, 292.14it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:05<00:28, 292.09it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:05<00:28, 291.91it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:05<00:28, 292.19it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:05<00:28, 292.26it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:06<00:28, 292.44it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:06<00:28, 292.77it/s]Running 10000 simulations.:  18%|█▊        | 1830/10000 [00:06<00:27, 293.39it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:06<00:28, 286.57it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:06<00:28, 289.39it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:06<00:27, 291.89it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:06<00:27, 292.20it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:06<00:27, 292.60it/s]Running 10000 simulations.:  20%|██        | 2010/10000 [00:06<00:27, 292.07it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:06<00:27, 292.33it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:07<00:27, 293.15it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:07<00:26, 293.19it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:07<00:26, 293.46it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:07<00:26, 293.81it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:07<00:26, 294.52it/s]Running 10000 simulations.:  22%|██▏       | 2220/10000 [00:07<00:26, 294.90it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:07<00:26, 295.40it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:07<00:26, 296.37it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:07<00:25, 297.18it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:07<00:25, 296.89it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:08<00:25, 295.51it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:08<00:25, 294.85it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:08<00:25, 294.39it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:08<00:25, 293.73it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:08<00:25, 293.31it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:08<00:25, 292.91it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:08<00:25, 292.71it/s]Running 10000 simulations.:  26%|██▌       | 2580/10000 [00:08<00:25, 292.62it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:08<00:25, 292.58it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:08<00:25, 292.36it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:09<00:24, 293.63it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:09<00:29, 250.68it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:09<00:27, 261.82it/s]Running 10000 simulations.:  28%|██▊       | 2760/10000 [00:09<00:26, 270.67it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:09<00:26, 277.20it/s]Running 10000 simulations.:  28%|██▊       | 2820/10000 [00:09<00:25, 281.69it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:09<00:25, 285.43it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:09<00:24, 287.96it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:09<00:24, 289.62it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:10<00:24, 290.98it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:10<00:24, 291.90it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:10<00:23, 292.30it/s]Running 10000 simulations.:  30%|███       | 3030/10000 [00:10<00:23, 292.63it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:10<00:23, 292.43it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:10<00:23, 292.58it/s]Running 10000 simulations.:  31%|███       | 3120/10000 [00:10<00:23, 292.56it/s]Running 10000 simulations.:  32%|███▏      | 3150/10000 [00:10<00:23, 292.46it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:10<00:23, 292.40it/s]Running 10000 simulations.:  32%|███▏      | 3210/10000 [00:10<00:23, 292.43it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:11<00:23, 292.72it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:11<00:23, 292.54it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:11<00:22, 292.03it/s]Running 10000 simulations.:  33%|███▎      | 3330/10000 [00:11<00:22, 291.84it/s]Running 10000 simulations.:  34%|███▎      | 3360/10000 [00:11<00:22, 291.89it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:11<00:22, 292.27it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:11<00:22, 292.89it/s]Running 10000 simulations.:  34%|███▍      | 3450/10000 [00:11<00:22, 293.78it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:11<00:22, 294.87it/s]Running 10000 simulations.:  35%|███▌      | 3510/10000 [00:11<00:21, 295.62it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:12<00:21, 296.41it/s]Running 10000 simulations.:  36%|███▌      | 3570/10000 [00:12<00:21, 296.83it/s]Running 10000 simulations.:  36%|███▌      | 3600/10000 [00:12<00:21, 295.82it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:12<00:21, 294.84it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:12<00:21, 293.75it/s]Running 10000 simulations.:  37%|███▋      | 3690/10000 [00:12<00:21, 294.06it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:12<00:21, 294.07it/s]Running 10000 simulations.:  38%|███▊      | 3750/10000 [00:12<00:21, 294.52it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:12<00:21, 294.69it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:13<00:21, 294.27it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:13<00:20, 293.84it/s]Running 10000 simulations.:  39%|███▊      | 3870/10000 [00:13<00:20, 293.33it/s]Running 10000 simulations.:  39%|███▉      | 3900/10000 [00:13<00:20, 293.74it/s]Running 10000 simulations.:  39%|███▉      | 3930/10000 [00:13<00:20, 293.32it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:13<00:20, 293.34it/s]Running 10000 simulations.:  40%|███▉      | 3990/10000 [00:13<00:20, 293.31it/s]Running 10000 simulations.:  40%|████      | 4020/10000 [00:13<00:20, 293.25it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:13<00:20, 293.00it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:13<00:20, 292.90it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:14<00:20, 292.97it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:14<00:19, 293.17it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:14<00:19, 292.89it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:14<00:19, 293.26it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:14<00:19, 293.33it/s]Running 10000 simulations.:  43%|████▎     | 4260/10000 [00:14<00:19, 293.13it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:14<00:19, 293.96it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:14<00:19, 295.29it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:14<00:19, 295.11it/s]Running 10000 simulations.:  44%|████▍     | 4380/10000 [00:14<00:18, 296.28it/s]Running 10000 simulations.:  44%|████▍     | 4410/10000 [00:15<00:18, 296.85it/s]Running 10000 simulations.:  44%|████▍     | 4440/10000 [00:15<00:18, 297.19it/s]Running 10000 simulations.:  45%|████▍     | 4470/10000 [00:15<00:18, 297.44it/s]Running 10000 simulations.:  45%|████▌     | 4500/10000 [00:15<00:18, 296.75it/s]Running 10000 simulations.:  45%|████▌     | 4530/10000 [00:15<00:18, 295.00it/s]Running 10000 simulations.:  46%|████▌     | 4560/10000 [00:15<00:18, 293.81it/s]Running 10000 simulations.:  46%|████▌     | 4590/10000 [00:15<00:18, 294.08it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:15<00:18, 294.74it/s]Running 10000 simulations.:  46%|████▋     | 4650/10000 [00:15<00:18, 295.80it/s]Running 10000 simulations.:  47%|████▋     | 4680/10000 [00:15<00:18, 294.92it/s]Running 10000 simulations.:  47%|████▋     | 4710/10000 [00:16<00:17, 293.91it/s]Running 10000 simulations.:  47%|████▋     | 4740/10000 [00:16<00:17, 293.44it/s]Running 10000 simulations.:  48%|████▊     | 4770/10000 [00:16<00:17, 293.65it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:16<00:17, 293.93it/s]Running 10000 simulations.:  48%|████▊     | 4830/10000 [00:16<00:17, 295.23it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:16<00:17, 296.49it/s]Running 10000 simulations.:  49%|████▉     | 4890/10000 [00:16<00:17, 295.85it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:16<00:17, 295.19it/s]Running 10000 simulations.:  50%|████▉     | 4950/10000 [00:16<00:17, 294.12it/s]Running 10000 simulations.:  50%|████▉     | 4980/10000 [00:16<00:17, 293.43it/s]Running 10000 simulations.:  50%|█████     | 5010/10000 [00:17<00:16, 293.64it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:17<00:16, 293.82it/s]Running 10000 simulations.:  51%|█████     | 5070/10000 [00:17<00:16, 293.81it/s]Running 10000 simulations.:  51%|█████     | 5100/10000 [00:17<00:16, 294.24it/s]Running 10000 simulations.:  51%|█████▏    | 5130/10000 [00:17<00:16, 295.26it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:17<00:16, 294.62it/s]Running 10000 simulations.:  52%|█████▏    | 5190/10000 [00:17<00:16, 295.48it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:17<00:16, 296.51it/s]Running 10000 simulations.:  52%|█████▎    | 5250/10000 [00:17<00:15, 297.16it/s]Running 10000 simulations.:  53%|█████▎    | 5280/10000 [00:18<00:15, 297.61it/s]Running 10000 simulations.:  53%|█████▎    | 5310/10000 [00:18<00:15, 296.00it/s]Running 10000 simulations.:  53%|█████▎    | 5340/10000 [00:18<00:15, 294.98it/s]Running 10000 simulations.:  54%|█████▎    | 5370/10000 [00:18<00:15, 295.20it/s]Running 10000 simulations.:  54%|█████▍    | 5400/10000 [00:18<00:15, 294.43it/s]Running 10000 simulations.:  54%|█████▍    | 5430/10000 [00:18<00:15, 293.79it/s]Running 10000 simulations.:  55%|█████▍    | 5460/10000 [00:18<00:15, 293.55it/s]Running 10000 simulations.:  55%|█████▍    | 5490/10000 [00:18<00:15, 293.33it/s]Running 10000 simulations.:  55%|█████▌    | 5520/10000 [00:18<00:15, 293.19it/s]Running 10000 simulations.:  56%|█████▌    | 5550/10000 [00:18<00:15, 292.97it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:19<00:15, 292.67it/s]Running 10000 simulations.:  56%|█████▌    | 5610/10000 [00:19<00:15, 292.51it/s]Running 10000 simulations.:  56%|█████▋    | 5640/10000 [00:19<00:14, 292.65it/s]Running 10000 simulations.:  57%|█████▋    | 5670/10000 [00:19<00:14, 293.16it/s]Running 10000 simulations.:  57%|█████▋    | 5700/10000 [00:19<00:14, 292.95it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:19<00:14, 292.09it/s]Running 10000 simulations.:  58%|█████▊    | 5760/10000 [00:19<00:14, 291.81it/s]Running 10000 simulations.:  58%|█████▊    | 5790/10000 [00:19<00:14, 292.05it/s]Running 10000 simulations.:  58%|█████▊    | 5820/10000 [00:19<00:14, 292.18it/s]Running 10000 simulations.:  58%|█████▊    | 5850/10000 [00:19<00:14, 292.42it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:20<00:14, 292.77it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:20<00:13, 294.12it/s]Running 10000 simulations.:  59%|█████▉    | 5940/10000 [00:20<00:13, 294.03it/s]Running 10000 simulations.:  60%|█████▉    | 5970/10000 [00:20<00:13, 294.36it/s]Running 10000 simulations.:  60%|██████    | 6000/10000 [00:20<00:13, 293.73it/s]Running 10000 simulations.:  60%|██████    | 6030/10000 [00:20<00:13, 293.40it/s]Running 10000 simulations.:  61%|██████    | 6060/10000 [00:20<00:13, 293.11it/s]Running 10000 simulations.:  61%|██████    | 6090/10000 [00:20<00:13, 293.40it/s]Running 10000 simulations.:  61%|██████    | 6120/10000 [00:20<00:13, 294.35it/s]Running 10000 simulations.:  62%|██████▏   | 6150/10000 [00:20<00:13, 295.24it/s]Running 10000 simulations.:  62%|██████▏   | 6180/10000 [00:21<00:12, 296.26it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:21<00:12, 296.18it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:21<00:12, 295.20it/s]Running 10000 simulations.:  63%|██████▎   | 6270/10000 [00:21<00:12, 295.98it/s]Running 10000 simulations.:  63%|██████▎   | 6300/10000 [00:21<00:12, 296.64it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:21<00:12, 296.38it/s]Running 10000 simulations.:  64%|██████▎   | 6360/10000 [00:21<00:12, 296.57it/s]Running 10000 simulations.:  64%|██████▍   | 6390/10000 [00:21<00:12, 297.29it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:21<00:12, 297.65it/s]Running 10000 simulations.:  64%|██████▍   | 6450/10000 [00:21<00:11, 296.50it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:22<00:11, 295.28it/s]Running 10000 simulations.:  65%|██████▌   | 6510/10000 [00:22<00:11, 294.50it/s]Running 10000 simulations.:  65%|██████▌   | 6540/10000 [00:22<00:11, 293.95it/s]Running 10000 simulations.:  66%|██████▌   | 6570/10000 [00:22<00:11, 293.49it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:22<00:11, 293.38it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:22<00:11, 293.19it/s]Running 10000 simulations.:  67%|██████▋   | 6660/10000 [00:22<00:11, 293.99it/s]Running 10000 simulations.:  67%|██████▋   | 6690/10000 [00:22<00:11, 294.60it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:22<00:11, 295.34it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:23<00:10, 295.68it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:23<00:10, 295.66it/s]Running 10000 simulations.:  68%|██████▊   | 6810/10000 [00:23<00:10, 296.52it/s]Running 10000 simulations.:  68%|██████▊   | 6840/10000 [00:23<00:10, 296.88it/s]Running 10000 simulations.:  69%|██████▊   | 6870/10000 [00:23<00:10, 296.45it/s]Running 10000 simulations.:  69%|██████▉   | 6900/10000 [00:23<00:10, 297.27it/s]Running 10000 simulations.:  69%|██████▉   | 6930/10000 [00:23<00:10, 297.92it/s]Running 10000 simulations.:  70%|██████▉   | 6960/10000 [00:23<00:10, 297.90it/s]Running 10000 simulations.:  70%|██████▉   | 6990/10000 [00:23<00:10, 297.05it/s]Running 10000 simulations.:  70%|███████   | 7020/10000 [00:23<00:10, 295.87it/s]Running 10000 simulations.:  70%|███████   | 7050/10000 [00:24<00:09, 295.05it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:24<00:09, 295.66it/s]Running 10000 simulations.:  71%|███████   | 7110/10000 [00:24<00:09, 295.79it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:24<00:09, 296.19it/s]Running 10000 simulations.:  72%|███████▏  | 7170/10000 [00:24<00:09, 295.51it/s]Running 10000 simulations.:  72%|███████▏  | 7200/10000 [00:24<00:09, 294.76it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:24<00:09, 293.97it/s]Running 10000 simulations.:  73%|███████▎  | 7260/10000 [00:24<00:09, 293.25it/s]Running 10000 simulations.:  73%|███████▎  | 7290/10000 [00:24<00:09, 294.13it/s]Running 10000 simulations.:  73%|███████▎  | 7320/10000 [00:24<00:09, 295.26it/s]Running 10000 simulations.:  74%|███████▎  | 7350/10000 [00:25<00:08, 295.81it/s]Running 10000 simulations.:  74%|███████▍  | 7380/10000 [00:25<00:08, 295.97it/s]Running 10000 simulations.:  74%|███████▍  | 7410/10000 [00:25<00:08, 296.59it/s]Running 10000 simulations.:  74%|███████▍  | 7440/10000 [00:25<00:08, 296.78it/s]Running 10000 simulations.:  75%|███████▍  | 7470/10000 [00:25<00:08, 296.58it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:25<00:08, 295.84it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:25<00:08, 296.43it/s]Running 10000 simulations.:  76%|███████▌  | 7560/10000 [00:25<00:08, 296.83it/s]Running 10000 simulations.:  76%|███████▌  | 7590/10000 [00:25<00:08, 297.12it/s]Running 10000 simulations.:  76%|███████▌  | 7620/10000 [00:25<00:07, 297.58it/s]Running 10000 simulations.:  76%|███████▋  | 7650/10000 [00:26<00:07, 297.79it/s]Running 10000 simulations.:  77%|███████▋  | 7680/10000 [00:26<00:07, 297.94it/s]Running 10000 simulations.:  77%|███████▋  | 7710/10000 [00:26<00:07, 297.51it/s]Running 10000 simulations.:  77%|███████▋  | 7740/10000 [00:26<00:07, 296.00it/s]Running 10000 simulations.:  78%|███████▊  | 7770/10000 [00:26<00:07, 295.33it/s]Running 10000 simulations.:  78%|███████▊  | 7800/10000 [00:26<00:07, 295.66it/s]Running 10000 simulations.:  78%|███████▊  | 7830/10000 [00:26<00:07, 296.33it/s]Running 10000 simulations.:  79%|███████▊  | 7860/10000 [00:26<00:07, 296.46it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:26<00:07, 297.06it/s]Running 10000 simulations.:  79%|███████▉  | 7920/10000 [00:26<00:06, 297.34it/s]Running 10000 simulations.:  80%|███████▉  | 7950/10000 [00:27<00:06, 296.24it/s]Running 10000 simulations.:  80%|███████▉  | 7980/10000 [00:27<00:06, 295.10it/s]Running 10000 simulations.:  80%|████████  | 8010/10000 [00:27<00:06, 294.81it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:27<00:06, 294.57it/s]Running 10000 simulations.:  81%|████████  | 8070/10000 [00:27<00:06, 294.05it/s]Running 10000 simulations.:  81%|████████  | 8100/10000 [00:27<00:06, 293.63it/s]Running 10000 simulations.:  81%|████████▏ | 8130/10000 [00:27<00:06, 293.13it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:27<00:06, 293.61it/s]Running 10000 simulations.:  82%|████████▏ | 8190/10000 [00:27<00:06, 293.95it/s]Running 10000 simulations.:  82%|████████▏ | 8220/10000 [00:27<00:06, 293.85it/s]Running 10000 simulations.:  82%|████████▎ | 8250/10000 [00:28<00:05, 294.38it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:28<00:05, 294.68it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:28<00:05, 293.72it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:28<00:05, 293.66it/s]Running 10000 simulations.:  84%|████████▎ | 8370/10000 [00:28<00:05, 293.18it/s]Running 10000 simulations.:  84%|████████▍ | 8400/10000 [00:28<00:05, 292.81it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:28<00:05, 292.67it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:28<00:05, 292.64it/s]Running 10000 simulations.:  85%|████████▍ | 8490/10000 [00:28<00:05, 292.67it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:28<00:05, 292.56it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:29<00:04, 292.93it/s]Running 10000 simulations.:  86%|████████▌ | 8580/10000 [00:29<00:04, 293.18it/s]Running 10000 simulations.:  86%|████████▌ | 8610/10000 [00:29<00:04, 293.47it/s]Running 10000 simulations.:  86%|████████▋ | 8640/10000 [00:29<00:04, 293.70it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [00:29<00:04, 294.63it/s]Running 10000 simulations.:  87%|████████▋ | 8700/10000 [00:29<00:04, 295.85it/s]Running 10000 simulations.:  87%|████████▋ | 8730/10000 [00:29<00:04, 296.39it/s]Running 10000 simulations.:  88%|████████▊ | 8760/10000 [00:29<00:04, 297.27it/s]Running 10000 simulations.:  88%|████████▊ | 8790/10000 [00:29<00:04, 297.76it/s]Running 10000 simulations.:  88%|████████▊ | 8820/10000 [00:30<00:03, 298.00it/s]Running 10000 simulations.:  88%|████████▊ | 8850/10000 [00:30<00:03, 297.99it/s]Running 10000 simulations.:  89%|████████▉ | 8880/10000 [00:30<00:03, 297.24it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [00:30<00:03, 297.23it/s]Running 10000 simulations.:  89%|████████▉ | 8940/10000 [00:30<00:03, 297.65it/s]Running 10000 simulations.:  90%|████████▉ | 8970/10000 [00:30<00:03, 298.11it/s]Running 10000 simulations.:  90%|█████████ | 9000/10000 [00:30<00:03, 298.45it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:30<00:03, 298.74it/s]Running 10000 simulations.:  91%|█████████ | 9060/10000 [00:30<00:03, 297.78it/s]Running 10000 simulations.:  91%|█████████ | 9090/10000 [00:30<00:03, 296.33it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:31<00:02, 296.42it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [00:31<00:02, 296.80it/s]Running 10000 simulations.:  92%|█████████▏| 9180/10000 [00:31<00:02, 296.70it/s]Running 10000 simulations.:  92%|█████████▏| 9210/10000 [00:31<00:02, 296.19it/s]Running 10000 simulations.:  92%|█████████▏| 9240/10000 [00:31<00:02, 296.26it/s]Running 10000 simulations.:  93%|█████████▎| 9270/10000 [00:31<00:02, 295.66it/s]Running 10000 simulations.:  93%|█████████▎| 9300/10000 [00:31<00:02, 295.22it/s]Running 10000 simulations.:  93%|█████████▎| 9330/10000 [00:31<00:02, 294.92it/s]Running 10000 simulations.:  94%|█████████▎| 9360/10000 [00:31<00:02, 296.05it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:31<00:02, 296.50it/s]Running 10000 simulations.:  94%|█████████▍| 9420/10000 [00:32<00:01, 296.83it/s]Running 10000 simulations.:  94%|█████████▍| 9450/10000 [00:32<00:01, 297.20it/s]Running 10000 simulations.:  95%|█████████▍| 9480/10000 [00:32<00:01, 296.93it/s]Running 10000 simulations.:  95%|█████████▌| 9510/10000 [00:32<00:01, 295.86it/s]Running 10000 simulations.:  95%|█████████▌| 9540/10000 [00:32<00:01, 294.82it/s]Running 10000 simulations.:  96%|█████████▌| 9570/10000 [00:32<00:01, 294.25it/s]Running 10000 simulations.:  96%|█████████▌| 9600/10000 [00:32<00:01, 293.70it/s]Running 10000 simulations.:  96%|█████████▋| 9630/10000 [00:32<00:01, 293.53it/s]Running 10000 simulations.:  97%|█████████▋| 9660/10000 [00:32<00:01, 293.17it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [00:32<00:01, 293.43it/s]Running 10000 simulations.:  97%|█████████▋| 9720/10000 [00:33<00:00, 293.83it/s]Running 10000 simulations.:  98%|█████████▊| 9750/10000 [00:33<00:00, 294.40it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [00:33<00:00, 293.83it/s]Running 10000 simulations.:  98%|█████████▊| 9810/10000 [00:33<00:00, 293.49it/s]Running 10000 simulations.:  98%|█████████▊| 9840/10000 [00:33<00:00, 293.76it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [00:33<00:00, 293.93it/s]Running 10000 simulations.:  99%|█████████▉| 9900/10000 [00:33<00:00, 294.01it/s]Running 10000 simulations.:  99%|█████████▉| 9930/10000 [00:33<00:00, 293.85it/s]Running 10000 simulations.: 100%|█████████▉| 9960/10000 [00:33<00:00, 294.06it/s]Running 10000 simulations.: 100%|█████████▉| 9990/10000 [00:33<00:00, 294.18it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:34<00:00, 294.09it/s]
Running 10000 simulations.:   0%|          | 0/10000 [00:00<?, ?it/s]Running 10000 simulations.:   0%|          | 30/10000 [00:00<00:33, 296.99it/s]Running 10000 simulations.:   1%|          | 60/10000 [00:00<00:33, 296.26it/s]Running 10000 simulations.:   1%|          | 90/10000 [00:00<00:33, 294.92it/s]Running 10000 simulations.:   1%|          | 120/10000 [00:00<00:33, 293.72it/s]Running 10000 simulations.:   2%|▏         | 150/10000 [00:00<00:33, 293.46it/s]Running 10000 simulations.:   2%|▏         | 180/10000 [00:00<00:33, 293.65it/s]Running 10000 simulations.:   2%|▏         | 210/10000 [00:00<00:33, 293.55it/s]Running 10000 simulations.:   2%|▏         | 240/10000 [00:00<00:33, 293.67it/s]Running 10000 simulations.:   3%|▎         | 270/10000 [00:00<00:33, 293.72it/s]Running 10000 simulations.:   3%|▎         | 300/10000 [00:01<00:33, 292.91it/s]Running 10000 simulations.:   3%|▎         | 330/10000 [00:01<00:33, 292.69it/s]Running 10000 simulations.:   4%|▎         | 360/10000 [00:01<00:32, 292.40it/s]Running 10000 simulations.:   4%|▍         | 390/10000 [00:01<00:32, 292.91it/s]Running 10000 simulations.:   4%|▍         | 420/10000 [00:01<00:32, 294.44it/s]Running 10000 simulations.:   4%|▍         | 450/10000 [00:01<00:32, 295.32it/s]Running 10000 simulations.:   5%|▍         | 480/10000 [00:01<00:32, 294.05it/s]Running 10000 simulations.:   5%|▌         | 510/10000 [00:01<00:32, 293.82it/s]Running 10000 simulations.:   5%|▌         | 540/10000 [00:01<00:32, 293.15it/s]Running 10000 simulations.:   6%|▌         | 570/10000 [00:01<00:32, 292.93it/s]Running 10000 simulations.:   6%|▌         | 600/10000 [00:02<00:32, 292.63it/s]Running 10000 simulations.:   6%|▋         | 630/10000 [00:02<00:32, 292.03it/s]Running 10000 simulations.:   7%|▋         | 660/10000 [00:02<00:32, 291.87it/s]Running 10000 simulations.:   7%|▋         | 690/10000 [00:02<00:31, 291.43it/s]Running 10000 simulations.:   7%|▋         | 720/10000 [00:02<00:31, 292.02it/s]Running 10000 simulations.:   8%|▊         | 750/10000 [00:02<00:31, 291.75it/s]Running 10000 simulations.:   8%|▊         | 780/10000 [00:02<00:31, 292.05it/s]Running 10000 simulations.:   8%|▊         | 810/10000 [00:02<00:31, 292.33it/s]Running 10000 simulations.:   8%|▊         | 840/10000 [00:02<00:31, 293.00it/s]Running 10000 simulations.:   9%|▊         | 870/10000 [00:02<00:31, 292.77it/s]Running 10000 simulations.:   9%|▉         | 900/10000 [00:03<00:31, 292.68it/s]Running 10000 simulations.:   9%|▉         | 930/10000 [00:03<00:30, 292.62it/s]Running 10000 simulations.:  10%|▉         | 960/10000 [00:03<00:30, 292.14it/s]Running 10000 simulations.:  10%|▉         | 990/10000 [00:03<00:30, 292.22it/s]Running 10000 simulations.:  10%|█         | 1020/10000 [00:03<00:30, 292.50it/s]Running 10000 simulations.:  10%|█         | 1050/10000 [00:03<00:30, 292.26it/s]Running 10000 simulations.:  11%|█         | 1080/10000 [00:03<00:30, 292.19it/s]Running 10000 simulations.:  11%|█         | 1110/10000 [00:03<00:30, 292.49it/s]Running 10000 simulations.:  11%|█▏        | 1140/10000 [00:03<00:30, 292.82it/s]Running 10000 simulations.:  12%|█▏        | 1170/10000 [00:03<00:30, 293.61it/s]Running 10000 simulations.:  12%|█▏        | 1200/10000 [00:04<00:29, 295.13it/s]Running 10000 simulations.:  12%|█▏        | 1230/10000 [00:04<00:29, 296.30it/s]Running 10000 simulations.:  13%|█▎        | 1260/10000 [00:04<00:29, 296.86it/s]Running 10000 simulations.:  13%|█▎        | 1290/10000 [00:04<00:29, 297.08it/s]Running 10000 simulations.:  13%|█▎        | 1320/10000 [00:04<00:29, 297.38it/s]Running 10000 simulations.:  14%|█▎        | 1350/10000 [00:04<00:29, 296.96it/s]Running 10000 simulations.:  14%|█▍        | 1380/10000 [00:04<00:29, 295.89it/s]Running 10000 simulations.:  14%|█▍        | 1410/10000 [00:04<00:29, 295.70it/s]Running 10000 simulations.:  14%|█▍        | 1440/10000 [00:04<00:28, 295.59it/s]Running 10000 simulations.:  15%|█▍        | 1470/10000 [00:05<00:28, 295.02it/s]Running 10000 simulations.:  15%|█▌        | 1500/10000 [00:05<00:28, 294.07it/s]Running 10000 simulations.:  15%|█▌        | 1530/10000 [00:05<00:28, 293.44it/s]Running 10000 simulations.:  16%|█▌        | 1560/10000 [00:05<00:28, 293.23it/s]Running 10000 simulations.:  16%|█▌        | 1590/10000 [00:05<00:28, 294.26it/s]Running 10000 simulations.:  16%|█▌        | 1620/10000 [00:05<00:28, 294.82it/s]Running 10000 simulations.:  16%|█▋        | 1650/10000 [00:05<00:28, 294.85it/s]Running 10000 simulations.:  17%|█▋        | 1680/10000 [00:05<00:28, 295.62it/s]Running 10000 simulations.:  17%|█▋        | 1710/10000 [00:05<00:27, 296.67it/s]Running 10000 simulations.:  17%|█▋        | 1740/10000 [00:05<00:27, 297.36it/s]Running 10000 simulations.:  18%|█▊        | 1770/10000 [00:06<00:27, 297.49it/s]Running 10000 simulations.:  18%|█▊        | 1800/10000 [00:06<00:27, 297.77it/s]Running 10000 simulations.:  18%|█▊        | 1830/10000 [00:06<00:27, 297.73it/s]Running 10000 simulations.:  19%|█▊        | 1860/10000 [00:06<00:27, 297.69it/s]Running 10000 simulations.:  19%|█▉        | 1890/10000 [00:06<00:27, 297.78it/s]Running 10000 simulations.:  19%|█▉        | 1920/10000 [00:06<00:27, 297.61it/s]Running 10000 simulations.:  20%|█▉        | 1950/10000 [00:06<00:27, 297.43it/s]Running 10000 simulations.:  20%|█▉        | 1980/10000 [00:06<00:26, 297.45it/s]Running 10000 simulations.:  20%|██        | 2010/10000 [00:06<00:26, 297.41it/s]Running 10000 simulations.:  20%|██        | 2040/10000 [00:06<00:26, 297.84it/s]Running 10000 simulations.:  21%|██        | 2070/10000 [00:07<00:26, 297.94it/s]Running 10000 simulations.:  21%|██        | 2100/10000 [00:07<00:26, 298.01it/s]Running 10000 simulations.:  21%|██▏       | 2130/10000 [00:07<00:26, 298.05it/s]Running 10000 simulations.:  22%|██▏       | 2160/10000 [00:07<00:26, 298.10it/s]Running 10000 simulations.:  22%|██▏       | 2190/10000 [00:07<00:26, 298.16it/s]Running 10000 simulations.:  22%|██▏       | 2220/10000 [00:07<00:26, 298.07it/s]Running 10000 simulations.:  22%|██▎       | 2250/10000 [00:07<00:26, 297.17it/s]Running 10000 simulations.:  23%|██▎       | 2280/10000 [00:07<00:26, 295.81it/s]Running 10000 simulations.:  23%|██▎       | 2310/10000 [00:07<00:26, 294.85it/s]Running 10000 simulations.:  23%|██▎       | 2340/10000 [00:07<00:26, 294.37it/s]Running 10000 simulations.:  24%|██▎       | 2370/10000 [00:08<00:25, 294.50it/s]Running 10000 simulations.:  24%|██▍       | 2400/10000 [00:08<00:25, 295.20it/s]Running 10000 simulations.:  24%|██▍       | 2430/10000 [00:08<00:25, 295.28it/s]Running 10000 simulations.:  25%|██▍       | 2460/10000 [00:08<00:25, 295.40it/s]Running 10000 simulations.:  25%|██▍       | 2490/10000 [00:08<00:25, 295.19it/s]Running 10000 simulations.:  25%|██▌       | 2520/10000 [00:08<00:25, 295.43it/s]Running 10000 simulations.:  26%|██▌       | 2550/10000 [00:08<00:25, 294.83it/s]Running 10000 simulations.:  26%|██▌       | 2580/10000 [00:08<00:25, 294.73it/s]Running 10000 simulations.:  26%|██▌       | 2610/10000 [00:08<00:25, 294.87it/s]Running 10000 simulations.:  26%|██▋       | 2640/10000 [00:08<00:24, 294.61it/s]Running 10000 simulations.:  27%|██▋       | 2670/10000 [00:09<00:24, 295.19it/s]Running 10000 simulations.:  27%|██▋       | 2700/10000 [00:09<00:24, 294.70it/s]Running 10000 simulations.:  27%|██▋       | 2730/10000 [00:09<00:24, 293.73it/s]Running 10000 simulations.:  28%|██▊       | 2760/10000 [00:09<00:24, 293.71it/s]Running 10000 simulations.:  28%|██▊       | 2790/10000 [00:09<00:24, 293.53it/s]Running 10000 simulations.:  28%|██▊       | 2820/10000 [00:09<00:24, 293.45it/s]Running 10000 simulations.:  28%|██▊       | 2850/10000 [00:09<00:24, 293.00it/s]Running 10000 simulations.:  29%|██▉       | 2880/10000 [00:09<00:24, 292.89it/s]Running 10000 simulations.:  29%|██▉       | 2910/10000 [00:09<00:24, 293.47it/s]Running 10000 simulations.:  29%|██▉       | 2940/10000 [00:09<00:23, 294.38it/s]Running 10000 simulations.:  30%|██▉       | 2970/10000 [00:10<00:23, 295.49it/s]Running 10000 simulations.:  30%|███       | 3000/10000 [00:10<00:23, 296.15it/s]Running 10000 simulations.:  30%|███       | 3030/10000 [00:10<00:23, 296.52it/s]Running 10000 simulations.:  31%|███       | 3060/10000 [00:10<00:23, 296.88it/s]Running 10000 simulations.:  31%|███       | 3090/10000 [00:10<00:23, 297.12it/s]Running 10000 simulations.:  31%|███       | 3120/10000 [00:10<00:23, 297.23it/s]Running 10000 simulations.:  32%|███▏      | 3150/10000 [00:10<00:23, 297.25it/s]Running 10000 simulations.:  32%|███▏      | 3180/10000 [00:10<00:22, 297.54it/s]Running 10000 simulations.:  32%|███▏      | 3210/10000 [00:10<00:22, 297.78it/s]Running 10000 simulations.:  32%|███▏      | 3240/10000 [00:10<00:22, 297.90it/s]Running 10000 simulations.:  33%|███▎      | 3270/10000 [00:11<00:22, 297.96it/s]Running 10000 simulations.:  33%|███▎      | 3300/10000 [00:11<00:22, 298.05it/s]Running 10000 simulations.:  33%|███▎      | 3330/10000 [00:11<00:22, 297.86it/s]Running 10000 simulations.:  34%|███▎      | 3360/10000 [00:11<00:22, 297.84it/s]Running 10000 simulations.:  34%|███▍      | 3390/10000 [00:11<00:22, 297.63it/s]Running 10000 simulations.:  34%|███▍      | 3420/10000 [00:11<00:22, 297.82it/s]Running 10000 simulations.:  34%|███▍      | 3450/10000 [00:11<00:22, 297.70it/s]Running 10000 simulations.:  35%|███▍      | 3480/10000 [00:11<00:21, 298.05it/s]Running 10000 simulations.:  35%|███▌      | 3510/10000 [00:11<00:21, 298.28it/s]Running 10000 simulations.:  35%|███▌      | 3540/10000 [00:11<00:21, 298.37it/s]Running 10000 simulations.:  36%|███▌      | 3570/10000 [00:12<00:21, 298.60it/s]Running 10000 simulations.:  36%|███▌      | 3600/10000 [00:12<00:21, 298.57it/s]Running 10000 simulations.:  36%|███▋      | 3630/10000 [00:12<00:21, 298.62it/s]Running 10000 simulations.:  37%|███▋      | 3660/10000 [00:12<00:21, 298.40it/s]Running 10000 simulations.:  37%|███▋      | 3690/10000 [00:12<00:21, 298.41it/s]Running 10000 simulations.:  37%|███▋      | 3720/10000 [00:12<00:21, 298.00it/s]Running 10000 simulations.:  38%|███▊      | 3750/10000 [00:12<00:21, 297.26it/s]Running 10000 simulations.:  38%|███▊      | 3780/10000 [00:12<00:20, 296.31it/s]Running 10000 simulations.:  38%|███▊      | 3810/10000 [00:12<00:20, 296.22it/s]Running 10000 simulations.:  38%|███▊      | 3840/10000 [00:13<00:20, 296.15it/s]Running 10000 simulations.:  39%|███▊      | 3870/10000 [00:13<00:20, 295.92it/s]Running 10000 simulations.:  39%|███▉      | 3900/10000 [00:13<00:20, 295.63it/s]Running 10000 simulations.:  39%|███▉      | 3930/10000 [00:13<00:20, 295.71it/s]Running 10000 simulations.:  40%|███▉      | 3960/10000 [00:13<00:20, 295.56it/s]Running 10000 simulations.:  40%|███▉      | 3990/10000 [00:13<00:20, 296.09it/s]Running 10000 simulations.:  40%|████      | 4020/10000 [00:13<00:20, 295.21it/s]Running 10000 simulations.:  40%|████      | 4050/10000 [00:13<00:20, 295.59it/s]Running 10000 simulations.:  41%|████      | 4080/10000 [00:13<00:19, 296.02it/s]Running 10000 simulations.:  41%|████      | 4110/10000 [00:13<00:19, 296.61it/s]Running 10000 simulations.:  41%|████▏     | 4140/10000 [00:14<00:19, 296.85it/s]Running 10000 simulations.:  42%|████▏     | 4170/10000 [00:14<00:19, 296.28it/s]Running 10000 simulations.:  42%|████▏     | 4200/10000 [00:14<00:19, 296.10it/s]Running 10000 simulations.:  42%|████▏     | 4230/10000 [00:14<00:19, 295.76it/s]Running 10000 simulations.:  43%|████▎     | 4260/10000 [00:14<00:19, 296.16it/s]Running 10000 simulations.:  43%|████▎     | 4290/10000 [00:14<00:19, 296.94it/s]Running 10000 simulations.:  43%|████▎     | 4320/10000 [00:14<00:19, 296.63it/s]Running 10000 simulations.:  44%|████▎     | 4350/10000 [00:14<00:19, 296.20it/s]Running 10000 simulations.:  44%|████▍     | 4380/10000 [00:14<00:19, 295.11it/s]Running 10000 simulations.:  44%|████▍     | 4410/10000 [00:14<00:19, 294.03it/s]Running 10000 simulations.:  44%|████▍     | 4440/10000 [00:15<00:18, 293.55it/s]Running 10000 simulations.:  45%|████▍     | 4470/10000 [00:15<00:18, 292.96it/s]Running 10000 simulations.:  45%|████▌     | 4500/10000 [00:15<00:18, 292.52it/s]Running 10000 simulations.:  45%|████▌     | 4530/10000 [00:15<00:18, 293.33it/s]Running 10000 simulations.:  46%|████▌     | 4560/10000 [00:15<00:18, 293.83it/s]Running 10000 simulations.:  46%|████▌     | 4590/10000 [00:15<00:18, 293.89it/s]Running 10000 simulations.:  46%|████▌     | 4620/10000 [00:15<00:18, 293.38it/s]Running 10000 simulations.:  46%|████▋     | 4650/10000 [00:15<00:18, 293.75it/s]Running 10000 simulations.:  47%|████▋     | 4680/10000 [00:15<00:18, 293.16it/s]Running 10000 simulations.:  47%|████▋     | 4710/10000 [00:15<00:18, 292.72it/s]Running 10000 simulations.:  47%|████▋     | 4740/10000 [00:16<00:17, 293.62it/s]Running 10000 simulations.:  48%|████▊     | 4770/10000 [00:16<00:17, 295.03it/s]Running 10000 simulations.:  48%|████▊     | 4800/10000 [00:16<00:17, 295.90it/s]Running 10000 simulations.:  48%|████▊     | 4830/10000 [00:16<00:17, 296.15it/s]Running 10000 simulations.:  49%|████▊     | 4860/10000 [00:16<00:17, 296.25it/s]Running 10000 simulations.:  49%|████▉     | 4890/10000 [00:16<00:17, 295.82it/s]Running 10000 simulations.:  49%|████▉     | 4920/10000 [00:16<00:17, 294.83it/s]Running 10000 simulations.:  50%|████▉     | 4950/10000 [00:16<00:17, 294.63it/s]Running 10000 simulations.:  50%|████▉     | 4980/10000 [00:16<00:17, 294.54it/s]Running 10000 simulations.:  50%|█████     | 5010/10000 [00:16<00:16, 294.14it/s]Running 10000 simulations.:  50%|█████     | 5040/10000 [00:17<00:16, 294.30it/s]Running 10000 simulations.:  51%|█████     | 5070/10000 [00:17<00:16, 295.09it/s]Running 10000 simulations.:  51%|█████     | 5100/10000 [00:17<00:16, 295.53it/s]Running 10000 simulations.:  51%|█████▏    | 5130/10000 [00:17<00:16, 296.13it/s]Running 10000 simulations.:  52%|█████▏    | 5160/10000 [00:17<00:16, 296.59it/s]Running 10000 simulations.:  52%|█████▏    | 5190/10000 [00:17<00:16, 297.16it/s]Running 10000 simulations.:  52%|█████▏    | 5220/10000 [00:17<00:16, 297.16it/s]Running 10000 simulations.:  52%|█████▎    | 5250/10000 [00:17<00:16, 295.46it/s]Running 10000 simulations.:  53%|█████▎    | 5280/10000 [00:17<00:16, 294.76it/s]Running 10000 simulations.:  53%|█████▎    | 5310/10000 [00:17<00:15, 294.77it/s]Running 10000 simulations.:  53%|█████▎    | 5340/10000 [00:18<00:15, 294.63it/s]Running 10000 simulations.:  54%|█████▎    | 5370/10000 [00:18<00:15, 294.85it/s]Running 10000 simulations.:  54%|█████▍    | 5400/10000 [00:18<00:15, 295.17it/s]Running 10000 simulations.:  54%|█████▍    | 5430/10000 [00:18<00:15, 295.45it/s]Running 10000 simulations.:  55%|█████▍    | 5460/10000 [00:18<00:15, 296.31it/s]Running 10000 simulations.:  55%|█████▍    | 5490/10000 [00:18<00:15, 296.60it/s]Running 10000 simulations.:  55%|█████▌    | 5520/10000 [00:18<00:15, 297.02it/s]Running 10000 simulations.:  56%|█████▌    | 5550/10000 [00:18<00:14, 297.22it/s]Running 10000 simulations.:  56%|█████▌    | 5580/10000 [00:18<00:14, 297.64it/s]Running 10000 simulations.:  56%|█████▌    | 5610/10000 [00:18<00:14, 297.77it/s]Running 10000 simulations.:  56%|█████▋    | 5640/10000 [00:19<00:14, 297.64it/s]Running 10000 simulations.:  57%|█████▋    | 5670/10000 [00:19<00:14, 297.84it/s]Running 10000 simulations.:  57%|█████▋    | 5700/10000 [00:19<00:14, 297.81it/s]Running 10000 simulations.:  57%|█████▋    | 5730/10000 [00:19<00:14, 298.03it/s]Running 10000 simulations.:  58%|█████▊    | 5760/10000 [00:19<00:14, 297.86it/s]Running 10000 simulations.:  58%|█████▊    | 5790/10000 [00:19<00:14, 297.70it/s]Running 10000 simulations.:  58%|█████▊    | 5820/10000 [00:19<00:14, 297.84it/s]Running 10000 simulations.:  58%|█████▊    | 5850/10000 [00:19<00:13, 298.05it/s]Running 10000 simulations.:  59%|█████▉    | 5880/10000 [00:19<00:13, 298.12it/s]Running 10000 simulations.:  59%|█████▉    | 5910/10000 [00:20<00:13, 297.94it/s]Running 10000 simulations.:  59%|█████▉    | 5940/10000 [00:20<00:13, 297.03it/s]Running 10000 simulations.:  60%|█████▉    | 5970/10000 [00:20<00:13, 297.13it/s]Running 10000 simulations.:  60%|██████    | 6000/10000 [00:20<00:13, 296.77it/s]Running 10000 simulations.:  60%|██████    | 6030/10000 [00:20<00:13, 296.73it/s]Running 10000 simulations.:  61%|██████    | 6060/10000 [00:20<00:13, 295.97it/s]Running 10000 simulations.:  61%|██████    | 6090/10000 [00:20<00:13, 295.82it/s]Running 10000 simulations.:  61%|██████    | 6120/10000 [00:20<00:13, 295.52it/s]Running 10000 simulations.:  62%|██████▏   | 6150/10000 [00:20<00:13, 294.55it/s]Running 10000 simulations.:  62%|██████▏   | 6180/10000 [00:20<00:13, 293.60it/s]Running 10000 simulations.:  62%|██████▏   | 6210/10000 [00:21<00:12, 293.04it/s]Running 10000 simulations.:  62%|██████▏   | 6240/10000 [00:21<00:12, 292.65it/s]Running 10000 simulations.:  63%|██████▎   | 6270/10000 [00:21<00:12, 293.10it/s]Running 10000 simulations.:  63%|██████▎   | 6300/10000 [00:21<00:12, 293.12it/s]Running 10000 simulations.:  63%|██████▎   | 6330/10000 [00:21<00:12, 293.49it/s]Running 10000 simulations.:  64%|██████▎   | 6360/10000 [00:21<00:12, 293.00it/s]Running 10000 simulations.:  64%|██████▍   | 6390/10000 [00:21<00:12, 293.14it/s]Running 10000 simulations.:  64%|██████▍   | 6420/10000 [00:21<00:12, 292.77it/s]Running 10000 simulations.:  64%|██████▍   | 6450/10000 [00:21<00:12, 292.47it/s]Running 10000 simulations.:  65%|██████▍   | 6480/10000 [00:21<00:12, 292.40it/s]Running 10000 simulations.:  65%|██████▌   | 6510/10000 [00:22<00:11, 291.99it/s]Running 10000 simulations.:  65%|██████▌   | 6540/10000 [00:22<00:11, 292.26it/s]Running 10000 simulations.:  66%|██████▌   | 6570/10000 [00:22<00:11, 292.81it/s]Running 10000 simulations.:  66%|██████▌   | 6600/10000 [00:22<00:11, 292.99it/s]Running 10000 simulations.:  66%|██████▋   | 6630/10000 [00:22<00:11, 293.14it/s]Running 10000 simulations.:  67%|██████▋   | 6660/10000 [00:22<00:11, 294.15it/s]Running 10000 simulations.:  67%|██████▋   | 6690/10000 [00:22<00:11, 294.77it/s]Running 10000 simulations.:  67%|██████▋   | 6720/10000 [00:22<00:11, 295.17it/s]Running 10000 simulations.:  68%|██████▊   | 6750/10000 [00:22<00:10, 296.15it/s]Running 10000 simulations.:  68%|██████▊   | 6780/10000 [00:22<00:10, 296.82it/s]Running 10000 simulations.:  68%|██████▊   | 6810/10000 [00:23<00:10, 296.62it/s]Running 10000 simulations.:  68%|██████▊   | 6840/10000 [00:23<00:10, 294.61it/s]Running 10000 simulations.:  69%|██████▊   | 6870/10000 [00:23<00:10, 294.45it/s]Running 10000 simulations.:  69%|██████▉   | 6900/10000 [00:23<00:10, 294.09it/s]Running 10000 simulations.:  69%|██████▉   | 6930/10000 [00:23<00:10, 294.22it/s]Running 10000 simulations.:  70%|██████▉   | 6960/10000 [00:23<00:10, 293.84it/s]Running 10000 simulations.:  70%|██████▉   | 6990/10000 [00:23<00:10, 294.59it/s]Running 10000 simulations.:  70%|███████   | 7020/10000 [00:23<00:10, 295.75it/s]Running 10000 simulations.:  70%|███████   | 7050/10000 [00:23<00:09, 296.61it/s]Running 10000 simulations.:  71%|███████   | 7080/10000 [00:23<00:09, 297.18it/s]Running 10000 simulations.:  71%|███████   | 7110/10000 [00:24<00:09, 297.26it/s]Running 10000 simulations.:  71%|███████▏  | 7140/10000 [00:24<00:09, 297.40it/s]Running 10000 simulations.:  72%|███████▏  | 7170/10000 [00:24<00:09, 297.57it/s]Running 10000 simulations.:  72%|███████▏  | 7200/10000 [00:24<00:09, 297.55it/s]Running 10000 simulations.:  72%|███████▏  | 7230/10000 [00:24<00:09, 296.94it/s]Running 10000 simulations.:  73%|███████▎  | 7260/10000 [00:24<00:09, 296.86it/s]Running 10000 simulations.:  73%|███████▎  | 7290/10000 [00:24<00:09, 287.90it/s]Running 10000 simulations.:  73%|███████▎  | 7320/10000 [00:24<00:09, 289.67it/s]Running 10000 simulations.:  74%|███████▎  | 7350/10000 [00:24<00:09, 290.98it/s]Running 10000 simulations.:  74%|███████▍  | 7380/10000 [00:24<00:08, 293.20it/s]Running 10000 simulations.:  74%|███████▍  | 7410/10000 [00:25<00:08, 293.74it/s]Running 10000 simulations.:  74%|███████▍  | 7440/10000 [00:25<00:08, 293.75it/s]Running 10000 simulations.:  75%|███████▍  | 7470/10000 [00:25<00:08, 293.59it/s]Running 10000 simulations.:  75%|███████▌  | 7500/10000 [00:25<00:08, 293.23it/s]Running 10000 simulations.:  75%|███████▌  | 7530/10000 [00:25<00:10, 244.06it/s]Running 10000 simulations.:  76%|███████▌  | 7560/10000 [00:25<00:09, 257.26it/s]Running 10000 simulations.:  76%|███████▌  | 7590/10000 [00:25<00:09, 267.38it/s]Running 10000 simulations.:  76%|███████▌  | 7620/10000 [00:25<00:08, 274.99it/s]Running 10000 simulations.:  76%|███████▋  | 7650/10000 [00:25<00:08, 280.30it/s]Running 10000 simulations.:  77%|███████▋  | 7680/10000 [00:26<00:08, 284.25it/s]Running 10000 simulations.:  77%|███████▋  | 7710/10000 [00:26<00:07, 287.63it/s]Running 10000 simulations.:  77%|███████▋  | 7740/10000 [00:26<00:07, 290.37it/s]Running 10000 simulations.:  78%|███████▊  | 7770/10000 [00:26<00:07, 293.02it/s]Running 10000 simulations.:  78%|███████▊  | 7800/10000 [00:26<00:07, 294.79it/s]Running 10000 simulations.:  78%|███████▊  | 7830/10000 [00:26<00:07, 294.64it/s]Running 10000 simulations.:  79%|███████▊  | 7860/10000 [00:26<00:07, 294.87it/s]Running 10000 simulations.:  79%|███████▉  | 7890/10000 [00:26<00:07, 296.21it/s]Running 10000 simulations.:  79%|███████▉  | 7920/10000 [00:26<00:07, 296.44it/s]Running 10000 simulations.:  80%|███████▉  | 7950/10000 [00:26<00:06, 296.94it/s]Running 10000 simulations.:  80%|███████▉  | 7980/10000 [00:27<00:06, 296.64it/s]Running 10000 simulations.:  80%|████████  | 8010/10000 [00:27<00:06, 296.55it/s]Running 10000 simulations.:  80%|████████  | 8040/10000 [00:27<00:06, 297.24it/s]Running 10000 simulations.:  81%|████████  | 8070/10000 [00:27<00:06, 297.60it/s]Running 10000 simulations.:  81%|████████  | 8100/10000 [00:27<00:06, 296.84it/s]Running 10000 simulations.:  81%|████████▏ | 8130/10000 [00:27<00:06, 295.62it/s]Running 10000 simulations.:  82%|████████▏ | 8160/10000 [00:27<00:06, 294.64it/s]Running 10000 simulations.:  82%|████████▏ | 8190/10000 [00:27<00:06, 294.12it/s]Running 10000 simulations.:  82%|████████▏ | 8220/10000 [00:27<00:06, 293.46it/s]Running 10000 simulations.:  82%|████████▎ | 8250/10000 [00:28<00:05, 293.83it/s]Running 10000 simulations.:  83%|████████▎ | 8280/10000 [00:28<00:05, 293.98it/s]Running 10000 simulations.:  83%|████████▎ | 8310/10000 [00:28<00:05, 294.67it/s]Running 10000 simulations.:  83%|████████▎ | 8340/10000 [00:28<00:05, 294.41it/s]Running 10000 simulations.:  84%|████████▎ | 8370/10000 [00:28<00:05, 294.28it/s]Running 10000 simulations.:  84%|████████▍ | 8400/10000 [00:28<00:05, 294.24it/s]Running 10000 simulations.:  84%|████████▍ | 8430/10000 [00:28<00:05, 294.50it/s]Running 10000 simulations.:  85%|████████▍ | 8460/10000 [00:28<00:05, 294.66it/s]Running 10000 simulations.:  85%|████████▍ | 8490/10000 [00:28<00:05, 294.11it/s]Running 10000 simulations.:  85%|████████▌ | 8520/10000 [00:28<00:05, 294.17it/s]Running 10000 simulations.:  86%|████████▌ | 8550/10000 [00:29<00:04, 294.21it/s]Running 10000 simulations.:  86%|████████▌ | 8580/10000 [00:29<00:04, 294.70it/s]Running 10000 simulations.:  86%|████████▌ | 8610/10000 [00:29<00:04, 295.48it/s]Running 10000 simulations.:  86%|████████▋ | 8640/10000 [00:29<00:04, 295.44it/s]Running 10000 simulations.:  87%|████████▋ | 8670/10000 [00:29<00:04, 295.38it/s]Running 10000 simulations.:  87%|████████▋ | 8700/10000 [00:29<00:04, 295.88it/s]Running 10000 simulations.:  87%|████████▋ | 8730/10000 [00:29<00:04, 296.43it/s]Running 10000 simulations.:  88%|████████▊ | 8760/10000 [00:29<00:04, 297.20it/s]Running 10000 simulations.:  88%|████████▊ | 8790/10000 [00:29<00:04, 297.66it/s]Running 10000 simulations.:  88%|████████▊ | 8820/10000 [00:29<00:03, 298.05it/s]Running 10000 simulations.:  88%|████████▊ | 8850/10000 [00:30<00:03, 298.14it/s]Running 10000 simulations.:  89%|████████▉ | 8880/10000 [00:30<00:03, 298.46it/s]Running 10000 simulations.:  89%|████████▉ | 8910/10000 [00:30<00:03, 298.57it/s]Running 10000 simulations.:  89%|████████▉ | 8940/10000 [00:30<00:03, 298.60it/s]Running 10000 simulations.:  90%|████████▉ | 8970/10000 [00:30<00:03, 298.60it/s]Running 10000 simulations.:  90%|█████████ | 9000/10000 [00:30<00:03, 298.71it/s]Running 10000 simulations.:  90%|█████████ | 9030/10000 [00:30<00:03, 298.62it/s]Running 10000 simulations.:  91%|█████████ | 9060/10000 [00:30<00:03, 298.51it/s]Running 10000 simulations.:  91%|█████████ | 9090/10000 [00:30<00:03, 298.08it/s]Running 10000 simulations.:  91%|█████████ | 9120/10000 [00:30<00:02, 297.45it/s]Running 10000 simulations.:  92%|█████████▏| 9150/10000 [00:31<00:02, 296.50it/s]Running 10000 simulations.:  92%|█████████▏| 9180/10000 [00:31<00:02, 295.95it/s]Running 10000 simulations.:  92%|█████████▏| 9210/10000 [00:31<00:02, 295.92it/s]Running 10000 simulations.:  92%|█████████▏| 9240/10000 [00:31<00:02, 296.57it/s]Running 10000 simulations.:  93%|█████████▎| 9270/10000 [00:31<00:02, 296.62it/s]Running 10000 simulations.:  93%|█████████▎| 9300/10000 [00:31<00:02, 297.31it/s]Running 10000 simulations.:  93%|█████████▎| 9330/10000 [00:31<00:02, 297.68it/s]Running 10000 simulations.:  94%|█████████▎| 9360/10000 [00:31<00:02, 296.51it/s]Running 10000 simulations.:  94%|█████████▍| 9390/10000 [00:31<00:02, 295.80it/s]Running 10000 simulations.:  94%|█████████▍| 9420/10000 [00:31<00:01, 295.30it/s]Running 10000 simulations.:  94%|█████████▍| 9450/10000 [00:32<00:01, 296.22it/s]Running 10000 simulations.:  95%|█████████▍| 9480/10000 [00:32<00:01, 296.26it/s]Running 10000 simulations.:  95%|█████████▌| 9510/10000 [00:32<00:01, 296.51it/s]Running 10000 simulations.:  95%|█████████▌| 9540/10000 [00:32<00:01, 296.60it/s]Running 10000 simulations.:  96%|█████████▌| 9570/10000 [00:32<00:01, 296.58it/s]Running 10000 simulations.:  96%|█████████▌| 9600/10000 [00:32<00:01, 296.73it/s]Running 10000 simulations.:  96%|█████████▋| 9630/10000 [00:32<00:01, 296.06it/s]Running 10000 simulations.:  97%|█████████▋| 9660/10000 [00:32<00:01, 296.32it/s]Running 10000 simulations.:  97%|█████████▋| 9690/10000 [00:32<00:01, 296.77it/s]Running 10000 simulations.:  97%|█████████▋| 9720/10000 [00:32<00:00, 297.31it/s]Running 10000 simulations.:  98%|█████████▊| 9750/10000 [00:33<00:00, 297.66it/s]Running 10000 simulations.:  98%|█████████▊| 9780/10000 [00:33<00:00, 296.89it/s]Running 10000 simulations.:  98%|█████████▊| 9810/10000 [00:33<00:00, 295.67it/s]Running 10000 simulations.:  98%|█████████▊| 9840/10000 [00:33<00:00, 295.02it/s]Running 10000 simulations.:  99%|█████████▊| 9870/10000 [00:33<00:00, 294.20it/s]Running 10000 simulations.:  99%|█████████▉| 9900/10000 [00:33<00:00, 294.06it/s]Running 10000 simulations.:  99%|█████████▉| 9930/10000 [00:33<00:00, 293.52it/s]Running 10000 simulations.: 100%|█████████▉| 9960/10000 [00:33<00:00, 295.09it/s]Running 10000 simulations.: 100%|█████████▉| 9990/10000 [00:33<00:00, 296.39it/s]Running 10000 simulations.: 100%|██████████| 10000/10000 [00:33<00:00, 294.84it/s]
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 231586.20it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229700.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29993/50000 [00:00<00:00, 229978.34it/s]Drawing 50000 posterior samples: 59981it [00:00, 230213.70it/s]                           Drawing 50000 posterior samples: 59981it [00:00, 230026.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225898.17it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225990.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227420.66it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228850.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  51%|█████     | 25483/50000 [00:00<00:00, 195602.83it/s]Drawing 50000 posterior samples: 50974it [00:00, 195328.87it/s]                           Drawing 50000 posterior samples: 50974it [00:00, 194853.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27412/50000 [00:00<00:00, 204981.75it/s]Drawing 50000 posterior samples: 54702it [00:00, 205845.30it/s]                           Drawing 50000 posterior samples: 54702it [00:00, 206093.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 231754.26it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 231437.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226336.61it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227088.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226930.12it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227263.58it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226127.13it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226744.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 224355.52it/s]Drawing 50000 posterior samples: 59999it [00:00, 220829.01it/s]                           Drawing 50000 posterior samples: 59999it [00:00, 218222.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 231839.23it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230240.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226889.61it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226812.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225931.43it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225580.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228275.94it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228336.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29824/50000 [00:00<00:00, 229017.01it/s]Drawing 50000 posterior samples: 59665it [00:00, 229263.34it/s]                           Drawing 50000 posterior samples: 59665it [00:00, 229082.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 229774.10it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225386.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 211535.82it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 210522.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29787/50000 [00:00<00:00, 202580.31it/s]Drawing 50000 posterior samples: 59611it [00:00, 205900.26it/s]                           Drawing 50000 posterior samples: 59611it [00:00, 207801.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227308.50it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227312.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230886.74it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229946.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225740.11it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225992.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227206.30it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226793.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227606.18it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226708.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 229217.82it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228339.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 223935.08it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 223541.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228877.18it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229393.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230355.85it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230467.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227209.17it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228036.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27118/50000 [00:00<00:00, 208662.58it/s]Drawing 50000 posterior samples: 54239it [00:00, 208056.82it/s]                           Drawing 50000 posterior samples: 54239it [00:00, 207306.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27496/50000 [00:00<00:00, 209309.08it/s]Drawing 50000 posterior samples: 54923it [00:00, 209658.05it/s]                           Drawing 50000 posterior samples: 54923it [00:00, 209603.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  46%|████▌     | 23096/50000 [00:00<00:00, 160378.47it/s]Drawing 50000 posterior samples:  92%|█████████▏| 46022/50000 [00:00<00:00, 159494.09it/s]Drawing 50000 posterior samples: 53702it [00:00, 158751.96it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27543/50000 [00:00<00:00, 190439.61it/s]Drawing 50000 posterior samples: 55074it [00:00, 190347.48it/s]                           Drawing 50000 posterior samples: 55074it [00:00, 190018.16it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27468/50000 [00:00<00:00, 190494.46it/s]Drawing 50000 posterior samples: 54969it [00:00, 190727.73it/s]                           Drawing 50000 posterior samples: 54969it [00:00, 190659.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  51%|█████     | 25525/50000 [00:00<00:00, 178054.91it/s]Drawing 50000 posterior samples: 51049it [00:00, 178204.51it/s]                           Drawing 50000 posterior samples: 51049it [00:00, 178072.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27537/50000 [00:00<00:00, 191825.23it/s]Drawing 50000 posterior samples: 55010it [00:00, 191756.92it/s]                           Drawing 50000 posterior samples: 55010it [00:00, 191459.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27434/50000 [00:00<00:00, 190883.27it/s]Drawing 50000 posterior samples: 54986it [00:00, 190715.88it/s]                           Drawing 50000 posterior samples: 54986it [00:00, 190381.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27496/50000 [00:00<00:00, 189345.85it/s]Drawing 50000 posterior samples: 54973it [00:00, 189360.98it/s]                           Drawing 50000 posterior samples: 54973it [00:00, 189089.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27450/50000 [00:00<00:00, 192091.42it/s]Drawing 50000 posterior samples: 55017it [00:00, 192221.69it/s]                           Drawing 50000 posterior samples: 55017it [00:00, 192058.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27514/50000 [00:00<00:00, 189934.13it/s]Drawing 50000 posterior samples: 55111it [00:00, 190361.53it/s]                           Drawing 50000 posterior samples: 55111it [00:00, 190403.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27507/50000 [00:00<00:00, 189332.70it/s]Drawing 50000 posterior samples: 54926it [00:00, 189245.45it/s]                           Drawing 50000 posterior samples: 54926it [00:00, 188972.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27488/50000 [00:00<00:00, 190358.07it/s]Drawing 50000 posterior samples: 54935it [00:00, 189900.21it/s]                           Drawing 50000 posterior samples: 54935it [00:00, 189343.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27556/50000 [00:00<00:00, 192589.00it/s]Drawing 50000 posterior samples: 55017it [00:00, 192370.91it/s]                           Drawing 50000 posterior samples: 55017it [00:00, 191941.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27631/50000 [00:00<00:00, 193131.51it/s]Drawing 50000 posterior samples: 55185it [00:00, 192762.72it/s]                           Drawing 50000 posterior samples: 55185it [00:00, 192280.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27609/50000 [00:00<00:00, 193363.78it/s]Drawing 50000 posterior samples: 55181it [00:00, 193955.15it/s]                           Drawing 50000 posterior samples: 55181it [00:00, 194094.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27498/50000 [00:00<00:00, 199857.51it/s]Drawing 50000 posterior samples: 55018it [00:00, 199604.08it/s]                           Drawing 50000 posterior samples: 55018it [00:00, 199149.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27497/50000 [00:00<00:00, 197930.91it/s]Drawing 50000 posterior samples: 55067it [00:00, 197581.28it/s]                           Drawing 50000 posterior samples: 55067it [00:00, 197081.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27410/50000 [00:00<00:00, 197356.82it/s]Drawing 50000 posterior samples: 54966it [00:00, 197317.48it/s]                           Drawing 50000 posterior samples: 54966it [00:00, 197035.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27558/50000 [00:00<00:00, 193372.11it/s]Drawing 50000 posterior samples: 55100it [00:00, 193444.86it/s]                           Drawing 50000 posterior samples: 55100it [00:00, 193224.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27518/50000 [00:00<00:00, 193144.75it/s]Drawing 50000 posterior samples: 54990it [00:00, 193053.01it/s]                           Drawing 50000 posterior samples: 54990it [00:00, 192728.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27555/50000 [00:00<00:00, 194216.96it/s]Drawing 50000 posterior samples: 55087it [00:00, 193754.58it/s]                           Drawing 50000 posterior samples: 55087it [00:00, 193180.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27462/50000 [00:00<00:00, 193750.31it/s]Drawing 50000 posterior samples: 54925it [00:00, 194287.92it/s]                           Drawing 50000 posterior samples: 54925it [00:00, 194380.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27464/50000 [00:00<00:00, 194543.25it/s]Drawing 50000 posterior samples: 54977it [00:00, 194561.89it/s]                           Drawing 50000 posterior samples: 54977it [00:00, 194302.02it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27501/50000 [00:00<00:00, 197406.12it/s]Drawing 50000 posterior samples: 55027it [00:00, 197339.02it/s]                           Drawing 50000 posterior samples: 55027it [00:00, 197017.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27459/50000 [00:00<00:00, 199604.49it/s]Drawing 50000 posterior samples: 54930it [00:00, 199422.41it/s]                           Drawing 50000 posterior samples: 54930it [00:00, 199026.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27513/50000 [00:00<00:00, 193073.14it/s]Drawing 50000 posterior samples: 55023it [00:00, 193117.82it/s]                           Drawing 50000 posterior samples: 55023it [00:00, 192867.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  48%|████▊     | 23923/50000 [00:00<00:00, 167098.26it/s]Drawing 50000 posterior samples:  96%|█████████▌| 47934/50000 [00:00<00:00, 167408.66it/s]Drawing 50000 posterior samples: 55834it [00:00, 167232.07it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27492/50000 [00:00<00:00, 190072.26it/s]Drawing 50000 posterior samples: 54973it [00:00, 188305.49it/s]                           Drawing 50000 posterior samples: 54973it [00:00, 186894.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27542/50000 [00:00<00:00, 192846.88it/s]Drawing 50000 posterior samples: 55078it [00:00, 192668.57it/s]                           Drawing 50000 posterior samples: 55078it [00:00, 192312.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27508/50000 [00:00<00:00, 193830.64it/s]Drawing 50000 posterior samples: 55003it [00:00, 193274.05it/s]                           Drawing 50000 posterior samples: 55003it [00:00, 192650.13it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27539/50000 [00:00<00:00, 208323.68it/s]Drawing 50000 posterior samples: 55140it [00:00, 208438.49it/s]                           Drawing 50000 posterior samples: 55140it [00:00, 208223.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27633/50000 [00:00<00:00, 210215.01it/s]Drawing 50000 posterior samples: 55192it [00:00, 209995.66it/s]                           Drawing 50000 posterior samples: 55192it [00:00, 209528.99it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27501/50000 [00:00<00:00, 209208.55it/s]Drawing 50000 posterior samples: 55105it [00:00, 209240.31it/s]                           Drawing 50000 posterior samples: 55105it [00:00, 208952.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27506/50000 [00:00<00:00, 207621.32it/s]Drawing 50000 posterior samples: 55114it [00:00, 207962.34it/s]                           Drawing 50000 posterior samples: 55114it [00:00, 207868.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  54%|█████▎    | 26845/50000 [00:00<00:00, 203612.14it/s]Drawing 50000 posterior samples: 53865it [00:00, 204424.29it/s]                           Drawing 50000 posterior samples: 53865it [00:00, 204676.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27528/50000 [00:00<00:00, 209063.96it/s]Drawing 50000 posterior samples: 55108it [00:00, 208863.21it/s]                           Drawing 50000 posterior samples: 55108it [00:00, 208404.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27532/50000 [00:00<00:00, 208657.21it/s]Drawing 50000 posterior samples: 55133it [00:00, 208519.77it/s]                           Drawing 50000 posterior samples: 55133it [00:00, 208131.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27616/50000 [00:00<00:00, 212398.64it/s]Drawing 50000 posterior samples: 55142it [00:00, 212302.65it/s]                           Drawing 50000 posterior samples: 55142it [00:00, 211911.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27583/50000 [00:00<00:00, 210062.86it/s]Drawing 50000 posterior samples: 55155it [00:00, 210549.03it/s]                           Drawing 50000 posterior samples: 55155it [00:00, 210548.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27521/50000 [00:00<00:00, 212091.51it/s]Drawing 50000 posterior samples: 55167it [00:00, 211792.49it/s]                           Drawing 50000 posterior samples: 55167it [00:00, 211278.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27622/50000 [00:00<00:00, 210076.84it/s]Drawing 50000 posterior samples: 55183it [00:00, 210357.37it/s]                           Drawing 50000 posterior samples: 55183it [00:00, 210219.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27481/50000 [00:00<00:00, 207324.79it/s]Drawing 50000 posterior samples: 55086it [00:00, 207834.07it/s]                           Drawing 50000 posterior samples: 55086it [00:00, 207828.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27544/50000 [00:00<00:00, 209845.86it/s]Drawing 50000 posterior samples: 55209it [00:00, 210217.27it/s]                           Drawing 50000 posterior samples: 55209it [00:00, 210158.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27601/50000 [00:00<00:00, 208456.95it/s]Drawing 50000 posterior samples: 55214it [00:00, 208812.73it/s]                           Drawing 50000 posterior samples: 55214it [00:00, 208718.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27533/50000 [00:00<00:00, 209746.81it/s]Drawing 50000 posterior samples: 55213it [00:00, 210090.30it/s]                           Drawing 50000 posterior samples: 55213it [00:00, 210028.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27412/50000 [00:00<00:00, 210623.79it/s]Drawing 50000 posterior samples: 55062it [00:00, 211344.80it/s]                           Drawing 50000 posterior samples: 55062it [00:00, 211504.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27489/50000 [00:00<00:00, 207774.94it/s]Drawing 50000 posterior samples: 55069it [00:00, 208151.91it/s]                           Drawing 50000 posterior samples: 55069it [00:00, 208101.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27533/50000 [00:00<00:00, 208151.40it/s]Drawing 50000 posterior samples: 55077it [00:00, 208593.22it/s]                           Drawing 50000 posterior samples: 55077it [00:00, 208537.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27586/50000 [00:00<00:00, 208753.76it/s]Drawing 50000 posterior samples: 55151it [00:00, 208988.67it/s]                           Drawing 50000 posterior samples: 55151it [00:00, 208818.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27658/50000 [00:00<00:00, 212827.82it/s]Drawing 50000 posterior samples: 55278it [00:00, 212648.99it/s]                           Drawing 50000 posterior samples: 55278it [00:00, 212222.57it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27559/50000 [00:00<00:00, 210790.22it/s]Drawing 50000 posterior samples: 55142it [00:00, 211413.26it/s]                           Drawing 50000 posterior samples: 55142it [00:00, 211511.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27562/50000 [00:00<00:00, 213275.07it/s]Drawing 50000 posterior samples: 55162it [00:00, 213226.44it/s]                           Drawing 50000 posterior samples: 55162it [00:00, 212798.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27579/50000 [00:00<00:00, 212014.54it/s]Drawing 50000 posterior samples: 55096it [00:00, 212228.16it/s]                           Drawing 50000 posterior samples: 55096it [00:00, 212062.10it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27527/50000 [00:00<00:00, 212976.74it/s]Drawing 50000 posterior samples: 55069it [00:00, 212685.17it/s]                           Drawing 50000 posterior samples: 55069it [00:00, 212164.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27528/50000 [00:00<00:00, 211389.62it/s]Drawing 50000 posterior samples: 55089it [00:00, 211542.32it/s]                           Drawing 50000 posterior samples: 55089it [00:00, 211335.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27588/50000 [00:00<00:00, 208775.68it/s]Drawing 50000 posterior samples: 55093it [00:00, 208800.45it/s]                           Drawing 50000 posterior samples: 55093it [00:00, 208506.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27573/50000 [00:00<00:00, 208009.89it/s]Drawing 50000 posterior samples: 55103it [00:00, 208055.64it/s]                           Drawing 50000 posterior samples: 55103it [00:00, 207783.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27541/50000 [00:00<00:00, 209116.12it/s]Drawing 50000 posterior samples: 55209it [00:00, 204657.50it/s]                           Drawing 50000 posterior samples: 55209it [00:00, 201458.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27560/50000 [00:00<00:00, 210180.40it/s]Drawing 50000 posterior samples: 55136it [00:00, 210467.40it/s]                           Drawing 50000 posterior samples: 55136it [00:00, 210318.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27523/50000 [00:00<00:00, 211658.91it/s]Drawing 50000 posterior samples: 55079it [00:00, 211833.71it/s]                           Drawing 50000 posterior samples: 55079it [00:00, 211618.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27555/50000 [00:00<00:00, 208203.64it/s]Drawing 50000 posterior samples: 55131it [00:00, 208212.19it/s]                           Drawing 50000 posterior samples: 55131it [00:00, 207934.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27355/50000 [00:00<00:00, 209227.22it/s]Drawing 50000 posterior samples: 54821it [00:00, 209940.22it/s]                           Drawing 50000 posterior samples: 54821it [00:00, 210104.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27566/50000 [00:00<00:00, 209196.88it/s]Drawing 50000 posterior samples: 55080it [00:00, 208744.77it/s]                           Drawing 50000 posterior samples: 55080it [00:00, 208148.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27482/50000 [00:00<00:00, 206771.11it/s]Drawing 50000 posterior samples: 55000it [00:00, 206929.84it/s]                           Drawing 50000 posterior samples: 55000it [00:00, 206710.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  54%|█████▍    | 27024/50000 [00:00<00:00, 206438.42it/s]Drawing 50000 posterior samples: 53982it [00:00, 206677.17it/s]                           Drawing 50000 posterior samples: 53982it [00:00, 206512.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27519/50000 [00:00<00:00, 208464.14it/s]Drawing 50000 posterior samples: 55146it [00:00, 208977.88it/s]                           Drawing 50000 posterior samples: 55146it [00:00, 208984.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27545/50000 [00:00<00:00, 210374.31it/s]Drawing 50000 posterior samples: 55044it [00:00, 210461.36it/s]                           Drawing 50000 posterior samples: 55044it [00:00, 210200.18it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27491/50000 [00:00<00:00, 208798.84it/s]Drawing 50000 posterior samples: 55042it [00:00, 208988.51it/s]                           Drawing 50000 posterior samples: 55042it [00:00, 208798.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27435/50000 [00:00<00:00, 207716.40it/s]Drawing 50000 posterior samples: 55031it [00:00, 208822.32it/s]                           Drawing 50000 posterior samples: 55031it [00:00, 209269.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27480/50000 [00:00<00:00, 208578.95it/s]Drawing 50000 posterior samples: 55063it [00:00, 209645.86it/s]                           Drawing 50000 posterior samples: 55063it [00:00, 210059.69it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27565/50000 [00:00<00:00, 208363.28it/s]Drawing 50000 posterior samples: 55107it [00:00, 208323.71it/s]                           Drawing 50000 posterior samples: 55107it [00:00, 208019.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27582/50000 [00:00<00:00, 209628.94it/s]Drawing 50000 posterior samples: 55208it [00:00, 209867.72it/s]                           Drawing 50000 posterior samples: 55208it [00:00, 209710.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27464/50000 [00:00<00:00, 207639.86it/s]Drawing 50000 posterior samples: 54976it [00:00, 208198.05it/s]                           Drawing 50000 posterior samples: 54976it [00:00, 208276.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27524/50000 [00:00<00:00, 210994.63it/s]Drawing 50000 posterior samples: 55118it [00:00, 211341.21it/s]                           Drawing 50000 posterior samples: 55118it [00:00, 211224.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27531/50000 [00:00<00:00, 211910.82it/s]Drawing 50000 posterior samples: 55020it [00:00, 211926.79it/s]                           Drawing 50000 posterior samples: 55020it [00:00, 211617.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27556/50000 [00:00<00:00, 208601.64it/s]Drawing 50000 posterior samples: 55104it [00:00, 209316.44it/s]                           Drawing 50000 posterior samples: 55104it [00:00, 209447.80it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27460/50000 [00:00<00:00, 207719.32it/s]Drawing 50000 posterior samples: 55004it [00:00, 207982.30it/s]                           Drawing 50000 posterior samples: 55004it [00:00, 207846.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27461/50000 [00:00<00:00, 207048.03it/s]Drawing 50000 posterior samples: 54999it [00:00, 207634.79it/s]                           Drawing 50000 posterior samples: 54999it [00:00, 207681.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27517/50000 [00:00<00:00, 207685.67it/s]Drawing 50000 posterior samples: 55085it [00:00, 207749.81it/s]                           Drawing 50000 posterior samples: 55085it [00:00, 207505.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27522/50000 [00:00<00:00, 210258.00it/s]Drawing 50000 posterior samples: 55072it [00:00, 209488.11it/s]                           Drawing 50000 posterior samples: 55072it [00:00, 208665.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27488/50000 [00:00<00:00, 209557.01it/s]Drawing 50000 posterior samples: 54928it [00:00, 209221.85it/s]                           Drawing 50000 posterior samples: 54928it [00:00, 208703.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27578/50000 [00:00<00:00, 211533.46it/s]Drawing 50000 posterior samples: 55105it [00:00, 210714.60it/s]                           Drawing 50000 posterior samples: 55105it [00:00, 209846.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27392/50000 [00:00<00:00, 206570.12it/s]Drawing 50000 posterior samples: 54938it [00:00, 206947.96it/s]                           Drawing 50000 posterior samples: 54938it [00:00, 206901.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27528/50000 [00:00<00:00, 207969.28it/s]Drawing 50000 posterior samples: 55072it [00:00, 208082.52it/s]                           Drawing 50000 posterior samples: 55072it [00:00, 207826.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27537/50000 [00:00<00:00, 210864.59it/s]Drawing 50000 posterior samples: 55072it [00:00, 210549.08it/s]                           Drawing 50000 posterior samples: 55072it [00:00, 210022.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27510/50000 [00:00<00:00, 208342.91it/s]Drawing 50000 posterior samples: 55014it [00:00, 208485.60it/s]                           Drawing 50000 posterior samples: 55014it [00:00, 208237.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27480/50000 [00:00<00:00, 210297.19it/s]Drawing 50000 posterior samples: 54989it [00:00, 210069.69it/s]                           Drawing 50000 posterior samples: 54989it [00:00, 209577.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27600/50000 [00:00<00:00, 208682.75it/s]Drawing 50000 posterior samples: 55092it [00:00, 208420.03it/s]                           Drawing 50000 posterior samples: 55092it [00:00, 207921.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27488/50000 [00:00<00:00, 212853.25it/s]Drawing 50000 posterior samples: 55018it [00:00, 212896.77it/s]                           Drawing 50000 posterior samples: 55018it [00:00, 212621.95it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27515/50000 [00:00<00:00, 207522.69it/s]Drawing 50000 posterior samples: 55116it [00:00, 208058.32it/s]                           Drawing 50000 posterior samples: 55116it [00:00, 208103.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226444.95it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226013.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29947/50000 [00:00<00:00, 225682.62it/s]Drawing 50000 posterior samples: 59909it [00:00, 225838.70it/s]                           Drawing 50000 posterior samples: 59909it [00:00, 225601.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228722.83it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228024.17it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227097.63it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226918.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27660/50000 [00:00<00:00, 209067.06it/s]Drawing 50000 posterior samples: 55251it [00:00, 209434.12it/s]                           Drawing 50000 posterior samples: 55251it [00:00, 209369.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  56%|█████▋    | 28185/50000 [00:00<00:00, 215762.84it/s]Drawing 50000 posterior samples: 56341it [00:00, 215831.01it/s]                           Drawing 50000 posterior samples: 56341it [00:00, 215538.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227032.48it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226733.11it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225727.56it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225966.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227411.20it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227912.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226258.46it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225896.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29992/50000 [00:00<00:00, 224963.14it/s]Drawing 50000 posterior samples: 59984it [00:00, 225294.57it/s]                           Drawing 50000 posterior samples: 59984it [00:00, 225189.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227477.39it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228169.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228832.23it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229005.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 231024.94it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229718.14it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225166.90it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226020.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29914/50000 [00:00<00:00, 229914.79it/s]Drawing 50000 posterior samples: 59812it [00:00, 230089.33it/s]                           Drawing 50000 posterior samples: 59812it [00:00, 229852.04it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228563.29it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227778.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227575.31it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226984.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  57%|█████▋    | 28382/50000 [00:00<00:00, 214233.95it/s]Drawing 50000 posterior samples: 56789it [00:00, 214127.74it/s]                           Drawing 50000 posterior samples: 56789it [00:00, 213734.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230487.50it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230443.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227090.66it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227236.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227882.77it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227981.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228075.26it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227326.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227059.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227079.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226335.38it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226331.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 229892.48it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230148.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230670.03it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230378.29it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227536.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228355.15it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230461.33it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228630.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  48%|████▊     | 24225/50000 [00:00<00:00, 184187.80it/s]Drawing 50000 posterior samples:  97%|█████████▋| 48455/50000 [00:00<00:00, 184270.34it/s]Drawing 50000 posterior samples: 56545it [00:00, 184368.41it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27485/50000 [00:00<00:00, 207198.81it/s]Drawing 50000 posterior samples: 55017it [00:00, 207577.86it/s]                           Drawing 50000 posterior samples: 55017it [00:00, 207490.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27283/50000 [00:00<00:00, 208876.88it/s]Drawing 50000 posterior samples: 54592it [00:00, 209327.63it/s]                           Drawing 50000 posterior samples: 54592it [00:00, 209303.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27554/50000 [00:00<00:00, 211609.81it/s]Drawing 50000 posterior samples: 55096it [00:00, 210953.56it/s]                           Drawing 50000 posterior samples: 55096it [00:00, 210140.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27578/50000 [00:00<00:00, 209598.54it/s]Drawing 50000 posterior samples: 55072it [00:00, 209434.21it/s]                           Drawing 50000 posterior samples: 55072it [00:00, 209001.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  53%|█████▎    | 26656/50000 [00:00<00:00, 203646.52it/s]Drawing 50000 posterior samples: 53359it [00:00, 204019.12it/s]                           Drawing 50000 posterior samples: 53359it [00:00, 203944.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27471/50000 [00:00<00:00, 211845.92it/s]Drawing 50000 posterior samples: 54858it [00:00, 211753.71it/s]                           Drawing 50000 posterior samples: 54858it [00:00, 211282.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27424/50000 [00:00<00:00, 208379.77it/s]Drawing 50000 posterior samples: 54924it [00:00, 208566.94it/s]                           Drawing 50000 posterior samples: 54924it [00:00, 208367.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27507/50000 [00:00<00:00, 208235.21it/s]Drawing 50000 posterior samples: 55068it [00:00, 208167.01it/s]                           Drawing 50000 posterior samples: 55068it [00:00, 207776.03it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27567/50000 [00:00<00:00, 209636.11it/s]Drawing 50000 posterior samples: 55044it [00:00, 209644.96it/s]                           Drawing 50000 posterior samples: 55044it [00:00, 209290.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27555/50000 [00:00<00:00, 207262.72it/s]Drawing 50000 posterior samples: 55074it [00:00, 207335.26it/s]                           Drawing 50000 posterior samples: 55074it [00:00, 207076.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27531/50000 [00:00<00:00, 207890.09it/s]Drawing 50000 posterior samples: 55071it [00:00, 208271.36it/s]                           Drawing 50000 posterior samples: 55071it [00:00, 208185.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27466/50000 [00:00<00:00, 207547.98it/s]Drawing 50000 posterior samples: 54937it [00:00, 207718.94it/s]                           Drawing 50000 posterior samples: 54937it [00:00, 207529.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27493/50000 [00:00<00:00, 206679.25it/s]Drawing 50000 posterior samples: 54954it [00:00, 207088.00it/s]                           Drawing 50000 posterior samples: 54954it [00:00, 207044.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27483/50000 [00:00<00:00, 211897.16it/s]Drawing 50000 posterior samples: 54943it [00:00, 211960.89it/s]                           Drawing 50000 posterior samples: 54943it [00:00, 211662.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27506/50000 [00:00<00:00, 209638.60it/s]Drawing 50000 posterior samples: 55012it [00:00, 209326.05it/s]                           Drawing 50000 posterior samples: 55012it [00:00, 208800.28it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27518/50000 [00:00<00:00, 210440.17it/s]Drawing 50000 posterior samples: 55046it [00:00, 210329.00it/s]                           Drawing 50000 posterior samples: 55046it [00:00, 209916.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27482/50000 [00:00<00:00, 208987.07it/s]Drawing 50000 posterior samples: 54991it [00:00, 204611.15it/s]                           Drawing 50000 posterior samples: 54991it [00:00, 201512.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27452/50000 [00:00<00:00, 209741.56it/s]Drawing 50000 posterior samples: 54964it [00:00, 209876.47it/s]                           Drawing 50000 posterior samples: 54964it [00:00, 209649.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27559/50000 [00:00<00:00, 207890.81it/s]Drawing 50000 posterior samples: 55096it [00:00, 208125.48it/s]                           Drawing 50000 posterior samples: 55096it [00:00, 207969.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27494/50000 [00:00<00:00, 209762.88it/s]Drawing 50000 posterior samples: 54955it [00:00, 210076.12it/s]                           Drawing 50000 posterior samples: 54955it [00:00, 209953.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27516/50000 [00:00<00:00, 212593.20it/s]Drawing 50000 posterior samples: 55008it [00:00, 211595.89it/s]                           Drawing 50000 posterior samples: 55008it [00:00, 210616.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27494/50000 [00:00<00:00, 209221.71it/s]Drawing 50000 posterior samples: 54985it [00:00, 209036.10it/s]                           Drawing 50000 posterior samples: 54985it [00:00, 208592.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27499/50000 [00:00<00:00, 207789.11it/s]Drawing 50000 posterior samples: 55057it [00:00, 208024.70it/s]                           Drawing 50000 posterior samples: 55057it [00:00, 207874.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27560/50000 [00:00<00:00, 208936.62it/s]Drawing 50000 posterior samples: 55132it [00:00, 209240.88it/s]                           Drawing 50000 posterior samples: 55132it [00:00, 209137.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27537/50000 [00:00<00:00, 210590.85it/s]Drawing 50000 posterior samples: 54929it [00:00, 209963.69it/s]                           Drawing 50000 posterior samples: 54929it [00:00, 209234.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27412/50000 [00:00<00:00, 208464.58it/s]Drawing 50000 posterior samples: 54833it [00:00, 209262.59it/s]                           Drawing 50000 posterior samples: 54833it [00:00, 209487.88it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27490/50000 [00:00<00:00, 211919.58it/s]Drawing 50000 posterior samples: 54985it [00:00, 212302.53it/s]                           Drawing 50000 posterior samples: 54985it [00:00, 212242.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27479/50000 [00:00<00:00, 212544.20it/s]Drawing 50000 posterior samples: 54971it [00:00, 212493.62it/s]                           Drawing 50000 posterior samples: 54971it [00:00, 212140.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27543/50000 [00:00<00:00, 210408.08it/s]Drawing 50000 posterior samples: 54952it [00:00, 209920.96it/s]                           Drawing 50000 posterior samples: 54952it [00:00, 209287.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27448/50000 [00:00<00:00, 207398.51it/s]Drawing 50000 posterior samples: 55045it [00:00, 208143.47it/s]                           Drawing 50000 posterior samples: 55045it [00:00, 208355.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227682.38it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227612.61it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29872/50000 [00:00<00:00, 227127.25it/s]Drawing 50000 posterior samples: 59730it [00:00, 227085.92it/s]                           Drawing 50000 posterior samples: 59730it [00:00, 226718.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226944.03it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226796.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227649.42it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227170.53it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  56%|█████▌    | 27778/50000 [00:00<00:00, 210509.02it/s]Drawing 50000 posterior samples: 55574it [00:00, 210714.89it/s]                           Drawing 50000 posterior samples: 55574it [00:00, 210490.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27561/50000 [00:00<00:00, 208573.99it/s]Drawing 50000 posterior samples: 55103it [00:00, 208587.99it/s]                           Drawing 50000 posterior samples: 55103it [00:00, 208278.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226489.38it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226299.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226187.29it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226010.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226163.30it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226124.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226409.91it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225825.60it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29995/50000 [00:00<00:00, 226106.91it/s]Drawing 50000 posterior samples: 59993it [00:00, 225958.50it/s]                           Drawing 50000 posterior samples: 59993it [00:00, 225533.12it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225664.81it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 224985.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226546.47it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226516.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 229525.97it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230359.56it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225659.96it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226534.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29892/50000 [00:00<00:00, 229378.34it/s]Drawing 50000 posterior samples: 59765it [00:00, 228399.99it/s]                           Drawing 50000 posterior samples: 59765it [00:00, 227390.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29993/50000 [00:00<00:00, 229221.96it/s]Drawing 50000 posterior samples: 59990it [00:00, 228703.98it/s]                           Drawing 50000 posterior samples: 59990it [00:00, 228003.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226508.14it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226255.86it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  59%|█████▉    | 29693/50000 [00:00<00:00, 224873.10it/s]Drawing 50000 posterior samples: 59366it [00:00, 224979.07it/s]                           Drawing 50000 posterior samples: 59366it [00:00, 224715.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227416.55it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226764.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228824.73it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229109.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228448.76it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229087.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225490.92it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225425.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228935.48it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227741.63it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230984.23it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 231271.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 231662.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230818.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230847.35it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229835.71it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226375.70it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226920.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226425.39it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226001.55it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  54%|█████▍    | 26890/50000 [00:00<00:00, 203750.44it/s]Drawing 50000 posterior samples: 53808it [00:00, 203800.69it/s]                           Drawing 50000 posterior samples: 53808it [00:00, 203520.47it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227448.61it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226940.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29991/50000 [00:00<00:00, 226633.97it/s]Drawing 50000 posterior samples: 59974it [00:00, 226483.35it/s]                           Drawing 50000 posterior samples: 59974it [00:00, 226012.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230400.56it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228882.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225973.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225871.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  50%|█████     | 25170/50000 [00:00<00:00, 190215.64it/s]Drawing 50000 posterior samples: 50549it [00:00, 190744.25it/s]                           Drawing 50000 posterior samples: 50549it [00:00, 190831.73it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  59%|█████▊    | 29362/50000 [00:00<00:00, 221115.11it/s]Drawing 50000 posterior samples: 58755it [00:00, 221500.66it/s]                           Drawing 50000 posterior samples: 58755it [00:00, 221407.94it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230550.43it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230247.52it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227129.61it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227072.39it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 224964.01it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225939.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 229862.24it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229664.05it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230924.03it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230564.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 231098.34it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230307.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230916.40it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 231053.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230946.92it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230772.24it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226663.59it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226560.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29983/50000 [00:00<00:00, 225207.36it/s]Drawing 50000 posterior samples: 59968it [00:00, 225570.80it/s]                           Drawing 50000 posterior samples: 59968it [00:00, 225475.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227217.38it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227103.37it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226120.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226073.66it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29989/50000 [00:00<00:00, 226818.69it/s]Drawing 50000 posterior samples: 59974it [00:00, 226853.30it/s]                           Drawing 50000 posterior samples: 59974it [00:00, 226519.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226497.53it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227115.42it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228952.56it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229075.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 232012.79it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 231472.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230673.42it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230645.85it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230025.70it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229919.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230559.72it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230197.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227374.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228245.79it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228460.37it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228763.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 232179.75it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229773.26it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 232713.50it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 232046.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  52%|█████▏    | 25907/50000 [00:00<00:00, 196890.03it/s]Drawing 50000 posterior samples: 51720it [00:00, 196330.22it/s]                           Drawing 50000 posterior samples: 51720it [00:00, 195569.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 227458.07it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227172.74it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29992/50000 [00:00<00:00, 227423.31it/s]Drawing 50000 posterior samples: 59986it [00:00, 228211.31it/s]                           Drawing 50000 posterior samples: 59986it [00:00, 228386.54it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230212.98it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229488.38it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225076.28it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225049.87it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27277/50000 [00:00<00:00, 207069.24it/s]Drawing 50000 posterior samples: 54570it [00:00, 206718.47it/s]                           Drawing 50000 posterior samples: 54570it [00:00, 206173.19it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27416/50000 [00:00<00:00, 211363.88it/s]Drawing 50000 posterior samples: 54753it [00:00, 211270.10it/s]                           Drawing 50000 posterior samples: 54753it [00:00, 210858.20it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225333.84it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225513.31it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 229804.31it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227405.78it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225408.52it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225215.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228308.66it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227947.59it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230036.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 229995.77it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230948.62it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230665.64it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228885.51it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228162.35it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228194.79it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 228566.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 230569.86it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 230531.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|█████▉    | 29762/50000 [00:00<00:00, 229757.83it/s]Drawing 50000 posterior samples: 59492it [00:00, 229836.07it/s]                           Drawing 50000 posterior samples: 59492it [00:00, 229544.96it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228135.22it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227922.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 229419.26it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227070.67it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  59%|█████▉    | 29646/50000 [00:00<00:00, 223459.63it/s]Drawing 50000 posterior samples: 59324it [00:00, 223570.36it/s]                           Drawing 50000 posterior samples: 59324it [00:00, 223307.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226011.37it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 224678.09it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226497.94it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226406.08it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226766.94it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226490.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 225878.30it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 225484.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 228001.70it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227155.27it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226571.76it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226565.07it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226276.37it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226056.36it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226620.73it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 227051.00it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226023.15it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226242.44it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  60%|██████    | 30000/50000 [00:00<00:00, 226408.69it/s]Drawing 50000 posterior samples: 100%|██████████| 50000/50000 [00:00<00:00, 226250.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  48%|████▊     | 24013/50000 [00:00<00:00, 181290.96it/s]Drawing 50000 posterior samples:  96%|█████████▌| 48090/50000 [00:00<00:00, 181936.05it/s]Drawing 50000 posterior samples: 56157it [00:00, 182344.67it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27460/50000 [00:00<00:00, 213141.29it/s]Drawing 50000 posterior samples: 55022it [00:00, 213631.46it/s]                           Drawing 50000 posterior samples: 55022it [00:00, 213630.45it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27460/50000 [00:00<00:00, 208859.15it/s]Drawing 50000 posterior samples: 54867it [00:00, 209294.33it/s]                           Drawing 50000 posterior samples: 54867it [00:00, 209272.75it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27491/50000 [00:00<00:00, 213042.07it/s]Drawing 50000 posterior samples: 54971it [00:00, 212724.81it/s]                           Drawing 50000 posterior samples: 54971it [00:00, 212213.30it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27461/50000 [00:00<00:00, 207802.22it/s]Drawing 50000 posterior samples: 54965it [00:00, 207847.70it/s]                           Drawing 50000 posterior samples: 54965it [00:00, 207558.43it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  48%|████▊     | 23821/50000 [00:00<00:00, 179916.22it/s]Drawing 50000 posterior samples:  95%|█████████▌| 47576/50000 [00:00<00:00, 179870.46it/s]Drawing 50000 posterior samples: 55439it [00:00, 179481.81it/s]                           
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27438/50000 [00:00<00:00, 208647.55it/s]Drawing 50000 posterior samples: 54910it [00:00, 209051.67it/s]                           Drawing 50000 posterior samples: 54910it [00:00, 208994.51it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27518/50000 [00:00<00:00, 212008.40it/s]Drawing 50000 posterior samples: 54906it [00:00, 211470.41it/s]                           Drawing 50000 posterior samples: 54906it [00:00, 210783.98it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27533/50000 [00:00<00:00, 209609.00it/s]Drawing 50000 posterior samples: 55018it [00:00, 209385.42it/s]                           Drawing 50000 posterior samples: 55018it [00:00, 208892.62it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27486/50000 [00:00<00:00, 211553.57it/s]Drawing 50000 posterior samples: 55000it [00:00, 212008.31it/s]                           Drawing 50000 posterior samples: 55000it [00:00, 211979.92it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27529/50000 [00:00<00:00, 208628.82it/s]Drawing 50000 posterior samples: 54960it [00:00, 208796.79it/s]                           Drawing 50000 posterior samples: 54960it [00:00, 208557.81it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27445/50000 [00:00<00:00, 210444.80it/s]Drawing 50000 posterior samples: 54915it [00:00, 211270.59it/s]                           Drawing 50000 posterior samples: 54915it [00:00, 211486.93it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27435/50000 [00:00<00:00, 210735.27it/s]Drawing 50000 posterior samples: 54887it [00:00, 210811.94it/s]                           Drawing 50000 posterior samples: 54887it [00:00, 210531.25it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27465/50000 [00:00<00:00, 210903.52it/s]Drawing 50000 posterior samples: 54975it [00:00, 210774.42it/s]                           Drawing 50000 posterior samples: 54975it [00:00, 210343.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27467/50000 [00:00<00:00, 209856.55it/s]Drawing 50000 posterior samples: 54942it [00:00, 209495.10it/s]                           Drawing 50000 posterior samples: 54942it [00:00, 208914.40it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27496/50000 [00:00<00:00, 206600.71it/s]Drawing 50000 posterior samples: 54951it [00:00, 206843.37it/s]                           Drawing 50000 posterior samples: 54951it [00:00, 206629.91it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27409/50000 [00:00<00:00, 208849.22it/s]Drawing 50000 posterior samples: 54840it [00:00, 209522.38it/s]                           Drawing 50000 posterior samples: 54840it [00:00, 209605.70it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27481/50000 [00:00<00:00, 207036.93it/s]Drawing 50000 posterior samples: 54992it [00:00, 207077.14it/s]                           Drawing 50000 posterior samples: 54992it [00:00, 206782.23it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27568/50000 [00:00<00:00, 211951.35it/s]Drawing 50000 posterior samples: 54995it [00:00, 211688.98it/s]                           Drawing 50000 posterior samples: 54995it [00:00, 211177.06it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27523/50000 [00:00<00:00, 208665.92it/s]Drawing 50000 posterior samples: 54998it [00:00, 209314.50it/s]                           Drawing 50000 posterior samples: 54998it [00:00, 209427.89it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27507/50000 [00:00<00:00, 210703.72it/s]Drawing 50000 posterior samples: 54942it [00:00, 210518.09it/s]                           Drawing 50000 posterior samples: 54942it [00:00, 210054.32it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27542/50000 [00:00<00:00, 207085.09it/s]Drawing 50000 posterior samples: 55016it [00:00, 206842.19it/s]                           Drawing 50000 posterior samples: 55016it [00:00, 206349.49it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27490/50000 [00:00<00:00, 206835.01it/s]Drawing 50000 posterior samples: 55069it [00:00, 207111.29it/s]                           Drawing 50000 posterior samples: 55069it [00:00, 206986.22it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27429/50000 [00:00<00:00, 206453.82it/s]Drawing 50000 posterior samples: 54898it [00:00, 206907.59it/s]                           Drawing 50000 posterior samples: 54898it [00:00, 206877.41it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27470/50000 [00:00<00:00, 207255.22it/s]Drawing 50000 posterior samples: 54935it [00:00, 207849.11it/s]                           Drawing 50000 posterior samples: 54935it [00:00, 207925.68it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27393/50000 [00:00<00:00, 210297.89it/s]Drawing 50000 posterior samples: 54799it [00:00, 211000.29it/s]                           Drawing 50000 posterior samples: 54799it [00:00, 211139.84it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▌    | 27505/50000 [00:00<00:00, 209815.13it/s]Drawing 50000 posterior samples: 55062it [00:00, 210147.88it/s]                           Drawing 50000 posterior samples: 55062it [00:00, 210016.90it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27453/50000 [00:00<00:00, 207520.04it/s]Drawing 50000 posterior samples: 54989it [00:00, 207421.60it/s]                           Drawing 50000 posterior samples: 54989it [00:00, 207037.48it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27452/50000 [00:00<00:00, 212361.21it/s]Drawing 50000 posterior samples: 54936it [00:00, 212017.89it/s]                           Drawing 50000 posterior samples: 54936it [00:00, 211401.46it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27478/50000 [00:00<00:00, 210340.22it/s]Drawing 50000 posterior samples: 54918it [00:00, 210338.75it/s]                           Drawing 50000 posterior samples: 54918it [00:00, 210003.33it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
Drawing 50000 posterior samples:   0%|          | 0/50000 [00:00<?, ?it/s]Drawing 50000 posterior samples:  55%|█████▍    | 27484/50000 [00:00<00:00, 207550.14it/s]Drawing 50000 posterior samples: 54924it [00:00, 207843.14it/s]                           Drawing 50000 posterior samples: 54924it [00:00, 207715.72it/s]
lstm_sbi.py:455: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  points=torch.tensor(true_theta),
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  arr_value = np.array(value)
/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/pandas/core/internals/blocks.py:867: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr_value = np.array(value)
30
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Neural network successfully converged after 284 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Neural network successfully converged after 235 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Neural network successfully converged after 169 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Neural network successfully converged after 181 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Neural network successfully converged after 252 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Neural network successfully converged after 267 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Neural network successfully converged after 244 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Neural network successfully converged after 337 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Training neural network. Epochs trained:  271Training neural network. Epochs trained:  272Training neural network. Epochs trained:  273Training neural network. Epochs trained:  274Training neural network. Epochs trained:  275Training neural network. Epochs trained:  276Training neural network. Epochs trained:  277Training neural network. Epochs trained:  278Training neural network. Epochs trained:  279Training neural network. Epochs trained:  280Training neural network. Epochs trained:  281Training neural network. Epochs trained:  282Training neural network. Epochs trained:  283Training neural network. Epochs trained:  284Training neural network. Epochs trained:  285Training neural network. Epochs trained:  286Training neural network. Epochs trained:  287Training neural network. Epochs trained:  288Training neural network. Epochs trained:  289Training neural network. Epochs trained:  290Training neural network. Epochs trained:  291Training neural network. Epochs trained:  292Training neural network. Epochs trained:  293Training neural network. Epochs trained:  294Training neural network. Epochs trained:  295Training neural network. Epochs trained:  296Training neural network. Epochs trained:  297Training neural network. Epochs trained:  298Training neural network. Epochs trained:  299Training neural network. Epochs trained:  300Training neural network. Epochs trained:  301Training neural network. Epochs trained:  302Training neural network. Epochs trained:  303Training neural network. Epochs trained:  304Training neural network. Epochs trained:  305Training neural network. Epochs trained:  306Training neural network. Epochs trained:  307Training neural network. Epochs trained:  308Training neural network. Epochs trained:  309Training neural network. Epochs trained:  310Training neural network. Epochs trained:  311Training neural network. Epochs trained:  312Training neural network. Epochs trained:  313Training neural network. Epochs trained:  314Training neural network. Epochs trained:  315Training neural network. Epochs trained:  316Training neural network. Epochs trained:  317Training neural network. Epochs trained:  318Training neural network. Epochs trained:  319Training neural network. Epochs trained:  320Training neural network. Epochs trained:  321Training neural network. Epochs trained:  322Training neural network. Epochs trained:  323Training neural network. Epochs trained:  324Training neural network. Epochs trained:  325Training neural network. Epochs trained:  326Training neural network. Epochs trained:  327Training neural network. Epochs trained:  328Training neural network. Epochs trained:  329Training neural network. Epochs trained:  330Training neural network. Epochs trained:  331Training neural network. Epochs trained:  332Training neural network. Epochs trained:  333Training neural network. Epochs trained:  334Training neural network. Epochs trained:  335Training neural network. Epochs trained:  336Training neural network. Epochs trained:  337Training neural network. Epochs trained:  338Training neural network. Epochs trained:  339Training neural network. Epochs trained:  340Training neural network. Epochs trained:  341Training neural network. Epochs trained:  342Training neural network. Epochs trained:  343Training neural network. Epochs trained:  344Training neural network. Epochs trained:  345Training neural network. Epochs trained:  346Training neural network. Epochs trained:  347Training neural network. Epochs trained:  348Training neural network. Epochs trained:  349Training neural network. Epochs trained:  350Training neural network. Epochs trained:  351Training neural network. Epochs trained:  352Training neural network. Epochs trained:  353Training neural network. Epochs trained:  354Training neural network. Epochs trained:  355Training neural network. Epochs trained:  356Training neural network. Epochs trained:  357Training neural network. Epochs trained:  358Training neural network. Epochs trained:  359Training neural network. Epochs trained:  360Training neural network. Epochs trained:  361Training neural network. Epochs trained:  362Training neural network. Epochs trained:  363Training neural network. Epochs trained:  364Training neural network. Epochs trained:  365Training neural network. Epochs trained:  366Training neural network. Epochs trained:  367Training neural network. Epochs trained:  368Training neural network. Epochs trained:  369Training neural network. Epochs trained:  370Training neural network. Epochs trained:  371Training neural network. Epochs trained:  372Training neural network. Epochs trained:  373Training neural network. Epochs trained:  374Training neural network. Epochs trained:  375Training neural network. Epochs trained:  376Training neural network. Epochs trained:  377Training neural network. Epochs trained:  378Training neural network. Epochs trained:  379Training neural network. Epochs trained:  380Training neural network. Epochs trained:  381Training neural network. Epochs trained:  382Training neural network. Epochs trained:  383Training neural network. Epochs trained:  384Training neural network. Epochs trained:  385Training neural network. Epochs trained:  386Training neural network. Epochs trained:  387Training neural network. Epochs trained:  388Neural network successfully converged after 388 epochs.
Training neural network. Epochs trained:  1Training neural network. Epochs trained:  2Training neural network. Epochs trained:  3Training neural network. Epochs trained:  4Training neural network. Epochs trained:  5Training neural network. Epochs trained:  6Training neural network. Epochs trained:  7Training neural network. Epochs trained:  8Training neural network. Epochs trained:  9Training neural network. Epochs trained:  10Training neural network. Epochs trained:  11Training neural network. Epochs trained:  12Training neural network. Epochs trained:  13Training neural network. Epochs trained:  14Training neural network. Epochs trained:  15Training neural network. Epochs trained:  16Training neural network. Epochs trained:  17Training neural network. Epochs trained:  18Training neural network. Epochs trained:  19Training neural network. Epochs trained:  20Training neural network. Epochs trained:  21Training neural network. Epochs trained:  22Training neural network. Epochs trained:  23Training neural network. Epochs trained:  24Training neural network. Epochs trained:  25Training neural network. Epochs trained:  26Training neural network. Epochs trained:  27Training neural network. Epochs trained:  28Training neural network. Epochs trained:  29Training neural network. Epochs trained:  30Training neural network. Epochs trained:  31Training neural network. Epochs trained:  32Training neural network. Epochs trained:  33Training neural network. Epochs trained:  34Training neural network. Epochs trained:  35Training neural network. Epochs trained:  36Training neural network. Epochs trained:  37Training neural network. Epochs trained:  38Training neural network. Epochs trained:  39Training neural network. Epochs trained:  40Training neural network. Epochs trained:  41Training neural network. Epochs trained:  42Training neural network. Epochs trained:  43Training neural network. Epochs trained:  44Training neural network. Epochs trained:  45Training neural network. Epochs trained:  46Training neural network. Epochs trained:  47Training neural network. Epochs trained:  48Training neural network. Epochs trained:  49Training neural network. Epochs trained:  50Training neural network. Epochs trained:  51Training neural network. Epochs trained:  52Training neural network. Epochs trained:  53Training neural network. Epochs trained:  54Training neural network. Epochs trained:  55Training neural network. Epochs trained:  56Training neural network. Epochs trained:  57Training neural network. Epochs trained:  58Training neural network. Epochs trained:  59Training neural network. Epochs trained:  60Training neural network. Epochs trained:  61Training neural network. Epochs trained:  62Training neural network. Epochs trained:  63Training neural network. Epochs trained:  64Training neural network. Epochs trained:  65Training neural network. Epochs trained:  66Training neural network. Epochs trained:  67Training neural network. Epochs trained:  68Training neural network. Epochs trained:  69Training neural network. Epochs trained:  70Training neural network. Epochs trained:  71Training neural network. Epochs trained:  72Training neural network. Epochs trained:  73Training neural network. Epochs trained:  74Training neural network. Epochs trained:  75Training neural network. Epochs trained:  76Training neural network. Epochs trained:  77Training neural network. Epochs trained:  78Training neural network. Epochs trained:  79Training neural network. Epochs trained:  80Training neural network. Epochs trained:  81Training neural network. Epochs trained:  82Training neural network. Epochs trained:  83Training neural network. Epochs trained:  84Training neural network. Epochs trained:  85Training neural network. Epochs trained:  86Training neural network. Epochs trained:  87Training neural network. Epochs trained:  88Training neural network. Epochs trained:  89Training neural network. Epochs trained:  90Training neural network. Epochs trained:  91Training neural network. Epochs trained:  92Training neural network. Epochs trained:  93Training neural network. Epochs trained:  94Training neural network. Epochs trained:  95Training neural network. Epochs trained:  96Training neural network. Epochs trained:  97Training neural network. Epochs trained:  98Training neural network. Epochs trained:  99Training neural network. Epochs trained:  100Training neural network. Epochs trained:  101Training neural network. Epochs trained:  102Training neural network. Epochs trained:  103Training neural network. Epochs trained:  104Training neural network. Epochs trained:  105Training neural network. Epochs trained:  106Training neural network. Epochs trained:  107Training neural network. Epochs trained:  108Training neural network. Epochs trained:  109Training neural network. Epochs trained:  110Training neural network. Epochs trained:  111Training neural network. Epochs trained:  112Training neural network. Epochs trained:  113Training neural network. Epochs trained:  114Training neural network. Epochs trained:  115Training neural network. Epochs trained:  116Training neural network. Epochs trained:  117Training neural network. Epochs trained:  118Training neural network. Epochs trained:  119Training neural network. Epochs trained:  120Training neural network. Epochs trained:  121Training neural network. Epochs trained:  122Training neural network. Epochs trained:  123Training neural network. Epochs trained:  124Training neural network. Epochs trained:  125Training neural network. Epochs trained:  126Training neural network. Epochs trained:  127Training neural network. Epochs trained:  128Training neural network. Epochs trained:  129Training neural network. Epochs trained:  130Training neural network. Epochs trained:  131Training neural network. Epochs trained:  132Training neural network. Epochs trained:  133Training neural network. Epochs trained:  134Training neural network. Epochs trained:  135Training neural network. Epochs trained:  136Training neural network. Epochs trained:  137Training neural network. Epochs trained:  138Training neural network. Epochs trained:  139Training neural network. Epochs trained:  140Training neural network. Epochs trained:  141Training neural network. Epochs trained:  142Training neural network. Epochs trained:  143Training neural network. Epochs trained:  144Training neural network. Epochs trained:  145Training neural network. Epochs trained:  146Training neural network. Epochs trained:  147Training neural network. Epochs trained:  148Training neural network. Epochs trained:  149Training neural network. Epochs trained:  150Training neural network. Epochs trained:  151Training neural network. Epochs trained:  152Training neural network. Epochs trained:  153Training neural network. Epochs trained:  154Training neural network. Epochs trained:  155Training neural network. Epochs trained:  156Training neural network. Epochs trained:  157Training neural network. Epochs trained:  158Training neural network. Epochs trained:  159Training neural network. Epochs trained:  160Training neural network. Epochs trained:  161Training neural network. Epochs trained:  162Training neural network. Epochs trained:  163Training neural network. Epochs trained:  164Training neural network. Epochs trained:  165Training neural network. Epochs trained:  166Training neural network. Epochs trained:  167Training neural network. Epochs trained:  168Training neural network. Epochs trained:  169Training neural network. Epochs trained:  170Training neural network. Epochs trained:  171Training neural network. Epochs trained:  172Training neural network. Epochs trained:  173Training neural network. Epochs trained:  174Training neural network. Epochs trained:  175Training neural network. Epochs trained:  176Training neural network. Epochs trained:  177Training neural network. Epochs trained:  178Training neural network. Epochs trained:  179Training neural network. Epochs trained:  180Training neural network. Epochs trained:  181Training neural network. Epochs trained:  182Training neural network. Epochs trained:  183Training neural network. Epochs trained:  184Training neural network. Epochs trained:  185Training neural network. Epochs trained:  186Training neural network. Epochs trained:  187Training neural network. Epochs trained:  188Training neural network. Epochs trained:  189Training neural network. Epochs trained:  190Training neural network. Epochs trained:  191Training neural network. Epochs trained:  192Training neural network. Epochs trained:  193Training neural network. Epochs trained:  194Training neural network. Epochs trained:  195Training neural network. Epochs trained:  196Training neural network. Epochs trained:  197Training neural network. Epochs trained:  198Training neural network. Epochs trained:  199Training neural network. Epochs trained:  200Training neural network. Epochs trained:  201Training neural network. Epochs trained:  202Training neural network. Epochs trained:  203Training neural network. Epochs trained:  204Training neural network. Epochs trained:  205Training neural network. Epochs trained:  206Training neural network. Epochs trained:  207Training neural network. Epochs trained:  208Training neural network. Epochs trained:  209Training neural network. Epochs trained:  210Training neural network. Epochs trained:  211Training neural network. Epochs trained:  212Training neural network. Epochs trained:  213Training neural network. Epochs trained:  214Training neural network. Epochs trained:  215Training neural network. Epochs trained:  216Training neural network. Epochs trained:  217Training neural network. Epochs trained:  218Training neural network. Epochs trained:  219Training neural network. Epochs trained:  220Training neural network. Epochs trained:  221Training neural network. Epochs trained:  222Training neural network. Epochs trained:  223Training neural network. Epochs trained:  224Training neural network. Epochs trained:  225Training neural network. Epochs trained:  226Training neural network. Epochs trained:  227Training neural network. Epochs trained:  228Training neural network. Epochs trained:  229Training neural network. Epochs trained:  230Training neural network. Epochs trained:  231Training neural network. Epochs trained:  232Training neural network. Epochs trained:  233Training neural network. Epochs trained:  234Training neural network. Epochs trained:  235Training neural network. Epochs trained:  236Training neural network. Epochs trained:  237Training neural network. Epochs trained:  238Training neural network. Epochs trained:  239Training neural network. Epochs trained:  240Training neural network. Epochs trained:  241Training neural network. Epochs trained:  242Training neural network. Epochs trained:  243Training neural network. Epochs trained:  244Training neural network. Epochs trained:  245Training neural network. Epochs trained:  246Training neural network. Epochs trained:  247Training neural network. Epochs trained:  248Training neural network. Epochs trained:  249Training neural network. Epochs trained:  250Training neural network. Epochs trained:  251Training neural network. Epochs trained:  252Training neural network. Epochs trained:  253Training neural network. Epochs trained:  254Training neural network. Epochs trained:  255Training neural network. Epochs trained:  256Training neural network. Epochs trained:  257Training neural network. Epochs trained:  258Training neural network. Epochs trained:  259Training neural network. Epochs trained:  260Training neural network. Epochs trained:  261Training neural network. Epochs trained:  262Training neural network. Epochs trained:  263Training neural network. Epochs trained:  264Training neural network. Epochs trained:  265Training neural network. Epochs trained:  266Training neural network. Epochs trained:  267Training neural network. Epochs trained:  268Training neural network. Epochs trained:  269Training neural network. Epochs trained:  270Neural network successfully converged after 270 epochs.
log prob true 7.510877
log prob true 7.0335646
log prob true 7.3760157
log prob true 6.7926793
log prob true 6.7472
log prob true 6.9115586
log prob true 6.868088
log prob true 7.2507157
log prob true 7.0104575
log prob true 6.8919797
log prob true 6.8011723
log prob true 7.2514634
log prob true 7.6399374
log prob true 7.1646733
log prob true 6.848295
log prob true 6.584556
log prob true 6.894793
log prob true 7.2131376
log prob true 6.8655095
log prob true 7.3710074
log prob true 7.324769
log prob true 6.898805
log prob true 7.564604
log prob true 6.7373843
log prob true 7.4360065
log prob true 7.075831
log prob true 6.610014
log prob true 6.7374306
log prob true 7.373481
log prob true 5.425302
log prob true 4.0580764
log prob true 4.0902066
log prob true 4.329452
log prob true 2.8963015
log prob true 3.3994284
log prob true 3.1060538
log prob true 3.6680777
log prob true 4.296537
log prob true 3.8718004
log prob true 3.4774022
log prob true 2.9902706
log prob true 4.1216507
log prob true 4.381777
log prob true 3.5894032
log prob true 3.1337895
log prob true 3.0997036
log prob true 3.8253648
log prob true 4.1647024
log prob true 2.4070208
log prob true 4.2826295
log prob true 4.0414305
log prob true 3.8292532
log prob true 4.2704024
log prob true 3.79878
log prob true 4.3269987
log prob true 4.0629196
log prob true 3.2765958
log prob true 3.6614695
log prob true 4.138116
log prob true 2.1386476
log prob true 4.2738094
log prob true 3.889998
log prob true 4.215291
log prob true 2.3472607
log prob true 3.342636
log prob true 3.0330632
log prob true 3.548303
log prob true 4.030497
log prob true 3.7559555
log prob true 3.6321657
log prob true 3.0677845
log prob true 4.044773
log prob true 4.037931
log prob true 3.9171002
log prob true 3.1479084
log prob true 2.9741993
log prob true 3.7306743
log prob true 4.037109
log prob true 1.902762
log prob true 4.1117725
log prob true 3.6873314
log prob true 3.4194455
log prob true 4.365766
log prob true 3.7298458
log prob true 4.2610173
log prob true 3.9305575
log prob true 3.100649
log prob true 3.4256527
log prob true 4.296467
log prob true 1.9060047
log prob true 4.1886897
log prob true 3.821303
log prob true 4.330632
log prob true 2.9472299
log prob true 3.5380292
log prob true 3.0800996
log prob true 3.4815958
log prob true 4.0242867
log prob true 3.8539128
log prob true 3.8400757
log prob true 3.1513708
log prob true 4.020532
log prob true 4.2527785
log prob true 3.9024312
log prob true 3.3214207
log prob true 3.1376224
log prob true 3.877549
log prob true 4.1505303
log prob true 2.5966315
log prob true 4.082879
log prob true 3.7582238
log prob true 3.6722493
log prob true 4.394089
log prob true 3.753282
log prob true 4.3424234
log prob true 3.9118044
log prob true 3.1057446
log prob true 3.4465344
log prob true 4.175734
log prob true 2.1591973
log prob true 7.3772635
log prob true 7.0232577
log prob true 7.145901
log prob true 6.8481135
log prob true 6.6414137
log prob true 6.855447
log prob true 6.789918
log prob true 7.21942
log prob true 6.89061
log prob true 6.965784
log prob true 6.7120967
log prob true 7.218383
log prob true 7.7820673
log prob true 7.0662804
log prob true 6.6272807
log prob true 6.452504
log prob true 6.8178544
log prob true 7.1249795
log prob true 6.620556
log prob true 7.317083
log prob true 7.3279524
log prob true 7.1385455
log prob true 7.3478775
log prob true 6.859503
log prob true 7.3276663
log prob true 7.048205
log prob true 6.40405
log prob true 6.757939
log prob true 7.351481
log prob true 6.8174787
log prob true 4.1461983
log prob true 3.8888392
log prob true 4.378507
log prob true 2.9818535
log prob true 3.3728452
log prob true 3.328847
log prob true 3.610203
log prob true 4.115797
log prob true 3.9484222
log prob true 3.6258523
log prob true 3.0911417
log prob true 4.041384
log prob true 4.274019
log prob true 3.800108
log prob true 3.3222806
log prob true 3.1631901
log prob true 3.8482466
log prob true 4.182382
log prob true 2.6643994
log prob true 4.2442827
log prob true 4.025288
log prob true 3.6781101
log prob true 4.4544773
log prob true 3.7494612
log prob true 4.388343
log prob true 4.000186
log prob true 3.1124103
log prob true 3.5722806
log prob true 4.3732758
log prob true 2.0797675
log prob true 7.524386
log prob true 7.097115
log prob true 7.2813067
log prob true 6.839985
log prob true 6.493117
log prob true 6.8802447
log prob true 6.812292
log prob true 7.253566
log prob true 6.9170437
log prob true 7.041483
log prob true 6.8395123
log prob true 7.3202825
log prob true 7.635441
log prob true 7.0803924
log prob true 6.769477
log prob true 6.508395
log prob true 6.8521757
log prob true 7.034089
log prob true 6.719839
log prob true 7.3694434
log prob true 7.2097464
log prob true 7.1002984
log prob true 7.540828
log prob true 6.935172
log prob true 7.368708
log prob true 7.114206
log prob true 6.3162785
log prob true 6.8387527
log prob true 7.322026
log prob true 6.6290097
log prob true 7.5909977
log prob true 7.241252
log prob true 7.4256454
log prob true 7.1770077
log prob true 7.0452027
log prob true 6.559739
log prob true 7.0608845
log prob true 7.304093
log prob true 7.180324
log prob true 7.12469
log prob true 6.8536186
log prob true 7.440757
log prob true 7.671309
log prob true 7.343455
log prob true 6.9474373
log prob true 6.5554557
log prob true 6.4301186
log prob true 6.959727
log prob true 6.720126
log prob true 7.4774227
log prob true 7.4754786
log prob true 7.025423
log prob true 7.384012
log prob true 6.6947193
log prob true 7.5300403
log prob true 7.326815
log prob true 6.562149
log prob true 6.9769154
log prob true 6.877145
log prob true 6.943046
log prob true 7.7306905
log prob true 7.0461845
log prob true 7.5278635
log prob true 7.0859785
log prob true 6.8574476
log prob true 6.916859
log prob true 6.7931223
log prob true 7.40502
log prob true 7.0026855
log prob true 7.28615
log prob true 7.0793066
log prob true 7.3113656
log prob true 7.706862
log prob true 7.21885
log prob true 6.9521866
log prob true 6.6345606
log prob true 7.024889
log prob true 7.3689437
log prob true 6.8607535
log prob true 7.510624
log prob true 7.1763034
log prob true 7.1600695
log prob true 7.629778
log prob true 6.990986
log prob true 7.5861373
log prob true 7.253016
log prob true 6.5808816
log prob true 6.961481
log prob true 7.5006366
log prob true 6.985016
log prob true 4.406928
log prob true 3.8445323
log prob true 4.360034
log prob true 3.1323605
log prob true 3.3520253
log prob true 3.0904822
log prob true 3.717785
log prob true 4.1982102
log prob true 3.9160082
log prob true 4.0526896
log prob true 3.5162911
log prob true 4.1427717
log prob true 4.366208
log prob true 4.0856395
log prob true 3.4416041
log prob true 3.2228866
log prob true 3.7395577
log prob true 4.1837335
log prob true 3.0443285
log prob true 4.2770596
log prob true 4.120379
log prob true 3.775586
log prob true 4.389316
log prob true 3.9090993
log prob true 4.4366727
log prob true 4.117958
log prob true 3.1816413
log prob true 3.6254456
log prob true 4.368188
log prob true 2.2286673
script complete
