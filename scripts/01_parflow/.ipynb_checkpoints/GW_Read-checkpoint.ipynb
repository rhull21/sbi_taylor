{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from parflow import Run\n",
    "from parflow.tools.fs import cp, mkdir\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import calendar\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 100.0 not included\n",
      "M 0.001 not included\n"
     ]
    }
   ],
   "source": [
    "# QH: must edit each time\n",
    "# ensemble_name (for the ensemble of outputs generated)\n",
    "ensemble_name = '0819_01'\n",
    "\n",
    "# modifications\n",
    "ensemble_name_mod = '0819_01_mod2'\n",
    "remove_list = [[100],[0.001]]\n",
    "\n",
    "# (where it saves and references)\n",
    "path_folder = '/scratch/taylor/ensembles_sbi/02_PARFLOW_OUT/02_PARFLOW_OUT/' # /home/qh8373/SBI_TAYLOR/data/02_PARFLOW_OUT/'\n",
    "supporting_folder = '/home/qh8373/SBI_TAYLOR/sbi_taylor/scripts/00_supporting/'\n",
    "\n",
    "#creating directory for the output\n",
    "out_dir = f'/home/qh8373/SBI_TAYLOR/data/01_c_gw_sim/{ensemble_name_mod}/'\n",
    "try:\n",
    "  os.makedirs(out_dir)\n",
    "except:\n",
    "  'directory exists'\n",
    "\n",
    "\n",
    "# QH Edit to include just the years you want, note that 1983 is not a good year\n",
    "# QH Edit - note that we may in some cases want to run an additional year of simulations on top of what we have already done\n",
    "new_Run = True # Set this to 'false' if not a new run \n",
    "year_run = 1995\n",
    "if calendar.isleap(year_run):\n",
    "  no_day = 366\n",
    "else:\n",
    "  no_day = 365\n",
    " \n",
    "# Set Parameter of Concernm (POC) - 'K', 'M', 'KM' \n",
    "POC = 'KM'\n",
    "\n",
    "# do multiple for different K / Mannings value\n",
    "AOC_vals = []\n",
    "for idx in range(len(POC)):\n",
    "    remove_list_temp = remove_list[idx]\n",
    "    POC_in = POC[idx]\n",
    "    AOC_vals.append([])\n",
    "    with open(f'{supporting_folder}{ensemble_name}_{POC_in}_{year_run}.txt', 'r') as AOC_lines:\n",
    "        # print(AOC_lines)\n",
    "        for line in AOC_lines:\n",
    "            add_temp = float(line)\n",
    "            if (add_temp in remove_list_temp):\n",
    "                print(POC_in, add_temp, 'not included')\n",
    "            else:\n",
    "                AOC_vals[idx].append(float(line))\n",
    "    AOC_lines.close()\n",
    "\n",
    "# Set up number of unique permutations of lists in tuples\n",
    "# https://cmsdk.com/python/all-possible-permutations-of-multiple-lists-and-sizes.html \n",
    "AOC_tuples = []\n",
    "for i in list(itertools.product(*AOC_vals)):\n",
    "    AOC_tuples.append(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001, 1e-08)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/taylor/ensembles_sbi/02_PARFLOW_OUT/02_PARFLOW_OUT/0819_01_K-0.001-M-1e-08-_1995/Taylor_1995.pfidb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c980d031b919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# load the PF metadata and put it in the run data structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_definition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_PFdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m# get dimensions of domain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/parflow/tools/core.py\u001b[0m in \u001b[0;36mfrom_definition\u001b[0;34m(cls, file_path)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mnew_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mext_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mnew_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpfset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilence_if_undefined\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# Try to solve order sensitive property settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/parflow/tools/database/core.py\u001b[0m in \u001b[0;36mpfset\u001b[0;34m(self, key, value, yaml_file, yaml_content, pfidb_file, hierarchical_map, flat_map, exit_if_undefined, silence_if_undefined)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpfidb_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mflat_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_pfidb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfidb_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhierarchical_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/SHARED/software/anaconda3/2020.07e/lib/python3.8/site-packages/parflow/tools/io.py\u001b[0m in \u001b[0;36mread_pfidb\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0mfull_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_absolute_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/taylor/ensembles_sbi/02_PARFLOW_OUT/02_PARFLOW_OUT/0819_01_K-0.001-M-1e-08-_1995/Taylor_1995.pfidb'"
     ]
    }
   ],
   "source": [
    "# Loop through ensemble\n",
    "for idx in range(len(AOC_tuples)):# len(AOC_tuples)\n",
    "  # make this as the AOC value\n",
    "  AOC = AOC_tuples[idx]\n",
    "  print(AOC)\n",
    "  \n",
    "  AOC_str = ''\n",
    "  for AOC_idx in range(len(AOC)):\n",
    "      AOC_str = AOC_str+str(POC[AOC_idx])+'-'+str(AOC[AOC_idx])\n",
    "      if AOC_idx != len(AOC):\n",
    "          AOC_str = AOC_str+'-'\n",
    "\n",
    "\n",
    "  name_run = f'{ensemble_name}_{AOC_str}_{year_run}' \n",
    "  run_dir = f'{path_folder}{name_run}'\n",
    "  path_PFdatabase = f'{run_dir}/Taylor_{year_run}.pfidb'\n",
    " \n",
    "#   print(run_dir)\n",
    "  \n",
    "  # load the PF metadata and put it in the run data structure\n",
    "  run = Run.from_definition(path_PFdatabase)\n",
    "  \n",
    "  # get dimensions of domain\n",
    "  nx = run.ComputationalGrid.NX\n",
    "  ny = run.ComputationalGrid.NY\n",
    "  \n",
    "  # get data\n",
    "  data = run.data_accessor\n",
    "  \n",
    "  # initialize holding array\n",
    "  store_arr = np.empty((no_day+1, 3))\n",
    "  \n",
    "  # ---------\n",
    "  # read dynamic PF-CLM Outputs\n",
    "  # ---------\n",
    "  for i in range(no_day+1):\n",
    "      data.time = i # time step for all Pf-cLM outputs\n",
    "    #   data.forcing_time = 0 # time step for all forcings\n",
    "      \n",
    "      # storages\n",
    "      w = 'subsurface_storage'\n",
    "      sub_array = getattr(data,w)\n",
    "      sub_sum = np.round(sub_array.sum(), 0)\n",
    "      \n",
    "      w = 'surface_storage'\n",
    "      surf_array = getattr(data,w)\n",
    "      surf_sum = np.round(surf_array.sum(), 0)\n",
    "     \n",
    "      tot_sum = np.round(sub_sum + surf_sum, 0)\n",
    "     \n",
    "#       # append\n",
    "#       store_arr[i, :] = [sub_sum, surf_sum, tot_sum] \n",
    "     \n",
    "      del sub_array, sub_sum, surf_array, surf_sum, tot_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   fig, ax = plt.subplots()\n",
    "  \n",
    "#   ax.plot(store_arr[:,1], label='surface', color='red')\n",
    "#   ax.set_xlabel('time (days)')\n",
    "#   ax.set_ylabel('total storage (units?)')\n",
    "# #   ax.set_ylim(1e10, 1e11)\n",
    "  \n",
    "# #   print((store_arr[:,0]/store_arr[:,2]))\n",
    "  \n",
    "# #   ax2 = ax.twinx()\n",
    "# #   ax2.plot((store_arr[:,0]/store_arr[:,2]), label='percent subsurface', color='red')\n",
    "# #   ax2.set_ylabel('perc subsurface (decimal)')\n",
    "# #   ax2.set_ylim(0, 1.1)\n",
    "\n",
    "#   ax.set_title(f'{name_run} surface storage unscaled')\n",
    "#   fig.legend()\n",
    "#   fig.savefig(f'{out_dir}{name_run}_surface_storage_unscaled.png')\n",
    "#   plt.show()\n",
    "#   plt.close()\n",
    "  \n",
    "  \n",
    "#   fig, ax = plt.subplots()\n",
    "  \n",
    "#   ax.plot(store_arr[:,2], label='total')\n",
    "#   ax.set_xlabel('time (days)')\n",
    "#   ax.set_ylabel('total storage (units?)')\n",
    "# #   ax.set_ylim(1e10, 1e11)\n",
    "  \n",
    "# #   print((store_arr[:,0]/store_arr[:,2]))\n",
    "  \n",
    "# #   ax2 = ax.twinx()\n",
    "# #   ax2.plot((store_arr[:,0]/store_arr[:,2]), label='percent subsurface', color='red')\n",
    "# #   ax2.set_ylabel('perc subsurface (decimal)')\n",
    "# #   ax2.set_ylim(0, 1.1)\n",
    "\n",
    "#   ax.set_title(f'{name_run} storage unscaled')\n",
    "#   fig.legend()\n",
    "#   fig.savefig(f'{out_dir}{name_run}_storage_unscaled.png')\n",
    "#   plt.show()\n",
    "#   plt.close()\n",
    "  \n",
    "#   # calculate net storage change and update\n",
    "#   for j in range(3):\n",
    "#     out = abs(store_arr[0,j] - store_arr[365,j]) / store_arr[0,j]\n",
    "#     # print(out)\n",
    "#     dS_arr[idx, j] = out\n",
    "#     del out\n",
    "    \n",
    "# #   print(dS_arr[idx, :])\n",
    "\n",
    "  \n",
    "# # ------\n",
    "# # compare change in storage for all models\n",
    "# # ------\n",
    "# fig, ax = plt.subplots(1,3, sharey=True)\n",
    "\n",
    "# nmlist = ['subsurface', 'surface', 'total']\n",
    "# for l in range(3):\n",
    "#     ax[l].boxplot(dS_arr[:, l]) # , labels=nmlist[l])\n",
    "#     ax[l].set_ylim(0.0000001,10)\n",
    "#     ax[l].set_yscale('log')\n",
    "#     ax[l].set_title(f'{nmlist[l]} storage')\n",
    "#     if l == 0:\n",
    "#         ax[l].set_ylabel('perc change storage')\n",
    "\n",
    "# fig.legend()\n",
    "# fig.savefig(f'{out_dir}00_all_deltastorage_log.png')\n",
    "# fig.savefig(f'{out_dir}00_all_deltastorage_log.eps', type='eps')\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
